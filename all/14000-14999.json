[{"original_method":"@Override\n  public void generate() {\n    IXtextProjectConfig _projectConfig = this.getProjectConfig();\n    ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n    boolean _isEnabled = _ideaPlugin.isEnabled();\n    boolean _not = (!_isEnabled);\n    if (_not) {\n      return;\n    }\n    IXtextGeneratorLanguage _language = this.getLanguage();\n    List<String> _fileExtensions = _language.getFileExtensions();\n    final String fileExtension = IterableExtensions.<String>head(_fileExtensions);\n    IXtextGeneratorLanguage _language_1 = this.getLanguage();\n    final Grammar grammar = _language_1.getGrammar();\n    final GuiceModuleAccess.BindingFactory bindFactory = new GuiceModuleAccess.BindingFactory();\n    TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.IAntlrTokenFileProvider\");\n    TypeReference _antlrTokenFileProvider = this._ideaPluginClassNames.getAntlrTokenFileProvider(grammar);\n    bindFactory.addTypeToType(_typeRef, _antlrTokenFileProvider);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.Lexer\");\n    TypeReference _psiInternalLexer = this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n    bindFactory.addTypeToType(_typeRef_1, _psiInternalLexer);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        _builder.append(Lexer.class, \"\");\n        _builder.append(\".class)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".annotatedWith(\");\n        _builder.append(Names.class, \"\\t\");\n        _builder.append(\".named(\");\n        _builder.append(LexerBindings.class, \"\\t\");\n        _builder.append(\".RUNTIME))\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".to(\");\n        TypeReference _psiInternalLexer = IdeaPluginGenerator.this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n        _builder.append(_psiInternalLexer, \"\\t\");\n        _builder.append(\".class);\");\n        _builder.newLineIfNotEmpty();\n      }\n    };\n    bindFactory.addConfiguredBinding(\"RuntimeLexer\", _client);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.lang.PsiParser\");\n    TypeReference _psiParser = this._ideaPluginClassNames.getPsiParser(grammar);\n    bindFactory.addTypeToType(_typeRef_2, _psiParser);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"org.eclipse.xtext.idea.parser.TokenTypeProvider\");\n    TypeReference _tokenTypeProvider = this._ideaPluginClassNames.getTokenTypeProvider(grammar);\n    bindFactory.addTypeToType(_typeRef_3, _tokenTypeProvider);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.lang.ParserDefinition\");\n    TypeReference _parserDefinition = this._ideaPluginClassNames.getParserDefinition(grammar);\n    bindFactory.addTypeToType(_typeRef_4, _parserDefinition);\n    TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.IElementTypeProvider\");\n    TypeReference _elementTypeProvider = this._ideaPluginClassNames.getElementTypeProvider(grammar);\n    bindFactory.addTypeToTypeSingleton(_typeRef_5, _elementTypeProvider);\n    TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n    TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n    bindFactory.addTypeToType(_typeRef_6, _facetConfiguration);\n    TypeReference _typeRef_7 = TypeReference.typeRef(\"com.intellij.facet.FacetTypeId\");\n    StringConcatenationClient _client_1 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        TypeReference _facetType = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetType(grammar);\n        _builder.append(_facetType, \"\");\n        _builder.append(\".TYPEID\");\n      }\n    };\n    bindFactory.addTypeToInstance(_typeRef_7, _client_1);\n    TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.IContentAssistParser\");\n    TypeReference _parserClass = this.caNaming.getParserClass(grammar);\n    bindFactory.addTypeToType(_typeRef_8, _parserClass);\n    StringConcatenationClient _client_2 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.internal.Lexer\");\n        _builder.append(_typeRef, \"\");\n        _builder.append(\".class).annotatedWith(\");\n        _builder.append(Names.class, \"\");\n        _builder.append(\".named(\");\n        TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.ide.LexerIdeBindings\");\n        _builder.append(_typeRef_1, \"\");\n        _builder.append(\".CONTENT_ASSIST)).to(\");\n        TypeReference _lexerClass = IdeaPluginGenerator.this.caNaming.getLexerClass(grammar);\n        _builder.append(_lexerClass, \"\");\n        _builder.append(\".class);\");\n      }\n    };\n    bindFactory.addConfiguredBinding(\"ContentAssistLexer\", _client_2);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_9 = TypeReference.typeRef(\"org.eclipse.xtext.common.types.xtext.AbstractTypeScopeProvider\");\n      TypeReference _typeRef_10 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.StubBasedTypeScopeProvider\");\n      bindFactory.addTypeToType(_typeRef_9, _typeRef_10);\n      TypeReference _typeReference = new TypeReference(\"org.eclipse.xtext.xbase.typesystem.internal\", \"IFeatureScopeTracker.Provider\");\n      TypeReference _typeRef_11 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.typesystem.internal.OptimizingFeatureScopeTrackerProvider\");\n      bindFactory.addTypeToType(_typeReference, _typeRef_11);\n      StringConcatenationClient _client_3 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"binder.bind(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.psi.IPsiModelAssociations\");\n          _builder.append(_typeRef, \"\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".annotatedWith(\");\n          _builder.append(LanguageSpecific.class, \"\\t\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".to(\");\n          TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.DerivedMemberAwarePsiModelAssociations\");\n          _builder.append(_typeRef_1, \"\\t\");\n          _builder.append(\".class);\");\n          _builder.newLineIfNotEmpty();\n        }\n      };\n      bindFactory.addConfiguredBinding(\"LanguageSpecificPsiModelAssociations\", _client_3);\n      TypeReference _typeRef_12 = TypeReference.typeRef(\"org.eclipse.xtext.idea.highlighting.IHighlightingConfiguration\");\n      TypeReference _typeRef_13 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.highlighting.XbaseHighlightingConfiguration\");\n      bindFactory.addTypeToType(_typeRef_12, _typeRef_13);\n      TypeReference _typeRef_14 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.BlockFactory\");\n      TypeReference _typeRef_15 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseBlockFactory\");\n      bindFactory.addTypeToType(_typeRef_14, _typeRef_15);\n      TypeReference _typeRef_16 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.ChildAttributesProvider\");\n      TypeReference _typeRef_17 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseChildAttributesProvider\");\n      bindFactory.addTypeToType(_typeRef_16, _typeRef_17);\n      TypeReference _typeRef_18 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.bracketmatching.IBracePairProvider\");\n      TypeReference _typeRef_19 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.bracketmatching.XbaseBracePairProvider\");\n      bindFactory.addTypeToType(_typeRef_18, _typeRef_19);\n      TypeReference _typeRef_20 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.IReferenceSearcher\");\n      TypeReference _typeRef_21 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.findusages.JvmElementAwareReferenceSearcher\");\n      bindFactory.addTypeToType(_typeRef_20, _typeRef_21);\n      TypeReference _typeRef_22 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.compiler.IGeneratorConfigProvider\");\n      TypeReference _typeRef_23 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigProvider\");\n      bindFactory.addTypeToType(_typeRef_22, _typeRef_23);\n      TypeReference _typeRef_24 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.WordsScannerProvider\");\n      TypeReference _typeReference_1 = new TypeReference(\"org.eclipse.xtext.xbase.idea.findusages\", \"XbaseWordsScanner.XbaseWordsScannerProvider\");\n      bindFactory.addTypeToType(_typeRef_24, _typeReference_1);\n    }\n    IXtextGeneratorLanguage _language_2 = this.getLanguage();\n    GuiceModuleAccess _ideaGenModule = _language_2.getIdeaGenModule();\n    bindFactory.contributeTo(_ideaGenModule);\n    XtendFileAccess _compileStandaloneSetup = this.compileStandaloneSetup(grammar);\n    XtendFileAccess _compileIdeaSetup = this.compileIdeaSetup(grammar);\n    JavaFileAccess _compileCompletionContributor = this.compileCompletionContributor(grammar);\n    XtendFileAccess _compileFileType = this.compileFileType(grammar);\n    JavaFileAccess _compileFacetConfiguration = this.compileFacetConfiguration(grammar);\n    JavaFileAccess _compileColorSettingsPage = this.compileColorSettingsPage(grammar);\n    final Procedure1<JavaFileAccess> _function = new Procedure1<JavaFileAccess>() {\n      @Override\n      public void apply(final JavaFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _src = _ideaPlugin.getSrc();\n        it.writeTo(_src);\n      }\n    };\n    IterableExtensions.forEach(Collections.<JavaFileAccess>unmodifiableList(CollectionLiterals.<JavaFileAccess>newArrayList(_compileStandaloneSetup, _compileIdeaSetup, _compileCompletionContributor, _compileFileType, _compileFacetConfiguration, _compileColorSettingsPage)), _function);\n    TextFileAccess _compileServicesISetup = this.compileServicesISetup(grammar);\n    JavaFileAccess _compileAbstractCompletionContributor = this.compileAbstractCompletionContributor(grammar);\n    JavaFileAccess _compileLanguage = this.compileLanguage(grammar);\n    JavaFileAccess _compileAbstractFileType = this.compileAbstractFileType(grammar, fileExtension);\n    JavaFileAccess _compileFileTypeFactory = this.compileFileTypeFactory(grammar);\n    JavaFileAccess _compileFileImpl = this.compileFileImpl(grammar);\n    JavaFileAccess _compileTokenTypeProvider = this.compileTokenTypeProvider(grammar);\n    JavaFileAccess _compileElementTypeProvider = this.compileElementTypeProvider(grammar);\n    JavaFileAccess _compileParserDefinition = this.compileParserDefinition(grammar);\n    JavaFileAccess _compileSyntaxHighlighterFactory = this.compileSyntaxHighlighterFactory(grammar);\n    JavaFileAccess _compileSemanticHighlightVisitor = this.compileSemanticHighlightVisitor(grammar);\n    JavaFileAccess _compileExtensionFactory = this.compileExtensionFactory(grammar);\n    JavaFileAccess _compileCodeBlockModificationListener = this.compileCodeBlockModificationListener(grammar);\n    JavaFileAccess _compilePsiParser = this.compilePsiParser(grammar);\n    JavaFileAccess _compileAntlrTokenFileProvider = this.compileAntlrTokenFileProvider(grammar);\n    JavaFileAccess _compilePomDeclarationSearcher = this.compilePomDeclarationSearcher(grammar);\n    JavaFileAccess _compileFacetType = this.compileFacetType(grammar);\n    JavaFileAccess _compileBaseColorSettingsPage = this.compileBaseColorSettingsPage(grammar);\n    final Procedure1<TextFileAccess> _function_1 = new Procedure1<TextFileAccess>() {\n      @Override\n      public void apply(final TextFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _srcGen = _ideaPlugin.getSrcGen();\n        it.writeTo(_srcGen);\n      }\n    };\n    IterableExtensions.forEach(Collections.<TextFileAccess>unmodifiableList(CollectionLiterals.<TextFileAccess>newArrayList(_compileServicesISetup, _compileAbstractCompletionContributor, _compileLanguage, _compileAbstractFileType, _compileFileTypeFactory, _compileFileImpl, _compileTokenTypeProvider, _compileElementTypeProvider, _compileParserDefinition, _compileSyntaxHighlighterFactory, _compileSemanticHighlightVisitor, _compileExtensionFactory, _compileCodeBlockModificationListener, _compilePsiParser, _compileAntlrTokenFileProvider, _compilePomDeclarationSearcher, _compileFacetType, _compileBaseColorSettingsPage)), _function_1);\n    if (this.deployable) {\n      final TextFileAccess pluginXml = this.compilePluginXml(grammar);\n      IXtextProjectConfig _projectConfig_1 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_1 = _projectConfig_1.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf = _ideaPlugin_1.getMetaInf();\n      String _path = pluginXml.getPath();\n      boolean _isFile = _metaInf.isFile(_path);\n      boolean _not_1 = (!_isFile);\n      if (_not_1) {\n        IXtextProjectConfig _projectConfig_2 = this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin_2 = _projectConfig_2.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _metaInf_1 = _ideaPlugin_2.getMetaInf();\n        pluginXml.writeTo(_metaInf_1);\n      }\n      TextFileAccess _compilePluginGenXml = this.compilePluginGenXml(grammar);\n      IXtextProjectConfig _projectConfig_3 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_3 = _projectConfig_3.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf_2 = _ideaPlugin_3.getMetaInf();\n      _compilePluginGenXml.writeTo(_metaInf_2);\n    }\n  }","id":14000,"modified_method":"@Override\n  public void generate() {\n    IXtextProjectConfig _projectConfig = this.getProjectConfig();\n    ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n    boolean _isEnabled = _ideaPlugin.isEnabled();\n    boolean _not = (!_isEnabled);\n    if (_not) {\n      return;\n    }\n    IXtextGeneratorLanguage _language = this.getLanguage();\n    List<String> _fileExtensions = _language.getFileExtensions();\n    final String fileExtension = IterableExtensions.<String>head(_fileExtensions);\n    IXtextGeneratorLanguage _language_1 = this.getLanguage();\n    final Grammar grammar = _language_1.getGrammar();\n    final GuiceModuleAccess.BindingFactory bindFactory = new GuiceModuleAccess.BindingFactory();\n    TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.IAntlrTokenFileProvider\");\n    TypeReference _antlrTokenFileProvider = this._ideaPluginClassNames.getAntlrTokenFileProvider(grammar);\n    bindFactory.addTypeToType(_typeRef, _antlrTokenFileProvider);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.Lexer\");\n    TypeReference _psiInternalLexer = this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n    bindFactory.addTypeToType(_typeRef_1, _psiInternalLexer);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        _builder.append(Lexer.class, \"\");\n        _builder.append(\".class)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".annotatedWith(\");\n        _builder.append(Names.class, \"\\t\");\n        _builder.append(\".named(\");\n        _builder.append(LexerBindings.class, \"\\t\");\n        _builder.append(\".RUNTIME))\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".to(\");\n        TypeReference _psiInternalLexer = IdeaPluginGenerator.this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n        _builder.append(_psiInternalLexer, \"\\t\");\n        _builder.append(\".class);\");\n        _builder.newLineIfNotEmpty();\n      }\n    };\n    bindFactory.addConfiguredBinding(\"RuntimeLexer\", _client);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.lang.PsiParser\");\n    TypeReference _psiParser = this._ideaPluginClassNames.getPsiParser(grammar);\n    bindFactory.addTypeToType(_typeRef_2, _psiParser);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"org.eclipse.xtext.idea.parser.TokenTypeProvider\");\n    TypeReference _tokenTypeProvider = this._ideaPluginClassNames.getTokenTypeProvider(grammar);\n    bindFactory.addTypeToType(_typeRef_3, _tokenTypeProvider);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.lang.ParserDefinition\");\n    TypeReference _parserDefinition = this._ideaPluginClassNames.getParserDefinition(grammar);\n    bindFactory.addTypeToType(_typeRef_4, _parserDefinition);\n    TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.IElementTypeProvider\");\n    TypeReference _elementTypeProvider = this._ideaPluginClassNames.getElementTypeProvider(grammar);\n    bindFactory.addTypeToTypeSingleton(_typeRef_5, _elementTypeProvider);\n    TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n    TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n    bindFactory.addTypeToType(_typeRef_6, _facetConfiguration);\n    TypeReference _typeRef_7 = TypeReference.typeRef(\"com.intellij.facet.FacetTypeId\");\n    StringConcatenationClient _client_1 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        TypeReference _facetType = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetType(grammar);\n        _builder.append(_facetType, \"\");\n        _builder.append(\".TYPEID\");\n      }\n    };\n    bindFactory.addTypeToInstance(_typeRef_7, _client_1);\n    TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.IContentAssistParser\");\n    TypeReference _parserClass = this.caNaming.getParserClass(grammar);\n    bindFactory.addTypeToType(_typeRef_8, _parserClass);\n    StringConcatenationClient _client_2 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.internal.Lexer\");\n        _builder.append(_typeRef, \"\");\n        _builder.append(\".class).annotatedWith(\");\n        _builder.append(Names.class, \"\");\n        _builder.append(\".named(\");\n        TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.ide.LexerIdeBindings\");\n        _builder.append(_typeRef_1, \"\");\n        _builder.append(\".CONTENT_ASSIST)).to(\");\n        TypeReference _lexerClass = IdeaPluginGenerator.this.caNaming.getLexerClass(grammar);\n        _builder.append(_lexerClass, \"\");\n        _builder.append(\".class);\");\n      }\n    };\n    bindFactory.addConfiguredBinding(\"ContentAssistLexer\", _client_2);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_9 = TypeReference.typeRef(\"org.eclipse.xtext.common.types.xtext.AbstractTypeScopeProvider\");\n      TypeReference _typeRef_10 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.StubBasedTypeScopeProvider\");\n      bindFactory.addTypeToType(_typeRef_9, _typeRef_10);\n      TypeReference _typeReference = new TypeReference(\"org.eclipse.xtext.xbase.typesystem.internal\", \"IFeatureScopeTracker.Provider\");\n      TypeReference _typeRef_11 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.typesystem.internal.OptimizingFeatureScopeTrackerProvider\");\n      bindFactory.addTypeToType(_typeReference, _typeRef_11);\n      StringConcatenationClient _client_3 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"binder.bind(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.psi.IPsiModelAssociations\");\n          _builder.append(_typeRef, \"\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".annotatedWith(\");\n          _builder.append(LanguageSpecific.class, \"\\t\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".to(\");\n          TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.DerivedMemberAwarePsiModelAssociations\");\n          _builder.append(_typeRef_1, \"\\t\");\n          _builder.append(\".class);\");\n          _builder.newLineIfNotEmpty();\n        }\n      };\n      bindFactory.addConfiguredBinding(\"LanguageSpecificPsiModelAssociations\", _client_3);\n      TypeReference _typeRef_12 = TypeReference.typeRef(\"org.eclipse.xtext.idea.highlighting.IHighlightingConfiguration\");\n      TypeReference _typeRef_13 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.highlighting.XbaseHighlightingConfiguration\");\n      bindFactory.addTypeToType(_typeRef_12, _typeRef_13);\n      TypeReference _typeRef_14 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.BlockFactory\");\n      TypeReference _typeRef_15 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseBlockFactory\");\n      bindFactory.addTypeToType(_typeRef_14, _typeRef_15);\n      TypeReference _typeRef_16 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.ChildAttributesProvider\");\n      TypeReference _typeRef_17 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseChildAttributesProvider\");\n      bindFactory.addTypeToType(_typeRef_16, _typeRef_17);\n      TypeReference _typeRef_18 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.bracketmatching.IBracePairProvider\");\n      TypeReference _typeRef_19 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.bracketmatching.XbaseBracePairProvider\");\n      bindFactory.addTypeToType(_typeRef_18, _typeRef_19);\n      TypeReference _typeRef_20 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.IReferenceSearcher\");\n      TypeReference _typeRef_21 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.findusages.JvmElementAwareReferenceSearcher\");\n      bindFactory.addTypeToType(_typeRef_20, _typeRef_21);\n      TypeReference _typeRef_22 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.compiler.IGeneratorConfigProvider\");\n      TypeReference _typeRef_23 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigProvider\");\n      bindFactory.addTypeToType(_typeRef_22, _typeRef_23);\n      TypeReference _typeRef_24 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.WordsScannerProvider\");\n      TypeReference _typeReference_1 = new TypeReference(\"org.eclipse.xtext.xbase.idea.findusages\", \"XbaseWordsScanner.XbaseWordsScannerProvider\");\n      bindFactory.addTypeToType(_typeRef_24, _typeReference_1);\n    }\n    IXtextGeneratorLanguage _language_2 = this.getLanguage();\n    GuiceModuleAccess _ideaGenModule = _language_2.getIdeaGenModule();\n    bindFactory.contributeTo(_ideaGenModule);\n    JavaFileAccess _compileStandaloneSetup = this.compileStandaloneSetup(grammar);\n    JavaFileAccess _compileIdeaSetup = this.compileIdeaSetup(grammar);\n    JavaFileAccess _compileCompletionContributor = this.compileCompletionContributor(grammar);\n    JavaFileAccess _compileFileType = this.compileFileType(grammar);\n    JavaFileAccess _compileFacetConfiguration = this.compileFacetConfiguration(grammar);\n    JavaFileAccess _compileColorSettingsPage = this.compileColorSettingsPage(grammar);\n    final Procedure1<JavaFileAccess> _function = new Procedure1<JavaFileAccess>() {\n      @Override\n      public void apply(final JavaFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _src = _ideaPlugin.getSrc();\n        it.writeTo(_src);\n      }\n    };\n    IterableExtensions.<JavaFileAccess>forEach(Collections.<JavaFileAccess>unmodifiableList(CollectionLiterals.<JavaFileAccess>newArrayList(_compileStandaloneSetup, _compileIdeaSetup, _compileCompletionContributor, _compileFileType, _compileFacetConfiguration, _compileColorSettingsPage)), _function);\n    TextFileAccess _compileServicesISetup = this.compileServicesISetup(grammar);\n    JavaFileAccess _compileAbstractCompletionContributor = this.compileAbstractCompletionContributor(grammar);\n    JavaFileAccess _compileLanguage = this.compileLanguage(grammar);\n    JavaFileAccess _compileAbstractFileType = this.compileAbstractFileType(grammar, fileExtension);\n    JavaFileAccess _compileFileTypeFactory = this.compileFileTypeFactory(grammar);\n    JavaFileAccess _compileFileImpl = this.compileFileImpl(grammar);\n    JavaFileAccess _compileTokenTypeProvider = this.compileTokenTypeProvider(grammar);\n    JavaFileAccess _compileElementTypeProvider = this.compileElementTypeProvider(grammar);\n    JavaFileAccess _compileParserDefinition = this.compileParserDefinition(grammar);\n    JavaFileAccess _compileSyntaxHighlighterFactory = this.compileSyntaxHighlighterFactory(grammar);\n    JavaFileAccess _compileSemanticHighlightVisitor = this.compileSemanticHighlightVisitor(grammar);\n    JavaFileAccess _compileExtensionFactory = this.compileExtensionFactory(grammar);\n    JavaFileAccess _compileCodeBlockModificationListener = this.compileCodeBlockModificationListener(grammar);\n    JavaFileAccess _compilePsiParser = this.compilePsiParser(grammar);\n    JavaFileAccess _compileAntlrTokenFileProvider = this.compileAntlrTokenFileProvider(grammar);\n    JavaFileAccess _compilePomDeclarationSearcher = this.compilePomDeclarationSearcher(grammar);\n    JavaFileAccess _compileFacetType = this.compileFacetType(grammar);\n    JavaFileAccess _compileBaseColorSettingsPage = this.compileBaseColorSettingsPage(grammar);\n    final Procedure1<TextFileAccess> _function_1 = new Procedure1<TextFileAccess>() {\n      @Override\n      public void apply(final TextFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _srcGen = _ideaPlugin.getSrcGen();\n        it.writeTo(_srcGen);\n      }\n    };\n    IterableExtensions.forEach(Collections.<TextFileAccess>unmodifiableList(CollectionLiterals.<TextFileAccess>newArrayList(_compileServicesISetup, _compileAbstractCompletionContributor, _compileLanguage, _compileAbstractFileType, _compileFileTypeFactory, _compileFileImpl, _compileTokenTypeProvider, _compileElementTypeProvider, _compileParserDefinition, _compileSyntaxHighlighterFactory, _compileSemanticHighlightVisitor, _compileExtensionFactory, _compileCodeBlockModificationListener, _compilePsiParser, _compileAntlrTokenFileProvider, _compilePomDeclarationSearcher, _compileFacetType, _compileBaseColorSettingsPage)), _function_1);\n    if (this.deployable) {\n      final TextFileAccess pluginXml = this.compilePluginXml(grammar);\n      IXtextProjectConfig _projectConfig_1 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_1 = _projectConfig_1.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf = _ideaPlugin_1.getMetaInf();\n      String _path = pluginXml.getPath();\n      boolean _isFile = _metaInf.isFile(_path);\n      boolean _not_1 = (!_isFile);\n      if (_not_1) {\n        IXtextProjectConfig _projectConfig_2 = this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin_2 = _projectConfig_2.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _metaInf_1 = _ideaPlugin_2.getMetaInf();\n        pluginXml.writeTo(_metaInf_1);\n      }\n      TextFileAccess _compilePluginGenXml = this.compilePluginGenXml(grammar);\n      IXtextProjectConfig _projectConfig_3 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_3 = _projectConfig_3.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf_2 = _ideaPlugin_3.getMetaInf();\n      _compilePluginGenXml.writeTo(_metaInf_2);\n    }\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"public JavaFileAccess compileCompletionContributor(final Grammar grammar) {\n    TypeReference _completionContributor = this._ideaPluginClassNames.getCompletionContributor(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n        String _simpleName = _completionContributor.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n        _builder.append(_abstractCompletionContributor, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"new() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"this(\");\n        TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n        _builder.append(_ideaLanguage, \"\\t\\t\");\n        _builder.append(\".INSTANCE)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"new(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n        _builder.append(_typeRef, \"\\t\");\n        _builder.append(\" lang) {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"super(lang)\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"//custom rules here\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_completionContributor, _client);\n  }","id":14001,"modified_method":"public JavaFileAccess compileCompletionContributor(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _completionContributor = this._ideaPluginClassNames.getCompletionContributor(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName = _completionContributor.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n          _builder.append(_abstractCompletionContributor, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"new() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"this(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"new(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n          _builder.append(_typeRef, \"\\t\");\n          _builder.append(\" lang) {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(lang)\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"//custom rules here\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_completionContributor, _client);\n    } else {\n      TypeReference _completionContributor_1 = this._ideaPluginClassNames.getCompletionContributor(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName = _completionContributor.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n          _builder.append(_abstractCompletionContributor, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _completionContributor_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName_1 = _completionContributor_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\"() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"this(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _completionContributor_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName_2 = _completionContributor_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n          _builder.append(_typeRef, \"\\t\");\n          _builder.append(\" lang) {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(lang);\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"//custom rules here\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_completionContributor_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"public XtendFileAccess compileFileType(final Grammar grammar) {\n    TypeReference _fileType = this._ideaPluginClassNames.getFileType(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName = _fileType.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n        _builder.append(_abstractFileType, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"public static final \");\n        TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName_1 = _fileType_1.getSimpleName();\n        _builder.append(_simpleName_1, \"\\t\");\n        _builder.append(\" INSTANCE = new \");\n        TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName_2 = _fileType_2.getSimpleName();\n        _builder.append(_simpleName_2, \"\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"new() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"super(\");\n        TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n        _builder.append(_ideaLanguage, \"\\t\\t\");\n        _builder.append(\".INSTANCE)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_fileType, _client);\n  }","id":14002,"modified_method":"public JavaFileAccess compileFileType(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _fileType = this._ideaPluginClassNames.getFileType(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName = _fileType.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n          _builder.append(_abstractFileType, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public static final \");\n          TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_1 = _fileType_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\" INSTANCE = new \");\n          TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_2 = _fileType_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"new() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_fileType, _client);\n    } else {\n      TypeReference _fileType_1 = this._ideaPluginClassNames.getFileType(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName = _fileType.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n          _builder.append(_abstractFileType, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public static final \");\n          TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_1 = _fileType_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\" INSTANCE = new \");\n          TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_2 = _fileType_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _fileType_3 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_3 = _fileType_3.getSimpleName();\n          _builder.append(_simpleName_3, \"\\t\");\n          _builder.append(\"() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_fileType_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"public JavaFileAccess compileColorSettingsPage(final Grammar grammar) {\n    TypeReference _colorSettingsPage = this._ideaPluginClassNames.colorSettingsPage(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n        String _simpleName = _colorSettingsPage.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n        _builder.append(_baseColorSettingsPage, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_colorSettingsPage, _client);\n  }","id":14003,"modified_method":"public JavaFileAccess compileColorSettingsPage(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _colorSettingsPage = this._ideaPluginClassNames.colorSettingsPage(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n          String _simpleName = _colorSettingsPage.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n          _builder.append(_baseColorSettingsPage, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_colorSettingsPage, _client);\n    } else {\n      TypeReference _colorSettingsPage_1 = this._ideaPluginClassNames.colorSettingsPage(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n          String _simpleName = _colorSettingsPage.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n          _builder.append(_baseColorSettingsPage, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_colorSettingsPage_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"public XtendFileAccess compileStandaloneSetup(final Grammar grammar) {\n    TypeReference _ideaStandaloneSetup = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n        String _simpleName = _ideaStandaloneSetup.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n        _builder.append(_runtimeGenSetup, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"override createInjector() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val runtimeModule = new \");\n        TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n        _builder.append(_runtimeModule, \"\\t\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val ideaModule = new \");\n        TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n        _builder.append(_ideaModule, \"\\t\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val mergedModule = \");\n        _builder.append(Modules2.class, \"\\t\\t\");\n        _builder.append(\".mixin(runtimeModule, ideaModule)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"return \");\n        _builder.append(Guice.class, \"\\t\\t\");\n        _builder.append(\".createInjector(mergedModule)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_ideaStandaloneSetup, _client);\n  }","id":14004,"modified_method":"public JavaFileAccess compileStandaloneSetup(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _ideaStandaloneSetup = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          String _simpleName = _ideaStandaloneSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n          _builder.append(_runtimeGenSetup, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"override createInjector() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val runtimeModule = new \");\n          TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule, \"\\t\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val ideaModule = new \");\n          TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule, \"\\t\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val mergedModule = \");\n          _builder.append(Modules2.class, \"\\t\\t\");\n          _builder.append(\".mixin(runtimeModule, ideaModule)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"return \");\n          _builder.append(Guice.class, \"\\t\\t\");\n          _builder.append(\".createInjector(mergedModule)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_ideaStandaloneSetup, _client);\n    } else {\n      TypeReference _ideaStandaloneSetup_1 = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          String _simpleName = _ideaStandaloneSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n          _builder.append(_runtimeGenSetup, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"@Override\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          _builder.append(Injector.class, \"\\t\");\n          _builder.append(\" createInjector() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule, \"\\t\\t\");\n          _builder.append(\" runtimeModule = new \");\n          TypeReference _runtimeModule_1 = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule_1, \"\\t\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule, \"\\t\\t\");\n          _builder.append(\" ideaModule = new \");\n          TypeReference _ideaModule_1 = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule_1, \"\\t\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(Module.class, \"\\t\\t\");\n          _builder.append(\" mergedModule = \");\n          _builder.append(Modules2.class, \"\\t\\t\");\n          _builder.append(\".mixin(runtimeModule, ideaModule);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"return \");\n          _builder.append(Guice.class, \"\\t\\t\");\n          _builder.append(\".createInjector(mergedModule);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_ideaStandaloneSetup_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"/**\n   * Returns the root-relative path of the folder where the generated .ecore and .genmodel can be found.\n   * The path is delimited by '/', but does not begin or end with a separator.\n   */\n  @Override\n  public String getEcoreModelFolder() {\n    String _path = this.ecoreModel.getPath();\n    IXtextGeneratorFileSystemAccess _root = this.getRoot();\n    String _path_1 = _root.getPath();\n    boolean _startsWith = _path.startsWith(_path_1);\n    if (_startsWith) {\n      String _path_2 = this.ecoreModel.getPath();\n      IXtextGeneratorFileSystemAccess _root_1 = this.getRoot();\n      String _path_3 = _root_1.getPath();\n      int _length = _path_3.length();\n      String _substring = _path_2.substring(_length);\n      final String relativePath = _substring.replace(\"\\\\\", \"/\");\n      CharMatcher _is = CharMatcher.is('/');\n      return _is.trimFrom(relativePath);\n    }\n    throw new RuntimeException(\"Could not derive the Ecore model folder from the project configuration. Please make sure that \\'root\\' is a prefix of \\'ecoreModel\\'.\");\n  }","id":14005,"modified_method":"/**\n   * Returns the root-relative path of the folder where the generated .ecore and .genmodel can be found.\n   * The path is delimited by '/', but does not begin or end with a separator.\n   */\n  @Override\n  public String getEcoreModelFolder() {\n    String _path = this.ecoreModel.getPath();\n    IXtextGeneratorFileSystemAccess _root = this.getRoot();\n    String _path_1 = _root.getPath();\n    boolean _startsWith = _path.startsWith(_path_1);\n    if (_startsWith) {\n      String _path_2 = this.ecoreModel.getPath();\n      IXtextGeneratorFileSystemAccess _root_1 = this.getRoot();\n      String _path_3 = _root_1.getPath();\n      int _length = _path_3.length();\n      String _substring = _path_2.substring(_length);\n      final String relativePath = _substring.replace(\"\\\\\", \"/\");\n      CharMatcher _is = CharMatcher.is('/');\n      return _is.trimFrom(relativePath);\n    }\n    StringConcatenation _builder = new StringConcatenation();\n    _builder.append(\"Could not derive the Ecore model folder from the project configuration. \");\n    _builder.newLine();\n    _builder.append(\"Please make sure that \\\\\\'root\\\\\\' is a prefix of \\\\\\'ecoreModel\\\\\\'.\");\n    _builder.newLine();\n    _builder.append(\"was (root=\\'\");\n    IXtextGeneratorFileSystemAccess _root_2 = this.getRoot();\n    String _path_4 = _root_2.getPath();\n    _builder.append(_path_4, \"\");\n    _builder.append(\"\\', ecoreModel=\\'\");\n    String _path_5 = this.ecoreModel.getPath();\n    _builder.append(_path_5, \"\");\n    _builder.append(\"\\')\");\n    _builder.newLineIfNotEmpty();\n    _builder.newLine();\n    throw new RuntimeException(_builder.toString());\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n  public void initialize(final Injector injector) {\n    injector.injectMembers(this);\n    if ((this.rootPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess = this.owner.newFileSystemAccess(this.rootPath, true);\n      this.root = _newFileSystemAccess;\n      this.root.initialize(injector);\n    }\n    if ((this.metaInfPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_1 = this.owner.newFileSystemAccess(this.metaInfPath, true);\n      this.metaInf = _newFileSystemAccess_1;\n      this.metaInf.initialize(injector);\n    }\n    if ((this.srcPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_2 = this.owner.newFileSystemAccess(this.srcPath, false);\n      this.src = _newFileSystemAccess_2;\n      this.src.initialize(injector);\n    }\n    if ((this.srcGenPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_3 = this.owner.newFileSystemAccess(this.srcGenPath, true);\n      this.srcGen = _newFileSystemAccess_3;\n      this.srcGen.initialize(injector);\n    }\n  }","id":14006,"modified_method":"@Override\n  public void initialize(final Injector injector) {\n    injector.injectMembers(this);\n    boolean _isNullOrEmpty = StringExtensions.isNullOrEmpty(this.rootPath);\n    boolean _not = (!_isNullOrEmpty);\n    if (_not) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess = this.owner.newFileSystemAccess(this.rootPath, true);\n      this.root = _newFileSystemAccess;\n      this.root.initialize(injector);\n    }\n    boolean _isNullOrEmpty_1 = StringExtensions.isNullOrEmpty(this.metaInfPath);\n    boolean _not_1 = (!_isNullOrEmpty_1);\n    if (_not_1) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_1 = this.owner.newFileSystemAccess(this.metaInfPath, true);\n      this.metaInf = _newFileSystemAccess_1;\n      this.metaInf.initialize(injector);\n    }\n    boolean _isNullOrEmpty_2 = StringExtensions.isNullOrEmpty(this.srcPath);\n    boolean _not_2 = (!_isNullOrEmpty_2);\n    if (_not_2) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_2 = this.owner.newFileSystemAccess(this.srcPath, this.overwriteSrc);\n      this.src = _newFileSystemAccess_2;\n      this.src.initialize(injector);\n    }\n    boolean _isNullOrEmpty_3 = StringExtensions.isNullOrEmpty(this.srcGenPath);\n    boolean _not_3 = (!_isNullOrEmpty_3);\n    if (_not_3) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_3 = this.owner.newFileSystemAccess(this.srcGenPath, true);\n      this.srcGen = _newFileSystemAccess_3;\n      this.srcGen.initialize(injector);\n    }\n  }","commit_id":"55dbda2f837decac21387c918b8ac40b34944364","url":"https://github.com/eclipse/xtext"},{"original_method":"public XtendFileAccess compileIdeaSetup(final Grammar grammar) {\n    TypeReference _ideaSetup = this._ideaPluginClassNames.getIdeaSetup(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _ideaSetup = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaSetup(grammar);\n        String _simpleName = _ideaSetup.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" implements \");\n        _builder.append(ISetup.class, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"override createInjectorAndDoEMFRegistration() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.extensions.EcoreGlobalRegistries\");\n        _builder.append(_typeRef, \"\\t\\t\");\n        _builder.append(\".ensureInitialized\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"new \");\n        TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n        _builder.append(_ideaStandaloneSetup, \"\\t\\t\");\n        _builder.append(\"().createInjector\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_ideaSetup, _client);\n  }","id":14007,"modified_method":"public JavaFileAccess compileIdeaSetup(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _ideaSetup = this._ideaPluginClassNames.getIdeaSetup(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _ideaSetup = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaSetup(grammar);\n          String _simpleName = _ideaSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" implements \");\n          _builder.append(ISetup.class, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"override createInjectorAndDoEMFRegistration() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.extensions.EcoreGlobalRegistries\");\n          _builder.append(_typeRef, \"\\t\\t\");\n          _builder.append(\".ensureInitialized\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"new \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          _builder.append(_ideaStandaloneSetup, \"\\t\\t\");\n          _builder.append(\"().createInjector\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_ideaSetup, _client);\n    } else {\n      TypeReference _ideaSetup_1 = this._ideaPluginClassNames.getIdeaSetup(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _ideaSetup = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaSetup(grammar);\n          String _simpleName = _ideaSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" implements \");\n          _builder.append(ISetup.class, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"@Override\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          _builder.append(Injector.class, \"\\t\");\n          _builder.append(\" createInjectorAndDoEMFRegistration() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.extensions.EcoreGlobalRegistries\");\n          _builder.append(_typeRef, \"\\t\\t\");\n          _builder.append(\".ensureInitialized();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"return new \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          _builder.append(_ideaStandaloneSetup, \"\\t\\t\");\n          _builder.append(\"().createInjector();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_ideaSetup_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public JavaFileAccess compileColorSettingsPage(final Grammar grammar) {\n    TypeReference _colorSettingsPage = this._ideaPluginClassNames.colorSettingsPage(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n        String _simpleName = _colorSettingsPage.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n        _builder.append(_baseColorSettingsPage, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_colorSettingsPage, _client);\n  }","id":14008,"modified_method":"public JavaFileAccess compileColorSettingsPage(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _colorSettingsPage = this._ideaPluginClassNames.colorSettingsPage(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n          String _simpleName = _colorSettingsPage.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n          _builder.append(_baseColorSettingsPage, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_colorSettingsPage, _client);\n    } else {\n      TypeReference _colorSettingsPage_1 = this._ideaPluginClassNames.colorSettingsPage(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _colorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.colorSettingsPage(grammar);\n          String _simpleName = _colorSettingsPage.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _baseColorSettingsPage = IdeaPluginGenerator.this._ideaPluginClassNames.baseColorSettingsPage(grammar);\n          _builder.append(_baseColorSettingsPage, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_colorSettingsPage_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n  public void generate() {\n    IXtextProjectConfig _projectConfig = this.getProjectConfig();\n    ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n    boolean _isEnabled = _ideaPlugin.isEnabled();\n    boolean _not = (!_isEnabled);\n    if (_not) {\n      return;\n    }\n    IXtextGeneratorLanguage _language = this.getLanguage();\n    List<String> _fileExtensions = _language.getFileExtensions();\n    final String fileExtension = IterableExtensions.<String>head(_fileExtensions);\n    IXtextGeneratorLanguage _language_1 = this.getLanguage();\n    final Grammar grammar = _language_1.getGrammar();\n    final GuiceModuleAccess.BindingFactory bindFactory = new GuiceModuleAccess.BindingFactory();\n    TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.IAntlrTokenFileProvider\");\n    TypeReference _antlrTokenFileProvider = this._ideaPluginClassNames.getAntlrTokenFileProvider(grammar);\n    bindFactory.addTypeToType(_typeRef, _antlrTokenFileProvider);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.Lexer\");\n    TypeReference _psiInternalLexer = this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n    bindFactory.addTypeToType(_typeRef_1, _psiInternalLexer);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        _builder.append(Lexer.class, \"\");\n        _builder.append(\".class)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".annotatedWith(\");\n        _builder.append(Names.class, \"\\t\");\n        _builder.append(\".named(\");\n        _builder.append(LexerBindings.class, \"\\t\");\n        _builder.append(\".RUNTIME))\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".to(\");\n        TypeReference _psiInternalLexer = IdeaPluginGenerator.this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n        _builder.append(_psiInternalLexer, \"\\t\");\n        _builder.append(\".class);\");\n        _builder.newLineIfNotEmpty();\n      }\n    };\n    bindFactory.addConfiguredBinding(\"RuntimeLexer\", _client);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.lang.PsiParser\");\n    TypeReference _psiParser = this._ideaPluginClassNames.getPsiParser(grammar);\n    bindFactory.addTypeToType(_typeRef_2, _psiParser);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"org.eclipse.xtext.idea.parser.TokenTypeProvider\");\n    TypeReference _tokenTypeProvider = this._ideaPluginClassNames.getTokenTypeProvider(grammar);\n    bindFactory.addTypeToType(_typeRef_3, _tokenTypeProvider);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.lang.ParserDefinition\");\n    TypeReference _parserDefinition = this._ideaPluginClassNames.getParserDefinition(grammar);\n    bindFactory.addTypeToType(_typeRef_4, _parserDefinition);\n    TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.IElementTypeProvider\");\n    TypeReference _elementTypeProvider = this._ideaPluginClassNames.getElementTypeProvider(grammar);\n    bindFactory.addTypeToTypeSingleton(_typeRef_5, _elementTypeProvider);\n    TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n    TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n    bindFactory.addTypeToType(_typeRef_6, _facetConfiguration);\n    TypeReference _typeRef_7 = TypeReference.typeRef(\"com.intellij.facet.FacetTypeId\");\n    StringConcatenationClient _client_1 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        TypeReference _facetType = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetType(grammar);\n        _builder.append(_facetType, \"\");\n        _builder.append(\".TYPEID\");\n      }\n    };\n    bindFactory.addTypeToInstance(_typeRef_7, _client_1);\n    TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.IContentAssistParser\");\n    TypeReference _parserClass = this.caNaming.getParserClass(grammar);\n    bindFactory.addTypeToType(_typeRef_8, _parserClass);\n    StringConcatenationClient _client_2 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.internal.Lexer\");\n        _builder.append(_typeRef, \"\");\n        _builder.append(\".class).annotatedWith(\");\n        _builder.append(Names.class, \"\");\n        _builder.append(\".named(\");\n        TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.ide.LexerIdeBindings\");\n        _builder.append(_typeRef_1, \"\");\n        _builder.append(\".CONTENT_ASSIST)).to(\");\n        TypeReference _lexerClass = IdeaPluginGenerator.this.caNaming.getLexerClass(grammar);\n        _builder.append(_lexerClass, \"\");\n        _builder.append(\".class);\");\n      }\n    };\n    bindFactory.addConfiguredBinding(\"ContentAssistLexer\", _client_2);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_9 = TypeReference.typeRef(\"org.eclipse.xtext.common.types.xtext.AbstractTypeScopeProvider\");\n      TypeReference _typeRef_10 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.StubBasedTypeScopeProvider\");\n      bindFactory.addTypeToType(_typeRef_9, _typeRef_10);\n      TypeReference _typeReference = new TypeReference(\"org.eclipse.xtext.xbase.typesystem.internal\", \"IFeatureScopeTracker.Provider\");\n      TypeReference _typeRef_11 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.typesystem.internal.OptimizingFeatureScopeTrackerProvider\");\n      bindFactory.addTypeToType(_typeReference, _typeRef_11);\n      StringConcatenationClient _client_3 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"binder.bind(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.psi.IPsiModelAssociations\");\n          _builder.append(_typeRef, \"\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".annotatedWith(\");\n          _builder.append(LanguageSpecific.class, \"\\t\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".to(\");\n          TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.DerivedMemberAwarePsiModelAssociations\");\n          _builder.append(_typeRef_1, \"\\t\");\n          _builder.append(\".class);\");\n          _builder.newLineIfNotEmpty();\n        }\n      };\n      bindFactory.addConfiguredBinding(\"LanguageSpecificPsiModelAssociations\", _client_3);\n      TypeReference _typeRef_12 = TypeReference.typeRef(\"org.eclipse.xtext.idea.highlighting.IHighlightingConfiguration\");\n      TypeReference _typeRef_13 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.highlighting.XbaseHighlightingConfiguration\");\n      bindFactory.addTypeToType(_typeRef_12, _typeRef_13);\n      TypeReference _typeRef_14 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.BlockFactory\");\n      TypeReference _typeRef_15 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseBlockFactory\");\n      bindFactory.addTypeToType(_typeRef_14, _typeRef_15);\n      TypeReference _typeRef_16 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.ChildAttributesProvider\");\n      TypeReference _typeRef_17 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseChildAttributesProvider\");\n      bindFactory.addTypeToType(_typeRef_16, _typeRef_17);\n      TypeReference _typeRef_18 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.bracketmatching.IBracePairProvider\");\n      TypeReference _typeRef_19 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.bracketmatching.XbaseBracePairProvider\");\n      bindFactory.addTypeToType(_typeRef_18, _typeRef_19);\n      TypeReference _typeRef_20 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.IReferenceSearcher\");\n      TypeReference _typeRef_21 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.findusages.JvmElementAwareReferenceSearcher\");\n      bindFactory.addTypeToType(_typeRef_20, _typeRef_21);\n      TypeReference _typeRef_22 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.compiler.IGeneratorConfigProvider\");\n      TypeReference _typeRef_23 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigProvider\");\n      bindFactory.addTypeToType(_typeRef_22, _typeRef_23);\n      TypeReference _typeRef_24 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.WordsScannerProvider\");\n      TypeReference _typeReference_1 = new TypeReference(\"org.eclipse.xtext.xbase.idea.findusages\", \"XbaseWordsScanner.XbaseWordsScannerProvider\");\n      bindFactory.addTypeToType(_typeRef_24, _typeReference_1);\n    }\n    IXtextGeneratorLanguage _language_2 = this.getLanguage();\n    GuiceModuleAccess _ideaGenModule = _language_2.getIdeaGenModule();\n    bindFactory.contributeTo(_ideaGenModule);\n    XtendFileAccess _compileStandaloneSetup = this.compileStandaloneSetup(grammar);\n    XtendFileAccess _compileIdeaSetup = this.compileIdeaSetup(grammar);\n    JavaFileAccess _compileCompletionContributor = this.compileCompletionContributor(grammar);\n    XtendFileAccess _compileFileType = this.compileFileType(grammar);\n    JavaFileAccess _compileFacetConfiguration = this.compileFacetConfiguration(grammar);\n    JavaFileAccess _compileColorSettingsPage = this.compileColorSettingsPage(grammar);\n    final Procedure1<JavaFileAccess> _function = new Procedure1<JavaFileAccess>() {\n      @Override\n      public void apply(final JavaFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _src = _ideaPlugin.getSrc();\n        it.writeTo(_src);\n      }\n    };\n    IterableExtensions.forEach(Collections.<JavaFileAccess>unmodifiableList(CollectionLiterals.<JavaFileAccess>newArrayList(_compileStandaloneSetup, _compileIdeaSetup, _compileCompletionContributor, _compileFileType, _compileFacetConfiguration, _compileColorSettingsPage)), _function);\n    TextFileAccess _compileServicesISetup = this.compileServicesISetup(grammar);\n    JavaFileAccess _compileAbstractCompletionContributor = this.compileAbstractCompletionContributor(grammar);\n    JavaFileAccess _compileLanguage = this.compileLanguage(grammar);\n    JavaFileAccess _compileAbstractFileType = this.compileAbstractFileType(grammar, fileExtension);\n    JavaFileAccess _compileFileTypeFactory = this.compileFileTypeFactory(grammar);\n    JavaFileAccess _compileFileImpl = this.compileFileImpl(grammar);\n    JavaFileAccess _compileTokenTypeProvider = this.compileTokenTypeProvider(grammar);\n    JavaFileAccess _compileElementTypeProvider = this.compileElementTypeProvider(grammar);\n    JavaFileAccess _compileParserDefinition = this.compileParserDefinition(grammar);\n    JavaFileAccess _compileSyntaxHighlighterFactory = this.compileSyntaxHighlighterFactory(grammar);\n    JavaFileAccess _compileSemanticHighlightVisitor = this.compileSemanticHighlightVisitor(grammar);\n    JavaFileAccess _compileExtensionFactory = this.compileExtensionFactory(grammar);\n    JavaFileAccess _compileCodeBlockModificationListener = this.compileCodeBlockModificationListener(grammar);\n    JavaFileAccess _compilePsiParser = this.compilePsiParser(grammar);\n    JavaFileAccess _compileAntlrTokenFileProvider = this.compileAntlrTokenFileProvider(grammar);\n    JavaFileAccess _compilePomDeclarationSearcher = this.compilePomDeclarationSearcher(grammar);\n    JavaFileAccess _compileFacetType = this.compileFacetType(grammar);\n    JavaFileAccess _compileBaseColorSettingsPage = this.compileBaseColorSettingsPage(grammar);\n    final Procedure1<TextFileAccess> _function_1 = new Procedure1<TextFileAccess>() {\n      @Override\n      public void apply(final TextFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _srcGen = _ideaPlugin.getSrcGen();\n        it.writeTo(_srcGen);\n      }\n    };\n    IterableExtensions.forEach(Collections.<TextFileAccess>unmodifiableList(CollectionLiterals.<TextFileAccess>newArrayList(_compileServicesISetup, _compileAbstractCompletionContributor, _compileLanguage, _compileAbstractFileType, _compileFileTypeFactory, _compileFileImpl, _compileTokenTypeProvider, _compileElementTypeProvider, _compileParserDefinition, _compileSyntaxHighlighterFactory, _compileSemanticHighlightVisitor, _compileExtensionFactory, _compileCodeBlockModificationListener, _compilePsiParser, _compileAntlrTokenFileProvider, _compilePomDeclarationSearcher, _compileFacetType, _compileBaseColorSettingsPage)), _function_1);\n    if (this.deployable) {\n      final TextFileAccess pluginXml = this.compilePluginXml(grammar);\n      IXtextProjectConfig _projectConfig_1 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_1 = _projectConfig_1.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf = _ideaPlugin_1.getMetaInf();\n      String _path = pluginXml.getPath();\n      boolean _isFile = _metaInf.isFile(_path);\n      boolean _not_1 = (!_isFile);\n      if (_not_1) {\n        IXtextProjectConfig _projectConfig_2 = this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin_2 = _projectConfig_2.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _metaInf_1 = _ideaPlugin_2.getMetaInf();\n        pluginXml.writeTo(_metaInf_1);\n      }\n      TextFileAccess _compilePluginGenXml = this.compilePluginGenXml(grammar);\n      IXtextProjectConfig _projectConfig_3 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_3 = _projectConfig_3.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf_2 = _ideaPlugin_3.getMetaInf();\n      _compilePluginGenXml.writeTo(_metaInf_2);\n    }\n  }","id":14009,"modified_method":"@Override\n  public void generate() {\n    IXtextProjectConfig _projectConfig = this.getProjectConfig();\n    ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n    boolean _isEnabled = _ideaPlugin.isEnabled();\n    boolean _not = (!_isEnabled);\n    if (_not) {\n      return;\n    }\n    IXtextGeneratorLanguage _language = this.getLanguage();\n    List<String> _fileExtensions = _language.getFileExtensions();\n    final String fileExtension = IterableExtensions.<String>head(_fileExtensions);\n    IXtextGeneratorLanguage _language_1 = this.getLanguage();\n    final Grammar grammar = _language_1.getGrammar();\n    final GuiceModuleAccess.BindingFactory bindFactory = new GuiceModuleAccess.BindingFactory();\n    TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.IAntlrTokenFileProvider\");\n    TypeReference _antlrTokenFileProvider = this._ideaPluginClassNames.getAntlrTokenFileProvider(grammar);\n    bindFactory.addTypeToType(_typeRef, _antlrTokenFileProvider);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.parser.antlr.Lexer\");\n    TypeReference _psiInternalLexer = this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n    bindFactory.addTypeToType(_typeRef_1, _psiInternalLexer);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        _builder.append(Lexer.class, \"\");\n        _builder.append(\".class)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".annotatedWith(\");\n        _builder.append(Names.class, \"\\t\");\n        _builder.append(\".named(\");\n        _builder.append(LexerBindings.class, \"\\t\");\n        _builder.append(\".RUNTIME))\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\".to(\");\n        TypeReference _psiInternalLexer = IdeaPluginGenerator.this._ideaPluginClassNames.getPsiInternalLexer(grammar);\n        _builder.append(_psiInternalLexer, \"\\t\");\n        _builder.append(\".class);\");\n        _builder.newLineIfNotEmpty();\n      }\n    };\n    bindFactory.addConfiguredBinding(\"RuntimeLexer\", _client);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.lang.PsiParser\");\n    TypeReference _psiParser = this._ideaPluginClassNames.getPsiParser(grammar);\n    bindFactory.addTypeToType(_typeRef_2, _psiParser);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"org.eclipse.xtext.idea.parser.TokenTypeProvider\");\n    TypeReference _tokenTypeProvider = this._ideaPluginClassNames.getTokenTypeProvider(grammar);\n    bindFactory.addTypeToType(_typeRef_3, _tokenTypeProvider);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.lang.ParserDefinition\");\n    TypeReference _parserDefinition = this._ideaPluginClassNames.getParserDefinition(grammar);\n    bindFactory.addTypeToType(_typeRef_4, _parserDefinition);\n    TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.IElementTypeProvider\");\n    TypeReference _elementTypeProvider = this._ideaPluginClassNames.getElementTypeProvider(grammar);\n    bindFactory.addTypeToTypeSingleton(_typeRef_5, _elementTypeProvider);\n    TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n    TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n    bindFactory.addTypeToType(_typeRef_6, _facetConfiguration);\n    TypeReference _typeRef_7 = TypeReference.typeRef(\"com.intellij.facet.FacetTypeId\");\n    StringConcatenationClient _client_1 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        TypeReference _facetType = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetType(grammar);\n        _builder.append(_facetType, \"\");\n        _builder.append(\".TYPEID\");\n      }\n    };\n    bindFactory.addTypeToInstance(_typeRef_7, _client_1);\n    TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.IContentAssistParser\");\n    TypeReference _parserClass = this.caNaming.getParserClass(grammar);\n    bindFactory.addTypeToType(_typeRef_8, _parserClass);\n    StringConcatenationClient _client_2 = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"binder.bind(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.contentassist.antlr.internal.Lexer\");\n        _builder.append(_typeRef, \"\");\n        _builder.append(\".class).annotatedWith(\");\n        _builder.append(Names.class, \"\");\n        _builder.append(\".named(\");\n        TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.ide.LexerIdeBindings\");\n        _builder.append(_typeRef_1, \"\");\n        _builder.append(\".CONTENT_ASSIST)).to(\");\n        TypeReference _lexerClass = IdeaPluginGenerator.this.caNaming.getLexerClass(grammar);\n        _builder.append(_lexerClass, \"\");\n        _builder.append(\".class);\");\n      }\n    };\n    bindFactory.addConfiguredBinding(\"ContentAssistLexer\", _client_2);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_9 = TypeReference.typeRef(\"org.eclipse.xtext.common.types.xtext.AbstractTypeScopeProvider\");\n      TypeReference _typeRef_10 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.StubBasedTypeScopeProvider\");\n      bindFactory.addTypeToType(_typeRef_9, _typeRef_10);\n      TypeReference _typeReference = new TypeReference(\"org.eclipse.xtext.xbase.typesystem.internal\", \"IFeatureScopeTracker.Provider\");\n      TypeReference _typeRef_11 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.typesystem.internal.OptimizingFeatureScopeTrackerProvider\");\n      bindFactory.addTypeToType(_typeReference, _typeRef_11);\n      StringConcatenationClient _client_3 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"binder.bind(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.psi.IPsiModelAssociations\");\n          _builder.append(_typeRef, \"\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".annotatedWith(\");\n          _builder.append(LanguageSpecific.class, \"\\t\");\n          _builder.append(\".class)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\".to(\");\n          TypeReference _typeRef_1 = TypeReference.typeRef(\"org.eclipse.xtext.idea.common.types.DerivedMemberAwarePsiModelAssociations\");\n          _builder.append(_typeRef_1, \"\\t\");\n          _builder.append(\".class);\");\n          _builder.newLineIfNotEmpty();\n        }\n      };\n      bindFactory.addConfiguredBinding(\"LanguageSpecificPsiModelAssociations\", _client_3);\n      TypeReference _typeRef_12 = TypeReference.typeRef(\"org.eclipse.xtext.idea.highlighting.IHighlightingConfiguration\");\n      TypeReference _typeRef_13 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.highlighting.XbaseHighlightingConfiguration\");\n      bindFactory.addTypeToType(_typeRef_12, _typeRef_13);\n      TypeReference _typeRef_14 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.BlockFactory\");\n      TypeReference _typeRef_15 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseBlockFactory\");\n      bindFactory.addTypeToType(_typeRef_14, _typeRef_15);\n      TypeReference _typeRef_16 = TypeReference.typeRef(\"org.eclipse.xtext.idea.formatting.ChildAttributesProvider\");\n      TypeReference _typeRef_17 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.formatting.XbaseChildAttributesProvider\");\n      bindFactory.addTypeToType(_typeRef_16, _typeRef_17);\n      TypeReference _typeRef_18 = TypeReference.typeRef(\"org.eclipse.xtext.ide.editor.bracketmatching.IBracePairProvider\");\n      TypeReference _typeRef_19 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.bracketmatching.XbaseBracePairProvider\");\n      bindFactory.addTypeToType(_typeRef_18, _typeRef_19);\n      TypeReference _typeRef_20 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.IReferenceSearcher\");\n      TypeReference _typeRef_21 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.findusages.JvmElementAwareReferenceSearcher\");\n      bindFactory.addTypeToType(_typeRef_20, _typeRef_21);\n      TypeReference _typeRef_22 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.compiler.IGeneratorConfigProvider\");\n      TypeReference _typeRef_23 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigProvider\");\n      bindFactory.addTypeToType(_typeRef_22, _typeRef_23);\n      TypeReference _typeRef_24 = TypeReference.typeRef(\"org.eclipse.xtext.idea.findusages.WordsScannerProvider\");\n      TypeReference _typeReference_1 = new TypeReference(\"org.eclipse.xtext.xbase.idea.findusages\", \"XbaseWordsScanner.XbaseWordsScannerProvider\");\n      bindFactory.addTypeToType(_typeRef_24, _typeReference_1);\n    }\n    IXtextGeneratorLanguage _language_2 = this.getLanguage();\n    GuiceModuleAccess _ideaGenModule = _language_2.getIdeaGenModule();\n    bindFactory.contributeTo(_ideaGenModule);\n    JavaFileAccess _compileStandaloneSetup = this.compileStandaloneSetup(grammar);\n    JavaFileAccess _compileIdeaSetup = this.compileIdeaSetup(grammar);\n    JavaFileAccess _compileCompletionContributor = this.compileCompletionContributor(grammar);\n    JavaFileAccess _compileFileType = this.compileFileType(grammar);\n    JavaFileAccess _compileFacetConfiguration = this.compileFacetConfiguration(grammar);\n    JavaFileAccess _compileColorSettingsPage = this.compileColorSettingsPage(grammar);\n    final Procedure1<JavaFileAccess> _function = new Procedure1<JavaFileAccess>() {\n      @Override\n      public void apply(final JavaFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _src = _ideaPlugin.getSrc();\n        it.writeTo(_src);\n      }\n    };\n    IterableExtensions.<JavaFileAccess>forEach(Collections.<JavaFileAccess>unmodifiableList(CollectionLiterals.<JavaFileAccess>newArrayList(_compileStandaloneSetup, _compileIdeaSetup, _compileCompletionContributor, _compileFileType, _compileFacetConfiguration, _compileColorSettingsPage)), _function);\n    TextFileAccess _compileServicesISetup = this.compileServicesISetup(grammar);\n    JavaFileAccess _compileAbstractCompletionContributor = this.compileAbstractCompletionContributor(grammar);\n    JavaFileAccess _compileLanguage = this.compileLanguage(grammar);\n    JavaFileAccess _compileAbstractFileType = this.compileAbstractFileType(grammar, fileExtension);\n    JavaFileAccess _compileFileTypeFactory = this.compileFileTypeFactory(grammar);\n    JavaFileAccess _compileFileImpl = this.compileFileImpl(grammar);\n    JavaFileAccess _compileTokenTypeProvider = this.compileTokenTypeProvider(grammar);\n    JavaFileAccess _compileElementTypeProvider = this.compileElementTypeProvider(grammar);\n    JavaFileAccess _compileParserDefinition = this.compileParserDefinition(grammar);\n    JavaFileAccess _compileSyntaxHighlighterFactory = this.compileSyntaxHighlighterFactory(grammar);\n    JavaFileAccess _compileSemanticHighlightVisitor = this.compileSemanticHighlightVisitor(grammar);\n    JavaFileAccess _compileExtensionFactory = this.compileExtensionFactory(grammar);\n    JavaFileAccess _compileCodeBlockModificationListener = this.compileCodeBlockModificationListener(grammar);\n    JavaFileAccess _compilePsiParser = this.compilePsiParser(grammar);\n    JavaFileAccess _compileAntlrTokenFileProvider = this.compileAntlrTokenFileProvider(grammar);\n    JavaFileAccess _compilePomDeclarationSearcher = this.compilePomDeclarationSearcher(grammar);\n    JavaFileAccess _compileFacetType = this.compileFacetType(grammar);\n    JavaFileAccess _compileBaseColorSettingsPage = this.compileBaseColorSettingsPage(grammar);\n    final Procedure1<TextFileAccess> _function_1 = new Procedure1<TextFileAccess>() {\n      @Override\n      public void apply(final TextFileAccess it) {\n        IXtextProjectConfig _projectConfig = IdeaPluginGenerator.this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin = _projectConfig.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _srcGen = _ideaPlugin.getSrcGen();\n        it.writeTo(_srcGen);\n      }\n    };\n    IterableExtensions.forEach(Collections.<TextFileAccess>unmodifiableList(CollectionLiterals.<TextFileAccess>newArrayList(_compileServicesISetup, _compileAbstractCompletionContributor, _compileLanguage, _compileAbstractFileType, _compileFileTypeFactory, _compileFileImpl, _compileTokenTypeProvider, _compileElementTypeProvider, _compileParserDefinition, _compileSyntaxHighlighterFactory, _compileSemanticHighlightVisitor, _compileExtensionFactory, _compileCodeBlockModificationListener, _compilePsiParser, _compileAntlrTokenFileProvider, _compilePomDeclarationSearcher, _compileFacetType, _compileBaseColorSettingsPage)), _function_1);\n    if (this.deployable) {\n      final TextFileAccess pluginXml = this.compilePluginXml(grammar);\n      IXtextProjectConfig _projectConfig_1 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_1 = _projectConfig_1.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf = _ideaPlugin_1.getMetaInf();\n      String _path = pluginXml.getPath();\n      boolean _isFile = _metaInf.isFile(_path);\n      boolean _not_1 = (!_isFile);\n      if (_not_1) {\n        IXtextProjectConfig _projectConfig_2 = this.getProjectConfig();\n        ISubProjectConfig _ideaPlugin_2 = _projectConfig_2.getIdeaPlugin();\n        IXtextGeneratorFileSystemAccess _metaInf_1 = _ideaPlugin_2.getMetaInf();\n        pluginXml.writeTo(_metaInf_1);\n      }\n      TextFileAccess _compilePluginGenXml = this.compilePluginGenXml(grammar);\n      IXtextProjectConfig _projectConfig_3 = this.getProjectConfig();\n      ISubProjectConfig _ideaPlugin_3 = _projectConfig_3.getIdeaPlugin();\n      IXtextGeneratorFileSystemAccess _metaInf_2 = _ideaPlugin_3.getMetaInf();\n      _compilePluginGenXml.writeTo(_metaInf_2);\n    }\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public JavaFileAccess compileCompletionContributor(final Grammar grammar) {\n    TypeReference _completionContributor = this._ideaPluginClassNames.getCompletionContributor(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n        String _simpleName = _completionContributor.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n        _builder.append(_abstractCompletionContributor, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"new() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"this(\");\n        TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n        _builder.append(_ideaLanguage, \"\\t\\t\");\n        _builder.append(\".INSTANCE)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"new(\");\n        TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n        _builder.append(_typeRef, \"\\t\");\n        _builder.append(\" lang) {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"super(lang)\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"//custom rules here\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_completionContributor, _client);\n  }","id":14010,"modified_method":"public JavaFileAccess compileCompletionContributor(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _completionContributor = this._ideaPluginClassNames.getCompletionContributor(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName = _completionContributor.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n          _builder.append(_abstractCompletionContributor, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"new() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"this(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"new(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n          _builder.append(_typeRef, \"\\t\");\n          _builder.append(\" lang) {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(lang)\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"//custom rules here\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_completionContributor, _client);\n    } else {\n      TypeReference _completionContributor_1 = this._ideaPluginClassNames.getCompletionContributor(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _completionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName = _completionContributor.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractCompletionContributor = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractCompletionContributor(grammar);\n          _builder.append(_abstractCompletionContributor, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _completionContributor_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName_1 = _completionContributor_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\"() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"this(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _completionContributor_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getCompletionContributor(grammar);\n          String _simpleName_2 = _completionContributor_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"(\");\n          TypeReference _typeRef = TypeReference.typeRef(\"org.eclipse.xtext.idea.lang.AbstractXtextLanguage\");\n          _builder.append(_typeRef, \"\\t\");\n          _builder.append(\" lang) {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(lang);\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"//custom rules here\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_completionContributor_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public XtendFileAccess compileFileType(final Grammar grammar) {\n    TypeReference _fileType = this._ideaPluginClassNames.getFileType(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName = _fileType.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n        _builder.append(_abstractFileType, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"public static final \");\n        TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName_1 = _fileType_1.getSimpleName();\n        _builder.append(_simpleName_1, \"\\t\");\n        _builder.append(\" INSTANCE = new \");\n        TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n        String _simpleName_2 = _fileType_2.getSimpleName();\n        _builder.append(_simpleName_2, \"\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.newLine();\n        _builder.append(\"\\t\");\n        _builder.append(\"new() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"super(\");\n        TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n        _builder.append(_ideaLanguage, \"\\t\\t\");\n        _builder.append(\".INSTANCE)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_fileType, _client);\n  }","id":14011,"modified_method":"public JavaFileAccess compileFileType(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _fileType = this._ideaPluginClassNames.getFileType(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName = _fileType.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n          _builder.append(_abstractFileType, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public static final \");\n          TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_1 = _fileType_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\" INSTANCE = new \");\n          TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_2 = _fileType_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"new() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_fileType, _client);\n    } else {\n      TypeReference _fileType_1 = this._ideaPluginClassNames.getFileType(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _fileType = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName = _fileType.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _abstractFileType = IdeaPluginGenerator.this._ideaPluginClassNames.getAbstractFileType(grammar);\n          _builder.append(_abstractFileType, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"public static final \");\n          TypeReference _fileType_1 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_1 = _fileType_1.getSimpleName();\n          _builder.append(_simpleName_1, \"\\t\");\n          _builder.append(\" INSTANCE = new \");\n          TypeReference _fileType_2 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_2 = _fileType_2.getSimpleName();\n          _builder.append(_simpleName_2, \"\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          TypeReference _fileType_3 = IdeaPluginGenerator.this._ideaPluginClassNames.getFileType(grammar);\n          String _simpleName_3 = _fileType_3.getSimpleName();\n          _builder.append(_simpleName_3, \"\\t\");\n          _builder.append(\"() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"super(\");\n          TypeReference _ideaLanguage = IdeaPluginGenerator.this._ideaPluginClassNames.getIdeaLanguage(grammar);\n          _builder.append(_ideaLanguage, \"\\t\\t\");\n          _builder.append(\".INSTANCE);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_fileType_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public XtendFileAccess compileStandaloneSetup(final Grammar grammar) {\n    TypeReference _ideaStandaloneSetup = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"class \");\n        TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n        String _simpleName = _ideaStandaloneSetup.getSimpleName();\n        _builder.append(_simpleName, \"\");\n        _builder.append(\" extends \");\n        TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n        _builder.append(_runtimeGenSetup, \"\");\n        _builder.append(\" {\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"override createInjector() {\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val runtimeModule = new \");\n        TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n        _builder.append(_runtimeModule, \"\\t\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val ideaModule = new \");\n        TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n        _builder.append(_ideaModule, \"\\t\\t\");\n        _builder.append(\"()\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"val mergedModule = \");\n        _builder.append(Modules2.class, \"\\t\\t\");\n        _builder.append(\".mixin(runtimeModule, ideaModule)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"return \");\n        _builder.append(Guice.class, \"\\t\\t\");\n        _builder.append(\".createInjector(mergedModule)\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\");\n        _builder.append(\"}\");\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    return this.fileAccessFactory.createXtendFile(_ideaStandaloneSetup, _client);\n  }","id":14012,"modified_method":"public JavaFileAccess compileStandaloneSetup(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _ideaStandaloneSetup = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n      StringConcatenationClient _client = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"class \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          String _simpleName = _ideaStandaloneSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n          _builder.append(_runtimeGenSetup, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"override createInjector() {\");\n          _builder.newLine();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val runtimeModule = new \");\n          TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule, \"\\t\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val ideaModule = new \");\n          TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule, \"\\t\\t\");\n          _builder.append(\"()\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"val mergedModule = \");\n          _builder.append(Modules2.class, \"\\t\\t\");\n          _builder.append(\".mixin(runtimeModule, ideaModule)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"return \");\n          _builder.append(Guice.class, \"\\t\\t\");\n          _builder.append(\".createInjector(mergedModule)\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createXtendFile(_ideaStandaloneSetup, _client);\n    } else {\n      TypeReference _ideaStandaloneSetup_1 = this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n      StringConcatenationClient _client_1 = new StringConcatenationClient() {\n        @Override\n        protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n          _builder.append(\"public class \");\n          TypeReference _ideaStandaloneSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaStandaloneSetup(grammar);\n          String _simpleName = _ideaStandaloneSetup.getSimpleName();\n          _builder.append(_simpleName, \"\");\n          _builder.append(\" extends \");\n          TypeReference _runtimeGenSetup = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeGenSetup(grammar);\n          _builder.append(_runtimeGenSetup, \"\");\n          _builder.append(\" {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"@Override\");\n          _builder.newLine();\n          _builder.append(\"\\t\");\n          _builder.append(\"public \");\n          _builder.append(Injector.class, \"\\t\");\n          _builder.append(\" createInjector() {\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          TypeReference _runtimeModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule, \"\\t\\t\");\n          _builder.append(\" runtimeModule = new \");\n          TypeReference _runtimeModule_1 = IdeaPluginGenerator.this._xtextGeneratorNaming.getRuntimeModule(grammar);\n          _builder.append(_runtimeModule_1, \"\\t\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          TypeReference _ideaModule = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule, \"\\t\\t\");\n          _builder.append(\" ideaModule = new \");\n          TypeReference _ideaModule_1 = IdeaPluginGenerator.this._xtextGeneratorNaming.getIdeaModule(grammar);\n          _builder.append(_ideaModule_1, \"\\t\\t\");\n          _builder.append(\"();\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(Module.class, \"\\t\\t\");\n          _builder.append(\" mergedModule = \");\n          _builder.append(Modules2.class, \"\\t\\t\");\n          _builder.append(\".mixin(runtimeModule, ideaModule);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\\t\");\n          _builder.append(\"return \");\n          _builder.append(Guice.class, \"\\t\\t\");\n          _builder.append(\".createInjector(mergedModule);\");\n          _builder.newLineIfNotEmpty();\n          _builder.append(\"\\t\");\n          _builder.append(\"}\");\n          _builder.newLine();\n          _builder.append(\"}\");\n          _builder.newLine();\n        }\n      };\n      _xifexpression = this.fileAccessFactory.createJavaFile(_ideaStandaloneSetup_1, _client_1);\n    }\n    return _xifexpression;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public JavaFileAccess compileFacetConfiguration(final Grammar grammar) {\n    TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n    final XtendFileAccess file = this.fileAccessFactory.createXtendFile(_facetConfiguration);\n    TypeReference _typeRef = TypeReference.typeRef(\"com.intellij.openapi.components.PersistentStateComponent\");\n    file.importType(_typeRef);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"com.intellij.openapi.components.State\");\n    file.importType(_typeRef_1);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.openapi.components.Storage\");\n    file.importType(_typeRef_2);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"com.intellij.openapi.components.StoragePathMacros\");\n    file.importType(_typeRef_3);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.openapi.components.StorageScheme\");\n    file.importType(_typeRef_4);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseFacetConfiguration\");\n      file.importType(_typeRef_5);\n      TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigurationState\");\n      file.importType(_typeRef_6);\n    } else {\n      TypeReference _typeRef_7 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n      file.importType(_typeRef_7);\n      TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.GeneratorConfigurationState\");\n      file.importType(_typeRef_8);\n    }\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        _builder.append(\"@State(name = \\\"\");\n        String _name = grammar.getName();\n        _builder.append(_name, \"\");\n        _builder.append(\"Generator\\\", storages = #[\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"@Storage(id = \\\"default\\\", file = StoragePathMacros.PROJECT_FILE),\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\");\n        _builder.append(\"@Storage(id = \\\"dir\\\", file = StoragePathMacros.PROJECT_CONFIG_DIR\");\n        _builder.newLine();\n        _builder.append(\"\\t\\t\\t\\t\");\n        _builder.append(\"+ \\\"/\");\n        String _simpleName = IdeaPluginGenerator.this._ideaPluginExtension.getSimpleName(grammar);\n        _builder.append(_simpleName, \"\\t\\t\\t\\t\");\n        _builder.append(\"GeneratorConfig.xml\\\", scheme = StorageScheme.DIRECTORY_BASED)])\");\n        _builder.newLineIfNotEmpty();\n        _builder.append(\"class \");\n        TypeReference _facetConfiguration = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetConfiguration(grammar);\n        String _simpleName_1 = _facetConfiguration.getSimpleName();\n        _builder.append(_simpleName_1, \"\");\n        _builder.append(\" extends \");\n        {\n          boolean _inheritsXbase = IdeaPluginGenerator.this._xbaseUsageDetector.inheritsXbase(grammar);\n          if (_inheritsXbase) {\n            _builder.append(\"XbaseFacetConfiguration implements PersistentStateComponent<XbaseGeneratorConfigurationState>\");\n          } else {\n            _builder.append(\"AbstractFacetConfiguration implements PersistentStateComponent<GeneratorConfigurationState>\");\n          }\n        }\n        _builder.append(\"{\");\n        _builder.newLineIfNotEmpty();\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    file.setContent(_client);\n    return file;\n  }","id":14013,"modified_method":"public JavaFileAccess compileFacetConfiguration(final Grammar grammar) {\n    JavaFileAccess _xifexpression = null;\n    boolean _isGenerateXtendStub = this.isGenerateXtendStub();\n    if (_isGenerateXtendStub) {\n      TypeReference _facetConfiguration = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n      _xifexpression = this.fileAccessFactory.createXtendFile(_facetConfiguration);\n    } else {\n      TypeReference _facetConfiguration_1 = this._ideaPluginClassNames.getFacetConfiguration(grammar);\n      _xifexpression = this.fileAccessFactory.createJavaFile(_facetConfiguration_1);\n    }\n    final JavaFileAccess file = _xifexpression;\n    TypeReference _typeRef = TypeReference.typeRef(\"com.intellij.openapi.components.PersistentStateComponent\");\n    file.importType(_typeRef);\n    TypeReference _typeRef_1 = TypeReference.typeRef(\"com.intellij.openapi.components.State\");\n    file.importType(_typeRef_1);\n    TypeReference _typeRef_2 = TypeReference.typeRef(\"com.intellij.openapi.components.Storage\");\n    file.importType(_typeRef_2);\n    TypeReference _typeRef_3 = TypeReference.typeRef(\"com.intellij.openapi.components.StoragePathMacros\");\n    file.importType(_typeRef_3);\n    TypeReference _typeRef_4 = TypeReference.typeRef(\"com.intellij.openapi.components.StorageScheme\");\n    file.importType(_typeRef_4);\n    boolean _inheritsXbase = this._xbaseUsageDetector.inheritsXbase(grammar);\n    if (_inheritsXbase) {\n      TypeReference _typeRef_5 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseFacetConfiguration\");\n      file.importType(_typeRef_5);\n      TypeReference _typeRef_6 = TypeReference.typeRef(\"org.eclipse.xtext.xbase.idea.facet.XbaseGeneratorConfigurationState\");\n      file.importType(_typeRef_6);\n    } else {\n      TypeReference _typeRef_7 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.AbstractFacetConfiguration\");\n      file.importType(_typeRef_7);\n      TypeReference _typeRef_8 = TypeReference.typeRef(\"org.eclipse.xtext.idea.facet.GeneratorConfigurationState\");\n      file.importType(_typeRef_8);\n    }\n    StringConcatenationClient _client = new StringConcatenationClient() {\n      @Override\n      protected void appendTo(StringConcatenationClient.TargetStringConcatenation _builder) {\n        {\n          boolean _isGenerateXtendStub = IdeaPluginGenerator.this.isGenerateXtendStub();\n          if (_isGenerateXtendStub) {\n            _builder.append(\"@State(name = \\\"\");\n            String _name = grammar.getName();\n            _builder.append(_name, \"\");\n            _builder.append(\"Generator\\\", storages = #[\");\n            _builder.newLineIfNotEmpty();\n            _builder.append(\"\\t\\t\");\n            _builder.append(\"@Storage(id = \\\"default\\\", file = StoragePathMacros.PROJECT_FILE),\");\n            _builder.newLine();\n            _builder.append(\"\\t\\t\");\n            _builder.append(\"@Storage(id = \\\"dir\\\", file = StoragePathMacros.PROJECT_CONFIG_DIR\");\n            _builder.newLine();\n            _builder.append(\"\\t\\t\\t\\t\");\n            _builder.append(\"+ \\\"/\");\n            String _simpleName = IdeaPluginGenerator.this._ideaPluginExtension.getSimpleName(grammar);\n            _builder.append(_simpleName, \"\\t\\t\\t\\t\");\n            _builder.append(\"GeneratorConfig.xml\\\", scheme = StorageScheme.DIRECTORY_BASED)])\");\n            _builder.newLineIfNotEmpty();\n          } else {\n            _builder.append(\"@State(name = \\\"\");\n            String _name_1 = grammar.getName();\n            _builder.append(_name_1, \"\");\n            _builder.append(\"Generator\\\", storages = {\");\n            _builder.newLineIfNotEmpty();\n            _builder.append(\"\\t\\t\");\n            _builder.append(\"@Storage(id = \\\"default\\\", file = StoragePathMacros.PROJECT_FILE),\");\n            _builder.newLine();\n            _builder.append(\"\\t\\t\");\n            _builder.append(\"@Storage(id = \\\"dir\\\", file = StoragePathMacros.PROJECT_CONFIG_DIR\");\n            _builder.newLine();\n            _builder.append(\"\\t\\t\\t\\t\");\n            _builder.append(\"+ \\\"/\");\n            String _simpleName_1 = IdeaPluginGenerator.this._ideaPluginExtension.getSimpleName(grammar);\n            _builder.append(_simpleName_1, \"\\t\\t\\t\\t\");\n            _builder.append(\"GeneratorConfig.xml\\\", scheme = StorageScheme.DIRECTORY_BASED)})\");\n            _builder.newLineIfNotEmpty();\n          }\n        }\n        {\n          boolean _isGenerateXtendStub_1 = IdeaPluginGenerator.this.isGenerateXtendStub();\n          boolean _not = (!_isGenerateXtendStub_1);\n          if (_not) {\n            _builder.append(\"public\");\n          }\n        }\n        _builder.append(\" class \");\n        TypeReference _facetConfiguration = IdeaPluginGenerator.this._ideaPluginClassNames.getFacetConfiguration(grammar);\n        String _simpleName_2 = _facetConfiguration.getSimpleName();\n        _builder.append(_simpleName_2, \"\");\n        _builder.append(\" extends \");\n        {\n          boolean _inheritsXbase = IdeaPluginGenerator.this._xbaseUsageDetector.inheritsXbase(grammar);\n          if (_inheritsXbase) {\n            _builder.append(\"XbaseFacetConfiguration implements PersistentStateComponent<XbaseGeneratorConfigurationState>\");\n          } else {\n            _builder.append(\"AbstractFacetConfiguration implements PersistentStateComponent<GeneratorConfigurationState>\");\n          }\n        }\n        _builder.append(\"{\");\n        _builder.newLineIfNotEmpty();\n        _builder.newLine();\n        _builder.append(\"}\");\n        _builder.newLine();\n      }\n    };\n    file.setContent(_client);\n    return file;\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"/**\n   * Returns the root-relative path of the folder where the generated .ecore and .genmodel can be found.\n   * The path is delimited by '/', but does not begin or end with a separator.\n   */\n  @Override\n  public String getEcoreModelFolder() {\n    String _path = this.ecoreModel.getPath();\n    IXtextGeneratorFileSystemAccess _root = this.getRoot();\n    String _path_1 = _root.getPath();\n    boolean _startsWith = _path.startsWith(_path_1);\n    if (_startsWith) {\n      String _path_2 = this.ecoreModel.getPath();\n      IXtextGeneratorFileSystemAccess _root_1 = this.getRoot();\n      String _path_3 = _root_1.getPath();\n      int _length = _path_3.length();\n      String _substring = _path_2.substring(_length);\n      final String relativePath = _substring.replace(\"\\\\\", \"/\");\n      CharMatcher _is = CharMatcher.is('/');\n      return _is.trimFrom(relativePath);\n    }\n    throw new RuntimeException(\"Could not derive the Ecore model folder from the project configuration. Please make sure that \\'root\\' is a prefix of \\'ecoreModel\\'.\");\n  }","id":14014,"modified_method":"/**\n   * Returns the root-relative path of the folder where the generated .ecore and .genmodel can be found.\n   * The path is delimited by '/', but does not begin or end with a separator.\n   */\n  @Override\n  public String getEcoreModelFolder() {\n    String _path = this.ecoreModel.getPath();\n    IXtextGeneratorFileSystemAccess _root = this.getRoot();\n    String _path_1 = _root.getPath();\n    boolean _startsWith = _path.startsWith(_path_1);\n    if (_startsWith) {\n      String _path_2 = this.ecoreModel.getPath();\n      IXtextGeneratorFileSystemAccess _root_1 = this.getRoot();\n      String _path_3 = _root_1.getPath();\n      int _length = _path_3.length();\n      String _substring = _path_2.substring(_length);\n      final String relativePath = _substring.replace(\"\\\\\", \"/\");\n      CharMatcher _is = CharMatcher.is('/');\n      return _is.trimFrom(relativePath);\n    }\n    StringConcatenation _builder = new StringConcatenation();\n    _builder.append(\"Could not derive the Ecore model folder from the project configuration. \");\n    _builder.newLine();\n    _builder.append(\"Please make sure that \\\\\\'root\\\\\\' is a prefix of \\\\\\'ecoreModel\\\\\\'.\");\n    _builder.newLine();\n    _builder.append(\"was (root=\\'\");\n    IXtextGeneratorFileSystemAccess _root_2 = this.getRoot();\n    String _path_4 = _root_2.getPath();\n    _builder.append(_path_4, \"\");\n    _builder.append(\"\\', ecoreModel=\\'\");\n    String _path_5 = this.ecoreModel.getPath();\n    _builder.append(_path_5, \"\");\n    _builder.append(\"\\')\");\n    _builder.newLineIfNotEmpty();\n    _builder.newLine();\n    throw new RuntimeException(_builder.toString());\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n  public void initialize(final Injector injector) {\n    injector.injectMembers(this);\n    if ((this.rootPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess = this.owner.newFileSystemAccess(this.rootPath, true);\n      this.root = _newFileSystemAccess;\n      this.root.initialize(injector);\n    }\n    if ((this.metaInfPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_1 = this.owner.newFileSystemAccess(this.metaInfPath, true);\n      this.metaInf = _newFileSystemAccess_1;\n      this.metaInf.initialize(injector);\n    }\n    if ((this.srcPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_2 = this.owner.newFileSystemAccess(this.srcPath, false);\n      this.src = _newFileSystemAccess_2;\n      this.src.initialize(injector);\n    }\n    if ((this.srcGenPath != null)) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_3 = this.owner.newFileSystemAccess(this.srcGenPath, true);\n      this.srcGen = _newFileSystemAccess_3;\n      this.srcGen.initialize(injector);\n    }\n  }","id":14015,"modified_method":"@Override\n  public void initialize(final Injector injector) {\n    injector.injectMembers(this);\n    boolean _isNullOrEmpty = StringExtensions.isNullOrEmpty(this.rootPath);\n    boolean _not = (!_isNullOrEmpty);\n    if (_not) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess = this.owner.newFileSystemAccess(this.rootPath, true);\n      this.root = _newFileSystemAccess;\n      this.root.initialize(injector);\n    }\n    boolean _isNullOrEmpty_1 = StringExtensions.isNullOrEmpty(this.metaInfPath);\n    boolean _not_1 = (!_isNullOrEmpty_1);\n    if (_not_1) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_1 = this.owner.newFileSystemAccess(this.metaInfPath, true);\n      this.metaInf = _newFileSystemAccess_1;\n      this.metaInf.initialize(injector);\n    }\n    boolean _isNullOrEmpty_2 = StringExtensions.isNullOrEmpty(this.srcPath);\n    boolean _not_2 = (!_isNullOrEmpty_2);\n    if (_not_2) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_2 = this.owner.newFileSystemAccess(this.srcPath, this.overwriteSrc);\n      this.src = _newFileSystemAccess_2;\n      this.src.initialize(injector);\n    }\n    boolean _isNullOrEmpty_3 = StringExtensions.isNullOrEmpty(this.srcGenPath);\n    boolean _not_3 = (!_isNullOrEmpty_3);\n    if (_not_3) {\n      XtextGeneratorFileSystemAccess _newFileSystemAccess_3 = this.owner.newFileSystemAccess(this.srcGenPath, true);\n      this.srcGen = _newFileSystemAccess_3;\n      this.srcGen.initialize(injector);\n    }\n  }","commit_id":"f9926602dc42c22d9407217b99701681da3e2429","url":"https://github.com/eclipse/xtext"},{"original_method":"public void appendEditButton(final Project project, final JPanel panel, GridBagConstraints gc, final Computable<Sdk> retrieveJDK){\n    myEditButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final Sdk projectJdk = retrieveJDK.compute();\n        if (projectJdk != null) {\n          ProjectStructureConfigurable.getInstance(project).select(projectJdk, true);\n        }\n      }\n    });\n    addActionListener(new ActionListener(){\n      public void actionPerformed(ActionEvent e) {\n        final JdkComboBoxItem selectedItem = getSelectedItem();\n        if (selectedItem instanceof ProjectJdkComboBoxItem) {\n          myEditButton.setEnabled(ProjectStructureConfigurable.getInstance(project).getProjectJdksModel().getProjectSdk() != null);\n        } else {\n          myEditButton.setEnabled(!(selectedItem instanceof InvalidJdkComboBoxItem) && selectedItem != null && selectedItem.getJdk() != null);\n        }\n      }\n    });\n    panel.add(myEditButton, gc);\n  }","id":14016,"modified_method":"public void setEditButton(final JButton editButton, final Project project, final Computable<Sdk> retrieveJDK){\n    editButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final Sdk projectJdk = retrieveJDK.compute();\n        if (projectJdk != null) {\n          ProjectStructureConfigurable.getInstance(project).select(projectJdk, true);\n        }\n      }\n    });\n    addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkComboBoxItem selectedItem = getSelectedItem();\n        if (selectedItem instanceof ProjectJdkComboBoxItem) {\n          editButton.setEnabled(ProjectStructureConfigurable.getInstance(project).getProjectJdksModel().getProjectSdk() != null);\n        }\n        else {\n          editButton.setEnabled(!(selectedItem instanceof InvalidJdkComboBoxItem) && selectedItem != null && selectedItem.getJdk() != null);\n        }\n      }\n    });\n  }","commit_id":"82f1c26a00baaecf5e795583c8500060283f3184","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JButton createSetupButton(final Project project,\n                                   final ProjectSdksModel jdksModel,\n                                   final JdkComboBoxItem firstItem,\n                                   @Nullable final Condition<Sdk> additionalSetup,\n                                   final boolean moduleJdkSetup) {\n    final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n    setUpButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkListConfigurable configurable = JdkListConfigurable.getInstance(project);\n        DefaultActionGroup group = new DefaultActionGroup();\n        jdksModel.createAddActions(group, JdkComboBox.this, new Consumer<Sdk>() {\n          public void consume(final Sdk jdk) {\n            configurable.addJdkNode(jdk, false);\n            reloadModel(firstItem, project);\n            setSelectedJdk(jdk); //restore selection\n            if (additionalSetup != null) {\n              if (additionalSetup.value(jdk)) { //leave old selection\n                setSelectedJdk(firstItem.getJdk());\n              }\n            }\n          }\n        });\n        JBPopupFactory.getInstance()\n          .createActionGroupPopup(ProjectBundle.message(\"project.roots.set.up.jdk.title\", moduleJdkSetup ? 1 : 2), group,\n                                  DataManager.getInstance().getDataContext(JdkComboBox.this), JBPopupFactory.ActionSelectionAid.MNEMONICS, false)\n          .showUnderneathOf(setUpButton);\n      }\n    });\n    return setUpButton;\n  }","id":14017,"modified_method":"public void setSetupButton(final JButton setUpButton,\n                                final Project project,\n                                final ProjectSdksModel jdksModel,\n                                final JdkComboBoxItem firstItem,\n                                @Nullable final Condition<Sdk> additionalSetup,\n                                final boolean moduleJdkSetup) {\n    setUpButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkListConfigurable configurable = JdkListConfigurable.getInstance(project);\n        DefaultActionGroup group = new DefaultActionGroup();\n        jdksModel.createAddActions(group, JdkComboBox.this, new Consumer<Sdk>() {\n          public void consume(final Sdk jdk) {\n            configurable.addJdkNode(jdk, false);\n            reloadModel(firstItem, project);\n            setSelectedJdk(jdk); //restore selection\n            if (additionalSetup != null) {\n              if (additionalSetup.value(jdk)) { //leave old selection\n                setSelectedJdk(firstItem.getJdk());\n              }\n            }\n          }\n        });\n        JBPopupFactory.getInstance()\n          .createActionGroupPopup(ProjectBundle.message(\"project.roots.set.up.jdk.title\", moduleJdkSetup ? 1 : 2), group,\n                                  DataManager.getInstance().getDataContext(JdkComboBox.this), JBPopupFactory.ActionSelectionAid.MNEMONICS,\n                                  false)\n          .showUnderneathOf(setUpButton);\n      }\n    });\n  }","commit_id":"82f1c26a00baaecf5e795583c8500060283f3184","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void init() {\n    myJdkPanel = new JPanel(new GridBagLayout());\n    myCbModuleJdk = new JdkComboBox(myJdksModel);\n    myCbModuleJdk.insertItemAt(new JdkComboBox.ProjectJdkComboBoxItem(), 0);\n    myCbModuleJdk.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        if (myFreeze) return;\n\n        final Sdk newJdk = myCbModuleJdk.getSelectedJdk();\n        myModuleEditor.setSdk(newJdk);\n\n        clearCaches();\n      }\n    });\n    myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.module.radio\")),\n                   new GridBagConstraints(0, 0, 1, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(12, 6, 12, 0), 0, 0));\n    myJdkPanel.add(myCbModuleJdk, new GridBagConstraints(1, 0, 1, 1, 0, 1.0,\n                                                         GridBagConstraints.NORTHWEST, GridBagConstraints.NONE,\n                                                         new Insets(6, 6, 12, 0), 0, 0));\n    final Project project = getRootModel().getModule().getProject();\n    final JButton setUpButton = myCbModuleJdk\n      .createSetupButton(project, myJdksModel, new JdkComboBox.ProjectJdkComboBoxItem(), new Condition<Sdk>(){\n        public boolean value(Sdk jdk) {\n          final Sdk projectJdk = myJdksModel.getProjectSdk();\n          if (projectJdk == null){\n            final int res =\n              Messages.showYesNoDialog(myJdkPanel,\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.message\"),\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.projecct.title\"),\n                                       Messages.getInformationIcon());\n            if (res == DialogWrapper.OK_EXIT_CODE){\n              myJdksModel.setProjectSdk(jdk);\n              return true;\n            }\n          }\n          return false;\n        }\n      }, true);\n    myJdkPanel.add(setUpButton, new GridBagConstraints(2, 0, 1, 1, 0, 0,\n                                                       GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                                       new Insets(0, 4, 7, 0), 0, 0));\n    myCbModuleJdk.appendEditButton(getRootModel().getModule().getProject(), myJdkPanel, new GridBagConstraints(GridBagConstraints.RELATIVE, 0, 1, 1, 1.0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 7, 0), 0, 0) , new Computable<Sdk>() {\n      @Nullable\n      public Sdk compute() {\n        return getRootModel().getSdk();\n      }\n    });\n  }","id":14018,"modified_method":"private void init() {\n    myJdkPanel = new JPanel(new GridBagLayout());\n    myCbModuleJdk = new JdkComboBox(myJdksModel);\n    myCbModuleJdk.insertItemAt(new JdkComboBox.ProjectJdkComboBoxItem(), 0);\n    myCbModuleJdk.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        if (myFreeze) return;\n\n        final Sdk newJdk = myCbModuleJdk.getSelectedJdk();\n        myModuleEditor.setSdk(newJdk);\n\n        clearCaches();\n      }\n    });\n    myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.module.radio\")),\n                   new GridBagConstraints(0, 0, 1, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(12, 6, 12, 0), 0, 0));\n    myJdkPanel.add(myCbModuleJdk, new GridBagConstraints(1, 0, 1, 1, 0, 1.0,\n                                                         GridBagConstraints.NORTHWEST, GridBagConstraints.NONE,\n                                                         new Insets(6, 6, 12, 0), 0, 0));\n    final Project project = getRootModel().getModule().getProject();\n    final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n    myCbModuleJdk\n      .setSetupButton(setUpButton, project, myJdksModel, new JdkComboBox.ProjectJdkComboBoxItem(), new Condition<Sdk>() {\n        public boolean value(Sdk jdk) {\n          final Sdk projectJdk = myJdksModel.getProjectSdk();\n          if (projectJdk == null) {\n            final int res =\n              Messages.showYesNoDialog(myJdkPanel,\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.message\"),\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.title\"),\n                                       Messages.getInformationIcon());\n            if (res == DialogWrapper.OK_EXIT_CODE) {\n              myJdksModel.setProjectSdk(jdk);\n              return true;\n            }\n          }\n          return false;\n        }\n      }, true);\n    myJdkPanel.add(setUpButton, new GridBagConstraints(2, 0, 1, 1, 0, 0,\n                                                       GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                                       new Insets(0, 4, 7, 0), 0, 0));\n    final JButton editButton = new JButton(ApplicationBundle.message(\"button.edit\"));\n    myCbModuleJdk.setEditButton(editButton, getRootModel().getModule().getProject(), new Computable<Sdk>() {\n      @Nullable\n      public Sdk compute() {\n        return getRootModel().getSdk();\n      }\n    });\n    myJdkPanel.add(editButton,\n                   new GridBagConstraints(GridBagConstraints.RELATIVE, 0, 1, 1, 1.0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                          new Insets(0, 4, 7, 0), 0, 0));\n  }","commit_id":"82f1c26a00baaecf5e795583c8500060283f3184","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JComponent createComponent() {\n    if (myJdkPanel == null) {\n      myJdkPanel = new JPanel(new GridBagLayout());\n      myCbProjectJdk = new JdkComboBox(myJdksModel);\n      myCbProjectJdk.insertItemAt(new JdkComboBox.NoneJdkComboBoxItem(), 0);\n      myCbProjectJdk.addActionListener(new ActionListener() {\n        public void actionPerformed(ActionEvent e) {\n          if (myFreeze) return;\n          myJdksModel.setProjectSdk(myCbProjectJdk.getSelectedJdk());\n          clearCaches();\n        }\n      });\n      myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.project.radio\")), new GridBagConstraints(0, 0, 3, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 0, 4, 0), 0, 0));\n      myJdkPanel.add(myCbProjectJdk, new GridBagConstraints(0, 1, 1, 1, 0, 1.0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton setUpButton = myCbProjectJdk.createSetupButton(myProject, myJdksModel, new JdkComboBox.NoneJdkComboBoxItem());\n      myJdkPanel.add(setUpButton, new GridBagConstraints(1, 1, 1, 1, 0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      myCbProjectJdk.appendEditButton(myProject, myJdkPanel, new GridBagConstraints(GridBagConstraints.RELATIVE, 1, 1, 1, 1.0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0), new Computable<Sdk>() {\n        @Nullable\n        public Sdk compute() {\n          return myJdksModel.getProjectSdk();\n        }\n      });\n    }\n    return myJdkPanel;\n  }","id":14019,"modified_method":"public JComponent createComponent() {\n    if (myJdkPanel == null) {\n      myJdkPanel = new JPanel(new GridBagLayout());\n      myCbProjectJdk = new JdkComboBox(myJdksModel);\n      myCbProjectJdk.insertItemAt(new JdkComboBox.NoneJdkComboBoxItem(), 0);\n      myCbProjectJdk.addActionListener(new ActionListener() {\n        public void actionPerformed(ActionEvent e) {\n          if (myFreeze) return;\n          myJdksModel.setProjectSdk(myCbProjectJdk.getSelectedJdk());\n          clearCaches();\n        }\n      });\n      myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.project.radio\")), new GridBagConstraints(0, 0, 3, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 0, 4, 0), 0, 0));\n      myJdkPanel.add(myCbProjectJdk, new GridBagConstraints(0, 1, 1, 1, 0, 1.0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n      myCbProjectJdk.setSetupButton(setUpButton, myProject, myJdksModel, new JdkComboBox.NoneJdkComboBoxItem(), null, false);\n      myJdkPanel.add(setUpButton, new GridBagConstraints(1, 1, 1, 1, 0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton editButton = new JButton(ApplicationBundle.message(\"button.edit\"));\n      myCbProjectJdk.setEditButton(editButton, myProject, new Computable<Sdk>() {\n        @Nullable\n        public Sdk compute() {\n          return myJdksModel.getProjectSdk();\n        }\n      });\n\n      myJdkPanel.add(editButton, new GridBagConstraints(GridBagConstraints.RELATIVE, 1, 1, 1, 1.0, 0, GridBagConstraints.NORTHWEST,\n                                                            GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n    }\n    return myJdkPanel;\n  }","commit_id":"82f1c26a00baaecf5e795583c8500060283f3184","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JButton createSetupButton(final Project project,\n                                   final ProjectSdksModel jdksModel,\n                                   final JdkComboBoxItem firstItem,\n                                   @Nullable final Condition<Sdk> additionalSetup,\n                                   final boolean moduleJdkSetup) {\n    final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n    setUpButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkListConfigurable configurable = JdkListConfigurable.getInstance(project);\n        DefaultActionGroup group = new DefaultActionGroup();\n        jdksModel.createAddActions(group, JdkComboBox.this, new Consumer<Sdk>() {\n          public void consume(final Sdk jdk) {\n            configurable.addJdkNode(jdk, false);\n            reloadModel(firstItem, project);\n            setSelectedJdk(jdk); //restore selection\n            if (additionalSetup != null) {\n              if (additionalSetup.value(jdk)) { //leave old selection\n                setSelectedJdk(firstItem.getJdk());\n              }\n            }\n          }\n        });\n        JBPopupFactory.getInstance()\n          .createActionGroupPopup(ProjectBundle.message(\"project.roots.set.up.jdk.title\", moduleJdkSetup ? 1 : 2), group,\n                                  DataManager.getInstance().getDataContext(JdkComboBox.this), JBPopupFactory.ActionSelectionAid.MNEMONICS, false)\n          .showUnderneathOf(setUpButton);\n      }\n    });\n    return setUpButton;\n  }","id":14020,"modified_method":"public void setSetupButton(final JButton setUpButton,\n                                final Project project,\n                                final ProjectSdksModel jdksModel,\n                                final JdkComboBoxItem firstItem,\n                                @Nullable final Condition<Sdk> additionalSetup,\n                                final boolean moduleJdkSetup) {\n    setUpButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkListConfigurable configurable = JdkListConfigurable.getInstance(project);\n        DefaultActionGroup group = new DefaultActionGroup();\n        jdksModel.createAddActions(group, JdkComboBox.this, new Consumer<Sdk>() {\n          public void consume(final Sdk jdk) {\n            configurable.addJdkNode(jdk, false);\n            reloadModel(firstItem, project);\n            setSelectedJdk(jdk); //restore selection\n            if (additionalSetup != null) {\n              if (additionalSetup.value(jdk)) { //leave old selection\n                setSelectedJdk(firstItem.getJdk());\n              }\n            }\n          }\n        });\n        JBPopupFactory.getInstance()\n          .createActionGroupPopup(ProjectBundle.message(\"project.roots.set.up.jdk.title\", moduleJdkSetup ? 1 : 2), group,\n                                  DataManager.getInstance().getDataContext(JdkComboBox.this), JBPopupFactory.ActionSelectionAid.MNEMONICS,\n                                  false)\n          .showUnderneathOf(setUpButton);\n      }\n    });\n  }","commit_id":"f08501ef5de3ed335b9ebad3e216e68bbe965d97","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void appendEditButton(final Project project, final JPanel panel, GridBagConstraints gc, final Computable<Sdk> retrieveJDK){\n    myEditButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final Sdk projectJdk = retrieveJDK.compute();\n        if (projectJdk != null) {\n          ProjectStructureConfigurable.getInstance(project).select(projectJdk, true);\n        }\n      }\n    });\n    addActionListener(new ActionListener(){\n      public void actionPerformed(ActionEvent e) {\n        final JdkComboBoxItem selectedItem = getSelectedItem();\n        if (selectedItem instanceof ProjectJdkComboBoxItem) {\n          myEditButton.setEnabled(ProjectStructureConfigurable.getInstance(project).getProjectJdksModel().getProjectSdk() != null);\n        } else {\n          myEditButton.setEnabled(!(selectedItem instanceof InvalidJdkComboBoxItem) && selectedItem != null && selectedItem.getJdk() != null);\n        }\n      }\n    });\n    panel.add(myEditButton, gc);\n  }","id":14021,"modified_method":"public void setEditButton(final JButton editButton, final Project project, final Computable<Sdk> retrieveJDK){\n    editButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final Sdk projectJdk = retrieveJDK.compute();\n        if (projectJdk != null) {\n          ProjectStructureConfigurable.getInstance(project).select(projectJdk, true);\n        }\n      }\n    });\n    addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        final JdkComboBoxItem selectedItem = getSelectedItem();\n        if (selectedItem instanceof ProjectJdkComboBoxItem) {\n          editButton.setEnabled(ProjectStructureConfigurable.getInstance(project).getProjectJdksModel().getProjectSdk() != null);\n        }\n        else {\n          editButton.setEnabled(!(selectedItem instanceof InvalidJdkComboBoxItem) && selectedItem != null && selectedItem.getJdk() != null);\n        }\n      }\n    });\n  }","commit_id":"f08501ef5de3ed335b9ebad3e216e68bbe965d97","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void init() {\n    myJdkPanel = new JPanel(new GridBagLayout());\n    myCbModuleJdk = new JdkComboBox(myJdksModel);\n    myCbModuleJdk.insertItemAt(new JdkComboBox.ProjectJdkComboBoxItem(), 0);\n    myCbModuleJdk.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        if (myFreeze) return;\n\n        final Sdk newJdk = myCbModuleJdk.getSelectedJdk();\n        myModuleEditor.setSdk(newJdk);\n\n        clearCaches();\n      }\n    });\n    myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.module.radio\")),\n                   new GridBagConstraints(0, 0, 1, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(12, 6, 12, 0), 0, 0));\n    myJdkPanel.add(myCbModuleJdk, new GridBagConstraints(1, 0, 1, 1, 0, 1.0,\n                                                         GridBagConstraints.NORTHWEST, GridBagConstraints.NONE,\n                                                         new Insets(6, 6, 12, 0), 0, 0));\n    final Project project = getRootModel().getModule().getProject();\n    final JButton setUpButton = myCbModuleJdk\n      .createSetupButton(project, myJdksModel, new JdkComboBox.ProjectJdkComboBoxItem(), new Condition<Sdk>(){\n        public boolean value(Sdk jdk) {\n          final Sdk projectJdk = myJdksModel.getProjectSdk();\n          if (projectJdk == null){\n            final int res =\n              Messages.showYesNoDialog(myJdkPanel,\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.message\"),\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.projecct.title\"),\n                                       Messages.getInformationIcon());\n            if (res == DialogWrapper.OK_EXIT_CODE){\n              myJdksModel.setProjectSdk(jdk);\n              return true;\n            }\n          }\n          return false;\n        }\n      }, true);\n    myJdkPanel.add(setUpButton, new GridBagConstraints(2, 0, 1, 1, 0, 0,\n                                                       GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                                       new Insets(0, 4, 7, 0), 0, 0));\n    myCbModuleJdk.appendEditButton(getRootModel().getModule().getProject(), myJdkPanel, new GridBagConstraints(GridBagConstraints.RELATIVE, 0, 1, 1, 1.0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 7, 0), 0, 0) , new Computable<Sdk>() {\n      @Nullable\n      public Sdk compute() {\n        return getRootModel().getSdk();\n      }\n    });\n  }","id":14022,"modified_method":"private void init() {\n    myJdkPanel = new JPanel(new GridBagLayout());\n    myCbModuleJdk = new JdkComboBox(myJdksModel);\n    myCbModuleJdk.insertItemAt(new JdkComboBox.ProjectJdkComboBoxItem(), 0);\n    myCbModuleJdk.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent e) {\n        if (myFreeze) return;\n\n        final Sdk newJdk = myCbModuleJdk.getSelectedJdk();\n        myModuleEditor.setSdk(newJdk);\n\n        clearCaches();\n      }\n    });\n    myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.module.radio\")),\n                   new GridBagConstraints(0, 0, 1, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(12, 6, 12, 0), 0, 0));\n    myJdkPanel.add(myCbModuleJdk, new GridBagConstraints(1, 0, 1, 1, 0, 1.0,\n                                                         GridBagConstraints.NORTHWEST, GridBagConstraints.NONE,\n                                                         new Insets(6, 6, 12, 0), 0, 0));\n    final Project project = getRootModel().getModule().getProject();\n    final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n    myCbModuleJdk\n      .setSetupButton(setUpButton, project, myJdksModel, new JdkComboBox.ProjectJdkComboBoxItem(), new Condition<Sdk>() {\n        public boolean value(Sdk jdk) {\n          final Sdk projectJdk = myJdksModel.getProjectSdk();\n          if (projectJdk == null) {\n            final int res =\n              Messages.showYesNoDialog(myJdkPanel,\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.message\"),\n                                       ProjectBundle.message(\"project.roots.no.jdk.on.project.title\"),\n                                       Messages.getInformationIcon());\n            if (res == DialogWrapper.OK_EXIT_CODE) {\n              myJdksModel.setProjectSdk(jdk);\n              return true;\n            }\n          }\n          return false;\n        }\n      }, true);\n    myJdkPanel.add(setUpButton, new GridBagConstraints(2, 0, 1, 1, 0, 0,\n                                                       GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                                       new Insets(0, 4, 7, 0), 0, 0));\n    final JButton editButton = new JButton(ApplicationBundle.message(\"button.edit\"));\n    myCbModuleJdk.setEditButton(editButton, getRootModel().getModule().getProject(), new Computable<Sdk>() {\n      @Nullable\n      public Sdk compute() {\n        return getRootModel().getSdk();\n      }\n    });\n    myJdkPanel.add(editButton,\n                   new GridBagConstraints(GridBagConstraints.RELATIVE, 0, 1, 1, 1.0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE,\n                                          new Insets(0, 4, 7, 0), 0, 0));\n  }","commit_id":"f08501ef5de3ed335b9ebad3e216e68bbe965d97","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JComponent createComponent() {\n    if (myJdkPanel == null) {\n      myJdkPanel = new JPanel(new GridBagLayout());\n      myCbProjectJdk = new JdkComboBox(myJdksModel);\n      myCbProjectJdk.insertItemAt(new JdkComboBox.NoneJdkComboBoxItem(), 0);\n      myCbProjectJdk.addActionListener(new ActionListener() {\n        public void actionPerformed(ActionEvent e) {\n          if (myFreeze) return;\n          myJdksModel.setProjectSdk(myCbProjectJdk.getSelectedJdk());\n          clearCaches();\n        }\n      });\n      myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.project.radio\")), new GridBagConstraints(0, 0, 3, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 0, 4, 0), 0, 0));\n      myJdkPanel.add(myCbProjectJdk, new GridBagConstraints(0, 1, 1, 1, 0, 1.0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton setUpButton = myCbProjectJdk.createSetupButton(myProject, myJdksModel, new JdkComboBox.NoneJdkComboBoxItem());\n      myJdkPanel.add(setUpButton, new GridBagConstraints(1, 1, 1, 1, 0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      myCbProjectJdk.appendEditButton(myProject, myJdkPanel, new GridBagConstraints(GridBagConstraints.RELATIVE, 1, 1, 1, 1.0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0), new Computable<Sdk>() {\n        @Nullable\n        public Sdk compute() {\n          return myJdksModel.getProjectSdk();\n        }\n      });\n    }\n    return myJdkPanel;\n  }","id":14023,"modified_method":"public JComponent createComponent() {\n    if (myJdkPanel == null) {\n      myJdkPanel = new JPanel(new GridBagLayout());\n      myCbProjectJdk = new JdkComboBox(myJdksModel);\n      myCbProjectJdk.insertItemAt(new JdkComboBox.NoneJdkComboBoxItem(), 0);\n      myCbProjectJdk.addActionListener(new ActionListener() {\n        public void actionPerformed(ActionEvent e) {\n          if (myFreeze) return;\n          myJdksModel.setProjectSdk(myCbProjectJdk.getSelectedJdk());\n          clearCaches();\n        }\n      });\n      myJdkPanel.add(new JLabel(ProjectBundle.message(\"module.libraries.target.jdk.project.radio\")), new GridBagConstraints(0, 0, 3, 1, 0, 0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 0, 4, 0), 0, 0));\n      myJdkPanel.add(myCbProjectJdk, new GridBagConstraints(0, 1, 1, 1, 0, 1.0, GridBagConstraints.NORTHWEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton setUpButton = new JButton(ApplicationBundle.message(\"button.new\"));\n      myCbProjectJdk.setSetupButton(setUpButton, myProject, myJdksModel, new JdkComboBox.NoneJdkComboBoxItem(), null, false);\n      myJdkPanel.add(setUpButton, new GridBagConstraints(1, 1, 1, 1, 0, 0, GridBagConstraints.WEST, GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n      final JButton editButton = new JButton(ApplicationBundle.message(\"button.edit\"));\n      myCbProjectJdk.setEditButton(editButton, myProject, new Computable<Sdk>() {\n        @Nullable\n        public Sdk compute() {\n          return myJdksModel.getProjectSdk();\n        }\n      });\n\n      myJdkPanel.add(editButton, new GridBagConstraints(GridBagConstraints.RELATIVE, 1, 1, 1, 1.0, 0, GridBagConstraints.NORTHWEST,\n                                                            GridBagConstraints.NONE, new Insets(0, 4, 0, 0), 0, 0));\n    }\n    return myJdkPanel;\n  }","commit_id":"f08501ef5de3ed335b9ebad3e216e68bbe965d97","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n    public void testParseDateMath() throws Exception {\n        \n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", System.currentTimeMillis()).endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", System.currentTimeMillis() - (1000 * 60 * 60 * 24)).endObject())).actionGet();\n        refresh();\n\n        SearchResponse sr = client().search(\n                searchRequest().source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"now\", \"2d\"))))).get();\n\n        assertNoFailures(sr);\n        assertOrderedSearchHits(sr, \"1\", \"2\");\n        \n        sr = client().search(\n                searchRequest().source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"now-1d\", \"2d\"))))).get();\n\n        assertNoFailures(sr);\n        assertOrderedSearchHits(sr, \"2\", \"1\");\n\n    }","id":14024,"modified_method":"@Test\n    public void testParseDateMath() throws Exception {\n        \n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", System.currentTimeMillis()).endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", System.currentTimeMillis() - (1000 * 60 * 60 * 24)).endObject())).actionGet();\n        refresh();\n\n        SearchResponse sr = client().search(\n                searchRequest().source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"now\", \"2d\"))))).get();\n\n        assertNoFailures(sr);\n        assertOrderedSearchHits(sr, \"1\", \"2\");\n        \n        sr = client().search(\n                searchRequest().source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"now-1d\", \"2d\"))))).get();\n\n        assertNoFailures(sr);\n        assertOrderedSearchHits(sr, \"2\", \"1\");\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDateWithoutOrigin() throws Exception {\n        DateTime dt = new DateTime();\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        DateTime docDate = dt.minusDays(1);\n        String docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n        docDate = dt.minusDays(2);\n        docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n        docDate = dt.minusDays(3);\n        docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"3\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(false).query(\n                                functionScoreQuery(QueryBuilders.matchAllQuery()).add(linearDecayFunction(\"num1\", \"1000w\"))\n                                        .add(gaussDecayFunction(\"num1\", \"1d\")).add(exponentialDecayFunction(\"num1\", \"1000w\"))\n                                        .scoreMode(\"multiply\"))));\n\n        SearchResponse sr = response.actionGet();\n        assertNoFailures(sr);\n        SearchHits sh = sr.getHits();\n        assertThat(sh.hits().length, equalTo(3));\n        double[] scores = new double[4];\n        for (int i = 0; i < sh.hits().length; i++) {\n            scores[Integer.parseInt(sh.getAt(i).getId()) - 1] = sh.getAt(i).getScore();\n        }\n        assertThat(scores[1], lessThan(scores[0]));\n        assertThat(scores[2], lessThan(scores[1]));\n\n    }","id":14025,"modified_method":"@Test\n    public void testDateWithoutOrigin() throws Exception {\n        DateTime dt = new DateTime();\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        DateTime docDate = dt.minusDays(1);\n        String docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n        docDate = dt.minusDays(2);\n        docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n        docDate = dt.minusDays(3);\n        docDateString = docDate.getYear() + \"-\" + docDate.getMonthOfYear() + \"-\" + docDate.getDayOfMonth();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"3\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", docDateString).endObject())).actionGet();\n\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(QueryBuilders.matchAllQuery()).add(linearDecayFunction(\"num1\", \"1000w\"))\n                                        .add(gaussDecayFunction(\"num1\", \"1d\")).add(exponentialDecayFunction(\"num1\", \"1000w\"))\n                                        .scoreMode(\"multiply\"))));\n\n        SearchResponse sr = response.actionGet();\n        assertNoFailures(sr);\n        SearchHits sh = sr.getHits();\n        assertThat(sh.hits().length, equalTo(3));\n        double[] scores = new double[4];\n        for (int i = 0; i < sh.hits().length; i++) {\n            scores[Integer.parseInt(sh.getAt(i).getId()) - 1] = sh.getAt(i).getScore();\n        }\n        assertThat(scores[1], lessThan(scores[0]));\n        assertThat(scores[2], lessThan(scores[1]));\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testValueMissingLin() throws Exception {\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().startObject(\"num2\").field(\"type\", \"double\")\n                        .endObject().endObject().endObject().endObject())\n        );\n\n        ensureYellow();\n\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-27\").field(\"num2\", \"1.0\")\n                                .endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num2\", \"1.0\").endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"3\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-30\").field(\"num2\", \"1.0\")\n                                .endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"4\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-30\").endObject())).actionGet();\n\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\"))).add(linearDecayFunction(\"num1\", \"2013-05-28\", \"+3d\"))\n                                        .add(linearDecayFunction(\"num2\", \"0.0\", \"1\")).scoreMode(\"multiply\"))));\n\n        SearchResponse sr = response.actionGet();\n\n        assertNoFailures(sr);\n        SearchHits sh = sr.getHits();\n        assertThat(sh.hits().length, equalTo(4));\n        double[] scores = new double[4];\n        for (int i = 0; i < sh.hits().length; i++) {\n            scores[Integer.parseInt(sh.getAt(i).getId()) - 1] = sh.getAt(i).getScore();\n        }\n        assertThat(scores[0], lessThan(scores[1]));\n        assertThat(scores[2], lessThan(scores[3]));\n\n    }","id":14026,"modified_method":"@Test\n    public void testValueMissingLin() throws Exception {\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().startObject(\"num2\").field(\"type\", \"double\")\n                        .endObject().endObject().endObject().endObject())\n        );\n\n        ensureYellow();\n\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-27\").field(\"num2\", \"1.0\")\n                                .endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num2\", \"1.0\").endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"3\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-30\").field(\"num2\", \"1.0\")\n                                .endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"4\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-30\").endObject())).actionGet();\n\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\"))).add(linearDecayFunction(\"num1\", \"2013-05-28\", \"+3d\"))\n                                        .add(linearDecayFunction(\"num2\", \"0.0\", \"1\")).scoreMode(\"multiply\"))));\n\n        SearchResponse sr = response.actionGet();\n\n        assertNoFailures(sr);\n        SearchHits sh = sr.getHits();\n        assertThat(sh.hits().length, equalTo(4));\n        double[] scores = new double[4];\n        for (int i = 0; i < sh.hits().length; i++) {\n            scores[Integer.parseInt(sh.getAt(i).getId()) - 1] = sh.getAt(i).getScore();\n        }\n        assertThat(scores[0], lessThan(scores[1]));\n        assertThat(scores[2], lessThan(scores[3]));\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testNoQueryGiven() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type\").source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.0).endObject()))\n                .actionGet();\n        refresh();\n        // so, we indexed a string field, but now we try to score a num field\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery().add(new MatchAllFilterBuilder(), linearDecayFunction(\"num\", 1, 0.5)).scoreMode(\n                                        \"multiply\"))));\n        response.actionGet();\n    }","id":14027,"modified_method":"@Test\n    public void testNoQueryGiven() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type\").source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.0).endObject()))\n                .actionGet();\n        refresh();\n        // so, we indexed a string field, but now we try to score a num field\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery().add(new MatchAllFilterBuilder(), linearDecayFunction(\"num\", 1, 0.5)).scoreMode(\n                                        \"multiply\"))));\n        response.actionGet();\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDistanceScoreGeoLinGaussExpWithOffset() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        // add tw docs within offset\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(\"1\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 0.5).endObject()));\n        indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(\"2\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.7).endObject()));\n\n        // add docs outside offset\n        int numDummyDocs = 20;\n        for (int i = 0; i < numDummyDocs; i++) {\n            indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(Integer.toString(i + 3)).setIndex(\"test\")\n                    .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 3.0 + i).endObject()));\n        }\n\n        indexRandom(true, indexBuilders);\n\n        // Test Gauss\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .explain(true)\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 1.0, 5.0).setOffset(1.0))\n                                        .boostMode(CombineFunction.REPLACE.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n        for (int i = 0; i < numDummyDocs; i++) {\n            assertThat(sh.getAt(i + 2).getId(), equalTo(Integer.toString(i + 3)));\n        }\n\n        // Test Exp\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .explain(true)\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"),\n                                        exponentialDecayFunction(\"num\", 1.0, 5.0).setOffset(1.0)).boostMode(\n                                        CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n        for (int i = 0; i < numDummyDocs; i++) {\n            assertThat(sh.getAt(i + 2).getId(), equalTo(Integer.toString(i + 3)));\n        }\n        // Test Lin\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .explain(true)\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"), linearDecayFunction(\"num\", 1.0, 20.0).setOffset(1.0))\n                                        .boostMode(CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n    }","id":14028,"modified_method":"@Test\n    public void testDistanceScoreGeoLinGaussExpWithOffset() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        // add tw docs within offset\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(\"1\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 0.5).endObject()));\n        indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(\"2\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.7).endObject()));\n\n        // add docs outside offset\n        int numDummyDocs = 20;\n        for (int i = 0; i < numDummyDocs; i++) {\n            indexBuilders.add(client().prepareIndex().setType(\"type1\").setId(Integer.toString(i + 3)).setIndex(\"test\")\n                    .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 3.0 + i).endObject()));\n        }\n\n        indexRandom(true, indexBuilders);\n\n        // Test Gauss\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 1.0, 5.0).setOffset(1.0))\n                                        .boostMode(CombineFunction.REPLACE.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n        for (int i = 0; i < numDummyDocs; i++) {\n            assertThat(sh.getAt(i + 2).getId(), equalTo(Integer.toString(i + 3)));\n        }\n\n        // Test Exp\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"),\n                                        exponentialDecayFunction(\"num\", 1.0, 5.0).setOffset(1.0)).boostMode(\n                                        CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n        for (int i = 0; i < numDummyDocs; i++) {\n            assertThat(sh.getAt(i + 2).getId(), equalTo(Integer.toString(i + 3)));\n        }\n        // Test Lin\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .size(numDummyDocs + 2)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\"), linearDecayFunction(\"num\", 1.0, 20.0).setOffset(1.0))\n                                        .boostMode(CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n        assertThat(sh.getAt(0).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).getId(), anyOf(equalTo(\"1\"), equalTo(\"2\")));\n        assertThat(sh.getAt(1).score(), equalTo(sh.getAt(0).score()));\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testBoostModeSettingWorks() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 21).endObject()\n                                .endObject()));\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"2\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 20)\n                                .endObject().endObject()));\n        indexRandom(true, false, indexBuilders); // force no dummy docs\n\n        // Test Gauss\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(20f);\n        lonlat.add(11f);\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", lonlat, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (2)));\n        assertThat(sh.getAt(0).getId(), isOneOf(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n\n        // Test Exp\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", lonlat, \"1000km\")).boostMode(\n                                        CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (2)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"2\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"1\"));\n\n    }","id":14029,"modified_method":"@Test\n    public void testBoostModeSettingWorks() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 21).endObject()\n                                .endObject()));\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"2\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 20)\n                                .endObject().endObject()));\n        indexRandom(true, false, indexBuilders); // force no dummy docs\n\n        // Test Gauss\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(20f);\n        lonlat.add(11f);\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", lonlat, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (2)));\n        assertThat(sh.getAt(0).getId(), isOneOf(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n\n        // Test Exp\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", lonlat, \"1000km\")).boostMode(\n                                        CombineFunction.REPLACE.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (2)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"2\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"1\"));\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testCombineModes() throws Exception {\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        client().prepareIndex().setType(\"type1\").setId(\"1\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.0).endObject()).setRefresh(true).get();\n\n        // function score should return 0.5 for this function\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MULT))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.REPLACE))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.SUM))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282 + 0.5), 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.AVG))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo((0.30685282 + 0.5), 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MIN))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282), 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MAX))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n    }","id":14030,"modified_method":"@Test\n    public void testCombineModes() throws Exception {\n\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"double\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        client().prepareIndex().setType(\"type1\").setId(\"1\").setIndex(\"test\")\n                .setSource(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", 1.0).endObject()).setRefresh(true).get();\n\n        // function score should return 0.5 for this function\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MULT))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.REPLACE))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.SUM))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282 + 0.5), 1.e-5));\n        logger.info(\"--> Hit[0] {} Explanation:\\n {}\", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.AVG))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo((0.30685282 + 0.5), 1.e-5));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MIN))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282), 1.e-5));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num\", 0.0, 1.0).setDecay(0.5)).boost(\n                                        2.0f).boostMode(CombineFunction.MAX))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testParseGeoPoint() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 20).field(\"lon\", 11).endObject()\n                                .endObject()).setRefresh(true).get();\n\n        GeoPoint point = new GeoPoint(20, 11);\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", point, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n        float[] coords = { 11, 20 };\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", coords, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n    }","id":14031,"modified_method":"@Test\n    public void testParseGeoPoint() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 20).field(\"lon\", 11).endObject()\n                                .endObject()).setRefresh(true).get();\n\n        GeoPoint point = new GeoPoint(20, 11);\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", point, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n        float[] coords = { 11, 20 };\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"loc\", coords, \"1000km\")).boostMode(\n                                        CombineFunction.MULT.getName()))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (1)));\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testParsingExceptionIfFieldDoesNotExist() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"geo\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        int numDocs = 2;\n        client().index(\n                indexRequest(\"test\").type(\"type1\").source(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"geo\").field(\"lat\", 1).field(\"lon\", 2).endObject()\n                                .endObject())).actionGet();\n        refresh();\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(100f);\n        lonlat.add(110f);\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .explain(true)\n                                .size(numDocs)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\")).add(new MatchAllFilterBuilder(),\n                                        linearDecayFunction(\"type1.geo\", lonlat, \"1000km\")).scoreMode(\"multiply\"))));\n        SearchResponse sr = response.actionGet();\n\n    }","id":14032,"modified_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testParsingExceptionIfFieldDoesNotExist() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"geo\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        int numDocs = 2;\n        client().index(\n                indexRequest(\"test\").type(\"type1\").source(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"geo\").field(\"lat\", 1).field(\"lon\", 2).endObject()\n                                .endObject())).actionGet();\n        refresh();\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(100f);\n        lonlat.add(110f);\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource()\n                                .size(numDocs)\n                                .query(functionScoreQuery(termQuery(\"test\", \"value\")).add(new MatchAllFilterBuilder(),\n                                        linearDecayFunction(\"type1.geo\", lonlat, \"1000km\")).scoreMode(\"multiply\"))));\n        SearchResponse sr = response.actionGet();\n\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testExceptionThrownIfScaleLE0() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-27\").endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-28\").endObject())).actionGet();\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"2013-05-28\", \"-1d\")))));\n\n        SearchResponse sr = response.actionGet();\n        assertOrderedSearchHits(sr, \"2\", \"1\");\n    }","id":14033,"modified_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testExceptionThrownIfScaleLE0() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num1\").field(\"type\", \"date\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"1\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-27\").endObject())).actionGet();\n        client().index(\n                indexRequest(\"test\").type(\"type1\").id(\"2\")\n                        .source(jsonBuilder().startObject().field(\"test\", \"value\").field(\"num1\", \"2013-05-28\").endObject())).actionGet();\n        refresh();\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\"), gaussDecayFunction(\"num1\", \"2013-05-28\", \"-1d\")))));\n\n        SearchResponse sr = response.actionGet();\n        assertOrderedSearchHits(sr, \"2\", \"1\");\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDistanceScoreGeoLinGaussExp() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 10).field(\"lon\", 20).endObject()\n                                .endObject()));\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"2\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 22).endObject()\n                                .endObject()));\n\n        int numDummyDocs = 20;\n        for (int i = 1; i <= numDummyDocs; i++) {\n            indexBuilders.add(client().prepareIndex()\n                    .setType(\"type1\")\n                    .setId(Integer.toString(i + 3))\n                    .setIndex(\"test\")\n                    .setSource(\n                            jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11 + i).field(\"lon\", 22 + i)\n                                    .endObject().endObject()));\n        }\n\n        indexRandom(true, indexBuilders);\n\n        // Test Gauss\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(20f);\n        lonlat.add(11f);\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(false).query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), gaussDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n        // Test Exp\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(false).query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), linearDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n        // Test Lin\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(false).query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), exponentialDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n    }","id":14034,"modified_method":"@Test\n    public void testDistanceScoreGeoLinGaussExp() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type1\",\n                jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"loc\").field(\"type\", \"geo_point\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n\n        List<IndexRequestBuilder> indexBuilders = new ArrayList<>();\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"1\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 10).field(\"lon\", 20).endObject()\n                                .endObject()));\n        indexBuilders.add(client().prepareIndex()\n                .setType(\"type1\")\n                .setId(\"2\")\n                .setIndex(\"test\")\n                .setSource(\n                        jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11).field(\"lon\", 22).endObject()\n                                .endObject()));\n\n        int numDummyDocs = 20;\n        for (int i = 1; i <= numDummyDocs; i++) {\n            indexBuilders.add(client().prepareIndex()\n                    .setType(\"type1\")\n                    .setId(Integer.toString(i + 3))\n                    .setIndex(\"test\")\n                    .setSource(\n                            jsonBuilder().startObject().field(\"test\", \"value\").startObject(\"loc\").field(\"lat\", 11 + i).field(\"lon\", 22 + i)\n                                    .endObject().endObject()));\n        }\n\n        indexRandom(true, indexBuilders);\n\n        // Test Gauss\n        List<Float> lonlat = new ArrayList<>();\n        lonlat.add(20f);\n        lonlat.add(11f);\n\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        SearchResponse sr = response.actionGet();\n        SearchHits sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), gaussDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n        // Test Exp\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), linearDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n        // Test Lin\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(constantScoreQuery(termQuery(\"test\", \"value\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(constantScoreQuery(termQuery(\"test\", \"value\")), exponentialDecayFunction(\"loc\", lonlat, \"1000km\")))));\n        sr = response.actionGet();\n        sh = sr.getHits();\n        assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));\n\n        assertThat(sh.getAt(0).getId(), equalTo(\"1\"));\n        assertThat(sh.getAt(1).getId(), equalTo(\"2\"));\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testParsingExceptionIfFieldTypeDoesNotMatch() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"string\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type\").source(\n                        jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", Integer.toString(1)).endObject())).actionGet();\n        refresh();\n        // so, we indexed a string field, but now we try to score a num field\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().explain(true).query(\n                                functionScoreQuery(termQuery(\"test\", \"value\")).add(new MatchAllFilterBuilder(),\n                                        linearDecayFunction(\"num\", 1.0, 0.5)).scoreMode(\"multiply\"))));\n        response.actionGet();\n    }","id":14035,"modified_method":"@Test(expected = SearchPhaseExecutionException.class)\n    public void testParsingExceptionIfFieldTypeDoesNotMatch() throws Exception {\n        assertAcked(prepareCreate(\"test\").addMapping(\n                \"type\",\n                jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\").startObject(\"test\").field(\"type\", \"string\")\n                        .endObject().startObject(\"num\").field(\"type\", \"string\").endObject().endObject().endObject().endObject()));\n        ensureYellow();\n        client().index(\n                indexRequest(\"test\").type(\"type\").source(\n                        jsonBuilder().startObject().field(\"test\", \"value\").field(\"num\", Integer.toString(1)).endObject())).actionGet();\n        refresh();\n        // so, we indexed a string field, but now we try to score a num field\n        ActionFuture<SearchResponse> response = client().search(\n                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n                        searchSource().query(\n                                functionScoreQuery(termQuery(\"test\", \"value\")).add(new MatchAllFilterBuilder(),\n                                        linearDecayFunction(\"num\", 1.0, 0.5)).scoreMode(\"multiply\"))));\n        response.actionGet();\n    }","commit_id":"d6312178ad07ce6854f2451e97eda2c86483efaf","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testScoring() throws Exception {\n        client().admin()\n                .indices()\n                .prepareCreate(\"test\")\n                .addMapping(\n                        \"type1\",\n                        jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"field1\")\n                                .field(\"index\", \"not_analyzed\").field(\"type\", \"string\").endObject().endObject().endObject().endObject())\n                .setSettings(ImmutableSettings.settingsBuilder()).execute().actionGet();\n        ensureGreen();\n        int numDocs = 1000;\n\n        for (int i = 0; i < numDocs; i++) {\n            client().prepareIndex(\"test\", \"type1\", String.valueOf(i)).setSource(\"field1\", English.intToEnglish(i)).execute().actionGet();\n        }\n\n        flush();\n        optimize(); // make sure we don't have a background merge running\n        refresh();\n        ensureGreen();\n\n        String[] scoreModes = new String[]{ \"max\", \"min\", \"avg\", \"total\", \"multiply\", \"\" };\n        float primaryWeight = 1.1f;\n        float secondaryWeight = 1.6f;\n\n        for (String scoreMode: scoreModes) {\n            for (int i = 0; i < numDocs - 4; i++) {\n                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };\n\n                QueryRescorer rescoreQuery = RescoreBuilder\n                        .queryRescorer(\n                                QueryBuilders.boolQuery()\n                                    .disableCoord(true)\n                                    .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[0])).script(\"5.0f\"))\n                                    .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[1])).script(\"7.0f\"))\n                                    .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[3])).script(\"0.0f\")))\n                        .setQueryWeight(primaryWeight)\n                        .setRescoreQueryWeight(secondaryWeight);\n\n                if (!\"\".equals(scoreMode)) {\n                    rescoreQuery.setScoreMode(scoreMode);\n                }\n\n                SearchResponse rescored = client()\n                        .prepareSearch()\n                        .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                        .setQuery(QueryBuilders.boolQuery()\n                                .disableCoord(true)\n                                .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[0])).script(\"2.0f\"))\n                                .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[1])).script(\"3.0f\"))\n                                .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[2])).script(\"5.0f\"))\n                                .should(QueryBuilders.customScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[3])).script(\"0.2f\")))\n                        .setFrom(0)\n                        .setSize(10)\n                        .setRescorer(rescoreQuery)\n                        .setRescoreWindow(50).execute().actionGet();\n\n                assertHitCount(rescored, 4);\n\n                if (\"total\".equals(scoreMode) || \"\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));\n                } else if (\"max\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));\n                } else if (\"min\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));\n                } else if (\"avg\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));\n                } else if (\"multiply\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));\n                }\n            }\n        }\n    }","id":14036,"modified_method":"@Test\n    public void testScoring() throws Exception {\n        client().admin()\n                .indices()\n                .prepareCreate(\"test\")\n                .addMapping(\n                        \"type1\",\n                        jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"field1\")\n                                .field(\"index\", \"not_analyzed\").field(\"type\", \"string\").endObject().endObject().endObject().endObject())\n                .setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", between(1,5)).put(\"index.number_of_replicas\", between(0,1))).get();\n        int numDocs = atLeast(100);\n        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];\n        for (int i = 0; i < numDocs; i++) {\n            docs[i] = client().prepareIndex(\"test\", \"type1\", String.valueOf(i)).setSource(\"field1\", English.intToEnglish(i));\n        }\n\n        indexRandom(true, docs);\n        ensureGreen();\n\n        String[] scoreModes = new String[]{ \"max\", \"min\", \"avg\", \"total\", \"multiply\", \"\" };\n        float primaryWeight = 1.1f;\n        float secondaryWeight = 1.6f;\n\n        for (String scoreMode: scoreModes) {\n            for (int i = 0; i < numDocs - 4; i++) {\n                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };\n\n                QueryRescorer rescoreQuery = RescoreBuilder\n                        .queryRescorer(\n                                QueryBuilders.boolQuery()\n                                        .disableCoord(true)\n                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[0])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"5.0f\")))\n                                    .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[1])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"7.0f\")))\n                                    .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[3])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"0.0f\"))))\n                        .setQueryWeight(primaryWeight)\n                        .setRescoreQueryWeight(secondaryWeight);\n\n                if (!\"\".equals(scoreMode)) {\n                    rescoreQuery.setScoreMode(scoreMode);\n                }\n\n                SearchResponse rescored = client()\n                        .prepareSearch()\n                        .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                        .setQuery(QueryBuilders.boolQuery()\n                                .disableCoord(true)\n                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[0])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"2.0f\")))\n                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[1])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"3.0f\")))\n                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[2])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"5.0f\")))\n                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery(\"field1\", intToEnglish[3])).boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(\"0.2f\"))))\n                        .setFrom(0)\n                        .setSize(10)\n                        .setRescorer(rescoreQuery)\n                        .setRescoreWindow(50).execute().actionGet();\n\n                assertHitCount(rescored, 4);\n\n                if (\"total\".equals(scoreMode) || \"\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));\n                } else if (\"max\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));\n                } else if (\"min\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));\n                } else if (\"avg\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));\n                } else if (\"multiply\".equals(scoreMode)) {\n                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));\n                    assertSecondHit(rescored, hasId(String.valueOf(i)));\n                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));\n                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));\n                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));\n                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));\n                }\n            }\n        }\n    }","commit_id":"d18ce2733d52e06bcc4aea80f39e92b113bc69fe","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testEquivalence() throws Exception {\n        client().admin()\n                .indices()\n                .prepareCreate(\"test\")\n                .addMapping(\n                        \"type1\",\n                        jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"field1\")\n                                .field(\"analyzer\", \"whitespace\").field(\"type\", \"string\").endObject().endObject().endObject().endObject())\n                .setSettings(ImmutableSettings.settingsBuilder()).execute().actionGet();\n        ensureGreen();\n        int numDocs = atLeast(100);\n\n        for (int i = 0; i < numDocs; i++) {\n            client().prepareIndex(\"test\", \"type1\", String.valueOf(i)).setSource(\"field1\", English.intToEnglish(i)).execute().actionGet();\n        }\n\n        flush();\n        optimize(); // make sure we don't have a background merge running\n        refresh();\n        ensureGreen();\n        final int iters = atLeast(50);\n        for (int i = 0; i < iters; i++) {\n            String intToEnglish = English.intToEnglish(between(0, numDocs-1));\n            String query = intToEnglish.split(\" \")[0];\n            SearchResponse rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders\n                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery(\"field1\", intToEnglish).slop(3)))\n                                    .setQueryWeight(1.0f)\n                                    .setRescoreQueryWeight(0.0f)) // no weigth - so we basically use the same score as the actual query\n                    .setRescoreWindow(50).execute().actionGet();\n\n            SearchResponse plain = client().prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR)).setFrom(0).setSize(10)\n                    .execute().actionGet();\n            \n            // check equivalence\n            assertEquivalent(plain, rescored);\n\n            rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders\n                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery(\"field1\", \"not in the index\").slop(3)))\n                                    .setQueryWeight(1.0f)\n                                    .setRescoreQueryWeight(1.0f))\n                    .setRescoreWindow(50).execute().actionGet();\n            // check equivalence\n            assertEquivalent(plain, rescored);\n\n            rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders.matchPhraseQuery(\"field1\", intToEnglish).slop(0))\n                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(100).execute().actionGet();\n            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc\n            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);\n        }\n    }","id":14037,"modified_method":"@Test\n    public void testEquivalence() throws Exception {\n        client().admin()\n                .indices()\n                .prepareCreate(\"test\")\n                .addMapping(\n                        \"type1\",\n                        jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\").startObject(\"field1\")\n                                .field(\"analyzer\", \"whitespace\").field(\"type\", \"string\").endObject().endObject().endObject().endObject())\n                .setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", between(1, 5)).put(\"index.number_of_replicas\", between(0, 1))).execute().actionGet();\n        ensureGreen();\n\n        int numDocs = atLeast(100);\n        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];\n        for (int i = 0; i < numDocs; i++) {\n            docs[i] = client().prepareIndex(\"test\", \"type1\", String.valueOf(i)).setSource(\"field1\", English.intToEnglish(i));\n        }\n\n        indexRandom(true, docs);\n        ensureGreen();\n        final int iters = atLeast(50);\n        for (int i = 0; i < iters; i++) {\n            String intToEnglish = English.intToEnglish(between(0, numDocs-1));\n            String query = intToEnglish.split(\" \")[0];\n            SearchResponse rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders\n                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery(\"field1\", intToEnglish).slop(3)))\n                                    .setQueryWeight(1.0f)\n                                    .setRescoreQueryWeight(0.0f)) // no weigth - so we basically use the same score as the actual query\n                    .setRescoreWindow(50).execute().actionGet();\n\n            SearchResponse plain = client().prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR)).setFrom(0).setSize(10)\n                    .execute().actionGet();\n            \n            // check equivalence\n            assertEquivalent(plain, rescored);\n\n            rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders\n                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery(\"field1\", \"not in the index\").slop(3)))\n                                    .setQueryWeight(1.0f)\n                                    .setRescoreQueryWeight(1.0f))\n                    .setRescoreWindow(50).execute().actionGet();\n            // check equivalence\n            assertEquivalent(plain, rescored);\n\n            rescored = client()\n                    .prepareSearch()\n                    .setPreference(\"test\") // ensure we hit the same shards for tie-breaking\n                    .setQuery(QueryBuilders.matchQuery(\"field1\", query).operator(MatchQueryBuilder.Operator.OR))\n                    .setFrom(0)\n                    .setSize(10)\n                    .setRescorer(\n                            RescoreBuilder\n                                    .queryRescorer(\n                                            QueryBuilders.matchPhraseQuery(\"field1\", intToEnglish).slop(0))\n                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(100).execute().actionGet();\n            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc\n            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);\n        }\n    }","commit_id":"d18ce2733d52e06bcc4aea80f39e92b113bc69fe","url":"https://github.com/elastic/elasticsearch"},{"original_method":"SimpleFieldSet exportPublicCryptoFieldSet(boolean forSetup, boolean forAnonInitiator) {\n\t\tSimpleFieldSet fs = new SimpleFieldSet(true);\n\t\tint[] negTypes = packetMangler.supportedNegTypes(true);\n\t\tif(!(forSetup || forAnonInitiator))\n\t\t\t// Can't change on setup.\n\t\t\t// Anonymous initiator doesn't need identity as we don't use it.\n\t\t\tfs.putSingle(\"identity\", Base64.encode(myIdentity));\n\t\tif(!forSetup) {\n\t\t\t// These are invariant. They cannot change on connection setup. They can safely be excluded.\n\t\t\tfs.put(\"dsaGroup\", cryptoGroup.asFieldSet());\n\t\t\tfs.put(\"dsaPubKey\", pubKey.asFieldSet());\n\t\t\tfs.put(\"ecdsa\", ecdsaP256.asFieldSet(false));\n\t\t}\n\t\tif(!forAnonInitiator) {\n\t\t\t// Short-lived connections don't need ARK and don't need negTypes either.\n\t\t\tfs.put(\"auth.negTypes\", negTypes);\n\t\t\tif(!forSetup) {\n\t\t\t\tfs.put(\"ark.number\", myARKNumber); // Can be changed on setup\n\t\t\t\tfs.putSingle(\"ark.pubURI\", myARK.getURI().toString(false, false)); // Can be changed on setup\n\t\t\t}\n\t\t}\n\t\treturn fs;\n\t}","id":14038,"modified_method":"SimpleFieldSet exportPublicCryptoFieldSet(boolean forSetup, boolean forAnonInitiator) {\n\t\tSimpleFieldSet fs = new SimpleFieldSet(true);\n\t\tint[] negTypes = packetMangler.supportedNegTypes(true);\n\t\tif(!(forSetup || forAnonInitiator))\n\t\t\t// Can't change on setup.\n\t\t\t// Anonymous initiator doesn't need identity as we don't use it.\n\t\t\tfs.putSingle(\"identity\", Base64.encode(myIdentity));\n\t\tif(!forSetup) {\n\t\t\t// These are invariant. They cannot change on connection setup. They can safely be excluded.\n\t\t\t// we have to return \"something\" otherwise we break opennet\n\t\t\t// TODO: remove it once 1471 is mandatory\n\t\t\tif(pubKey == null)\n\t\t\t\tfs.putSingle(\"dsaPubKey.y\", \"placeholder\");\n\t\t\telse\n\t\t\t\tfs.put(\"dsaPubKey\", pubKey.asFieldSet());\n\t\t\tif(cryptoGroup == null) {\n\t\t\t\tfs.putSingle(\"dsaGroup.g\", \"placeholder\");\n\t\t\t\tfs.putSingle(\"dsaGroup.p\", \"placeholder\");\n\t\t\t\tfs.putSingle(\"dsaGroup.q\", \"placeholder\");\n\t\t\t} else {\n\t\t\t\tfs.put(\"dsaGroup\", cryptoGroup.asFieldSet());\n\t\t\t}\n\t\t\tfs.put(\"ecdsa\", ecdsaP256.asFieldSet(false));\n\t\t}\n\t\tif(!forAnonInitiator) {\n\t\t\t// Short-lived connections don't need ARK and don't need negTypes either.\n\t\t\tfs.put(\"auth.negTypes\", negTypes);\n\t\t\tif(!forSetup) {\n\t\t\t\tfs.put(\"ark.number\", myARKNumber); // Can be changed on setup\n\t\t\t\tfs.putSingle(\"ark.pubURI\", myARK.getURI().toString(false, false)); // Can be changed on setup\n\t\t\t}\n\t\t}\n\t\treturn fs;\n\t}","commit_id":"503071262e58587aba361f88d55e6d852519624d","url":"https://github.com/freenet/fred"},{"original_method":"void addPrivateFields(SimpleFieldSet fs) {\n\t    // Let's not add it twice\n\t    fs.removeSubset(\"ecdsa\");\n\t    fs.put(\"ecdsa\", ecdsaP256.asFieldSet(true));\n\t    \n\t\tfs.put(\"dsaPrivKey\", privKey.asFieldSet());\n\t\tfs.putSingle(\"ark.privURI\", myARK.getInsertURI().toString(false, false));\n\t\tfs.putSingle(\"clientNonce\", Base64.encode(clientNonce));\n\n\t}","id":14039,"modified_method":"void addPrivateFields(SimpleFieldSet fs) {\n\t    // Let's not add it twice\n\t    fs.removeSubset(\"ecdsa\");\n\t    fs.put(\"ecdsa\", ecdsaP256.asFieldSet(true));\n\n\t\tif(privKey != null)\n\t\t\tfs.put(\"dsaPrivKey\", privKey.asFieldSet());\n\t\tfs.putSingle(\"ark.privURI\", myARK.getInsertURI().toString(false, false));\n\t\tfs.putSingle(\"clientNonce\", Base64.encode(clientNonce));\n\n\t}","commit_id":"503071262e58587aba361f88d55e6d852519624d","url":"https://github.com/freenet/fred"},{"original_method":"/**\n\t * Read the cryptographic keys etc from a SimpleFieldSet\n\t * @param fs\n\t * @throws IOException\n\t */\n\tpublic void readCrypto(SimpleFieldSet fs) throws IOException {\n\t\tString identity = fs.get(\"identity\");\n\t\tif(identity == null)\n\t\t\tthrow new IOException();\n\t\ttry {\n\t\t\tmyIdentity = Base64.decode(identity);\n\t\t} catch (IllegalBase64Exception e2) {\n\t\t\tthrow new IOException();\n\t\t}\n\t\tidentityHash = SHA256.digest(myIdentity);\n\t\tanonSetupCipher.initialize(identityHash);\n\t\tidentityHashHash = SHA256.digest(identityHash);\n\n\t\tSimpleFieldSet ecdsaSFS = null;\n\t\ttry {\n\t\t\tcryptoGroup = DSAGroup.create(fs.subset(\"dsaGroup\"));\n\t\t\tprivKey = DSAPrivateKey.create(fs.subset(\"dsaPrivKey\"), cryptoGroup);\n\t\t\tpubKey = DSAPublicKey.create(fs.subset(\"dsaPubKey\"), cryptoGroup);\n\t\t\t\n\t\t\tecdsaSFS = fs.subset(\"ecdsa\");\n\t\t\tif(ecdsaSFS != null) {\n\t\t\t    ecdsaP256 = new ECDSA(ecdsaSFS.subset(ECDSA.Curves.P256.name()), Curves.P256);\n\t\t    }\n\t\t} catch (IllegalBase64Exception e) {\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t} catch (FSParseException e) {\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t} catch (IllegalArgumentException e) {\n\t\t\t// DSAPrivateKey is invalid\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t}\n\t\t\n\t\tif(ecdsaP256 == null) {\n\t\t    // We don't have a keypair, generate one.\n\t\t    Logger.normal(this, \"No ecdsa.P256 field found in noderef: let's generate a new key\");\n\t\t    ecdsaP256 = new ECDSA(Curves.P256);\n\t\t}\n        \tecdsaPubKeyHash = SHA256.digest(ecdsaP256.getPublicKey().getEncoded());\n\t\t\n\t\tInsertableClientSSK ark = null;\n\n\t\t// ARK\n\n\t\tString s = fs.get(\"ark.number\");\n\n\t\tString privARK = fs.get(\"ark.privURI\");\n\t\ttry {\n\t\t\tif(privARK != null) {\n\t\t\t\tFreenetURI uri = new FreenetURI(privARK);\n\t\t\t\tark = InsertableClientSSK.create(uri);\n\t\t\t\tif(s == null) {\n\t\t\t\t\tark = null;\n\t\t\t\t\tmyARKNumber = 0;\n\t\t\t\t} else {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tmyARKNumber = Long.parseLong(s);\n\t\t\t\t\t} catch (NumberFormatException e) {\n\t\t\t\t\t\tmyARKNumber = 0;\n\t\t\t\t\t\tark = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (MalformedURLException e) {\n\t\t\tLogger.minor(this, \"Caught \"+e, e);\n\t\t\tark = null;\n\t\t}\n\t\tif(ark == null) {\n\t\t\tark = InsertableClientSSK.createRandom(random, \"ark\");\n\t\t\tmyARKNumber = 0;\n\t\t}\n\t\tmyARK = ark;\n\n\t\tString cn = fs.get(\"clientNonce\");\n\t\tif(cn != null) {\n\t\t\ttry {\n\t\t\t\tclientNonce = Base64.decode(cn);\n\t\t\t} catch (IllegalBase64Exception e) {\n\t\t\t\tthrow new IOException(\"Invalid clientNonce field: \"+e);\n\t\t\t}\n\t\t} else {\n\t\t\tclientNonce = new byte[32];\n\t\t\tnode.random.nextBytes(clientNonce);\n\t\t}\n\n\t}","id":14040,"modified_method":"/**\n\t * Read the cryptographic keys etc from a SimpleFieldSet\n\t * @param fs\n\t * @throws IOException\n\t */\n\tpublic void readCrypto(SimpleFieldSet fs) throws IOException {\n\t\tString identity = fs.get(\"identity\");\n\t\tif(identity == null)\n\t\t\tthrow new IOException();\n\t\ttry {\n\t\t\tmyIdentity = Base64.decode(identity);\n\t\t} catch (IllegalBase64Exception e2) {\n\t\t\tthrow new IOException();\n\t\t}\n\t\tidentityHash = SHA256.digest(myIdentity);\n\t\tanonSetupCipher.initialize(identityHash);\n\t\tidentityHashHash = SHA256.digest(identityHash);\n\n\t\tSimpleFieldSet ecdsaSFS = null;\n\t\tSimpleFieldSet dsaSFS = null;\n\t\ttry {\n\n\t\t\tecdsaSFS = fs.subset(\"ecdsa\");\n\t\t\tif(ecdsaSFS != null)\n\t\t\t\tecdsaP256 = new ECDSA(ecdsaSFS.subset(ECDSA.Curves.P256.name()), Curves.P256);\n\n\t\t\t//TODO: remove this once 1471 is mandatory\n\t\t\tdsaSFS = fs.subset(\"dsaGroup\");\n\t\t\tif(dsaSFS != null && dsaSFS.toString().length() > 30)\n\t\t\t\tcryptoGroup = DSAGroup.create(dsaSFS);\n\t\t\tdsaSFS = fs.subset(\"dsaPrivKey\");\n\t\t\tif(dsaSFS != null && dsaSFS.toString().length() > 30)\n\t\t\t\tprivKey = DSAPrivateKey.create(dsaSFS, cryptoGroup);\n\t\t\tdsaSFS = fs.subset(\"dsaPubKey\");\n\t\t\tif(dsaSFS != null && dsaSFS.toString().length() > 30)\n\t\t\t\tpubKey = DSAPublicKey.create(dsaSFS, cryptoGroup);\n\t\t} catch (IllegalBase64Exception e) {\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t} catch (FSParseException e) {\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t} catch (IllegalArgumentException e) {\n\t\t\t// DSAPrivateKey is invalid\n\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\tthrow new IOException(e.toString());\n\t\t}\n\t\t\n\t\tif(ecdsaP256 == null) {\n\t\t    // We don't have a keypair, generate one.\n\t\t    Logger.normal(this, \"No ecdsa.P256 field found in noderef: let's generate a new key\");\n\t\t    ecdsaP256 = new ECDSA(Curves.P256);\n\t\t}\n        \tecdsaPubKeyHash = SHA256.digest(ecdsaP256.getPublicKey().getEncoded());\n\t\t\n\t\tInsertableClientSSK ark = null;\n\n\t\t// ARK\n\n\t\tString s = fs.get(\"ark.number\");\n\n\t\tString privARK = fs.get(\"ark.privURI\");\n\t\ttry {\n\t\t\tif(privARK != null) {\n\t\t\t\tFreenetURI uri = new FreenetURI(privARK);\n\t\t\t\tark = InsertableClientSSK.create(uri);\n\t\t\t\tif(s == null) {\n\t\t\t\t\tark = null;\n\t\t\t\t\tmyARKNumber = 0;\n\t\t\t\t} else {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tmyARKNumber = Long.parseLong(s);\n\t\t\t\t\t} catch (NumberFormatException e) {\n\t\t\t\t\t\tmyARKNumber = 0;\n\t\t\t\t\t\tark = null;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (MalformedURLException e) {\n\t\t\tLogger.minor(this, \"Caught \"+e, e);\n\t\t\tark = null;\n\t\t}\n\t\tif(ark == null) {\n\t\t\tark = InsertableClientSSK.createRandom(random, \"ark\");\n\t\t\tmyARKNumber = 0;\n\t\t}\n\t\tmyARK = ark;\n\n\t\tString cn = fs.get(\"clientNonce\");\n\t\tif(cn != null) {\n\t\t\ttry {\n\t\t\t\tclientNonce = Base64.decode(cn);\n\t\t\t} catch (IllegalBase64Exception e) {\n\t\t\t\tthrow new IOException(\"Invalid clientNonce field: \"+e);\n\t\t\t}\n\t\t} else {\n\t\t\tclientNonce = new byte[32];\n\t\t\tnode.random.nextBytes(clientNonce);\n\t\t}\n\n\t}","commit_id":"503071262e58587aba361f88d55e6d852519624d","url":"https://github.com/freenet/fred"},{"original_method":"/**\n\t * Create the cryptographic keys etc from scratch\n\t */\n\tpublic void initCrypto() {\n\t\tecdsaP256 = new ECDSA(ECDSA.Curves.P256);\n\t\tecdsaPubKeyHash = SHA256.digest(ecdsaP256.getPublicKey().getEncoded());\n\t\tcryptoGroup = Global.DSAgroupBigA;\n\t\tprivKey = new DSAPrivateKey(cryptoGroup, random);\n\t\tpubKey = new DSAPublicKey(cryptoGroup, privKey);\n\t\tmyARK = InsertableClientSSK.createRandom(random, \"ark\");\n\t\tmyARKNumber = 0;\n\t\tclientNonce = new byte[32];\n\t\tnode.random.nextBytes(clientNonce);\n\t\tmyIdentity = Arrays.copyOf(ecdsaPubKeyHash, IDENTITY_LENGTH);\n\t\tidentityHash = SHA256.digest(myIdentity);\n\t\tidentityHashHash = SHA256.digest(identityHash);\n\t\tanonSetupCipher.initialize(identityHash);\n\t}","id":14041,"modified_method":"/**\n\t * Create the cryptographic keys etc from scratch\n\t */\n\tpublic void initCrypto() {\n\t\tecdsaP256 = new ECDSA(ECDSA.Curves.P256);\n\t\tecdsaPubKeyHash = SHA256.digest(ecdsaP256.getPublicKey().getEncoded());\n\t\tmyARK = InsertableClientSSK.createRandom(random, \"ark\");\n\t\tmyARKNumber = 0;\n\t\tclientNonce = new byte[32];\n\t\tnode.random.nextBytes(clientNonce);\n\t\tmyIdentity = Arrays.copyOf(ecdsaPubKeyHash, IDENTITY_LENGTH);\n\t\tidentityHash = SHA256.digest(myIdentity);\n\t\tidentityHashHash = SHA256.digest(identityHash);\n\t\tanonSetupCipher.initialize(identityHash);\n\t}","commit_id":"503071262e58587aba361f88d55e6d852519624d","url":"https://github.com/freenet/fred"},{"original_method":"private byte[] myCompressedRef(boolean setup, boolean heavySetup, boolean forARK) {\n\t\tSimpleFieldSet fs = exportPublicFieldSet(setup, heavySetup, forARK);\n\t\tboolean shouldStripGroup = heavySetup && Global.DSAgroupBigA.equals(cryptoGroup);\n\t\tif(shouldStripGroup)\n\t\t\tfs.removeSubset(\"dsaGroup\");\n\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n\t\tDeflaterOutputStream gis;\n\t\tgis = new DeflaterOutputStream(baos);\n\t\ttry {\n\t\t\tfs.writeTo(gis);\n                } catch (IOException e) {\n                    Logger.error(this, \"IOE :\"+e.getMessage(), e);\n\t\t} finally {\n\t\t\tCloser.close(gis);\n                        Closer.close(baos);\n\t\t}\n\n\t\tbyte[] buf = baos.toByteArray();\n\t\tif(buf.length >= 4096)\n\t\t\tthrow new IllegalStateException(\"We are attempting to send a \"+buf.length+\" bytes big reference!\");\n\t\tbyte[] obuf = new byte[buf.length + 1 + (shouldStripGroup ? 1 : 0)];\n\t\tint offset = 0;\n\t\tif(shouldStripGroup) {\n\t\t\tobuf[offset++] = 0x3; // compressed noderef - group\n\t\t\tint dsaGroupIndex = Global.GROUP_INDEX_BIG_A;\n\t\t\tif(logMINOR)\n\t\t\t\tLogger.minor(this, \"We are stripping the group from the reference as it's a known group (groupIndex=\"+dsaGroupIndex+')');\n\t\t\tobuf[offset++] = (byte)(dsaGroupIndex & 0xff);\n\t\t} else\n\t\t\tobuf[offset++] = 0x01; // compressed noderef\n\t\tSystem.arraycopy(buf, 0, obuf, offset, buf.length);\n\t\tif(logMINOR)\n\t\t\tLogger.minor(this, \"myCompressedRef(\"+setup+\",\"+heavySetup+\") returning \"+obuf.length+\" bytes\");\n\t\treturn obuf;\n\t}","id":14042,"modified_method":"private byte[] myCompressedRef(boolean setup, boolean heavySetup, boolean forARK) {\n\t\tSimpleFieldSet fs = exportPublicFieldSet(setup, heavySetup, forARK);\n\t\tboolean shouldStripGroup = heavySetup;\n\t\tif(shouldStripGroup)\n\t\t\tfs.removeSubset(\"dsaGroup\");\n\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n\t\tDeflaterOutputStream gis;\n\t\tgis = new DeflaterOutputStream(baos);\n\t\ttry {\n\t\t\tfs.writeTo(gis);\n                } catch (IOException e) {\n                    Logger.error(this, \"IOE :\"+e.getMessage(), e);\n\t\t} finally {\n\t\t\tCloser.close(gis);\n                        Closer.close(baos);\n\t\t}\n\n\t\tbyte[] buf = baos.toByteArray();\n\t\tif(buf.length >= 4096)\n\t\t\tthrow new IllegalStateException(\"We are attempting to send a \"+buf.length+\" bytes big reference!\");\n\t\tbyte[] obuf = new byte[buf.length + 1 + (shouldStripGroup ? 1 : 0)];\n\t\tint offset = 0;\n\t\tif(shouldStripGroup) {\n\t\t\tobuf[offset++] = 0x3; // compressed noderef - group\n\t\t\tint dsaGroupIndex = Global.GROUP_INDEX_BIG_A;\n\t\t\tif(logMINOR)\n\t\t\t\tLogger.minor(this, \"We are stripping the group from the reference as it's a known group (groupIndex=\"+dsaGroupIndex+')');\n\t\t\tobuf[offset++] = (byte)(dsaGroupIndex & 0xff);\n\t\t} else\n\t\t\tobuf[offset++] = 0x01; // compressed noderef\n\t\tSystem.arraycopy(buf, 0, obuf, offset, buf.length);\n\t\tif(logMINOR)\n\t\t\tLogger.minor(this, \"myCompressedRef(\"+setup+\",\"+heavySetup+\") returning \"+obuf.length+\" bytes\");\n\t\treturn obuf;\n\t}","commit_id":"503071262e58587aba361f88d55e6d852519624d","url":"https://github.com/freenet/fred"},{"original_method":"public Collection<V> values() {\n        ValuesRequest request = new ValuesRequest(name);\n        PortableCollection result = invoke(request);\n        return toObjectCollection(result);\n    }","id":14043,"modified_method":"public Collection<V> values() {\n        ClientMessage request = MultiMapValuesParameters.encode(name);\n        ClientMessage response = invoke(request);\n        DataCollectionResultParameters resultParameters = DataCollectionResultParameters.decode(response);\n        Collection<Data> result = resultParameters.result;\n        Collection<V> resultCollection = new ArrayList<V>(result.size());\n        for (Data data : result) {\n            final V value = toObject(data);\n            resultCollection.add(value);\n        }\n        return resultCollection;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean containsEntry(K key, V value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        ClientRequest request = new KeyBasedContainsRequest(name, keyData, valueData, ThreadUtil.getThreadId());\n        Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14044,"modified_method":"public boolean containsEntry(K key, V value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        ClientMessage request = MultiMapContainsEntryParameters.encode(name, keyData, valueData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void lock(K key, long leaseTime, TimeUnit timeUnit) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        shouldBePositive(leaseTime, \"leaseTime\");\n        final Data keyData = toData(key);\n        MultiMapLockRequest request = new MultiMapLockRequest(keyData, ThreadUtil.getThreadId(),\n                getTimeInMillis(leaseTime, timeUnit), -1, name);\n        invoke(request, keyData);\n    }","id":14045,"modified_method":"public void lock(K key, long leaseTime, TimeUnit timeUnit) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        shouldBePositive(leaseTime, \"leaseTime\");\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapLockWithLeaseTimeParameters.encode(name, keyData, ThreadUtil.getThreadId(), getTimeInMillis(leaseTime, timeUnit));\n        invoke(request, keyData);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void clear() {\n        ClearRequest request = new ClearRequest(name);\n        invoke(request);\n    }","id":14046,"modified_method":"public void clear() {\n        ClientMessage request = MultiMapClearParameters.encode(name);\n        invoke(request);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public Set<Map.Entry<K, V>> entrySet() {\n        EntrySetRequest request = new EntrySetRequest(name);\n        PortableEntrySetResponse result = invoke(request);\n        Set<Map.Entry> dataEntrySet = result.getEntrySet();\n        Set<Map.Entry<K, V>> entrySet = new HashSet<Map.Entry<K, V>>(dataEntrySet.size());\n        for (Map.Entry entry : dataEntrySet) {\n            Object key = toObject((Data) entry.getKey());\n            Object val = toObject((Data) entry.getValue());\n            entrySet.add(new AbstractMap.SimpleEntry(key, val));\n        }\n        return entrySet;\n    }","id":14047,"modified_method":"public Set<Map.Entry<K, V>> entrySet() {\n        ClientMessage request = MultiMapEntrySetParameters.encode(name);\n        ClientMessage response = invoke(request);\n        DataEntryListResultParameters resultParameters = DataEntryListResultParameters.decode(response);\n        Set<Map.Entry<K, V>> entrySet = new HashSet<Map.Entry<K, V>>();\n        int size = resultParameters.keys.size();\n\n        for (int i = 0; i < size; i++) {\n            Data keyData = resultParameters.keys.get(i);\n            Data valueData = resultParameters.values.get(i);\n            K key = toObject(keyData);\n            V value = toObject(valueData);\n\n            entrySet.add(new AbstractMap.SimpleEntry<K, V>(key, value));\n        }\n        return entrySet;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public int size() {\n        SizeRequest request = new SizeRequest(name);\n        Integer result = invoke(request);\n        return result;\n    }","id":14048,"modified_method":"public int size() {\n        ClientMessage request = MultiMapSizeParameters.encode(name);\n        ClientMessage response = invoke(request);\n        IntResultParameters resultParameters = IntResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public int valueCount(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        CountRequest request = new CountRequest(name, keyData, ThreadUtil.getThreadId());\n        Integer result = invoke(request, keyData);\n        return result;\n    }","id":14049,"modified_method":"public int valueCount(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        ClientMessage request = MultiMapValueCountParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        IntResultParameters resultParameters = IntResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean containsKey(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        ClientRequest request = new KeyBasedContainsRequest(name, keyData, null, ThreadUtil.getThreadId());\n        Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14050,"modified_method":"public boolean containsKey(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        ClientMessage request = MultiMapContainsKeyParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean put(K key, V value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        PutRequest request = new PutRequest(name, keyData, valueData, -1, ThreadUtil.getThreadId());\n        Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14051,"modified_method":"public boolean put(K key, V value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        ClientMessage request = MultiMapPutParameters.encode(name, keyData, valueData, ThreadUtil.getThreadId(), -1);\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean removeEntryListener(String registrationId) {\n        final RemoveEntryListenerRequest request = new RemoveEntryListenerRequest(name, registrationId);\n        return stopListening(request, registrationId);\n    }","id":14052,"modified_method":"public boolean removeEntryListener(String registrationId) {\n        ClientMessage request = MultiMapRemoveEntryListenerParameters.encode(name, registrationId);\n        return stopListening(request, registrationId);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public Collection<V> get(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        GetAllRequest request = new GetAllRequest(name, keyData, ThreadUtil.getThreadId());\n        PortableCollection result = invoke(request, keyData);\n        return toObjectCollection(result);\n    }","id":14053,"modified_method":"public Collection<V> get(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        ClientMessage request = MultiMapGetParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        DataCollectionResultParameters resultParameters = DataCollectionResultParameters.decode(response);\n        Collection<Data> result = resultParameters.result;\n        Collection<V> resultCollection = new ArrayList<V>(result.size());\n        for (Data data : result) {\n            final V value = toObject(data);\n            resultCollection.add(value);\n        }\n        return resultCollection;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public Collection<V> remove(Object key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        RemoveAllRequest request = new RemoveAllRequest(name, keyData, ThreadUtil.getThreadId());\n        PortableCollection result = invoke(request, keyData);\n        return toObjectCollection(result);\n    }","id":14054,"modified_method":"public Collection<V> remove(Object key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        ClientMessage request = MultiMapRemoveParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        DataCollectionResultParameters resultParameters = DataCollectionResultParameters.decode(response);\n        Collection<Data> result = resultParameters.result;\n        Collection<V> resultCollection = new ArrayList<V>(result.size());\n        for (Data data : result) {\n            final V value = toObject(data);\n            resultCollection.add(value);\n        }\n        return resultCollection;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean tryLock(K key, long time, TimeUnit timeunit) throws InterruptedException {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        MultiMapLockRequest request = new MultiMapLockRequest(keyData, ThreadUtil.getThreadId(),\n                Long.MAX_VALUE, getTimeInMillis(time, timeunit), name);\n        Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14055,"modified_method":"public boolean tryLock(K key, long time, TimeUnit timeunit) throws InterruptedException {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapTryLockParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean remove(Object key, Object value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        RemoveRequest request = new RemoveRequest(name, keyData, valueData, ThreadUtil.getThreadId());\n        Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14056,"modified_method":"public boolean remove(Object key, Object value) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyData = toData(key);\n        Data valueData = toData(value);\n        ClientMessage request = MultiMapRemoveEntryParameters.encode(name, keyData, valueData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void lock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        MultiMapLockRequest request = new MultiMapLockRequest(keyData, ThreadUtil.getThreadId(), name);\n        invoke(request, keyData);\n    }","id":14057,"modified_method":"public void lock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapLockParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        invoke(request, keyData);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void unlock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        MultiMapUnlockRequest request = new MultiMapUnlockRequest(keyData, ThreadUtil.getThreadId(), name);\n        invoke(request, keyData);\n    }","id":14058,"modified_method":"public void unlock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapUnlockParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        invoke(request, keyData);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean isLocked(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        final MultiMapIsLockedRequest request = new MultiMapIsLockedRequest(keyData, name);\n        final Boolean result = invoke(request, keyData);\n        return result;\n    }","id":14059,"modified_method":"public boolean isLocked(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapIsLockedParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        ClientMessage response = invoke(request, keyData);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void forceUnlock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        MultiMapUnlockRequest request = new MultiMapUnlockRequest(keyData, ThreadUtil.getThreadId(), true, name);\n        invoke(request, keyData);\n    }","id":14060,"modified_method":"public void forceUnlock(K key) {\n        checkNotNull(key, NULL_KEY_IS_NOT_ALLOWED);\n\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapForceUnlockParameters.encode(name, keyData, ThreadUtil.getThreadId());\n        invoke(request, keyData);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public Set<K> keySet() {\n        KeySetRequest request = new KeySetRequest(name);\n        PortableCollection result = invoke(request);\n        return (Set) toObjectCollection(result);\n    }","id":14061,"modified_method":"public Set<K> keySet() {\n        ClientMessage request = MultiMapKeySetParameters.encode(name);\n        ClientMessage response = invoke(request);\n        DataCollectionResultParameters resultParameters = DataCollectionResultParameters.decode(response);\n        Collection<Data> result = resultParameters.result;\n        Set<K> keySet = new HashSet<K>(result.size());\n        for (Data data : result) {\n            final K key = toObject(data);\n            keySet.add(key);\n        }\n        return keySet;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public String addEntryListener(EntryListener<K, V> listener, K key, boolean includeValue) {\n        final Data keyData = toData(key);\n        AddEntryListenerRequest request = new AddEntryListenerRequest(name, keyData, includeValue);\n        EventHandler<PortableEntryEvent> handler = createHandler(listener, includeValue);\n        return listen(request, keyData, handler);\n    }","id":14062,"modified_method":"public String addEntryListener(EntryListener<K, V> listener, K key, boolean includeValue) {\n        final Data keyData = toData(key);\n        ClientMessage request = MultiMapAddEntryListenerToKeyParameters.encode(name, keyData, includeValue);\n\n        EventHandler<ClientMessage> handler = createHandler(listener, includeValue);\n        return listen(request, keyData, handler);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public String addEntryListener(EntryListener<K, V> listener, boolean includeValue) {\n        isNotNull(listener, \"listener\");\n        AddEntryListenerRequest request = new AddEntryListenerRequest(name, null, includeValue);\n        EventHandler<PortableEntryEvent> handler = createHandler(listener, includeValue);\n        return listen(request, handler);\n    }","id":14063,"modified_method":"public String addEntryListener(EntryListener<K, V> listener, boolean includeValue) {\n        isNotNull(listener, \"listener\");\n        ClientMessage request = MultiMapAddEntryListenerParameters.encode(name, includeValue);\n\n        EventHandler<ClientMessage> handler = createHandler(listener, includeValue);\n        return listen(request, handler);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean containsValue(Object value) {\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data valueData = toData(value);\n        ClientRequest request = new ContainsRequest(name, valueData);\n        Boolean result = invoke(request);\n        return result;\n    }","id":14064,"modified_method":"public boolean containsValue(Object value) {\n        checkNotNull(value, NULL_VALUE_IS_NOT_ALLOWED);\n\n        Data keyValue = toData(value);\n        ClientMessage request = MultiMapContainsValueParameters.encode(name, keyValue);\n        ClientMessage response = invoke(request);\n        BooleanResultParameters resultParameters = BooleanResultParameters.decode(response);\n        return resultParameters.result;\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"protected final boolean stopListening(BaseClientRemoveListenerRequest clientMessageuest, String registrationId) {\n        return context.getListenerService().stopListening(clientMessageuest, registrationId);\n    }","id":14065,"modified_method":"protected final boolean stopListening(ClientMessage clientMessageuest, String registrationId) {\n        return context.getListenerService().stopListening(clientMessageuest, registrationId);\n    }","commit_id":"2f7a81016c05f0bb63c52e3a2e054faa328504b6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public void handleDelete()\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\n            if (documentInfo == null) {\n                /* Should not happen since we requested not to fail if the document doesn't exist */\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n\n            }\n\n            Document doc = documentInfo.getDocument();\n            /* If the doc is null we don't have the rights to access it. */\n            if (doc == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return;\n            }\n\n            /* If the doc is locked then return */\n            if (doc.getLocked()) {\n                getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\n                return;\n            }\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n\n            com.xpn.xwiki.api.Attachment xwikiAttachment = doc.getAttachment(attachmentName);\n            if (xwikiAttachment == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return;\n            }\n\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n            XWikiAttachment baseXWikiAttachment = xwikiDocument.getAttachment(attachmentName);\n            if (doc.hasAccessLevel(\"edit\", xwikiUser)) {\n                xwikiDocument.deleteAttachment(baseXWikiAttachment, xwikiContext);\n                getResponse().setStatus(Status.SUCCESS_NO_CONTENT);\n            } else {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            }\n        } catch (Exception e) {\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n    }","id":14066,"modified_method":"@Override\n    public void handleDelete()\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, true);\n            if (documentInfo == null) {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n\n            com.xpn.xwiki.api.Attachment xwikiAttachment = doc.getAttachment(attachmentName);\n            if (xwikiAttachment == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return;\n            }\n\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n            XWikiAttachment baseXWikiAttachment = xwikiDocument.getAttachment(attachmentName);\n            if (doc.hasAccessLevel(\"edit\", xwikiUser)) {\n                xwikiDocument.deleteAttachment(baseXWikiAttachment, xwikiContext);\n                getResponse().setStatus(Status.SUCCESS_NO_CONTENT);\n            } else {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            }\n        } catch (Exception e) {\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\n            if (documentInfo == null) {\n                /* If the document doesn't exist send a not found header */\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            /* Check if we have access to it */\n            if (doc == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return null;\n            }\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n\n            final com.xpn.xwiki.api.Attachment xwikiAttachment = doc.getAttachment(attachmentName);\n            if (xwikiAttachment == null) {\n                /* If the attachment doesn't exist send a not found header */\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            return new OutputRepresentation(MediaType.valueOf(xwikiAttachment.getMimeType()))\n            {\n                @Override\n                public void write(OutputStream outputStream) throws IOException\n                {\n                    /* TODO: Maybe we should write the content N bytes at a time */\n                    try {\n                        outputStream.write(xwikiAttachment.getContent());\n                    } catch (XWikiException e) {\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                    } finally {\n                        outputStream.close();\n                    }\n                }\n            };\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","id":14067,"modified_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\n            if (documentInfo == null) {\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n\n            final com.xpn.xwiki.api.Attachment xwikiAttachment = doc.getAttachment(attachmentName);\n            if (xwikiAttachment == null) {\n                /* If the attachment doesn't exist send a not found header */\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            return new OutputRepresentation(MediaType.valueOf(xwikiAttachment.getMimeType()))\n            {\n                @Override\n                public void write(OutputStream outputStream) throws IOException\n                {\n                    /* TODO: Maybe we should write the content N bytes at a time */\n                    try {\n                        outputStream.write(xwikiAttachment.getContent());\n                    } catch (XWikiException e) {\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                    } finally {\n                        outputStream.close();\n                    }\n                }\n            };\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public void handlePut()\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\n            if (documentInfo == null) {\n                /* Should not happen since we requested not to fail if the document doesn't exist */\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n\n            }\n\n            Document doc = documentInfo.getDocument();\n            /* If the doc is null we don't have the rights to access it. */\n            if (doc == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return;\n            }\n\n            /* If the doc is locked then return */\n            if (doc.getLocked()) {\n                getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\n                return;\n            }\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n            boolean existed = false;\n\n            if (doc.getAttachment(attachmentName) != null) {\n                existed = true;\n            }\n\n            doc.addAttachment(attachmentName, getRequest().getEntity().getStream());\n\n            doc.save();\n\n            if (existed) {\n                getResponse().setStatus(Status.SUCCESS_ACCEPTED);\n            } else {\n                getResponse().setStatus(Status.SUCCESS_CREATED);\n            }\n\n            /*\n             * We need to retrieve the base XWiki documents because Document doesn't have a method for retrieving the\n             * external URL for an attachment\n             */\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n            String attachmentXWikiUrl =\n                xwikiDocument.getExternalAttachmentURL(attachmentName, \"download\", xwikiContext).toString();\n\n            getResponse().setEntity(\n                new StringRepresentation(Utils.toXml(DomainObjectFactory.createAttachment(getRequest(),\n                    resourceClassRegistry, doc.getAttachment(attachmentName), attachmentXWikiUrl))));\n\n        } catch (XWikiException e) {\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            } else {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n    }","id":14068,"modified_method":"@Override\n    public void handlePut()\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), false, true);\n            if (documentInfo == null) {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            String attachmentName = (String) getRequest().getAttributes().get(Constants.ATTACHMENT_NAME_PARAMETER);\n            boolean existed = false;\n\n            if (doc.getAttachment(attachmentName) != null) {\n                existed = true;\n            }\n\n            doc.addAttachment(attachmentName, getRequest().getEntity().getStream());\n\n            doc.save();\n\n            if (existed) {\n                getResponse().setStatus(Status.SUCCESS_ACCEPTED);\n            } else {\n                getResponse().setStatus(Status.SUCCESS_CREATED);\n            }\n\n            /*\n             * We need to retrieve the base XWiki documents because Document doesn't have a method for retrieving the\n             * external URL for an attachment\n             */\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n            String attachmentXWikiUrl =\n                xwikiDocument.getExternalAttachmentURL(attachmentName, \"download\", xwikiContext).toString();\n\n            getResponse().setEntity(\n                new StringRepresentation(Utils.toXml(DomainObjectFactory.createAttachment(getRequest(),\n                    resourceClassRegistry, doc.getAttachment(attachmentName), attachmentXWikiUrl))));\n\n        } catch (XWikiException e) {\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            } else {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\n            if (documentInfo == null) {\n                /* If the document doesn't exist send a not found header */\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            /* Check if we have access to it */\n            if (doc == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return null;\n            }\n\n            List<com.xpn.xwiki.api.Attachment> xwikiAttachments = doc.getAttachmentList();\n\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\n            RangeIterable<com.xpn.xwiki.api.Attachment> ri =\n                new RangeIterable<com.xpn.xwiki.api.Attachment>(xwikiAttachments, Utils.parseInt(queryForm\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\n\n            /*\n             * We need to retrieve the base XWiki documents because Document doesn't have a method for retrieving the\n             * external URL for an attachment\n             */\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n\n            Attachments attachments = new Attachments();\n\n            for (com.xpn.xwiki.api.Attachment xwikiAttachment : ri) {\n                String attachmentXWikiUrl =\n                    xwikiDocument.getExternalAttachmentURL(xwikiAttachment.getFilename(), \"download\", xwikiContext)\n                        .toString();\n\n                attachments.addAttachment(DomainObjectFactory.createAttachment(getRequest(), resourceClassRegistry,\n                    xwikiAttachment, attachmentXWikiUrl));\n            }\n\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), attachments);\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","id":14069,"modified_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\n            if (documentInfo == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            List<com.xpn.xwiki.api.Attachment> xwikiAttachments = doc.getAttachmentList();\n\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\n            RangeIterable<com.xpn.xwiki.api.Attachment> ri =\n                new RangeIterable<com.xpn.xwiki.api.Attachment>(xwikiAttachments, Utils.parseInt(queryForm\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\n\n            /*\n             * We need to retrieve the base XWiki documents because Document doesn't have a method for retrieving the\n             * external URL for an attachment\n             */\n            XWikiDocument xwikiDocument = xwiki.getDocument(doc.getPrefixedFullName(), xwikiContext);\n\n            Attachments attachments = new Attachments();\n\n            for (com.xpn.xwiki.api.Attachment xwikiAttachment : ri) {\n                String attachmentXWikiUrl =\n                    xwikiDocument.getExternalAttachmentURL(xwikiAttachment.getFilename(), \"download\", xwikiContext)\n                        .toString();\n\n                attachments.addAttachment(DomainObjectFactory.createAttachment(getRequest(), resourceClassRegistry,\n                    xwikiAttachment, attachmentXWikiUrl));\n            }\n\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), attachments);\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            String commentIdString = (String) getRequest().getAttributes().get(Constants.COMMENT_ID_PARAMETER);\n            int commentId;\n\n            try {\n                commentId = Integer.parseInt(commentIdString);\n            } catch (NumberFormatException e) {\n                getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n                return null;\n            }\n\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\n            if (documentInfo == null) {\n                /* If the document doesn't exist send a not found header */\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            /* Check if we have access to it */\n            if (doc == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return null;\n            }\n\n            Comment comment = null;\n\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\n            for (com.xpn.xwiki.api.Object xwikiComment : xwikiComments) {\n                if (xwikiComment.getNumber() == commentId) {\n                    comment =\n                        DomainObjectFactory\n                            .createComment(getRequest(), resourceClassRegistry, doc, xwikiComment, false);\n                    break;\n                }\n            }\n\n            if (comment == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comment);\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","id":14070,"modified_method":"@Override\n    public Representation represent(Variant variant)\n    {\n        try {\n            String commentIdString = (String) getRequest().getAttributes().get(Constants.COMMENT_ID_PARAMETER);\n            int commentId;\n\n            try {\n                commentId = Integer.parseInt(commentIdString);\n            } catch (NumberFormatException e) {\n                getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n                return null;\n            }\n\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\n            if (documentInfo == null) {\n                return null;\n            }\n\n            Document doc = documentInfo.getDocument();\n\n            Comment comment = null;\n\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\n            for (com.xpn.xwiki.api.Object xwikiComment : xwikiComments) {\n                if (xwikiComment.getNumber() == commentId) {\n                    comment =\n                        DomainObjectFactory\n                            .createComment(getRequest(), resourceClassRegistry, doc, xwikiComment, false);\n                    break;\n                }\n            }\n\n            if (comment == null) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                return null;\n            }\n\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comment);\n        } catch (Exception e) {\n            e.printStackTrace();\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n        }\n\n        return null;\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            String commentIdString = (String) getRequest().getAttributes().get(Constants.COMMENT_ID_PARAMETER);\r\n            int commentId;\r\n\r\n            try {\r\n                commentId = Integer.parseInt(commentIdString);\r\n            } catch (NumberFormatException e) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\r\n                return null;\r\n            }\r\n\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n            if (documentInfo == null) {\r\n                /* If the document doesn't exist send a not found header */\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            /* Check if we have access to it */\r\n            if (doc == null) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                return null;\r\n            }\r\n\r\n            Comment comment = null;\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n            for (com.xpn.xwiki.api.Object xwikiComment : xwikiComments) {\r\n                if (xwikiComment.getNumber() == commentId) {\r\n                    comment =\r\n                        DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc, xwikiComment, true);\r\n                    break;\r\n                }\r\n            }\r\n\r\n            if (comment == null) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n                return null;\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comment);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","id":14071,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            String commentIdString = (String) getRequest().getAttributes().get(Constants.COMMENT_ID_PARAMETER);\r\n            int commentId;\r\n\r\n            try {\r\n                commentId = Integer.parseInt(commentIdString);\r\n            } catch (NumberFormatException e) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\r\n                return null;\r\n            }\r\n\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n            if (documentInfo == null) {\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            Comment comment = null;\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n            for (com.xpn.xwiki.api.Object xwikiComment : xwikiComments) {\r\n                if (xwikiComment.getNumber() == commentId) {\r\n                    comment =\r\n                        DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc, xwikiComment, true);\r\n                    break;\r\n                }\r\n            }\r\n\r\n            if (comment == null) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n                return null;\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comment);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public void handlePost()\r\n    {\r\n        MediaType mediaType = getRequest().getEntity().getMediaType();\r\n\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\r\n        if (documentInfo == null) {\r\n            /* Should not happen since we requested not to fail if the document doesn't exist */\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return;\r\n\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n        /* If the doc is null we don't have the rights to access it. */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return;\r\n        }\r\n\r\n        /* If the doc is locked then return */\r\n        if (doc.getLocked()) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\r\n            return;\r\n        }\r\n\r\n        try {\r\n            int id = doc.createNewObject(\"XWiki.XWikiComments\");\r\n            com.xpn.xwiki.api.Object commentObject = doc.getObject(\"XWiki.XWikiComments\", id);\r\n            commentObject.set(\"author\", xwikiUser);\r\n            commentObject.set(\"date\", new Date());\r\n\r\n            /* Process the entity */\r\n            if (MediaType.TEXT_PLAIN.equals(mediaType)) {\r\n                try {\r\n                    commentObject.set(\"comment\", getRequest().getEntity().getText());\r\n\r\n                    doc.save();\r\n                } catch (IOException e) {\r\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                    return;\r\n                }\r\n            } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\r\n                XStream xstream = XStreamFactory.getXStream();\r\n\r\n                Comment comment = null;\r\n\r\n                /* If we receive an XML that is not convertible to a Page object we reject it */\r\n                try {\r\n                    comment = (Comment) xstream.fromXML(getRequest().getEntity().getText());\r\n                } catch (Exception e) {\r\n                    getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\r\n                    return;\r\n                }\r\n\r\n                /* We will only save if something changes... */\r\n                boolean save = false;\r\n\r\n                if (comment.getHighlight() != null) {\r\n                    commentObject.set(\"highlight\", comment.getHighlight());\r\n                    save = true;\r\n                }\r\n\r\n                if (comment.getText() != null) {\r\n                    commentObject.set(\"comment\", comment.getText());\r\n                    save = true;\r\n                }\r\n\r\n                if (save) {\r\n                    doc.save();\r\n\r\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\r\n\r\n                    /* Set the entity as being the new/updated document XML representation */\r\n                    getResponse().setEntity(\r\n                        new StringRepresentation(Utils.toXml(DomainObjectFactory.createComment(getRequest(),\r\n                            resourceClassRegistry, doc, commentObject, false)), MediaType.APPLICATION_XML));\r\n                }\r\n            }\r\n        } catch (XWikiException e) {\r\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            } else {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            }\r\n\r\n            return;\r\n        }\r\n    }","id":14072,"modified_method":"@Override\r\n    public void handlePost()\r\n    {\r\n        MediaType mediaType = getRequest().getEntity().getMediaType();\r\n\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, true);\r\n        if (documentInfo == null) {\r\n            return;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        try {\r\n            int id = doc.createNewObject(\"XWiki.XWikiComments\");\r\n            com.xpn.xwiki.api.Object commentObject = doc.getObject(\"XWiki.XWikiComments\", id);\r\n            commentObject.set(\"author\", xwikiUser);\r\n            commentObject.set(\"date\", new Date());\r\n\r\n            /* Process the entity */\r\n            if (MediaType.TEXT_PLAIN.equals(mediaType)) {\r\n                try {\r\n                    commentObject.set(\"comment\", getRequest().getEntity().getText());\r\n\r\n                    doc.save();\r\n                } catch (IOException e) {\r\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                    return;\r\n                }\r\n            } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\r\n                XStream xstream = XStreamFactory.getXStream();\r\n\r\n                Comment comment = null;\r\n\r\n                /* If we receive an XML that is not convertible to a Page object we reject it */\r\n                try {\r\n                    comment = (Comment) xstream.fromXML(getRequest().getEntity().getText());\r\n                } catch (Exception e) {\r\n                    getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\r\n                    return;\r\n                }\r\n\r\n                /* We will only save if something changes... */\r\n                boolean save = false;\r\n\r\n                if (comment.getHighlight() != null) {\r\n                    commentObject.set(\"highlight\", comment.getHighlight());\r\n                    save = true;\r\n                }\r\n\r\n                if (comment.getText() != null) {\r\n                    commentObject.set(\"comment\", comment.getText());\r\n                    save = true;\r\n                }\r\n\r\n                if (save) {\r\n                    doc.save();\r\n\r\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\r\n\r\n                    /* Set the entity as being the new/updated document XML representation */\r\n                    getResponse().setEntity(\r\n                        new StringRepresentation(Utils.toXml(DomainObjectFactory.createComment(getRequest(),\r\n                            resourceClassRegistry, doc, commentObject, false)), MediaType.APPLICATION_XML));\r\n                }\r\n            }\r\n        } catch (XWikiException e) {\r\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            } else {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            }\r\n\r\n            return;\r\n        }\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n            if (documentInfo == null) {\r\n                /* If the document doesn't exist send a not found header */\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            /* Check if we have access to it */\r\n            if (doc == null) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                return null;\r\n            }\r\n\r\n            Comments comments = new Comments();\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n\r\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\r\n            RangeIterable<com.xpn.xwiki.api.Object> ri =\r\n                new RangeIterable<com.xpn.xwiki.api.Object>(xwikiComments, Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\r\n\r\n            for (com.xpn.xwiki.api.Object xwikiComment : ri) {\r\n                comments.addComment(DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc,\r\n                    xwikiComment, false));\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comments);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","id":14073,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n            if (documentInfo == null) {\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            Comments comments = new Comments();\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n\r\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\r\n            RangeIterable<com.xpn.xwiki.api.Object> ri =\r\n                new RangeIterable<com.xpn.xwiki.api.Object>(xwikiComments, Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\r\n\r\n            for (com.xpn.xwiki.api.Object xwikiComment : ri) {\r\n                comments.addComment(DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc,\r\n                    xwikiComment, false));\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comments);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n            if (documentInfo == null) {\r\n                /* If the document doesn't exist send a not found header */\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            /* Check if we have access to it */\r\n            if (doc == null) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                return null;\r\n            }\r\n\r\n            Comments comments = new Comments();\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n\r\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\r\n            RangeIterable<com.xpn.xwiki.api.Object> ri =\r\n                new RangeIterable<com.xpn.xwiki.api.Object>(xwikiComments, Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\r\n\r\n            for (com.xpn.xwiki.api.Object xwikiComment : ri) {\r\n                comments.addComment(DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc,\r\n                    xwikiComment, true));\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comments);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","id":14074,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        try {\r\n            DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n            if (documentInfo == null) {\r\n                return null;\r\n            }\r\n\r\n            Document doc = documentInfo.getDocument();\r\n\r\n            Comments comments = new Comments();\r\n\r\n            Vector<com.xpn.xwiki.api.Object> xwikiComments = doc.getComments();\r\n\r\n            Form queryForm = getRequest().getResourceRef().getQueryAsForm();\r\n            RangeIterable<com.xpn.xwiki.api.Object> ri =\r\n                new RangeIterable<com.xpn.xwiki.api.Object>(xwikiComments, Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.START_PARAMETER), 0), Utils.parseInt(queryForm\r\n                    .getFirstValue(Constants.NUMBER_PARAMETER), -1));\r\n\r\n            for (com.xpn.xwiki.api.Object xwikiComment : ri) {\r\n                comments.addComment(DomainObjectFactory.createComment(getRequest(), resourceClassRegistry, doc,\r\n                    xwikiComment, true));\r\n            }\r\n\r\n            return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), comments);\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n        }\r\n\r\n        return null;\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public void handleDelete()\n    {\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\n        if (documentInfo == null) {\n            /* Should not happen since we requested not to fail if the document doesn't exist */\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            return;\n\n        }\n\n        Document doc = documentInfo.getDocument();\n        /* If the doc is null we don't have the rights to access it. */\n        if (doc == null) {\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            return;\n        }\n\n        /* If the doc is locked then return */\n        if (doc.getLocked()) {\n            getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\n            return;\n        }\n\n        try {\n            doc.delete();\n        } catch (XWikiException e) {\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            } else {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            }\n\n            return;\n        }\n    }","id":14075,"modified_method":"@Override\n    public void handleDelete()\n    {\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, true);\n        if (documentInfo == null) {\n            return;\n        }\n\n        Document doc = documentInfo.getDocument();\n\n        try {\n            doc.delete();\n        } catch (XWikiException e) {\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            } else {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            }\n\n            return;\n        }\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public void handlePut()\n    {\n        MediaType mediaType = getRequest().getEntity().getMediaType();\n\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\n        if (documentInfo == null) {\n            /* Should not happen since we requested not to fail if the document doesn't exist */\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            return;\n\n        }\n\n        Document doc = documentInfo.getDocument();\n        /* If the doc is null we don't have the rights to access it. */\n        if (doc == null) {\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            return;\n        }\n\n        /* If the doc is locked then return */\n        if (doc.getLocked()) {\n            getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\n            return;\n        }\n\n        /* Process the entity */\n        if (MediaType.TEXT_PLAIN.equals(mediaType)) {\n            try {\n                doc.setContent(getRequest().getEntity().getText());\n                doc.save();\n            } catch (IOException e) {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n            } catch (XWikiException e) {\n                if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                    getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                } else {\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                }\n\n                return;\n            }\n        } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\n            XStream xstream = XStreamFactory.getXStream();\n\n            Page page = null;\n\n            /* If we receive an XML that is not convertible to a Page object we reject it */\n            try {\n                page = (Page) xstream.fromXML(getRequest().getEntity().getText());\n            } catch (Exception e) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\n                return;\n            }\n\n            /* We will only save if something changes... */\n            boolean save = false;\n\n            if (page.getContent() != null) {\n                doc.setContent(page.getContent());\n                save = true;\n            }\n\n            if (page.getParent() != null) {\n                if (!page.getParent().equals(doc.getParent())) {\n                    doc.setParent(page.getParent());\n                    save = true;\n                }\n            }\n\n            if (page.getTitle() != null) {\n                if (!page.getTitle().equals(doc.getTitle())) {\n                    doc.setTitle(page.getTitle());\n                    save = true;\n                }\n            }\n\n            if (save) {\n                try {\n                    doc.save();\n                } catch (XWikiException e) {\n                    if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                        getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                    } else {\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                    }\n\n                    return;\n                }\n\n                /* Set the correct response code, depending whether the document existed or not */\n                if (documentInfo.isCreated()) {\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\n                } else {\n                    getResponse().setStatus(Status.SUCCESS_ACCEPTED);\n                }\n\n                /* Set the entity as being the new/updated document XML representation */\n                getResponse().setEntity(\n                    new StringRepresentation(Utils.toXml(DomainObjectFactory.createPage(getRequest(),\n                        resourceClassRegistry, doc, false)), MediaType.APPLICATION_XML));\n            }\n        }\n    }","id":14076,"modified_method":"@Override\n    public void handlePut()\n    {\n        MediaType mediaType = getRequest().getEntity().getMediaType();\n\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), false, true);\n        if (documentInfo == null) {\n            return;\n\n        }\n\n        Document doc = documentInfo.getDocument();\n\n        /* Process the entity */\n        if (MediaType.TEXT_PLAIN.equals(mediaType)) {\n            try {\n                doc.setContent(getRequest().getEntity().getText());\n                doc.save();\n            } catch (IOException e) {\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                return;\n            } catch (XWikiException e) {\n                if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                    getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                } else {\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                }\n\n                return;\n            }\n        } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\n            XStream xstream = XStreamFactory.getXStream();\n\n            Page page = null;\n\n            /* If we receive an XML that is not convertible to a Page object we reject it */\n            try {\n                page = (Page) xstream.fromXML(getRequest().getEntity().getText());\n            } catch (Exception e) {\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\n                return;\n            }\n\n            /* We will only save if something changes... */\n            boolean save = false;\n\n            if (page.getContent() != null) {\n                doc.setContent(page.getContent());\n                save = true;\n            }\n\n            if (page.getParent() != null) {\n                if (!page.getParent().equals(doc.getParent())) {\n                    doc.setParent(page.getParent());\n                    save = true;\n                }\n            }\n\n            if (page.getTitle() != null) {\n                if (!page.getTitle().equals(doc.getTitle())) {\n                    doc.setTitle(page.getTitle());\n                    save = true;\n                }\n            }\n\n            if (save) {\n                try {\n                    doc.save();\n                } catch (XWikiException e) {\n                    if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\n                        getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                    } else {\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n                    }\n\n                    return;\n                }\n\n                /* Set the correct response code, depending whether the document existed or not */\n                if (documentInfo.isCreated()) {\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\n                } else {\n                    getResponse().setStatus(Status.SUCCESS_ACCEPTED);\n                }\n\n                /* Set the entity as being the new/updated document XML representation */\n                getResponse().setEntity(\n                    new StringRepresentation(Utils.toXml(DomainObjectFactory.createPage(getRequest(),\n                        resourceClassRegistry, doc, false)), MediaType.APPLICATION_XML));\n            }\n        }\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n        if (documentInfo == null) {\r\n            /* If the document doesn't exist send a not found header */\r\n            getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        /* Check if we have access to it */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return null;\r\n        }\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, false);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","id":14077,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n        if (documentInfo == null) {\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, false);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public void handleDelete()\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\r\n        if (documentInfo == null) {\r\n            /* Should not happen since we requested not to fail if the document doesn't exist */\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return;\r\n\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n        /* If the doc is null we don't have the rights to access it. */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return;\r\n        }\r\n\r\n        /* If the doc is locked then return */\r\n        if (doc.getLocked()) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\r\n            return;\r\n        }\r\n\r\n        try {\r\n            doc.delete();\r\n        } catch (XWikiException e) {\r\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            } else {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            }\r\n\r\n            return;\r\n        }\r\n    }","id":14078,"modified_method":"@Override\r\n    public void handleDelete()\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, true);\r\n        if (documentInfo == null) {\r\n            return;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        try {\r\n            doc.delete();\r\n        } catch (XWikiException e) {\r\n            if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            } else {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            }\r\n\r\n            return;\r\n        }\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public void handlePut()\r\n    {\r\n        MediaType mediaType = getRequest().getEntity().getMediaType();\r\n\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), false);\r\n        if (documentInfo == null) {\r\n            /* Should not happen since we requested not to fail if the document doesn't exist */\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return;\r\n\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n        /* If the doc is null we don't have the rights to access it. */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return;\r\n        }\r\n\r\n        /* If the doc is locked then return */\r\n        if (doc.getLocked()) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_LOCKED);\r\n            return;\r\n        }\r\n\r\n        /* Process the entity */\r\n        if (MediaType.TEXT_PLAIN.equals(mediaType)) {\r\n            try {\r\n                doc.setContent(getRequest().getEntity().getText());\r\n                doc.save();\r\n            } catch (IOException e) {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                return;\r\n            } catch (XWikiException e) {\r\n                if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                    getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                } else {\r\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                }\r\n\r\n                return;\r\n            }\r\n        } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\r\n            XStream xstream = XStreamFactory.getXStream();\r\n\r\n            Page page = null;\r\n\r\n            /* If we receive an XML that is not convertible to a Page object we reject it */\r\n            try {\r\n                page = (Page) xstream.fromXML(getRequest().getEntity().getText());\r\n            } catch (Exception e) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\r\n                return;\r\n            }\r\n\r\n            /* We will only save if something changes... */\r\n            boolean save = false;\r\n\r\n            if (page.getContent() != null) {\r\n                doc.setContent(page.getContent());\r\n                save = true;\r\n            }\r\n\r\n            if (page.getParent() != null) {\r\n                if (!page.getParent().equals(doc.getParent())) {\r\n                    doc.setParent(page.getParent());\r\n                    save = true;\r\n                }\r\n            }\r\n\r\n            if (page.getTitle() != null) {\r\n                if (!page.getTitle().equals(doc.getTitle())) {\r\n                    doc.setTitle(page.getTitle());\r\n                    save = true;\r\n                }\r\n            }\r\n\r\n            if (save) {\r\n                try {\r\n                    doc.save();\r\n                } catch (XWikiException e) {\r\n                    if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                        getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                    } else {\r\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                    }\r\n\r\n                    return;\r\n                }\r\n\r\n                /* Set the correct response code, depending whether the document existed or not */\r\n                if (documentInfo.isCreated()) {\r\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\r\n                } else {\r\n                    getResponse().setStatus(Status.SUCCESS_ACCEPTED);\r\n                }\r\n\r\n                /* Set the entity as being the new/updated document XML representation */\r\n                getResponse().setEntity(\r\n                    new StringRepresentation(Utils.toXml(DomainObjectFactory.createPage(getRequest(),\r\n                        resourceClassRegistry, doc, false)), MediaType.APPLICATION_XML));\r\n            }\r\n        }\r\n    }","id":14079,"modified_method":"@Override\r\n    public void handlePut()\r\n    {\r\n        MediaType mediaType = getRequest().getEntity().getMediaType();\r\n\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), false, true);\r\n        if (documentInfo == null) {\r\n            return;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        /* Process the entity */\r\n        if (MediaType.TEXT_PLAIN.equals(mediaType)) {\r\n            try {\r\n                doc.setContent(getRequest().getEntity().getText());\r\n                doc.save();\r\n            } catch (IOException e) {\r\n                getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                return;\r\n            } catch (XWikiException e) {\r\n                if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                    getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                } else {\r\n                    getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                }\r\n\r\n                return;\r\n            }\r\n        } else if (MediaType.APPLICATION_XML.equals(mediaType)) {\r\n            XStream xstream = XStreamFactory.getXStream();\r\n\r\n            Page page = null;\r\n\r\n            /* If we receive an XML that is not convertible to a Page object we reject it */\r\n            try {\r\n                page = (Page) xstream.fromXML(getRequest().getEntity().getText());\r\n            } catch (Exception e) {\r\n                getResponse().setStatus(Status.CLIENT_ERROR_NOT_ACCEPTABLE);\r\n                return;\r\n            }\r\n\r\n            /* We will only save if something changes... */\r\n            boolean save = false;\r\n\r\n            if (page.getContent() != null) {\r\n                doc.setContent(page.getContent());\r\n                save = true;\r\n            }\r\n\r\n            if (page.getParent() != null) {\r\n                if (!page.getParent().equals(doc.getParent())) {\r\n                    doc.setParent(page.getParent());\r\n                    save = true;\r\n                }\r\n            }\r\n\r\n            if (page.getTitle() != null) {\r\n                if (!page.getTitle().equals(doc.getTitle())) {\r\n                    doc.setTitle(page.getTitle());\r\n                    save = true;\r\n                }\r\n            }\r\n\r\n            if (save) {\r\n                try {\r\n                    doc.save();\r\n                } catch (XWikiException e) {\r\n                    if (e.getCode() == XWikiException.ERROR_XWIKI_ACCESS_DENIED) {\r\n                        getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n                    } else {\r\n                        getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n                    }\r\n\r\n                    return;\r\n                }\r\n\r\n                /* Set the correct response code, depending whether the document existed or not */\r\n                if (documentInfo.isCreated()) {\r\n                    getResponse().setStatus(Status.SUCCESS_CREATED);\r\n                } else {\r\n                    getResponse().setStatus(Status.SUCCESS_ACCEPTED);\r\n                }\r\n\r\n                /* Set the entity as being the new/updated document XML representation */\r\n                getResponse().setEntity(\r\n                    new StringRepresentation(Utils.toXml(DomainObjectFactory.createPage(getRequest(),\r\n                        resourceClassRegistry, doc, false)), MediaType.APPLICATION_XML));\r\n            }\r\n        }\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n        if (documentInfo == null) {\r\n            /* If the document doesn't exist send a not found header */\r\n            getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        /* Check if we have access to it */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return null;\r\n        }\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, true);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","id":14080,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n        if (documentInfo == null) {\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, true);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"/**\n     * Get all the available translations for a page.\n     * \n     * @param variant The variant.\n     * @return representation The XML containing the list of spaces.\n     */\n    @Override\n    public Representation represent(Variant variant)\n    {\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\n        if (documentInfo == null) {\n            /* If the document doesn't exist send a not found header */\n            getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n            return null;\n        }\n\n        Document doc = documentInfo.getDocument();\n\n        /* Check if we have access to it */\n        if (doc == null) {\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n            return null;\n        }\n\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, false);\n        if (page == null) {\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            return null;\n        }\n\n        /*\n         * Set the pageId attribute of the translations list. Normally this is not set because it is embedded in a page\n         * element so it's redundant.\n         */\n        page.getTranslations().setPageFullName(page.getFullName());\n\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page.getTranslations());\n    }","id":14081,"modified_method":"/**\n     * Get all the available translations for a page.\n     * \n     * @param variant The variant.\n     * @return representation The XML containing the list of spaces.\n     */\n    @Override\n    public Representation represent(Variant variant)\n    {\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\n        if (documentInfo == null) {\n            return null;\n        }\n\n        Document doc = documentInfo.getDocument();\n\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, false);\n        if (page == null) {\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\n            return null;\n        }\n\n        /*\n         * Set the pageId attribute of the translations list. Normally this is not set because it is embedded in a page\n         * element so it's redundant.\n         */\n        page.getTranslations().setPageFullName(page.getFullName());\n\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page.getTranslations());\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), true);\r\n        if (documentInfo == null) {\r\n            /* If the document doesn't exist send a not found header */\r\n            getResponse().setStatus(Status.CLIENT_ERROR_NOT_FOUND);\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        /* Check if we have access to it */\r\n        if (doc == null) {\r\n            getResponse().setStatus(Status.CLIENT_ERROR_FORBIDDEN);\r\n            return null;\r\n        }\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, true);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","id":14082,"modified_method":"@Override\r\n    public Representation represent(Variant variant)\r\n    {\r\n        DocumentInfo documentInfo = getDocumentFromRequest(getRequest(), getResponse(), true, false);\r\n        if (documentInfo == null) {\r\n            return null;\r\n        }\r\n\r\n        Document doc = documentInfo.getDocument();\r\n\r\n        Page page = DomainObjectFactory.createPage(getRequest(), resourceClassRegistry, doc, true);\r\n        if (page == null) {\r\n            getResponse().setStatus(Status.SERVER_ERROR_INTERNAL);\r\n            return null;\r\n        }\r\n\r\n        return getRepresenterFor(variant).represent(getContext(), getRequest(), getResponse(), page);\r\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"/**\n     * <p>\n     * Returns a document based on the request. A DocumentInfo object is returned in order to provide additional\n     * information.\n     * <\/p>\n     * <p>\n     * If failIfDoesntExist is true, null is returned whenever the requested document does not exist\n     * <\/p>\n     * <p>\n     * If failIfDoesntExist is false then a DocumentInfo is returned. However the document field could be null if the\n     * user doesn't have the rights to access the document\n     * <\/p>\n     * \n     * @param failIfDoesntExist\n     * @return A DocumentInfo containing the document or null if the document doesn't exist or an exception was thrown.\n     */\n    public DocumentInfo getDocumentFromRequest(Request request, boolean failIfDoesntExist)\n    {\n        try {\n            String wikiName = (String) request.getAttributes().get(Constants.WIKI_NAME_PARAMETER);\n            String spaceName = (String) request.getAttributes().get(Constants.SPACE_NAME_PARAMETER);\n            String pageName = (String) request.getAttributes().get(Constants.PAGE_NAME_PARAMETER);\n            String language = (String) request.getAttributes().get(Constants.LANGUAGE_ID_PARAMETER);\n            String version = (String) request.getAttributes().get(Constants.VERSION_PARAMETER);\n\n            String pageFullName = Utils.getPrefixedPageName(wikiName, spaceName, pageName);\n\n            boolean existed = xwikiApi.exists(pageFullName);\n\n            if (failIfDoesntExist) {\n                if (!existed) {\n                    return null;\n                }\n            }\n\n            Document doc = xwikiApi.getDocument(pageFullName);\n\n            /* If doc is null, we don't have the rights to access the document */\n            if (doc == null) {\n                return new DocumentInfo(null, false);\n            }\n\n            if (language != null) {\n                doc = doc.getTranslatedDocument(language);\n\n                /*\n                 * If the language of the translated document is not the one we requested, then the requested\n                 * translation doesn't exist. new translated document by hand.\n                 */\n                if (!language.equals(doc.getLanguage())) {\n                    /* If we are here the requested translation doesn't exist */\n                    if (failIfDoesntExist) {\n                        return null;\n                    } else {\n                        XWikiDocument xwikiDocument = new XWikiDocument(spaceName, pageName);\n                        xwikiDocument.setLanguage(language);\n                        doc = new Document(xwikiDocument, xwikiContext);\n\n                        existed = false;\n                    }\n                }\n            }\n\n            /* Get a specific version if requested to */\n            if (version != null) {\n                doc = doc.getDocumentRevision(version);\n            }\n\n            return new DocumentInfo(doc, !existed);\n        } catch (Exception e) {\n            return null;\n        }\n    }","id":14083,"modified_method":"/**\n     * <p>\n     * Returns a document based on the request. A DocumentInfo object is returned in order to provide additional\n     * information.\n     * <\/p>\n     * <p>\n     * If failIfDoesntExist is true, null is returned whenever the requested document does not exist\n     * <\/p>\n     * <p>\n     * If failIfDoesntExist is false then a DocumentInfo is returned. However the document field could be null if the\n     * user doesn't have the rights to access the document\n     * <\/p>\n     * \n     * @param failIfDoesntExist\n     * @return A DocumentInfo containing the document or null if the document doesn't exist or an exception was thrown.\n     */\n    public DocumentInfo getDocumentFromRequest(Request request, Response response, boolean failIfDoesntExist,\n        boolean failIfLocked)\n    {\n        try {\n            String wikiName = (String) request.getAttributes().get(Constants.WIKI_NAME_PARAMETER);\n            String spaceName = (String) request.getAttributes().get(Constants.SPACE_NAME_PARAMETER);\n            String pageName = (String) request.getAttributes().get(Constants.PAGE_NAME_PARAMETER);\n            String language = (String) request.getAttributes().get(Constants.LANGUAGE_ID_PARAMETER);\n            String version = (String) request.getAttributes().get(Constants.VERSION_PARAMETER);\n\n            String pageFullName = Utils.getPrefixedPageName(wikiName, spaceName, pageName);\n\n            boolean existed = xwikiApi.exists(pageFullName);\n\n            if (failIfDoesntExist) {\n                if (!existed) {\n                    response.setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                    return null;\n                }\n            }\n\n            Document doc = xwikiApi.getDocument(pageFullName);\n\n            /* If doc is null, we don't have the rights to access the document */\n            if (doc == null) {\n                response.setStatus(Status.CLIENT_ERROR_FORBIDDEN);\n                return null;\n            }\n\n            if (language != null) {\n                doc = doc.getTranslatedDocument(language);\n\n                /*\n                 * If the language of the translated document is not the one we requested, then the requested\n                 * translation doesn't exist. new translated document by hand.\n                 */\n                if (!language.equals(doc.getLanguage())) {\n                    /* If we are here the requested translation doesn't exist */\n                    if (failIfDoesntExist) {\n                        response.setStatus(Status.CLIENT_ERROR_NOT_FOUND);\n                        return null;\n                    } else {\n                        XWikiDocument xwikiDocument = new XWikiDocument(spaceName, pageName);\n                        xwikiDocument.setLanguage(language);\n                        doc = new Document(xwikiDocument, xwikiContext);\n\n                        existed = false;\n                    }\n                }\n            }\n\n            /* Get a specific version if requested to */\n            if (version != null) {\n                doc = doc.getDocumentRevision(version);\n            }\n\n            /* If the doc is locked then return */\n            if (doc.getLocked()) {\n                response.setStatus(Status.CLIENT_ERROR_LOCKED);\n                return null;\n            }\n\n            return new DocumentInfo(doc, !existed);\n        } catch (Exception e) {\n            return null;\n        }\n    }","commit_id":"40009b013c0cb4ae73d9b5e4ec95ce4ac1a37f17","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n  protected boolean isValidForFile(Project project, Editor editor, PsiFile file) {\n    if (!(file instanceof PsiJavaFile)) return false;\n    if (file instanceof PsiCompiledElement) return false;\n\n    PsiDocumentManager.getInstance(project).commitAllDocuments();\n\n    PsiClass targetClass = getTargetClass(editor, file);\n    if (targetClass == null) return false;\n    if (!isValidForClass(targetClass)) return false; //?\n\n    return true;\n  }","id":14084,"modified_method":"@Override\n  protected boolean isValidForFile(Project project, Editor editor, PsiFile file) {\n    if (!(file instanceof PsiJavaFile)) return false;\n    if (file instanceof PsiCompiledElement) return false;\n\n    PsiDocumentManager.getInstance(project).commitAllDocuments();\n\n    PsiClass targetClass = getTargetClass(editor, file);\n    return targetClass != null && isValidForClass(targetClass);\n  }","commit_id":"9f002548ac7f85a90363ab0c6e65b8977f6f1c39","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean isValidFor(final Editor editor, final PsiFile file) {\n    if (!(file instanceof PsiJavaFile)) {\n      return false;\n    }\n\n    PsiClass aClass = OverrideImplementUtil.getContextClass(file.getProject(), editor, file, false);\n    return aClass != null;\n  }","id":14085,"modified_method":"public boolean isValidFor(final Editor editor, final PsiFile file) {\n    if (!(file instanceof PsiJavaFile)) {\n      return false;\n    }\n\n    PsiClass aClass = OverrideImplementUtil.getContextClass(file.getProject(), editor, file, false);\n    return aClass != null && !OverrideImplementUtil.getMethodSignaturesToImplement(aClass).isEmpty();\n  }","commit_id":"9f002548ac7f85a90363ab0c6e65b8977f6f1c39","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void invoke(@NotNull final Project project, @NotNull final Editor editor, @NotNull final PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass != null) {\n      OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n    }\n  }","id":14086,"modified_method":"public void invoke(@NotNull final Project project, @NotNull final Editor editor, @NotNull final PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass == null) return;\n\n    if (OverrideImplementUtil.getMethodSignaturesToOverride(aClass).isEmpty()) {\n      HintManager.getInstance().showErrorHint(editor, \"No methods to override have been found\");\n      return;\n    }\n    OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n  }","commit_id":"9f002548ac7f85a90363ab0c6e65b8977f6f1c39","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean isValidFor(final Editor editor, final PsiFile file) {\n    return file instanceof PsiJavaFile && OverrideImplementUtil.getContextClass(file.getProject(), editor, file, true) != null;\n  }","id":14087,"modified_method":"public boolean isValidFor(final Editor editor, final PsiFile file) {\n    if (!(file instanceof PsiJavaFile)) {\n      return false;\n    }\n\n    PsiClass aClass = OverrideImplementUtil.getContextClass(file.getProject(), editor, file, true);\n    return aClass != null && !OverrideImplementUtil.getMethodSignaturesToOverride(aClass).isEmpty();\n  }","commit_id":"9f002548ac7f85a90363ab0c6e65b8977f6f1c39","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void invoke(@NotNull final Project project, @NotNull Editor editor, @NotNull PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass != null) {\n      OverrideImplementUtil.chooseAndImplementMethods(project, editor, aClass);\n    }\n  }","id":14088,"modified_method":"public void invoke(@NotNull final Project project, @NotNull Editor editor, @NotNull PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass == null) return;\n\n    if (OverrideImplementUtil.getMethodSignaturesToImplement(aClass).isEmpty()) {\n      HintManager.getInstance().showErrorHint(editor, \"No methods to implement have been found\");\n      return;\n    }\n\n    OverrideImplementUtil.chooseAndImplementMethods(project, editor, aClass);\n  }","commit_id":"271c55991c515a325bac80c81977311b49b9713a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void invoke(@NotNull final Project project, @NotNull Editor editor, @NotNull PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass != null) {\n      OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n    }\n  }","id":14089,"modified_method":"public void invoke(@NotNull final Project project, @NotNull Editor editor, @NotNull PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass == null) return;\n\n    if (OverrideImplementUtil.getMethodSignaturesToImplement(aClass).isEmpty()) {\n      HintManager.getInstance().showErrorHint(editor, \"No methods to override have been found\");\n      return;\n    }\n\n    OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n  }","commit_id":"271c55991c515a325bac80c81977311b49b9713a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void invoke(@NotNull final Project project, @NotNull final Editor editor, @NotNull final PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass != null) {\n      OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n    }\n  }","id":14090,"modified_method":"public void invoke(@NotNull final Project project, @NotNull final Editor editor, @NotNull final PsiFile file) {\n    PsiClass aClass = OverrideImplementUtil.getContextClass(project, editor, file, true);\n    if (aClass == null) return;\n\n    if (OverrideImplementUtil.getMethodSignaturesToImplement(aClass).isEmpty()) {\n      HintManager.getInstance().showErrorHint(editor, \"No methods to override have been found\");\n      return;\n    }\n\n    OverrideImplementUtil.chooseAndOverrideMethods(project, editor, aClass);\n  }","commit_id":"271c55991c515a325bac80c81977311b49b9713a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean showMessageBefore(MigrationStage stage) {\n    String mb = stage.messageBefore();\n    if (mb != null) {\n      int res = Messages.showDialog(mb, stage.title(), new String[]{\"Proceed\", \"Stop\"}, 0, Messages.getInformationIcon());\n      if (res != 0) {\n        Messages.showMessageDialog(\"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\", \"Migration stopped\", Messages.getInformationIcon());\n        return true;\n      }\n    }\n    return false;\n  }","id":14091,"modified_method":"private boolean showMessageBefore(MigrationStage stage) {\n    String mb = stage.messageBefore();\n    if (mb == null) return false;\n    int res = Messages.showDialog(mb, stage.title(), new String[]{\"Proceed\", \"Stop\"}, 0, Messages.getInformationIcon());\n    if (res != 0) {\n      Messages.showMessageDialog(\"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\", \"Migration stopped\", Messages.getInformationIcon());\n      return true;\n    }\n    return false;\n  }","commit_id":"2c56c8ed3fd1213dc41f5cb17969acaa3eafd00f","url":"https://github.com/JetBrains/MPS"},{"original_method":"private boolean showMessageAfter(MigrationStage stage) {\n    String ma = stage.messageAfter();\n    if (ma == null) return false;\n\n    ma += \"\\n\\n\" + \"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\";\n    Messages.showMessageDialog(ma, stage.title() + \" finished\", Messages.getInformationIcon());\n    return true;\n  }","id":14092,"modified_method":"private boolean showMessageAfter(MigrationStage stage) {\n    String ma = stage.messageAfter();\n    if (ma == null) return true;\n\n    ma += \"\\n\\n\" + \"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\";\n    int res = Messages.showDialog(ma, stage.title()+ \" finished\", new String[]{\"Force next step\", \"Stop\"}, 0, Messages.getInformationIcon());\n    if (res == 0) return true;\n\n    Messages.showMessageDialog(\"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\", \"Migration stopped\", Messages.getInformationIcon());\n    return false;\n  }","commit_id":"2c56c8ed3fd1213dc41f5cb17969acaa3eafd00f","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void migrate() {\n    final MigrationState msComponent = myProject.getComponent(MigrationState.class);\n    final MPSProject mpsProject = myProject.getComponent(MPSProject.class);\n\n    for (MState state : MState.values()) {\n      if (msComponent.getMigrationState() == state) {\n        final MState next = MState.values()[state.ordinal() + 1];\n        final MigrationStage stage = next.getStage();\n\n        if (stage == null) {\n          msComponent.setMigrationState(next);\n          continue;\n        }\n\n        String mb = stage.messageBefore();\n        if (mb != null) {\n          Messages.showMessageDialog(mb, stage.title(), Messages.getInformationIcon());\n        }\n\n        Runnable stageRunnable = new Runnable() {\n          public void run() {\n            stage.execute(mpsProject);\n            msComponent.setMigrationState(next);\n          }\n        };\n\n        if (stage.needsCommand()) {\n          ModelAccess.instance().runWriteActionInCommand(stageRunnable);\n        } else {\n          stageRunnable.run();\n        }\n\n        String ma = stage.messageAfter();\n        if (ma != null) {\n          Messages.showMessageDialog(ma, stage.title(), Messages.getInformationIcon());\n        }\n\n        if (stage.needsRestart()) {\n          FSRecords.invalidateCaches();\n\n          int res = Messages.showDialog(\n            \"Refactoring \" + stage.title() + \" requested IDE restart.\\n+\" +\n              \"Restart now?\",\n            \"Restart request\", new String[]{\"Restart\", \"Later\"}, 0, Messages.getQuestionIcon());\n\n          if (res == 0) {\n            ApplicationManager.getApplication().restart();\n          }\n        }\n      }\n    }\n  }","id":14093,"modified_method":"public void migrate() {\n    final MigrationState msComponent = myProject.getComponent(MigrationState.class);\n    final MPSProject mpsProject = myProject.getComponent(MPSProject.class);\n\n    for (MState state : MState.values()) {\n      if (msComponent.getMigrationState() == state) {\n        final MState next = MState.values()[state.ordinal() + 1];\n        final MigrationStage stage = next.getStage();\n\n        if (stage == null) {\n          msComponent.setMigrationState(next);\n          continue;\n        }\n\n        String mb = stage.messageBefore();\n        if (mb != null) {\n          int res = Messages.showDialog(mb, stage.title(), new String[]{\"Proceed\", \"Stop\"}, 0, Messages.getInformationIcon());\n          if (res!=0){\n            Messages.showMessageDialog(\"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\",\"Migration stopped\",Messages.getInformationIcon());\n            return;\n          }\n        }\n\n        Runnable stageRunnable = new Runnable() {\n          public void run() {\n            stage.execute(mpsProject);\n            msComponent.setMigrationState(next);\n          }\n        };\n\n        if (stage.needsCommand()) {\n          ModelAccess.instance().runWriteActionInCommand(stageRunnable);\n        } else {\n          stageRunnable.run();\n        }\n\n        String ma = stage.messageAfter();\n        if (ma != null) {\n          int res = Messages.showDialog(ma, stage.title(), new String[]{\"Next\", \"Stop\"}, 0, Messages.getInformationIcon());\n          if (res!=0){\n            Messages.showMessageDialog(\"You can continue migration later by executing MainMenu->Tools->Continue Migration to MPS 2.0\",\"Migration stopped\",Messages.getInformationIcon());\n            return;\n          }\n        }\n\n        if (stage.needsRestart()) {\n          FSRecords.invalidateCaches();\n\n          int res = Messages.showDialog(\n            \"Refactoring \" + stage.title() + \" requested IDE restart.\\n+\" +\n              \"Restart now?\",\n            \"Restart request\", new String[]{\"Restart\", \"Later\"}, 0, Messages.getQuestionIcon());\n\n          if (res == 0) {\n            ApplicationManager.getApplication().restart();\n          }\n        }\n      }\n    }\n  }","commit_id":"efe807a788c117cc4317e62e297853f27ff4b822","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14094,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14095,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14096,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14097,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14098,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"public boolean isApplicable(SNode node) {\n    return SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)), SNodeOperations.asSConcept(getApplicableConcept()));\n  }","id":14099,"modified_method":"public boolean isApplicable(SNode node) {\n    SAbstractConcept concept = SNodeOperations.getConcept(node);\n    SAbstractConcept applicableConcept = getApplicableConcept();\n    return concept.equals(applicableConcept) || concept.isSubConceptOf(applicableConcept);\n  }","commit_id":"dd4dce8dce39118e76906abf265624ab1394ed16","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n   protected StoredElement get(String name, byte[] id) throws DatastoreOperationException {\n      InetSocketAddress target;\n\n      while (!(target = getTarget(id)).equals(clusterView.localMember())) {\n         LOG.debug(clusterView.localMember().toString() + \":: Routing datastore get request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n         try {\n            return remoteCache.get(name, target);\n         } catch (RemoteConnectionException rce) {\n            clusterMemberDamaged(target, clusterView, rce);\n         }\n      }\n\n      return localDatastore.get(name);\n   }","id":14100,"modified_method":"@Override\n   protected StoredElement get(String name, byte[] id) throws DatastoreOperationException {\n      boolean retry;\n\n      do {\n         retry = false;\n\n         final InetSocketAddress target = getTarget(id);\n\n         if (target != null && !target.equals(clusterView.localMember())) {\n            LOG.debug(clusterView.localMember() + \":: Routing datastore get request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n            try {\n               return remoteCache.get(name, target);\n            } catch (RemoteConnectionException rce) {\n               clusterMemberDamaged(target, clusterView, rce);\n               retry = true;\n            }\n         }\n      } while (retry);\n\n      return localDatastore.get(name);\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n   protected boolean remove(String name, byte[] id) throws DatastoreOperationException {\n      InetSocketAddress target;\n\n      while (!(target = getTarget(id)).equals(clusterView.localMember())) {\n         LOG.debug(clusterView.localMember().toString() + \":: Routing datastore delete request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n         try {\n            return remoteCache.remove(name, target);\n         } catch (RemoteConnectionException rce) {\n            clusterMemberDamaged(target, clusterView, rce);\n         }\n      }\n\n      return localDatastore.remove(name);\n   }","id":14101,"modified_method":"@Override\n   protected boolean remove(String name, byte[] id) throws DatastoreOperationException {\n      boolean retry;\n\n      do {\n         retry = false;\n\n         final InetSocketAddress target = getTarget(id);\n\n         if (target != null && !target.equals(clusterView.localMember())) {\n            LOG.debug(clusterView.localMember() + \":: Routing datastore delete request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n            try {\n               return remoteCache.delete(name, target);\n            } catch (RemoteConnectionException rce) {\n               clusterMemberDamaged(target, clusterView, rce);\n               retry = true;\n            }\n         }\n      } while (retry);\n\n      return localDatastore.remove(name);\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n   protected void put(String name, byte[] id, byte[] value, int ttl, TimeUnit timeUnit) throws DatastoreOperationException {\n      InetSocketAddress target;\n\n      while (!(target = getTarget(id)).equals(clusterView.localMember())) {\n         LOG.debug(clusterView.localMember().toString() + \":: Routing datastore get request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n         try {\n            remoteCache.put(name, value, ttl, timeUnit, target);\n            return;\n         } catch (RemoteConnectionException rce) {\n            clusterMemberDamaged(target, clusterView, rce);\n         }\n      }\n\n      localDatastore.put(name, value, ttl, timeUnit);\n   }","id":14102,"modified_method":"@Override\n   protected void put(String name, byte[] id, byte[] value, int ttl, TimeUnit timeUnit) throws DatastoreOperationException {\n      boolean retry;\n\n      do {\n         retry = false;\n\n         final InetSocketAddress target = getTarget(id);\n\n         if (target != null && !target.equals(clusterView.localMember())) {\n            LOG.debug(clusterView.localMember() + \":: Routing datastore put request for, \\\"\" + name + \"\\\" to: \" + target.toString());\n\n            try {\n               remoteCache.put(name, value, ttl, timeUnit, target);\n               return;\n            } catch (RemoteConnectionException rce) {\n               clusterMemberDamaged(target, clusterView, rce);\n               retry = true;\n            }\n         }\n      } while (retry);\n\n      localDatastore.put(name, value, ttl, timeUnit);\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"public DatastoreFilterLogicHandler(MutableClusterView clusterView, String lastLocalAddr, HashedDatastore hashRingDatastore, DatastoreAccessControl hostAcl) {\n      this.clusterView = clusterView;\n      this.hostAcl = hostAcl;\n      this.lastLocalAddr = lastLocalAddr;\n      this.hashRingDatastore = hashRingDatastore;\n   }","id":14103,"modified_method":"public DatastoreFilterLogicHandler(MutableClusterView clusterView, String lastLocalAddr, HashedDatastore hashRingDatastore, DatastoreAccessControl hostAcl) {\n      this.clusterView = clusterView;\n      this.hostAcl = hostAcl;\n      this.hashRingDatastore = hashRingDatastore;\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n   public FilterDirector handleRequest(HttpServletRequest request, ReadableHttpServletResponse response) {\n      FilterDirector director = new FilterDirectorImpl();\n      director.setFilterAction(FilterAction.PASS);\n\n      if (CacheRequest.isCacheRequest(request)) {\n         if (isAllowed(request)) {\n            // TODO: Get rid of this monstrosity :x\n            updateClusterViewLocalAddress(request.getLocalAddr(), request.getLocalPort());\n\n            director = performCacheRequest(request);\n         } else {\n            director.setResponseStatus(HttpStatusCode.FORBIDDEN);\n            director.setFilterAction(FilterAction.RETURN);\n         }\n      }\n\n      return director;\n   }","id":14104,"modified_method":"@Override\n   public FilterDirector handleRequest(HttpServletRequest request, ReadableHttpServletResponse response) {\n      FilterDirector director = new FilterDirectorImpl();\n      director.setFilterAction(FilterAction.PASS);\n\n      if (CacheRequest.isCacheRequest(request)) {\n         if (isAllowed(request)) {\n            clusterView.updateLocalAddress(new InetSocketAddress(request.getLocalAddr(), request.getLocalPort()));\n            director = performCacheRequest(request);\n         } else {\n            director.setResponseStatus(HttpStatusCode.FORBIDDEN);\n            director.setFilterAction(FilterAction.RETURN);\n         }\n      }\n\n      return director;\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"public static void main(String[] args) throws Exception {\n        final MutableClusterView view = new ThreadSafeClusterView();\n        final EHCacheDatastoreManager localManager = new EHCacheDatastoreManager(new CacheManager());\n        final HashRingDatastoreManager remoteManager = new HashRingDatastoreManager(\"temp-host-key\", UUIDEncodingProvider.getInstance(), MD5MessageDigestFactory.getInstance(), view, localManager.getDatastore());\n        final Datastore datastore = remoteManager.getDatastore();\n\n        view.updateLocal(new InetSocketAddress(InetAddress.getLocalHost(), 20000));\n        view.updateMembers(new InetSocketAddress[]{\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2101),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2102),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2103),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2104)});\n\n        final String myKey = \"mykey\";\n        final int finishTotal = 9700,\n                sleep1 = 1000,\n                sleep2 = 2000,\n                sleep3 = 1200,\n                sleep4 = 3000;\n\n        total = 0;\n\n        final Thread inserter1 = new Thread(new CacheInserterRunnable(sleep1, finishTotal, datastore, myKey)),\n                inserter2 = new Thread(new CacheInserterRunnable(sleep2, finishTotal, datastore, myKey)),\n                inserter3 = new Thread(new CacheInserterRunnable(sleep3, finishTotal, datastore, myKey)),\n                inserter4 = new Thread(new CacheInserterRunnable(sleep4, finishTotal, datastore, myKey));\n\n        final Thread reader = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                try {\n                    while (true) {\n                        try {\n                            Thread.sleep(400);\n                        } catch (InterruptedException ie) {\n                            break;\n                        }\n\n                        final CacheableValue myValue = datastore.get(myKey).elementAs(CacheableValue.class);\n                        System.out.println(\"Acquired: \" + myValue.getValue() + \" out of \" + total\n                                + \"\\t\\t\\t\\t- Potential Drift Ratio: \" + ((double) myValue.getValue() / (double) total)\n                                + \"\\t\\t- Elapsed time: \" + (System.currentTimeMillis() - beginTimestamp) + \"ms\");\n                    }\n                } catch (Exception ex) {\n                    ex.printStackTrace();\n                }\n            }\n        }, \"Reader 1\");\n\n        Thread.sleep(4000);\n\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final ObjectOutputStream oos = new ObjectOutputStream(baos);\n\n        oos.writeObject(new CacheableValue(0, true));\n        oos.close();\n\n        beginTimestamp = System.currentTimeMillis();\n\n        datastore.put(myKey, baos.toByteArray(), 200, TimeUnit.SECONDS);\n\n        reader.start();\n        inserter1.start();\n        inserter2.start();\n        inserter3.start();\n        inserter4.start();\n\n        Thread.sleep(200000);\n\n        System.exit(0);\n    }","id":14105,"modified_method":"public static void main(String[] args) throws Exception {\n        final MutableClusterView view = new ThreadSafeClusterView();\n        final EHCacheDatastoreManager localManager = new EHCacheDatastoreManager(new CacheManager());\n        final HashRingDatastoreManager remoteManager = new HashRingDatastoreManager(\"temp-host-key\", UUIDEncodingProvider.getInstance(), MD5MessageDigestFactory.getInstance(), view, localManager.getDatastore());\n        final Datastore datastore = remoteManager.getDatastore();\n\n        view.updateLocalAddress(new InetSocketAddress(InetAddress.getLocalHost(), 20000));\n        view.updateMembers(new InetSocketAddress[]{\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2101),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2102),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2103),\n                    new InetSocketAddress(InetAddress.getLocalHost(), 2104)});\n\n        final String myKey = \"mykey\";\n        final int finishTotal = 9700,\n                sleep1 = 100,\n                sleep2 = 200,\n                sleep3 = 1200,\n                sleep4 = 300;\n\n        total = 0;\n\n        final Thread inserter1 = new Thread(new CacheInserterRunnable(sleep1, finishTotal, datastore, myKey)),\n                inserter2 = new Thread(new CacheInserterRunnable(sleep2, finishTotal, datastore, myKey)),\n                inserter3 = new Thread(new CacheInserterRunnable(sleep3, finishTotal, datastore, myKey)),\n                inserter4 = new Thread(new CacheInserterRunnable(sleep4, finishTotal, datastore, myKey));\n\n        final Thread reader = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                try {\n                    while (true) {\n                        try {\n                            Thread.sleep(400);\n                        } catch (InterruptedException ie) {\n                            break;\n                        }\n\n                        final CacheableValue myValue = datastore.get(myKey).elementAs(CacheableValue.class);\n                        System.out.println(\"Acquired: \" + myValue.getValue() + \" out of \" + total\n                                + \"\\t\\t\\t\\t- Potential Drift Ratio: \" + ((double) myValue.getValue() / (double) total)\n                                + \"\\t\\t- Elapsed time: \" + (System.currentTimeMillis() - beginTimestamp) + \"ms\");\n                    }\n                } catch (Exception ex) {\n                    ex.printStackTrace();\n                }\n            }\n        }, \"Reader 1\");\n\n        Thread.sleep(4000);\n\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final ObjectOutputStream oos = new ObjectOutputStream(baos);\n\n        oos.writeObject(new CacheableValue(0, true));\n        oos.close();\n\n        beginTimestamp = System.currentTimeMillis();\n\n        datastore.put(myKey, baos.toByteArray(), 200, TimeUnit.SECONDS);\n\n        reader.start();\n        inserter1.start();\n        inserter2.start();\n        inserter3.start();\n        inserter4.start();\n\n        Thread.sleep(200000);\n\n        System.exit(0);\n    }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n   public boolean remove(String key, InetSocketAddress remoteEndpoint) throws RemoteConnectionException {\n      final String targetUrl = CacheRequest.urlFor(remoteEndpoint, key);\n\n      final HttpDelete cacheObjectDelete = new HttpDelete(targetUrl);\n      cacheObjectDelete.addHeader(DatastoreRequestHeaders.DATASTORE_HOST_KEY, hostKey);\n\n      return httpClientPool.use(new ResourceContext<HttpClient, Boolean>() {\n\n         @Override\n         public Boolean perform(HttpClient client) throws ResourceContextException {\n            HttpEntity responseEnttiy = null;\n\n            try {\n               final HttpResponse response = client.execute(cacheObjectDelete);\n               responseEnttiy = response.getEntity();\n\n               return response.getStatusLine().getStatusCode() == HttpStatusCode.ACCEPTED.intValue();\n            } catch (IOException ioe) {\n               throw new RemoteConnectionException(\"Unable to perform put against target: \" + targetUrl, ioe);\n            } finally {\n               releaseEntity(responseEnttiy);\n            }\n         }\n      });\n   }","id":14106,"modified_method":"@Override\n   public boolean delete(String key, InetSocketAddress remoteEndpoint) throws RemoteConnectionException {\n      final String targetUrl = CacheRequest.urlFor(remoteEndpoint, key);\n\n      final HttpDelete cacheObjectDelete = new HttpDelete(targetUrl);\n      cacheObjectDelete.addHeader(DatastoreRequestHeaders.DATASTORE_HOST_KEY, hostKey);\n\n      return httpClientPool.use(new ResourceContext<HttpClient, Boolean>() {\n\n         @Override\n         public Boolean perform(HttpClient client) throws ResourceContextException {\n            HttpEntity responseEnttiy = null;\n\n            try {\n               final HttpResponse response = client.execute(cacheObjectDelete);\n               responseEnttiy = response.getEntity();\n\n               return response.getStatusLine().getStatusCode() == HttpStatusCode.ACCEPTED.intValue();\n            } catch (IOException ioe) {\n               throw new RemoteConnectionException(\"Unable to perform put against target: \" + targetUrl, ioe);\n            } finally {\n               releaseEntity(responseEnttiy);\n            }\n         }\n      });\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public synchronized InetSocketAddress localMember() {\n        return localAddress;\n    }","id":14107,"modified_method":"@Override\n   public synchronized InetSocketAddress localMember() {\n      return localAddress.get();\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ThreadSafeClusterView copy() {\n       return new ThreadSafeClusterView(localAddress, clusterMembers);\n    }","id":14108,"modified_method":"@Override\n   public ThreadSafeClusterView copy() {\n      return new ThreadSafeClusterView(clusterMembers);\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ThreadSafeClusterView(InetSocketAddress localAddress, List<ClusterMember> clusterMembers) {\n        this.clusterMembers = new LinkedList<ClusterMember>(clusterMembers);\n        this.localAddress = localAddress;\n    }","id":14109,"modified_method":"public ThreadSafeClusterView(List<ClusterMember> clusterMembers) {\n      this.clusterMembers = new LinkedList<ClusterMember>(clusterMembers);\n\n      localAddress = new ThreadLocal<InetSocketAddress>();\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public synchronized void updateLocal(InetSocketAddress local) {\n        localAddress = local;\n    }","id":14110,"modified_method":"@Override\n   public synchronized void updateLocalAddress(InetSocketAddress local) {\n      localAddress.set(local);\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ThreadSafeClusterView() {\n        clusterMembers = new LinkedList<ClusterMember>();\n    }","id":14111,"modified_method":"public ThreadSafeClusterView() {\n      this(new LinkedList<ClusterMember>());\n   }","commit_id":"e6467d01ce5ba49eb4495372b70270d5cec008c4","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarBooking calendarBooking)\n\t\tthrows Exception {\n\n\t\tStagedModelDataHandlerUtil.exportStagedModel(\n\t\t\tportletDataContext, calendarBooking.getCalendar());\n\n\t\tif (!calendarBooking.isMasterBooking()) {\n\t\t\tStagedModelDataHandlerUtil.exportStagedModel(\n\t\t\t\tportletDataContext, calendarBooking.getParentCalendarBooking());\n\t\t}\n\n\t\tElement calendarBookingElement =\n\t\t\tportletDataContext.getExportDataElement(calendarBooking);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarBookingElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarBooking),\n\t\t\tcalendarBooking);\n\t}","id":14112,"modified_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarBooking calendarBooking)\n\t\tthrows Exception {\n\n\t\tStagedModelDataHandlerUtil.exportReferenceStagedModel(\n\t\t\tportletDataContext, calendarBooking, calendarBooking.getCalendar(),\n\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG);\n\n\t\tif (!calendarBooking.isMasterBooking()) {\n\t\t\tStagedModelDataHandlerUtil.exportReferenceStagedModel(\n\t\t\t\tportletDataContext, calendarBooking,\n\t\t\t\tcalendarBooking.getParentCalendarBooking(),\n\t\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG);\n\t\t}\n\n\t\tElement calendarBookingElement =\n\t\t\tportletDataContext.getExportDataElement(calendarBooking);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarBookingElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarBooking),\n\t\t\tcalendarBooking);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarBooking calendarBooking)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarBooking.getUserUuid());\n\n\t\tString calendarPath = ExportImportPathUtil.getModelPath(\n\t\t\tportletDataContext, Calendar.class.getName(),\n\t\t\tcalendarBooking.getCalendarId());\n\n\t\tCalendar calendar = (Calendar)portletDataContext.getZipEntryAsObject(\n\t\t\tcalendarPath);\n\n\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\tportletDataContext, calendar);\n\n\t\tMap<Long, Long> calendarIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendar.class);\n\n\t\tlong calendarId = MapUtil.getLong(\n\t\t\tcalendarIds, calendarBooking.getCalendarId(),\n\t\t\tcalendarBooking.getCalendarId());\n\n\t\tlong parentCalendarBookingId =\n\t\t\tCalendarBookingConstants.PARENT_CALENDAR_BOOKING_ID_DEFAULT;\n\n\t\tif (!calendarBooking.isMasterBooking()) {\n\t\t\tString parentCalendarBookingPath =\n\t\t\t\tExportImportPathUtil.getModelPath(\n\t\t\t\t\tportletDataContext, CalendarBooking.class.getName(),\n\t\t\t\t\tcalendarBooking.getParentCalendarBookingId());\n\n\t\t\tCalendarBooking parentCalendarBooking =\n\t\t\t\t(CalendarBooking)portletDataContext.getZipEntryAsObject(\n\t\t\t\t\tparentCalendarBookingPath);\n\n\t\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\t\tportletDataContext, parentCalendarBooking);\n\n\t\t\tMap<Long, Long> calendarBookingIds =\n\t\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\t\tCalendarBooking.class);\n\n\t\t\tparentCalendarBookingId = MapUtil.getLong(\n\t\t\t\tcalendarBookingIds,\n\t\t\t\tcalendarBooking.getParentCalendarBookingId(),\n\t\t\t\tcalendarBooking.getParentCalendarBookingId());\n\t\t}\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarBooking);\n\n\t\tCalendarBooking importedCalendarBooking = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarBooking existingCalendarBooking =\n\t\t\t\tCalendarBookingLocalServiceUtil.\n\t\t\t\t\tfetchCalendarBookingByUuidAndGroupId(\n\t\t\t\t\t\tcalendarBooking.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarBooking == null) {\n\t\t\t\tserviceContext.setUuid(calendarBooking.getUuid());\n\n\t\t\t\timportedCalendarBooking =\n\t\t\t\t\tCalendarBookingLocalServiceUtil.addCalendarBooking(\n\t\t\t\t\t\tuserId, calendarId, new long[0],\n\t\t\t\t\t\tparentCalendarBookingId, calendarBooking.getTitleMap(),\n\t\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\t\tcalendarBooking.getEndTime(),\n\t\t\t\t\t\tcalendarBooking.isAllDay(),\n\t\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminderType(),\n\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarBooking =\n\t\t\t\t\tCalendarBookingLocalServiceUtil.updateCalendarBooking(\n\t\t\t\t\t\tuserId, existingCalendarBooking.getCalendarBookingId(),\n\t\t\t\t\t\tcalendarId, calendarBooking.getTitleMap(),\n\t\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\t\tcalendarBooking.getEndTime(),\n\t\t\t\t\t\tcalendarBooking.isAllDay(),\n\t\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminderType(),\n\t\t\t\t\t\tcalendarBooking.getStatus(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarBooking =\n\t\t\t\tCalendarBookingLocalServiceUtil.addCalendarBooking(\n\t\t\t\t\tuserId, calendarId, new long[0], parentCalendarBookingId,\n\t\t\t\t\tcalendarBooking.getTitleMap(),\n\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\tcalendarBooking.getEndTime(), calendarBooking.isAllDay(),\n\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\tcalendarBooking.getSecondReminderType(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarBooking, importedCalendarBooking);\n\t}","id":14113,"modified_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarBooking calendarBooking)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarBooking.getUserUuid());\n\n\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\tportletDataContext, calendarBooking, Calendar.class);\n\n\t\tMap<Long, Long> calendarIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendar.class);\n\n\t\tlong calendarId = MapUtil.getLong(\n\t\t\tcalendarIds, calendarBooking.getCalendarId(),\n\t\t\tcalendarBooking.getCalendarId());\n\n\t\tlong parentCalendarBookingId =\n\t\t\tCalendarBookingConstants.PARENT_CALENDAR_BOOKING_ID_DEFAULT;\n\n\t\tif (!calendarBooking.isMasterBooking()) {\n\t\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\t\tportletDataContext, calendarBooking, CalendarBooking.class);\n\n\t\t\tMap<Long, Long> calendarBookingIds =\n\t\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\t\tCalendarBooking.class);\n\n\t\t\tparentCalendarBookingId = MapUtil.getLong(\n\t\t\t\tcalendarBookingIds,\n\t\t\t\tcalendarBooking.getParentCalendarBookingId(),\n\t\t\t\tcalendarBooking.getParentCalendarBookingId());\n\t\t}\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarBooking);\n\n\t\tCalendarBooking importedCalendarBooking = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarBooking existingCalendarBooking =\n\t\t\t\tCalendarBookingLocalServiceUtil.\n\t\t\t\t\tfetchCalendarBookingByUuidAndGroupId(\n\t\t\t\t\t\tcalendarBooking.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarBooking == null) {\n\t\t\t\tserviceContext.setUuid(calendarBooking.getUuid());\n\n\t\t\t\timportedCalendarBooking =\n\t\t\t\t\tCalendarBookingLocalServiceUtil.addCalendarBooking(\n\t\t\t\t\t\tuserId, calendarId, new long[0],\n\t\t\t\t\t\tparentCalendarBookingId, calendarBooking.getTitleMap(),\n\t\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\t\tcalendarBooking.getEndTime(),\n\t\t\t\t\t\tcalendarBooking.isAllDay(),\n\t\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminderType(),\n\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarBooking =\n\t\t\t\t\tCalendarBookingLocalServiceUtil.updateCalendarBooking(\n\t\t\t\t\t\tuserId, existingCalendarBooking.getCalendarBookingId(),\n\t\t\t\t\t\tcalendarId, calendarBooking.getTitleMap(),\n\t\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\t\tcalendarBooking.getEndTime(),\n\t\t\t\t\t\tcalendarBooking.isAllDay(),\n\t\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\t\tcalendarBooking.getSecondReminderType(),\n\t\t\t\t\t\tcalendarBooking.getStatus(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarBooking =\n\t\t\t\tCalendarBookingLocalServiceUtil.addCalendarBooking(\n\t\t\t\t\tuserId, calendarId, new long[0], parentCalendarBookingId,\n\t\t\t\t\tcalendarBooking.getTitleMap(),\n\t\t\t\t\tcalendarBooking.getDescriptionMap(),\n\t\t\t\t\tcalendarBooking.getLocation(),\n\t\t\t\t\tcalendarBooking.getStartTime(),\n\t\t\t\t\tcalendarBooking.getEndTime(), calendarBooking.isAllDay(),\n\t\t\t\t\tcalendarBooking.getRecurrence(),\n\t\t\t\t\tcalendarBooking.getFirstReminder(),\n\t\t\t\t\tcalendarBooking.getFirstReminderType(),\n\t\t\t\t\tcalendarBooking.getSecondReminder(),\n\t\t\t\t\tcalendarBooking.getSecondReminderType(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarBooking, importedCalendarBooking);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarNotificationTemplate calendarNotificationTemplate)\n\t\tthrows Exception {\n\n\t\tCalendar calendar = CalendarLocalServiceUtil.getCalendar(\n\t\t\tcalendarNotificationTemplate.getCalendarId());\n\n\t\tStagedModelDataHandlerUtil.exportStagedModel(\n\t\t\tportletDataContext, calendar);\n\n\t\tElement calendarNotificationTemplateElement =\n\t\t\tportletDataContext.getExportDataElement(\n\t\t\t\tcalendarNotificationTemplate);\n\n\t\tString body = ExportImportHelperUtil.replaceExportContentReferences(\n\t\t\tportletDataContext, calendarNotificationTemplate,\n\t\t\tcalendarNotificationTemplateElement,\n\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\tportletDataContext.getBooleanParameter(\n\t\t\t\tCalendarPortletDataHandler.NAMESPACE, \"referenced-content\"));\n\n\t\tcalendarNotificationTemplate.setBody(body);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarNotificationTemplateElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarNotificationTemplate),\n\t\t\tcalendarNotificationTemplate);\n\t}","id":14114,"modified_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarNotificationTemplate calendarNotificationTemplate)\n\t\tthrows Exception {\n\n\t\tCalendar calendar = CalendarLocalServiceUtil.getCalendar(\n\t\t\tcalendarNotificationTemplate.getCalendarId());\n\n\t\tStagedModelDataHandlerUtil.exportReferenceStagedModel(\n\t\t\tportletDataContext, calendarNotificationTemplate, calendar,\n\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG);\n\n\t\tElement calendarNotificationTemplateElement =\n\t\t\tportletDataContext.getExportDataElement(\n\t\t\t\tcalendarNotificationTemplate);\n\n\t\tString body = ExportImportHelperUtil.replaceExportContentReferences(\n\t\t\tportletDataContext, calendarNotificationTemplate,\n\t\t\tcalendarNotificationTemplateElement,\n\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\tportletDataContext.getBooleanParameter(\n\t\t\t\tCalendarPortletDataHandler.NAMESPACE, \"referenced-content\"));\n\n\t\tcalendarNotificationTemplate.setBody(body);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarNotificationTemplateElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarNotificationTemplate),\n\t\t\tcalendarNotificationTemplate);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarNotificationTemplate calendarNotificationTemplate)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarNotificationTemplate.getUserUuid());\n\n\t\tString calendarPath = ExportImportPathUtil.getModelPath(\n\t\t\tportletDataContext, Calendar.class.getName(),\n\t\t\tcalendarNotificationTemplate.getCalendarId());\n\n\t\tCalendar calendar = (Calendar)portletDataContext.getZipEntryAsObject(\n\t\t\tcalendarPath);\n\n\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\tportletDataContext, calendar);\n\n\t\tMap<Long, Long> calendarIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendar.class);\n\n\t\tlong calendarId = MapUtil.getLong(\n\t\t\tcalendarIds, calendarNotificationTemplate.getCalendarId(),\n\t\t\tcalendarNotificationTemplate.getCalendarId());\n\n\t\tNotificationType notificationType = NotificationType.parse(\n\t\t\tcalendarNotificationTemplate.getNotificationType());\n\t\tNotificationTemplateType notificationTemplateType =\n\t\t\tNotificationTemplateType.parse(\n\t\t\t\tcalendarNotificationTemplate.getNotificationTemplateType());\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarNotificationTemplate);\n\n\t\tCalendarNotificationTemplate importedCalendarNotificationTemplate =\n\t\t\tnull;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarNotificationTemplate existingCalendarNotificationTemplate =\n\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\tfetchCalendarNotificationTemplateByUuidAndGroupId(\n\t\t\t\t\t\tcalendarNotificationTemplate.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarNotificationTemplate == null) {\n\t\t\t\tserviceContext.setUuid(calendarNotificationTemplate.getUuid());\n\n\t\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\t\taddCalendarNotificationTemplate(\n\t\t\t\t\t\t\tuserId, calendarId, notificationType,\n\t\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\t\tnotificationTemplateType,\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\t\tupdateCalendarNotificationTemplate(\n\t\t\t\t\t\t\texistingCalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetCalendarNotificationTemplateId(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\taddCalendarNotificationTemplate(\n\t\t\t\t\t\tuserId, calendarId, notificationType,\n\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\tnotificationTemplateType,\n\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\tcalendarNotificationTemplate.getBody(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarNotificationTemplate, importedCalendarNotificationTemplate);\n\t}","id":14115,"modified_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarNotificationTemplate calendarNotificationTemplate)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarNotificationTemplate.getUserUuid());\n\n\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\tportletDataContext, calendarNotificationTemplate, Calendar.class);\n\n\t\tMap<Long, Long> calendarIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendar.class);\n\n\t\tlong calendarId = MapUtil.getLong(\n\t\t\tcalendarIds, calendarNotificationTemplate.getCalendarId(),\n\t\t\tcalendarNotificationTemplate.getCalendarId());\n\n\t\tNotificationType notificationType = NotificationType.parse(\n\t\t\tcalendarNotificationTemplate.getNotificationType());\n\t\tNotificationTemplateType notificationTemplateType =\n\t\t\tNotificationTemplateType.parse(\n\t\t\t\tcalendarNotificationTemplate.getNotificationTemplateType());\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarNotificationTemplate);\n\n\t\tCalendarNotificationTemplate importedCalendarNotificationTemplate =\n\t\t\tnull;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarNotificationTemplate existingCalendarNotificationTemplate =\n\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\tfetchCalendarNotificationTemplateByUuidAndGroupId(\n\t\t\t\t\t\tcalendarNotificationTemplate.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarNotificationTemplate == null) {\n\t\t\t\tserviceContext.setUuid(calendarNotificationTemplate.getUuid());\n\n\t\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\t\taddCalendarNotificationTemplate(\n\t\t\t\t\t\t\tuserId, calendarId, notificationType,\n\t\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\t\tnotificationTemplateType,\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\t\tupdateCalendarNotificationTemplate(\n\t\t\t\t\t\t\texistingCalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetCalendarNotificationTemplateId(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\t\tcalendarNotificationTemplate.getBody(),\n\t\t\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarNotificationTemplate =\n\t\t\t\tCalendarNotificationTemplateLocalServiceUtil.\n\t\t\t\t\taddCalendarNotificationTemplate(\n\t\t\t\t\t\tuserId, calendarId, notificationType,\n\t\t\t\t\t\tcalendarNotificationTemplate.\n\t\t\t\t\t\t\tgetNotificationTypeSettings(),\n\t\t\t\t\t\tnotificationTemplateType,\n\t\t\t\t\t\tcalendarNotificationTemplate.getSubject(),\n\t\t\t\t\t\tcalendarNotificationTemplate.getBody(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarNotificationTemplate, importedCalendarNotificationTemplate);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarResource calendarResource)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarResource.getUserUuid());\n\n\t\tList<Element> calendarElements =\n\t\t\tportletDataContext.getReferenceDataElements(\n\t\t\t\tcalendarResource, Calendar.class);\n\n\t\tfor (Element calendarElement : calendarElements) {\n\t\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\t\tportletDataContext, calendarElement);\n\t\t}\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarResource);\n\n\t\tlong classPK = getClassPK(portletDataContext, calendarResource, userId);\n\n\t\tCalendarResource importedCalendarResource = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarResource existingCalendarResource =\n\t\t\t\tCalendarResourceLocalServiceUtil.\n\t\t\t\t\tfetchCalendarResourceByUuidAndGroupId(\n\t\t\t\t\t\tcalendarResource.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarResource == null) {\n\t\t\t\texistingCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.fetchCalendarResource(\n\t\t\t\t\t\tcalendarResource.getClassNameId(), classPK);\n\t\t\t}\n\n\t\t\tif (existingCalendarResource == null) {\n\t\t\t\tserviceContext.setUuid(calendarResource.getUuid());\n\n\t\t\t\timportedCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.addCalendarResource(\n\t\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\t\tcalendarResource.getClassNameId(), classPK,\n\t\t\t\t\t\tcalendarResource.getClassUuid(),\n\t\t\t\t\t\tcalendarResource.getCode(),\n\t\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.updateCalendarResource(\n\t\t\t\t\t\texistingCalendarResource.getCalendarResourceId(),\n\t\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarResource =\n\t\t\t\tCalendarResourceLocalServiceUtil.addCalendarResource(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\tcalendarResource.getClassNameId(), classPK,\n\t\t\t\t\tcalendarResource.getClassUuid(), calendarResource.getCode(),\n\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t}\n\n\t\tupdateCalendars(\n\t\t\tportletDataContext, calendarResource, importedCalendarResource);\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarResource, importedCalendarResource);\n\t}","id":14116,"modified_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarResource calendarResource)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(\n\t\t\tcalendarResource.getUserUuid());\n\n\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\tportletDataContext, calendarResource, Calendar.class);\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendarResource);\n\n\t\tlong classPK = getClassPK(portletDataContext, calendarResource, userId);\n\n\t\tCalendarResource importedCalendarResource = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendarResource existingCalendarResource =\n\t\t\t\tCalendarResourceLocalServiceUtil.\n\t\t\t\t\tfetchCalendarResourceByUuidAndGroupId(\n\t\t\t\t\t\tcalendarResource.getUuid(),\n\t\t\t\t\t\tportletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendarResource == null) {\n\t\t\t\texistingCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.fetchCalendarResource(\n\t\t\t\t\t\tcalendarResource.getClassNameId(), classPK);\n\t\t\t}\n\n\t\t\tif (existingCalendarResource == null) {\n\t\t\t\tserviceContext.setUuid(calendarResource.getUuid());\n\n\t\t\t\timportedCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.addCalendarResource(\n\t\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\t\tcalendarResource.getClassNameId(), classPK,\n\t\t\t\t\t\tcalendarResource.getClassUuid(),\n\t\t\t\t\t\tcalendarResource.getCode(),\n\t\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendarResource =\n\t\t\t\t\tCalendarResourceLocalServiceUtil.updateCalendarResource(\n\t\t\t\t\t\texistingCalendarResource.getCalendarResourceId(),\n\t\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendarResource =\n\t\t\t\tCalendarResourceLocalServiceUtil.addCalendarResource(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\tcalendarResource.getClassNameId(), classPK,\n\t\t\t\t\tcalendarResource.getClassUuid(), calendarResource.getCode(),\n\t\t\t\t\tcalendarResource.getNameMap(),\n\t\t\t\t\tcalendarResource.getDescriptionMap(),\n\t\t\t\t\tcalendarResource.isActive(), serviceContext);\n\t\t}\n\n\t\tupdateCalendars(\n\t\t\tportletDataContext, calendarResource, importedCalendarResource);\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tcalendarResource, importedCalendarResource);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarResource calendarResource)\n\t\tthrows Exception {\n\n\t\tElement calendarResourceElement =\n\t\t\tportletDataContext.getExportDataElement(calendarResource);\n\n\t\tfor (Calendar calendar : calendarResource.getCalendars()) {\n\t\t\tStagedModelDataHandlerUtil.exportStagedModel(\n\t\t\t\tportletDataContext, calendar);\n\n\t\t\tportletDataContext.addReferenceElement(\n\t\t\t\tcalendarResource, calendarResourceElement, calendar,\n\t\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG, false);\n\t\t}\n\n\t\tif (calendarResource.getClassNameId() ==\n\t\t\t\tPortalUtil.getClassNameId(User.class)) {\n\n\t\t\tUser user = UserLocalServiceUtil.getUser(\n\t\t\t\tcalendarResource.getClassPK());\n\n\t\t\tportletDataContext.addReferenceElement(\n\t\t\t\tcalendarResource, calendarResourceElement, user, User.class,\n\t\t\t\tPortletDataContext.REFERENCE_TYPE_DEPENDENCY_DISPOSABLE, true);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarResourceElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarResource),\n\t\t\tcalendarResource);\n\t}","id":14117,"modified_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext,\n\t\t\tCalendarResource calendarResource)\n\t\tthrows Exception {\n\n\t\tElement calendarResourceElement =\n\t\t\tportletDataContext.getExportDataElement(calendarResource);\n\n\t\tfor (Calendar calendar : calendarResource.getCalendars()) {\n\t\t\tStagedModelDataHandlerUtil.exportReferenceStagedModel(\n\t\t\t\tportletDataContext, calendarResource, calendar,\n\t\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG);\n\t\t}\n\n\t\tif (calendarResource.getClassNameId() ==\n\t\t\t\tPortalUtil.getClassNameId(User.class)) {\n\n\t\t\tUser user = UserLocalServiceUtil.getUser(\n\t\t\t\tcalendarResource.getClassPK());\n\n\t\t\tportletDataContext.addReferenceElement(\n\t\t\t\tcalendarResource, calendarResourceElement, user, User.class,\n\t\t\t\tPortletDataContext.REFERENCE_TYPE_DEPENDENCY_DISPOSABLE, true);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarResourceElement,\n\t\t\tExportImportPathUtil.getModelPath(calendarResource),\n\t\t\tcalendarResource);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext, Calendar calendar)\n\t\tthrows Exception {\n\n\t\tStagedModelDataHandlerUtil.exportStagedModel(\n\t\t\tportletDataContext, calendar.getCalendarResource());\n\n\t\tElement calendarElement = portletDataContext.getExportDataElement(\n\t\t\tcalendar);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarElement, ExportImportPathUtil.getModelPath(calendar),\n\t\t\tcalendar);\n\t}","id":14118,"modified_method":"@Override\n\tprotected void doExportStagedModel(\n\t\t\tPortletDataContext portletDataContext, Calendar calendar)\n\t\tthrows Exception {\n\n\t\tStagedModelDataHandlerUtil.exportReferenceStagedModel(\n\t\t\tportletDataContext, calendar, calendar.getCalendarResource(),\n\t\t\tPortletDataContext.REFERENCE_TYPE_STRONG);\n\n\t\tElement calendarElement = portletDataContext.getExportDataElement(\n\t\t\tcalendar);\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tcalendarElement, ExportImportPathUtil.getModelPath(calendar),\n\t\t\tcalendar);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext, Calendar calendar)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(calendar.getUserUuid());\n\n\t\tString calendarResourcePath =\n\t\t\tExportImportPathUtil.getModelPath(\n\t\t\t\tportletDataContext, CalendarResource.class.getName(),\n\t\t\t\tcalendar.getCalendarResourceId());\n\n\t\tCalendarResource calendarResource =\n\t\t\t(CalendarResource)portletDataContext.getZipEntryAsObject(\n\t\t\t\tcalendarResourcePath);\n\n\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\tportletDataContext, calendarResource);\n\n\t\tMap<Long, Long> calendarResourceIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendarResource.class);\n\n\t\tlong calendarResourceId = MapUtil.getLong(\n\t\t\tcalendarResourceIds, calendar.getCalendarResourceId(),\n\t\t\tcalendar.getCalendarResourceId());\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendar);\n\n\t\tCalendar importedCalendar = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendar existingCalendar =\n\t\t\t\tCalendarLocalServiceUtil.fetchCalendarByUuidAndGroupId(\n\t\t\t\t\tcalendar.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendar == null) {\n\t\t\t\tserviceContext.setUuid(calendar.getUuid());\n\n\t\t\t\timportedCalendar = CalendarLocalServiceUtil.addCalendar(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\tcalendarResourceId, calendar.getNameMap(),\n\t\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendar = CalendarLocalServiceUtil.updateCalendar(\n\t\t\t\t\texistingCalendar.getCalendarId(), calendar.getNameMap(),\n\t\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendar = CalendarLocalServiceUtil.addCalendar(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\tcalendarResourceId, calendar.getNameMap(),\n\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(calendar, importedCalendar);\n\t}","id":14119,"modified_method":"@Override\n\tprotected void doImportStagedModel(\n\t\t\tPortletDataContext portletDataContext, Calendar calendar)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(calendar.getUserUuid());\n\n\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\tportletDataContext, CalendarResource.class);\n\n\t\tMap<Long, Long> calendarResourceIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tCalendarResource.class);\n\n\t\tlong calendarResourceId = MapUtil.getLong(\n\t\t\tcalendarResourceIds, calendar.getCalendarResourceId(),\n\t\t\tcalendar.getCalendarResourceId());\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tcalendar);\n\n\t\tCalendar importedCalendar = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tCalendar existingCalendar =\n\t\t\t\tCalendarLocalServiceUtil.fetchCalendarByUuidAndGroupId(\n\t\t\t\t\tcalendar.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingCalendar == null) {\n\t\t\t\tserviceContext.setUuid(calendar.getUuid());\n\n\t\t\t\timportedCalendar = CalendarLocalServiceUtil.addCalendar(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\t\tcalendarResourceId, calendar.getNameMap(),\n\t\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedCalendar = CalendarLocalServiceUtil.updateCalendar(\n\t\t\t\t\texistingCalendar.getCalendarId(), calendar.getNameMap(),\n\t\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedCalendar = CalendarLocalServiceUtil.addCalendar(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(),\n\t\t\t\tcalendarResourceId, calendar.getNameMap(),\n\t\t\t\tcalendar.getDescriptionMap(), calendar.getColor(),\n\t\t\t\tcalendar.isDefaultCalendar(), calendar.isEnableComments(),\n\t\t\t\tcalendar.isEnableRatings(), serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(calendar, importedCalendar);\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected PortletPreferences doProcessImportPortletPreferences(\n\t\t\tPortletDataContext portletDataContext, String portletId,\n\t\t\tPortletPreferences portletPreferences)\n\t\tthrows Exception {\n\n\t\tportletDataContext.importPortletPermissions(RESOURCE_NAME);\n\n\t\tElement recordSetsElement =\n\t\t\tportletDataContext.getImportDataGroupElement(DDLRecordSet.class);\n\n\t\tList<Element> recordSetElements = recordSetsElement.elements();\n\n\t\tElement recordSetElement = recordSetElements.get(0);\n\n\t\tStagedModelDataHandlerUtil.importStagedModel(\n\t\t\tportletDataContext, recordSetElement);\n\n\t\tMap<Long, Long> templateIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMTemplate.class);\n\n\t\tlong importedFormDDMTemplateId = GetterUtil.getLong(\n\t\t\tportletPreferences.getValue(\"formDDMTemplateId\", null));\n\n\t\tlong formDDMTemplateId = MapUtil.getLong(\n\t\t\ttemplateIds, importedFormDDMTemplateId, importedFormDDMTemplateId);\n\n\t\tportletPreferences.setValue(\n\t\t\t\"formDDMTemplateId\", String.valueOf(formDDMTemplateId));\n\n\t\tlong importedRecordSetId = GetterUtil.getLong(\n\t\t\tportletPreferences.getValue(\"recordSetId\", null));\n\n\t\tMap<Long, Long> recordSetIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDLRecordSet.class);\n\n\t\tlong recordSetId = MapUtil.getLong(\n\t\t\trecordSetIds, importedRecordSetId, importedRecordSetId);\n\n\t\tportletPreferences.setValue(\"recordSetId\", String.valueOf(recordSetId));\n\n\t\treturn portletPreferences;\n\t}","id":14120,"modified_method":"@Override\n\tprotected PortletPreferences doProcessImportPortletPreferences(\n\t\t\tPortletDataContext portletDataContext, String portletId,\n\t\t\tPortletPreferences portletPreferences)\n\t\tthrows Exception {\n\n\t\tportletDataContext.importPortletPermissions(RESOURCE_NAME);\n\n\t\tStagedModelDataHandlerUtil.importReferenceStagedModels(\n\t\t\tportletDataContext, DDLRecordSet.class);\n\n\t\tMap<Long, Long> templateIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMTemplate.class);\n\n\t\tlong importedFormDDMTemplateId = GetterUtil.getLong(\n\t\t\tportletPreferences.getValue(\"formDDMTemplateId\", null));\n\n\t\tlong formDDMTemplateId = MapUtil.getLong(\n\t\t\ttemplateIds, importedFormDDMTemplateId, importedFormDDMTemplateId);\n\n\t\tportletPreferences.setValue(\n\t\t\t\"formDDMTemplateId\", String.valueOf(formDDMTemplateId));\n\n\t\tlong importedRecordSetId = GetterUtil.getLong(\n\t\t\tportletPreferences.getValue(\"recordSetId\", null));\n\n\t\tMap<Long, Long> recordSetIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDLRecordSet.class);\n\n\t\tlong recordSetId = MapUtil.getLong(\n\t\t\trecordSetIds, importedRecordSetId, importedRecordSetId);\n\n\t\tportletPreferences.setValue(\"recordSetId\", String.valueOf(recordSetId));\n\n\t\treturn portletPreferences;\n\t}","commit_id":"31d693a55d4599bbdb6026299411853e539e0422","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"public void sendData(LiveMonitoringData data) {\n\t\tString st = settings.LIVE_MONITORING_URL.get();\n\t\tList<String> prm = new ArrayList<String>();\n\t\tint maxLen = 0;\n\t\tfor(int i = 0; i < 7; i++) {\n\t\t\tboolean b = st.contains(\"{\"+i+\"}\");\n\t\t\tif(b) {\n\t\t\t\tmaxLen = i;\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < maxLen + 1; i++) {\n\t\t\tswitch (i) {\n\t\t\tcase 0:\n\t\t\t\tprm.add(data.lat + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tprm.add(data.lon + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\tprm.add(data.time + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 3:\n\t\t\t\tprm.add(data.hdop + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 4:\n\t\t\t\tprm.add(data.alt + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 5:\n\t\t\t\tprm.add(data.speed + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 6:\n\t\t\t\tprm.add(data.bearing + \"\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tString url = MessageFormat.format(st, prm.toArray());\n\t\ttry {\n\n\t\t\tHttpParams params = new BasicHttpParams();\n\t\t\tHttpConnectionParams.setConnectionTimeout(params, 15000);\n\t\t\tDefaultHttpClient httpclient = new DefaultHttpClient(params);\n\t\t\t//allow certificates where hostnames doesn't match CN\n\t\t\tSSLSocketFactory sf = (SSLSocketFactory) httpclient.getConnectionManager().getSchemeRegistry().getScheme(\"https\").getSocketFactory();\n\t\t\tsf.setHostnameVerifier(new AllowAllHostnameVerifier());\n\t\t\t// Parse the URL and let the URI constructor handle proper encoding of special characters such as spaces\n\t\t\tURL u = new URL(url);\n\t\t\tURI uri = new URI(u.getProtocol(), u.getUserInfo(), u.getHost(), u.getPort(), u.getPath(), u.getQuery(), u.getRef());\n\t\t\tHttpRequestBase method = new HttpGet(uri);\n\t\t\tlog.info(\"Monitor \" + uri);\n\t\t\tHttpResponse response = httpclient.execute(method);\n\t\t\t\n\t\t\tif(response.getStatusLine() == null || \n\t\t\t\tresponse.getStatusLine().getStatusCode() != 200){\n\t\t\t\t\n\t\t\t\tString msg;\n\t\t\t\tif(response.getStatusLine() == null){\n\t\t\t\t\tmsg = ctx.getString(R.string.failed_op); //$NON-NLS-1$\n\t\t\t\t} else {\n\t\t\t\t\tmsg = response.getStatusLine().getStatusCode() + \" : \" + //$NON-NLS-1$//$NON-NLS-2$\n\t\t\t\t\t\t\tresponse.getStatusLine().getReasonPhrase();\n\t\t\t\t}\n\t\t\t\tlog.error(\"Error sending monitor request: \" +  msg);\n\t\t\t} else {\n\t\t\t\tInputStream is = response.getEntity().getContent();\n\t\t\t\tStringBuilder responseBody = new StringBuilder();\n\t\t\t\tif (is != null) {\n\t\t\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(is, \"UTF-8\")); //$NON-NLS-1$\n\t\t\t\t\tString s;\n\t\t\t\t\twhile ((s = in.readLine()) != null) {\n\t\t\t\t\t\tresponseBody.append(s);\n\t\t\t\t\t\tresponseBody.append(\"\\n\"); //$NON-NLS-1$\n\t\t\t\t\t}\n\t\t\t\t\tis.close();\n\t\t\t\t}\n\t\t\t\thttpclient.getConnectionManager().shutdown();\n\t\t\t\tlog.info(\"Monitor response (\" + response.getFirstHeader(\"Content-Type\") + \"): \" + responseBody.toString());\n\t\t\t}\n\n\t\t\t\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed connect to \" + url + \": \" + e.getMessage(), e);\n\t\t}\n\t}","id":14121,"modified_method":"public void sendData(LiveMonitoringData data) {\n\t\tString st = settings.LIVE_MONITORING_URL.get();\n\t\tList<String> prm = new ArrayList<String>();\n\t\tint maxLen = 0;\n\t\tfor(int i = 0; i < 7; i++) {\n\t\t\tboolean b = st.contains(\"{\"+i+\"}\");\n\t\t\tif(b) {\n\t\t\t\tmaxLen = i;\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < maxLen + 1; i++) {\n\t\t\tswitch (i) {\n\t\t\tcase 0:\n\t\t\t\tprm.add(data.lat + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tprm.add(data.lon + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\tprm.add(data.time + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 3:\n\t\t\t\tprm.add(data.hdop + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 4:\n\t\t\t\tprm.add(data.alt + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 5:\n\t\t\t\tprm.add(data.speed + \"\");\n\t\t\t\tbreak;\n\t\t\tcase 6:\n\t\t\t\tprm.add(data.bearing + \"\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tString urlStr = MessageFormat.format(st, prm.toArray());\n\t\ttry {\n\n\t\t\t// Parse the URL and let the URI constructor handle proper encoding of special characters such as spaces\n\t\t\tURL url = new URL(urlStr);\n\t\t\tHttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();\n\t\t\tURI uri = new URI(url.getProtocol(), url.getUserInfo(), url.getHost(), url.getPort(),\n\t\t\t\t\t\turl.getPath(), url.getQuery(), url.getRef());\n\n\t\t\turlConnection.setConnectTimeout(15000);\n\t\t\turlConnection.setReadTimeout(15000);\n\n\t\t\t// allow certificates where hostnames doesn't match CN\n\t\t\tif (url.getProtocol() == \"https\") {\n\t\t\t\t((HttpsURLConnection) urlConnection).setHostnameVerifier(\n\t\t\t\t\t\tnew HostnameVerifier() {\n\t\t\t\t\t\t\tpublic boolean verify(String host, SSLSession session) {\n\t\t\t\t\t\t\t\treturn (true);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t}\n\n\t\t\tlog.info(\"Monitor \" + uri);\n\n\t\t\tif (urlConnection.getResponseCode() != 200) {\n\n\t\t\t\tString msg = urlConnection.getResponseCode() + \" : \" + //$NON-NLS-1$//$NON-NLS-2$\n\t\t\t\t\t\turlConnection.getResponseMessage();\n\t\t\t\tlog.error(\"Error sending monitor request: \" +  msg);\n\t\t\t} else {\n\t\t\t\tInputStream is = urlConnection.getInputStream();\n\t\t\t\tStringBuilder responseBody = new StringBuilder();\n\t\t\t\tif (is != null) {\n\t\t\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(is, \"UTF-8\")); //$NON-NLS-1$\n\t\t\t\t\tString s;\n\t\t\t\t\twhile ((s = in.readLine()) != null) {\n\t\t\t\t\t\tresponseBody.append(s);\n\t\t\t\t\t\tresponseBody.append(\"\\n\"); //$NON-NLS-1$\n\t\t\t\t\t}\n\t\t\t\t\tis.close();\n\t\t\t\t}\n\t\t\t\tlog.info(\"Monitor response (\" + urlConnection.getHeaderField(\"Content-Type\") + \"): \" + responseBody.toString());\n\t\t\t}\n\n\t\t\turlConnection.disconnect();\n\t\t\t\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed connect to \" + urlStr + \": \" + e.getMessage(), e);\n\t\t}\n\t}","commit_id":"1358e3fe5832fa6c1febf8966d2b1348c7c92683","url":"https://github.com/osmandapp/Osmand"},{"original_method":"public SessionInfo prepareSessionToken() throws IOException {\n\t\tString deviceKey = app.getSettings().OSMO_DEVICE_KEY.get();\n\t\tif(deviceKey.length() == 0) {\n\t\t\tdeviceKey = registerOsmoDeviceKey();\n\t\t}\n\t\tHttpClient httpclient = new DefaultHttpClient();\n\t\tHttpPost httppost = new HttpPost(plugin.useHttps()? HTTPS_API_PREPARE : HTTP_API_PREPARE);\n\t\ttry {\n\t\t\t// Add your data\n\t\t\tList<NameValuePair> nameValuePairs = new ArrayList<NameValuePair>(2);\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"app\", Version.getFullVersion(app)));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"key\", deviceKey));\n\t\t\tif(app.getSettings().OSMO_USER_PWD.get() != null) {\n\t\t\t\tnameValuePairs.add(new BasicNameValuePair(\"auth\", app.getSettings().OSMO_USER_PWD.get()));\n\t\t\t}\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"protocol\", \"1\"));\n\t\t\thttppost.setEntity(new UrlEncodedFormEntity(nameValuePairs));\n\n\t\t\t// Execute HTTP Post Request\n\t\t\tHttpResponse response = httpclient.execute(httppost);\n\t\t\tInputStream cm = response.getEntity().getContent();\n\t\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(cm));\n\t\t\tString r = reader.readLine();\n\t\t\treader.close();\n\t\t\tlog.info(\"Authorization key : \" + r);\n\t\t\tfinal JSONObject obj = new JSONObject(r);\n\t\t\tif(obj.has(\"error\")) {\n\t\t\t\tlastRegistrationError = obj.getString(\"error\");\n\t\t\t\trunNotification(lastRegistrationError);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tif(!obj.has(\"address\")) {\n\t\t\t\tlastRegistrationError = \"Host name not specified\";\n\t\t\t\tthrow new RuntimeException(\"Host name not specified\");\n\t\t\t}\n\t\t\tif(!obj.has(\"token\")) {\n\t\t\t\tlastRegistrationError = \"Token not specified by server\";\n\t\t\t\tthrow new RuntimeException(\"Token not specified by server\");\n\t\t\t}\n\t\t\t\n\t\t\tSessionInfo si = new SessionInfo();\n\t\t\tString a = obj.getString(\"address\");\n\t\t\tif(obj.has(\"name\")) {\n\t\t\t\tsi.username = obj.getString(\"name\");\n\t\t\t}\n\t\t\tif(obj.has(\"uid\")) {\n\t\t\t\tsi.uid = obj.getString(\"uid\");\n\t\t\t}\n\t\t\tint i = a.indexOf(':');\n\t\t\tsi.hostName = a.substring(0, i);\n\t\t\tsi.port = a.substring(i + 1);\n\t\t\tsi.token = obj.getString(\"token\");\n\t\t\treturn si;\n\t\t} catch (ClientProtocolException e) {\n\t\t\tthrow new IOException(e);\n\t\t} catch (IOException e) {\n\t\t\tthrow e;\n\t\t} catch (JSONException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","id":14122,"modified_method":"public SessionInfo prepareSessionToken() throws IOException {\n\t\tString deviceKey = app.getSettings().OSMO_DEVICE_KEY.get();\n\t\tif (deviceKey.length() == 0) {\n\t\t\tdeviceKey = registerOsmoDeviceKey();\n\t\t}\n\n\t\tURL url = new URL(plugin.useHttps() ? HTTPS_API_PREPARE : HTTP_API_PREPARE);\n\t\tHttpURLConnection conn = (HttpURLConnection) url.openConnection();\n\t\ttry {\n\t\t\tconn.setDoOutput(true);\n\t\t\tHttpPostWriter postWriter = new HttpPostWriter(conn.getOutputStream());\n\n\t\t\t// Add your data\n\t\t\tpostWriter.addPair(\"app\", Version.getFullVersion(app));\n\t\t\tpostWriter.addPair(\"key\", deviceKey);\n\t\t\tif (app.getSettings().OSMO_USER_PWD.get() != null) {\n\t\t\t\tpostWriter.addPair(\"auth\", app.getSettings().OSMO_USER_PWD.get());\n\t\t\t}\n\t\t\tpostWriter.addPair(\"protocol\", \"1\");\n\n\t\t\t// Execute HTTP Post Request\n\t\t\tpostWriter.flush();\n\t\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(conn.getInputStream()));\n\t\t\tString r = reader.readLine();\n\t\t\treader.close();\n\t\t\tconn.disconnect();\n\t\t\tlog.info(\"Authorization key : \" + r);\n\t\t\tfinal JSONObject obj = new JSONObject(r);\n\t\t\tif (obj.has(\"error\")) {\n\t\t\t\tlastRegistrationError = obj.getString(\"error\");\n\t\t\t\trunNotification(lastRegistrationError);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tif (!obj.has(\"address\")) {\n\t\t\t\tlastRegistrationError = \"Host name not specified\";\n\t\t\t\tthrow new RuntimeException(\"Host name not specified\");\n\t\t\t}\n\t\t\tif (!obj.has(\"token\")) {\n\t\t\t\tlastRegistrationError = \"Token not specified by server\";\n\t\t\t\tthrow new RuntimeException(\"Token not specified by server\");\n\t\t\t}\n\n\t\t\tSessionInfo si = new SessionInfo();\n\t\t\tString a = obj.getString(\"address\");\n\t\t\tif (obj.has(\"name\")) {\n\t\t\t\tsi.username = obj.getString(\"name\");\n\t\t\t}\n\t\t\tif (obj.has(\"uid\")) {\n\t\t\t\tsi.uid = obj.getString(\"uid\");\n\t\t\t}\n\t\t\tint i = a.indexOf(':');\n\t\t\tsi.hostName = a.substring(0, i);\n\t\t\tsi.port = a.substring(i + 1);\n\t\t\tsi.token = obj.getString(\"token\");\n\t\t\treturn si;\n\t\t} catch (IOException e) {\n\t\t\tthrow e;\n\t\t} catch (JSONException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","commit_id":"1358e3fe5832fa6c1febf8966d2b1348c7c92683","url":"https://github.com/osmandapp/Osmand"},{"original_method":"public String registerOsmoDeviceKey() throws IOException {\n\t\tHttpClient httpclient = new DefaultHttpClient();\n\t\tHttpPost httppost = new HttpPost(plugin.useHttps()? HTTPS_AUTH : HTTP_AUTH);\n\t\ttry {\n\t\t\t// Add your data\n\t\t\tList<NameValuePair> nameValuePairs = new ArrayList<NameValuePair>(2);\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"android_id\",\n\t\t\t\t\tSecure.getString(app.getContentResolver(),\n                            Secure.ANDROID_ID)));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"android_model\", Build.MODEL));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"imei\", \"0\"));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"android_product\", Build.PRODUCT));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"client\", Version.getFullVersion(app)));\n\t\t\tnameValuePairs.add(new BasicNameValuePair(\"osmand\", Version.getFullVersion(app)));\n\t\t\thttppost.setEntity(new UrlEncodedFormEntity(nameValuePairs));\n\n\t\t\t// Execute HTTP Post Request\n\t\t\tHttpResponse response = httpclient.execute(httppost);\n\t\t\tInputStream cm = response.getEntity().getContent();\n\t\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(cm));\n\t\t\tString r = reader.readLine();\n\t\t\treader.close();\n\t\t\tlog.info(\"Authorization key : \" + r);\n\t\t\tfinal JSONObject obj = new JSONObject(r);\n\t\t\tif(obj.has(\"error\")) {\n\t\t\t\tlastRegistrationError = obj.getString(\"error\");\n\t\t\t\tthrow new RuntimeException(obj.getString(\"error\"));\n\t\t\t}\n\t\t\tapp.getSettings().OSMO_DEVICE_KEY.set(obj.getString(\"key\"));\n\t\t\treturn obj.getString(\"key\");\n\t\t} catch (JSONException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","id":14123,"modified_method":"public String registerOsmoDeviceKey() throws IOException {\n\t\tURL url = new URL(plugin.useHttps()? HTTPS_AUTH : HTTP_AUTH);\n\n\t\ttry {\n\t\t\tHttpURLConnection conn = (HttpURLConnection) url.openConnection();\n\t\t\tconn.setDoOutput(true);\n\n\t\t\t// Add your data\n\t\t\tHttpPostWriter postWriter = new HttpPostWriter(conn.getOutputStream());\n\t\t\tpostWriter.addPair(\"android_id\", Secure.getString(app.getContentResolver(),\n\t\t\t\t\tSecure.ANDROID_ID));\n\n\t\t\tpostWriter.addPair(\"android_model\", Build.MODEL);\n\t\t\tpostWriter.addPair(\"imei\", \"0\");\n\t\t\tpostWriter.addPair(\"android_product\", Build.PRODUCT);\n\t\t\tpostWriter.addPair(\"client\", Version.getFullVersion(app));\n\t\t\tpostWriter.addPair(\"osmand\", Version.getFullVersion(app));\n\n\t\t\t// Execute HTTP Post Request\n\t\t\tpostWriter.flush();\n\t\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(conn.getInputStream()));\n\t\t\tString r = reader.readLine();\n\t\t\treader.close();\n\t\t\tconn.disconnect();\n\t\t\tlog.info(\"Authorization key : \" + r);\n\t\t\tfinal JSONObject obj = new JSONObject(r);\n\t\t\tif(obj.has(\"error\")) {\n\t\t\t\tlastRegistrationError = obj.getString(\"error\");\n\t\t\t\tthrow new RuntimeException(obj.getString(\"error\"));\n\t\t\t}\n\t\t\tapp.getSettings().OSMO_DEVICE_KEY.set(obj.getString(\"key\"));\n\t\t\treturn obj.getString(\"key\");\n\t\t} catch (JSONException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","commit_id":"1358e3fe5832fa6c1febf8966d2b1348c7c92683","url":"https://github.com/osmandapp/Osmand"},{"original_method":"public static void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                verifyNode( node, otherNode, refDb, otherDb );\n                otherNodes.remove( otherNode );\n            }\n            assertTrue( otherNodes.isEmpty() );\n        }\n    }","id":14124,"modified_method":"public void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            int vNodeCount = 0;\n            int vRelCount = 0;\n            int vNodePropCount = 0;\n            int vRelPropCount = 0;\n            int vNodeIndexPropCount = 0;\n            \n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                int[] counts = verifyNode( node, otherNode, refDb, otherDb );\n                vRelCount += counts[0];\n                vNodePropCount += counts[1];\n                vRelPropCount += counts[2];\n                vNodeIndexPropCount += counts[3];\n                otherNodes.remove( otherNode );\n                vNodeCount++;\n            }\n            assertTrue( otherNodes.isEmpty() );\n            \n            if ( expectsResults )\n            {\n                assertEquals( nodeCount, vNodeCount );\n                assertEquals( relCount, vRelCount );\n                assertEquals( nodePropCount, vNodePropCount );\n                assertEquals( relPropCount, vRelPropCount );\n                assertEquals( nodeIndexPropCount, vNodeIndexPropCount );\n            }\n        }\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","id":14125,"modified_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","id":14126,"modified_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        setExpectedResults( 3, 2, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n    }","id":14127,"modified_method":"private static int verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        int count = 0;\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n            count++;\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","id":14128,"modified_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","id":14129,"modified_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        setExpectedResults( 2, 0, 1, 0, 1 );\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","id":14130,"modified_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        setExpectedResults( 1, 0, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n    }","id":14131,"modified_method":"private static int verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        int count = 0;\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return count;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        count = otherKeys.size();\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","id":14132,"modified_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","id":14133,"modified_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","id":14134,"modified_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        setExpectedResults( 3, 2, 2, 2, 0 );\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        verifyProperties( node, otherNode );\n        verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n    }","id":14135,"modified_method":"private static int[] verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        int vNodePropCount = verifyProperties( node, otherNode );\n        int vNodeIndexPropCount = verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        int vRelCount = 0;\n        int vRelPropCount = 0;\n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            vRelPropCount += verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n            vRelCount++;\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n        return new int[] { vRelCount, vNodePropCount, vRelPropCount, vNodeIndexPropCount };\n    }","commit_id":"593a623aa3b80b899e94d65ed27492e2a3c7b0fe","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","id":14136,"modified_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        setExpectedResults( 1, 0, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","id":14137,"modified_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        setExpectedResults( 2, 0, 1, 0, 1 );\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n    }","id":14138,"modified_method":"private static int verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        int count = 0;\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return count;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        count = otherKeys.size();\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","id":14139,"modified_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","id":14140,"modified_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n    }","id":14141,"modified_method":"private static int verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        int count = 0;\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n            count++;\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","id":14142,"modified_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"public static void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                verifyNode( node, otherNode, refDb, otherDb );\n                otherNodes.remove( otherNode );\n            }\n            assertTrue( otherNodes.isEmpty() );\n        }\n    }","id":14143,"modified_method":"public void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            int vNodeCount = 0;\n            int vRelCount = 0;\n            int vNodePropCount = 0;\n            int vRelPropCount = 0;\n            int vNodeIndexPropCount = 0;\n            \n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                int[] counts = verifyNode( node, otherNode, refDb, otherDb );\n                vRelCount += counts[0];\n                vNodePropCount += counts[1];\n                vRelPropCount += counts[2];\n                vNodeIndexPropCount += counts[3];\n                otherNodes.remove( otherNode );\n                vNodeCount++;\n            }\n            assertTrue( otherNodes.isEmpty() );\n            \n            if ( expectsResults )\n            {\n                assertEquals( nodeCount, vNodeCount );\n                assertEquals( relCount, vRelCount );\n                assertEquals( nodePropCount, vNodePropCount );\n                assertEquals( relPropCount, vRelPropCount );\n                assertEquals( nodeIndexPropCount, vNodeIndexPropCount );\n            }\n        }\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","id":14144,"modified_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        setExpectedResults( 3, 2, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        verifyProperties( node, otherNode );\n        verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n    }","id":14145,"modified_method":"private static int[] verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        int vNodePropCount = verifyProperties( node, otherNode );\n        int vNodeIndexPropCount = verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        int vRelCount = 0;\n        int vRelPropCount = 0;\n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            vRelPropCount += verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n            vRelCount++;\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n        return new int[] { vRelCount, vNodePropCount, vRelPropCount, vNodeIndexPropCount };\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","id":14146,"modified_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        setExpectedResults( 3, 2, 2, 2, 0 );\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","id":14147,"modified_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","commit_id":"73c364e6776f0990416eb8675f9530e9f9b0ba7b","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","id":14148,"modified_method":"@Test\n    public void testMultipleSlaves() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 3 );\n        executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        executeJob( new CommonJobs.SetSubRefPropertyJob( \"name\", \"Hello\" ), 1 );\n        pullUpdates( 0, 2 );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        verifyProperties( node, otherNode );\n        verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n    }","id":14149,"modified_method":"private static int[] verifyNode( Node node, Node otherNode,\n            VerifyDbContext refDb, VerifyDbContext otherDb )\n    {\n        int vNodePropCount = verifyProperties( node, otherNode );\n        int vNodeIndexPropCount = verifyIndex( node, otherNode, refDb, otherDb );\n        Set<Long> otherRelIds = new HashSet<Long>();\n        for ( Relationship otherRel : otherNode.getRelationships( Direction.OUTGOING ) )\n        {\n            otherRelIds.add( otherRel.getId() );\n        }\n        \n        int vRelCount = 0;\n        int vRelPropCount = 0;\n        for ( Relationship rel : node.getRelationships( Direction.OUTGOING ) )\n        {\n            Relationship otherRel = otherDb.db.getRelationshipById( rel.getId() );\n            vRelPropCount += verifyProperties( rel, otherRel );\n            if ( rel.getStartNode().getId() != otherRel.getStartNode().getId() )\n            {\n                throw new RuntimeException( \"Start node differs on \" + rel );\n            }\n            if ( rel.getEndNode().getId() != otherRel.getEndNode().getId() )\n            {\n                throw new RuntimeException( \"End node differs on \" + rel );\n            }\n            if ( !rel.getType().name().equals( otherRel.getType().name() ) )\n            {\n                throw new RuntimeException( \"Type differs on \" + rel );\n            }\n            otherRelIds.remove( rel.getId() );\n            vRelCount++;\n        }\n        \n        if ( !otherRelIds.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more relationships \" +\n                    otherRelIds );\n        }\n        return new int[] { vRelCount, vNodePropCount, vRelPropCount, vNodeIndexPropCount };\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","id":14150,"modified_method":"@Test\n    public void testNodeDeleted() throws Exception\n    {\n        setExpectedResults( 1, 0, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJobOnMaster( new CommonJobs.CreateNodeJob() );\n        pullUpdates();\n        assertTrue( executeJobOnMaster( new CommonJobs.DeleteNodeJob(\n                nodeId.longValue() ) ).booleanValue() );\n        assertFalse( executeJob( new CommonJobs.SetNodePropertyJob( nodeId.longValue(), \"something\",\n                \"some thing\" ), 0 ) );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","id":14151,"modified_method":"@Test\n    public void testMasterConstrainViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 1, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob( CommonJobs.REL_TYPE.name(),\n                \"name\", \"Mattias\" ), 0 );\n        Boolean successful = executeJobOnMaster( new CommonJobs.DeleteNodeJob( nodeId.longValue() ) );\n        assertFalse( successful.booleanValue() );\n        pullUpdates();\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","id":14152,"modified_method":"@Test\n    public void slaveCreateNode() throws Exception\n    {\n        setExpectedResults( 3, 2, 2, 2, 0 );\n        initializeDbs( 1 );\n        executeJob( new CommonJobs.CreateSomeEntitiesJob(), 0 );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","id":14153,"modified_method":"@Test\n    public void createNodeAndIndex() throws Exception\n    {\n        setExpectedResults( 2, 0, 1, 0, 1 );\n        initializeDbs( 1, INDEX_CONFIG );\n        executeJob( new CommonJobs.CreateNodeAndIndexJob(), 0 );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","id":14154,"modified_method":"@Test\n    public void testNoTransaction() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        executeJobOnMaster( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ) );\n        assertFalse( executeJob( new CommonJobs.CreateNodeOutsideOfTxJob(), 0 ).booleanValue() );\n        assertFalse( executeJobOnMaster( new CommonJobs.CreateNodeOutsideOfTxJob() ).booleanValue() );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n    }","id":14155,"modified_method":"private static int verifyProperties( PropertyContainer entity, PropertyContainer otherEntity )\n    {\n        int count = 0;\n        Set<String> otherKeys = IteratorUtil.addToCollection(\n                otherEntity.getPropertyKeys().iterator(), new HashSet<String>() );\n        for ( String key : entity.getPropertyKeys() )\n        {\n            Object value1 = entity.getProperty( key );\n            Object value2 = otherEntity.getProperty( key );\n            if ( !value1.equals( value2 ) )\n            {\n                throw new RuntimeException( entity + \" not equals property '\" + key + \"': \" +\n                        value1 + \", \" + value2 );\n            }\n            otherKeys.remove( key );\n            count++;\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherEntity + \" has more properties: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","id":14156,"modified_method":"@Test\n    public void testSlaveConstraintViolation() throws Exception\n    {\n        setExpectedResults( 2, 1, 0, 1, 0 );\n        initializeDbs( 1 );\n        \n        Long nodeId = executeJob( new CommonJobs.CreateSubRefNodeJob(\n                CommonJobs.REL_TYPE.name(), null, null ), 0 );\n        Boolean successful = executeJob( new CommonJobs.DeleteNodeJob( nodeId.longValue() ), 0 );\n        assertFalse( successful.booleanValue() );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","id":14157,"modified_method":"@Test\n    public void testGetRelationships() throws Exception\n    {\n        setExpectedResults( 3, 2, 0, 0, 0 );\n        initializeDbs( 1 );\n        \n        assertEquals( (Integer) 1, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.CreateSubRefNodeWithRelCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJob( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ), 0 ) );\n        assertEquals( (Integer) 2, executeJobOnMaster( new CommonJobs.GetRelationshipCountJob(\n                CommonJobs.REL_TYPE.name(), CommonJobs.KNOWS.name() ) ) );\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"private static void verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n    }","id":14158,"modified_method":"private static int verifyIndex( Node node, Node otherNode, VerifyDbContext refDb,\n            VerifyDbContext otherDb )\n    {\n        int count = 0;\n        if ( refDb.index == null || otherDb.index == null )\n        {\n            return count;\n        }\n        \n        Set<String> otherKeys = new HashSet<String>();\n        for ( String key : otherNode.getPropertyKeys() )\n        {\n            if ( isIndexed( otherNode, otherDb, key ) )\n            {\n                otherKeys.add( key );\n            }\n        }\n        count = otherKeys.size();\n        \n        for ( String key : node.getPropertyKeys() )\n        {\n            if ( otherKeys.remove( key ) != isIndexed( node, refDb, key ) )\n            {\n                throw new RuntimeException( \"Index differs on \" + node + \", \" + key );\n            }\n        }\n        if ( !otherKeys.isEmpty() )\n        {\n            throw new RuntimeException( \"Other node \" + otherNode + \" has more indexing: \" +\n                    otherKeys );\n        }\n        return count;\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"public static void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                verifyNode( node, otherNode, refDb, otherDb );\n                otherNodes.remove( otherNode );\n            }\n            assertTrue( otherNodes.isEmpty() );\n        }\n    }","id":14159,"modified_method":"public void verify( VerifyDbContext refDb, VerifyDbContext... dbs )\n    {\n        for ( VerifyDbContext otherDb : dbs )\n        {\n            int vNodeCount = 0;\n            int vRelCount = 0;\n            int vNodePropCount = 0;\n            int vRelPropCount = 0;\n            int vNodeIndexPropCount = 0;\n            \n            Set<Node> otherNodes = IteratorUtil.addToCollection( otherDb.db.getAllNodes().iterator(),\n                    new HashSet<Node>() );\n            for ( Node node : refDb.db.getAllNodes() )\n            {\n                Node otherNode = otherDb.db.getNodeById( node.getId() );\n                int[] counts = verifyNode( node, otherNode, refDb, otherDb );\n                vRelCount += counts[0];\n                vNodePropCount += counts[1];\n                vRelPropCount += counts[2];\n                vNodeIndexPropCount += counts[3];\n                otherNodes.remove( otherNode );\n                vNodeCount++;\n            }\n            assertTrue( otherNodes.isEmpty() );\n            \n            if ( expectsResults )\n            {\n                assertEquals( nodeCount, vNodeCount );\n                assertEquals( relCount, vRelCount );\n                assertEquals( nodePropCount, vNodePropCount );\n                assertEquals( relPropCount, vRelPropCount );\n                assertEquals( nodeIndexPropCount, vNodeIndexPropCount );\n            }\n        }\n    }","commit_id":"284bf5665ccddae130e2243a321dd717e0022b74","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Perform recovery on a list of commit log files.\n     *\n     * @param clogs   the list of commit log files to replay\n     * @return the number of mutations replayed\n     */\n    public int recover(File... clogs) throws IOException\n    {\n        try\n        {\n            CommitLogReplayer recovery = new CommitLogReplayer();\n            recovery.recover(clogs);\n            return recovery.blockForWrites();\n        }\n        catch (IOException e)\n        {\n            if (e instanceof UnknownColumnFamilyException)\n                logger.error(\"Commit log replay failed due to replaying a mutation for a missing table. This error can be ignored by providing -Dcassandra.commitlog.stop_on_missing_tables=false on the command line\");\n            if (e instanceof MalformedCommitLogException)\n                logger.error(\"Commit log replay failed due to a non-fatal exception. This error can be ignored by providing -Dcassandra.commitlog.stop_on_errors=false on the command line\");\n            throw e;\n        }\n    }","id":14160,"modified_method":"/**\n     * Perform recovery on a list of commit log files.\n     *\n     * @param clogs   the list of commit log files to replay\n     * @return the number of mutations replayed\n     */\n    public int recover(File... clogs) throws IOException\n    {\n        CommitLogReplayer recovery = new CommitLogReplayer();\n        recovery.recover(clogs);\n        return recovery.blockForWrites();\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@VisibleForTesting\n    public static void writeHeader(ByteBuffer out, CommitLogDescriptor descriptor)\n    {\n        out.putInt(0, descriptor.version);\n        out.putLong(4, descriptor.id);\n        PureJavaCrc32 crc = new PureJavaCrc32();\n        crc.updateInt(descriptor.version);\n        crc.updateInt((int) (descriptor.id & 0xFFFFFFFFL));\n        crc.updateInt((int) (descriptor.id >>> 32));\n        out.putInt(12, crc.getCrc());\n    }","id":14161,"modified_method":"static void writeHeader(ByteBuffer out, CommitLogDescriptor descriptor)\n    {\n        out.putInt(0, descriptor.version);\n        out.putLong(4, descriptor.id);\n        PureJavaCrc32 crc = new PureJavaCrc32();\n        crc.updateInt(descriptor.version);\n        crc.updateInt((int) (descriptor.id & 0xFFFFFFFFL));\n        crc.updateInt((int) (descriptor.id >>> 32));\n        out.putInt(12, crc.getCrc());\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"public void recover(File file) throws IOException\n    {\n        final ReplayFilter replayFilter = ReplayFilter.create();\n        logger.info(\"Replaying {}\", file.getPath());\n        CommitLogDescriptor desc = CommitLogDescriptor.fromFileName(file.getName());\n        final long segmentId = desc.id;\n        logger.info(\"Replaying {} (CL version {}, messaging version {})\",\n                    file.getPath(),\n                    desc.version,\n                    desc.getMessagingVersion());\n        RandomAccessReader reader = RandomAccessReader.open(new File(file.getAbsolutePath()));\n\n        try\n        {\n            assert reader.length() <= Integer.MAX_VALUE;\n            int offset = getStartOffset(segmentId, desc.version);\n            if (offset < 0)\n            {\n                logger.debug(\"skipping replay of fully-flushed {}\", file);\n                return;\n            }\n\n            int prevEnd = CommitLogDescriptor.HEADER_SIZE;\n            main: while (true)\n            {\n\n                int end = prevEnd;\n                if (desc.version < CommitLogDescriptor.VERSION_21)\n                    end = Integer.MAX_VALUE;\n                else\n                {\n                    do { end = readSyncMarker(desc, end, reader); }\n                    while (end < offset && end > prevEnd);\n                }\n\n                if (end < prevEnd)\n                    break;\n\n                if (logger.isDebugEnabled())\n                    logger.debug(\"Replaying {} between {} and {}\", file, offset, end);\n\n                reader.seek(offset);\n\n                 /* read the logs populate Mutation and apply */\n                while (reader.getPosition() < end && !reader.isEOF())\n                {\n                    long mutationStart = reader.getFilePointer();\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"Reading mutation at {}\", mutationStart);\n\n                    long claimedCRC32;\n                    int serializedSize;\n                    try\n                    {\n                        // any of the reads may hit EOF\n                        serializedSize = reader.readInt();\n                        if (serializedSize == LEGACY_END_OF_SEGMENT_MARKER)\n                        {\n                            logger.debug(\"Encountered end of segment marker at {}\", mutationStart);\n                            break main;\n                        }\n\n                        // Mutation must be at LEAST 10 bytes:\n                        // 3 each for a non-empty Keyspace and Key (including the\n                        // 2-byte length from writeUTF/writeWithShortLength) and 4 bytes for column count.\n                        // This prevents CRC by being fooled by special-case garbage in the file; see CASSANDRA-2128\n                        if (serializedSize < 10)\n                        {\n                            if (!IGNORE_ERRORS)\n                                throw new MalformedCommitLogException(\"Too small mutation encountered at position \" + mutationStart);\n                            break main;\n                        }\n\n                        long claimedSizeChecksum;\n                        if (desc.version < CommitLogDescriptor.VERSION_21)\n                            claimedSizeChecksum = reader.readLong();\n                        else\n                            claimedSizeChecksum = reader.readInt() & 0xffffffffL;\n                        checksum.reset();\n                        if (desc.version < CommitLogDescriptor.VERSION_20)\n                            checksum.update(serializedSize);\n                        else\n                            checksum.updateInt(serializedSize);\n\n                        if (checksum.getValue() != claimedSizeChecksum)\n                        {\n                            if (!IGNORE_ERRORS)\n                                throw new IOException(\"Invalid size checksum for mutation at position \" + mutationStart + \" of \" + file);\n                            break main; // entry wasn't synced correctly/fully. that's\n                        }\n                        // ok.\n\n                        if (serializedSize > buffer.length)\n                            buffer = new byte[(int) (1.2 * serializedSize)];\n                        reader.readFully(buffer, 0, serializedSize);\n                        if (desc.version < CommitLogDescriptor.VERSION_21)\n                            claimedCRC32 = reader.readLong();\n                        else\n                            claimedCRC32 = reader.readInt() & 0xffffffffL;\n                    }\n                    catch (EOFException eof)\n                    {\n                        if (!IGNORE_ERRORS)\n                            throw new MalformedCommitLogException(\"Encountered end-of-file unexpectedly\", eof);\n\n                        break main; // last CL entry didn't get completely written. that's ok.\n                    }\n\n                    checksum.update(buffer, 0, serializedSize);\n                    if (claimedCRC32 != checksum.getValue())\n                    {\n                        if (!IGNORE_ERRORS)\n                            throw new IOException(\"Invalid checksum for mutation at position \" + mutationStart + \" of \" + file);\n                        // this entry must not have been fsynced. probably the rest is bad too,\n                        // but just in case there is no harm in trying them (since we still read on an entry boundary)\n                        continue;\n                    }\n\n                    /* deserialize the commit log entry */\n                    FastByteArrayInputStream bufIn = new FastByteArrayInputStream(buffer, 0, serializedSize);\n                    final Mutation mutation;\n                    try\n                    {\n                        mutation = Mutation.serializer.deserialize(new DataInputStream(bufIn),\n                                                                   desc.getMessagingVersion(),\n                                                                   ColumnSerializer.Flag.LOCAL);\n                        // doublecheck that what we read is [still] valid for the current schema\n                        for (ColumnFamily cf : mutation.getColumnFamilies())\n                            for (Cell cell : cf)\n                                cf.getComparator().validate(cell.name());\n                    }\n                    catch (UnknownColumnFamilyException ex)\n                    {\n                        if (!IGNORE_MISSING_TABLES)\n                            throw ex;\n\n                        if (ex.cfId == null)\n                            continue;\n                        AtomicInteger i = invalidMutations.get(ex.cfId);\n                        if (i == null)\n                        {\n                            i = new AtomicInteger(1);\n                            invalidMutations.put(ex.cfId, i);\n                        }\n                        else\n                            i.incrementAndGet();\n                        continue;\n                    }\n                    catch (Throwable t)\n                    {\n                        if (!IGNORE_ERRORS)\n                            throw new MalformedCommitLogException(\"Encountered bad mutation\", t);\n\n                        File f = File.createTempFile(\"mutation\", \"dat\");\n                        try (DataOutputStream out = new DataOutputStream(new FileOutputStream(f)))\n                        {\n                            out.write(buffer, 0, serializedSize);\n                        }\n                        String st = String.format(\"Unexpected error deserializing mutation; saved to %s and ignored.  This may be caused by replaying a mutation against a table with the same name but incompatible schema.  Exception follows: \",\n                                                  f.getAbsolutePath());\n                        logger.error(st, t);\n                        continue;\n                    }\n\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"replaying mutation for {}.{}: {}\", mutation.getKeyspaceName(), ByteBufferUtil.bytesToHex(mutation.key()), \"{\" + StringUtils.join(mutation.getColumnFamilies().iterator(), \", \") + \"}\");\n\n                    final long entryLocation = reader.getFilePointer();\n                    Runnable runnable = new WrappedRunnable()\n                    {\n                        public void runMayThrow() throws IOException\n                        {\n                            if (Schema.instance.getKSMetaData(mutation.getKeyspaceName()) == null)\n                            {\n                                if (!IGNORE_MISSING_TABLES)\n                                    throw new UnknownColumnFamilyException(\"Keyspace for this table is missing\", mutation.getColumnFamilyIds().iterator().next());\n                                return;\n                            }\n                            if (pointInTimeExceeded(mutation))\n                                return;\n\n                            final Keyspace keyspace = Keyspace.open(mutation.getKeyspaceName());\n\n                            // Rebuild the mutation, omitting column families that\n                            //    a) the user has requested that we ignore,\n                            //    b) have already been flushed,\n                            // or c) are part of a cf that was dropped.\n                            // Keep in mind that the cf.name() is suspect. do every thing based on the cfid instead.\n                            Mutation newMutation = null;\n                            for (ColumnFamily columnFamily : replayFilter.filter(mutation))\n                            {\n                                if (Schema.instance.getCF(columnFamily.id()) == null)\n                                {\n                                    if (!IGNORE_MISSING_TABLES)\n                                        throw new UnknownColumnFamilyException(\"Missing table with cfid=\" + columnFamily.id(),\n                                                                               mutation.getColumnFamilyIds().iterator().next());\n                                    continue; // dropped\n                                }\n\n                                ReplayPosition rp = cfPositions.get(columnFamily.id());\n\n                                // replay if current segment is newer than last flushed one or,\n                                // if it is the last known segment, if we are after the replay position\n                                if (segmentId > rp.segment || (segmentId == rp.segment && entryLocation > rp.position))\n                                {\n                                    if (newMutation == null)\n                                        newMutation = new Mutation(mutation.getKeyspaceName(), mutation.key());\n                                    newMutation.add(columnFamily);\n                                    replayedCount.incrementAndGet();\n                                }\n                            }\n                            if (newMutation != null)\n                            {\n                                assert !newMutation.isEmpty();\n                                keyspace.apply(newMutation, false);\n                                keyspacesRecovered.add(keyspace);\n                            }\n                        }\n                    };\n                    futures.add(StageManager.getStage(Stage.MUTATION).submit(runnable));\n                    if (futures.size() > MAX_OUTSTANDING_REPLAY_COUNT)\n                    {\n                        FBUtilities.waitOnFutures(futures);\n                        futures.clear();\n                    }\n                }\n\n                if (desc.version < CommitLogDescriptor.VERSION_21)\n                    break;\n\n                offset = end + CommitLogSegment.SYNC_MARKER_SIZE;\n                prevEnd = end;\n            }\n        }\n        finally\n        {\n            FileUtils.closeQuietly(reader);\n            logger.info(\"Finished reading {}\", file);\n        }\n    }","id":14162,"modified_method":"public void recover(File file) throws IOException\n    {\n        final ReplayFilter replayFilter = ReplayFilter.create();\n        logger.info(\"Replaying {}\", file.getPath());\n        CommitLogDescriptor desc = CommitLogDescriptor.fromFileName(file.getName());\n        final long segmentId = desc.id;\n        logger.info(\"Replaying {} (CL version {}, messaging version {})\",\n                    file.getPath(),\n                    desc.version,\n                    desc.getMessagingVersion());\n        RandomAccessReader reader = RandomAccessReader.open(new File(file.getAbsolutePath()));\n\n        try\n        {\n            assert reader.length() <= Integer.MAX_VALUE;\n            int offset = getStartOffset(segmentId, desc.version);\n            if (offset < 0)\n            {\n                logger.debug(\"skipping replay of fully-flushed {}\", file);\n                return;\n            }\n\n            int prevEnd = CommitLogDescriptor.HEADER_SIZE;\n            main: while (true)\n            {\n\n                int end = prevEnd;\n                if (desc.version < CommitLogDescriptor.VERSION_21)\n                    end = Integer.MAX_VALUE;\n                else\n                {\n                    do { end = readSyncMarker(desc, end, reader); }\n                    while (end < offset && end > prevEnd);\n                }\n\n                if (end < prevEnd)\n                    break;\n\n                if (logger.isDebugEnabled())\n                    logger.debug(\"Replaying {} between {} and {}\", file, offset, end);\n\n                reader.seek(offset);\n\n                 /* read the logs populate Mutation and apply */\n                while (reader.getPosition() < end && !reader.isEOF())\n                {\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"Reading mutation at {}\", reader.getFilePointer());\n\n                    long claimedCRC32;\n                    int serializedSize;\n                    try\n                    {\n                        // any of the reads may hit EOF\n                        serializedSize = reader.readInt();\n                        if (serializedSize == LEGACY_END_OF_SEGMENT_MARKER)\n                        {\n                            logger.debug(\"Encountered end of segment marker at {}\", reader.getFilePointer());\n                            break main;\n                        }\n\n                        // Mutation must be at LEAST 10 bytes:\n                        // 3 each for a non-empty Keyspace and Key (including the\n                        // 2-byte length from writeUTF/writeWithShortLength) and 4 bytes for column count.\n                        // This prevents CRC by being fooled by special-case garbage in the file; see CASSANDRA-2128\n                        if (serializedSize < 10)\n                            break main;\n\n                        long claimedSizeChecksum;\n                        if (desc.version < CommitLogDescriptor.VERSION_21)\n                            claimedSizeChecksum = reader.readLong();\n                        else\n                            claimedSizeChecksum = reader.readInt() & 0xffffffffL;\n                        checksum.reset();\n                        if (desc.version < CommitLogDescriptor.VERSION_20)\n                            checksum.update(serializedSize);\n                        else\n                            checksum.updateInt(serializedSize);\n\n                        if (checksum.getValue() != claimedSizeChecksum)\n                            break main; // entry wasn't synced correctly/fully. that's\n                        // ok.\n\n                        if (serializedSize > buffer.length)\n                            buffer = new byte[(int) (1.2 * serializedSize)];\n                        reader.readFully(buffer, 0, serializedSize);\n                        if (desc.version < CommitLogDescriptor.VERSION_21)\n                            claimedCRC32 = reader.readLong();\n                        else\n                            claimedCRC32 = reader.readInt() & 0xffffffffL;\n                    }\n                    catch (EOFException eof)\n                    {\n                        break main; // last CL entry didn't get completely written. that's ok.\n                    }\n\n                    checksum.update(buffer, 0, serializedSize);\n                    if (claimedCRC32 != checksum.getValue())\n                    {\n                        // this entry must not have been fsynced. probably the rest is bad too,\n                        // but just in case there is no harm in trying them (since we still read on an entry boundary)\n                        continue;\n                    }\n\n                    /* deserialize the commit log entry */\n                    FastByteArrayInputStream bufIn = new FastByteArrayInputStream(buffer, 0, serializedSize);\n                    final Mutation mutation;\n                    try\n                    {\n                        mutation = Mutation.serializer.deserialize(new DataInputStream(bufIn),\n                                                                   desc.getMessagingVersion(),\n                                                                   ColumnSerializer.Flag.LOCAL);\n                        // doublecheck that what we read is [still] valid for the current schema\n                        for (ColumnFamily cf : mutation.getColumnFamilies())\n                            for (Cell cell : cf)\n                                cf.getComparator().validate(cell.name());\n                    }\n                    catch (UnknownColumnFamilyException ex)\n                    {\n                        if (ex.cfId == null)\n                            continue;\n                        AtomicInteger i = invalidMutations.get(ex.cfId);\n                        if (i == null)\n                        {\n                            i = new AtomicInteger(1);\n                            invalidMutations.put(ex.cfId, i);\n                        }\n                        else\n                            i.incrementAndGet();\n                        continue;\n                    }\n                    catch (Throwable t)\n                    {\n                        File f = File.createTempFile(\"mutation\", \"dat\");\n                        DataOutputStream out = new DataOutputStream(new FileOutputStream(f));\n                        try\n                        {\n                            out.write(buffer, 0, serializedSize);\n                        }\n                        finally\n                        {\n                            out.close();\n                        }\n                        String st = String.format(\"Unexpected error deserializing mutation; saved to %s and ignored.  This may be caused by replaying a mutation against a table with the same name but incompatible schema.  Exception follows: \",\n                                                  f.getAbsolutePath());\n                        logger.error(st, t);\n                        continue;\n                    }\n\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"replaying mutation for {}.{}: {}\", mutation.getKeyspaceName(), ByteBufferUtil.bytesToHex(mutation.key()), \"{\" + StringUtils.join(mutation.getColumnFamilies().iterator(), \", \") + \"}\");\n\n                    final long entryLocation = reader.getFilePointer();\n                    Runnable runnable = new WrappedRunnable()\n                    {\n                        public void runMayThrow() throws IOException\n                        {\n                            if (Schema.instance.getKSMetaData(mutation.getKeyspaceName()) == null)\n                                return;\n                            if (pointInTimeExceeded(mutation))\n                                return;\n\n                            final Keyspace keyspace = Keyspace.open(mutation.getKeyspaceName());\n\n                            // Rebuild the mutation, omitting column families that\n                            //    a) the user has requested that we ignore,\n                            //    b) have already been flushed,\n                            // or c) are part of a cf that was dropped.\n                            // Keep in mind that the cf.name() is suspect. do every thing based on the cfid instead.\n                            Mutation newMutation = null;\n                            for (ColumnFamily columnFamily : replayFilter.filter(mutation))\n                            {\n                                if (Schema.instance.getCF(columnFamily.id()) == null)\n                                    continue; // dropped\n\n                                ReplayPosition rp = cfPositions.get(columnFamily.id());\n\n                                // replay if current segment is newer than last flushed one or,\n                                // if it is the last known segment, if we are after the replay position\n                                if (segmentId > rp.segment || (segmentId == rp.segment && entryLocation > rp.position))\n                                {\n                                    if (newMutation == null)\n                                        newMutation = new Mutation(mutation.getKeyspaceName(), mutation.key());\n                                    newMutation.add(columnFamily);\n                                    replayedCount.incrementAndGet();\n                                }\n                            }\n                            if (newMutation != null)\n                            {\n                                assert !newMutation.isEmpty();\n                                Keyspace.open(newMutation.getKeyspaceName()).apply(newMutation, false);\n                                keyspacesRecovered.add(keyspace);\n                            }\n                        }\n                    };\n                    futures.add(StageManager.getStage(Stage.MUTATION).submit(runnable));\n                    if (futures.size() > MAX_OUTSTANDING_REPLAY_COUNT)\n                    {\n                        FBUtilities.waitOnFutures(futures);\n                        futures.clear();\n                    }\n                }\n\n                if (desc.version < CommitLogDescriptor.VERSION_21)\n                    break;\n\n                offset = end + CommitLogSegment.SYNC_MARKER_SIZE;\n                prevEnd = end;\n            }\n        }\n        finally\n        {\n            FileUtils.closeQuietly(reader);\n            logger.info(\"Finished reading {}\", file);\n        }\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"private int readSyncMarker(CommitLogDescriptor descriptor, int offset, RandomAccessReader reader) throws IOException\n    {\n        if (offset > reader.length() - CommitLogSegment.SYNC_MARKER_SIZE)\n        {\n            if (offset != reader.length() && offset != Integer.MAX_VALUE)\n            {\n                String message = String.format(\"Encountered bad header at position %d of Commit log %s; not enough room for a header\", offset, reader.getPath());\n                if (!IGNORE_ERRORS)\n                    throw new MalformedCommitLogException(message);\n                logger.warn(message);\n            }\n            // cannot possibly be a header here. if we're == length(), assume it's a correctly written final segment\n            return -1;\n        }\n        reader.seek(offset);\n        PureJavaCrc32 crc = new PureJavaCrc32();\n        crc.updateInt((int) (descriptor.id & 0xFFFFFFFFL));\n        crc.updateInt((int) (descriptor.id >>> 32));\n        crc.updateInt((int) reader.getPosition());\n        int end = reader.readInt();\n        long filecrc;\n        if (descriptor.version < CommitLogDescriptor.VERSION_21)\n            filecrc = reader.readLong();\n        else\n            filecrc = reader.readInt() & 0xffffffffL;\n        if (crc.getValue() != filecrc)\n        {\n            if (end != 0 || filecrc != 0)\n            {\n                String message = String.format(\"Encountered bad header at position %d of Commit log %s, with invalid CRC. The end of segment marker should be zero.\", offset, reader.getPath());\n                if (!IGNORE_ERRORS)\n                    throw new MalformedCommitLogException(message);\n                logger.warn(message);\n            }\n            return -1;\n        }\n        else if (end < offset || end > reader.length())\n        {\n            String message = String.format(\"Encountered bad header at position %d of Commit log %s, with bad position but valid CRC.\", offset, reader.getPath());\n            if (!IGNORE_ERRORS)\n                throw new MalformedCommitLogException(message);\n            logger.warn(message);\n            return -1;\n        }\n        return end;\n    }","id":14163,"modified_method":"private int readSyncMarker(CommitLogDescriptor descriptor, int offset, RandomAccessReader reader) throws IOException\n    {\n        if (offset > reader.length() - CommitLogSegment.SYNC_MARKER_SIZE)\n        {\n            if (offset != reader.length() && offset != Integer.MAX_VALUE)\n                logger.warn(\"Encountered bad header at position {} of Commit log {}; not enough room for a header\", offset, reader.getPath());\n            // cannot possibly be a header here. if we're == length(), assume it's a correctly written final segment\n            return -1;\n        }\n        reader.seek(offset);\n        PureJavaCrc32 crc = new PureJavaCrc32();\n        crc.updateInt((int) (descriptor.id & 0xFFFFFFFFL));\n        crc.updateInt((int) (descriptor.id >>> 32));\n        crc.updateInt((int) reader.getPosition());\n        int end = reader.readInt();\n        long filecrc;\n        if (descriptor.version < CommitLogDescriptor.VERSION_21)\n            filecrc = reader.readLong();\n        else\n            filecrc = reader.readInt() & 0xffffffffL;\n        if (crc.getValue() != filecrc)\n        {\n            if (end != 0 || filecrc != 0)\n            {\n                logger.warn(\"Encountered bad header at position {} of commit log {}, with invalid CRC. The end of segment marker should be zero.\", offset, reader.getPath());\n            }\n            return -1;\n        }\n        else if (end < offset || end > reader.length())\n        {\n            logger.warn(\"Encountered bad header at position {} of commit log {}, with bad position but valid CRC\", offset, reader.getPath());\n            return -1;\n        }\n        return end;\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"public CommitLogReplayer()\n    {\n        this.keyspacesRecovered = new NonBlockingHashSet<>();\n        this.futures = new ArrayList<>();\n        this.buffer = new byte[4096];\n        this.invalidMutations = new HashMap<>();\n        // count the number of replayed mutation. We don't really care about atomicity, but we need it to be a reference.\n        this.replayedCount = new AtomicInteger();\n        this.checksum = new PureJavaCrc32();\n\n        // compute per-CF and global replay positions\n        cfPositions = new HashMap<>();\n        Ordering<ReplayPosition> replayPositionOrdering = Ordering.from(ReplayPosition.comparator);\n        for (ColumnFamilyStore cfs : ColumnFamilyStore.all())\n        {\n            // it's important to call RP.gRP per-cf, before aggregating all the positions w/ the Ordering.min call\n            // below: gRP will return NONE if there are no flushed sstables, which is important to have in the\n            // list (otherwise we'll just start replay from the first flush position that we do have, which is not correct).\n            ReplayPosition rp = ReplayPosition.getReplayPosition(cfs.getSSTables());\n\n            // but, if we've truncted the cf in question, then we need to need to start replay after the truncation\n            ReplayPosition truncatedAt = SystemKeyspace.getTruncatedPosition(cfs.metadata.cfId);\n            if (truncatedAt != null)\n                rp = replayPositionOrdering.max(Arrays.asList(rp, truncatedAt));\n\n            cfPositions.put(cfs.metadata.cfId, rp);\n        }\n        globalPosition = replayPositionOrdering.min(cfPositions.values());\n        logger.debug(\"Global replay position is {} from columnfamilies {}\", globalPosition, FBUtilities.toString(cfPositions));\n    }","id":14164,"modified_method":"public CommitLogReplayer()\n    {\n        this.keyspacesRecovered = new NonBlockingHashSet<Keyspace>();\n        this.futures = new ArrayList<Future<?>>();\n        this.buffer = new byte[4096];\n        this.invalidMutations = new HashMap<UUID, AtomicInteger>();\n        // count the number of replayed mutation. We don't really care about atomicity, but we need it to be a reference.\n        this.replayedCount = new AtomicInteger();\n        this.checksum = new PureJavaCrc32();\n\n        // compute per-CF and global replay positions\n        cfPositions = new HashMap<UUID, ReplayPosition>();\n        Ordering<ReplayPosition> replayPositionOrdering = Ordering.from(ReplayPosition.comparator);\n        for (ColumnFamilyStore cfs : ColumnFamilyStore.all())\n        {\n            // it's important to call RP.gRP per-cf, before aggregating all the positions w/ the Ordering.min call\n            // below: gRP will return NONE if there are no flushed sstables, which is important to have in the\n            // list (otherwise we'll just start replay from the first flush position that we do have, which is not correct).\n            ReplayPosition rp = ReplayPosition.getReplayPosition(cfs.getSSTables());\n\n            // but, if we've truncted the cf in question, then we need to need to start replay after the truncation\n            ReplayPosition truncatedAt = SystemKeyspace.getTruncatedPosition(cfs.metadata.cfId);\n            if (truncatedAt != null)\n                rp = replayPositionOrdering.max(Arrays.asList(rp, truncatedAt));\n\n            cfPositions.put(cfs.metadata.cfId, rp);\n        }\n        globalPosition = replayPositionOrdering.min(cfPositions.values());\n        logger.debug(\"Global replay position is {} from columnfamilies {}\", globalPosition, FBUtilities.toString(cfPositions));\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithBadSizeChecksum() throws Exception\n    {\n        Checksum checksum = new CRC32();\n        checksum.update(100);\n        testMalformed(badLogFile(100, checksum.getValue(), new byte[100]));\n        testMalformed(badLogFile(100, checksum.getValue(), garbage(100)));\n    }","id":14165,"modified_method":"@Test\n    public void testRecoveryWithBadSizeChecksum() throws Exception\n    {\n        Checksum checksum = new CRC32();\n        checksum.update(100);\n        testRecoveryWithBadSizeArgument(100, 100, ~checksum.getValue());\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithZeroSegmentSizeArgument() throws Exception\n    {\n        // many different combinations of 4 bytes (garbage) will be read as zero by readInt()\n        testMalformed(badLogFile(0, -1L, 10)); // zero size, but no EOF\n    }","id":14166,"modified_method":"@Test\n    public void testRecoveryWithZeroSegmentSizeArgument() throws Exception\n    {\n        // many different combinations of 4 bytes (garbage) will be read as zero by readInt()\n        testRecoveryWithBadSizeArgument(0, 10); // zero size, but no EOF\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"private static int getMaxRecordDataSize(String keyspace, ByteBuffer key, String table, CellName column)\n    {\n        Mutation rm = new Mutation(keyspace, key);\n        rm.add(table, column, ByteBuffer.allocate(0), 0);\n\n        int max = (DatabaseDescriptor.getCommitLogSegmentSize() / 2);\n        max -= CommitLogSegment.ENTRY_OVERHEAD_SIZE; // log entry overhead\n        return max - (int) Mutation.serializer.serializedSize(rm, MessagingService.current_version);\n    }","id":14167,"modified_method":"private static int getMaxRecordDataSize(String keyspace, ByteBuffer key, String table, CellName column)\n    {\n        Mutation rm = new Mutation(\"Keyspace1\", bytes(\"k\"));\n        rm.add(\"Standard1\", Util.cellname(\"c1\"), ByteBuffer.allocate(0), 0);\n\n        int max = (DatabaseDescriptor.getCommitLogSegmentSize() / 2);\n        max -= CommitLogSegment.ENTRY_OVERHEAD_SIZE; // log entry overhead\n        return max - (int) Mutation.serializer.serializedSize(rm, MessagingService.current_version);\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithEmptyLog() throws Exception\n    {\n        testMalformed(badLogFile(new byte[0]));\n    }","id":14168,"modified_method":"@Test\n    public void testRecoveryWithEmptyLog() throws Exception\n    {\n        CommitLog.instance.recover(new File[]{ tmpFile() });\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithNegativeSizeArgument() throws Exception\n    {\n        // garbage from a partial/bad flush could be read as a negative size even if there is no EOF\n        testMalformed(badLogFile(-10, 10)); // zero size, but no EOF\n    }","id":14169,"modified_method":"@Test\n    public void testRecoveryWithNegativeSizeArgument() throws Exception\n    {\n        // garbage from a partial/bad flush could be read as a negative size even if there is no EOF\n        testRecoveryWithBadSizeArgument(-10, 10); // negative size, but no EOF\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithShortCheckSum() throws Exception\n    {\n        testMalformed(new byte[6]);\n    }","id":14170,"modified_method":"@Test\n    public void testRecoveryWithShortCheckSum() throws Exception\n    {\n        testRecovery(new byte[6]);\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithGarbageLog() throws Exception\n    {\n        testMalformed(garbage(100));\n    }","id":14171,"modified_method":"@Test\n    public void testRecoveryWithGarbageLog() throws Exception\n    {\n        byte[] garbage = new byte[100];\n        (new java.util.Random()).nextBytes(garbage);\n        testRecovery(garbage);\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithShortSize() throws Exception\n    {\n        testMalformed(new byte[2]);\n    }","id":14172,"modified_method":"@Test\n    public void testRecoveryWithShortSize() throws Exception\n    {\n        testRecovery(new byte[2]);\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithShortLog() throws Exception\n    {\n        // force EOF while reading log\n        testMalformed(badLogFile(100, 10));\n    }","id":14173,"modified_method":"@Test\n    public void testRecoveryWithShortLog() throws Exception\n    {\n        // force EOF while reading log\n        testRecoveryWithBadSizeArgument(100, 10);\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"@Test\n    public void testRecoveryWithBadSize() throws Exception\n    {\n        Checksum checksum = new CRC32();\n        checksum.update(100);\n        testMalformed(badLogFile(120, checksum.getValue(), garbage(100)));\n    }","id":14174,"modified_method":"protected void testRecoveryWithBadSizeArgument(int size, int dataSize) throws Exception\n    {\n        Checksum checksum = new CRC32();\n        checksum.update(size);\n        testRecoveryWithBadSizeArgument(size, dataSize, checksum.getValue());\n    }","commit_id":"a5bc52eee90e342efcdc53282612008d3dbaeaeb","url":"https://github.com/apache/cassandra"},{"original_method":"private void validateDependencies( ModelProblemCollector problems, List<Dependency> dependencies, String prefix,\n                                       ModelBuildingRequest request )\n    {\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        Map<String, Dependency> index = new HashMap<String, Dependency>();\n\n        for ( Dependency dependency : dependencies )\n        {\n            String key = dependency.getManagementKey();\n\n            if ( \"pom\".equals( dependency.getType() ) && \"import\".equals( dependency.getScope() )\n                && StringUtils.isNotEmpty( dependency.getClassifier() ) )\n            {\n                addViolation( problems, errOn30, \"'\" + prefix + \".classifier' must be empty for imported POM: \" + key );\n            }\n            else if ( \"system\".equals( dependency.getScope() ) )\n            {\n                String sysPath = dependency.getSystemPath();\n                if ( StringUtils.isNotEmpty( sysPath ) && !hasExpression( sysPath ) )\n                {\n                    addViolation( problems, Severity.WARNING, \"'\" + prefix\n                        + \".systemPath' should use a variable instead of a hard-coded path: \" + key + \" -> \" + sysPath );\n                }\n            }\n\n            Dependency existing = index.get( key );\n\n            if ( existing != null )\n            {\n                String msg;\n                if ( equals( existing.getVersion(), dependency.getVersion() ) )\n                {\n                    msg =\n                        \"duplicate declaration of version \"\n                            + StringUtils.defaultString( dependency.getVersion(), \"(?)\" );\n                }\n                else\n                {\n                    msg =\n                        \"version \" + StringUtils.defaultString( existing.getVersion(), \"(?)\" ) + \" vs \"\n                            + StringUtils.defaultString( dependency.getVersion(), \"(?)\" );\n                }\n\n                addViolation( problems, errOn30, \"'\" + prefix\n                    + \".(groupId:artifactId:type:classifier)' must be unique: \" + key + \" -> \" + msg );\n            }\n            else\n            {\n                index.put( key, dependency );\n            }\n        }\n    }","id":14175,"modified_method":"private void validateRawDependencies( ModelProblemCollector problems, List<Dependency> dependencies, String prefix,\n                                       ModelBuildingRequest request )\n    {\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        Map<String, Dependency> index = new HashMap<String, Dependency>();\n\n        for ( Dependency dependency : dependencies )\n        {\n            String key = dependency.getManagementKey();\n\n            if ( \"pom\".equals( dependency.getType() ) && \"import\".equals( dependency.getScope() )\n                && StringUtils.isNotEmpty( dependency.getClassifier() ) )\n            {\n                addViolation( problems, errOn30, prefix + \".classifier\", key,\n                              \"must be empty, imported POM cannot have a classifier.\" );\n            }\n            else if ( \"system\".equals( dependency.getScope() ) )\n            {\n                String sysPath = dependency.getSystemPath();\n                if ( StringUtils.isNotEmpty( sysPath ) && !hasExpression( sysPath ) )\n                {\n                    addViolation( problems, Severity.WARNING, prefix + \".systemPath\", key,\n                                  \"should use a variable instead of a hard-coded path \" + sysPath );\n                }\n            }\n\n            Dependency existing = index.get( key );\n\n            if ( existing != null )\n            {\n                String msg;\n                if ( equals( existing.getVersion(), dependency.getVersion() ) )\n                {\n                    msg =\n                        \"duplicate declaration of version \"\n                            + StringUtils.defaultString( dependency.getVersion(), \"(?)\" );\n                }\n                else\n                {\n                    msg =\n                        \"version \" + StringUtils.defaultString( existing.getVersion(), \"(?)\" ) + \" vs \"\n                            + StringUtils.defaultString( dependency.getVersion(), \"(?)\" );\n                }\n\n                addViolation( problems, errOn30, prefix + \".(groupId:artifactId:type:classifier)\", null,\n                              \"must be unique: \" + key + \" -> \" + msg );\n            }\n            else\n            {\n                index.put( key, dependency );\n            }\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"/**\n     * Asserts:\n     * <p/>\n     * <ul>\n     * <li><code>string != null<\/code>\n     * <li><code>string.length > 0<\/code>\n     * <\/ul>\n     */\n    private boolean validateStringNotEmpty( String fieldName, ModelProblemCollector problems, Severity severity,\n                                            String string, String sourceHint )\n    {\n        if ( !validateNotNull( fieldName, problems, severity, string, sourceHint ) )\n        {\n            return false;\n        }\n\n        if ( string.length() > 0 )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' is missing for \" + sourceHint );\n        }\n        else\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' is missing.\" );\n        }\n\n        return false;\n    }","id":14176,"modified_method":"/**\n     * Asserts:\n     * <p/>\n     * <ul>\n     * <li><code>string != null<\/code>\n     * <li><code>string.length > 0<\/code>\n     * <\/ul>\n     */\n    private boolean validateStringNotEmpty( String fieldName, ModelProblemCollector problems, Severity severity,\n                                            String string, String sourceHint )\n    {\n        if ( !validateNotNull( fieldName, problems, severity, string, sourceHint ) )\n        {\n            return false;\n        }\n\n        if ( string.length() > 0 )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, sourceHint, \"is missing.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validateEnum( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                  String sourceHint, String... validValues )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        List<String> values = Arrays.asList( validValues );\n\n        if ( values.contains( string ) )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be one of \" + values + \" for \" + sourceHint\n                + \" but is '\" + string + \"'.\" );\n        }\n        else\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be one of \" + values + \" but is '\" + string\n                + \"'.\" );\n        }\n\n        return false;\n    }","id":14177,"modified_method":"private boolean validateEnum( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                  String sourceHint, String... validValues )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        List<String> values = Arrays.asList( validValues );\n\n        if ( values.contains( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, sourceHint, \"must be one of \" + values + \" but is '\" + string\n            + \"'.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"/**\n     * Asserts:\n     * <p/>\n     * <ul>\n     * <li><code>string != null<\/code>\n     * <\/ul>\n     */\n    private boolean validateNotNull( String fieldName, ModelProblemCollector problems, Severity severity,\n                                     Object object, String sourceHint )\n    {\n        if ( object != null )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' is missing for \" + sourceHint );\n        }\n        else\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' is missing.\" );\n        }\n\n        return false;\n    }","id":14178,"modified_method":"/**\n     * Asserts:\n     * <p/>\n     * <ul>\n     * <li><code>string != null<\/code>\n     * <\/ul>\n     */\n    private boolean validateNotNull( String fieldName, ModelProblemCollector problems, Severity severity,\n                                     Object object, String sourceHint )\n    {\n        if ( object != null )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, sourceHint, \"is missing.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void validateRawModel( Model model, ModelBuildingRequest request, ModelProblemCollector problems )\n    {\n        Parent parent = model.getParent();\n        if ( parent != null )\n        {\n            validateStringNotEmpty( \"parent.groupId\", problems, Severity.FATAL, parent.getGroupId() );\n\n            validateStringNotEmpty( \"parent.artifactId\", problems, Severity.FATAL, parent.getArtifactId() );\n\n            validateStringNotEmpty( \"parent.version\", problems, Severity.FATAL, parent.getVersion() );\n\n            if ( equals( parent.getGroupId(), model.getGroupId() )\n                && equals( parent.getArtifactId(), model.getArtifactId() ) )\n            {\n                addViolation( problems, Severity.FATAL, \"The parent element cannot have the same ID as the project.\" );\n            }\n        }\n\n        if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n        {\n            Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n            validateEnum( \"modelVersion\", problems, Severity.ERROR, model.getModelVersion(), null, \"4.0.0\" );\n            validateStringNoExpression( \"groupId\", problems, Severity.WARNING, model.getGroupId() );\n            validateStringNoExpression( \"artifactId\", problems, Severity.WARNING, model.getArtifactId() );\n            validateStringNoExpression( \"version\", problems, Severity.WARNING, model.getVersion() );\n\n            validateDependencies( problems, model.getDependencies(), \"dependencies.dependency\", request );\n\n            if ( model.getDependencyManagement() != null )\n            {\n                validateDependencies( problems, model.getDependencyManagement().getDependencies(),\n                                      \"dependencyManagement.dependencies.dependency\", request );\n            }\n\n            validateRepositories( problems, model.getRepositories(), \"repositories.repository\", request );\n\n            validateRepositories( problems, model.getPluginRepositories(), \"pluginRepositories.pluginRepository\", request );\n\n            Set<String> profileIds = new HashSet<String>();\n\n            for ( Profile profile : model.getProfiles() )\n            {\n                if ( !profileIds.add( profile.getId() ) )\n                {\n                    addViolation( problems, errOn30, \"profiles.profile.id must be unique\"\n                        + \" but found duplicate profile with id \" + profile.getId() );\n                }\n\n                validateDependencies( problems, profile.getDependencies(), \"profiles.profile[\" + profile.getId()\n                    + \"].dependencies.dependency\", request );\n\n                if ( profile.getDependencyManagement() != null )\n                {\n                    validateDependencies( problems, profile.getDependencyManagement().getDependencies(),\n                                          \"profiles.profile[\" + profile.getId()\n                                              + \"].dependencyManagement.dependencies.dependency\", request );\n                }\n\n                validateRepositories( problems, profile.getRepositories(), \"profiles.profile[\" + profile.getId()\n                    + \"].repositories.repository\", request );\n\n                validateRepositories( problems, profile.getPluginRepositories(), \"profiles.profile[\" + profile.getId()\n                    + \"].pluginRepositories.pluginRepository\", request );\n            }\n        }\n    }","id":14179,"modified_method":"public void validateRawModel( Model model, ModelBuildingRequest request, ModelProblemCollector problems )\n    {\n        Parent parent = model.getParent();\n        if ( parent != null )\n        {\n            validateStringNotEmpty( \"parent.groupId\", problems, Severity.FATAL, parent.getGroupId() );\n\n            validateStringNotEmpty( \"parent.artifactId\", problems, Severity.FATAL, parent.getArtifactId() );\n\n            validateStringNotEmpty( \"parent.version\", problems, Severity.FATAL, parent.getVersion() );\n\n            if ( equals( parent.getGroupId(), model.getGroupId() )\n                && equals( parent.getArtifactId(), model.getArtifactId() ) )\n            {\n                addViolation( problems, Severity.FATAL, \"The parent element cannot have the same ID as the project.\" );\n            }\n        }\n\n        if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n        {\n            Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n            validateEnum( \"modelVersion\", problems, Severity.ERROR, model.getModelVersion(), null, \"4.0.0\" );\n            validateStringNoExpression( \"groupId\", problems, Severity.WARNING, model.getGroupId() );\n            validateStringNoExpression( \"artifactId\", problems, Severity.WARNING, model.getArtifactId() );\n            validateStringNoExpression( \"version\", problems, Severity.WARNING, model.getVersion() );\n\n            validateRawDependencies( problems, model.getDependencies(), \"dependencies.dependency\", request );\n\n            if ( model.getDependencyManagement() != null )\n            {\n                validateRawDependencies( problems, model.getDependencyManagement().getDependencies(),\n                                      \"dependencyManagement.dependencies.dependency\", request );\n            }\n\n            validateRepositories( problems, model.getRepositories(), \"repositories.repository\", request );\n\n            validateRepositories( problems, model.getPluginRepositories(), \"pluginRepositories.pluginRepository\", request );\n\n            Set<String> profileIds = new HashSet<String>();\n\n            for ( Profile profile : model.getProfiles() )\n            {\n                if ( !profileIds.add( profile.getId() ) )\n                {\n                    addViolation( problems, errOn30, \"profiles.profile.id\", null,\n                                  \"must be unique but found duplicate profile with id \" + profile.getId() );\n                }\n\n                validateRawDependencies( problems, profile.getDependencies(), \"profiles.profile[\" + profile.getId()\n                    + \"].dependencies.dependency\", request );\n\n                if ( profile.getDependencyManagement() != null )\n                {\n                    validateRawDependencies( problems, profile.getDependencyManagement().getDependencies(),\n                                          \"profiles.profile[\" + profile.getId()\n                                              + \"].dependencyManagement.dependencies.dependency\", request );\n                }\n\n                validateRepositories( problems, profile.getRepositories(), \"profiles.profile[\" + profile.getId()\n                    + \"].repositories.repository\", request );\n\n                validateRepositories( problems, profile.getPluginRepositories(), \"profiles.profile[\" + profile.getId()\n                    + \"].pluginRepositories.pluginRepository\", request );\n            }\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private void validateRepositories( ModelProblemCollector problems, List<Repository> repositories, String prefix,\n                                       ModelBuildingRequest request )\n    {\n        Map<String, Repository> index = new HashMap<String, Repository>();\n\n        for ( Repository repository : repositories )\n        {\n            validateStringNotEmpty( prefix + \".id\", problems, Severity.ERROR, repository.getId() );\n\n            validateStringNotEmpty( prefix + \"[\" + repository.getId() + \"].url\", problems, Severity.ERROR,\n                                    repository.getUrl() );\n\n            String key = repository.getId();\n\n            Repository existing = index.get( key );\n\n            if ( existing != null )\n            {\n                Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n                addViolation( problems, errOn30, \"'\" + prefix + \".id' must be unique: \" + repository.getId() + \" -> \"\n                    + existing.getUrl() + \" vs \" + repository.getUrl() );\n            }\n            else\n            {\n                index.put( key, repository );\n            }\n        }\n    }","id":14180,"modified_method":"private void validateRepositories( ModelProblemCollector problems, List<Repository> repositories, String prefix,\n                                       ModelBuildingRequest request )\n    {\n        Map<String, Repository> index = new HashMap<String, Repository>();\n\n        for ( Repository repository : repositories )\n        {\n            validateStringNotEmpty( prefix + \".id\", problems, Severity.ERROR, repository.getId() );\n\n            validateStringNotEmpty( prefix + \"[\" + repository.getId() + \"].url\", problems, Severity.ERROR,\n                                    repository.getUrl() );\n\n            String key = repository.getId();\n\n            Repository existing = index.get( key );\n\n            if ( existing != null )\n            {\n                Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n                addViolation( problems, errOn30, prefix + \".id\", null, \"must be unique: \" + repository.getId() + \" -> \"\n                    + existing.getUrl() + \" vs \" + repository.getUrl() );\n            }\n            else\n            {\n                index.put( key, repository );\n            }\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void validateEffectiveModel( Model model, ModelBuildingRequest request, ModelProblemCollector problems )\n    {\n        validateStringNotEmpty( \"modelVersion\", problems, Severity.ERROR, model.getModelVersion() );\n\n        validateId( \"groupId\", problems, model.getGroupId() );\n\n        validateId( \"artifactId\", problems, model.getArtifactId() );\n\n        validateStringNotEmpty( \"packaging\", problems, Severity.ERROR, model.getPackaging() );\n\n        if ( !model.getModules().isEmpty() )\n        {\n            if ( !\"pom\".equals( model.getPackaging() ) )\n            {\n                addViolation( problems, Severity.ERROR, \"Packaging '\" + model.getPackaging()\n                    + \"' is invalid. Aggregator projects \" + \"require 'pom' as packaging.\" );\n            }\n\n            for ( String module : model.getModules() )\n            {\n                if ( StringUtils.isBlank( module ) )\n                {\n                    addViolation( problems, Severity.WARNING,\n                                  \"Child module has been specified without path to its project directory.\" );\n                }\n            }\n        }\n\n        validateStringNotEmpty( \"version\", problems, Severity.ERROR, model.getVersion() );\n\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        for ( Dependency d : model.getDependencies() )\n        {\n            validateId( \"dependencies.dependency.artifactId\", problems, d.getArtifactId(), d.getManagementKey() );\n\n            validateId( \"dependencies.dependency.groupId\", problems, d.getGroupId(), d.getManagementKey() );\n\n            validateStringNotEmpty( \"dependencies.dependency.type\", problems, Severity.ERROR, d.getType(),\n                                    d.getManagementKey() );\n\n            validateStringNotEmpty( \"dependencies.dependency.version\", problems, Severity.ERROR, d.getVersion(),\n                                    d.getManagementKey() );\n\n            if ( \"system\".equals( d.getScope() ) )\n            {\n                String systemPath = d.getSystemPath();\n\n                if ( StringUtils.isEmpty( systemPath ) )\n                {\n                    addViolation( problems, Severity.ERROR, \"For dependency \" + d.getManagementKey()\n                        + \": system-scoped dependency must specify systemPath.\" );\n                }\n                else\n                {\n                    if ( !new File( systemPath ).isAbsolute() )\n                    {\n                        addViolation( problems, Severity.ERROR, \"For dependency \" + d.getManagementKey()\n                            + \": system-scoped dependency must specify an absolute systemPath but is \" + systemPath );\n                    }\n                }\n            }\n            else if ( StringUtils.isNotEmpty( d.getSystemPath() ) )\n            {\n                addViolation( problems, Severity.ERROR, \"For dependency \" + d.getManagementKey()\n                    + \": only dependency with system scope can specify systemPath.\" );\n            }\n\n            if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n            {\n                validateVersion( \"dependencies.dependency.version\", problems, errOn30, d.getVersion(),\n                                 d.getManagementKey() );\n\n                validateBoolean( \"dependencies.dependency.optional\", problems, errOn30, d.getOptional(),\n                                 d.getManagementKey() );\n\n                /*\n                 * TODO: Extensions like Flex Mojos use custom scopes like \"merged\", \"internal\", \"external\", etc. In\n                 * order to don't break backward-compat with those, only warn but don't error out.\n                 */\n                validateEnum( \"dependencies.dependency.scope\", problems, Severity.WARNING, d.getScope(),\n                              d.getManagementKey(), \"provided\", \"compile\", \"runtime\", \"test\", \"system\" );\n            }\n        }\n\n        DependencyManagement mgmt = model.getDependencyManagement();\n        if ( mgmt != null )\n        {\n            for ( Dependency d : mgmt.getDependencies() )\n            {\n                validateStringNotEmpty( \"dependencyManagement.dependencies.dependency.artifactId\", problems,\n                                        Severity.ERROR, d.getArtifactId(), d.getManagementKey() );\n\n                validateStringNotEmpty( \"dependencyManagement.dependencies.dependency.groupId\", problems,\n                                        Severity.ERROR, d.getGroupId(), d.getManagementKey() );\n\n                if ( \"system\".equals( d.getScope() ) )\n                {\n                    String systemPath = d.getSystemPath();\n\n                    if ( StringUtils.isEmpty( systemPath ) )\n                    {\n                        addViolation( problems, Severity.ERROR, \"For managed dependency \" + d.getManagementKey()\n                            + \": system-scoped dependency must specify systemPath.\" );\n                    }\n                    else\n                    {\n                        if ( !new File( systemPath ).isAbsolute() )\n                        {\n                            addViolation( problems, Severity.ERROR, \"For managed dependency \" + d.getManagementKey()\n                                + \": system-scoped dependency must specify an absolute systemPath but is \" + systemPath );\n                        }\n                    }\n                }\n                else if ( StringUtils.isNotEmpty( d.getSystemPath() ) )\n                {\n                    addViolation( problems, Severity.ERROR, \"For managed dependency \" + d.getManagementKey()\n                        + \": only dependency with system scope can specify systemPath.\" );\n                }\n\n                if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n                {\n                    validateBoolean( \"dependencyManagement.dependencies.dependency.optional\", problems, errOn30,\n                                     d.getOptional(), d.getManagementKey() );\n                }\n            }\n        }\n\n        if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n        {\n            Set<String> modules = new HashSet<String>();\n            for ( String module : model.getModules() )\n            {\n                if ( !modules.add( module ) )\n                {\n                    addViolation( problems, Severity.ERROR, \"Duplicate child module: \" + module );\n                }\n            }\n\n            Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n            Build build = model.getBuild();\n            if ( build != null )\n            {\n                for ( Plugin p : build.getPlugins() )\n                {\n                    validateStringNotEmpty( \"build.plugins.plugin.artifactId\", problems, Severity.ERROR,\n                                            p.getArtifactId() );\n\n                    validateStringNotEmpty( \"build.plugins.plugin.groupId\", problems, Severity.ERROR, p.getGroupId() );\n\n                    validatePluginVersion( \"build.plugins.plugin.version\", problems, p.getVersion(), p.getKey(),\n                                           request );\n\n                    validateBoolean( \"build.plugins.plugin.inherited\", problems, errOn30, p.getInherited(),\n                                     p.getKey() );\n\n                    validateBoolean( \"build.plugins.plugin.extensions\", problems, errOn30, p.getExtensions(),\n                                     p.getKey() );\n\n                    for ( Dependency d : p.getDependencies() )\n                    {\n                        validateEnum( \"build.plugins.plugin[\" + p.getKey() + \"].dependencies.dependency.scope\",\n                                      problems, errOn30, d.getScope(), d.getManagementKey(),\n                                      \"compile\", \"runtime\", \"system\" );\n                    }\n                }\n\n                validateResources( problems, build.getResources(), \"build.resources.resource\", request );\n\n                validateResources( problems, build.getTestResources(), \"build.testResources.testResource\", request );\n            }\n\n            Reporting reporting = model.getReporting();\n            if ( reporting != null )\n            {\n                for ( ReportPlugin p : reporting.getPlugins() )\n                {\n                    validateStringNotEmpty( \"reporting.plugins.plugin.artifactId\", problems, Severity.ERROR,\n                                            p.getArtifactId() );\n\n                    validateStringNotEmpty( \"reporting.plugins.plugin.groupId\", problems, Severity.ERROR,\n                                            p.getGroupId() );\n\n                    validateStringNotEmpty( \"reporting.plugins.plugin.version\", problems, errOn31, p.getVersion(),\n                                            p.getKey() );\n                }\n            }\n\n            forcePluginExecutionIdCollision( model, problems );\n\n            for ( Repository repository : model.getRepositories() )\n            {\n                validateRepositoryLayout( problems, repository, \"repositories.repository\", request );\n            }\n\n            for ( Repository repository : model.getPluginRepositories() )\n            {\n                validateRepositoryLayout( problems, repository, \"pluginRepositories.pluginRepository\", request );\n            }\n\n            DistributionManagement distMgmt = model.getDistributionManagement();\n            if ( distMgmt != null )\n            {\n                if ( distMgmt.getStatus() != null )\n                {\n                    addViolation( problems, Severity.ERROR, \"'distributionManagement.status' must not be specified\" );\n                }\n\n                validateRepositoryLayout( problems, distMgmt.getRepository(), \"distributionManagement.repository\",\n                                          request );\n                validateRepositoryLayout( problems, distMgmt.getSnapshotRepository(),\n                                          \"distributionManagement.snapshotRepository\", request );\n            }\n        }\n    }","id":14181,"modified_method":"public void validateEffectiveModel( Model model, ModelBuildingRequest request, ModelProblemCollector problems )\n    {\n        validateStringNotEmpty( \"modelVersion\", problems, Severity.ERROR, model.getModelVersion() );\n\n        validateId( \"groupId\", problems, model.getGroupId() );\n\n        validateId( \"artifactId\", problems, model.getArtifactId() );\n\n        validateStringNotEmpty( \"packaging\", problems, Severity.ERROR, model.getPackaging() );\n\n        if ( !model.getModules().isEmpty() )\n        {\n            if ( !\"pom\".equals( model.getPackaging() ) )\n            {\n                addViolation( problems, Severity.ERROR, \"packaging\", null, \"with value '\" + model.getPackaging()\n                    + \"' is invalid. Aggregator projects \" + \"require 'pom' as packaging.\" );\n            }\n\n            for ( String module : model.getModules() )\n            {\n                if ( StringUtils.isBlank( module ) )\n                {\n                    addViolation( problems, Severity.WARNING, \"modules.module\", null,\n                                  \"has been specified without a path to the project directory.\" );\n                }\n            }\n        }\n\n        validateStringNotEmpty( \"version\", problems, Severity.ERROR, model.getVersion() );\n\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        validateEffectiveDependencies( problems, model.getDependencies(), false, request );\n\n        DependencyManagement mgmt = model.getDependencyManagement();\n        if ( mgmt != null )\n        {\n            validateEffectiveDependencies( problems, mgmt.getDependencies(), true, request );\n        }\n\n        if ( request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0 )\n        {\n            Set<String> modules = new HashSet<String>();\n            for ( String module : model.getModules() )\n            {\n                if ( !modules.add( module ) )\n                {\n                    addViolation( problems, Severity.ERROR, \"modules.module\", null, \"specifies duplicate child module \"\n                        + module );\n                }\n            }\n\n            Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n            Build build = model.getBuild();\n            if ( build != null )\n            {\n                for ( Plugin p : build.getPlugins() )\n                {\n                    validateStringNotEmpty( \"build.plugins.plugin.artifactId\", problems, Severity.ERROR,\n                                            p.getArtifactId() );\n\n                    validateStringNotEmpty( \"build.plugins.plugin.groupId\", problems, Severity.ERROR, p.getGroupId() );\n\n                    validatePluginVersion( \"build.plugins.plugin.version\", problems, p.getVersion(), p.getKey(),\n                                           request );\n\n                    validateBoolean( \"build.plugins.plugin.inherited\", problems, errOn30, p.getInherited(),\n                                     p.getKey() );\n\n                    validateBoolean( \"build.plugins.plugin.extensions\", problems, errOn30, p.getExtensions(),\n                                     p.getKey() );\n\n                    for ( Dependency d : p.getDependencies() )\n                    {\n                        validateEnum( \"build.plugins.plugin[\" + p.getKey() + \"].dependencies.dependency.scope\",\n                                      problems, errOn30, d.getScope(), d.getManagementKey(),\n                                      \"compile\", \"runtime\", \"system\" );\n                    }\n                }\n\n                validateResources( problems, build.getResources(), \"build.resources.resource\", request );\n\n                validateResources( problems, build.getTestResources(), \"build.testResources.testResource\", request );\n            }\n\n            Reporting reporting = model.getReporting();\n            if ( reporting != null )\n            {\n                for ( ReportPlugin p : reporting.getPlugins() )\n                {\n                    validateStringNotEmpty( \"reporting.plugins.plugin.artifactId\", problems, Severity.ERROR,\n                                            p.getArtifactId() );\n\n                    validateStringNotEmpty( \"reporting.plugins.plugin.groupId\", problems, Severity.ERROR,\n                                            p.getGroupId() );\n\n                    validateStringNotEmpty( \"reporting.plugins.plugin.version\", problems, errOn31, p.getVersion(),\n                                            p.getKey() );\n                }\n            }\n\n            forcePluginExecutionIdCollision( model, problems );\n\n            for ( Repository repository : model.getRepositories() )\n            {\n                validateRepositoryLayout( problems, repository, \"repositories.repository\", request );\n            }\n\n            for ( Repository repository : model.getPluginRepositories() )\n            {\n                validateRepositoryLayout( problems, repository, \"pluginRepositories.pluginRepository\", request );\n            }\n\n            DistributionManagement distMgmt = model.getDistributionManagement();\n            if ( distMgmt != null )\n            {\n                if ( distMgmt.getStatus() != null )\n                {\n                    addViolation( problems, Severity.ERROR, \"distributionManagement.status\", null,\n                                  \"must not be specified.\" );\n                }\n\n                validateRepositoryLayout( problems, distMgmt.getRepository(), \"distributionManagement.repository\",\n                                          request );\n                validateRepositoryLayout( problems, distMgmt.getSnapshotRepository(),\n                                          \"distributionManagement.snapshotRepository\", request );\n            }\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validateBoolean( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                     String sourceHint )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        if ( \"true\".equalsIgnoreCase( string ) || \"false\".equalsIgnoreCase( string ) )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be 'true' or 'false' for \" + sourceHint\n                + \" but is '\" + string + \"'.\" );\n        }\n        else\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be 'true' or 'false' but is '\" + string + \"'.\" );\n        }\n\n        return false;\n    }","id":14182,"modified_method":"private boolean validateBoolean( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                     String sourceHint )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        if ( \"true\".equalsIgnoreCase( string ) || \"false\".equalsIgnoreCase( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, sourceHint, \"must be 'true' or 'false' but is '\" + string + \"'.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validateStringNoExpression( String fieldName, ModelProblemCollector problems, Severity severity,\n                                                String string )\n    {\n        if ( !hasExpression( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, \"'\" + fieldName + \"' contains an expression but should be a constant.\" );\n\n        return false;\n    }","id":14183,"modified_method":"private boolean validateStringNoExpression( String fieldName, ModelProblemCollector problems, Severity severity,\n                                                String string )\n    {\n        if ( !hasExpression( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, null, \"contains an expression but should be a constant.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validateId( String fieldName, ModelProblemCollector problems, String id, String sourceHint )\n    {\n        if ( !validateStringNotEmpty( fieldName, problems, Severity.ERROR, id, sourceHint ) )\n        {\n            return false;\n        }\n        else\n        {\n            boolean match = id.matches( ID_REGEX );\n            if ( !match )\n            {\n                addViolation( problems, Severity.ERROR, \"'\" + fieldName + \"'\"\n                    + ( sourceHint != null ? \" for \" + sourceHint : \"\" ) + \" with value '\" + id\n                    + \"' does not match a valid id pattern.\" );\n            }\n            return match;\n        }\n    }","id":14184,"modified_method":"private boolean validateId( String fieldName, ModelProblemCollector problems, String id, String sourceHint )\n    {\n        if ( !validateStringNotEmpty( fieldName, problems, Severity.ERROR, id, sourceHint ) )\n        {\n            return false;\n        }\n        else\n        {\n            boolean match = id.matches( ID_REGEX );\n            if ( !match )\n            {\n                addViolation( problems, Severity.ERROR, fieldName, sourceHint, \"with value '\" + id\n                    + \"' does not match a valid id pattern.\" );\n            }\n            return match;\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private void validateRepositoryLayout( ModelProblemCollector problems, Repository repository, String prefix,\n                                           ModelBuildingRequest request )\n    {\n        if ( repository != null && \"legacy\".equals( repository.getLayout() ) )\n        {\n            addViolation( problems, Severity.WARNING, \"'\" + prefix + \".layout = legacy' is deprecated: \"\n                + repository.getId() );\n        }\n    }","id":14185,"modified_method":"private void validateRepositoryLayout( ModelProblemCollector problems, Repository repository, String prefix,\n                                           ModelBuildingRequest request )\n    {\n        if ( repository != null && \"legacy\".equals( repository.getLayout() ) )\n        {\n            addViolation( problems, Severity.WARNING, prefix + \".layout\", repository.getId(),\n                          \"uses the deprecated value 'legacy'.\" );\n        }\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validatePluginVersion( String fieldName, ModelProblemCollector problems, String string,\n                                           String sourceHint, ModelBuildingRequest request )\n    {\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n        Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n        if ( !validateNotNull( fieldName, problems, errOn31, string, sourceHint ) )\n        {\n            return false;\n        }\n\n        if ( string.length() > 0 && !hasExpression( string ) && !\"RELEASE\".equals( string )\n            && !\"LATEST\".equals( string ) )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, errOn30, \"'\" + fieldName + \"' must be a valid version for \" + sourceHint\n                + \" but is '\" + string + \"'.\" );\n        }\n        else\n        {\n            addViolation( problems, errOn30, \"'\" + fieldName + \"' must be a valid version but is '\" + string + \"'.\" );\n        }\n\n        return false;\n    }","id":14186,"modified_method":"private boolean validatePluginVersion( String fieldName, ModelProblemCollector problems, String string,\n                                           String sourceHint, ModelBuildingRequest request )\n    {\n        Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n        Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n        if ( !validateNotNull( fieldName, problems, errOn31, string, sourceHint ) )\n        {\n            return false;\n        }\n\n        if ( string.length() > 0 && !hasExpression( string ) && !\"RELEASE\".equals( string )\n            && !\"LATEST\".equals( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, errOn30, fieldName, sourceHint, \"must be a valid version but is '\" + string + \"'.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"private boolean validateVersion( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                     String sourceHint )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        if ( !hasExpression( string ) )\n        {\n            return true;\n        }\n\n        if ( sourceHint != null )\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be a valid version for \" + sourceHint\n                + \" but is '\" + string + \"'.\" );\n        }\n        else\n        {\n            addViolation( problems, severity, \"'\" + fieldName + \"' must be a valid version but is '\" + string + \"'.\" );\n        }\n\n        return false;\n    }","id":14187,"modified_method":"private boolean validateVersion( String fieldName, ModelProblemCollector problems, Severity severity, String string,\n                                     String sourceHint )\n    {\n        if ( string == null || string.length() <= 0 )\n        {\n            return true;\n        }\n\n        if ( !hasExpression( string ) )\n        {\n            return true;\n        }\n\n        addViolation( problems, severity, fieldName, sourceHint, \"must be a valid version but is '\" + string + \"'.\" );\n\n        return false;\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingDependencyVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-version-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf( \"'dependencies.dependency.version' is missing\" ) > -1 );\n    }","id":14188,"modified_method":"public void testMissingDependencyVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-version-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencies.dependency.version' for groupId:artifactId:jar is missing\" ) > -1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingDependencyManagementArtifactId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-mgmt-artifactId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencyManagement.dependencies.dependency.artifactId' is missing\" ) > -1 );\n    }","id":14189,"modified_method":"public void testMissingDependencyManagementArtifactId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-mgmt-artifactId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencyManagement.dependencies.dependency.artifactId' for groupId:null:jar is missing\" ) > -1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testEmptyPluginVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"empty-plugin-version.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertEquals( \"'build.plugins.plugin.version' must be a valid version \"\n            + \"for org.apache.maven.plugins:maven-it-plugin but is ''.\", result.getErrors().get( 0 ) );\n    }","id":14190,"modified_method":"public void testEmptyPluginVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"empty-plugin-version.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertEquals( \"'build.plugins.plugin.version' for org.apache.maven.plugins:maven-it-plugin\"\n            + \" must be a valid version but is ''.\", result.getErrors().get( 0 ) );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingDependencyArtifactId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-artifactId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf( \"'dependencies.dependency.artifactId' is missing\" ) > -1 );\n    }","id":14191,"modified_method":"public void testMissingDependencyArtifactId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-artifactId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencies.dependency.artifactId' for groupId:null:jar is missing\" ) > -1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingDependencyGroupId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-groupId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf( \"'dependencies.dependency.groupId' is missing\" ) > -1 );\n    }","id":14192,"modified_method":"public void testMissingDependencyGroupId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-groupId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencies.dependency.groupId' for null:artifactId:jar is missing\" ) > -1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingDependencyManagementGroupId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-mgmt-groupId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencyManagement.dependencies.dependency.groupId' is missing\" ) > -1 );\n    }","id":14193,"modified_method":"public void testMissingDependencyManagementGroupId()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"missing-dependency-mgmt-groupId-pom.xml\" );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertTrue( result.getErrors().get( 0 ).indexOf(\n                                                         \"'dependencyManagement.dependencies.dependency.groupId' for null:artifactId:jar is missing\" ) > -1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testMissingPluginVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result =\n            validateEffective( \"missing-plugin-version-pom.xml\", ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertEquals( \"'build.plugins.plugin.version' is missing for org.apache.maven.plugins:maven-it-plugin\",\n                      result.getErrors().get( 0 ) );\n\n        result = validateEffective( \"missing-plugin-version-pom.xml\", ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        assertViolations( result, 0, 0, 1 );\n    }","id":14194,"modified_method":"public void testMissingPluginVersion()\n        throws Exception\n    {\n        SimpleProblemCollector result =\n            validateEffective( \"missing-plugin-version-pom.xml\", ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );\n\n        assertViolations( result, 0, 1, 0 );\n\n        assertEquals( \"'build.plugins.plugin.version' for org.apache.maven.plugins:maven-it-plugin is missing.\",\n                      result.getErrors().get( 0 ) );\n\n        result = validateEffective( \"missing-plugin-version-pom.xml\", ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );\n\n        assertViolations( result, 0, 0, 1 );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"public void testEmptyModule()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"empty-module.xml\" );\n\n        assertViolations( result, 0, 0, 1 );\n\n        assertTrue( result.getWarnings().get( 0 ).contains( \"Child module has been specified without path\" ) );\n    }","id":14195,"modified_method":"public void testEmptyModule()\n        throws Exception\n    {\n        SimpleProblemCollector result = validate( \"empty-module.xml\" );\n\n        assertViolations( result, 0, 0, 1 );\n\n        assertTrue( result.getWarnings().get( 0 ).contains( \"'modules.module' has been specified without a path\" ) );\n    }","commit_id":"38b4606a1809f8f2e724a371bc407f479acc93ee","url":"https://github.com/apache/maven"},{"original_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Get the current set of tag names.\n            DrawableTagsManager tagsManager = controller.getTagsManager();\n            List<TagName> tagNames = null;\n            try {\n                tagNames = tagsManager.getAllTagNames();\n            } catch (TskCoreException ex) {\n                Logger.getLogger(TagsManager.class.getName()).log(Level.SEVERE, \"Failed to get tag names\", ex);\n            }\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            // Each tag name in the current set of tags gets its own menu item in\n            // the \"Quick Tags\" sub-menu. Selecting one of these menu items adds\n            // a tag with the associated tag name. \n            if (null != tagNames && !tagNames.isEmpty()) {\n                for (final TagName tagName : tagNames) {\n                    if (CategoryManager.isNotCategoryTagName(tagName)) {\n                        MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                        tagNameItem.setOnAction((ActionEvent t) -> {\n                            addTag(tagName, NO_COMMENT);\n                        });\n                        quickTagMenu.getItems().add(tagNameItem);\n                    }\n                }\n            } else {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            }\n\n            //   quickTagMenu.addSeparator();\n            // The \"Quick Tag\" menu also gets an \"Choose Tag...\" menu item.\n            // Selecting this item initiates a dialog that can be used to create\n            // or select a tag name and adds a tag with the resulting name.\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    TagName tagName = GetTagNameDialog.doDialog();\n                    if (tagName != null) {\n                        addTag(tagName, NO_COMMENT);\n                    }\n                });\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            // Create a \"Choose Tag and Comment...\" menu item. Selecting this item initiates\n            // a dialog that can be used to create or select a tag name with an \n            // optional comment and adds a tag with the resulting name.\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                    if (null != tagNameAndComment) {\n                            if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                                new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        } else {\n                                new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        }\n                    }\n                });\n            });\n            getItems().add(tagAndCommentItem);\n        }","id":14196,"modified_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            /* Each non-Category tag name in the current set of tags gets its\n             * own menu item in the \"Quick Tags\" sub-menu. Selecting one of\n             * these menu items adds a tag with the associated tag name. */\n            Collection<TagName> tagNames = controller.getTagsManager().getNonCategoryTagNames();\n            if (tagNames.isEmpty()) {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            } else {\n                for (final TagName tagName : tagNames) {\n                    MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                    tagNameItem.setOnAction((ActionEvent t) -> {\n                        addTag(tagName, NO_COMMENT);\n                    });\n                    quickTagMenu.getItems().add(tagNameItem);\n                }\n            }\n\n            /* The \"Quick Tag\" menu also gets an \"New Tag...\" menu item.\n             * Selecting this item initiates a dialog that can be used to create\n             * or select a tag name and adds a tag with the resulting name. */\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    TagName tagName = GetTagNameDialog.doDialog();\n                    if (tagName != null) {\n                        addTag(tagName, NO_COMMENT);\n                    }\n                });\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            /* Create a \"Tag and Comment...\" menu item. Selecting this item\n             * initiates a dialog that can be used to create or select a tag\n             * name with an optional comment and adds a tag with the resulting\n             * name. */\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                    if (null != tagNameAndComment) {\n                        if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                            new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        } else {\n                            new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        }\n                    }\n                });\n            });\n            getItems().add(tagAndCommentItem);\n        }","commit_id":"5dfae177dbec07dc50f622d1c235f2505858ed1c","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isCategoryTagName)\n                        .collect(Collectors.toSet());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","id":14197,"modified_method":"/**\n     * get all the TagNames that are not categories\n     *\n     * @return all the TagNames that are not categories, in alphabetical order\n     *         by displayName, or, an empty set if there was an exception looking them\n     *         up from the db.\n     */\n    @Nonnull\n    public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isNotCategoryTagName)\n                        .distinct().sorted()\n                        .collect(Collectors.toList());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","commit_id":"5dfae177dbec07dc50f622d1c235f2505858ed1c","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Get the current set of tag names.\n            DrawableTagsManager tagsManager = controller.getTagsManager();\n            List<TagName> tagNames = null;\n            try {\n                tagNames = tagsManager.getAllTagNames();\n            } catch (TskCoreException ex) {\n                Logger.getLogger(TagsManager.class.getName()).log(Level.SEVERE, \"Failed to get tag names\", ex);\n            }\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            // Each tag name in the current set of tags gets its own menu item in\n            // the \"Quick Tags\" sub-menu. Selecting one of these menu items adds\n            // a tag with the associated tag name. \n            if (null != tagNames && !tagNames.isEmpty()) {\n                for (final TagName tagName : tagNames) {\n                    if (CategoryManager.isNotCategoryTagName(tagName)) {\n                        MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                        tagNameItem.setOnAction((ActionEvent t) -> {\n                            addTag(tagName, NO_COMMENT);\n                        });\n                        quickTagMenu.getItems().add(tagNameItem);\n                    }\n                }\n            } else {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            }\n\n            //   quickTagMenu.addSeparator();\n            // The \"Quick Tag\" menu also gets an \"Choose Tag...\" menu item.\n            // Selecting this item initiates a dialog that can be used to create\n            // or select a tag name and adds a tag with the resulting name.\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                try {\n                    SwingUtilities.invokeAndWait(() -> {\n                        TagName tagName = GetTagNameDialog.doDialog();\n                        if (tagName != null) {\n                            addTag(tagName, NO_COMMENT);\n                        }\n                    });\n                } catch (InterruptedException | InvocationTargetException ex) {\n                    Exceptions.printStackTrace(ex);\n                }\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            // Create a \"Choose Tag and Comment...\" menu item. Selecting this item initiates\n            // a dialog that can be used to create or select a tag name with an \n            // optional comment and adds a tag with the resulting name.\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                try {\n                    SwingUtilities.invokeAndWait(() -> {\n                        GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                        if (null != tagNameAndComment) {\n                            if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                                new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                            } else {\n                                new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                            }\n                        }\n                    });\n                } catch (InterruptedException | InvocationTargetException ex) {\n                    Exceptions.printStackTrace(ex);\n                }\n            });\n            getItems().add(tagAndCommentItem);\n        }","id":14198,"modified_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            /* Each non-Category tag name in the current set of tags gets its\n             * own menu item in the \"Quick Tags\" sub-menu. Selecting one of\n             * these menu items adds a tag with the associated tag name. */\n            Collection<TagName> tagNames = controller.getTagsManager().getNonCategoryTagNames();\n            if (tagNames.isEmpty()) {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            } else {\n                for (final TagName tagName : tagNames) {\n                    MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                    tagNameItem.setOnAction((ActionEvent t) -> {\n                        addTag(tagName, NO_COMMENT);\n                    });\n                    quickTagMenu.getItems().add(tagNameItem);\n                }\n            }\n\n            /* The \"Quick Tag\" menu also gets an \"New Tag...\" menu item.\n             * Selecting this item initiates a dialog that can be used to create\n             * or select a tag name and adds a tag with the resulting name. */\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    TagName tagName = GetTagNameDialog.doDialog();\n                    if (tagName != null) {\n                        addTag(tagName, NO_COMMENT);\n                    }\n                });\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            /* Create a \"Tag and Comment...\" menu item. Selecting this item\n             * initiates a dialog that can be used to create or select a tag\n             * name with an optional comment and adds a tag with the resulting\n             * name. */\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                    if (null != tagNameAndComment) {\n                        if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                            new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        } else {\n                            new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        }\n                    }\n                });\n            });\n            getItems().add(tagAndCommentItem);\n        }","commit_id":"76cdc7863f27cd98832a0930a1866b3ac4107715","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isCategoryTagName)\n                        .collect(Collectors.toSet());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","id":14199,"modified_method":"/**\n     * get all the TagNames that are not categories\n     *\n     * @return all the TagNames that are not categories, in alphabetical order\n     *         by displayName, or, an empty set if there was an exception looking them\n     *         up from the db.\n     */\n    @Nonnull\n    public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isNotCategoryTagName)\n                        .distinct().sorted()\n                        .collect(Collectors.toList());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","commit_id":"76cdc7863f27cd98832a0930a1866b3ac4107715","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Get the current set of tag names.\n            DrawableTagsManager tagsManager = controller.getTagsManager();\n            List<TagName> tagNames = null;\n            try {\n                tagNames = tagsManager.getAllTagNames();\n            } catch (TskCoreException ex) {\n                Logger.getLogger(TagsManager.class.getName()).log(Level.SEVERE, \"Failed to get tag names\", ex);\n            }\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            // Each tag name in the current set of tags gets its own menu item in\n            // the \"Quick Tags\" sub-menu. Selecting one of these menu items adds\n            // a tag with the associated tag name. \n            if (null != tagNames && !tagNames.isEmpty()) {\n                for (final TagName tagName : tagNames) {\n                    if (CategoryManager.isNotCategoryTagName(tagName)) {\n                        MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                        tagNameItem.setOnAction((ActionEvent t) -> {\n                            addTag(tagName, NO_COMMENT);\n                        });\n                        quickTagMenu.getItems().add(tagNameItem);\n                    }\n                }\n            } else {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            }\n\n            //   quickTagMenu.addSeparator();\n            // The \"Quick Tag\" menu also gets an \"Choose Tag...\" menu item.\n            // Selecting this item initiates a dialog that can be used to create\n            // or select a tag name and adds a tag with the resulting name.\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    TagName tagName = GetTagNameDialog.doDialog();\n                    if (tagName != null) {\n                        addTag(tagName, NO_COMMENT);\n                 \n                    }\n                });\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            // Create a \"Choose Tag and Comment...\" menu item. Selecting this item initiates\n            // a dialog that can be used to create or select a tag name with an \n            // optional comment and adds a tag with the resulting name.\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                    if (null != tagNameAndComment) {\n                            if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                                new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        } else {\n                                new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        }\n                      \n                    }\n                });\n            });\n            getItems().add(tagAndCommentItem);\n        }","id":14200,"modified_method":"TagMenu(ImageGalleryController controller) {\n            super(getActionDisplayName());\n\n            // Create a \"Quick Tag\" sub-menu.\n            Menu quickTagMenu = new Menu(\"Quick Tag\");\n            getItems().add(quickTagMenu);\n\n            /* Each non-Category tag name in the current set of tags gets its\n             * own menu item in the \"Quick Tags\" sub-menu. Selecting one of\n             * these menu items adds a tag with the associated tag name. */\n            Collection<TagName> tagNames = controller.getTagsManager().getNonCategoryTagNames();\n            if (tagNames.isEmpty()) {\n                MenuItem empty = new MenuItem(\"No tags\");\n                empty.setDisable(true);\n                quickTagMenu.getItems().add(empty);\n            } else {\n                for (final TagName tagName : tagNames) {\n                    MenuItem tagNameItem = new MenuItem(tagName.getDisplayName());\n                    tagNameItem.setOnAction((ActionEvent t) -> {\n                        addTag(tagName, NO_COMMENT);\n                    });\n                    quickTagMenu.getItems().add(tagNameItem);\n                }\n            }\n\n            /* The \"Quick Tag\" menu also gets an \"New Tag...\" menu item.\n             * Selecting this item initiates a dialog that can be used to create\n             * or select a tag name and adds a tag with the resulting name. */\n            MenuItem newTagMenuItem = new MenuItem(\"New Tag...\");\n            newTagMenuItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    TagName tagName = GetTagNameDialog.doDialog();\n                    if (tagName != null) {\n                        addTag(tagName, NO_COMMENT);\n                 \n                    }\n                });\n            });\n            quickTagMenu.getItems().add(newTagMenuItem);\n\n            /* Create a \"Tag and Comment...\" menu item. Selecting this item\n             * initiates a dialog that can be used to create or select a tag\n             * name with an optional comment and adds a tag with the resulting\n             * name. */\n            MenuItem tagAndCommentItem = new MenuItem(\"Tag and Comment...\");\n            tagAndCommentItem.setOnAction((ActionEvent t) -> {\n                SwingUtilities.invokeLater(() -> {\n                    GetTagNameAndCommentDialog.TagNameAndComment tagNameAndComment = GetTagNameAndCommentDialog.doDialog();\n                    if (null != tagNameAndComment) {\n                        if (CategoryManager.isCategoryTagName(tagNameAndComment.getTagName())) {\n                            new CategorizeAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        } else {\n                            new AddDrawableTagAction(controller).addTag(tagNameAndComment.getTagName(), tagNameAndComment.getComment());\n                        }\n                      \n                    }\n                });\n            });\n            getItems().add(tagAndCommentItem);\n        }","commit_id":"28e3c015c34bfa3c191a6af67da106606fae1422","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isCategoryTagName)\n                        .collect(Collectors.toSet());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","id":14201,"modified_method":"/**\n     * get all the TagNames that are not categories\n     *\n     * @return all the TagNames that are not categories, in alphabetical order\n     *         by displayName, or, an empty set if there was an exception looking them\n     *         up from the db.\n     */\n    @Nonnull\n    public Collection<TagName> getNonCategoryTagNames() {\n        synchronized (autopsyTagsManagerLock) {\n            try {\n                return autopsyTagsManager.getAllTagNames().stream()\n                        .filter(CategoryManager::isNotCategoryTagName)\n                        .distinct().sorted()\n                        .collect(Collectors.toList());\n            } catch (TskCoreException | IllegalStateException ex) {\n                LOGGER.log(Level.WARNING, \"couldn't access case\", ex);\n            }\n            return Collections.emptySet();\n        }\n    }","commit_id":"28e3c015c34bfa3c191a6af67da106606fae1422","url":"https://github.com/sleuthkit/autopsy"},{"original_method":"/**\n     * @see org.opencms.db.I_CmsHistoryDriver#deleteEntries(CmsDbContext, I_CmsHistoryResource, int, long)\n     */\n    public int deleteEntries(CmsDbContext dbc, I_CmsHistoryResource resource, int versionsToKeep, long time)\n    throws CmsDataAccessException {\n\n        Connection conn = null;\n        PreparedStatement stmt = null;\n        ResultSet res = null;\n\n        try {\n            conn = m_sqlManager.getConnection(dbc);\n\n            int maxVersion = -1;\n            // get the maximal version number for this resource\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_MAXVER\");\n            stmt.setString(1, resource.getStructureId().toString());\n            res = stmt.executeQuery();\n            if (res.next()) {\n                maxVersion = res.getInt(1);\n                while (res.next()) {\n                    // do nothing only move through all rows because of mssql odbc driver\n                }\n            } else {\n                // make sure the connection is closed\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return 0;\n            }\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n\n            if (time >= 0) {\n                int maxVersionByTime = -1;\n                conn = m_sqlManager.getConnection(dbc);\n                // get the maximal version to keep for this resource based on the time parameter\n                stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_MAXVER_BYTIME\");\n                stmt.setString(1, resource.getStructureId().toString());\n                stmt.setLong(2, time);\n                res = stmt.executeQuery();\n                if (res.next()) {\n                    maxVersionByTime = res.getInt(1);\n                    while (res.next()) {\n                        // do nothing only move through all rows because of mssql odbc driver\n                    }\n                }\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                if (maxVersionByTime > 0) {\n                    if (versionsToKeep < 0) {\n                        versionsToKeep = (maxVersion - maxVersionByTime);\n                    } else {\n                        versionsToKeep = Math.min(versionsToKeep, (maxVersion - maxVersionByTime));\n                    }\n                }\n            }\n\n            if ((maxVersion - versionsToKeep) <= 0) {\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return 0;\n            }\n\n            // get the minimal structure publish tag to keep for this sibling\n            int minStrPublishTagToKeep = -1;\n            conn = m_sqlManager.getConnection(dbc);\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_HISTORY_READ_MAXTAG_FOR_VERSION\");\n            stmt.setString(1, resource.getStructureId().toString());\n            stmt.setInt(2, (1 + maxVersion) - versionsToKeep);\n            res = stmt.executeQuery();\n            if (res.next()) {\n                minStrPublishTagToKeep = res.getInt(1);\n                while (res.next()) {\n                    // do nothing only move through all rows because of mssql odbc driver\n                }\n            } else {\n                // make sure the statement and the result is closed\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return 0;\n            }\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n            if (minStrPublishTagToKeep < 1) {\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return 0;\n            }\n            minStrPublishTagToKeep++;\n\n            // delete the properties\n            conn = m_sqlManager.getConnection(dbc);\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_PROPERTIES_HISTORY_DELETE\");\n            stmt.setString(1, resource.getStructureId().toString());\n            stmt.setInt(2, minStrPublishTagToKeep);\n            stmt.executeUpdate();\n            m_sqlManager.closeAll(dbc, null, stmt, null);\n\n            // delete the structure entries\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_DELETE\");\n            stmt.setString(1, resource.getStructureId().toString());\n            stmt.setInt(2, minStrPublishTagToKeep);\n            int structureVersions = stmt.executeUpdate();\n            m_sqlManager.closeAll(dbc, null, stmt, null);\n\n            // get the minimal resource publish tag to keep, \n            // all entries with publish tag less than this will be deleted\n            int minResPublishTagToKeep = -1;\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_HISTORY_READ_MIN_USED_TAG\");\n            stmt.setString(1, resource.getResourceId().toString());\n            res = stmt.executeQuery();\n            if (res.next()) {\n                minResPublishTagToKeep = res.getInt(1);\n                if (res.wasNull()) {\n                    // the database will return a row with a single NULL column if there are no rows at all for the given\n                    // resource id. This means that we want to clean up all resource history and content history entries \n                    // for this resource id, and we achieve this by comparing their publish tag with the maximum integer.\n                    minResPublishTagToKeep = Integer.MAX_VALUE;\n                }\n                while (res.next()) {\n                    // do nothing only move through all rows because of mssql odbc driver\n                }\n            } else {\n                // make sure the statement and the result is closed\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return structureVersions;\n            }\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n\n            // delete the resource entries\n            conn = m_sqlManager.getConnection(dbc);\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_RESOURCES_HISTORY_DELETE\");\n            stmt.setString(1, resource.getResourceId().toString());\n            stmt.setInt(2, minResPublishTagToKeep);\n            int resourceVersions = stmt.executeUpdate();\n            m_sqlManager.closeAll(dbc, null, stmt, null);\n\n            // delete the content entries\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_CONTENT_HISTORY_DELETE\");\n            stmt.setString(1, resource.getResourceId().toString());\n            stmt.setInt(2, minResPublishTagToKeep);\n            stmt.executeUpdate();\n\n            // make sure the statement and the result is closed\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n            internalCleanup(dbc, resource);\n            return Math.max(structureVersions, resourceVersions);\n        } catch (SQLException e) {\n            throw new CmsDbSqlException(Messages.get().container(\n                Messages.ERR_GENERIC_SQL_1,\n                CmsDbSqlException.getErrorQuery(stmt)), e);\n        } finally {\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n        }\n    }","id":14202,"modified_method":"/**\n     * @see org.opencms.db.I_CmsHistoryDriver#deleteEntries(CmsDbContext, I_CmsHistoryResource, int, long)\n     */\n    public int deleteEntries(CmsDbContext dbc, I_CmsHistoryResource resource, int versionsToKeep, long time)\n    throws CmsDataAccessException {\n\n        Connection conn = null;\n        PreparedStatement stmt = null;\n        ResultSet res = null;\n\n        try {\n            conn = m_sqlManager.getConnection(dbc);\n\n            int maxVersion = -1;\n            // get the maximal version number for this resource\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_MAXVER\");\n            stmt.setString(1, resource.getStructureId().toString());\n            res = stmt.executeQuery();\n            boolean noHistoryStructure = false;\n            if (res.next()) {\n                maxVersion = res.getInt(1);\n                noHistoryStructure |= res.wasNull();\n                while (res.next()) {\n                    // do nothing only move through all rows because of mssql odbc driver\n                }\n            } else {\n                // make sure the connection is closed\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                // nothing to delete\n                internalCleanup(dbc, resource);\n                return 0;\n            }\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n\n            if (time >= 0) {\n                int maxVersionByTime = -1;\n                conn = m_sqlManager.getConnection(dbc);\n                // get the maximal version to keep for this resource based on the time parameter\n                stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_MAXVER_BYTIME\");\n                stmt.setString(1, resource.getStructureId().toString());\n                stmt.setLong(2, time);\n                res = stmt.executeQuery();\n                if (res.next()) {\n                    maxVersionByTime = res.getInt(1);\n                    while (res.next()) {\n                        // do nothing only move through all rows because of mssql odbc driver\n                    }\n                }\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                if (maxVersionByTime > 0) {\n                    if (versionsToKeep < 0) {\n                        versionsToKeep = (maxVersion - maxVersionByTime);\n                    } else {\n                        versionsToKeep = Math.min(versionsToKeep, (maxVersion - maxVersionByTime));\n                    }\n                }\n            }\n            int structureVersions = 0;\n\n            conn = m_sqlManager.getConnection(dbc);\n            if (!noHistoryStructure) {\n                if (((maxVersion - versionsToKeep) <= 0)) {\n                    // nothing to delete\n                    internalCleanup(dbc, resource);\n                    return 0;\n                }\n\n                // get the minimal structure publish tag to keep for this sibling\n                int minStrPublishTagToKeep = -1;\n\n                stmt = m_sqlManager.getPreparedStatement(conn, \"C_HISTORY_READ_MAXTAG_FOR_VERSION\");\n                stmt.setString(1, resource.getStructureId().toString());\n                stmt.setInt(2, (1 + maxVersion) - versionsToKeep);\n                res = stmt.executeQuery();\n                if (res.next()) {\n                    minStrPublishTagToKeep = res.getInt(1);\n                    while (res.next()) {\n                        // do nothing only move through all rows because of mssql odbc driver\n                    }\n                } else {\n                    // make sure the statement and the result is closed\n                    m_sqlManager.closeAll(dbc, conn, stmt, res);\n                    // nothing to delete\n                    internalCleanup(dbc, resource);\n                    return 0;\n                }\n                m_sqlManager.closeAll(dbc, conn, stmt, res);\n                if (minStrPublishTagToKeep < 1) {\n                    // nothing to delete\n                    internalCleanup(dbc, resource);\n                    return 0;\n                }\n                minStrPublishTagToKeep++;\n\n                // delete the properties\n                conn = m_sqlManager.getConnection(dbc);\n                stmt = m_sqlManager.getPreparedStatement(conn, \"C_PROPERTIES_HISTORY_DELETE\");\n                stmt.setString(1, resource.getStructureId().toString());\n                stmt.setInt(2, minStrPublishTagToKeep);\n                stmt.executeUpdate();\n                m_sqlManager.closeAll(dbc, null, stmt, null);\n\n                // delete the structure entries\n                stmt = m_sqlManager.getPreparedStatement(conn, \"C_STRUCTURE_HISTORY_DELETE\");\n                stmt.setString(1, resource.getStructureId().toString());\n                stmt.setInt(2, minStrPublishTagToKeep);\n                structureVersions = stmt.executeUpdate();\n                m_sqlManager.closeAll(dbc, null, stmt, null);\n            }\n\n            // get the minimal resource publish tag to keep, \n            // all entries with publish tag less than this will be deleted\n            int minResPublishTagToKeep = -1;\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_HISTORY_READ_MIN_USED_TAG\");\n            stmt.setString(1, resource.getResourceId().toString());\n            res = stmt.executeQuery();\n            if (res.next()) {\n                minResPublishTagToKeep = res.getInt(1);\n                if (res.wasNull()) {\n                    // the database will return a row with a single NULL column if there are no rows at all for the given\n                    // resource id. This means that we want to clean up all resource history and content history entries \n                    // for this resource id, and we achieve this by comparing their publish tag with the maximum integer.\n                    minResPublishTagToKeep = Integer.MAX_VALUE;\n                }\n                while (res.next()) {\n                    // do nothing only move through all rows because of mssql odbc driver\n                }\n            }\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n\n            // delete the resource entries\n            conn = m_sqlManager.getConnection(dbc);\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_RESOURCES_HISTORY_DELETE\");\n            stmt.setString(1, resource.getResourceId().toString());\n            stmt.setInt(2, minResPublishTagToKeep);\n            int resourceVersions = stmt.executeUpdate();\n            m_sqlManager.closeAll(dbc, null, stmt, null);\n\n            // delete the content entries\n            stmt = m_sqlManager.getPreparedStatement(conn, \"C_CONTENT_HISTORY_DELETE\");\n            stmt.setString(1, resource.getResourceId().toString());\n            stmt.setInt(2, minResPublishTagToKeep);\n            stmt.executeUpdate();\n\n            // make sure the statement and the result is closed\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n            internalCleanup(dbc, resource);\n            return Math.max(structureVersions, resourceVersions);\n        } catch (SQLException e) {\n            throw new CmsDbSqlException(Messages.get().container(\n                Messages.ERR_GENERIC_SQL_1,\n                CmsDbSqlException.getErrorQuery(stmt)), e);\n        } finally {\n            m_sqlManager.closeAll(dbc, conn, stmt, res);\n        }\n    }","commit_id":"2db9e9482d554afba33d0a2066fd41350babd535","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n   * Collapse multi-words preposition of the following format: advmod|prt(gov,\n   * mwp[0]) prep(gov,mwp[1]) pobj|pcomp(mwp[1], compl) ->\n   * prep_mwp[0]_mwp[1](gov, compl)\n   * <p/>\n   *\n   * @param list\n   *          List of typedDependencies to work on\n   */\n  private static void collapse2WPbis(Collection<TypedDependency> list) {\n    Collection<TypedDependency> newTypedDeps = new ArrayList<TypedDependency>();\n\n    for (String[] mwp : MULTIWORD_PREPS) {\n      newTypedDeps.clear();\n\n      IndexedWord mwp0 = null;\n      IndexedWord mwp1 = null;\n      IndexedWord governor = null;\n\n      TypedDependency prep = null;\n      TypedDependency dep = null;\n      TypedDependency pobj = null;\n      TypedDependency newtd = null;\n\n      // first find the first part of the multi_preposition: advmod|prt(gov, mwp[0])\n\n      for (TypedDependency td : list) {\n        if (td.dep().value().equalsIgnoreCase(mwp[0]) && (td.reln() == PHRASAL_VERB_PARTICLE || td.reln() == ADVERBIAL_MODIFIER || td.reln() == DEPENDENT || td.reln() == MULTI_WORD_EXPRESSION)) {\n          // we found advmod(gov, mwp0) or prt(gov, mwp0)\n          governor = td.gov();\n          mwp0 = td.dep();\n          dep = td;\n        }\n      }\n\n      // now search for the second part: prep(gov, mwp1)\n      // the two words in the mwp should be next to another in the sentence\n      // (difference of indexes = 1)\n\n      if (mwp0 == null) {\n        continue;\n      }\n\n      for (TypedDependency td1 : list) {\n        if (td1.reln() == PREPOSITIONAL_MODIFIER && td1.dep().value().equalsIgnoreCase(mwp[1]) && Math.abs(td1.dep().index() - mwp0.index()) == 1 && td1.gov().equals(governor)) {// we\n          // found\n          // prep(gov,\n          // mwp1)\n          mwp1 = td1.dep();\n          prep = td1;\n        }\n      }\n\n      if (mwp1 == null) {\n        continue;\n      }\n\n      // search for the complement: pobj|pcomp(mwp1,X)\n      for (TypedDependency td2 : list) {\n        if (td2.reln() == PREPOSITIONAL_OBJECT && td2.gov().equals(mwp1)) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrep(mwp[0] + '_' + mwp[1]);\n          if (governor != null) {\n            newtd = new TypedDependency(gr, governor, pobj.dep());\n          }\n        }\n        if (td2.reln() == PREPOSITIONAL_COMPLEMENT && td2.gov().equals(mwp1)) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrepC(mwp[0] + '_' + mwp[1]);\n          if (governor != null) {\n            newtd = new TypedDependency(gr, governor, pobj.dep());\n          }\n        }\n      }\n\n      // only if we found the three parts, set to KILL and remove\n      // and add the new one\n      if (prep != null && pobj != null && newtd != null) {\n        prep.setReln(KILL);\n        dep.setReln(KILL);\n        pobj.setReln(KILL);\n        newTypedDeps.add(newtd);\n\n        // now remove typed dependencies with reln \"kill\"\n        // and promote possible orphans\n        for (TypedDependency td1 : list) {\n          if (td1.reln() != KILL) {\n            if (td1.gov().equals(mwp0) || td1.gov().equals(mwp1)) {\n              td1.setGov(governor);\n            }\n            if (!newTypedDeps.contains(td1)) {\n              newTypedDeps.add(td1);\n            }\n          }\n        }\n        list.clear();\n        list.addAll(newTypedDeps);\n      }\n    }\n  }","id":14203,"modified_method":"/**\n   * Collapse multi-words preposition of the following format: advmod|prt(gov,\n   * mwp[0]) prep(gov,mwp[1]) pobj|pcomp(mwp[1], compl) ->\n   * prep_mwp[0]_mwp[1](gov, compl)\n   * <p/>\n   *\n   * @param list\n   *          List of typedDependencies to work on\n   */\n  private static void collapse2WPbis(Collection<TypedDependency> list) {\n    Collection<TypedDependency> newTypedDeps = new ArrayList<TypedDependency>();\n\n    for (String[] mwp : MULTIWORD_PREPS) {\n      newTypedDeps.clear();\n\n      IndexedWord mwp0 = null;\n      IndexedWord mwp1 = null;\n      IndexedWord governor = null;\n\n      TypedDependency prep = null;\n      TypedDependency dep = null;\n      TypedDependency pobj = null;\n      TypedDependency newtd = null;\n\n      // first find the first part of the multi_preposition: advmod|prt(gov, mwp[0])\n\n      for (TypedDependency td : list) {\n        if (td.dep().value().equalsIgnoreCase(mwp[0]) && (td.reln() == PHRASAL_VERB_PARTICLE || td.reln() == ADVERBIAL_MODIFIER || td.reln() == DEPENDENT || td.reln() == MULTI_WORD_EXPRESSION)) {\n          // we found advmod(gov, mwp0) or prt(gov, mwp0)\n          governor = td.gov();\n          mwp0 = td.dep();\n          dep = td;\n        }\n      }\n\n      // now search for the second part: prep(gov, mwp1)\n      // the two words in the mwp should be next to another in the sentence\n      // (difference of indexes = 1)\n\n      if (mwp0 == null || governor == null) {\n        continue;\n      }\n\n      for (TypedDependency td1 : list) {\n        if (td1.reln() == PREPOSITIONAL_MODIFIER && td1.dep().value().equalsIgnoreCase(mwp[1]) && Math.abs(td1.dep().index() - mwp0.index()) == 1 && td1.gov().equals(governor)) {// we\n          // found\n          // prep(gov,\n          // mwp1)\n          mwp1 = td1.dep();\n          prep = td1;\n        }\n      }\n\n      if (mwp1 == null) {\n        continue;\n      }\n\n      // search for the complement: pobj|pcomp(mwp1,X)\n      for (TypedDependency td2 : list) {\n        if (td2.reln() == PREPOSITIONAL_OBJECT && td2.gov().equals(mwp1)) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrep(mwp[0] + '_' + mwp[1]);\n          newtd = new TypedDependency(gr, governor, pobj.dep());\n        }\n        if (td2.reln() == PREPOSITIONAL_COMPLEMENT && td2.gov().equals(mwp1)) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrepC(mwp[0] + '_' + mwp[1]);\n          newtd = new TypedDependency(gr, governor, pobj.dep());\n        }\n      }\n\n      if (pobj == null) {\n        return;\n      }\n\n      // only if we found the three parts, set to KILL and remove\n      // and add the new one\n      // now prep != null, pobj != null and newtd != null\n\n      prep.setReln(KILL);\n      dep.setReln(KILL);\n      pobj.setReln(KILL);\n      newTypedDeps.add(newtd);\n\n      // now remove typed dependencies with reln \"kill\"\n      // and promote possible orphans\n      for (TypedDependency td1 : list) {\n        if (td1.reln() != KILL) {\n          if (td1.gov().equals(mwp0) || td1.gov().equals(mwp1)) {\n            td1.setGov(governor);\n          }\n          if (!newTypedDeps.contains(td1)) {\n            newTypedDeps.add(td1);\n          }\n        }\n      }\n      list.clear();\n      list.addAll(newTypedDeps);\n    }\n  }","commit_id":"3b0f81e44f48cea00b6bff94712a20cfffb82346","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"/**\n   * Look for ref rules for a given word.  We look through the\n   * children and grandchildren of the rcmod dependency, and if any\n   * children or grandchildren depend on a that/what/which/etc word,\n   * we take the leftmost that/what/which/etc word as the dependent\n   * for the ref TypedDependency.\n   */\n  private static void addRef(Collection<TypedDependency> list) {\n    List<TypedDependency> newDeps = new ArrayList<TypedDependency>();\n\n    for (TypedDependency rcmod : list) {\n      if (rcmod.reln() != RELATIVE_CLAUSE_MODIFIER) {\n        // we only add ref dependencies across relative clauses\n        continue;\n      }\n\n      IndexedWord head = rcmod.gov();\n      IndexedWord modifier = rcmod.dep();\n\n      TypedDependency leftChild = null;\n      for (TypedDependency child : list) {\n        if (child.gov().equals(modifier) &&\n            RELATIVIZING_WORD_PATTERN.matcher(child.dep().value()).matches() &&\n            (leftChild == null || child.dep().index() < leftChild.dep().index())) {\n          leftChild = child;\n        }\n      }\n\n      // TODO: could be made more efficient\n      TypedDependency leftGrandchild = null;\n      for (TypedDependency child : list) {\n        if (!child.gov().equals(modifier)) {\n          continue;\n        }\n        for (TypedDependency grandchild : list) {\n          if (grandchild.gov().equals(child.dep()) &&\n              RELATIVIZING_WORD_PATTERN.matcher(grandchild.dep().value()).matches() &&\n              (leftGrandchild == null || grandchild.dep().index() < leftGrandchild.dep().index())) {\n            leftGrandchild = grandchild;\n          }\n        }\n      }\n\n      TypedDependency newDep = null;\n      if (leftGrandchild != null && (leftChild == null || leftGrandchild.dep().index() < leftChild.dep().index())) {\n        newDep = new TypedDependency(REFERENT, head, leftGrandchild.dep());\n      } else if (leftChild != null) {\n        newDep = new TypedDependency(REFERENT, head, leftChild.dep());\n      }\n      if (newDep != null) {\n        newDeps.add(newDep);\n      }\n    }\n\n    for (TypedDependency newDep : newDeps) {\n      if (!list.contains(newDep)) {\n        newDep.setExtra();\n        list.add(newDep);\n      }\n    }\n  }","id":14204,"modified_method":"/**\n   * Look for ref rules for a given word.  We look through the\n   * children and grandchildren of the rcmod dependency, and if any\n   * children or grandchildren depend on a that/what/which/etc word,\n   * we take the leftmost that/what/which/etc word as the dependent\n   * for the ref TypedDependency.\n   */\n  private static void addRef(Collection<TypedDependency> list) {\n    List<TypedDependency> newDeps = new ArrayList<TypedDependency>();\n\n    for (TypedDependency rcmod : list) {\n      if (rcmod.reln() != RELATIVE_CLAUSE_MODIFIER) {\n        // we only add ref dependencies across relative clauses\n        continue;\n      }\n\n      IndexedWord head = rcmod.gov();\n      IndexedWord modifier = rcmod.dep();\n\n      TypedDependency leftChild = null;\n      for (TypedDependency child : list) {\n        if (child.gov().equals(modifier) &&\n            EnglishPatterns.RELATIVIZING_WORD_PATTERN.matcher(child.dep().value()).matches() &&\n            (leftChild == null || child.dep().index() < leftChild.dep().index())) {\n          leftChild = child;\n        }\n      }\n\n      // TODO: could be made more efficient\n      TypedDependency leftGrandchild = null;\n      for (TypedDependency child : list) {\n        if (!child.gov().equals(modifier)) {\n          continue;\n        }\n        for (TypedDependency grandchild : list) {\n          if (grandchild.gov().equals(child.dep()) &&\n              EnglishPatterns.RELATIVIZING_WORD_PATTERN.matcher(grandchild.dep().value()).matches() &&\n              (leftGrandchild == null || grandchild.dep().index() < leftGrandchild.dep().index())) {\n            leftGrandchild = grandchild;\n          }\n        }\n      }\n\n      TypedDependency newDep = null;\n      if (leftGrandchild != null && (leftChild == null || leftGrandchild.dep().index() < leftChild.dep().index())) {\n        newDep = new TypedDependency(REFERENT, head, leftGrandchild.dep());\n      } else if (leftChild != null) {\n        newDep = new TypedDependency(REFERENT, head, leftChild.dep());\n      }\n      if (newDep != null) {\n        newDeps.add(newDep);\n      }\n    }\n\n    for (TypedDependency newDep : newDeps) {\n      if (!list.contains(newDep)) {\n        newDep.setExtra();\n        list.add(newDep);\n      }\n    }\n  }","commit_id":"3b0f81e44f48cea00b6bff94712a20cfffb82346","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"/**\n   * Collapse multi-words preposition of the following format, which comes from\n   * flat annotation. This handles e.g., \"because of\" (PP (IN because) (IN of)\n   * ...), \"such as\" (PP (JJ such) (IN as) ...)\n   * <p/>\n   * prep(gov, mwp[1]) dep(mpw[1], mwp[0]) pobj(mwp[1], compl) ->\n   * prep_mwp[0]_mwp[1](gov, compl)\n   *\n   * @param list\n   *          List of typedDependencies to work on\n   */\n  private static void collapseFlatMWP(Collection<TypedDependency> list) {\n    Collection<TypedDependency> newTypedDeps = new ArrayList<TypedDependency>();\n\n    for (String[] mwp : MULTIWORD_PREPS) {\n      newTypedDeps.clear();\n\n      IndexedWord mwp1 = null;\n      IndexedWord governor = null;\n\n      TypedDependency prep = null;\n      TypedDependency dep = null;\n      TypedDependency pobj = null;\n\n      // first find the multi_preposition: dep(mpw[1], mwp[0])\n      for (TypedDependency td : list) {\n        if (Math.abs(td.gov().index() - td.dep().index()) == 1 && td.gov().value().equalsIgnoreCase(mwp[1]) && td.dep().value().equalsIgnoreCase(mwp[0])) {\n          mwp1 = td.gov();\n          dep = td;\n        }\n      }\n\n      if (mwp1 == null) {\n        continue;\n      }\n\n      // now search for prep(gov, mwp1)\n      for (TypedDependency td1 : list) {\n        if (td1.dep().equals(mwp1) && td1.reln() == PREPOSITIONAL_MODIFIER) {\n          // we found prep(gov, mwp1)\n          prep = td1;\n          governor = prep.gov();\n        }\n      }\n\n      if (prep == null) {\n        continue;\n      }\n\n      // search for the complement: pobj|pcomp(mwp1,X)\n      for (TypedDependency td2 : list) {\n        if (td2.gov().equals(mwp1) && td2.reln() == PREPOSITIONAL_OBJECT) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrep(mwp[0] + '_' + mwp[1]);\n          newTypedDeps.add(new TypedDependency(gr, governor, pobj.dep()));\n        }\n        if (td2.gov().equals(mwp1) && td2.reln() == PREPOSITIONAL_COMPLEMENT) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrepC(mwp[0] + '_' + mwp[1]);\n          newTypedDeps.add(new TypedDependency(gr, governor, pobj.dep()));\n        }\n      }\n\n      // only if we found the three parts, set to KILL and remove\n      if (prep != null && dep != null && pobj != null) {\n        prep.setReln(KILL);\n        dep.setReln(KILL);\n        pobj.setReln(KILL);\n\n        // now remove typed dependencies with reln \"kill\"\n        // and promote possible orphans\n        for (TypedDependency td1 : list) {\n          if (td1.reln() != KILL) {\n            if (td1.gov().equals(mwp1)) {\n              td1.setGov(governor);\n            }\n            if (!newTypedDeps.contains(td1)) {\n              newTypedDeps.add(td1);\n            }\n          }\n        }\n        list.clear();\n        list.addAll(newTypedDeps);\n      }\n    }\n  }","id":14205,"modified_method":"/**\n   * Collapse multi-words preposition of the following format, which comes from\n   * flat annotation. This handles e.g., \"because of\" (PP (IN because) (IN of)\n   * ...), \"such as\" (PP (JJ such) (IN as) ...)\n   * <p/>\n   * prep(gov, mwp[1]) dep(mpw[1], mwp[0]) pobj(mwp[1], compl) ->\n   * prep_mwp[0]_mwp[1](gov, compl)\n   *\n   * @param list\n   *          List of typedDependencies to work on\n   */\n  private static void collapseFlatMWP(Collection<TypedDependency> list) {\n    Collection<TypedDependency> newTypedDeps = new ArrayList<TypedDependency>();\n\n    for (String[] mwp : MULTIWORD_PREPS) {\n      newTypedDeps.clear();\n\n      IndexedWord mwp1 = null;\n      IndexedWord governor = null;\n\n      TypedDependency prep = null;\n      TypedDependency dep = null;\n      TypedDependency pobj = null;\n\n      // first find the multi_preposition: dep(mpw[1], mwp[0])\n      for (TypedDependency td : list) {\n        if (Math.abs(td.gov().index() - td.dep().index()) == 1 && td.gov().value().equalsIgnoreCase(mwp[1]) && td.dep().value().equalsIgnoreCase(mwp[0])) {\n          mwp1 = td.gov();\n          dep = td;\n        }\n      }\n\n      if (mwp1 == null) {\n        continue;\n      }\n\n      // now search for prep(gov, mwp1)\n      for (TypedDependency td1 : list) {\n        if (td1.dep().equals(mwp1) && td1.reln() == PREPOSITIONAL_MODIFIER) {\n          // we found prep(gov, mwp1)\n          prep = td1;\n          governor = prep.gov();\n        }\n      }\n\n      if (prep == null) {\n        continue;\n      }\n\n      // search for the complement: pobj|pcomp(mwp1,X)\n      for (TypedDependency td2 : list) {\n        if (td2.gov().equals(mwp1) && td2.reln() == PREPOSITIONAL_OBJECT) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrep(mwp[0] + '_' + mwp[1]);\n          newTypedDeps.add(new TypedDependency(gr, governor, pobj.dep()));\n        }\n        if (td2.gov().equals(mwp1) && td2.reln() == PREPOSITIONAL_COMPLEMENT) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr = EnglishGrammaticalRelations.getPrepC(mwp[0] + '_' + mwp[1]);\n          newTypedDeps.add(new TypedDependency(gr, governor, pobj.dep()));\n        }\n      }\n\n      if (pobj == null) {\n        return;\n      }\n      // only if we found the three parts, set to KILL and remove\n      // we know prep != null && dep != null && dep != null\n      prep.setReln(KILL);\n      dep.setReln(KILL);\n      pobj.setReln(KILL);\n\n      // now remove typed dependencies with reln \"kill\"\n      // and promote possible orphans\n      for (TypedDependency td1 : list) {\n        if (td1.reln() != KILL) {\n          if (td1.gov().equals(mwp1)) {\n            td1.setGov(governor);\n          }\n          if (!newTypedDeps.contains(td1)) {\n            newTypedDeps.add(td1);\n          }\n        }\n      }\n      list.clear();\n      list.addAll(newTypedDeps);\n    }\n  }","commit_id":"3b0f81e44f48cea00b6bff94712a20cfffb82346","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"/**\n   * Collapse multiword preposition of the following format:\n   * prep|advmod|dep|amod(gov, mwp0) dep(mpw0,mwp1) pobj|pcomp(mwp1, compl) or\n   * pobj|pcomp(mwp0, compl) -> prep_mwp0_mwp1(gov, compl)\n   * <p/>\n   *\n   * @param list\n   *          List of typedDependencies to work on,\n   * @param newTypedDeps\n   *          List of typedDependencies that we construct\n   * @param str_mwp0\n   *          First part of the multiword preposition to construct the collapsed\n   *          preposition\n   * @param str_mwp1\n   *          Second part of the multiword preposition to construct the\n   *          collapsed preposition\n   * @param w_mwp0\n   *          First part of the multiword preposition that we look for\n   * @param w_mwp1\n   *          Second part of the multiword preposition that we look for\n   */\n  private static void collapseMultiWordPrep(Collection<TypedDependency> list, Collection<TypedDependency> newTypedDeps, String str_mwp0, String str_mwp1, String w_mwp0, String w_mwp1) {\n\n    // first find the multiword_preposition: dep(mpw[0], mwp[1])\n    // the two words should be next to another in the sentence (difference of\n    // indexes = 1)\n    IndexedWord mwp0 = null;\n    IndexedWord mwp1 = null;\n    TypedDependency dep = null;\n    for (TypedDependency td : list) {\n      if (td.gov().value().equalsIgnoreCase(w_mwp0) && td.dep().value().equalsIgnoreCase(w_mwp1) && Math.abs(td.gov().index() - td.dep().index()) == 1) {\n        mwp0 = td.gov();\n        mwp1 = td.dep();\n        dep = td;\n      }\n    }\n\n    if (mwp0 == null) {\n      return;\n    }\n\n    // now search for prep|advmod|dep|amod(gov, mwp0)\n    IndexedWord governor = null;\n    TypedDependency prep = null;\n    for (TypedDependency td1 : list) {\n      if ((td1.reln() == PREPOSITIONAL_MODIFIER || td1.reln() == ADVERBIAL_MODIFIER || td1.reln() == ADJECTIVAL_MODIFIER || td1.reln() == DEPENDENT || td1.reln() == MULTI_WORD_EXPRESSION) && td1.dep().equals(mwp0)) {\n        // we found prep|advmod|dep|amod(gov, mwp0)\n        prep = td1;\n        governor = prep.gov();\n      }\n    }\n\n    if (prep == null) {\n      return;\n    }\n\n    // search for the complement: pobj|pcomp(mwp1,X)\n    // or for pobj|pcomp(mwp0,X)\n    // There may be more than one in weird constructions; if there are several,\n    // take the one with the LOWEST index!\n    TypedDependency pobj = null;\n    TypedDependency newtd = null;\n    for (TypedDependency td2 : list) {\n      if ((td2.reln() == PREPOSITIONAL_OBJECT || td2.reln() == PREPOSITIONAL_COMPLEMENT) && (td2.gov().equals(mwp1) || td2.gov().equals(mwp0))) {\n        if (pobj == null || pobj.dep().index() > td2.dep().index()) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr;\n          if (td2.reln() == PREPOSITIONAL_COMPLEMENT) {\n            gr = EnglishGrammaticalRelations.getPrepC(str_mwp0 + '_' + str_mwp1);\n          } else {\n            gr = EnglishGrammaticalRelations.getPrep(str_mwp0 + '_' + str_mwp1);\n          }\n          if (governor != null) {\n            newtd = new TypedDependency(gr, governor, pobj.dep());\n          }\n        }\n      }\n    }\n\n    // only if we found the three parts, set to KILL and remove\n    // and add the new one\n    if (prep != null && dep != null && pobj != null && newtd != null) {\n      if (DEBUG) {\n        System.err.println(\"Removing \" + prep + \", \" + dep + \", and \" + pobj);\n        System.err.println(\"  and adding \" + newtd);\n      }\n      prep.setReln(KILL);\n      dep.setReln(KILL);\n      pobj.setReln(KILL);\n      newTypedDeps.add(newtd);\n\n      // now remove typed dependencies with reln \"kill\"\n      // and promote possible orphans\n      for (TypedDependency td1 : list) {\n        if (td1.reln() != KILL) {\n          if (td1.gov().equals(mwp0) || td1.gov().equals(mwp1)) {\n            // CDM: Thought of adding this in Jan 2010, but it causes\n            // conflicting relations tmod vs. pobj. Needs more thought\n            // maybe restrict pobj to first NP in PP, and allow tmod for a later\n            // one?\n            if (td1.reln() == TEMPORAL_MODIFIER) {\n              // special case when an extra NP-TMP is buried in a PP for\n              // \"during the same period last year\"\n              td1.setGov(pobj.dep());\n            } else {\n              td1.setGov(governor);\n            }\n          }\n          if (!newTypedDeps.contains(td1)) {\n            newTypedDeps.add(td1);\n          }\n        }\n      }\n      list.clear();\n      list.addAll(newTypedDeps);\n    }\n  }","id":14206,"modified_method":"/**\n   * Collapse multiword preposition of the following format:\n   * prep|advmod|dep|amod(gov, mwp0) dep(mpw0,mwp1) pobj|pcomp(mwp1, compl) or\n   * pobj|pcomp(mwp0, compl) -> prep_mwp0_mwp1(gov, compl)\n   * <p/>\n   *\n   * @param list\n   *          List of typedDependencies to work on,\n   * @param newTypedDeps\n   *          List of typedDependencies that we construct\n   * @param str_mwp0\n   *          First part of the multiword preposition to construct the collapsed\n   *          preposition\n   * @param str_mwp1\n   *          Second part of the multiword preposition to construct the\n   *          collapsed preposition\n   * @param w_mwp0\n   *          First part of the multiword preposition that we look for\n   * @param w_mwp1\n   *          Second part of the multiword preposition that we look for\n   */\n  private static void collapseMultiWordPrep(Collection<TypedDependency> list, Collection<TypedDependency> newTypedDeps, String str_mwp0, String str_mwp1, String w_mwp0, String w_mwp1) {\n\n    // first find the multiword_preposition: dep(mpw[0], mwp[1])\n    // the two words should be next to another in the sentence (difference of\n    // indexes = 1)\n    IndexedWord mwp0 = null;\n    IndexedWord mwp1 = null;\n    TypedDependency dep = null;\n    for (TypedDependency td : list) {\n      if (td.gov().value().equalsIgnoreCase(w_mwp0) && td.dep().value().equalsIgnoreCase(w_mwp1) && Math.abs(td.gov().index() - td.dep().index()) == 1) {\n        mwp0 = td.gov();\n        mwp1 = td.dep();\n        dep = td;\n      }\n    }\n\n    if (mwp0 == null) {\n      return;\n    }\n\n    // now search for prep|advmod|dep|amod(gov, mwp0)\n    IndexedWord governor = null;\n    TypedDependency prep = null;\n    for (TypedDependency td1 : list) {\n      if ((td1.reln() == PREPOSITIONAL_MODIFIER || td1.reln() == ADVERBIAL_MODIFIER || td1.reln() == ADJECTIVAL_MODIFIER || td1.reln() == DEPENDENT || td1.reln() == MULTI_WORD_EXPRESSION) && td1.dep().equals(mwp0)) {\n        // we found prep|advmod|dep|amod(gov, mwp0)\n        prep = td1;\n        governor = prep.gov();\n      }\n    }\n\n    if (prep == null) {\n      return;\n    }\n\n    // search for the complement: pobj|pcomp(mwp1,X)\n    // or for pobj|pcomp(mwp0,X)\n    // There may be more than one in weird constructions; if there are several,\n    // take the one with the LOWEST index!\n    TypedDependency pobj = null;\n    TypedDependency newtd = null;\n    for (TypedDependency td2 : list) {\n      if ((td2.reln() == PREPOSITIONAL_OBJECT || td2.reln() == PREPOSITIONAL_COMPLEMENT) && (td2.gov().equals(mwp1) || td2.gov().equals(mwp0))) {\n        if (pobj == null || pobj.dep().index() > td2.dep().index()) {\n          pobj = td2;\n          // create the new gr relation\n          GrammaticalRelation gr;\n          if (td2.reln() == PREPOSITIONAL_COMPLEMENT) {\n            gr = EnglishGrammaticalRelations.getPrepC(str_mwp0 + '_' + str_mwp1);\n          } else {\n            gr = EnglishGrammaticalRelations.getPrep(str_mwp0 + '_' + str_mwp1);\n          }\n          if (governor != null) {\n            newtd = new TypedDependency(gr, governor, pobj.dep());\n          }\n        }\n      }\n    }\n\n    if (pobj == null || newtd == null) {\n      return;\n    }\n\n    // only if we found the three parts, set to KILL and remove\n    // and add the new one\n    // Necessarily from the above: prep != null, dep != null, pobj != null, newtd != null\n\n    if (DEBUG) {\n      System.err.println(\"Removing \" + prep + \", \" + dep + \", and \" + pobj);\n      System.err.println(\"  and adding \" + newtd);\n    }\n    prep.setReln(KILL);\n    dep.setReln(KILL);\n    pobj.setReln(KILL);\n    newTypedDeps.add(newtd);\n\n    // now remove typed dependencies with reln \"kill\"\n    // and promote possible orphans\n    for (TypedDependency td1 : list) {\n      if (td1.reln() != KILL) {\n        if (td1.gov().equals(mwp0) || td1.gov().equals(mwp1)) {\n          // CDM: Thought of adding this in Jan 2010, but it causes\n          // conflicting relations tmod vs. pobj. Needs more thought\n          // maybe restrict pobj to first NP in PP, and allow tmod for a later\n          // one?\n          if (td1.reln() == TEMPORAL_MODIFIER) {\n            // special case when an extra NP-TMP is buried in a PP for\n            // \"during the same period last year\"\n            td1.setGov(pobj.dep());\n          } else {\n            td1.setGov(governor);\n          }\n        }\n        if (!newTypedDeps.contains(td1)) {\n          newTypedDeps.add(td1);\n        }\n      }\n    }\n    list.clear();\n    list.addAll(newTypedDeps);\n  }","commit_id":"3b0f81e44f48cea00b6bff94712a20cfffb82346","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"protected void processFabInstructions() {\n        sharedFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_PROVIDED_DEPENDENCY)), \"\\\\s+\"));\n        requireBundleFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_DEPENDENCY_REQUIRE_BUNDLE)), \"\\\\s+\"));\n        excludeDependencyFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_EXCLUDE_DEPENDENCY)), \"\\\\s+\"));\n        optionalDependencyPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_OPTIONAL_DEPENDENCY)), \"\\\\s+\"));\n        importExportFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_IMPORT_DEPENDENCY_EXPORTS)), \"\\\\s+\"));\n        installFeatures.addCollection(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE)), \"\\\\s+\"));\n        for (String url : Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL)), \"\\\\s+\")) {\n            try {\n                installFeatureURLs.add(new URI(url));\n            } catch (URISyntaxException e) {\n                LOG.warn(\"Invalid URI {} listed in {} will be ignored\", new Object[] { url, ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL });\n            }\n        }\n    }","id":14207,"modified_method":"protected void processFabInstructions() {\n        sharedFilterPatterns.addAll(\n                getListManifestProperty(ServiceConstants.INSTR_FAB_PROVIDED_DEPENDENCY, ServiceConstants.DEFAULT_FAB_PROIVDED_DEPENDENCY));\n        requireBundleFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_DEPENDENCY_REQUIRE_BUNDLE));\n        excludeDependencyFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_EXCLUDE_DEPENDENCY));\n        optionalDependencyPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_OPTIONAL_DEPENDENCY));\n        importExportFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_IMPORT_DEPENDENCY_EXPORTS));\n        installFeatures.addCollection(getListManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE));\n        for (String url : getListManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL)) {\n            try {\n                installFeatureURLs.add(new URI(url));\n            } catch (URISyntaxException e) {\n                LOG.warn(\"Invalid URI {} listed in {} will be ignored\", new Object[] { url, ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL });\n            }\n        }\n    }","commit_id":"32e49d4a003dab76068320701a1bd8fdeefc2546","url":"https://github.com/fabric8io/fabric8"},{"original_method":"protected void processFabInstructions() {\n        sharedFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_PROVIDED_DEPENDENCY)), \"\\\\s+\"));\n        requireBundleFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_DEPENDENCY_REQUIRE_BUNDLE)), \"\\\\s+\"));\n        excludeDependencyFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_EXCLUDE_DEPENDENCY)), \"\\\\s+\"));\n        optionalDependencyPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_OPTIONAL_DEPENDENCY)), \"\\\\s+\"));\n        importExportFilterPatterns.addAll(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_IMPORT_DEPENDENCY_EXPORTS)), \"\\\\s+\"));\n        installFeatures.addCollection(Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE)), \"\\\\s+\"));\n        for (String url : Strings.splitAndTrimAsList(emptyIfNull(getManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL)), \"\\\\s+\")) {\n            try {\n                installFeatureURLs.add(new URI(url));\n            } catch (URISyntaxException e) {\n                LOG.warn(\"Invalid URI {} listed in {} will be ignored\", new Object[] { url, ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL });\n            }\n        }\n    }","id":14208,"modified_method":"protected void processFabInstructions() {\n        sharedFilterPatterns.addAll(\n                getListManifestProperty(ServiceConstants.INSTR_FAB_PROVIDED_DEPENDENCY, ServiceConstants.DEFAULT_FAB_PROIVDED_DEPENDENCY));\n        requireBundleFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_DEPENDENCY_REQUIRE_BUNDLE));\n        excludeDependencyFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_EXCLUDE_DEPENDENCY));\n        optionalDependencyPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_OPTIONAL_DEPENDENCY));\n        importExportFilterPatterns.addAll(getListManifestProperty(ServiceConstants.INSTR_FAB_IMPORT_DEPENDENCY_EXPORTS));\n        installFeatures.addCollection(getListManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE));\n        for (String url : getListManifestProperty(ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL)) {\n            try {\n                installFeatureURLs.add(new URI(url));\n            } catch (URISyntaxException e) {\n                LOG.warn(\"Invalid URI {} listed in {} will be ignored\", new Object[] { url, ServiceConstants.INSTR_FAB_REQUIRE_FEATURE_URL });\n            }\n        }\n    }","commit_id":"0ccf056fa4652147f253d002db7a97bae57e3e65","url":"https://github.com/fabric8io/fabric8"},{"original_method":"@Override\n  public Item item(final QueryContext qc, final InputInfo ii) throws QueryException {\n    final Iter entr = qc.iter(exprs[0]), cont = qc.iter(exprs[1]);\n    final Options opts = toOptions(2, Q_OPTIONS, new ArchOptions(), qc);\n\n    final String format = opts.get(ArchOptions.FORMAT);\n    try(final ArchiveOut out = ArchiveOut.get(format.toLowerCase(Locale.ENGLISH), info)) {\n      // check algorithm\n      final String alg = opts.get(ArchOptions.ALGORITHM);\n      int level = ZipEntry.DEFLATED;\n      if(alg != null) {\n        if(format.equals(ZIP)  && !Strings.eq(alg, STORED, DEFLATE) ||\n           format.equals(GZIP) && !Strings.eq(alg, DEFLATE)) {\n          throw ARCH_SUPP_X_X.get(info, ArchOptions.ALGORITHM.name(), alg);\n        }\n        if(Strings.eq(alg, STORED)) level = ZipEntry.STORED;\n        else if(Strings.eq(alg, DEFLATE)) level = ZipEntry.DEFLATED;\n      }\n      out.level(level);\n\n      try {\n        Item en, cn;\n        int e = 0, c = 0;\n        while(true) {\n          en = entr.next();\n          cn = cont.next();\n          if(en == null || cn == null) break;\n          if(out instanceof GZIPOut && c > 0)\n            throw ARCH_ONE_X.get(info, format.toUpperCase(Locale.ENGLISH));\n          add(checkElemToken(en), cn, out, level, qc);\n          e++;\n          c++;\n        }\n        // count remaining entries\n        if(cn != null) do c++; while(cont.next() != null);\n        if(en != null) do e++; while(entr.next() != null);\n        if(e != c) throw ARCH_DIFF_X_X.get(info, e, c);\n      } catch(final IOException ex) {\n        throw ARCH_FAIL_X.get(info, ex);\n      }\n      return new B64(out.finish());\n    }\n  }","id":14209,"modified_method":"@Override\n  public Item item(final QueryContext qc, final InputInfo ii) throws QueryException {\n    final Iter entries = qc.iter(exprs[0]), contents = qc.iter(exprs[1]);\n    final ArchOptions opts = toOptions(2, Q_OPTIONS, new ArchOptions(), qc);\n\n    // check options\n    final String format = opts.get(ArchOptions.FORMAT);\n    final int level = level(opts);\n\n    try(final ArchiveOut out = ArchiveOut.get(format.toLowerCase(Locale.ENGLISH), info)) {\n      out.level(level);\n      try {\n        int e = 0, c = 0;\n        while(true) {\n          final Item en = entries.next(), cn = contents.next();\n          if(en == null || cn == null) {\n            // count remaining entries\n            if(cn != null) do c++; while(contents.next() != null);\n            if(en != null) do e++; while(entries.next() != null);\n            if(e != c) throw ARCH_DIFF_X_X.get(info, e, c);\n            break;\n          }\n          if(out instanceof GZIPOut && c > 0)\n            throw ARCH_ONE_X.get(info, format.toUpperCase(Locale.ENGLISH));\n          add(checkElemToken(en), cn, out, level, qc);\n          e++;\n          c++;\n        }\n      } catch(final IOException ex) {\n        throw ARCH_FAIL_X.get(info, ex);\n      }\n      return new B64(out.finish());\n    }\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"/**\n   * Adds the specified entry to the output stream.\n   * @param entry entry descriptor\n   * @param cont contents\n   * @param out output archive\n   * @param level default compression level\n   * @param qc query context\n   * @throws QueryException query exception\n   * @throws IOException I/O exception\n   */\n  final void add(final Item entry, final Item cont, final ArchiveOut out, final int level,\n      final QueryContext qc) throws QueryException, IOException {\n\n    // create new zip entry\n    String name = string(entry.string(info));\n    if(name.isEmpty()) throw ARCH_EMPTY.get(info);\n    if(Prop.WIN) name = name.replace('\\\\', '/');\n\n    final ZipEntry ze = new ZipEntry(name);\n    String enc = Strings.UTF8;\n\n    // compression level\n    byte[] lvl = null;\n    if(entry instanceof ANode) {\n      final ANode el = (ANode) entry;\n      lvl = el.attribute(LEVEL);\n\n      // last modified\n      final byte[] mod = el.attribute(LAST_MOD);\n      if(mod != null) {\n        try {\n          ze.setTime(dateTimeToMs(new Dtm(mod, info), qc));\n        } catch(final QueryException qe) {\n          throw ARCH_DATETIME_X.get(info, mod);\n        }\n      }\n\n      // encoding\n      final byte[] ea = el.attribute(ENCODING);\n      if(ea != null) {\n        enc = Strings.normEncoding(string(ea));\n        if(!Charset.isSupported(enc)) throw ARCH_ENCODING_X.get(info, ea);\n      }\n    }\n\n    // data to be compressed\n    byte[] val = toBytes(cont);\n    if(cont instanceof AStr && enc != Strings.UTF8) val = encode(val, enc, qc);\n\n    try {\n      out.level(lvl == null ? level : toInt(lvl));\n    } catch(final IllegalArgumentException ex) {\n      throw ARCH_LEVEL_X.get(info, lvl);\n    }\n    out.write(ze, val);\n  }","id":14210,"modified_method":"/**\n   * Adds the specified entry to the output stream.\n   * @param entry entry descriptor\n   * @param cont contents\n   * @param out output archive\n   * @param level default compression level\n   * @param qc query context\n   * @throws QueryException query exception\n   * @throws IOException I/O exception\n   */\n  protected final void add(final Item entry, final Item cont, final ArchiveOut out, final int level,\n      final QueryContext qc) throws QueryException, IOException {\n\n    // create new zip entry\n    String name = string(entry.string(info));\n    if(name.isEmpty()) throw ARCH_EMPTY.get(info);\n    if(Prop.WIN) name = name.replace('\\\\', '/');\n\n    final ZipEntry ze = new ZipEntry(name);\n    String enc = Strings.UTF8;\n\n    // compression level\n    byte[] lvl = null;\n    if(entry instanceof ANode) {\n      final ANode el = (ANode) entry;\n      lvl = el.attribute(LEVEL);\n\n      // last modified\n      final byte[] mod = el.attribute(LAST_MOD);\n      if(mod != null) {\n        try {\n          ze.setTime(dateTimeToMs(new Dtm(mod, info), qc));\n        } catch(final QueryException qe) {\n          throw ARCH_DATETIME_X.get(info, mod);\n        }\n      }\n\n      // encoding\n      final byte[] ea = el.attribute(ENCODING);\n      if(ea != null) {\n        enc = Strings.normEncoding(string(ea));\n        if(!Charset.isSupported(enc)) throw ARCH_ENCODING_X.get(info, ea);\n      }\n    }\n\n    // data to be compressed\n    byte[] val = toBytes(cont);\n    if(cont instanceof AStr && enc != Strings.UTF8) val = encode(val, enc, qc);\n\n    try {\n      out.level(lvl == null ? level : toInt(lvl));\n    } catch(final IllegalArgumentException ex) {\n      throw ARCH_LEVEL_X.get(info, lvl);\n    }\n    out.write(ze, val);\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"/** Test method. */\n  @Test\n  public void entries() {\n    // read entries\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(ZIP))), \"5\");\n    // simple zip files\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(ZIP)) +\n        \"[@size][@last-modified][@compressed-size]\"), \"5\");\n    // simple gzip files\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(GZIP)) +\n        \"[not(@size)][not(@last-modified)][not(@compressed-size)][not(text())]\"), \"1\");\n  }","id":14211,"modified_method":"/** Test method. */\n  @Test\n  public void entries() {\n    // read entries\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(ZIP))), 5);\n    // simple zip files\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(ZIP)) +\n        \"[@size][@last-modified][@compressed-size]\"), 5);\n    // simple gzip files\n    query(COUNT.args(_ARCHIVE_ENTRIES.args(_FILE_READ_BINARY.args(GZIP)) +\n        \"[not(@size)][not(@last-modified)][not(@compressed-size)][not(text())]\"), 1);\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"/** Test method. */\n  @Test\n  public void extractText() {\n    // extract all entries\n    query(COUNT.args(_ARCHIVE_EXTRACT_TEXT.args(_FILE_READ_BINARY.args(ZIP))), \"5\");\n    // extract all entries\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_ENTRIES.args(\"$a\") +\n          \"return \" + COUNT.args(_ARCHIVE_EXTRACT_TEXT.args(\"$a\", \"$b\")), 5);\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_TEXT.args(\"$a\", \"test/input.xml\") +\n          \"let $c := \" + PARSE_XML.args(\"$b\") +\n          \"return $c//title/text()\", \"XML\");\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_TEXT.args(\"$a\",\n              \"<archive:entry>test/input.xml<\/archive:entry>\") +\n          \"let $c := \" + PARSE_XML.args(\"$b\") +\n          \"return $c//title/text()\", \"XML\");\n  }","id":14212,"modified_method":"/** Test method. */\n  @Test\n  public void extractText() {\n    // extract all entries\n    query(COUNT.args(_ARCHIVE_EXTRACT_TEXT.args(_FILE_READ_BINARY.args(ZIP))), 5);\n    // extract all entries\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_ENTRIES.args(\"$a\") +\n          \"return \" + COUNT.args(_ARCHIVE_EXTRACT_TEXT.args(\"$a\", \"$b\")), 5);\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_TEXT.args(\"$a\", \"test/input.xml\") +\n          \"let $c := \" + PARSE_XML.args(\"$b\") +\n          \"return $c//title/text()\", \"XML\");\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_TEXT.args(\"$a\",\n              \"<archive:entry>test/input.xml<\/archive:entry>\") +\n          \"let $c := \" + PARSE_XML.args(\"$b\") +\n          \"return $c//title/text()\", \"XML\");\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"/** Test method. */\n  @Test\n  public void create() {\n    // simple zip files\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\")), \"1\");\n    // simple zip files\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\n        \"<archive:entry level='9'>X<\/archive:entry>\", \"\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\n        \"<archive:entry encoding='US-ASCII'>X<\/archive:entry>\", \"\")),\n        \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry \" +\n        \"last-modified='2000-01-01T12:12:12'>X<\/archive:entry>\", \"\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \" map { }\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \" map { 'format':'zip', 'algorithm':'deflate' }\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\", \"<archive:options/>\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='zip'/>\" +\n        \"<archive:algorithm value='deflate'/><\/archive:options>\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='zip'/><\/archive:options>\")), \"1\");\n    query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='gzip'/><\/archive:options>\")), \"1\");\n\n    // different number of entries and contents\n    error(_ARCHIVE_CREATE.args(\"X\", \"()\"), ARCH_DIFF_X_X);\n    // name must not be empty\n    error(_ARCHIVE_CREATE.args(\"<archive:entry/>\", \"\"), ARCH_EMPTY);\n    // invalid compression level\n    error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='x'>X<\/archive:entry>\", \"\"),\n        ARCH_LEVEL_X);\n    error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='10'>X<\/archive:entry>\", \"\"),\n        ARCH_LEVEL_X);\n    // invalid modification date\n    error(_ARCHIVE_CREATE.args(\"<archive:entry last-modified='2020'>X<\/archive:entry>\", \"\"),\n        ARCH_DATETIME_X);\n    // content must be string or binary\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \" 123\"), STRBIN_X_X);\n    // wrong encoding\n    error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='x'>X<\/archive:entry>\", \"\"),\n        ARCH_ENCODING_X);\n    // errors while converting a string\n    error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X<\/archive:entry>\",\n        \"\\u00fc\"), ARCH_ENCODE_X);\n    // format not supported\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\", \" map { 'format':'rar' }\"),\n        ARCH_UNKNOWN);\n    // unknown option\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\", \" map { 'x':'y' }\"),\n        INVALIDOPT_X);\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='rar'/><\/archive:options>\"),\n        ARCH_UNKNOWN);\n    // algorithm not supported\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:algorithm value='unknown'/><\/archive:options>\"),\n        ARCH_SUPP_X_X);\n    // algorithm not supported\n    error(_ARCHIVE_CREATE.args(\"('x','y')\", \"('a','b')\",\n        \"<archive:options><archive:format value='gzip'/><\/archive:options>\"),\n        ARCH_ONE_X);\n  }","id":14213,"modified_method":"/** Test method. */\n  @Test\n  public void create() {\n    // simple zip files\n    count(_ARCHIVE_CREATE.args(\"X\", \"\"), 1);\n\n    // simple zip files\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry level='9'>X<\/archive:entry>\", \"\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X<\/archive:entry>\", \"\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry \" +\n        \"last-modified='2000-01-01T12:12:12'>X<\/archive:entry>\", \"\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\", \" map { }\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \" map { 'format':'zip', 'algorithm':'deflate' }\"), 1);\n    count(_ARCHIVE_CREATE.args(\"X\", \"\", \"<archive:options/>\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='zip'/>\" +\n        \"<archive:algorithm value='deflate'/><\/archive:options>\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='zip'/><\/archive:options>\"), 1);\n    count(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='gzip'/><\/archive:options>\"), 1);\n\n    // different number of entries and contents\n    error(_ARCHIVE_CREATE.args(\"X\", \"()\"), ARCH_DIFF_X_X);\n    // name must not be empty\n    error(_ARCHIVE_CREATE.args(\"<archive:entry/>\", \"\"), ARCH_EMPTY);\n    // invalid compression level\n    error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='x'>X<\/archive:entry>\", \"\"),\n        ARCH_LEVEL_X);\n    error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='10'>X<\/archive:entry>\", \"\"),\n        ARCH_LEVEL_X);\n    // invalid modification date\n    error(_ARCHIVE_CREATE.args(\"<archive:entry last-modified='2020'>X<\/archive:entry>\", \"\"),\n        ARCH_DATETIME_X);\n    // content must be string or binary\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \" 123\"), STRBIN_X_X);\n    // wrong encoding\n    error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='x'>X<\/archive:entry>\", \"\"),\n        ARCH_ENCODING_X);\n    // errors while converting a string\n    error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X<\/archive:entry>\",\n        \"\\u00fc\"), ARCH_ENCODE_X);\n    // format not supported\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\", \" map { 'format':'rar' }\"),\n        ARCH_UNKNOWN);\n    // unknown option\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\", \" map { 'x':'y' }\"),\n        INVALIDOPT_X);\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:format value='rar'/><\/archive:options>\"), ARCH_UNKNOWN);\n    // algorithm not supported\n    error(_ARCHIVE_CREATE.args(\"<archive:entry>X<\/archive:entry>\", \"\",\n        \"<archive:options><archive:algorithm value='unknown'/><\/archive:options>\"), ARCH_SUPP_X_X);\n    // algorithm not supported\n    error(_ARCHIVE_CREATE.args(\"('x','y')\", \"('a','b')\",\n        \"<archive:options><archive:format value='gzip'/><\/archive:options>\"), ARCH_ONE_X);\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"/** Test method. */\n  @Test\n  public void extractBinary() {\n    // extract all entries\n    query(COUNT.args(_ARCHIVE_EXTRACT_BINARY.args(_FILE_READ_BINARY.args(ZIP))), \"5\");\n    // extract all entries\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_ENTRIES.args(\"$a\") +\n          \"return count(\" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\", \"$b\") + ')', 5);\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\", \"test/input.xml\") +\n          \"let $c := \" + _CONVERT_BINARY_TO_STRING.args(\"$b\") +\n          \"let $d := \" + PARSE_XML.args(\"$c\") +\n          \"return $d//title/text()\", \"XML\");\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\",\n              \"<archive:entry>test/input.xml<\/archive:entry>\") +\n          \"let $c := \" + _CONVERT_BINARY_TO_STRING.args(\"$b\") +\n          \"let $d := \" + PARSE_XML.args(\"$c\") +\n          \"return $d//title/text()\", \"XML\");\n  }","id":14214,"modified_method":"/** Test method. */\n  @Test\n  public void extractBinary() {\n    // extract all entries\n    query(COUNT.args(_ARCHIVE_EXTRACT_BINARY.args(_FILE_READ_BINARY.args(ZIP))), 5);\n    // extract all entries\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_ENTRIES.args(\"$a\") +\n          \"return count(\" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\", \"$b\") + ')', 5);\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\", \"test/input.xml\") +\n          \"let $c := \" + _CONVERT_BINARY_TO_STRING.args(\"$b\") +\n          \"let $d := \" + PARSE_XML.args(\"$c\") +\n          \"return $d//title/text()\", \"XML\");\n    // extract single entry\n    query(\"let $a := \" + _FILE_READ_BINARY.args(ZIP) +\n          \"let $b := \" + _ARCHIVE_EXTRACT_BINARY.args(\"$a\",\n              \"<archive:entry>test/input.xml<\/archive:entry>\") +\n          \"let $c := \" + _CONVERT_BINARY_TO_STRING.args(\"$b\") +\n          \"let $d := \" + PARSE_XML.args(\"$c\") +\n          \"return $d//title/text()\", \"XML\");\n  }","commit_id":"b07c5cde086586d84bddcac4c27e10ffdfa9a7d3","url":"https://github.com/BaseXdb/basex"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"hash\")\n      .setDescription(\"Show line line hashes for a given file. Require See Source Code permission on file's project<br/>\")\n      .setSince(\"5.0\")\n      .setInternal(true)\n      .setResponseExample(Resources.getResource(getClass(), \"example-hash.txt\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/source/SourceService.java\");\n  }","id":14215,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"hash\")\n      .setDescription(\"Show line line hashes for a given file. Require See Source Code permission on file's project<br/>\")\n      .setSince(\"5.0\")\n      .setInternal(true)\n      .setResponseExample(Resources.getResource(getClass(), \"example-hash.txt\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/source/SourceService.java\");\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void before() throws Exception {\n    db.truncateTables();\n    this.session = db.myBatis().openSession(false);\n\n    DbClient dbClient = new DbClient(db.database(), db.myBatis(), new FileSourceDao(db.myBatis()), new ComponentDao());\n\n    tester = new WsTester(\n      new SourcesWs(\n        mock(ShowAction.class),\n        mock(RawAction.class),\n        mock(LinesAction.class),\n        new HashAction(dbClient),\n        mock(IndexAction.class)\n      )\n      );\n  }","id":14216,"modified_method":"@Before\n  public void before() throws Exception {\n    db.truncateTables();\n    this.session = db.myBatis().openSession(false);\n\n    DbClient dbClient = new DbClient(db.database(), db.myBatis(), new FileSourceDao(db.myBatis()), new ComponentDao());\n\n    tester = new WsTester(new SourcesWs(new HashAction(dbClient)));\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"index\")\n      .setDescription(\"Get source code as line number / text pairs. Require See Source Code permission on file\")\n      .setSince(\"5.0\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-index.json\"))\n      .setInternal(true)\n      .setHandler(this);\n\n    action\n      .createParam(\"resource\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n\n    action\n      .createParam(\"from\")\n      .setDefaultValue(1)\n      .setDescription(\"First line\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line (excluded). If not specified, all lines are returned until end of file\");\n  }","id":14217,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"index\")\n      .setDescription(\"Get source code as line number / text pairs. Require See Source Code permission on file\")\n      .setSince(\"5.0\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-index.json\"))\n      .setInternal(true)\n      .setHandler(this);\n\n    action\n      .createParam(\"resource\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n\n    action\n      .createParam(\"from\")\n      .setDefaultValue(1)\n      .setDescription(\"First line\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line (excluded). If not specified, all lines are returned until end of file\");\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(mock(ShowAction.class), mock(RawAction.class), mock(LinesAction.class),\n      mock(HashAction.class), new IndexAction(dbClient, sourceService)));\n  }","id":14218,"modified_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(new IndexAction(dbClient, sourceService)));\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void writeSource(List<SourceLineDoc> lines, int from, JsonWriter json) {\n    json.name(\"sources\").beginArray();\n    for (SourceLineDoc line: lines) {\n      json.beginObject()\n        .prop(\"line\", line.line())\n        .prop(\"code\", htmlSourceDecorator.getDecoratedSourceAsHtml(line.source(), line.highlighting(), line.symbols()))\n        .prop(\"scmAuthor\", line.scmAuthor())\n        .prop(\"scmRevision\", line.scmRevision());\n      Date scmDate = line.scmDate();\n      json.prop(\"scmDate\", scmDate == null ? null : DateUtils.formatDateTime(scmDate));\n      json.prop(\"utLineHits\", line.utLineHits())\n        .prop(\"utConditions\", line.utConditions())\n        .prop(\"utCoveredConditions\", line.utCoveredConditions())\n        .prop(\"itLineHits\", line.itLineHits())\n        .prop(\"itConditions\", line.itConditions())\n        .prop(\"itCoveredConditions\", line.itCoveredConditions());\n      if (! line.duplications().isEmpty()) {\n        json.prop(\"duplicated\", true);\n      }\n      json.endObject();\n    }\n    json.endArray();\n  }","id":14219,"modified_method":"private void writeSource(List<SourceLineDoc> lines, JsonWriter json) {\n    json.name(\"sources\").beginArray();\n    for (SourceLineDoc line: lines) {\n      json.beginObject()\n        .prop(\"line\", line.line())\n        .prop(\"code\", htmlSourceDecorator.getDecoratedSourceAsHtml(line.source(), line.highlighting(), line.symbols()))\n        .prop(\"scmAuthor\", line.scmAuthor())\n        .prop(\"scmRevision\", line.scmRevision());\n      Date scmDate = line.scmDate();\n      json.prop(\"scmDate\", scmDate == null ? null : DateUtils.formatDateTime(scmDate));\n      json.prop(\"utLineHits\", line.utLineHits())\n        .prop(\"utConditions\", line.utConditions())\n        .prop(\"utCoveredConditions\", line.utCoveredConditions())\n        .prop(\"itLineHits\", line.itLineHits())\n        .prop(\"itConditions\", line.itConditions())\n        .prop(\"itCoveredConditions\", line.itCoveredConditions());\n      if (! line.duplications().isEmpty()) {\n        json.prop(\"duplicated\", true);\n      }\n      json.endObject();\n    }\n    json.endArray();\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n  public void handle(Request request, Response response) {\n    String fileUuid = request.mandatoryParam(\"uuid\");\n    ComponentDto component = componentService.getByUuid(fileUuid);\n    UserSession.get().checkProjectUuidPermission(UserRole.CODEVIEWER, component.projectUuid());\n\n    int from = Math.max(request.mandatoryParamAsInt(\"from\"), 1);\n    int to = (Integer) ObjectUtils.defaultIfNull(request.paramAsInt(\"to\"), Integer.MAX_VALUE);\n\n    List<SourceLineDoc> sourceLines = sourceLineIndex.getLines(fileUuid, from, to);\n    if (sourceLines.isEmpty()) {\n      throw new NotFoundException(\"File '\" + fileUuid + \"' has no sources\");\n    }\n\n    JsonWriter json = response.newJsonWriter().beginObject();\n    writeSource(sourceLines, from, json);\n\n    json.endObject().close();\n  }","id":14220,"modified_method":"@Override\n  public void handle(Request request, Response response) {\n    String fileUuid = request.mandatoryParam(\"uuid\");\n    ComponentDto component = componentService.getByUuid(fileUuid);\n    UserSession.get().checkProjectUuidPermission(UserRole.CODEVIEWER, component.projectUuid());\n\n    int from = Math.max(request.mandatoryParamAsInt(\"from\"), 1);\n    int to = (Integer) ObjectUtils.defaultIfNull(request.paramAsInt(\"to\"), Integer.MAX_VALUE);\n\n    List<SourceLineDoc> sourceLines = sourceLineIndex.getLines(fileUuid, from, to);\n    if (sourceLines.isEmpty()) {\n      throw new NotFoundException(\"File '\" + fileUuid + \"' has no sources\");\n    }\n\n    JsonWriter json = response.newJsonWriter().beginObject();\n    writeSource(sourceLines, json);\n\n    json.endObject().close();\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"lines\")\n      .setDescription(\"Show source code with line oriented info. Require See Source Code permission on file's project<br/>\" +\n        \"Each element of the result array is an object which contains:\" +\n        \"<ol>\" +\n        \"<li>Line number<\/li>\" +\n        \"<li>Content of the line<\/li>\" +\n        \"<li>Author of the line (from SCM information)<\/li>\" +\n        \"<li>Revision of the line (from SCM information)<\/li>\" +\n        \"<li>Last commit date of the line (from SCM information)<\/li>\" +\n        \"<li>Line hits from unit test coverage<\/li>\" +\n        \"<li>Number of conditions to cover in unit tests<\/li>\" +\n        \"<li>Number of conditions covered by unit tests<\/li>\" +\n        \"<li>Line hits from integration test coverage<\/li>\" +\n        \"<li>Number of conditions to cover in integration tests<\/li>\" +\n        \"<li>Number of conditions covered by integration tests<\/li>\" +\n        \"<\/ol>\")\n      .setSince(\"5.0\")\n      .setInternal(true)\n      .setResponseExample(Resources.getResource(getClass(), \"example-lines.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"uuid\")\n      .setRequired(true)\n      .setDescription(\"File uuid\")\n      .setExampleValue(\"f333aab4-7e3a-4d70-87e1-f4c491f05e5c\");\n\n    action\n      .createParam(\"from\")\n      .setDescription(\"First line to return. Starts at 1\")\n      .setExampleValue(\"10\")\n      .setDefaultValue(\"1\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line to return (inclusive)\")\n      .setExampleValue(\"20\");\n  }","id":14221,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"lines\")\n      .setDescription(\"Show source code with line oriented info. Require See Source Code permission on file's project<br/>\" +\n        \"Each element of the result array is an object which contains:\" +\n        \"<ol>\" +\n        \"<li>Line number<\/li>\" +\n        \"<li>Content of the line<\/li>\" +\n        \"<li>Author of the line (from SCM information)<\/li>\" +\n        \"<li>Revision of the line (from SCM information)<\/li>\" +\n        \"<li>Last commit date of the line (from SCM information)<\/li>\" +\n        \"<li>Line hits from unit test coverage<\/li>\" +\n        \"<li>Number of conditions to cover in unit tests<\/li>\" +\n        \"<li>Number of conditions covered by unit tests<\/li>\" +\n        \"<li>Line hits from integration test coverage<\/li>\" +\n        \"<li>Number of conditions to cover in integration tests<\/li>\" +\n        \"<li>Number of conditions covered by integration tests<\/li>\" +\n        \"<\/ol>\")\n      .setSince(\"5.0\")\n      .setInternal(true)\n      .setResponseExample(Resources.getResource(getClass(), \"example-lines.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"uuid\")\n      .setRequired(true)\n      .setDescription(\"File uuid\")\n      .setExampleValue(\"f333aab4-7e3a-4d70-87e1-f4c491f05e5c\");\n\n    action\n      .createParam(\"from\")\n      .setDescription(\"First line to return. Starts at 1\")\n      .setExampleValue(\"10\")\n      .setDefaultValue(\"1\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line to return (inclusive)\")\n      .setExampleValue(\"20\");\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    tester = new WsTester(\n      new SourcesWs(\n        mock(ShowAction.class),\n        mock(RawAction.class),\n        new LinesAction(sourceLineIndex, htmlSourceDecorator, componentService),\n        mock(HashAction.class),\n        mock(IndexAction.class)\n      )\n      );\n    when(htmlSourceDecorator.getDecoratedSourceAsHtml(anyString(), anyString(), anyString())).thenAnswer(new Answer<String>() {\n      @Override\n      public String answer(InvocationOnMock invocation) throws Throwable {\n        return \"<span class=\\\"\" + invocation.getArguments()[1] + \" sym-\" + invocation.getArguments()[2] + \"\\\">\" +\n          StringEscapeUtils.escapeHtml((String) invocation.getArguments()[0]) +\n          \"<\/span>\";\n      }\n    });\n  }","id":14222,"modified_method":"@Before\n  public void setUp() throws Exception {\n    tester = new WsTester(new SourcesWs(new LinesAction(sourceLineIndex, htmlSourceDecorator, componentService)));\n    when(htmlSourceDecorator.getDecoratedSourceAsHtml(anyString(), anyString(), anyString())).thenAnswer(new Answer<String>() {\n      @Override\n      public String answer(InvocationOnMock invocation) throws Throwable {\n        return \"<span class=\\\"\" + invocation.getArguments()[1] + \" sym-\" + invocation.getArguments()[2] + \"\\\">\" +\n          StringEscapeUtils.escapeHtml((String) invocation.getArguments()[0]) +\n          \"<\/span>\";\n      }\n    });\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"raw\")\n      .setDescription(\"Get source code as plain text. Require See Source Code permission on file\")\n      .setSince(\"5.0\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-raw.txt\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n  }","id":14223,"modified_method":"@Override\n  public void  define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"raw\")\n      .setDescription(\"Get source code as plain text. Require See Source Code permission on file\")\n      .setSince(\"5.0\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-raw.txt\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(mock(ShowAction.class), new RawAction(dbClient, sourceService), mock(LinesAction.class),\n      mock(HashAction.class), mock(IndexAction.class)));\n  }","id":14224,"modified_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(new RawAction(dbClient, sourceService)));\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void startLevel4Components(ComponentContainer pico) {\n    pico.addSingleton(PluginDownloader.class);\n    pico.addSingleton(ChartFactory.class);\n    pico.addSingleton(Views.class);\n    pico.addSingleton(ResourceTypes.class);\n    pico.addSingleton(SettingsChangeNotifier.class);\n    pico.addSingleton(PageDecorations.class);\n    pico.addSingleton(DefaultResourcePermissions.class);\n    pico.addSingleton(Periods.class);\n    pico.addSingleton(ServerWs.class);\n    pico.addSingleton(BackendCleanup.class);\n    pico.addSingleton(IndexDefinitions.class);\n    pico.addSingleton(IndexCreator.class);\n\n    // Activity\n    pico.addSingleton(ActivityService.class);\n    pico.addSingleton(ActivityIndexDefinition.class);\n    pico.addSingleton(ActivityIndexer.class);\n    pico.addSingleton(ActivityIndex.class);\n\n    // batch\n    pico.addSingleton(BatchIndex.class);\n    pico.addSingleton(GlobalRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryLoader.class);\n    pico.addSingleton(SubmitReportWsAction.class);\n    pico.addSingleton(IssuesAction.class);\n    pico.addSingleton(BatchWs.class);\n\n    // update center\n    pico.addSingleton(UpdateCenterClient.class);\n    pico.addSingleton(UpdateCenterMatrixFactory.class);\n    pico.addSingleton(UpdateCenterWs.class);\n\n    // quality profile\n    pico.addSingleton(XMLProfileParser.class);\n    pico.addSingleton(XMLProfileSerializer.class);\n    pico.addSingleton(AnnotationProfileParser.class);\n    pico.addSingleton(QProfiles.class);\n    pico.addSingleton(QProfileLookup.class);\n    pico.addSingleton(QProfileProjectOperations.class);\n    pico.addSingleton(QProfileProjectLookup.class);\n    pico.addSingleton(BuiltInProfiles.class);\n    pico.addSingleton(QProfileRestoreBuiltInAction.class);\n    pico.addSingleton(QProfileSearchAction.class);\n    pico.addSingleton(QProfilesWs.class);\n    pico.addSingleton(ProfilesWs.class);\n    pico.addSingleton(RuleActivationActions.class);\n    pico.addSingleton(BulkRuleActivationActions.class);\n    pico.addSingleton(ProjectAssociationActions.class);\n    pico.addSingleton(RuleActivator.class);\n    pico.addSingleton(QProfileLoader.class);\n    pico.addSingleton(QProfileExporters.class);\n    pico.addSingleton(QProfileService.class);\n    pico.addSingleton(RuleActivatorContextFactory.class);\n    pico.addSingleton(QProfileFactory.class);\n    pico.addSingleton(QProfileCopier.class);\n    pico.addSingleton(QProfileBackuper.class);\n    pico.addSingleton(QProfileReset.class);\n    pico.addSingleton(RubyQProfileActivityService.class);\n\n    // rule\n    pico.addSingleton(AnnotationRuleParser.class);\n    pico.addSingleton(XMLRuleParser.class);\n    pico.addSingleton(DefaultRuleFinder.class);\n    pico.addSingleton(RuleOperations.class);\n    pico.addSingleton(RubyRuleService.class);\n    pico.addSingleton(RuleRepositories.class);\n    pico.addSingleton(DeprecatedRulesDefinitionLoader.class);\n    pico.addSingleton(RuleDefinitionsLoader.class);\n    pico.addSingleton(RulesDefinitionXmlLoader.class);\n    pico.addSingleton(RuleService.class);\n    pico.addSingleton(RuleUpdater.class);\n    pico.addSingleton(RuleCreator.class);\n    pico.addSingleton(RuleDeleter.class);\n    pico.addSingleton(UpdateAction.class);\n    pico.addSingleton(RulesWebService.class);\n    pico.addSingleton(SearchAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.ShowAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.CreateAction.class);\n    pico.addSingleton(DeleteAction.class);\n    pico.addSingleton(TagsAction.class);\n    pico.addSingleton(RuleMapping.class);\n    pico.addSingleton(ActiveRuleCompleter.class);\n    pico.addSingleton(RepositoriesAction.class);\n    pico.addSingleton(AppAction.class);\n\n    // languages\n    pico.addSingleton(Languages.class);\n    pico.addSingleton(LanguageWs.class);\n    pico.addSingleton(ListAction.class);\n\n    // activity\n    pico.addSingleton(ActivitiesWebService.class);\n    pico.addSingleton(org.sonar.server.activity.ws.SearchAction.class);\n    pico.addSingleton(ActivityMapping.class);\n\n    // measure\n    pico.addComponent(MeasuresDao.class, false);\n    pico.addSingleton(MeasureFilterFactory.class);\n    pico.addSingleton(MeasureFilterExecutor.class);\n    pico.addSingleton(MeasureFilterEngine.class);\n    pico.addSingleton(DefaultMetricFinder.class);\n    pico.addSingleton(ServerLifecycleNotifier.class);\n    pico.addSingleton(TimeMachineWs.class);\n    pico.addSingleton(ManualMeasuresWs.class);\n    pico.addSingleton(MetricsWs.class);\n\n    // quality gates\n    pico.addSingleton(QualityGateDao.class);\n    pico.addSingleton(QualityGateConditionDao.class);\n    pico.addSingleton(QualityGates.class);\n    pico.addSingleton(ProjectQgateAssociationDao.class);\n    pico.addSingleton(QgateProjectFinder.class);\n\n    pico.addSingleton(QGatesListAction.class);\n    pico.addSingleton(QGatesSearchAction.class);\n    pico.addSingleton(QGatesShowAction.class);\n    pico.addSingleton(QGatesCreateAction.class);\n    pico.addSingleton(QGatesRenameAction.class);\n    pico.addSingleton(QGatesCopyAction.class);\n    pico.addSingleton(QGatesDestroyAction.class);\n    pico.addSingleton(QGatesSetAsDefaultAction.class);\n    pico.addSingleton(QGatesUnsetDefaultAction.class);\n    pico.addSingleton(QGatesSelectAction.class);\n    pico.addSingleton(QGatesDeselectAction.class);\n    pico.addSingleton(QGatesCreateConditionAction.class);\n    pico.addSingleton(QGatesDeleteConditionAction.class);\n    pico.addSingleton(QGatesUpdateConditionAction.class);\n    pico.addSingleton(QGatesAppAction.class);\n    pico.addSingleton(QGatesWs.class);\n\n    // web services\n    pico.addSingleton(WebServiceEngine.class);\n    pico.addSingleton(ListingWs.class);\n\n    // localization\n    pico.addSingleton(L10nWs.class);\n\n    // authentication\n    pico.addSingleton(AuthenticationWs.class);\n\n    // users\n    pico.addSingleton(SecurityRealmFactory.class);\n    pico.addSingleton(HibernateUserFinder.class);\n    pico.addSingleton(NewUserNotifier.class);\n    pico.addSingleton(DefaultUserFinder.class);\n    pico.addSingleton(DefaultUserService.class);\n    pico.addSingleton(UsersWs.class);\n    pico.addSingleton(org.sonar.server.user.ws.CreateAction.class);\n    pico.addSingleton(org.sonar.server.user.ws.UpdateAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.AuthorsAction.class);\n    pico.addSingleton(FavoritesWs.class);\n    pico.addSingleton(UserPropertiesWs.class);\n    pico.addSingleton(UserIndexDefinition.class);\n    pico.addSingleton(UserIndexer.class);\n    pico.addSingleton(UserIndex.class);\n    pico.addSingleton(UserService.class);\n    pico.addSingleton(UserUpdater.class);\n\n    // groups\n    pico.addSingleton(GroupMembershipService.class);\n    pico.addSingleton(GroupMembershipFinder.class);\n\n    // permissions\n    pico.addSingleton(PermissionFacade.class);\n    pico.addSingleton(InternalPermissionService.class);\n    pico.addSingleton(InternalPermissionTemplateService.class);\n    pico.addSingleton(PermissionFinder.class);\n    pico.addSingleton(PermissionsWs.class);\n\n    // components\n    pico.addSingleton(DefaultComponentFinder.class);\n    pico.addSingleton(DefaultRubyComponentService.class);\n    pico.addSingleton(ComponentService.class);\n    pico.addSingleton(ResourcesWs.class);\n    pico.addSingleton(ComponentsWs.class);\n    pico.addSingleton(ProjectsWs.class);\n    pico.addSingleton(ComponentAppAction.class);\n    pico.addSingleton(org.sonar.server.component.ws.SearchAction.class);\n    pico.addSingleton(EventsWs.class);\n    pico.addSingleton(ComponentCleanerService.class);\n\n    // views\n    pico.addSingleton(ViewIndexDefinition.class);\n    pico.addSingleton(ViewIndexer.class);\n    pico.addSingleton(ViewIndex.class);\n\n    // issues\n    pico.addSingleton(IssueIndexDefinition.class);\n    pico.addSingleton(IssueIndexer.class);\n    pico.addSingleton(IssueAuthorizationIndexer.class);\n    pico.addSingleton(ServerIssueStorage.class);\n    pico.addSingleton(IssueUpdater.class);\n    pico.addSingleton(FunctionExecutor.class);\n    pico.addSingleton(IssueWorkflow.class);\n    pico.addSingleton(IssueCommentService.class);\n    pico.addSingleton(InternalRubyIssueService.class);\n    pico.addSingleton(IssueChangelogService.class);\n    pico.addSingleton(ActionService.class);\n    pico.addSingleton(Actions.class);\n    pico.addSingleton(IssueBulkChangeService.class);\n    pico.addSingleton(IssueChangelogFormatter.class);\n    pico.addSingleton(IssuesWs.class);\n    pico.addSingleton(IssueShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.SearchAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.TagsAction.class);\n    pico.addSingleton(SetTagsAction.class);\n    pico.addSingleton(ComponentTagsAction.class);\n    pico.addSingleton(IssueService.class);\n    pico.addSingleton(IssueActionsWriter.class);\n    pico.addSingleton(IssueQueryService.class);\n    pico.addSingleton(NewIssuesEmailTemplate.class);\n    pico.addSingleton(MyNewIssuesEmailTemplate.class);\n    pico.addSingleton(IssueChangesEmailTemplate.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationDispatcher.class);\n    pico.addSingleton(NewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(MyNewIssuesNotificationDispatcher.class);\n    pico.addSingleton(MyNewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(DoNotFixNotificationDispatcher.class);\n    pico.addSingleton(DoNotFixNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationFactory.class);\n\n    // issue filters\n    pico.addSingleton(IssueFilterService.class);\n    pico.addSingleton(IssueFilterSerializer.class);\n    pico.addSingleton(IssueFilterWs.class);\n    pico.addSingleton(IssueFilterWriter.class);\n    pico.addSingleton(org.sonar.server.issue.filter.AppAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.ShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.FavoritesAction.class);\n\n    // action plan\n    pico.addSingleton(ActionPlanWs.class);\n    pico.addSingleton(ActionPlanService.class);\n\n    // issues actions\n    pico.addSingleton(AssignAction.class);\n    pico.addSingleton(PlanAction.class);\n    pico.addSingleton(SetSeverityAction.class);\n    pico.addSingleton(CommentAction.class);\n    pico.addSingleton(TransitionAction.class);\n    pico.addSingleton(AddTagsAction.class);\n    pico.addSingleton(RemoveTagsAction.class);\n\n    // technical debt\n    pico.addSingleton(DebtModelService.class);\n    pico.addSingleton(DebtModelOperations.class);\n    pico.addSingleton(DebtModelLookup.class);\n    pico.addSingleton(DebtModelBackup.class);\n    pico.addSingleton(DebtModelPluginRepository.class);\n    pico.addSingleton(DebtModelXMLExporter.class);\n    pico.addSingleton(DebtRulesXMLImporter.class);\n    pico.addSingleton(DebtCharacteristicsXMLImporter.class);\n\n    // source\n    pico.addSingleton(HtmlSourceDecorator.class);\n    pico.addSingleton(SourceService.class);\n    pico.addSingleton(SourcesWs.class);\n    pico.addSingleton(ShowAction.class);\n    pico.addSingleton(LinesAction.class);\n    pico.addSingleton(HashAction.class);\n    pico.addSingleton(RawAction.class);\n    pico.addSingleton(IndexAction.class);\n    pico.addSingleton(SourceLineIndexDefinition.class);\n    pico.addSingleton(SourceLineIndex.class);\n    pico.addSingleton(SourceLineIndexer.class);\n\n    // Duplications\n    pico.addSingleton(DuplicationsParser.class);\n    pico.addSingleton(DuplicationsWs.class);\n    pico.addSingleton(DuplicationsJsonWriter.class);\n    pico.addSingleton(org.sonar.server.duplication.ws.ShowAction.class);\n\n    // text\n    pico.addSingleton(MacroInterpreter.class);\n    pico.addSingleton(RubyTextService.class);\n\n    // Notifications\n    pico.addSingleton(EmailSettings.class);\n    pico.addSingleton(NotificationService.class);\n    pico.addSingleton(NotificationCenter.class);\n    pico.addSingleton(DefaultNotificationManager.class);\n\n    // Tests\n    pico.addSingleton(CoverageService.class);\n    pico.addSingleton(CoverageWs.class);\n    pico.addSingleton(CoverageShowAction.class);\n    pico.addSingleton(TestsWs.class);\n    pico.addSingleton(TestsTestCasesAction.class);\n    pico.addSingleton(TestsCoveredFilesAction.class);\n    pico.addSingleton(TestsShowAction.class);\n\n    // Properties\n    pico.addSingleton(PropertiesWs.class);\n\n    // graphs and perspective related classes\n    pico.addSingleton(TestablePerspectiveLoader.class);\n    pico.addSingleton(TestPlanPerspectiveLoader.class);\n    pico.addSingleton(SnapshotPerspectives.class);\n\n    // Type validation\n    pico.addSingleton(TypeValidations.class);\n    pico.addSingleton(IntegerTypeValidation.class);\n    pico.addSingleton(FloatTypeValidation.class);\n    pico.addSingleton(BooleanTypeValidation.class);\n    pico.addSingleton(TextTypeValidation.class);\n    pico.addSingleton(StringTypeValidation.class);\n    pico.addSingleton(StringListTypeValidation.class);\n\n    // Design\n    pico.addSingleton(FileDesignWidget.class);\n\n    // System\n    pico.addSingletons(Arrays.asList(\n      SystemRestartWsAction.class,\n      SystemInfoWsAction.class,\n      SystemWs.class,\n      SystemMonitor.class,\n      SonarQubeMonitor.class,\n      EsMonitor.class,\n      PluginsMonitor.class,\n      JvmPropertiesMonitor.class,\n      DatabaseMonitor.class\n      ));\n\n    // Compute engine\n    pico.addSingleton(ReportQueue.class);\n    pico.addSingleton(ComputationThreadLauncher.class);\n    pico.addSingleton(ComputationWebService.class);\n    pico.addSingleton(IsQueueEmptyWebService.class);\n    pico.addSingleton(QueueWsAction.class);\n    pico.addSingleton(HistoryWsAction.class);\n    pico.addSingleton(DefaultPeriodCleaner.class);\n    pico.addSingleton(DefaultPurgeTask.class);\n    pico.addSingleton(ProjectCleaner.class);\n    pico.addSingleton(ProjectSettingsFactory.class);\n    pico.addSingleton(IndexPurgeListener.class);\n\n    for (Object components : level4AddedComponents) {\n      pico.addSingleton(components);\n    }\n\n    ServerExtensionInstaller extensionInstaller = pico.getComponentByType(ServerExtensionInstaller.class);\n    extensionInstaller.installExtensions(pico);\n\n    pico.startComponents();\n  }","id":14225,"modified_method":"void startLevel4Components(ComponentContainer pico) {\n    pico.addSingleton(PluginDownloader.class);\n    pico.addSingleton(ChartFactory.class);\n    pico.addSingleton(Views.class);\n    pico.addSingleton(ResourceTypes.class);\n    pico.addSingleton(SettingsChangeNotifier.class);\n    pico.addSingleton(PageDecorations.class);\n    pico.addSingleton(DefaultResourcePermissions.class);\n    pico.addSingleton(Periods.class);\n    pico.addSingleton(ServerWs.class);\n    pico.addSingleton(BackendCleanup.class);\n    pico.addSingleton(IndexDefinitions.class);\n    pico.addSingleton(IndexCreator.class);\n\n    // Activity\n    pico.addSingleton(ActivityService.class);\n    pico.addSingleton(ActivityIndexDefinition.class);\n    pico.addSingleton(ActivityIndexer.class);\n    pico.addSingleton(ActivityIndex.class);\n\n    // batch\n    pico.addSingleton(BatchIndex.class);\n    pico.addSingleton(GlobalRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryLoader.class);\n    pico.addSingleton(SubmitReportWsAction.class);\n    pico.addSingleton(IssuesAction.class);\n    pico.addSingleton(BatchWs.class);\n\n    // update center\n    pico.addSingleton(UpdateCenterClient.class);\n    pico.addSingleton(UpdateCenterMatrixFactory.class);\n    pico.addSingleton(UpdateCenterWs.class);\n\n    // quality profile\n    pico.addSingleton(XMLProfileParser.class);\n    pico.addSingleton(XMLProfileSerializer.class);\n    pico.addSingleton(AnnotationProfileParser.class);\n    pico.addSingleton(QProfiles.class);\n    pico.addSingleton(QProfileLookup.class);\n    pico.addSingleton(QProfileProjectOperations.class);\n    pico.addSingleton(QProfileProjectLookup.class);\n    pico.addSingleton(BuiltInProfiles.class);\n    pico.addSingleton(QProfileRestoreBuiltInAction.class);\n    pico.addSingleton(QProfileSearchAction.class);\n    pico.addSingleton(QProfilesWs.class);\n    pico.addSingleton(ProfilesWs.class);\n    pico.addSingleton(RuleActivationActions.class);\n    pico.addSingleton(BulkRuleActivationActions.class);\n    pico.addSingleton(ProjectAssociationActions.class);\n    pico.addSingleton(RuleActivator.class);\n    pico.addSingleton(QProfileLoader.class);\n    pico.addSingleton(QProfileExporters.class);\n    pico.addSingleton(QProfileService.class);\n    pico.addSingleton(RuleActivatorContextFactory.class);\n    pico.addSingleton(QProfileFactory.class);\n    pico.addSingleton(QProfileCopier.class);\n    pico.addSingleton(QProfileBackuper.class);\n    pico.addSingleton(QProfileReset.class);\n    pico.addSingleton(RubyQProfileActivityService.class);\n\n    // rule\n    pico.addSingleton(AnnotationRuleParser.class);\n    pico.addSingleton(XMLRuleParser.class);\n    pico.addSingleton(DefaultRuleFinder.class);\n    pico.addSingleton(RuleOperations.class);\n    pico.addSingleton(RubyRuleService.class);\n    pico.addSingleton(RuleRepositories.class);\n    pico.addSingleton(DeprecatedRulesDefinitionLoader.class);\n    pico.addSingleton(RuleDefinitionsLoader.class);\n    pico.addSingleton(RulesDefinitionXmlLoader.class);\n    pico.addSingleton(RuleService.class);\n    pico.addSingleton(RuleUpdater.class);\n    pico.addSingleton(RuleCreator.class);\n    pico.addSingleton(RuleDeleter.class);\n    pico.addSingleton(UpdateAction.class);\n    pico.addSingleton(RulesWebService.class);\n    pico.addSingleton(SearchAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.ShowAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.CreateAction.class);\n    pico.addSingleton(DeleteAction.class);\n    pico.addSingleton(TagsAction.class);\n    pico.addSingleton(RuleMapping.class);\n    pico.addSingleton(ActiveRuleCompleter.class);\n    pico.addSingleton(RepositoriesAction.class);\n    pico.addSingleton(AppAction.class);\n\n    // languages\n    pico.addSingleton(Languages.class);\n    pico.addSingleton(LanguageWs.class);\n    pico.addSingleton(ListAction.class);\n\n    // activity\n    pico.addSingleton(ActivitiesWebService.class);\n    pico.addSingleton(org.sonar.server.activity.ws.SearchAction.class);\n    pico.addSingleton(ActivityMapping.class);\n\n    // measure\n    pico.addComponent(MeasuresDao.class, false);\n    pico.addSingleton(MeasureFilterFactory.class);\n    pico.addSingleton(MeasureFilterExecutor.class);\n    pico.addSingleton(MeasureFilterEngine.class);\n    pico.addSingleton(DefaultMetricFinder.class);\n    pico.addSingleton(ServerLifecycleNotifier.class);\n    pico.addSingleton(TimeMachineWs.class);\n    pico.addSingleton(ManualMeasuresWs.class);\n    pico.addSingleton(MetricsWs.class);\n\n    // quality gates\n    pico.addSingleton(QualityGateDao.class);\n    pico.addSingleton(QualityGateConditionDao.class);\n    pico.addSingleton(QualityGates.class);\n    pico.addSingleton(ProjectQgateAssociationDao.class);\n    pico.addSingleton(QgateProjectFinder.class);\n\n    pico.addSingleton(QGatesListAction.class);\n    pico.addSingleton(QGatesSearchAction.class);\n    pico.addSingleton(QGatesShowAction.class);\n    pico.addSingleton(QGatesCreateAction.class);\n    pico.addSingleton(QGatesRenameAction.class);\n    pico.addSingleton(QGatesCopyAction.class);\n    pico.addSingleton(QGatesDestroyAction.class);\n    pico.addSingleton(QGatesSetAsDefaultAction.class);\n    pico.addSingleton(QGatesUnsetDefaultAction.class);\n    pico.addSingleton(QGatesSelectAction.class);\n    pico.addSingleton(QGatesDeselectAction.class);\n    pico.addSingleton(QGatesCreateConditionAction.class);\n    pico.addSingleton(QGatesDeleteConditionAction.class);\n    pico.addSingleton(QGatesUpdateConditionAction.class);\n    pico.addSingleton(QGatesAppAction.class);\n    pico.addSingleton(QGatesWs.class);\n\n    // web services\n    pico.addSingleton(WebServiceEngine.class);\n    pico.addSingleton(ListingWs.class);\n\n    // localization\n    pico.addSingleton(L10nWs.class);\n\n    // authentication\n    pico.addSingleton(AuthenticationWs.class);\n\n    // users\n    pico.addSingleton(SecurityRealmFactory.class);\n    pico.addSingleton(HibernateUserFinder.class);\n    pico.addSingleton(NewUserNotifier.class);\n    pico.addSingleton(DefaultUserFinder.class);\n    pico.addSingleton(DefaultUserService.class);\n    pico.addSingleton(UsersWs.class);\n    pico.addSingleton(org.sonar.server.user.ws.CreateAction.class);\n    pico.addSingleton(org.sonar.server.user.ws.UpdateAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.AuthorsAction.class);\n    pico.addSingleton(FavoritesWs.class);\n    pico.addSingleton(UserPropertiesWs.class);\n    pico.addSingleton(UserIndexDefinition.class);\n    pico.addSingleton(UserIndexer.class);\n    pico.addSingleton(UserIndex.class);\n    pico.addSingleton(UserService.class);\n    pico.addSingleton(UserUpdater.class);\n\n    // groups\n    pico.addSingleton(GroupMembershipService.class);\n    pico.addSingleton(GroupMembershipFinder.class);\n\n    // permissions\n    pico.addSingleton(PermissionFacade.class);\n    pico.addSingleton(InternalPermissionService.class);\n    pico.addSingleton(InternalPermissionTemplateService.class);\n    pico.addSingleton(PermissionFinder.class);\n    pico.addSingleton(PermissionsWs.class);\n\n    // components\n    pico.addSingleton(DefaultComponentFinder.class);\n    pico.addSingleton(DefaultRubyComponentService.class);\n    pico.addSingleton(ComponentService.class);\n    pico.addSingleton(ResourcesWs.class);\n    pico.addSingleton(ComponentsWs.class);\n    pico.addSingleton(ProjectsWs.class);\n    pico.addSingleton(ComponentAppAction.class);\n    pico.addSingleton(org.sonar.server.component.ws.SearchAction.class);\n    pico.addSingleton(EventsWs.class);\n    pico.addSingleton(ComponentCleanerService.class);\n\n    // views\n    pico.addSingleton(ViewIndexDefinition.class);\n    pico.addSingleton(ViewIndexer.class);\n    pico.addSingleton(ViewIndex.class);\n\n    // issues\n    pico.addSingleton(IssueIndexDefinition.class);\n    pico.addSingleton(IssueIndexer.class);\n    pico.addSingleton(IssueAuthorizationIndexer.class);\n    pico.addSingleton(ServerIssueStorage.class);\n    pico.addSingleton(IssueUpdater.class);\n    pico.addSingleton(FunctionExecutor.class);\n    pico.addSingleton(IssueWorkflow.class);\n    pico.addSingleton(IssueCommentService.class);\n    pico.addSingleton(InternalRubyIssueService.class);\n    pico.addSingleton(IssueChangelogService.class);\n    pico.addSingleton(ActionService.class);\n    pico.addSingleton(Actions.class);\n    pico.addSingleton(IssueBulkChangeService.class);\n    pico.addSingleton(IssueChangelogFormatter.class);\n    pico.addSingleton(IssuesWs.class);\n    pico.addSingleton(IssueShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.SearchAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.TagsAction.class);\n    pico.addSingleton(SetTagsAction.class);\n    pico.addSingleton(ComponentTagsAction.class);\n    pico.addSingleton(IssueService.class);\n    pico.addSingleton(IssueActionsWriter.class);\n    pico.addSingleton(IssueQueryService.class);\n    pico.addSingleton(NewIssuesEmailTemplate.class);\n    pico.addSingleton(MyNewIssuesEmailTemplate.class);\n    pico.addSingleton(IssueChangesEmailTemplate.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationDispatcher.class);\n    pico.addSingleton(NewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(MyNewIssuesNotificationDispatcher.class);\n    pico.addSingleton(MyNewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(DoNotFixNotificationDispatcher.class);\n    pico.addSingleton(DoNotFixNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationFactory.class);\n\n    // issue filters\n    pico.addSingleton(IssueFilterService.class);\n    pico.addSingleton(IssueFilterSerializer.class);\n    pico.addSingleton(IssueFilterWs.class);\n    pico.addSingleton(IssueFilterWriter.class);\n    pico.addSingleton(org.sonar.server.issue.filter.AppAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.ShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.FavoritesAction.class);\n\n    // action plan\n    pico.addSingleton(ActionPlanWs.class);\n    pico.addSingleton(ActionPlanService.class);\n\n    // issues actions\n    pico.addSingleton(AssignAction.class);\n    pico.addSingleton(PlanAction.class);\n    pico.addSingleton(SetSeverityAction.class);\n    pico.addSingleton(CommentAction.class);\n    pico.addSingleton(TransitionAction.class);\n    pico.addSingleton(AddTagsAction.class);\n    pico.addSingleton(RemoveTagsAction.class);\n\n    // technical debt\n    pico.addSingleton(DebtModelService.class);\n    pico.addSingleton(DebtModelOperations.class);\n    pico.addSingleton(DebtModelLookup.class);\n    pico.addSingleton(DebtModelBackup.class);\n    pico.addSingleton(DebtModelPluginRepository.class);\n    pico.addSingleton(DebtModelXMLExporter.class);\n    pico.addSingleton(DebtRulesXMLImporter.class);\n    pico.addSingleton(DebtCharacteristicsXMLImporter.class);\n\n    // source\n    pico.addSingleton(HtmlSourceDecorator.class);\n    pico.addSingleton(SourceService.class);\n    pico.addSingleton(SourcesWs.class);\n    pico.addSingleton(ShowAction.class);\n    pico.addSingleton(LinesAction.class);\n    pico.addSingleton(HashAction.class);\n    pico.addSingleton(RawAction.class);\n    pico.addSingleton(IndexAction.class);\n    pico.addSingleton(ScmAction.class);\n    pico.addSingleton(SourceLineIndexDefinition.class);\n    pico.addSingleton(SourceLineIndex.class);\n    pico.addSingleton(SourceLineIndexer.class);\n\n    // Duplications\n    pico.addSingleton(DuplicationsParser.class);\n    pico.addSingleton(DuplicationsWs.class);\n    pico.addSingleton(DuplicationsJsonWriter.class);\n    pico.addSingleton(org.sonar.server.duplication.ws.ShowAction.class);\n\n    // text\n    pico.addSingleton(MacroInterpreter.class);\n    pico.addSingleton(RubyTextService.class);\n\n    // Notifications\n    pico.addSingleton(EmailSettings.class);\n    pico.addSingleton(NotificationService.class);\n    pico.addSingleton(NotificationCenter.class);\n    pico.addSingleton(DefaultNotificationManager.class);\n\n    // Tests\n    pico.addSingleton(CoverageService.class);\n    pico.addSingleton(CoverageWs.class);\n    pico.addSingleton(CoverageShowAction.class);\n    pico.addSingleton(TestsWs.class);\n    pico.addSingleton(TestsTestCasesAction.class);\n    pico.addSingleton(TestsCoveredFilesAction.class);\n    pico.addSingleton(TestsShowAction.class);\n\n    // Properties\n    pico.addSingleton(PropertiesWs.class);\n\n    // graphs and perspective related classes\n    pico.addSingleton(TestablePerspectiveLoader.class);\n    pico.addSingleton(TestPlanPerspectiveLoader.class);\n    pico.addSingleton(SnapshotPerspectives.class);\n\n    // Type validation\n    pico.addSingleton(TypeValidations.class);\n    pico.addSingleton(IntegerTypeValidation.class);\n    pico.addSingleton(FloatTypeValidation.class);\n    pico.addSingleton(BooleanTypeValidation.class);\n    pico.addSingleton(TextTypeValidation.class);\n    pico.addSingleton(StringTypeValidation.class);\n    pico.addSingleton(StringListTypeValidation.class);\n\n    // Design\n    pico.addSingleton(FileDesignWidget.class);\n\n    // System\n    pico.addSingletons(Arrays.asList(\n      SystemRestartWsAction.class,\n      SystemInfoWsAction.class,\n      SystemWs.class,\n      SystemMonitor.class,\n      SonarQubeMonitor.class,\n      EsMonitor.class,\n      PluginsMonitor.class,\n      JvmPropertiesMonitor.class,\n      DatabaseMonitor.class\n      ));\n\n    // Compute engine\n    pico.addSingleton(ReportQueue.class);\n    pico.addSingleton(ComputationThreadLauncher.class);\n    pico.addSingleton(ComputationWebService.class);\n    pico.addSingleton(IsQueueEmptyWebService.class);\n    pico.addSingleton(QueueWsAction.class);\n    pico.addSingleton(HistoryWsAction.class);\n    pico.addSingleton(DefaultPeriodCleaner.class);\n    pico.addSingleton(DefaultPurgeTask.class);\n    pico.addSingleton(ProjectCleaner.class);\n    pico.addSingleton(ProjectSettingsFactory.class);\n    pico.addSingleton(IndexPurgeListener.class);\n\n    for (Object components : level4AddedComponents) {\n      pico.addSingleton(components);\n    }\n\n    ServerExtensionInstaller extensionInstaller = pico.getComponentByType(ServerExtensionInstaller.class);\n    extensionInstaller.installExtensions(pico);\n\n    pico.startComponents();\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"show\")\n      .setDescription(\"Get source code. Require See Source Code permission on file's project<br/>\" +\n        \"Each element of the result array is composed of:\" +\n        \"<ol>\" +\n        \"<li>Line number<\/li>\" +\n        \"<li>Content of the line<\/li>\" +\n        \"<\/ol>\")\n      .setSince(\"4.4\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n\n    action\n      .createParam(\"from\")\n      .setDescription(\"First line to return. Starts at 1\")\n      .setExampleValue(\"10\")\n      .setDefaultValue(\"1\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line to return (inclusive)\")\n      .setExampleValue(\"20\");\n  }","id":14226,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"show\")\n      .setDescription(\"Get source code. Require See Source Code permission on file's project<br/>\" +\n        \"Each element of the result array is composed of:\" +\n        \"<ol>\" +\n        \"<li>Line number<\/li>\" +\n        \"<li>Content of the line<\/li>\" +\n        \"<\/ol>\")\n      .setSince(\"4.4\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(\"key\")\n      .setRequired(true)\n      .setDescription(\"File key\")\n      .setExampleValue(\"my_project:/src/foo/Bar.php\");\n\n    action\n      .createParam(\"from\")\n      .setDescription(\"First line to return. Starts at 1\")\n      .setExampleValue(\"10\")\n      .setDefaultValue(\"1\");\n\n    action\n      .createParam(\"to\")\n      .setDescription(\"Last line to return (inclusive)\")\n      .setExampleValue(\"20\");\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(new ShowAction(sourceService, dbClient), mock(RawAction.class),\n      mock(LinesAction.class),\n      mock(HashAction.class),\n      mock(IndexAction.class)));\n  }","id":14227,"modified_method":"@Before\n  public void setUp() throws Exception {\n    when(dbClient.componentDao()).thenReturn(componentDao);\n    when(dbClient.openSession(false)).thenReturn(session);\n    tester = new WsTester(new SourcesWs(new ShowAction(sourceService, dbClient)));\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n  public void define(Context context) {\n    NewController controller = context.createController(\"api/sources\")\n      .setSince(\"4.2\")\n      .setDescription(\"Display sources information\");\n    showAction.define(controller);\n    linesAction.define(controller);\n    rawAction.define(controller);\n    hashAction.define(controller);\n    indexAction.define(controller);\n    controller.done();\n  }","id":14228,"modified_method":"@Override\n  public void define(Context context) {\n    NewController controller = context.createController(\"api/sources\")\n      .setSince(\"4.2\")\n      .setDescription(\"Display sources information\");\n    for (SourcesAction action : actions) {\n      action.define(controller);\n    }\n    controller.done();\n  }","commit_id":"ed7971e6c86396f4add566c0a7a2809aad277935","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    controller.createAction(\"app\")\n      .setDescription(\"Data required for rendering the page 'Coding Rules'\")\n      .setInternal(true)\n      .setHandler(this);\n  }","id":14229,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    controller.createAction(\"app\")\n      .setDescription(\"Data required for rendering the page 'Coding Rules'\")\n      .setInternal(true)\n      .setHandler(this);\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_generate_app_init_info() throws Exception {\n    AppAction app = new AppAction(languages, ruleRepositories, i18n, debtModel, profileLoader);\n    WsTester tester = new WsTester(new RulesWebService(\n      new SearchAction(null, null, null), mock(ShowAction.class), mock(TagsAction.class), mock(CreateAction.class),\n      app, mock(UpdateAction.class), mock(DeleteAction.class)));\n\n    MockUserSession.set().setGlobalPermissions(GlobalPermissions.QUALITY_PROFILE_ADMIN);\n\n    QualityProfileDto profile1 = QProfileTesting.newXooP1();\n    QualityProfileDto profile2 = QProfileTesting.newXooP2().setParentKee(QProfileTesting.XOO_P1_KEY);\n    when(profileLoader.findAll()).thenReturn(ImmutableList.of(profile1, profile2));\n\n    Language xoo = mock(Language.class);\n    when(xoo.getKey()).thenReturn(\"xoo\");\n    when(xoo.getName()).thenReturn(\"Xoo\");\n    Language whitespace = mock(Language.class);\n    when(whitespace.getKey()).thenReturn(\"ws\");\n    when(whitespace.getName()).thenReturn(\"Whitespace\");\n    when(languages.get(\"xoo\")).thenReturn(xoo);\n    when(languages.all()).thenReturn(new Language[]{xoo, whitespace});\n\n    RuleRepositories.Repository repo1 = mock(RuleRepositories.Repository.class);\n    when(repo1.key()).thenReturn(\"xoo\");\n    when(repo1.name()).thenReturn(\"SonarQube\");\n    when(repo1.language()).thenReturn(\"xoo\");\n    RuleRepositories.Repository repo2 = mock(RuleRepositories.Repository.class);\n    when(repo2.key()).thenReturn(\"squid\");\n    when(repo2.name()).thenReturn(\"SonarQube\");\n    when(repo2.language()).thenReturn(\"ws\");\n    when(ruleRepositories.repositories()).thenReturn(ImmutableList.of(repo1, repo2));\n\n    when(i18n.message(isA(Locale.class), anyString(), anyString())).thenAnswer(new Answer<String>() {\n      @Override\n      public String answer(InvocationOnMock invocation) throws Throwable {\n        return (String) invocation.getArguments()[1];\n      }\n    });\n\n    int parentId = 42;\n    DefaultDebtCharacteristic char1 = new DefaultDebtCharacteristic();\n    char1.setId(parentId).setKey(\"REUSABILITY\").setName(\"Reusability\");\n    DefaultDebtCharacteristic char2 = new DefaultDebtCharacteristic();\n    char2.setId(24).setParentId(parentId).setKey(\"MODULARITY\").setName(\"Modularity\");\n    when(debtModel.allCharacteristics()).thenReturn(ImmutableList.<DebtCharacteristic>of(char1, char2));\n\n    tester.newGetRequest(\"api/rules\", \"app\").execute().assertJson(this.getClass(), \"app.json\");\n  }","id":14230,"modified_method":"@Test\n  public void should_generate_app_init_info() throws Exception {\n    AppAction app = new AppAction(languages, ruleRepositories, i18n, debtModel, profileLoader);\n    WsTester tester = new WsTester(new RulesWebService(app));\n\n    MockUserSession.set().setGlobalPermissions(GlobalPermissions.QUALITY_PROFILE_ADMIN);\n\n    QualityProfileDto profile1 = QProfileTesting.newXooP1();\n    QualityProfileDto profile2 = QProfileTesting.newXooP2().setParentKee(QProfileTesting.XOO_P1_KEY);\n    when(profileLoader.findAll()).thenReturn(ImmutableList.of(profile1, profile2));\n\n    Language xoo = mock(Language.class);\n    when(xoo.getKey()).thenReturn(\"xoo\");\n    when(xoo.getName()).thenReturn(\"Xoo\");\n    Language whitespace = mock(Language.class);\n    when(whitespace.getKey()).thenReturn(\"ws\");\n    when(whitespace.getName()).thenReturn(\"Whitespace\");\n    when(languages.get(\"xoo\")).thenReturn(xoo);\n    when(languages.all()).thenReturn(new Language[]{xoo, whitespace});\n\n    RuleRepositories.Repository repo1 = mock(RuleRepositories.Repository.class);\n    when(repo1.key()).thenReturn(\"xoo\");\n    when(repo1.name()).thenReturn(\"SonarQube\");\n    when(repo1.language()).thenReturn(\"xoo\");\n    RuleRepositories.Repository repo2 = mock(RuleRepositories.Repository.class);\n    when(repo2.key()).thenReturn(\"squid\");\n    when(repo2.name()).thenReturn(\"SonarQube\");\n    when(repo2.language()).thenReturn(\"ws\");\n    when(ruleRepositories.repositories()).thenReturn(ImmutableList.of(repo1, repo2));\n\n    when(i18n.message(isA(Locale.class), anyString(), anyString())).thenAnswer(new Answer<String>() {\n      @Override\n      public String answer(InvocationOnMock invocation) throws Throwable {\n        return (String) invocation.getArguments()[1];\n      }\n    });\n\n    int parentId = 42;\n    DefaultDebtCharacteristic char1 = new DefaultDebtCharacteristic();\n    char1.setId(parentId).setKey(\"REUSABILITY\").setName(\"Reusability\");\n    DefaultDebtCharacteristic char2 = new DefaultDebtCharacteristic();\n    char2.setId(24).setParentId(parentId).setKey(\"MODULARITY\").setName(\"Modularity\");\n    when(debtModel.allCharacteristics()).thenReturn(ImmutableList.<DebtCharacteristic>of(char1, char2));\n\n    tester.newGetRequest(\"api/rules\", \"app\").execute().assertJson(this.getClass(), \"app.json\");\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"create\")\n      .setDescription(\"Create a custom rule or a manual rule\")\n      .setSince(\"4.4\")\n      .setPost(true)\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_CUSTOM_KEY)\n      .setDescription(\"Key of the custom rule\")\n      .setExampleValue(\"Todo_should_not_be_used\");\n\n    action\n      .createParam(PARAM_MANUAL_KEY)\n      .setDescription(\"Key of the manual rule\")\n      .setExampleValue(\"Error_handling\");\n\n    action\n      .createParam(PARAM_TEMPLATE_KEY)\n      .setDescription(\"Key of the template rule in order to create a custom rule (mandatory for custom rule)\")\n      .setExampleValue(\"java:XPath\");\n\n    action\n      .createParam(PARAM_NAME)\n      .setDescription(\"Rule name\")\n      .setRequired(true)\n      .setExampleValue(\"My custom rule\");\n\n    action\n      .createParam(PARAM_DESCRIPTION)\n      .setDescription(\"Rule description\")\n      .setRequired(true)\n      .setExampleValue(\"Description of my custom rule\");\n\n    action\n      .createParam(PARAM_SEVERITY)\n      .setDescription(\"Rule severity (Only for custom rule)\")\n      .setPossibleValues(Severity.ALL);\n\n    action\n      .createParam(PARAM_STATUS)\n      .setDescription(\"Rule status (Only for custom rule)\")\n      .setDefaultValue(RuleStatus.READY)\n      .setPossibleValues(RuleStatus.values());\n\n    action.createParam(PARAMS)\n      .setDescription(\"Parameters as semi-colon list of <key>=<value>, for example 'params=key1=v1;key2=v2' (Only for custom rule)\");\n\n    action\n      .createParam(PARAM_PREVENT_REACTIVATION)\n      .setDescription(\"If set to true and if the rule has been deactivated (status 'REMOVED'), a status 409 will be returned\")\n      .setDefaultValue(false)\n      .setBooleanPossibleValues();\n  }","id":14231,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"create\")\n      .setDescription(\"Create a custom rule or a manual rule\")\n      .setSince(\"4.4\")\n      .setPost(true)\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_CUSTOM_KEY)\n      .setDescription(\"Key of the custom rule\")\n      .setExampleValue(\"Todo_should_not_be_used\");\n\n    action\n      .createParam(PARAM_MANUAL_KEY)\n      .setDescription(\"Key of the manual rule\")\n      .setExampleValue(\"Error_handling\");\n\n    action\n      .createParam(PARAM_TEMPLATE_KEY)\n      .setDescription(\"Key of the template rule in order to create a custom rule (mandatory for custom rule)\")\n      .setExampleValue(\"java:XPath\");\n\n    action\n      .createParam(PARAM_NAME)\n      .setDescription(\"Rule name\")\n      .setRequired(true)\n      .setExampleValue(\"My custom rule\");\n\n    action\n      .createParam(PARAM_DESCRIPTION)\n      .setDescription(\"Rule description\")\n      .setRequired(true)\n      .setExampleValue(\"Description of my custom rule\");\n\n    action\n      .createParam(PARAM_SEVERITY)\n      .setDescription(\"Rule severity (Only for custom rule)\")\n      .setPossibleValues(Severity.ALL);\n\n    action\n      .createParam(PARAM_STATUS)\n      .setDescription(\"Rule status (Only for custom rule)\")\n      .setDefaultValue(RuleStatus.READY)\n      .setPossibleValues(RuleStatus.values());\n\n    action.createParam(PARAMS)\n      .setDescription(\"Parameters as semi-colon list of <key>=<value>, for example 'params=key1=v1;key2=v2' (Only for custom rule)\");\n\n    action\n      .createParam(PARAM_PREVENT_REACTIVATION)\n      .setDescription(\"If set to true and if the rule has been deactivated (status 'REMOVED'), a status 409 will be returned\")\n      .setDefaultValue(false)\n      .setBooleanPossibleValues();\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"delete\")\n      .setDescription(\"Delete custom rule or manual rule\")\n      .setSince(\"4.4\")\n      .setPost(true)\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_KEY)\n      .setDescription(\"Rule key\")\n      .setRequired(true)\n      .setExampleValue(\"squid:XPath_1402065390816\");\n  }","id":14232,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"delete\")\n      .setDescription(\"Delete custom rule or manual rule\")\n      .setSince(\"4.4\")\n      .setPost(true)\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_KEY)\n      .setDescription(\"Rule key\")\n      .setRequired(true)\n      .setExampleValue(\"squid:XPath_1402065390816\");\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    tester = new WsTester(new RulesWebService(new SearchAction(null, null, null), mock(ShowAction.class), mock(TagsAction.class), mock(CreateAction.class), mock(AppAction.class),\n      mock(UpdateAction.class), new DeleteAction(ruleService)));\n  }","id":14233,"modified_method":"@Before\n  public void setUp() throws Exception {\n    tester = new WsTester(new RulesWebService(new DeleteAction(ruleService)));\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n  public void define(Context context) {\n    NewController controller = context\n      .createController(\"api/rules\")\n      .setDescription(\"Coding rules\");\n\n    search.define(controller);\n    show.define(controller);\n    tags.define(controller);\n    app.define(controller);\n    update.define(controller);\n    create.define(controller);\n    delete.define(controller);\n\n    controller.done();\n  }","id":14234,"modified_method":"@Override\n  public void define(Context context) {\n    NewController controller = context\n      .createController(\"api/rules\")\n      .setDescription(\"Coding rules\");\n\n    for (RulesAction action : actions) {\n      action.define(controller);\n    }\n\n    controller.done();\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void define() throws Exception {\n    WebService.Context context = new WebService.Context();\n    ws.define(context);\n\n    WebService.Controller controller = context.controller(API_ENDPOINT);\n\n    assertThat(controller).isNotNull();\n    assertThat(controller.actions()).hasSize(7);\n    assertThat(controller.action(API_SEARCH_METHOD)).isNotNull();\n    assertThat(controller.action(API_SHOW_METHOD)).isNotNull();\n    assertThat(controller.action(API_TAGS_METHOD)).isNotNull();\n    assertThat(controller.action(\"update\")).isNotNull();\n    assertThat(controller.action(\"create\")).isNotNull();\n    assertThat(controller.action(\"delete\")).isNotNull();\n    assertThat(controller.action(\"app\")).isNotNull();\n  }","id":14235,"modified_method":"@Test\n  public void define() throws Exception {\n    WebService.Context context = new WebService.Context();\n    ws.define(context);\n\n    WebService.Controller controller = context.controller(API_ENDPOINT);\n\n    assertThat(controller).isNotNull();\n    assertThat(controller.actions()).hasSize(8);\n    assertThat(controller.action(API_SEARCH_METHOD)).isNotNull();\n    assertThat(controller.action(API_SHOW_METHOD)).isNotNull();\n    assertThat(controller.action(API_TAGS_METHOD)).isNotNull();\n    assertThat(controller.action(\"update\")).isNotNull();\n    assertThat(controller.action(\"create\")).isNotNull();\n    assertThat(controller.action(\"delete\")).isNotNull();\n    assertThat(controller.action(\"repositories\")).isNotNull();\n    assertThat(controller.action(\"app\")).isNotNull();\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void startLevel4Components(ComponentContainer pico) {\n    pico.addSingleton(PluginDownloader.class);\n    pico.addSingleton(ChartFactory.class);\n    pico.addSingleton(Views.class);\n    pico.addSingleton(ResourceTypes.class);\n    pico.addSingleton(SettingsChangeNotifier.class);\n    pico.addSingleton(PageDecorations.class);\n    pico.addSingleton(PreviewCache.class);\n    pico.addSingleton(DefaultResourcePermissions.class);\n    pico.addSingleton(Periods.class);\n    pico.addSingleton(ServerWs.class);\n    pico.addSingleton(BackendCleanup.class);\n    pico.addSingleton(IndexRegistry.class);\n    pico.addSingleton(IndexCreator.class);\n\n    // batch\n    pico.addSingleton(BatchIndex.class);\n    pico.addSingleton(GlobalRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryLoader.class);\n    pico.addSingleton(SubmitReportWsAction.class);\n    pico.addSingleton(IssuesAction.class);\n    pico.addSingleton(BatchWs.class);\n\n    // update center\n    pico.addSingleton(UpdateCenterClient.class);\n    pico.addSingleton(UpdateCenterMatrixFactory.class);\n    pico.addSingleton(UpdateCenterWs.class);\n\n    // quality profile\n    pico.addSingleton(XMLProfileParser.class);\n    pico.addSingleton(XMLProfileSerializer.class);\n    pico.addSingleton(AnnotationProfileParser.class);\n    pico.addSingleton(QProfiles.class);\n    pico.addSingleton(QProfileLookup.class);\n    pico.addSingleton(QProfileProjectOperations.class);\n    pico.addSingleton(QProfileProjectLookup.class);\n    pico.addSingleton(BuiltInProfiles.class);\n    pico.addSingleton(QProfileRestoreBuiltInAction.class);\n    pico.addSingleton(QProfilesWs.class);\n    pico.addSingleton(ProfilesWs.class);\n    pico.addSingleton(RuleActivationActions.class);\n    pico.addSingleton(BulkRuleActivationActions.class);\n    pico.addSingleton(RuleActivator.class);\n    pico.addSingleton(QProfileLoader.class);\n    pico.addSingleton(QProfileExporters.class);\n    pico.addSingleton(QProfileService.class);\n    pico.addSingleton(RuleActivatorContextFactory.class);\n    pico.addSingleton(QProfileFactory.class);\n    pico.addSingleton(QProfileCopier.class);\n    pico.addSingleton(QProfileBackuper.class);\n    pico.addSingleton(QProfileReset.class);\n    pico.addSingleton(RubyQProfileActivityService.class);\n\n    // rule\n    pico.addSingleton(AnnotationRuleParser.class);\n    pico.addSingleton(XMLRuleParser.class);\n    pico.addSingleton(DefaultRuleFinder.class);\n    pico.addSingleton(RuleOperations.class);\n    pico.addSingleton(RubyRuleService.class);\n    pico.addSingleton(RuleRepositories.class);\n    pico.addSingleton(DeprecatedRulesDefinitionLoader.class);\n    pico.addSingleton(RuleDefinitionsLoader.class);\n    pico.addSingleton(RulesDefinitionXmlLoader.class);\n    pico.addSingleton(RuleService.class);\n    pico.addSingleton(RuleUpdater.class);\n    pico.addSingleton(RuleCreator.class);\n    pico.addSingleton(RuleDeleter.class);\n    pico.addSingleton(UpdateAction.class);\n    pico.addSingleton(RulesWebService.class);\n    pico.addSingleton(SearchAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.ShowAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.CreateAction.class);\n    pico.addSingleton(DeleteAction.class);\n    pico.addSingleton(TagsAction.class);\n    pico.addSingleton(RuleMapping.class);\n    pico.addSingleton(ActiveRuleCompleter.class);\n    pico.addSingleton(AppAction.class);\n\n    // languages\n    pico.addSingleton(Languages.class);\n    pico.addSingleton(LanguageWs.class);\n    pico.addSingleton(ListAction.class);\n\n    // activity\n    pico.addSingleton(ActivitiesWebService.class);\n    pico.addSingleton(org.sonar.server.activity.ws.SearchAction.class);\n    pico.addSingleton(ActivityMapping.class);\n\n    // measure\n    pico.addComponent(MeasuresDao.class, false);\n    pico.addSingleton(MeasureFilterFactory.class);\n    pico.addSingleton(MeasureFilterExecutor.class);\n    pico.addSingleton(MeasureFilterEngine.class);\n    pico.addSingleton(DefaultMetricFinder.class);\n    pico.addSingleton(ServerLifecycleNotifier.class);\n    pico.addSingleton(TimeMachineWs.class);\n    pico.addSingleton(ManualMeasuresWs.class);\n    pico.addSingleton(MetricsWs.class);\n\n    // quality gates\n    pico.addSingleton(QualityGateDao.class);\n    pico.addSingleton(QualityGateConditionDao.class);\n    pico.addSingleton(QualityGates.class);\n    pico.addSingleton(ProjectQgateAssociationDao.class);\n    pico.addSingleton(QgateProjectFinder.class);\n\n    pico.addSingleton(QGatesListAction.class);\n    pico.addSingleton(QGatesSearchAction.class);\n    pico.addSingleton(QGatesShowAction.class);\n    pico.addSingleton(QGatesCreateAction.class);\n    pico.addSingleton(QGatesRenameAction.class);\n    pico.addSingleton(QGatesCopyAction.class);\n    pico.addSingleton(QGatesDestroyAction.class);\n    pico.addSingleton(QGatesSetAsDefaultAction.class);\n    pico.addSingleton(QGatesUnsetDefaultAction.class);\n    pico.addSingleton(QGatesSelectAction.class);\n    pico.addSingleton(QGatesDeselectAction.class);\n    pico.addSingleton(QGatesCreateConditionAction.class);\n    pico.addSingleton(QGatesDeleteConditionAction.class);\n    pico.addSingleton(QGatesUpdateConditionAction.class);\n    pico.addSingleton(QGatesAppAction.class);\n    pico.addSingleton(QGatesWs.class);\n\n    // web services\n    pico.addSingleton(WebServiceEngine.class);\n    pico.addSingleton(ListingWs.class);\n\n    // localization\n    pico.addSingleton(L10nWs.class);\n\n    // authentication\n    pico.addSingleton(AuthenticationWs.class);\n\n    // users\n    pico.addSingleton(SecurityRealmFactory.class);\n    pico.addSingleton(HibernateUserFinder.class);\n    pico.addSingleton(NewUserNotifier.class);\n    pico.addSingleton(DefaultUserFinder.class);\n    pico.addSingleton(DefaultUserService.class);\n    pico.addSingleton(UsersWs.class);\n    pico.addSingleton(org.sonar.server.user.ws.CreateAction.class);\n    pico.addSingleton(org.sonar.server.user.ws.UpdateAction.class);\n    pico.addSingleton(FavoritesWs.class);\n    pico.addSingleton(UserPropertiesWs.class);\n    pico.addSingleton(UserIndexDefinition.class);\n    pico.addSingleton(UserIndexer.class);\n    pico.addSingleton(UserIndex.class);\n    pico.addSingleton(UserService.class);\n    pico.addSingleton(UserUpdater.class);\n\n    // groups\n    pico.addSingleton(GroupMembershipService.class);\n    pico.addSingleton(GroupMembershipFinder.class);\n\n    // permissions\n    pico.addSingleton(PermissionFacade.class);\n    pico.addSingleton(InternalPermissionService.class);\n    pico.addSingleton(InternalPermissionTemplateService.class);\n    pico.addSingleton(PermissionFinder.class);\n    pico.addSingleton(PermissionsWs.class);\n\n    // components\n    pico.addSingleton(DefaultComponentFinder.class);\n    pico.addSingleton(DefaultRubyComponentService.class);\n    pico.addSingleton(ComponentService.class);\n    pico.addSingleton(ComponentDao.class);\n    pico.addSingleton(ResourcesWs.class);\n    pico.addSingleton(ComponentsWs.class);\n    pico.addSingleton(ProjectsWs.class);\n    pico.addSingleton(ComponentAppAction.class);\n    pico.addSingleton(EventsWs.class);\n    pico.addSingleton(ComponentCleanerService.class);\n\n    // issues\n    pico.addSingleton(IssueIndexDefinition.class);\n    pico.addSingleton(IssueIndexer.class);\n    pico.addSingleton(IssueAuthorizationIndexer.class);\n    pico.addSingleton(ServerIssueStorage.class);\n    pico.addSingleton(IssueUpdater.class);\n    pico.addSingleton(FunctionExecutor.class);\n    pico.addSingleton(IssueWorkflow.class);\n    pico.addSingleton(IssueCommentService.class);\n    pico.addSingleton(InternalRubyIssueService.class);\n    pico.addSingleton(IssueChangelogService.class);\n    pico.addSingleton(ActionService.class);\n    pico.addSingleton(Actions.class);\n    pico.addSingleton(IssueBulkChangeService.class);\n    pico.addSingleton(IssueChangelogFormatter.class);\n    pico.addSingleton(IssuesWs.class);\n    pico.addSingleton(IssueShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.SearchAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.TagsAction.class);\n    pico.addSingleton(SetTagsAction.class);\n    pico.addSingleton(ComponentTagsAction.class);\n    pico.addSingleton(IssueService.class);\n    pico.addSingleton(IssueActionsWriter.class);\n    pico.addSingleton(IssueQueryService.class);\n    pico.addSingleton(IssueNotifications.class);\n    pico.addSingleton(NewIssuesEmailTemplate.class);\n    pico.addSingleton(IssueChangesEmailTemplate.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationDispatcher.class);\n    pico.addSingleton(NewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewFalsePositiveNotificationDispatcher.class);\n    pico.addSingleton(NewFalsePositiveNotificationDispatcher.newMetadata());\n\n    // issue filters\n    pico.addSingleton(IssueFilterService.class);\n    pico.addSingleton(IssueFilterSerializer.class);\n    pico.addSingleton(IssueFilterWs.class);\n    pico.addSingleton(IssueFilterWriter.class);\n    pico.addSingleton(org.sonar.server.issue.filter.AppAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.ShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.FavoritesAction.class);\n\n    // action plan\n    pico.addSingleton(ActionPlanWs.class);\n    pico.addSingleton(ActionPlanService.class);\n\n    // issues actions\n    pico.addSingleton(AssignAction.class);\n    pico.addSingleton(PlanAction.class);\n    pico.addSingleton(SetSeverityAction.class);\n    pico.addSingleton(CommentAction.class);\n    pico.addSingleton(TransitionAction.class);\n    pico.addSingleton(AddTagsAction.class);\n    pico.addSingleton(RemoveTagsAction.class);\n\n    // technical debt\n    pico.addSingleton(DebtModelService.class);\n    pico.addSingleton(DebtModelOperations.class);\n    pico.addSingleton(DebtModelLookup.class);\n    pico.addSingleton(DebtModelBackup.class);\n    pico.addSingleton(DebtModelPluginRepository.class);\n    pico.addSingleton(DebtModelXMLExporter.class);\n    pico.addSingleton(DebtRulesXMLImporter.class);\n    pico.addSingleton(DebtCharacteristicsXMLImporter.class);\n\n    // source\n    pico.addSingleton(HtmlSourceDecorator.class);\n    pico.addSingleton(SourceService.class);\n    pico.addSingleton(SourcesWs.class);\n    pico.addSingleton(ShowAction.class);\n    pico.addSingleton(LinesAction.class);\n    pico.addSingleton(HashAction.class);\n    pico.addSingleton(ScmWriter.class);\n    pico.addSingleton(RawAction.class);\n    pico.addSingleton(IndexAction.class);\n    pico.addSingleton(ScmAction.class);\n    pico.addSingleton(SourceLineIndexDefinition.class);\n    pico.addSingleton(SourceLineIndex.class);\n    pico.addSingleton(SourceLineIndexer.class);\n\n    // Duplications\n    pico.addSingleton(DuplicationsParser.class);\n    pico.addSingleton(DuplicationsWs.class);\n    pico.addSingleton(DuplicationsJsonWriter.class);\n    pico.addSingleton(org.sonar.server.duplication.ws.ShowAction.class);\n\n    // text\n    pico.addSingleton(MacroInterpreter.class);\n    pico.addSingleton(RubyTextService.class);\n\n    // Notifications\n    pico.addSingleton(EmailSettings.class);\n    pico.addSingleton(NotificationService.class);\n    pico.addSingleton(NotificationCenter.class);\n    pico.addSingleton(DefaultNotificationManager.class);\n\n    // Tests\n    pico.addSingleton(CoverageService.class);\n    pico.addSingleton(CoverageWs.class);\n    pico.addSingleton(CoverageShowAction.class);\n    pico.addSingleton(TestsWs.class);\n    pico.addSingleton(TestsTestCasesAction.class);\n    pico.addSingleton(TestsCoveredFilesAction.class);\n    pico.addSingleton(TestsShowAction.class);\n\n    // Properties\n    pico.addSingleton(PropertiesWs.class);\n\n    // graphs and perspective related classes\n    pico.addSingleton(TestablePerspectiveLoader.class);\n    pico.addSingleton(TestPlanPerspectiveLoader.class);\n    pico.addSingleton(SnapshotPerspectives.class);\n\n    // Type validation\n    pico.addSingleton(TypeValidations.class);\n    pico.addSingleton(IntegerTypeValidation.class);\n    pico.addSingleton(FloatTypeValidation.class);\n    pico.addSingleton(BooleanTypeValidation.class);\n    pico.addSingleton(TextTypeValidation.class);\n    pico.addSingleton(StringTypeValidation.class);\n    pico.addSingleton(StringListTypeValidation.class);\n\n    // Design\n    pico.addSingleton(FileDesignWidget.class);\n\n    // Compute engine\n    pico.addSingleton(AnalysisReportQueue.class);\n    pico.addSingleton(ComputationThreadLauncher.class);\n    pico.addSingleton(ComputationWebService.class);\n    pico.addSingleton(IsQueueEmptyWebService.class);\n    pico.addSingleton(QueueWsAction.class);\n    pico.addSingleton(HistoryWsAction.class);\n    pico.addSingleton(DefaultPeriodCleaner.class);\n    pico.addSingleton(DefaultPurgeTask.class);\n    pico.addSingleton(ProjectCleaner.class);\n    pico.addSingleton(ProjectSettingsFactory.class);\n    pico.addSingleton(IndexPurgeListener.class);\n\n    for (Object components : level4AddedComponents) {\n      pico.addSingleton(components);\n    }\n\n    ServerExtensionInstaller extensionInstaller = pico.getComponentByType(ServerExtensionInstaller.class);\n    extensionInstaller.installExtensions(pico);\n\n    pico.startComponents();\n  }","id":14236,"modified_method":"void startLevel4Components(ComponentContainer pico) {\n    pico.addSingleton(PluginDownloader.class);\n    pico.addSingleton(ChartFactory.class);\n    pico.addSingleton(Views.class);\n    pico.addSingleton(ResourceTypes.class);\n    pico.addSingleton(SettingsChangeNotifier.class);\n    pico.addSingleton(PageDecorations.class);\n    pico.addSingleton(PreviewCache.class);\n    pico.addSingleton(DefaultResourcePermissions.class);\n    pico.addSingleton(Periods.class);\n    pico.addSingleton(ServerWs.class);\n    pico.addSingleton(BackendCleanup.class);\n    pico.addSingleton(IndexRegistry.class);\n    pico.addSingleton(IndexCreator.class);\n\n    // batch\n    pico.addSingleton(BatchIndex.class);\n    pico.addSingleton(GlobalRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryAction.class);\n    pico.addSingleton(ProjectRepositoryLoader.class);\n    pico.addSingleton(SubmitReportWsAction.class);\n    pico.addSingleton(IssuesAction.class);\n    pico.addSingleton(BatchWs.class);\n\n    // update center\n    pico.addSingleton(UpdateCenterClient.class);\n    pico.addSingleton(UpdateCenterMatrixFactory.class);\n    pico.addSingleton(UpdateCenterWs.class);\n\n    // quality profile\n    pico.addSingleton(XMLProfileParser.class);\n    pico.addSingleton(XMLProfileSerializer.class);\n    pico.addSingleton(AnnotationProfileParser.class);\n    pico.addSingleton(QProfiles.class);\n    pico.addSingleton(QProfileLookup.class);\n    pico.addSingleton(QProfileProjectOperations.class);\n    pico.addSingleton(QProfileProjectLookup.class);\n    pico.addSingleton(BuiltInProfiles.class);\n    pico.addSingleton(QProfileRestoreBuiltInAction.class);\n    pico.addSingleton(QProfilesWs.class);\n    pico.addSingleton(ProfilesWs.class);\n    pico.addSingleton(RuleActivationActions.class);\n    pico.addSingleton(BulkRuleActivationActions.class);\n    pico.addSingleton(RuleActivator.class);\n    pico.addSingleton(QProfileLoader.class);\n    pico.addSingleton(QProfileExporters.class);\n    pico.addSingleton(QProfileService.class);\n    pico.addSingleton(RuleActivatorContextFactory.class);\n    pico.addSingleton(QProfileFactory.class);\n    pico.addSingleton(QProfileCopier.class);\n    pico.addSingleton(QProfileBackuper.class);\n    pico.addSingleton(QProfileReset.class);\n    pico.addSingleton(RubyQProfileActivityService.class);\n\n    // rule\n    pico.addSingleton(AnnotationRuleParser.class);\n    pico.addSingleton(XMLRuleParser.class);\n    pico.addSingleton(DefaultRuleFinder.class);\n    pico.addSingleton(RuleOperations.class);\n    pico.addSingleton(RubyRuleService.class);\n    pico.addSingleton(RuleRepositories.class);\n    pico.addSingleton(DeprecatedRulesDefinitionLoader.class);\n    pico.addSingleton(RuleDefinitionsLoader.class);\n    pico.addSingleton(RulesDefinitionXmlLoader.class);\n    pico.addSingleton(RuleService.class);\n    pico.addSingleton(RuleUpdater.class);\n    pico.addSingleton(RuleCreator.class);\n    pico.addSingleton(RuleDeleter.class);\n    pico.addSingleton(UpdateAction.class);\n    pico.addSingleton(RulesWebService.class);\n    pico.addSingleton(SearchAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.ShowAction.class);\n    pico.addSingleton(org.sonar.server.rule.ws.CreateAction.class);\n    pico.addSingleton(DeleteAction.class);\n    pico.addSingleton(TagsAction.class);\n    pico.addSingleton(RuleMapping.class);\n    pico.addSingleton(ActiveRuleCompleter.class);\n    pico.addSingleton(RepositoriesAction.class);\n    pico.addSingleton(AppAction.class);\n\n    // languages\n    pico.addSingleton(Languages.class);\n    pico.addSingleton(LanguageWs.class);\n    pico.addSingleton(ListAction.class);\n\n    // activity\n    pico.addSingleton(ActivitiesWebService.class);\n    pico.addSingleton(org.sonar.server.activity.ws.SearchAction.class);\n    pico.addSingleton(ActivityMapping.class);\n\n    // measure\n    pico.addComponent(MeasuresDao.class, false);\n    pico.addSingleton(MeasureFilterFactory.class);\n    pico.addSingleton(MeasureFilterExecutor.class);\n    pico.addSingleton(MeasureFilterEngine.class);\n    pico.addSingleton(DefaultMetricFinder.class);\n    pico.addSingleton(ServerLifecycleNotifier.class);\n    pico.addSingleton(TimeMachineWs.class);\n    pico.addSingleton(ManualMeasuresWs.class);\n    pico.addSingleton(MetricsWs.class);\n\n    // quality gates\n    pico.addSingleton(QualityGateDao.class);\n    pico.addSingleton(QualityGateConditionDao.class);\n    pico.addSingleton(QualityGates.class);\n    pico.addSingleton(ProjectQgateAssociationDao.class);\n    pico.addSingleton(QgateProjectFinder.class);\n\n    pico.addSingleton(QGatesListAction.class);\n    pico.addSingleton(QGatesSearchAction.class);\n    pico.addSingleton(QGatesShowAction.class);\n    pico.addSingleton(QGatesCreateAction.class);\n    pico.addSingleton(QGatesRenameAction.class);\n    pico.addSingleton(QGatesCopyAction.class);\n    pico.addSingleton(QGatesDestroyAction.class);\n    pico.addSingleton(QGatesSetAsDefaultAction.class);\n    pico.addSingleton(QGatesUnsetDefaultAction.class);\n    pico.addSingleton(QGatesSelectAction.class);\n    pico.addSingleton(QGatesDeselectAction.class);\n    pico.addSingleton(QGatesCreateConditionAction.class);\n    pico.addSingleton(QGatesDeleteConditionAction.class);\n    pico.addSingleton(QGatesUpdateConditionAction.class);\n    pico.addSingleton(QGatesAppAction.class);\n    pico.addSingleton(QGatesWs.class);\n\n    // web services\n    pico.addSingleton(WebServiceEngine.class);\n    pico.addSingleton(ListingWs.class);\n\n    // localization\n    pico.addSingleton(L10nWs.class);\n\n    // authentication\n    pico.addSingleton(AuthenticationWs.class);\n\n    // users\n    pico.addSingleton(SecurityRealmFactory.class);\n    pico.addSingleton(HibernateUserFinder.class);\n    pico.addSingleton(NewUserNotifier.class);\n    pico.addSingleton(DefaultUserFinder.class);\n    pico.addSingleton(DefaultUserService.class);\n    pico.addSingleton(UsersWs.class);\n    pico.addSingleton(org.sonar.server.user.ws.CreateAction.class);\n    pico.addSingleton(org.sonar.server.user.ws.UpdateAction.class);\n    pico.addSingleton(FavoritesWs.class);\n    pico.addSingleton(UserPropertiesWs.class);\n    pico.addSingleton(UserIndexDefinition.class);\n    pico.addSingleton(UserIndexer.class);\n    pico.addSingleton(UserIndex.class);\n    pico.addSingleton(UserService.class);\n    pico.addSingleton(UserUpdater.class);\n\n    // groups\n    pico.addSingleton(GroupMembershipService.class);\n    pico.addSingleton(GroupMembershipFinder.class);\n\n    // permissions\n    pico.addSingleton(PermissionFacade.class);\n    pico.addSingleton(InternalPermissionService.class);\n    pico.addSingleton(InternalPermissionTemplateService.class);\n    pico.addSingleton(PermissionFinder.class);\n    pico.addSingleton(PermissionsWs.class);\n\n    // components\n    pico.addSingleton(DefaultComponentFinder.class);\n    pico.addSingleton(DefaultRubyComponentService.class);\n    pico.addSingleton(ComponentService.class);\n    pico.addSingleton(ComponentDao.class);\n    pico.addSingleton(ResourcesWs.class);\n    pico.addSingleton(ComponentsWs.class);\n    pico.addSingleton(ProjectsWs.class);\n    pico.addSingleton(ComponentAppAction.class);\n    pico.addSingleton(EventsWs.class);\n    pico.addSingleton(ComponentCleanerService.class);\n\n    // issues\n    pico.addSingleton(IssueIndexDefinition.class);\n    pico.addSingleton(IssueIndexer.class);\n    pico.addSingleton(IssueAuthorizationIndexer.class);\n    pico.addSingleton(ServerIssueStorage.class);\n    pico.addSingleton(IssueUpdater.class);\n    pico.addSingleton(FunctionExecutor.class);\n    pico.addSingleton(IssueWorkflow.class);\n    pico.addSingleton(IssueCommentService.class);\n    pico.addSingleton(InternalRubyIssueService.class);\n    pico.addSingleton(IssueChangelogService.class);\n    pico.addSingleton(ActionService.class);\n    pico.addSingleton(Actions.class);\n    pico.addSingleton(IssueBulkChangeService.class);\n    pico.addSingleton(IssueChangelogFormatter.class);\n    pico.addSingleton(IssuesWs.class);\n    pico.addSingleton(IssueShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.SearchAction.class);\n    pico.addSingleton(org.sonar.server.issue.ws.TagsAction.class);\n    pico.addSingleton(SetTagsAction.class);\n    pico.addSingleton(ComponentTagsAction.class);\n    pico.addSingleton(IssueService.class);\n    pico.addSingleton(IssueActionsWriter.class);\n    pico.addSingleton(IssueQueryService.class);\n    pico.addSingleton(IssueNotifications.class);\n    pico.addSingleton(NewIssuesEmailTemplate.class);\n    pico.addSingleton(IssueChangesEmailTemplate.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.class);\n    pico.addSingleton(ChangesOnMyIssueNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewIssuesNotificationDispatcher.class);\n    pico.addSingleton(NewIssuesNotificationDispatcher.newMetadata());\n    pico.addSingleton(NewFalsePositiveNotificationDispatcher.class);\n    pico.addSingleton(NewFalsePositiveNotificationDispatcher.newMetadata());\n\n    // issue filters\n    pico.addSingleton(IssueFilterService.class);\n    pico.addSingleton(IssueFilterSerializer.class);\n    pico.addSingleton(IssueFilterWs.class);\n    pico.addSingleton(IssueFilterWriter.class);\n    pico.addSingleton(org.sonar.server.issue.filter.AppAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.ShowAction.class);\n    pico.addSingleton(org.sonar.server.issue.filter.FavoritesAction.class);\n\n    // action plan\n    pico.addSingleton(ActionPlanWs.class);\n    pico.addSingleton(ActionPlanService.class);\n\n    // issues actions\n    pico.addSingleton(AssignAction.class);\n    pico.addSingleton(PlanAction.class);\n    pico.addSingleton(SetSeverityAction.class);\n    pico.addSingleton(CommentAction.class);\n    pico.addSingleton(TransitionAction.class);\n    pico.addSingleton(AddTagsAction.class);\n    pico.addSingleton(RemoveTagsAction.class);\n\n    // technical debt\n    pico.addSingleton(DebtModelService.class);\n    pico.addSingleton(DebtModelOperations.class);\n    pico.addSingleton(DebtModelLookup.class);\n    pico.addSingleton(DebtModelBackup.class);\n    pico.addSingleton(DebtModelPluginRepository.class);\n    pico.addSingleton(DebtModelXMLExporter.class);\n    pico.addSingleton(DebtRulesXMLImporter.class);\n    pico.addSingleton(DebtCharacteristicsXMLImporter.class);\n\n    // source\n    pico.addSingleton(HtmlSourceDecorator.class);\n    pico.addSingleton(SourceService.class);\n    pico.addSingleton(SourcesWs.class);\n    pico.addSingleton(ShowAction.class);\n    pico.addSingleton(LinesAction.class);\n    pico.addSingleton(HashAction.class);\n    pico.addSingleton(ScmWriter.class);\n    pico.addSingleton(RawAction.class);\n    pico.addSingleton(IndexAction.class);\n    pico.addSingleton(ScmAction.class);\n    pico.addSingleton(SourceLineIndexDefinition.class);\n    pico.addSingleton(SourceLineIndex.class);\n    pico.addSingleton(SourceLineIndexer.class);\n\n    // Duplications\n    pico.addSingleton(DuplicationsParser.class);\n    pico.addSingleton(DuplicationsWs.class);\n    pico.addSingleton(DuplicationsJsonWriter.class);\n    pico.addSingleton(org.sonar.server.duplication.ws.ShowAction.class);\n\n    // text\n    pico.addSingleton(MacroInterpreter.class);\n    pico.addSingleton(RubyTextService.class);\n\n    // Notifications\n    pico.addSingleton(EmailSettings.class);\n    pico.addSingleton(NotificationService.class);\n    pico.addSingleton(NotificationCenter.class);\n    pico.addSingleton(DefaultNotificationManager.class);\n\n    // Tests\n    pico.addSingleton(CoverageService.class);\n    pico.addSingleton(CoverageWs.class);\n    pico.addSingleton(CoverageShowAction.class);\n    pico.addSingleton(TestsWs.class);\n    pico.addSingleton(TestsTestCasesAction.class);\n    pico.addSingleton(TestsCoveredFilesAction.class);\n    pico.addSingleton(TestsShowAction.class);\n\n    // Properties\n    pico.addSingleton(PropertiesWs.class);\n\n    // graphs and perspective related classes\n    pico.addSingleton(TestablePerspectiveLoader.class);\n    pico.addSingleton(TestPlanPerspectiveLoader.class);\n    pico.addSingleton(SnapshotPerspectives.class);\n\n    // Type validation\n    pico.addSingleton(TypeValidations.class);\n    pico.addSingleton(IntegerTypeValidation.class);\n    pico.addSingleton(FloatTypeValidation.class);\n    pico.addSingleton(BooleanTypeValidation.class);\n    pico.addSingleton(TextTypeValidation.class);\n    pico.addSingleton(StringTypeValidation.class);\n    pico.addSingleton(StringListTypeValidation.class);\n\n    // Design\n    pico.addSingleton(FileDesignWidget.class);\n\n    // Compute engine\n    pico.addSingleton(AnalysisReportQueue.class);\n    pico.addSingleton(ComputationThreadLauncher.class);\n    pico.addSingleton(ComputationWebService.class);\n    pico.addSingleton(IsQueueEmptyWebService.class);\n    pico.addSingleton(QueueWsAction.class);\n    pico.addSingleton(HistoryWsAction.class);\n    pico.addSingleton(DefaultPeriodCleaner.class);\n    pico.addSingleton(DefaultPurgeTask.class);\n    pico.addSingleton(ProjectCleaner.class);\n    pico.addSingleton(ProjectSettingsFactory.class);\n    pico.addSingleton(IndexPurgeListener.class);\n\n    for (Object components : level4AddedComponents) {\n      pico.addSingleton(components);\n    }\n\n    ServerExtensionInstaller extensionInstaller = pico.getComponentByType(ServerExtensionInstaller.class);\n    extensionInstaller.installExtensions(pico);\n\n    pico.startComponents();\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"show\")\n      .setDescription(\"Get detailed information about a rule\")\n      .setSince(\"4.2\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_KEY)\n      .setDescription(\"Rule key\")\n      .setRequired(true)\n      .setExampleValue(\"javascript:EmptyBlock\");\n\n    action\n      .createParam(PARAM_ACTIVES)\n      .setDescription(\"Show rule's activations for all profiles (\\\"active rules\\\")\")\n      .setBooleanPossibleValues()\n      .setDefaultValue(false);\n  }","id":14237,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"show\")\n      .setDescription(\"Get detailed information about a rule\")\n      .setSince(\"4.2\")\n      .setResponseExample(Resources.getResource(getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action\n      .createParam(PARAM_KEY)\n      .setDescription(\"Rule key\")\n      .setRequired(true)\n      .setExampleValue(\"javascript:EmptyBlock\");\n\n    action\n      .createParam(PARAM_ACTIVES)\n      .setDescription(\"Show rule's activations for all profiles (\\\"active rules\\\")\")\n      .setBooleanPossibleValues()\n      .setDefaultValue(false);\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    NewAction action = controller\n      .createAction(\"tags\")\n      .setDescription(\"List rule tags\")\n      .setSince(\"4.4\")\n      .setHandler(this)\n      .setResponseExample(Resources.getResource(getClass(), \"example-tags.json\"));\n\n    action.createParam(\"q\")\n      .setDescription(\"A pattern to match tags against\")\n      .setExampleValue(\"misra\");\n    action.createParam(\"ps\")\n      .setDescription(\"The size of the list to return, 0 for all tags\")\n      .setExampleValue(\"25\")\n      .setDefaultValue(\"0\");\n  }","id":14238,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    NewAction action = controller\n      .createAction(\"tags\")\n      .setDescription(\"List rule tags\")\n      .setSince(\"4.4\")\n      .setHandler(this)\n      .setResponseExample(Resources.getResource(getClass(), \"example-tags.json\"));\n\n    action.createParam(\"q\")\n      .setDescription(\"A pattern to match tags against\")\n      .setExampleValue(\"misra\");\n    action.createParam(\"ps\")\n      .setDescription(\"The size of the list to return, 0 for all tags\")\n      .setExampleValue(\"25\")\n      .setDefaultValue(\"0\");\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"update\")\n      .setPost(true)\n      .setDescription(\"Update an existing rule\")\n      .setSince(\"4.4\")\n      .setHandler(this);\n\n    action.createParam(PARAM_KEY)\n      .setRequired(true)\n      .setDescription(\"Key of the rule to update\")\n      .setExampleValue(\"javascript:NullCheck\");\n\n    action.createParam(PARAM_TAGS)\n      .setDescription(\"Optional comma-separated list of tags to set. Use blank value to remove current tags. Tags \" +\n        \"are not changed if the parameter is not set.\")\n      .setExampleValue(\"java8,security\");\n\n    action.createParam(PARAM_MARKDOWN_NOTE)\n      .setDescription(\"Optional note in markdown format. Use empty value to remove current note. Note is not changed\" +\n        \"if the parameter is not set.\")\n      .setExampleValue(\"my *note*\");\n\n    action.createParam(PARAM_DEBT_SUB_CHARACTERISTIC)\n      .setDescription(\"Optional key of the debt sub-characteristic. Use empty value to unset (-> none) or '\" +\n        RuleUpdate.DEFAULT_DEBT_CHARACTERISTIC + \"' to revert to default sub-characteristic.\")\n      .setExampleValue(\"FAULT_TOLERANCE\");\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FN_TYPE)\n      .setPossibleValues(DebtRemediationFunction.Type.values());\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FN_OFFSET)\n      .setExampleValue(\"1d\");\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FY_COEFF)\n      .setExampleValue(\"3min\");\n\n    action\n      .createParam(PARAM_NAME)\n      .setDescription(\"Rule name (mandatory for custom rule and manual rule)\")\n      .setExampleValue(\"My custom rule\");\n\n    action\n      .createParam(PARAM_DESCRIPTION)\n      .setDescription(\"Rule description (mandatory for custom rule and manual rule)\")\n      .setExampleValue(\"Description of my custom rule\");\n\n    action\n      .createParam(PARAM_SEVERITY)\n      .setDescription(\"Rule severity (Only when updating a custom rule)\")\n      .setPossibleValues(Severity.ALL);\n\n    action\n      .createParam(PARAM_STATUS)\n      .setDescription(\"Rule status (Only when updating a custom rule)\")\n      .setPossibleValues(RuleStatus.values());\n\n    action.createParam(PARAMS)\n      .setDescription(\"Parameters as semi-colon list of <key>=<value>, for example 'params=key1=v1;key2=v2' (Only when updating a custom rule)\");\n  }","id":14239,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller\n      .createAction(\"update\")\n      .setPost(true)\n      .setDescription(\"Update an existing rule\")\n      .setSince(\"4.4\")\n      .setHandler(this);\n\n    action.createParam(PARAM_KEY)\n      .setRequired(true)\n      .setDescription(\"Key of the rule to update\")\n      .setExampleValue(\"javascript:NullCheck\");\n\n    action.createParam(PARAM_TAGS)\n      .setDescription(\"Optional comma-separated list of tags to set. Use blank value to remove current tags. Tags \" +\n        \"are not changed if the parameter is not set.\")\n      .setExampleValue(\"java8,security\");\n\n    action.createParam(PARAM_MARKDOWN_NOTE)\n      .setDescription(\"Optional note in markdown format. Use empty value to remove current note. Note is not changed\" +\n        \"if the parameter is not set.\")\n      .setExampleValue(\"my *note*\");\n\n    action.createParam(PARAM_DEBT_SUB_CHARACTERISTIC)\n      .setDescription(\"Optional key of the debt sub-characteristic. Use empty value to unset (-> none) or '\" +\n        RuleUpdate.DEFAULT_DEBT_CHARACTERISTIC + \"' to revert to default sub-characteristic.\")\n      .setExampleValue(\"FAULT_TOLERANCE\");\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FN_TYPE)\n      .setPossibleValues(DebtRemediationFunction.Type.values());\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FN_OFFSET)\n      .setExampleValue(\"1d\");\n\n    action.createParam(PARAM_DEBT_REMEDIATION_FY_COEFF)\n      .setExampleValue(\"3min\");\n\n    action\n      .createParam(PARAM_NAME)\n      .setDescription(\"Rule name (mandatory for custom rule and manual rule)\")\n      .setExampleValue(\"My custom rule\");\n\n    action\n      .createParam(PARAM_DESCRIPTION)\n      .setDescription(\"Rule description (mandatory for custom rule and manual rule)\")\n      .setExampleValue(\"Description of my custom rule\");\n\n    action\n      .createParam(PARAM_SEVERITY)\n      .setDescription(\"Rule severity (Only when updating a custom rule)\")\n      .setPossibleValues(Severity.ALL);\n\n    action\n      .createParam(PARAM_STATUS)\n      .setDescription(\"Rule status (Only when updating a custom rule)\")\n      .setPossibleValues(RuleStatus.values());\n\n    action.createParam(PARAMS)\n      .setDescription(\"Parameters as semi-colon list of <key>=<value>, for example 'params=key1=v1;key2=v2' (Only when updating a custom rule)\");\n  }","commit_id":"0d24e1857064b3346461d77e7b53824c77cc7681","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    controller.createAction(\"app\")\n      .setInternal(true)\n      .setDescription(\"Get initialization items for the admin UI. For internal use\")\n      .setSince(\"4.3\")\n      .setHandler(this);\n  }","id":14240,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    controller.createAction(\"app\")\n      .setInternal(true)\n      .setDescription(\"Get initialization items for the admin UI. For internal use\")\n      .setSince(\"4.3\")\n      .setHandler(this);\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"copy\")\n      .setDescription(\"Copy a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"The ID of the source quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"The name of the quality gate to create\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","id":14241,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"copy\")\n      .setDescription(\"Copy a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"The ID of the source quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"The name of the quality gate to create\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"create\")\n      .setDescription(\"Create a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"The name of the quality gate to create\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","id":14242,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"create\")\n      .setDescription(\"Create a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"The name of the quality gate to create\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"create_condition\")\n      .setDescription(\"Add a new condition to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"ID of the quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    QGatesWs.addConditionParams(createCondition);\n  }","id":14243,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"create_condition\")\n      .setDescription(\"Add a new condition to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"ID of the quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    QGatesWs.addConditionParams(createCondition);\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"delete_condition\")\n      .setDescription(\"Delete a condition from a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_ID)\n      .setRequired(true)\n      .setDescription(\"Condition ID\")\n      .setExampleValue(\"2\");\n  }","id":14244,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"delete_condition\")\n      .setDescription(\"Delete a condition from a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_ID)\n      .setRequired(true)\n      .setDescription(\"Condition ID\")\n      .setExampleValue(\"2\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"deselect\")\n      .setDescription(\"Remove the association of a project from a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_PROJECT_ID)\n      .setDescription(\"Project ID\")\n      .setRequired(true)\n      .setExampleValue(\"12\");\n  }","id":14245,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"deselect\")\n      .setDescription(\"Remove the association of a project from a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_PROJECT_ID)\n      .setDescription(\"Project ID\")\n      .setRequired(true)\n      .setExampleValue(\"12\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"destroy\")\n      .setDescription(\"Delete a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to delete\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","id":14246,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"destroy\")\n      .setDescription(\"Delete a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to delete\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    controller.createAction(\"list\")\n      .setDescription(\"Get a list of quality gates\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-list.json\"))\n      .setHandler(this);\n  }","id":14247,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    controller.createAction(\"list\")\n      .setDescription(\"Get a list of quality gates\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-list.json\"))\n      .setHandler(this);\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"rename\")\n      .setDescription(\"Rename a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to rename\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"New name of the quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","id":14248,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"rename\")\n      .setDescription(\"Rename a Quality Gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to rename\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"New name of the quality gate\")\n      .setRequired(true)\n      .setExampleValue(\"My Quality Gate\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"search\")\n      .setDescription(\"Search for projects associated (or not) to a quality gate\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-search.json\"))\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_QUERY)\n      .setDescription(\"To search for projects containing this string. If this parameter is set, \\\"selected\\\" is set to \\\"all\\\".\")\n      .setExampleValue(\"abc\");\n\n    action.createParam(QGatesWs.PARAM_SELECTED)\n      .setDescription(\"If \\\"selected\\\", search for projects associated to the quality gate\")\n      .setDefaultValue(ProjectQgateAssociationQuery.IN)\n      .setPossibleValues(ProjectQgateAssociationQuery.AVAILABLE_MEMBERSHIP)\n      .setExampleValue(ProjectQgateAssociationQuery.OUT);\n\n    action.createParam(QGatesWs.PARAM_PAGE)\n      .setDescription(\"Page number\")\n      .setDefaultValue(\"1\")\n      .setExampleValue(\"2\");\n\n    action.createParam(QGatesWs.PARAM_PAGE_SIZE)\n      .setDescription(\"Page size\")\n      .setExampleValue(\"10\");\n  }","id":14249,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"search\")\n      .setDescription(\"Search for projects associated (or not) to a quality gate\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-search.json\"))\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_QUERY)\n      .setDescription(\"To search for projects containing this string. If this parameter is set, \\\"selected\\\" is set to \\\"all\\\".\")\n      .setExampleValue(\"abc\");\n\n    action.createParam(QGatesWs.PARAM_SELECTED)\n      .setDescription(\"If \\\"selected\\\", search for projects associated to the quality gate\")\n      .setDefaultValue(ProjectQgateAssociationQuery.IN)\n      .setPossibleValues(ProjectQgateAssociationQuery.AVAILABLE_MEMBERSHIP)\n      .setExampleValue(ProjectQgateAssociationQuery.OUT);\n\n    action.createParam(QGatesWs.PARAM_PAGE)\n      .setDescription(\"Page number\")\n      .setDefaultValue(\"1\")\n      .setExampleValue(\"2\");\n\n    action.createParam(QGatesWs.PARAM_PAGE_SIZE)\n      .setDescription(\"Page size\")\n      .setExampleValue(\"10\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"select\")\n      .setDescription(\"Associate a project to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_PROJECT_ID)\n      .setDescription(\"Project ID\")\n      .setRequired(true)\n      .setExampleValue(\"12\");\n  }","id":14250,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"select\")\n      .setDescription(\"Associate a project to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_GATE_ID)\n      .setDescription(\"Quality Gate ID\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_PROJECT_ID)\n      .setDescription(\"Project ID\")\n      .setRequired(true)\n      .setExampleValue(\"12\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"set_as_default\")\n      .setDescription(\"Set a quality gate as the default quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to set as default\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","id":14251,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"set_as_default\")\n      .setDescription(\"Set a quality gate as the default quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to set as default\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"show\")\n      .setDescription(\"Display the details of a quality gate\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate. Either id or name must be set\")\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"Name of the quality gate. Either id or name must be set\")\n      .setExampleValue(\"My Quality Gate\");\n  }","id":14252,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"show\")\n      .setDescription(\"Display the details of a quality gate\")\n      .setSince(\"4.3\")\n      .setResponseExample(Resources.getResource(this.getClass(), \"example-show.json\"))\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate. Either id or name must be set\")\n      .setExampleValue(\"1\");\n\n    action.createParam(QGatesWs.PARAM_NAME)\n      .setDescription(\"Name of the quality gate. Either id or name must be set\")\n      .setExampleValue(\"My Quality Gate\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"unset_default\")\n      .setDescription(\"Unset a quality gate as the default quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to unset as default\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","id":14253,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction action = controller.createAction(\"unset_default\")\n      .setDescription(\"Unset a quality gate as the default quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setSince(\"4.3\")\n      .setPost(true)\n      .setHandler(this);\n\n    action.createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"ID of the quality gate to unset as default\")\n      .setRequired(true)\n      .setExampleValue(\"1\");\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"update_condition\")\n      .setDescription(\"Update a condition attached to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"Condition ID\")\n      .setRequired(true)\n      .setExampleValue(\"10\");\n\n    QGatesWs.addConditionParams(createCondition);\n  }","id":14254,"modified_method":"@Override\n  public void define(WebService.NewController controller) {\n    WebService.NewAction createCondition = controller.createAction(\"update_condition\")\n      .setDescription(\"Update a condition attached to a quality gate. Require Administer Quality Profiles and Gates permission\")\n      .setPost(true)\n      .setSince(\"4.3\")\n      .setHandler(this);\n\n    createCondition\n      .createParam(QGatesWs.PARAM_ID)\n      .setDescription(\"Condition ID\")\n      .setRequired(true)\n      .setExampleValue(\"10\");\n\n    QGatesWs.addConditionParams(createCondition);\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n  public void define(Context context) {\n    NewController controller = context.createController(\"api/qualitygates\")\n      .setSince(\"4.3\")\n      .setDescription(\"This service manages quality gates, including conditions and project association\");\n\n    listAction.define(controller);\n    showAction.define(controller);\n    searchAction.define(controller);\n\n    createAction.define(controller);\n    renameAction.define(controller);\n    copyAction.define(controller);\n    destroyAction.define(controller);\n    setAsDefaultAction.define(controller);\n    unsetAction.define(controller);\n\n    createConditionAction.define(controller);\n    updateConditionAction.define(controller);\n    deleteConditionAction.define(controller);\n\n    selectAction.define(controller);\n    deselectAction.define(controller);\n\n    appAction.define(controller);\n\n    controller.done();\n  }","id":14255,"modified_method":"@Override\n  public void define(Context context) {\n    NewController controller = context.createController(\"api/qualitygates\")\n      .setSince(\"4.3\")\n      .setDescription(\"This service manages quality gates, including conditions and project association\");\n\n    for (BaseQGateWsAction action : actions) {\n      action.define(controller);\n    }\n\n    controller.done();\n  }","commit_id":"37b5e0d4790dada05da80884689ebbbea9eb0794","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = gt.getType().isDerivedFrom(classNodeType.getType());\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match && classNodeType.getType().isDerivedFrom(gt.getType());\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","id":14256,"modified_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = (gt.getType().isDerivedFrom(classNodeType.getType())\n                                                || gt.getType().implementsInterface(classNodeType.getType()));\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match &&\n                                                        (classNodeType.getType().isDerivedFrom(gt.getType())\n                                                         || classNodeType.getType().implementsInterface(gt.getType()));\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","commit_id":"508787cff1329da13c49adc71fad9f11531109aa","url":"https://github.com/apache/groovy"},{"original_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum]);\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","id":14257,"modified_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    GenericsType[] argumentGenericTypes = arguments[argNum].getGenericsTypes();\n                    ClassNode actualType = argumentGenericTypes!=null?getWrapper(argumentGenericTypes[0].getType()):nodeType;\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","commit_id":"508787cff1329da13c49adc71fad9f11531109aa","url":"https://github.com/apache/groovy"},{"original_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = gt.getType().isDerivedFrom(classNodeType.getType());\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match && classNodeType.getType().isDerivedFrom(gt.getType());\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","id":14258,"modified_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = (gt.getType().isDerivedFrom(classNodeType.getType())\n                                                || gt.getType().implementsInterface(classNodeType.getType()));\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match &&\n                                                        (classNodeType.getType().isDerivedFrom(gt.getType())\n                                                         || classNodeType.getType().implementsInterface(gt.getType()));\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","commit_id":"4559107396fcd34adb15d08fa6093e02bca5ece4","url":"https://github.com/apache/groovy"},{"original_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum]);\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","id":14259,"modified_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    GenericsType[] argumentGenericTypes = arguments[argNum].getGenericsTypes();\n                    ClassNode actualType = argumentGenericTypes!=null?getWrapper(argumentGenericTypes[0].getType()):nodeType;\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","commit_id":"4559107396fcd34adb15d08fa6093e02bca5ece4","url":"https://github.com/apache/groovy"},{"original_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = gt.getType().isDerivedFrom(classNodeType.getType());\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match && classNodeType.getType().isDerivedFrom(gt.getType());\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","id":14260,"modified_method":"/**\n         * Given a parameterized type (List&lt;String&gt; for example), checks that its\n         * generic types are compatible with those from a bound.\n         * @param classNode the classnode from which we will compare generics types\n         * @param bound the bound to which the types will be compared\n         * @return true if generics are compatible\n         */\n        private boolean compareGenericsWithBound(final ClassNode classNode, final ClassNode bound) {\n            if (classNode==null) return false;\n            if (!bound.isUsingGenerics()) {\n                // if the bound is not using generics, there's nothing to compare with\n                return true;\n            }\n            if (!classNode.equals(bound)) {\n                 // the class nodes are on different types\n                // in this situation, we must choose the correct execution path : either the bound\n                // is an interface and we must find the implementing interface from the classnode\n                // to compare their parameterized generics, or the bound is a regular class and we\n                // must compare the bound with a superclass\n                if (bound.isInterface()) {\n                    Set<ClassNode> interfaces = classNode.getAllInterfaces();\n                    // iterate over all interfaces to check if any corresponds to the bound we are\n                    // comparing to\n                    for (ClassNode anInterface : interfaces) {\n                        if (anInterface.equals(bound)) {\n                            // when we obtain an interface, the types represented by the interface\n                            // class node are not parameterized. This means that we must create a\n                            // new class node with the parameterized types that the current class node\n                            // has defined.\n                            ClassNode node = GenericsUtils.parameterizeInterfaceGenerics(classNode, anInterface);\n                            return compareGenericsWithBound(node, bound);\n                        }\n                    }\n                }\n                return compareGenericsWithBound(classNode.getUnresolvedSuperClass(), bound);\n            }\n            GenericsType[] cnTypes = classNode.getGenericsTypes();\n            if (cnTypes==null && classNode.isRedirectNode()) cnTypes=classNode.redirect().getGenericsTypes();\n            if (cnTypes==null) {\n                // may happen if generic type is Foo<T extends Foo> and classnode is Foo -> Foo\n                return true;\n            }\n            GenericsType[] redirectBoundGenericTypes = bound.redirect().getGenericsTypes();\n            Map<String, GenericsType> classNodePlaceholders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(classNode);\n            Map<String, GenericsType> boundPlaceHolders = org.codehaus.groovy.ast.tools.GenericsUtils.extractPlaceholders(bound);\n            boolean match = true;\n            for (int i = 0; i < redirectBoundGenericTypes.length && match; i++) {\n                GenericsType redirectBoundType = redirectBoundGenericTypes[i];\n                GenericsType classNodeType = cnTypes[i];\n                if (classNodeType.isWildcard()) {\n                    for (ClassNode node : classNodeType.getUpperBounds()) {\n                        match = compareGenericsWithBound(node, bound);\n                        if (!match) return false;\n                    }\n                } else if (classNodeType.isPlaceholder()) {\n                    if (redirectBoundType.isPlaceholder()) {\n                        match = classNodeType.getName().equals(redirectBoundType.getName());\n                    } else {\n                        String name = classNodeType.getName();\n                        if (classNodePlaceholders.containsKey(name)) classNodeType=classNodePlaceholders.get(name);\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                } else {\n                    if (redirectBoundType.isPlaceholder()) {\n                        if (classNodeType.isPlaceholder()) {\n                            match = classNodeType.getName().equals(redirectBoundType.getName());\n                        } else {\n                            String name = redirectBoundType.getName();\n                            if (boundPlaceHolders.containsKey(name)) {\n                                redirectBoundType = boundPlaceHolders.get(name);\n                                boolean wildcard = redirectBoundType.isWildcard();\n                                boolean placeholder = redirectBoundType.isPlaceholder();\n                                if (placeholder || wildcard) {\n                                    // placeholder aliases, like Map<U,V> -> Map<K,V>\n//                                    redirectBoundType = classNodePlaceholders.get(name);\n                                    if (wildcard) {\n                                        // ex: Comparable<Integer> <=> Comparable<? super T>\n                                        if (redirectBoundType.lowerBound!=null) {\n                                            GenericsType gt = new GenericsType(redirectBoundType.lowerBound);\n                                            if (gt.isPlaceholder()) {\n                                                // check for recursive generic typedef, like in\n                                                // <T extends Comparable<? super T>>\n                                                if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                    gt = classNodePlaceholders.get(gt.getName());\n                                                }\n                                            }\n                                            match = (gt.getType().isDerivedFrom(classNodeType.getType())\n                                                || gt.getType().implementsInterface(classNodeType.getType()));\n                                        }\n                                        if (match && redirectBoundType.upperBounds!=null) {\n                                            for (ClassNode upperBound : redirectBoundType.upperBounds) {\n                                                GenericsType gt = new GenericsType(upperBound);\n                                                if (gt.isPlaceholder()) {\n                                                    // check for recursive generic typedef, like in\n                                                    // <T extends Comparable<? super T>>\n                                                    if (classNodePlaceholders.containsKey(gt.getName())) {\n                                                        gt = classNodePlaceholders.get(gt.getName());\n                                                    }\n                                                }\n                                                match = match &&\n                                                        (classNodeType.getType().isDerivedFrom(gt.getType())\n                                                         || classNodeType.getType().implementsInterface(gt.getType()));\n                                            }\n                                        }\n                                        return match;\n                                    } else {\n                                        redirectBoundType = classNodePlaceholders.get(name);\n                                    }\n\n                                }\n                            }\n                            match = redirectBoundType.isCompatibleWith(classNodeType.getType());\n                        }\n                    } else {\n                        match = classNodeType.isCompatibleWith(redirectBoundType.getType());\n                    }\n                }\n            }\n            if (!match) return false;\n            return true;\n        }","commit_id":"6d7abfc0176993ff10b2932dd88b9cbb407ea50e","url":"https://github.com/apache/groovy"},{"original_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum]);\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","id":14261,"modified_method":"private void typeCheckMethodsWithGenerics(ClassNode receiver, ClassNode[] arguments, MethodNode candidateMethod, Expression location) {\n        if (!isUsingGenericsOrIsArrayUsingGenerics(receiver)) return;\n        boolean failure=false;\n        GenericsType[] methodGenericTypes = null;\n        ClassNode methodNodeReceiver = candidateMethod.getDeclaringClass();\n        if (!implementsInterfaceOrIsSubclassOf(receiver, methodNodeReceiver) || !isUsingGenericsOrIsArrayUsingGenerics(methodNodeReceiver))\n            return;\n        // both candidate method and receiver have generic information so a check is possible\n        Parameter[] parameters = candidateMethod.getParameters();\n        int argNum = 0;\n        for (Parameter parameter : parameters) {\n            ClassNode type = parameter.getType();\n            if (type.isUsingGenerics()) {\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                type.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    GenericsType[] argumentGenericTypes = arguments[argNum].getGenericsTypes();\n                    ClassNode actualType = argumentGenericTypes!=null?getWrapper(argumentGenericTypes[0].getType()):nodeType;\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            } else if (type.isArray() && type.getComponentType().isUsingGenerics()) {\n                ClassNode componentType = type.getComponentType();\n                methodGenericTypes =\n                        GenericsUtils.alignGenericTypes(\n                                receiver.redirect().getGenericsTypes(),\n                                receiver.getGenericsTypes(),\n                                componentType.getGenericsTypes());\n                if (methodGenericTypes.length == 1) {\n                    ClassNode nodeType = getWrapper(methodGenericTypes[0].getType());\n                    ClassNode actualType = getWrapper(arguments[argNum].getComponentType());\n                    if (!implementsInterfaceOrIsSubclassOf(actualType, nodeType)) {\n                        failure = true;\n                        // for proper error message\n                        GenericsType baseGT = methodGenericTypes[0];\n                        methodGenericTypes[0] = new GenericsType(baseGT.getType(), baseGT.getUpperBounds(), baseGT.getLowerBound());\n                        methodGenericTypes[0].setType(methodGenericTypes[0].getType().makeArray());\n                    }\n                } else {\n                    // not sure this is possible !\n                }\n            }\n            argNum++;\n        }\n        if (failure) {\n            ClassNode[] parameterTypes = new ClassNode[methodGenericTypes.length];\n            for (int i = 0; i < methodGenericTypes.length; i++) {\n                parameterTypes[i] = methodGenericTypes[i].getType();\n            }\n            addStaticTypeError(\"Cannot call \" + receiver.getName() + \"#\" +\n                    toMethodParametersString(candidateMethod.getName(), parameterTypes) +\n                    \" with arguments \" + formatArgumentList(arguments), location);\n        }\n    }","commit_id":"6d7abfc0176993ff10b2932dd88b9cbb407ea50e","url":"https://github.com/apache/groovy"},{"original_method":"@Override\n  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(\n      RefreshSuperUserGroupsConfigurationRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshSuperUserGroupsConfiguration\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh super-user-groups.\");\n      throwStandbyException();\n    }\n\n    // Accept hadoop common configs in core-site.xml as well as RM specific\n    // configurations in yarn-site.xml\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE,\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    RMServerUtils.processRMProxyUsersConf(conf);\n    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);\n    RMAuditLogger.logSuccess(user.getShortUserName(),\n        argName, \"AdminService\");\n    \n    return recordFactory.newRecordInstance(\n        RefreshSuperUserGroupsConfigurationResponse.class);\n  }","id":14262,"modified_method":"@Override\n  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(\n      RefreshSuperUserGroupsConfigurationRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshSuperUserGroupsConfiguration\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, \"refresh super-user-groups.\");\n\n    // Accept hadoop common configs in core-site.xml as well as RM specific\n    // configurations in yarn-site.xml\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE,\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    RMServerUtils.processRMProxyUsersConf(conf);\n    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);\n    RMAuditLogger.logSuccess(user.getShortUserName(),\n        argName, \"AdminService\");\n    \n    return recordFactory.newRecordInstance(\n        RefreshSuperUserGroupsConfigurationResponse.class);\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState && !isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh user-groups.\");\n      throwStandbyException();\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    adminAcl = new AccessControlList(conf.get(\n        YarnConfiguration.YARN_ADMIN_ACL,\n        YarnConfiguration.DEFAULT_YARN_ADMIN_ACL));\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }","id":14263,"modified_method":"private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), argName, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    adminAcl = new AccessControlList(conf.get(\n        YarnConfiguration.YARN_ADMIN_ACL,\n        YarnConfiguration.DEFAULT_YARN_ADMIN_ACL));\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshNodes\";\n    UserGroupInformation user = checkAcls(\"refreshNodes\");\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh nodes.\");\n      throwStandbyException();\n    }\n\n    try {\n      Configuration conf =\n          getConfiguration(new Configuration(false),\n              YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n      rmContext.getNodesListManager().refreshNodes(conf);\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return recordFactory.newRecordInstance(RefreshNodesResponse.class);\n    } catch (IOException ioe) {\n      LOG.info(\"Exception refreshing nodes \", ioe);\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\", \"Exception refreshing nodes\");\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }","id":14264,"modified_method":"@Override\n  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshNodes\";\n    final String msg = \"refresh nodes.\";\n    UserGroupInformation user = checkAcls(\"refreshNodes\");\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    try {\n      Configuration conf =\n          getConfiguration(new Configuration(false),\n              YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n      rmContext.getNodesListManager().refreshNodes(conf);\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return recordFactory.newRecordInstance(RefreshNodesResponse.class);\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public RefreshServiceAclsResponse refreshServiceAcls(\n      RefreshServiceAclsRequest request) throws YarnException, IOException {\n    if (!getConfig().getBoolean(\n             CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, \n             false)) {\n      throw RPCUtil.getRemoteException(\n          new IOException(\"Service Authorization (\" + \n              CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION + \n              \") not enabled.\"));\n    }\n\n    String argName = \"refreshServiceAcls\";\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(UserGroupInformation.getCurrentUser()\n          .getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh Service ACLs.\");\n      throwStandbyException();\n    }\n\n    PolicyProvider policyProvider = RMPolicyProvider.getInstance();\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.HADOOP_POLICY_CONFIGURATION_FILE);\n\n    refreshServiceAcls(conf, policyProvider);\n    rmContext.getClientRMService().refreshServiceAcls(conf, policyProvider);\n    rmContext.getApplicationMasterService().refreshServiceAcls(\n        conf, policyProvider);\n    rmContext.getResourceTrackerService().refreshServiceAcls(\n        conf, policyProvider);\n    \n    return recordFactory.newRecordInstance(RefreshServiceAclsResponse.class);\n  }","id":14265,"modified_method":"@Override\n  public RefreshServiceAclsResponse refreshServiceAcls(\n      RefreshServiceAclsRequest request) throws YarnException, IOException {\n    if (!getConfig().getBoolean(\n             CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, \n             false)) {\n      throw RPCUtil.getRemoteException(\n          new IOException(\"Service Authorization (\" + \n              CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION + \n              \") not enabled.\"));\n    }\n\n    String argName = \"refreshServiceAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, \"refresh Service ACLs.\");\n\n    PolicyProvider policyProvider = RMPolicyProvider.getInstance();\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.HADOOP_POLICY_CONFIGURATION_FILE);\n\n    refreshServiceAcls(conf, policyProvider);\n    rmContext.getClientRMService().refreshServiceAcls(conf, policyProvider);\n    rmContext.getApplicationMasterService().refreshServiceAcls(\n        conf, policyProvider);\n    rmContext.getResourceTrackerService().refreshServiceAcls(\n        conf, policyProvider);\n    \n    return recordFactory.newRecordInstance(RefreshServiceAclsResponse.class);\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@SuppressWarnings(\"unchecked\")\n  @Override\n  public UpdateNodeResourceResponse updateNodeResource(\n      UpdateNodeResourceRequest request) throws YarnException, IOException {\n    String argName = \"updateNodeResource\";\n    UserGroupInformation user = checkAcls(argName);\n    \n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not update node resource.\");\n      throwStandbyException();\n    }\n    \n    Map<NodeId, ResourceOption> nodeResourceMap = request.getNodeResourceMap();\n    Set<NodeId> nodeIds = nodeResourceMap.keySet();\n    // verify nodes are all valid first. \n    // if any invalid nodes, throw exception instead of partially updating\n    // valid nodes.\n    for (NodeId nodeId : nodeIds) {\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node == null) {\n        LOG.error(\"Resource update get failed on all nodes due to change \"\n            + \"resource on an unrecognized node: \" + nodeId);\n        throw RPCUtil.getRemoteException(\n            \"Resource update get failed on all nodes due to change resource \"\n                + \"on an unrecognized node: \" + nodeId);\n      }\n    }\n    \n    // do resource update on each node.\n    // Notice: it is still possible to have invalid NodeIDs as nodes decommission\n    // may happen just at the same time. This time, only log and skip absent\n    // nodes without throwing any exceptions.\n    boolean allSuccess = true;\n    for (Map.Entry<NodeId, ResourceOption> entry : nodeResourceMap.entrySet()) {\n      ResourceOption newResourceOption = entry.getValue();\n      NodeId nodeId = entry.getKey();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      \n      if (node == null) {\n        LOG.warn(\"Resource update get failed on an unrecognized node: \" + nodeId);\n        allSuccess = false;\n      } else {\n        // update resource to RMNode\n        this.rmContext.getDispatcher().getEventHandler()\n          .handle(new RMNodeResourceUpdateEvent(nodeId, newResourceOption));\n        LOG.info(\"Update resource on node(\" + node.getNodeID()\n            + \") with resource(\" + newResourceOption.toString() + \")\");\n\n      }\n    }\n    if (allSuccess) {\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n    }\n    UpdateNodeResourceResponse response = \n        UpdateNodeResourceResponse.newInstance();\n    return response;\n  }","id":14266,"modified_method":"@SuppressWarnings(\"unchecked\")\n  @Override\n  public UpdateNodeResourceResponse updateNodeResource(\n      UpdateNodeResourceRequest request) throws YarnException, IOException {\n    String argName = \"updateNodeResource\";\n    UserGroupInformation user = checkAcls(argName);\n    \n    checkRMStatus(user.getShortUserName(), argName, \"update node resource.\");\n    \n    Map<NodeId, ResourceOption> nodeResourceMap = request.getNodeResourceMap();\n    Set<NodeId> nodeIds = nodeResourceMap.keySet();\n    // verify nodes are all valid first. \n    // if any invalid nodes, throw exception instead of partially updating\n    // valid nodes.\n    for (NodeId nodeId : nodeIds) {\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node == null) {\n        LOG.error(\"Resource update get failed on all nodes due to change \"\n            + \"resource on an unrecognized node: \" + nodeId);\n        throw RPCUtil.getRemoteException(\n            \"Resource update get failed on all nodes due to change resource \"\n                + \"on an unrecognized node: \" + nodeId);\n      }\n    }\n    \n    // do resource update on each node.\n    // Notice: it is still possible to have invalid NodeIDs as nodes decommission\n    // may happen just at the same time. This time, only log and skip absent\n    // nodes without throwing any exceptions.\n    boolean allSuccess = true;\n    for (Map.Entry<NodeId, ResourceOption> entry : nodeResourceMap.entrySet()) {\n      ResourceOption newResourceOption = entry.getValue();\n      NodeId nodeId = entry.getKey();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      \n      if (node == null) {\n        LOG.warn(\"Resource update get failed on an unrecognized node: \" + nodeId);\n        allSuccess = false;\n      } else {\n        // update resource to RMNode\n        this.rmContext.getDispatcher().getEventHandler()\n          .handle(new RMNodeResourceUpdateEvent(nodeId, newResourceOption));\n        LOG.info(\"Update resource on node(\" + node.getNodeID()\n            + \") with resource(\" + newResourceOption.toString() + \")\");\n\n      }\n    }\n    if (allSuccess) {\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n    }\n    UpdateNodeResourceResponse response = \n        UpdateNodeResourceResponse.newInstance();\n    return response;\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshQueues\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh queues.\");\n      throwStandbyException();\n    }\n\n    RefreshQueuesResponse response =\n        recordFactory.newRecordInstance(RefreshQueuesResponse.class);\n    try {\n      rmContext.getScheduler().reinitialize(getConfig(), this.rmContext);\n      // refresh the reservation system\n      ReservationSystem rSystem = rmContext.getReservationSystem();\n      if (rSystem != null) {\n        rSystem.reinitialize(getConfig(), rmContext);\n      }\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      LOG.info(\"Exception refreshing queues \", ioe);\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"Exception refreshing queues\");\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }","id":14267,"modified_method":"@Override\n  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshQueues\";\n    final String msg = \"refresh queues.\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    RefreshQueuesResponse response =\n        recordFactory.newRecordInstance(RefreshQueuesResponse.class);\n    try {\n      rmContext.getScheduler().reinitialize(getConfig(), this.rmContext);\n      // refresh the reservation system\n      ReservationSystem rSystem = rmContext.getReservationSystem();\n      if (rSystem != null) {\n        rSystem.reinitialize(getConfig(), rmContext);\n      }\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(\n      RemoveFromClusterNodeLabelsRequest request) throws YarnException, IOException {\n    String argName = \"removeFromClusterNodeLabels\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not remove labels.\");\n      throwStandbyException();\n    }\n\n    RemoveFromClusterNodeLabelsResponse response =\n        recordFactory.newRecordInstance(RemoveFromClusterNodeLabelsResponse.class);\n    try {\n      rmContext.getNodeLabelManager().removeFromClusterNodeLabels(request.getNodeLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      LOG.info(\"Exception remove labels\", ioe);\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\", \"Exception remove label\");\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }","id":14268,"modified_method":"@Override\n  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(\n      RemoveFromClusterNodeLabelsRequest request) throws YarnException, IOException {\n    String argName = \"removeFromClusterNodeLabels\";\n    final String msg = \"remove labels.\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    RemoveFromClusterNodeLabelsResponse response =\n        recordFactory.newRecordInstance(RemoveFromClusterNodeLabelsResponse.class);\n    try {\n      rmContext.getNodeLabelManager().removeFromClusterNodeLabels(request.getNodeLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(\n      RefreshUserToGroupsMappingsRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshUserToGroupsMappings\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not refresh user-groups.\");\n      throwStandbyException();\n    }\n\n    Groups.getUserToGroupsMappingService(\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE)).refresh();\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName, \"AdminService\");\n\n    return recordFactory.newRecordInstance(\n        RefreshUserToGroupsMappingsResponse.class);\n  }","id":14269,"modified_method":"@Override\n  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(\n      RefreshUserToGroupsMappingsRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshUserToGroupsMappings\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, \"refresh user-groups.\");\n\n    Groups.getUserToGroupsMappingService(\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE)).refresh();\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName, \"AdminService\");\n\n    return recordFactory.newRecordInstance(\n        RefreshUserToGroupsMappingsResponse.class);\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(AddToClusterNodeLabelsRequest request)\n      throws YarnException, IOException {\n    String argName = \"addToClusterNodeLabels\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not add labels.\");\n      throwStandbyException();\n    }\n\n    AddToClusterNodeLabelsResponse response =\n        recordFactory.newRecordInstance(AddToClusterNodeLabelsResponse.class);\n    try {\n      rmContext.getNodeLabelManager().addToCluserNodeLabels(request.getNodeLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      LOG.info(\"Exception add labels\", ioe);\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\", \"Exception add label\");\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }","id":14270,"modified_method":"@Override\n  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(AddToClusterNodeLabelsRequest request)\n      throws YarnException, IOException {\n    String argName = \"addToClusterNodeLabels\";\n    final String msg = \"add labels.\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    AddToClusterNodeLabelsResponse response =\n        recordFactory.newRecordInstance(AddToClusterNodeLabelsResponse.class);\n    try {\n      rmContext.getNodeLabelManager().addToCluserNodeLabels(request.getNodeLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(\n      ReplaceLabelsOnNodeRequest request) throws YarnException, IOException {\n    String argName = \"replaceLabelsOnNode\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"ResourceManager is not active. Can not set node to labels.\");\n      throwStandbyException();\n    }\n\n    ReplaceLabelsOnNodeResponse response =\n        recordFactory.newRecordInstance(ReplaceLabelsOnNodeResponse.class);\n    try {\n      rmContext.getNodeLabelManager().replaceLabelsOnNode(\n          request.getNodeToLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      LOG.info(\"Exception set node to labels. \", ioe);\n      RMAuditLogger.logFailure(user.getShortUserName(), argName,\n          adminAcl.toString(), \"AdminService\",\n          \"Exception set node to labels.\");\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }","id":14271,"modified_method":"@Override\n  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(\n      ReplaceLabelsOnNodeRequest request) throws YarnException, IOException {\n    String argName = \"replaceLabelsOnNode\";\n    final String msg = \"set node to labels.\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    ReplaceLabelsOnNodeResponse response =\n        recordFactory.newRecordInstance(ReplaceLabelsOnNodeResponse.class);\n    try {\n      rmContext.getNodeLabelManager().replaceLabelsOnNode(\n          request.getNodeToLabels());\n      RMAuditLogger\n          .logSuccess(user.getShortUserName(), argName, \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }","commit_id":"40ee4bff65b2bfdabfd16ee7d9be3382a0476565","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n        \n        System.setProperty(\"opennms.poller.configuration.resource\", m_fileAnticipator.expecting(\"remote-poller.configuration\").toURL().toString());\n    }","id":14272,"modified_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n\n        String filename = m_fileAnticipator.expecting(\"remote-poller.configuration\").getCanonicalPath();\n        filename = filename.replace(\"+\", \"%2B\");\n        System.setProperty(\"opennms.poller.configuration.resource\", \"file://\" + filename);\n    }","commit_id":"c1599a779174f4c2364a0b84408b1af964d9f7d8","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                final DBUtils dbu = new DBUtils(getClass());\n                try {\n                    rset = ifStmt.executeQuery();\n                    dbu.watch(rs);\n                    if (rset.next()) {\n                        Timestamp lastPolled = rset.getTimestamp(1);\n                        if (lastPolled != null && rset.wasNull() == false) {\n                            if (log().isDebugEnabled())\n                                log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                            NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                            m_knownNodes.add(nodeInfo);\n                        }\n                    } else {\n                        if (log().isDebugEnabled())\n                            log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                    }\n                } finally {\n                    dbu.cleanUp();\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","id":14273,"modified_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                rset = ifStmt.executeQuery();\n                d.watch(rs);\n                if (rset.next()) {\n                    Timestamp lastPolled = rset.getTimestamp(1);\n                    if (lastPolled != null && rset.wasNull() == false) {\n                        if (log().isDebugEnabled())\n                            log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                        NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                        m_knownNodes.add(nodeInfo);\n                    }\n                } else {\n                    if (log().isDebugEnabled())\n                        log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","commit_id":"c1599a779174f4c2364a0b84408b1af964d9f7d8","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n        \n        System.setProperty(\"opennms.poller.configuration.resource\", m_fileAnticipator.expecting(\"remote-poller.configuration\").toURL().toString());\n    }","id":14274,"modified_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n\n        String filename = m_fileAnticipator.expecting(\"remote-poller.configuration\").getCanonicalPath();\n        filename = filename.replace(\"+\", \"%2B\");\n        System.setProperty(\"opennms.poller.configuration.resource\", \"file://\" + filename);\n    }","commit_id":"632b8f21c3cebcca4c788e9100541350fd17c4f7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                final DBUtils dbu = new DBUtils(getClass());\n                try {\n                    rset = ifStmt.executeQuery();\n                    dbu.watch(rs);\n                    if (rset.next()) {\n                        Timestamp lastPolled = rset.getTimestamp(1);\n                        if (lastPolled != null && rset.wasNull() == false) {\n                            if (log().isDebugEnabled())\n                                log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                            NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                            m_knownNodes.add(nodeInfo);\n                        }\n                    } else {\n                        if (log().isDebugEnabled())\n                            log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                    }\n                } finally {\n                    dbu.cleanUp();\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","id":14275,"modified_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                rset = ifStmt.executeQuery();\n                d.watch(rs);\n                if (rset.next()) {\n                    Timestamp lastPolled = rset.getTimestamp(1);\n                    if (lastPolled != null && rset.wasNull() == false) {\n                        if (log().isDebugEnabled())\n                            log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                        NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                        m_knownNodes.add(nodeInfo);\n                    }\n                } else {\n                    if (log().isDebugEnabled())\n                        log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","commit_id":"632b8f21c3cebcca4c788e9100541350fd17c4f7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n        \n        System.setProperty(\"opennms.poller.configuration.resource\", m_fileAnticipator.expecting(\"remote-poller.configuration\").toURL().toString());\n    }","id":14276,"modified_method":"@Override\n    protected void setUpConfiguration() throws IOException {\n        DaoTestConfigBean daoTestConfig = new DaoTestConfigBean();\n        daoTestConfig.afterPropertiesSet();\n        \n        m_fileAnticipator = new FileAnticipator();\n\n        String filename = m_fileAnticipator.expecting(\"remote-poller.configuration\").getCanonicalPath();\n        filename = filename.replace(\"+\", \"%2B\");\n        System.setProperty(\"opennms.poller.configuration.resource\", \"file://\" + filename);\n    }","commit_id":"f3abe1f6509e2785112f14ca61ccd0ebb71761e8","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                final DBUtils dbu = new DBUtils(getClass());\n                try {\n                    rset = ifStmt.executeQuery();\n                    dbu.watch(rs);\n                    if (rset.next()) {\n                        Timestamp lastPolled = rset.getTimestamp(1);\n                        if (lastPolled != null && rset.wasNull() == false) {\n                            if (log().isDebugEnabled())\n                                log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                            NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                            m_knownNodes.add(nodeInfo);\n                        }\n                    } else {\n                        if (log().isDebugEnabled())\n                            log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                    }\n                } finally {\n                    dbu.cleanUp();\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","id":14277,"modified_method":"/**\n     * Builds a list of NodeInfo objects representing each of the nodes in the\n     * database capable of being scheduled for rescan.\n     * \n     * @throws SQLException\n     *             if there is a problem accessing the database.\n     */\n    private void loadKnownNodes() throws SQLException {\n        Connection db = null;\n\n        PreparedStatement nodeStmt = null;\n        PreparedStatement ifStmt = null;\n        ResultSet rs = null;\n        ResultSet rset = null;\n        \n        final DBUtils d = new DBUtils(getClass());\n        try {\n            db = DataSourceFactory.getInstance().getConnection();\n            d.watch(db);\n            // Prepare SQL statements in advance\n            //\n            nodeStmt = db.prepareStatement(SQL_RETRIEVE_NODES);\n            d.watch(nodeStmt);\n            ifStmt = db.prepareStatement(SQL_GET_LAST_POLL_TIME);\n            d.watch(ifStmt);\n\n            // Retrieve non-deleted nodes from the node table in the database\n            //\n            rs = nodeStmt.executeQuery();\n            d.watch(rs);\n\n            while (rs.next()) {\n                // Retrieve an interface from the ipInterface table in\n                // the database for its last polled/scanned time\n\n                int nodeId = rs.getInt(1);\n                ifStmt.setInt(1, nodeId); // set nodeid\n                if (log().isDebugEnabled())\n                    log().debug(\"loadKnownNodes: retrieved nodeid \" + nodeId + \", now getting last poll time.\");\n\n                rset = ifStmt.executeQuery();\n                d.watch(rs);\n                if (rset.next()) {\n                    Timestamp lastPolled = rset.getTimestamp(1);\n                    if (lastPolled != null && rset.wasNull() == false) {\n                        if (log().isDebugEnabled())\n                            log().debug(\"loadKnownNodes: adding node \" + nodeId + \" with last poll time \" + lastPolled);\n                        NodeInfo nodeInfo = new NodeInfo(nodeId, lastPolled, m_interval);\n                        m_knownNodes.add(nodeInfo);\n                    }\n                } else {\n                    if (log().isDebugEnabled())\n                        log().debug(\"Node w/ nodeid \" + nodeId + \" has no managed interfaces from which to retrieve a last poll time...it will not be scheduled.\");\n                }\n            }\n        } finally {\n            d.cleanUp();\n        }\n\n    }","commit_id":"f3abe1f6509e2785112f14ca61ccd0ebb71761e8","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    P newPriority = addPriority( next, currentAggregatedValue,\n                            calculateValue( next ) );\n                    queue.put( next, newPriority );\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                return current;\n            }\n            return null;\n        }","id":14278,"modified_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    if ( !visitedNodes.contains( next.node().getId() ) )\n                    {\n                        P newPriority = addPriority( next, currentAggregatedValue,\n                                calculateValue( next ) );\n                        queue.put( next, newPriority );\n                        System.out.println( \">\" + newPriority + \" \" + next.node().getProperty(\n                                SimpleGraphBuilder.KEY_ID ) );\n                    }\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                visitedNodes.add( current.node().getId() );\n                System.out.println( \"<\" + currentAggregatedValue + \" \" + current.node().getProperty(\n                        SimpleGraphBuilder.KEY_ID ) );\n                return current;\n            }\n            return null;\n        }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.RELATIONSHIP_GLOBAL ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","id":14279,"modified_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.NONE ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Add an entity to the priority map.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     */\n    public void put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        if ( node != null && priority.equals( node.priority ) )\n        {\n            node.head = new Link<E>( entity, node.head );\n        }\n        else\n        {\n            node = new Node<E, P>( entity, priority );\n            map.put( key, node );\n            queue.add( node );\n        }\n    }","id":14280,"modified_method":"/**\n     * Add an entity to the priority map. If the key for the {@code entity}\n     * was already found in the priority map and the priority is the same\n     * the entity will be added. If the priority is lower the existing entities\n     * for that key will be discarded.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     * @return whether or not the entity (with its priority) was added to the\n     * priority map. Will return {@code false} iff the key for the entity\n     * already exist and its priority is better than the given\n     * {@code priority}.\n     */\n    public boolean put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        boolean result = false;\n        if ( node != null )\n        {\n            if ( priority.equals( node.priority ) )\n            {\n                node.head = new Link<E>( entity, node.head );\n                result = true;\n            }\n            else if ( order.compare( priority, node.priority ) < 0 )\n            {\n                queue.remove( node );\n                put( entity, priority, key );\n                result = true;\n            }\n        }\n        else\n        {\n            put( entity, priority, key );\n            result = true;\n        }\n        return result;\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n        }\n        else\n        {\n            node.head = node.head.next;\n        }\n        return new Entry<E, P>( node );\n    }","id":14281,"modified_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        Entry<E, P> result = null;\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n            result = new Entry<E, P>( node );\n        }\n        else\n        {\n            result = new Entry<E, P>( node );\n            node.head = node.head.next;\n        }\n        return result;\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","id":14282,"modified_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            System.out.println( \"no more paths\" );\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        System.out.println( \"found path \" + path );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            System.out.println( \"wrong weight\" );\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","id":14283,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        AStar astar = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        WeightedPath path = astar.findSinglePath( nodeA, nodeC );\n        assertEquals( (Double)5d, (Double)path.weight() );\n        assertPath( path, nodeA, nodeB, nodeC );\n    }","id":14284,"modified_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relAB2 = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        PathFinder<WeightedPath> astar = newFinder();\n        int counter = 0;\n        for ( WeightedPath path : astar.findAllPaths( nodeA, nodeC ) )\n        {\n            assertEquals( (Double)5d, (Double)path.weight() );\n            assertPath( path, nodeA, nodeB, nodeC );\n            counter++;\n        }\n//        assertEquals( 2, counter );\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","id":14285,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","commit_id":"af9f3ab276b77b612485b37a5838ce2f6b7849c3","url":"https://github.com/neo4j/neo4j"},{"original_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    P newPriority = addPriority( next, currentAggregatedValue,\n                            calculateValue( next ) );\n                    queue.put( next, newPriority );\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                return current;\n            }\n            return null;\n        }","id":14286,"modified_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    if ( !visitedNodes.contains( next.node().getId() ) )\n                    {\n                        P newPriority = addPriority( next, currentAggregatedValue,\n                                calculateValue( next ) );\n                        queue.put( next, newPriority );\n                        System.out.println( \">\" + newPriority + \" \" + next.node().getProperty(\n                                SimpleGraphBuilder.KEY_ID ) );\n                    }\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                visitedNodes.add( current.node().getId() );\n                System.out.println( \"<\" + currentAggregatedValue + \" \" + current.node().getProperty(\n                        SimpleGraphBuilder.KEY_ID ) );\n                return current;\n            }\n            return null;\n        }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.RELATIONSHIP_GLOBAL ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","id":14287,"modified_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.NONE ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Add an entity to the priority map.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     */\n    public void put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        if ( node != null && priority.equals( node.priority ) )\n        {\n            node.head = new Link<E>( entity, node.head );\n        }\n        else\n        {\n            node = new Node<E, P>( entity, priority );\n            map.put( key, node );\n            queue.add( node );\n        }\n    }","id":14288,"modified_method":"/**\n     * Add an entity to the priority map. If the key for the {@code entity}\n     * was already found in the priority map and the priority is the same\n     * the entity will be added. If the priority is lower the existing entities\n     * for that key will be discarded.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     * @return whether or not the entity (with its priority) was added to the\n     * priority map. Will return {@code false} iff the key for the entity\n     * already exist and its priority is better than the given\n     * {@code priority}.\n     */\n    public boolean put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        boolean result = false;\n        if ( node != null )\n        {\n            if ( priority.equals( node.priority ) )\n            {\n                node.head = new Link<E>( entity, node.head );\n                result = true;\n            }\n            else if ( order.compare( priority, node.priority ) < 0 )\n            {\n                queue.remove( node );\n                put( entity, priority, key );\n                result = true;\n            }\n        }\n        else\n        {\n            put( entity, priority, key );\n            result = true;\n        }\n        return result;\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n        }\n        else\n        {\n            node.head = node.head.next;\n        }\n        return new Entry<E, P>( node );\n    }","id":14289,"modified_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        Entry<E, P> result = null;\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n            result = new Entry<E, P>( node );\n        }\n        else\n        {\n            result = new Entry<E, P>( node );\n            node.head = node.head.next;\n        }\n        return result;\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","id":14290,"modified_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            System.out.println( \"no more paths\" );\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        System.out.println( \"found path \" + path );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            System.out.println( \"wrong weight\" );\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","id":14291,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        AStar astar = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        WeightedPath path = astar.findSinglePath( nodeA, nodeC );\n        assertEquals( (Double)5d, (Double)path.weight() );\n        assertPath( path, nodeA, nodeB, nodeC );\n    }","id":14292,"modified_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relAB2 = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        PathFinder<WeightedPath> astar = newFinder();\n        int counter = 0;\n        for ( WeightedPath path : astar.findAllPaths( nodeA, nodeC ) )\n        {\n            assertEquals( (Double)5d, (Double)path.weight() );\n            assertPath( path, nodeA, nodeB, nodeC );\n            counter++;\n        }\n//        assertEquals( 2, counter );\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","id":14293,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","commit_id":"cb2e44a57bf98bda2aa1f707a3c27e80f996bd0c","url":"https://github.com/neo4j/neo4j"},{"original_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    P newPriority = addPriority( next, currentAggregatedValue,\n                            calculateValue( next ) );\n                    queue.put( next, newPriority );\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                return current;\n            }\n            return null;\n        }","id":14294,"modified_method":"public ExpansionSource nextPosition()\n        {\n            // Exhaust current if not already exhausted\n            while ( true )\n            {\n                ExpansionSource next = current.next();\n                if ( next != null )\n                {\n                    if ( !visitedNodes.contains( next.node().getId() ) )\n                    {\n                        P newPriority = addPriority( next, currentAggregatedValue,\n                                calculateValue( next ) );\n                        queue.put( next, newPriority );\n                        System.out.println( \">\" + newPriority + \" \" + next.node().getProperty(\n                                SimpleGraphBuilder.KEY_ID ) );\n                    }\n                }\n                else\n                {\n                    break;\n                }\n            }\n            \n            // Pop the top from priorityMap\n            Entry<ExpansionSource, P> entry = queue.pop();\n            if ( entry != null )\n            {\n                current = entry.getEntity();\n                currentAggregatedValue = entry.getPriority();\n                visitedNodes.add( current.node().getId() );\n                System.out.println( \"<\" + currentAggregatedValue + \" \" + current.node().getProperty(\n                        SimpleGraphBuilder.KEY_ID ) );\n                return current;\n            }\n            return null;\n        }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.RELATIONSHIP_GLOBAL ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","id":14295,"modified_method":"public ExperimentalAStar( RelationshipExpander expander, CostEvaluator<Double> costEvaluator,\n            EstimateEvaluator<Double> estimateEvaluator )\n    {\n        this.traversalDescription = TraversalFactory.createTraversalDescription().uniqueness(\n                Uniqueness.NONE ).expand( expander );\n        this.costEvaluator = costEvaluator;\n        this.estimateEvaluator = estimateEvaluator;\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n        }\n        else\n        {\n            node.head = node.head.next;\n        }\n        return new Entry<E, P>( node );\n    }","id":14296,"modified_method":"/**\n     * Remove and return the entry with the highest priority.\n     *\n     * @return the entry with the highest priority.\n     */\n    public Entry<E, P> pop()\n    {\n        Node<E, P> node = queue.peek();\n        Entry<E, P> result = null;\n        if ( node == null )\n        {\n            return null;\n        }\n        else if ( node.head.next == null )\n        {\n            node = queue.poll();\n            map.remove( keyFunction.convert( node.head.entity ) );\n            result = new Entry<E, P>( node );\n        }\n        else\n        {\n            result = new Entry<E, P>( node );\n            node.head = node.head.next;\n        }\n        return result;\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"/**\n     * Add an entity to the priority map.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     */\n    public void put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        if ( node != null && priority.equals( node.priority ) )\n        {\n            node.head = new Link<E>( entity, node.head );\n        }\n        else\n        {\n            node = new Node<E, P>( entity, priority );\n            map.put( key, node );\n            queue.add( node );\n        }\n    }","id":14297,"modified_method":"/**\n     * Add an entity to the priority map. If the key for the {@code entity}\n     * was already found in the priority map and the priority is the same\n     * the entity will be added. If the priority is lower the existing entities\n     * for that key will be discarded.\n     *\n     * @param entity the entity to add.\n     * @param priority the priority of the entity.\n     * @return whether or not the entity (with its priority) was added to the\n     * priority map. Will return {@code false} iff the key for the entity\n     * already exist and its priority is better than the given\n     * {@code priority}.\n     */\n    public boolean put( E entity, P priority )\n    {\n        K key = keyFunction.convert( entity );\n        Node<E, P> node = map.get( key );\n        boolean result = false;\n        if ( node != null )\n        {\n            if ( priority.equals( node.priority ) )\n            {\n                node.head = new Link<E>( entity, node.head );\n                result = true;\n            }\n            else if ( order.compare( priority, node.priority ) < 0 )\n            {\n                queue.remove( node );\n                put( entity, priority, key );\n                result = true;\n            }\n        }\n        else\n        {\n            put( entity, priority, key );\n            result = true;\n        }\n        return result;\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","id":14298,"modified_method":"@Override\n    protected WeightedPath fetchNextOrNull()\n    {\n        if ( !paths.hasNext() )\n        {\n            System.out.println( \"no more paths\" );\n            return null;\n        }\n        WeightedPath path = new WeightedPathImpl( costEvaluator, paths.next() );\n        System.out.println( \"found path \" + path );\n        if ( foundWeight != null && path.weight() > foundWeight )\n        {\n            System.out.println( \"wrong weight\" );\n            return null;\n        }\n        foundWeight = path.weight();\n        return path;\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        AStar astar = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        WeightedPath path = astar.findSinglePath( nodeA, nodeC );\n        assertEquals( (Double)5d, (Double)path.weight() );\n        assertPath( path, nodeA, nodeB, nodeC );\n    }","id":14299,"modified_method":"@Test\n    public void testSimplest()\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Relationship relAB = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relAB2 = graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        Relationship relBC = graph.makeEdge( \"B\", \"C\", \"length\", 3d );\n        Relationship relAC = graph.makeEdge( \"A\", \"C\", \"length\", 10d );\n\n        PathFinder<WeightedPath> astar = newFinder();\n        int counter = 0;\n        for ( WeightedPath path : astar.findAllPaths( nodeA, nodeC ) )\n        {\n            assertEquals( (Double)5d, (Double)path.weight() );\n            assertPath( path, nodeA, nodeB, nodeC );\n            counter++;\n        }\n//        assertEquals( 2, counter );\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","id":14300,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInTriangleGraph() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 0d, \"y\", 0d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 1d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 7d, \"y\", 0d );\n        Set<Relationship> expectedFirsts = new HashSet<Relationship>();\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        expectedFirsts.add( graph.makeEdge( \"A\", \"B\", \"length\", 1d ) );\n        Relationship expectedSecond = graph.makeEdge( \"B\", \"C\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 5d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n        Iterator<WeightedPath> paths = algo.findAllPaths( nodeA, nodeC ).iterator();\n        for ( int i = 0; i < 2; i++ )\n        {\n            assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n            Path path = paths.next();\n            assertPath( path, nodeA, nodeB, nodeC );\n\n            Iterator<Relationship> relationships = path.relationships().iterator();\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertTrue( \"path contained unexpected relationship\",\n                    expectedFirsts.remove( relationships.next() ) );\n            assertTrue( \"found shorter path than expected\",\n                    relationships.hasNext() );\n            assertEquals( expectedSecond, relationships.next() );\n            assertFalse( \"found longer path than expected\",\n                    relationships.hasNext() );\n        }\n        assertFalse( \"expected at most two paths\", paths.hasNext() );\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        AStar algo = new AStar( graphDb,\n                TraversalFactory.expanderForAllTypes(), new DoubleEvaluator(\n                        \"length\" ), ESTIMATE_EVALUATOR );\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","id":14301,"modified_method":"@Ignore\n    @Test\n    public void canGetMultiplePathsInASmallRoadNetwork() throws Exception\n    {\n        Node nodeA = graph.makeNode( \"A\", \"x\", 1d, \"y\", 1d );\n        Node nodeB = graph.makeNode( \"B\", \"x\", 2d, \"y\", 2d );\n        Node nodeC = graph.makeNode( \"C\", \"x\", 0d, \"y\", 3d );\n        Node nodeD = graph.makeNode( \"D\", \"x\", 1d, \"y\", 4d );\n        Node nodeE = graph.makeNode( \"E\", \"x\", 1d, \"y\", 4d );\n        Node nodeF = graph.makeNode( \"F\", \"x\", 1d, \"y\", 4d );\n        graph.makeEdge( \"A\", \"B\", \"length\", 2d );\n        graph.makeEdge( \"A\", \"C\", \"length\", 2.5d );\n        graph.makeEdge( \"C\", \"D\", \"length\", 7.3d );\n        graph.makeEdge( \"B\", \"D\", \"length\", 2.5d );\n        graph.makeEdge( \"D\", \"E\", \"length\", 3d );\n        graph.makeEdge( \"C\", \"E\", \"length\", 5d );\n        graph.makeEdge( \"E\", \"F\", \"length\", 5d );\n        graph.makeEdge( \"C\", \"F\", \"length\", 12d );\n        graph.makeEdge( \"A\", \"F\", \"length\", 25d );\n\n        PathFinder<WeightedPath> algo = newFinder();\n\n        // Try the search in both directions.\n        for ( Node[] nodes : new Node[][] { { nodeA, nodeF }, { nodeF, nodeA } } )\n        {\n            int found = 0;\n            Iterator<WeightedPath> paths = algo.findAllPaths( nodes[0], nodes[1] ).iterator();\n            for ( int i = 0; i < 2; i++ )\n            {\n                assertTrue( \"expected more paths (i=\" + i + \")\", paths.hasNext() );\n                Path path = paths.next();\n                if ( path.length() != found && path.length() == 3 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeC, nodeE, nodeF );\n                }\n                else if ( path.length() != found && path.length() == 4 )\n                {\n                    assertContains( path.nodes(), nodeA, nodeB, nodeD, nodeE,\n                            nodeF );\n                }\n                else\n                {\n                    fail( \"unexpected path length: \" + path.length() );\n                }\n                found = path.length();\n            }\n            assertFalse( \"expected at most two paths\", paths.hasNext() );\n        }\n    }","commit_id":"075ecfc7025da6b4b8cf8f40fe87f93530ed5496","url":"https://github.com/neo4j/neo4j"},{"original_method":"public GameOver (Application app) {\r\n\t\tspriteBatch = new SpriteBatch();\r\n\t\tbackground = app.getGraphics().newTexture(app.getFiles().getFileHandle(\"data/planet.jpg\", FileType.Internal),\r\n\t\t\tTextureFilter.Linear, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\r\n\t\tlogo = app.getGraphics().newTexture(app.getFiles().getFileHandle(\"data/title.png\", FileType.Internal),\r\n\t\t\tTextureFilter.Linear, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\r\n\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font16.fnt\"), Gdx.files.internal(\"data/font16.png\"), false);\r\n\t}","id":14302,"modified_method":"public GameOver (Application app) {\r\n\t\tspriteBatch = new SpriteBatch();\r\n\t\tbackground = new Texture(Gdx.files.internal(\"data/planet.jpg\"));\r\n\t\tbackground.setFilter(TextureFilter.Linear, TextureFilter.Linear);\r\n\r\n\t\tlogo = new Texture(Gdx.files.internal(\"data/title.png\"));\r\n\t\tlogo.setFilter(TextureFilter.Linear, TextureFilter.Linear);\r\n\r\n\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font16.fnt\"), Gdx.files.internal(\"data/font16.png\"), false);\r\n\t}","commit_id":"3862e5b81c5f707cda03ec2d6440a5eb141015de","url":"https://github.com/libgdx/libgdx"},{"original_method":"public MainMenu (Application app) {\r\n\t\tspriteBatch = new SpriteBatch();\r\n\t\tbackground = app.getGraphics().newTexture(app.getFiles().getFileHandle(\"data/planet.jpg\", FileType.Internal),\r\n\t\t\tTextureFilter.Linear, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\r\n\t\tlogo = app.getGraphics().newTexture(app.getFiles().getFileHandle(\"data/title.png\", FileType.Internal),\r\n\t\t\tTextureFilter.Linear, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\r\n\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font16.fnt\"), Gdx.files.internal(\"data/font16.png\"), false);\r\n\t}","id":14303,"modified_method":"public MainMenu (Application app) {\r\n\t\tspriteBatch = new SpriteBatch();\r\n\t\tbackground = new Texture(Gdx.files.internal(\"data/planet.jpg\"));\r\n\t\tbackground.setFilter(TextureFilter.Linear, TextureFilter.Linear);\t\t\r\n\r\n\t\tlogo = new Texture(Gdx.files.internal(\"data/title.png\"));\r\n\t\tlogo.setFilter(TextureFilter.Linear, TextureFilter.Linear);\r\n\r\n\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font16.fnt\"), Gdx.files.internal(\"data/font16.png\"), false);\r\n\t}","commit_id":"3862e5b81c5f707cda03ec2d6440a5eb141015de","url":"https://github.com/libgdx/libgdx"},{"original_method":"public Renderer (Application app) {\r\n\t\ttry {\r\n\t\t\tspriteBatch = new SpriteBatch();\r\n\r\n\t\t\tInputStream in = Gdx.files.internal(\"data/ship.obj\").read();\r\n\t\t\tshipMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/invader.obj\").read();\r\n\t\t\tinvaderMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/block.obj\").read();\r\n\t\t\tblockMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/shot.obj\").read();\r\n\t\t\tshotMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tshipTexture = app.getGraphics().newTexture(Gdx.files.internal(\"data/ship.png\"),\r\n\t\t\t\tTextureFilter.MipMap, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\t\t\tinvaderTexture = app.getGraphics().newTexture(Gdx.files.internal(\"data/invader.png\"),\r\n\t\t\t\tTextureFilter.MipMap, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\t\t\tbackgroundTexture = app.getGraphics().newTexture(Gdx.files.internal(\"data/planet.jpg\"),\r\n\t\t\t\tTextureFilter.MipMap, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\t\t\texplosionTexture = app.getGraphics().newTexture(Gdx.files.internal(\"data/explode.png\"),\r\n\t\t\t\tTextureFilter.MipMap, TextureFilter.Linear, TextureWrap.ClampToEdge, TextureWrap.ClampToEdge);\r\n\r\n\t\t\texplosionMesh = new Mesh(true, 4 * 16, 0, new VertexAttribute(Usage.Position, 3, \"a_position\"),\r\n\t\t\t\tnew VertexAttribute(Usage.TextureCoordinates, 2, \"a_texCoord\"));\r\n\r\n\t\t\tfloat[] vertices = new float[4 * 16 * (3 + 2)];\r\n\t\t\tint idx = 0;\r\n\t\t\tfor (int row = 0; row < 4; row++) {\r\n\t\t\t\tfor (int column = 0; column < 4; column++) {\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0 + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0 + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0 + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + row * 0.25f;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t\texplosionMesh.setVertices(vertices);\r\n\t\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font10.fnt\"), Gdx.files.internal(\"data/font10.png\"), false);\r\n\r\n\t\t\tcamera = new PerspectiveCamera();\r\n\t\t\tcamera.setFov(67);\r\n\t\t\tcamera.setViewport(480, 320);\r\n\t\t} catch (Exception ex) {\r\n\t\t\tex.printStackTrace();\r\n\t\t}\r\n\t}","id":14304,"modified_method":"public Renderer (Application app) {\r\n\t\ttry {\r\n\t\t\tspriteBatch = new SpriteBatch();\r\n\r\n\t\t\tInputStream in = Gdx.files.internal(\"data/ship.obj\").read();\r\n\t\t\tshipMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/invader.obj\").read();\r\n\t\t\tinvaderMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/block.obj\").read();\r\n\t\t\tblockMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tin = Gdx.files.internal(\"data/shot.obj\").read();\r\n\t\t\tshotMesh = ModelLoader.loadObj(in);\r\n\t\t\tin.close();\r\n\r\n\t\t\tshipTexture = new Texture(Gdx.files.internal(\"data/ship.png\"), true);\r\n\t\t\tshipTexture.setFilter(TextureFilter.MipMap, TextureFilter.Linear);\t\t\t\t\r\n\t\t\tinvaderTexture = new Texture(Gdx.files.internal(\"data/invader.png\"), true);\r\n\t\t\tinvaderTexture.setFilter(TextureFilter.MipMap, TextureFilter.Linear);\r\n\t\t\tbackgroundTexture = new Texture(Gdx.files.internal(\"data/planet.jpg\"), true);\r\n\t\t\tbackgroundTexture.setFilter(TextureFilter.MipMap, TextureFilter.Linear);\r\n\t\t\texplosionTexture = new Texture(Gdx.files.internal(\"data/explode.png\"), true);\r\n\t\t\texplosionTexture.setFilter(TextureFilter.MipMap, TextureFilter.Linear);\r\n\r\n\t\t\texplosionMesh = new Mesh(true, 4 * 16, 0, new VertexAttribute(Usage.Position, 3, \"a_position\"),\r\n\t\t\t\tnew VertexAttribute(Usage.TextureCoordinates, 2, \"a_texCoord\"));\r\n\r\n\t\t\tfloat[] vertices = new float[4 * 16 * (3 + 2)];\r\n\t\t\tint idx = 0;\r\n\t\t\tfor (int row = 0; row < 4; row++) {\r\n\t\t\t\tfor (int column = 0; column < 4; column++) {\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0 + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0 + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0 + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + row * 0.25f;\r\n\r\n\t\t\t\t\tvertices[idx++] = 1;\r\n\t\t\t\t\tvertices[idx++] = -1;\r\n\t\t\t\t\tvertices[idx++] = 0;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + column * 0.25f;\r\n\t\t\t\t\tvertices[idx++] = 0.25f + row * 0.25f;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t\texplosionMesh.setVertices(vertices);\r\n\t\t\tfont = new BitmapFont(Gdx.files.internal(\"data/font10.fnt\"), Gdx.files.internal(\"data/font10.png\"), false);\r\n\r\n\t\t\tcamera = new PerspectiveCamera();\r\n\t\t\tcamera.setFov(67);\r\n\t\t\tcamera.setViewport(480, 320);\r\n\t\t} catch (Exception ex) {\r\n\t\t\tex.printStackTrace();\r\n\t\t}\r\n\t}","commit_id":"3862e5b81c5f707cda03ec2d6440a5eb141015de","url":"https://github.com/libgdx/libgdx"},{"original_method":"BackupSiteResourceDefinition(final boolean runtimeRegistration) {\n        super(PathElement.pathElement(ModelKeys.BACKUP), InfinispanExtension.getResourceDescriptionResolver(ModelKeys.BACKUP), new CacheConfigAdd(ATTRIBUTES), ReloadRequiredRemoveStepHandler.INSTANCE);\n        this.runtimeRegistration = runtimeRegistration;\n    }","id":14305,"modified_method":"BackupSiteResourceDefinition(final boolean runtimeRegistration) {\n        super(BACKUP_PATH, InfinispanExtension.getResourceDescriptionResolver(ModelKeys.BACKUP), new CacheConfigAdd(ATTRIBUTES), ReloadRequiredRemoveStepHandler.INSTANCE);\n        this.runtimeRegistration = runtimeRegistration;\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n     * Register the transformers for transforming from current to 1.3.0 management api version, in which:\n     * - attributes INDEXING_PROPERTIES, SEGMENTS were added in 1.4\n     * - attribute VIRTUAL_NODES was deprecated in 1.4\n     * - expression support was added to most attributes in 1.4, except for CLUSTER, DEFAULT_CACHE and MODE\n     * for which it was already enabled in 1.3\n     * - attribute STATISTICS was added in 2.0\n     *\n     * Chaining of transformers is used in cases where two transformers are required for the same operation.\n     *\n     * @param subsystem the subsystems registration\n     */\n    private static void registerTransformers130(final SubsystemRegistration subsystem) {\n        final ModelVersion version = ModelVersion.create(1, 3);\n\n        final ResourceTransformationDescriptionBuilder subsystemBuilder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n\n        final ResourceTransformationDescriptionBuilder cacheContainerBuilder = subsystemBuilder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, InfinispanRejectedExpressions_1_3.REJECT_CONTAINER_ATTRIBUTES)\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        cacheContainerBuilder.addChildResource(TransportResourceDefinition.TRANSPORT_PATH)\n            .getAttributeBuilder()\n            .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, InfinispanRejectedExpressions_1_3.REJECT_TRANSPORT_ATTRIBUTES)\n            .end();\n\n        @SuppressWarnings(\"deprecation\")\n        final ResourceTransformationDescriptionBuilder distributedCacheBuilder = cacheContainerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL,  ClusteredCacheResourceDefinition.QUEUE_SIZE,\n                        ClusteredCacheResourceDefinition.REMOTE_TIMEOUT, CacheResourceDefinition.START,\n                        DistributedCacheResourceDefinition.L1_LIFESPAN, DistributedCacheResourceDefinition.OWNERS, DistributedCacheResourceDefinition.VIRTUAL_NODES, DistributedCacheResourceDefinition.SEGMENTS)\n                //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                //Convert segments to virtual-nodes if it is set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, DistributedCacheResourceDefinition.SEGMENTS)\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .setValueConverter(new AttributeConverter.DefaultAttributeConverter() {\n                        @Override\n                        protected void convertAttribute(PathAddress address, String attributeName, ModelNode attributeValue,\n                                TransformationContext context) {\n                            if (attributeValue.isDefined()) {\n                                attributeValue.set(SegmentsAndVirtualNodeConverter.segmentsToVirtualNodes(attributeValue.asString()));\n                            }\n                        }\n                    }, DistributedCacheResourceDefinition.SEGMENTS)\n                .addRename(DistributedCacheResourceDefinition.SEGMENTS, DistributedCacheResourceDefinition.VIRTUAL_NODES.getName())\n                .end();\n        registerCacheResourceChildren(distributedCacheBuilder, true);\n\n        final ResourceTransformationDescriptionBuilder invalidationCacheBuilder = cacheContainerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL, ClusteredCacheResourceDefinition.QUEUE_SIZE, ClusteredCacheResourceDefinition.REMOTE_TIMEOUT,\n                        CacheResourceDefinition.START)\n                //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        registerCacheResourceChildren(invalidationCacheBuilder, false);\n\n        final ResourceTransformationDescriptionBuilder localCacheBuilder = cacheContainerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME,\n                        CacheResourceDefinition.MODULE, CacheResourceDefinition.START)\n                //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        registerCacheResourceChildren(localCacheBuilder, false);\n\n        final ResourceTransformationDescriptionBuilder replicatedCacheBuilder = cacheContainerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL, ClusteredCacheResourceDefinition.QUEUE_SIZE, ClusteredCacheResourceDefinition.REMOTE_TIMEOUT,\n                        CacheResourceDefinition.START)\n                //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        registerCacheResourceChildren(replicatedCacheBuilder, true);\n\n        TransformationDescription.Tools.register(subsystemBuilder.build(), subsystem, version);\n\n    }","id":14306,"modified_method":"/**\n     * Register the transformers for transforming from current to 1.3.0 management api version, in which:\n     * - attributes INDEXING_PROPERTIES, SEGMENTS were added in 1.4\n     * - attribute VIRTUAL_NODES was deprecated in 1.4\n     * - expression support was added to most attributes in 1.4, except for CLUSTER, DEFAULT_CACHE and MODE for which it was already enabled in 1.3\n     * - attribute STATISTICS was added in 2.0\n     * - shared state cache children backup and backup-for are rejected\n     * <p/>\n     * Chaining of transformers is used in cases where two transformers are required for the same operation.\n     *\n     * @param subsystem the subsystems registration\n     */\n    private static void registerTransformers130(final SubsystemRegistration subsystem) {\n        final ModelVersion version = ModelVersion.create(1, 3);\n\n        final ResourceTransformationDescriptionBuilder subsystemBuilder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n\n        final ResourceTransformationDescriptionBuilder cacheContainerBuilder = subsystemBuilder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, InfinispanRejectedExpressions_1_3.REJECT_CONTAINER_ATTRIBUTES)\n                        // discard statistics if set to true, reject otherwise\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        cacheContainerBuilder.addChildResource(TransportResourceDefinition.TRANSPORT_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, InfinispanRejectedExpressions_1_3.REJECT_TRANSPORT_ATTRIBUTES)\n                .end();\n\n        final ResourceTransformationDescriptionBuilder localCacheBuilder = cacheContainerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME,\n                        CacheResourceDefinition.MODULE, CacheResourceDefinition.START)\n                        //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                        // discard statistics if set to true, reject otherwise\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        registerCacheResourceChildren(localCacheBuilder, false);\n\n        final ResourceTransformationDescriptionBuilder invalidationCacheBuilder = cacheContainerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL, ClusteredCacheResourceDefinition.QUEUE_SIZE, ClusteredCacheResourceDefinition.REMOTE_TIMEOUT,\n                        CacheResourceDefinition.START)\n                        //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                        // discard statistics if set to true, reject otherwise\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        registerCacheResourceChildren(invalidationCacheBuilder, false);\n\n        ResourceTransformationDescriptionBuilder replicatedCacheBuilder = cacheContainerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH);\n        replicatedCacheBuilder.getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL, ClusteredCacheResourceDefinition.QUEUE_SIZE, ClusteredCacheResourceDefinition.REMOTE_TIMEOUT,\n                        CacheResourceDefinition.START)\n                        //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                        // discard statistics if set to true, reject otherwise\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        // reject use of x-site related elements\n        replicatedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        replicatedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n        registerCacheResourceChildren(replicatedCacheBuilder, true);\n\n        @SuppressWarnings(\"deprecation\")\n        ResourceTransformationDescriptionBuilder distributedCacheBuilder = cacheContainerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH);\n        distributedCacheBuilder.getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        ClusteredCacheResourceDefinition.ASYNC_MARSHALLING, CacheResourceDefinition.BATCHING, CacheResourceDefinition.INDEXING, CacheResourceDefinition.JNDI_NAME, ClusteredCacheResourceDefinition.MODE,\n                        CacheResourceDefinition.MODULE, ClusteredCacheResourceDefinition.QUEUE_FLUSH_INTERVAL, ClusteredCacheResourceDefinition.QUEUE_SIZE,\n                        ClusteredCacheResourceDefinition.REMOTE_TIMEOUT, CacheResourceDefinition.START,\n                        DistributedCacheResourceDefinition.L1_LIFESPAN, DistributedCacheResourceDefinition.OWNERS, DistributedCacheResourceDefinition.VIRTUAL_NODES, DistributedCacheResourceDefinition.SEGMENTS)\n                        //discard indexing-properties if undefined, and reject it if not set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                .addRejectCheck(RejectAttributeChecker.DEFINED, CacheResourceDefinition.INDEXING_PROPERTIES)\n                        //Convert segments to virtual-nodes if it is set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, DistributedCacheResourceDefinition.SEGMENTS)\n                .setValueConverter(new AttributeConverter.DefaultAttributeConverter() {\n                    @Override\n                    protected void convertAttribute(PathAddress address, String attributeName, ModelNode attributeValue,\n                                                    TransformationContext context) {\n                        if (attributeValue.isDefined()) {\n                            attributeValue.set(SegmentsAndVirtualNodeConverter.segmentsToVirtualNodes(attributeValue.asString()));\n                        }\n                    }\n                }, DistributedCacheResourceDefinition.SEGMENTS)\n                .addRename(DistributedCacheResourceDefinition.SEGMENTS, DistributedCacheResourceDefinition.VIRTUAL_NODES.getName())\n                        // discard statistics if set to true, reject otherwise\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        // reject use of x-site related elements\n        distributedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        distributedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n        registerCacheResourceChildren(distributedCacheBuilder, true);\n\n        TransformationDescription.Tools.register(subsystemBuilder.build(), subsystem, version);\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n     * Register the transformers for transforming from current to 1.4.0 management api version, including:\n     * - attribute STATISTICS was added in 2.0\n     * @param subsystem the subsystems registration\n     */\n    private static void registerTransformers141(final SubsystemRegistration subsystem) {\n\n        ResourceTransformationDescriptionBuilder builder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n        ResourceTransformationDescriptionBuilder containerBuilder = builder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        containerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        containerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        containerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        containerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        TransformationDescription.Tools.register(builder.build(), subsystem, ModelVersion.create(1, 4, 1));\n    }","id":14307,"modified_method":"/**\n     * Register the transformers for transforming from current to 1.4.0 management api version, including:\n     * - attribute STATISTICS was added in 2.0\n     * - shared state cache children backup and backup-for are rejected\n     * @param subsystem the subsystems registration\n     */\n    private static void registerTransformers141(final SubsystemRegistration subsystem) {\n\n        ResourceTransformationDescriptionBuilder builder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n        ResourceTransformationDescriptionBuilder containerBuilder = builder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        ResourceTransformationDescriptionBuilder distributedCacheBuilder = containerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH);\n        distributedCacheBuilder.getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        distributedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        distributedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n        ResourceTransformationDescriptionBuilder replicatedCacheBuilder = containerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH);\n        replicatedCacheBuilder.getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        replicatedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        replicatedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n        containerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        containerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        TransformationDescription.Tools.register(builder.build(), subsystem, ModelVersion.create(1, 4, 1));\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n     * Register the transformers for transforming from current to 1.4.0 management api version, including:\n     * - use of the VIRTUAL_NODES attribute was again allowed in 1.4.1, with a value conversion applied\n     * - attribute STATISTICS was added in 2.0\n     * @param subsystem the subsystems registration\n     */\n    @SuppressWarnings(\"deprecation\")\n    private static void registerTransformers140(final SubsystemRegistration subsystem) {\n        final ModelVersion version = ModelVersion.create(1, 4, 0);\n\n        final ResourceTransformationDescriptionBuilder subsystemBuilder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n        ResourceTransformationDescriptionBuilder cacheContainerBuilder = subsystemBuilder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        cacheContainerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH).getAttributeBuilder()\n                //Convert virtual-nodes to segments if it is set\n                .setDiscard(DiscardAttributeChecker.UNDEFINED, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                .setValueConverter(new AttributeConverter.DefaultAttributeConverter() {\n                    @Override\n                    protected void convertAttribute(PathAddress address, String attributeName, ModelNode attributeValue,\n                                                    TransformationContext context) {\n                        if (attributeValue.isDefined()) {\n                            attributeValue.set(SegmentsAndVirtualNodeConverter.virtualNodesToSegments(attributeValue));\n                        }\n                    }\n                }, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                .addRename(DistributedCacheResourceDefinition.VIRTUAL_NODES, DistributedCacheResourceDefinition.SEGMENTS.getName())\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        cacheContainerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        cacheContainerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        cacheContainerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        TransformationDescription.Tools.register(subsystemBuilder.build(), subsystem, version);\n    }","id":14308,"modified_method":"/**\n     * Register the transformers for transforming from current to 1.4.0 management api version, including:\n     * - use of the VIRTUAL_NODES attribute was again allowed in 1.4.1, with a value conversion applied\n     * - attribute STATISTICS was added in 2.0\n     * - shared state cache children backup and backup-for are rejected\n     *\n     * @param subsystem the subsystems registration\n     */\n    @SuppressWarnings(\"deprecation\")\n    private static void registerTransformers140(final SubsystemRegistration subsystem) {\n        final ModelVersion version = ModelVersion.create(1, 4, 0);\n\n        final ResourceTransformationDescriptionBuilder subsystemBuilder = TransformationDescriptionBuilder.Factory.createSubsystemInstance();\n        ResourceTransformationDescriptionBuilder cacheContainerBuilder = subsystemBuilder.addChildResource(CacheContainerResourceDefinition.CONTAINER_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n        ResourceTransformationDescriptionBuilder distributedCacheBuilder = cacheContainerBuilder.addChildResource(DistributedCacheResourceDefinition.DISTRIBUTED_CACHE_PATH);\n        distributedCacheBuilder.getAttributeBuilder()\n                //Convert virtual-nodes to segments if it is set\n                //.setDiscard(DiscardAttributeChecker.UNDEFINED, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                // this is required to address WFLY-2598\n                .setDiscard(new DiscardAttributeChecker.DefaultDiscardAttributeChecker(false, true) {\n                    @Override\n                    protected boolean isValueDiscardable(PathAddress address, String attributeName, ModelNode attributeValue, TransformationContext context) {\n                        if (attributeName.equals(DistributedCacheResourceDefinition.VIRTUAL_NODES.getName())) {\n                            if (attributeValue.isDefined()) {\n                                if (attributeValue.equals(new ModelNode().set(1))) {\n                                    return true;\n                                }\n                            }\n                        }\n                        return false;\n                    }\n                }, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                .addRejectCheck(VirtualNodesCheckerAndConverter.INSTANCE, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                .setValueConverter(VirtualNodesCheckerAndConverter.INSTANCE, DistributedCacheResourceDefinition.VIRTUAL_NODES)\n                .addRename(DistributedCacheResourceDefinition.VIRTUAL_NODES, DistributedCacheResourceDefinition.SEGMENTS.getName())\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        distributedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        distributedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n\n        ResourceTransformationDescriptionBuilder replicatedCacheBuilder = cacheContainerBuilder.addChildResource(ReplicatedCacheResourceDefinition.REPLICATED_CACHE_PATH);\n        replicatedCacheBuilder.getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        replicatedCacheBuilder.rejectChildResource(BackupSiteResourceDefinition.BACKUP_PATH);\n        replicatedCacheBuilder.rejectChildResource(BackupForResourceDefinition.BACKUP_FOR_PATH);\n\n        cacheContainerBuilder.addChildResource(InvalidationCacheResourceDefinition.INVALIDATION_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n        cacheContainerBuilder.addChildResource(LocalCacheResourceDefinition.LOCAL_CACHE_PATH).getAttributeBuilder()\n                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(false, false, new ModelNode(true)), CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.UNDEFINED, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CacheResourceDefinition.STATISTICS)\n                .addRejectCheck(new RejectAttributeChecker.SimpleRejectAttributeChecker(new ModelNode(false)), CacheResourceDefinition.STATISTICS)\n                .end();\n\n\n        TransformationDescription sub = subsystemBuilder.build();\n\n        // TransformationDescription.Tools.register(subsystemBuilder.build(), subsystem, version);\n        TransformationDescription.Tools.register(sub, subsystem, version);\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"private static void registerCacheResourceChildren(final ResourceTransformationDescriptionBuilder parent, final boolean addStateTransfer) {\n        parent.addChildResource(LockingResourceDefinition.LOCKING_PATH)\n            .getAttributeBuilder()\n            .addRejectCheck(\n                    RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                    LockingResourceDefinition.ACQUIRE_TIMEOUT, LockingResourceDefinition.CONCURRENCY_LEVEL, LockingResourceDefinition.ISOLATION, LockingResourceDefinition.STRIPING)\n            .end();\n        parent.addChildResource(EvictionResourceDefinition.EVICTION_PATH)\n            .getAttributeBuilder()\n            .addRejectCheck(\n                    RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                    EvictionResourceDefinition.MAX_ENTRIES, EvictionResourceDefinition.STRATEGY)\n            .end();\n        parent.addChildResource(ExpirationResourceDefinition.EXPIRATION_PATH)\n            .getAttributeBuilder()\n            .addRejectCheck(\n                    RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                    ExpirationResourceDefinition.EXPIRATION_ATTRIBUTES)\n            .end();\n        parent.addChildResource(TransactionResourceDefinition.TRANSACTION_PATH)\n            .getAttributeBuilder()\n            .addRejectCheck(\n                    RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                    TransactionResourceDefinition.LOCKING, TransactionResourceDefinition.STOP_TIMEOUT)\n            .end();\n\n        // Store transformers ///////\n        registerJdbcStoreTransformers(parent);\n        //fileStore=FILE_STORE\n        ResourceTransformationDescriptionBuilder fileStoreBuilder = parent.addChildResource(FileStoreResourceDefinition.FILE_STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        FileStoreResourceDefinition.PATH, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION,\n                        StoreResourceDefinition.PRELOAD, StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON)\n                .end();\n        registerStoreTransformerChildren(fileStoreBuilder);\n        //store=STORE\n        ResourceTransformationDescriptionBuilder storeBuilder = parent.addChildResource(CustomStoreResourceDefinition.STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        CustomStoreResourceDefinition.CLASS, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION, StoreResourceDefinition.PRELOAD,\n                        StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON)\n                .end();\n        registerStoreTransformerChildren(storeBuilder);\n        //remote-store=REMOTE_STORE\n        ResourceTransformationDescriptionBuilder remoteStoreBuilder = parent.addChildResource(RemoteStoreResourceDefinition.REMOTE_STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        RemoteStoreResourceDefinition.CACHE, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION, StoreResourceDefinition.PRELOAD,\n                        StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON, RemoteStoreResourceDefinition.SOCKET_TIMEOUT,\n                        RemoteStoreResourceDefinition.TCP_NO_DELAY)\n                .end();\n        registerStoreTransformerChildren(remoteStoreBuilder);\n\n        if (addStateTransfer) {\n            parent.addChildResource(StateTransferResourceDefinition.STATE_TRANSFER_PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, StateTransferResourceDefinition.STATE_TRANSFER_ATTRIBUTES)\n                    .end();\n        }\n    }","id":14309,"modified_method":"private static void registerCacheResourceChildren(final ResourceTransformationDescriptionBuilder parent, final boolean addStateTransfer) {\n        parent.addChildResource(LockingResourceDefinition.LOCKING_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, LockingResourceDefinition.LOCKING_ATTRIBUTES)\n                .end();\n        parent.addChildResource(EvictionResourceDefinition.EVICTION_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, EvictionResourceDefinition.EVICTION_ATTRIBUTES)\n                .end();\n        parent.addChildResource(ExpirationResourceDefinition.EXPIRATION_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, ExpirationResourceDefinition.EXPIRATION_ATTRIBUTES)\n                .end();\n        parent.addChildResource(TransactionResourceDefinition.TRANSACTION_PATH)\n                .getAttributeBuilder()\n                        // TRANSACTION_ATTRIBUTES - MODE\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, TransactionResourceDefinition.LOCKING, TransactionResourceDefinition.STOP_TIMEOUT)\n                .end();\n\n        // Store transformers\n        registerJdbcStoreTransformers(parent);\n\n        //fileStore=FILE_STORE\n        ResourceTransformationDescriptionBuilder fileStoreBuilder = parent.addChildResource(FileStoreResourceDefinition.FILE_STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        FileStoreResourceDefinition.PATH, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION,\n                        StoreResourceDefinition.PRELOAD, StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON)\n                .end();\n        registerStoreTransformerChildren(fileStoreBuilder);\n\n        //store=STORE\n        ResourceTransformationDescriptionBuilder storeBuilder = parent.addChildResource(CustomStoreResourceDefinition.STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        CustomStoreResourceDefinition.CLASS, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION, StoreResourceDefinition.PRELOAD,\n                        StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON)\n                .end();\n        registerStoreTransformerChildren(storeBuilder);\n\n        //remote-store=REMOTE_STORE\n        ResourceTransformationDescriptionBuilder remoteStoreBuilder = parent.addChildResource(RemoteStoreResourceDefinition.REMOTE_STORE_PATH)\n                .getAttributeBuilder()\n                .addRejectCheck(\n                        RejectAttributeChecker.SIMPLE_EXPRESSIONS,\n                        RemoteStoreResourceDefinition.CACHE, StoreResourceDefinition.FETCH_STATE, StoreResourceDefinition.PASSIVATION, StoreResourceDefinition.PRELOAD,\n                        StoreResourceDefinition.PURGE, StoreResourceDefinition.SHARED, StoreResourceDefinition.SINGLETON, RemoteStoreResourceDefinition.SOCKET_TIMEOUT,\n                        RemoteStoreResourceDefinition.TCP_NO_DELAY)\n                .end();\n        registerStoreTransformerChildren(remoteStoreBuilder);\n\n        if (addStateTransfer) {\n            parent.addChildResource(StateTransferResourceDefinition.STATE_TRANSFER_PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, StateTransferResourceDefinition.STATE_TRANSFER_ATTRIBUTES)\n                    .end();\n        }\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"public SubsystemParsingTestCase() {\n        super(InfinispanExtension.SUBSYSTEM_NAME, new InfinispanExtension());\n    }","id":14310,"modified_method":"public SubsystemParsingTestCase(String xmlFile, int operations) {\n        super(InfinispanExtension.SUBSYSTEM_NAME, new InfinispanExtension(), xmlFile);\n        this.xmlFile = xmlFile ;\n        this.operations = operations ;\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    public void testParseAndMarshallModel() throws Exception {\n\n        // Parse and install the XML into the controller\n        String subsystemXml = getSubsystemXml() ;\n        KernelServices servicesA = createKernelServicesBuilder(null).setSubsystemXml(subsystemXml).build();\n\n        // list the names of the services which have been installed\n        System.out.println(\"service names = \" + servicesA.getContainer().getServiceNames());\n\n        ModelNode modelA = servicesA.readWholeModel() ;\n        // print out the resulting model\n        String marshalled = servicesA.getPersistedSubsystemXml();\n        System.out.println(\"marshalled XML = \" + marshalled);\n\n        // install the persisted xml from the first controller into a second controller\n        KernelServices servicesB = createKernelServicesBuilder(null).setSubsystemXml(marshalled).build();\n        ModelNode modelB = servicesB.readWholeModel() ;\n\n        // make sure the models are identical\n        super.compare(modelA, modelB);\n    }","id":14311,"modified_method":"/**\n     * Starts a controller with a given subsystem xml and then checks that a second controller\n     * started with the xml marshalled from the first one results in the same model\n     */\n    @Test\n    public void testParseAndMarshalModel() throws Exception {\n       // Parse the subsystem xml and install into the first controller\n\n       KernelServices servicesA = createKernelServicesBuilder(null).setSubsystemXml(getSubsystemXml()).build();\n\n       // Get the model and the persisted xml from the first controller\n       ModelNode modelA = servicesA.readWholeModel();\n       String marshalled = servicesA.getPersistedSubsystemXml();\n\n       // Install the persisted xml from the first controller into a second controller\n       KernelServices servicesB = createKernelServicesBuilder(null).setSubsystemXml(marshalled).build();\n       ModelNode modelB = servicesB.readWholeModel();\n\n       // Make sure the models from the two controllers are identical\n       super.compare(modelA, modelB);\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    public void testInstallIntoController() throws Exception {\n\n        // Parse and install the XML into the controller\n        String subsystemXml = getSubsystemXml() ;\n        KernelServices services = createKernelServicesBuilder(null).setSubsystemXml(subsystemXml).build();\n\n        // print out the resulting model\n        ModelNode model = services.readWholeModel() ;\n        System.out.println(model);\n\n        // use some assertions here to check the correctness of the model\n        Assert.assertTrue(model.get(SUBSYSTEM).hasDefined(InfinispanExtension.SUBSYSTEM_NAME));\n\n        assertRemoveSubsystemResources(services);\n\n    }","id":14312,"modified_method":"/**\n     * Test that the model created from the xml looks as expected\n     */\n    @Test\n    public void testInstallIntoController() throws Exception {\n       // Parse the subsystem xml and install into the controller\n       KernelServices services = createKernelServicesBuilder(null).setSubsystemXml(getSubsystemXml()).build();\n\n       // Read the whole model and make sure it looks as expected\n       ModelNode model = services.readWholeModel();\n\n       // System.out.println(\"model = \" + model.asString());\n\n       Assert.assertTrue(model.get(SUBSYSTEM).hasDefined(getMainSubsystemName()));\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n      * Tests that the xml is parsed into the correct operations\n     */\n    @Test\n    public void testParseSubsystem() throws Exception {\n\n        //Parse the subsystem xml into operations\n        String subsystemXml = getSubsystemXml() ;\n        List<ModelNode> operations = super.parse(subsystemXml);\n\n        // Check that we have the expected number of operations\n        // one operation for adding subsystem; one operation for adding deployment-type\n        Assert.assertEquals(8, operations.size());\n\n        //Check that each operation has the correct content\n        for (int i = 0; i < 8; i++) {\n            ModelNode operation = operations.get(i) ;\n            System.out.println(operation);\n        }\n    }","id":14313,"modified_method":"/**\n     * Tests that the xml is parsed into the correct operations\n     */\n    @Test\n    public void testParseSubsystem() throws Exception {\n       // Parse the subsystem xml into operations\n       List<ModelNode> operations = super.parse(getSubsystemXml());\n\n       /*\n       // print the operations\n       System.out.println(\"List of operations\");\n       for (ModelNode op : operations) {\n           System.out.println(\"operation = \" + op.toString());\n       }\n       */\n\n       // Check that we have the expected number of operations\n       // one for each resource instance\n       Assert.assertEquals(this.operations, operations.size());\n\n       // Check that each operation has the correct content\n       ModelNode addSubsystem = operations.get(0);\n       Assert.assertEquals(ADD, addSubsystem.get(OP).asString());\n       PathAddress addr = PathAddress.pathAddress(addSubsystem.get(OP_ADDR));\n       Assert.assertEquals(1, addr.size());\n       PathElement element = addr.getElement(0);\n       Assert.assertEquals(SUBSYSTEM, element.getKey());\n       Assert.assertEquals(getMainSubsystemName(), element.getValue());\n    }","commit_id":"4006309ff9f9f6f023f2c2560af6b84f5b5f8490","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"A child\", \"A child\\\\a.txt\");\n  }","id":14314,"modified_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMoveDir() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n    VirtualFile d2 = createDirInCommand(myWorkingCopyDir, \"d2\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String oldPath = absPath(d1);\n    moveFileInCommand(d1, d2);\n    Thread.sleep(100);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- moved from ..\\\\d1\"),\n      new Data(oldPath, FileStatus.DELETED, null)});\n  }","id":14315,"modified_method":"@Test\n  public void testMoveDir() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n    VirtualFile d2 = createDirInCommand(myWorkingCopyDir, \"d2\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String oldPath = absPath(d1);\n    moveFileInCommand(d1, d2);\n    Thread.sleep(100);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- moved from ..\" + File.separatorChar + \"d1\"),\n      new Data(oldPath, FileStatus.DELETED, null)});\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMoveDirChangeFile() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n    VirtualFile d2 = createDirInCommand(myWorkingCopyDir, \"d2\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String oldPath = absPath(d1);\n    final String oldF11Path = new File(f11.getPath()).getAbsolutePath();\n    moveFileInCommand(d1, d2);\n    editFileInCommand(myProject, f11, \"new\");\n\n    Thread.sleep(100);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- moved from ..\\\\d1\"),\n      new Data(oldPath, FileStatus.DELETED, null),\n      new Data(absPath(f11), FileStatus.MODIFIED, \"- moved from \" + oldF11Path)});\n  }","id":14316,"modified_method":"@Test\n  public void testMoveDirChangeFile() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n    VirtualFile d2 = createDirInCommand(myWorkingCopyDir, \"d2\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String oldPath = absPath(d1);\n    final String oldF11Path = new File(f11.getPath()).getAbsolutePath();\n    moveFileInCommand(d1, d2);\n    editFileInCommand(myProject, f11, \"new\");\n\n    Thread.sleep(100);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- moved from ..\" + File.separatorChar + \"d1\"),\n      new Data(oldPath, FileStatus.DELETED, null),\n      new Data(absPath(f11), FileStatus.MODIFIED, \"- moved from \" + oldF11Path)});\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testDeletePackage() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"child\");\n    createFileInCommand(dir, \"a.txt\", \"content\");\n\n    verify(runSvn(\"status\"), \"A child\", \"A child\\\\a.txt\");\n    checkin();\n\n    deleteFileInCommand(dir);\n    verify(runSvn(\"status\"), \"D child\", \"D child\\\\a.txt\");\n\n    LocalFileSystem.getInstance().refresh(false);\n\n    final AlienDirtyScope dirtyScope = new AlienDirtyScope();\n    dirtyScope.addDir(new FilePathImpl(myWorkingCopyDir));\n    final List<Change> changesManually = getChangesInScope(dirtyScope);\n    Assert.assertEquals(2, changesManually.size());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    // since ChangeListManager is runnning, it can take dirty scope itself;... it's easier to just take changes from it\n    final ChangeListManager clManager = ChangeListManager.getInstance(myProject);\n    clManager.ensureUpToDate(false);\n    final List<LocalChangeList> lists = clManager.getChangeListsCopy();\n    Assert.assertEquals(1, lists.size());\n    final Collection<Change> changes = lists.get(0).getChanges();\n    Assert.assertEquals(2, changes.size());\n  }","id":14317,"modified_method":"@Test\n  public void testDeletePackage() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"child\");\n    createFileInCommand(dir, \"a.txt\", \"content\");\n\n    verify(runSvn(\"status\"), \"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n    checkin();\n\n    deleteFileInCommand(dir);\n    verify(runSvn(\"status\"), \"D child\", \"D child\" + File.separatorChar + \"a.txt\");\n\n    LocalFileSystem.getInstance().refresh(false);\n\n    final AlienDirtyScope dirtyScope = new AlienDirtyScope();\n    dirtyScope.addDir(new FilePathImpl(myWorkingCopyDir));\n    final List<Change> changesManually = getChangesInScope(dirtyScope);\n    Assert.assertEquals(2, changesManually.size());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    // since ChangeListManager is runnning, it can take dirty scope itself;... it's easier to just take changes from it\n    final ChangeListManager clManager = ChangeListManager.getInstance(myProject);\n    clManager.ensureUpToDate(false);\n    final List<LocalChangeList> lists = clManager.getChangeListsCopy();\n    Assert.assertEquals(1, lists.size());\n    final Collection<Change> changes = lists.get(0).getChanges();\n    Assert.assertEquals(2, changes.size());\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMoveToNewPackage() throws Throwable {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(myWorkingCopyDir, \"a.txt\", \"A\");\n    moveToNewPackage(file, \"child\");\n    verifySorted(runSvn(\"status\"), \"A child\", \"A child\\\\a.txt\");\n  }","id":14318,"modified_method":"@Test\n  public void testMoveToNewPackage() throws Throwable {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(myWorkingCopyDir, \"a.txt\", \"A\");\n    moveToNewPackage(file, \"child\");\n    verifySorted(runSvn(\"status\"), \"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMovePackageToParent() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile child = createDirInCommand(myWorkingCopyDir, \"child\");\n    final VirtualFile grandChild = createDirInCommand(child, \"grandChild\");\n    createFileInCommand(grandChild, \"a.txt\", \"a\");\n    checkin();\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n\n    moveFileInCommand(grandChild, myWorkingCopyDir);\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    changeListManager.ensureUpToDate(false);\n    final List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    Assert.assertEquals(listToString(changes), 2, changes.size());\n    sortChanges(changes);\n    verifyChange(changes.get(0), \"child\\\\grandChild\", \"grandChild\");\n    verifyChange(changes.get(1), \"child\\\\grandChild\\\\a.txt\", \"grandChild\\\\a.txt\");\n  }","id":14319,"modified_method":"@Test\n  public void testMovePackageToParent() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile child = createDirInCommand(myWorkingCopyDir, \"child\");\n    final VirtualFile grandChild = createDirInCommand(child, \"grandChild\");\n    createFileInCommand(grandChild, \"a.txt\", \"a\");\n    checkin();\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n\n    moveFileInCommand(grandChild, myWorkingCopyDir);\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    changeListManager.ensureUpToDate(false);\n    final List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    Assert.assertEquals(listToString(changes), 2, changes.size());\n    sortChanges(changes);\n    verifyChange(changes.get(0), \"child\" + File.separatorChar + \"grandChild\", \"grandChild\");\n    verifyChange(changes.get(1), \"child\" + File.separatorChar + \"grandChild\" + File.separatorChar + \"a.txt\", \"grandChild\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testRenameFileRenameDir() throws Exception {\n    final VirtualFile child = prepareDirectoriesForRename();\n    final VirtualFile f = child.findChild(\"a.txt\");\n    renameFileInCommand(f, \"anew.txt\");\n    renameFileInCommand(child, \"newchild\");\n\n    verifySorted(runSvn(\"status\"), \"A + newchild\", \"A + newchild\\\\anew.txt\",\n                 \"D child\", \"D child\\\\a.txt\", \"D child\\\\grandChild\", \"D child\\\\grandChild\\\\b.txt\", \"D + newchild\\\\a.txt\");\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    changeListManager.ensureUpToDate(false);\n    final List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    final List<VcsException> list = SvnVcs.getInstance(myProject).getCheckinEnvironment().commit(changes, \"test\");\n    Assert.assertEquals(0, list.size());\n  }","id":14320,"modified_method":"@Test\n  public void testRenameFileRenameDir() throws Exception {\n    final VirtualFile child = prepareDirectoriesForRename();\n    final VirtualFile f = child.findChild(\"a.txt\");\n    renameFileInCommand(f, \"anew.txt\");\n    renameFileInCommand(child, \"newchild\");\n\n    verifySorted(runSvn(\"status\"), \"A + newchild\", \"A + newchild\" + File.separatorChar + \"anew.txt\",\n                 \"D child\", \"D child\" + File.separatorChar + \"a.txt\", \"D child\" + File.separatorChar + \"grandChild\", \"D child\" + File.separatorChar + \"grandChild\" + File.separatorChar + \"b.txt\", \"D + newchild\" + File.separatorChar + \"a.txt\");\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    changeListManager.ensureUpToDate(false);\n    final List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    final List<VcsException> list = SvnVcs.getInstance(myProject).getCheckinEnvironment().commit(changes, \"test\");\n    Assert.assertEquals(0, list.size());\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testRenamePackageWithChildren() throws Exception {\n    final VirtualFile child = prepareDirectoriesForRename();\n\n    renameFileInCommand(child, \"childnew\");\n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"D child\", \"D child\\\\grandChild\", \"D child\\\\grandChild\\\\b.txt\", \"D child\\\\a.txt\", \"A + childnew\");\n\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    changeListManager.ensureUpToDate(false);\n    List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    Assert.assertEquals(4, changes.size());\n    sortChanges(changes);\n    verifyChange(changes.get(0), \"child\", \"childnew\");\n    verifyChange(changes.get(1), \"child\\\\a.txt\", \"childnew\\\\a.txt\");\n    verifyChange(changes.get(2), \"child\\\\grandChild\", \"childnew\\\\grandChild\");\n    verifyChange(changes.get(3), \"child\\\\grandChild\\\\b.txt\", \"childnew\\\\grandChild\\\\b.txt\");\n\n    VirtualFile oldChild = myWorkingCopyDir.findChild(\"child\");\n    Assert.assertEquals(FileStatus.DELETED, changeListManager.getStatus(oldChild));\n  }","id":14321,"modified_method":"@Test\n  public void testRenamePackageWithChildren() throws Exception {\n    final VirtualFile child = prepareDirectoriesForRename();\n\n    renameFileInCommand(child, \"childnew\");\n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"D child\", \"D child\" + File.separatorChar + \"grandChild\", \"D child\" + File.separatorChar + \"grandChild\" + File.separatorChar + \"b.txt\", \"D child\" + File.separatorChar + \"a.txt\", \"A + childnew\");\n\n    LocalFileSystem.getInstance().refresh(false);   // wait for end of refresh operations initiated from SvnFileSystemListener\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    changeListManager.ensureUpToDate(false);\n    List<Change> changes = new ArrayList<Change>(changeListManager.getDefaultChangeList().getChanges());\n    Assert.assertEquals(4, changes.size());\n    sortChanges(changes);\n    verifyChange(changes.get(0), \"child\", \"childnew\");\n    verifyChange(changes.get(1), \"child\" + File.separatorChar + \"a.txt\", \"childnew\" + File.separatorChar + \"a.txt\");\n    verifyChange(changes.get(2), \"child\" + File.separatorChar + \"grandChild\", \"childnew\" + File.separatorChar + \"grandChild\");\n    verifyChange(changes.get(3), \"child\" + File.separatorChar + \"grandChild\" + File.separatorChar + \"b.txt\", \"childnew\" + File.separatorChar + \"grandChild\" + File.separatorChar + \"b.txt\");\n\n    VirtualFile oldChild = myWorkingCopyDir.findChild(\"child\");\n    Assert.assertEquals(FileStatus.DELETED, changeListManager.getStatus(oldChild));\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMoveToNewPackageCommitted() throws Throwable {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(myWorkingCopyDir, \"a.txt\", \"A\");\n    checkin();\n    moveToNewPackage(file, \"child\");\n    verifySorted(runSvn(\"status\"), \"A child\", \"A + child\\\\a.txt\", \"D a.txt\");\n  }","id":14322,"modified_method":"@Test\n  public void testMoveToNewPackageCommitted() throws Throwable {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(myWorkingCopyDir, \"a.txt\", \"A\");\n    checkin();\n    moveToNewPackage(file, \"child\");\n    verifySorted(runSvn(\"status\"), \"A child\", \"A + child\" + File.separatorChar + \"a.txt\", \"D a.txt\");\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testRenameAddedPackage() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"child\");\n    createFileInCommand(dir, \"a.txt\", \"content\");\n    renameFileInCommand(dir, \"newchild\");\n    verify(runSvn(\"status\"), \"A newchild\", \"A newchild\\\\a.txt\");\n  }","id":14323,"modified_method":"@Test\n  public void testRenameAddedPackage() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"child\");\n    createFileInCommand(dir, \"a.txt\", \"content\");\n    renameFileInCommand(dir, \"newchild\");\n    verify(runSvn(\"status\"), \"A newchild\", \"A newchild\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"37fb6c2429927118ad5ca1888d17bcba7bfa9e6f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public ApplyPatchStatus applyModifications(final CharSequence text, final StringBuilder newText) throws ApplyPatchException {\n    List<String> lines = new ArrayList<String>();\n    Collections.addAll(lines, LineTokenizer.tokenize(text, false));\n    ApplyPatchStatus result = null;\n    for(PatchHunk hunk: myHunks) {\n      result = ApplyPatchStatus.and(result, hunk.apply(lines));\n    }\n    for(String line: lines) {\n      newText.append(line).append(\"\\n\");\n    }\n    return result;\n  }","id":14324,"modified_method":"public ApplyPatchStatus applyModifications(final CharSequence text, final StringBuilder newText) throws ApplyPatchException {\n    if (myHunks.size() == 0) {\n      return ApplyPatchStatus.SUCCESS;\n    }\n    List<String> lines = new ArrayList<String>();\n    Collections.addAll(lines, LineTokenizer.tokenize(text, false));\n    ApplyPatchStatus result = null;\n    for(PatchHunk hunk: myHunks) {\n      result = ApplyPatchStatus.and(result, hunk.apply(lines));\n    }\n    for(int i=0; i<lines.size(); i++) {\n      newText.append(lines.get(i));\n      if (i < lines.size()-1 || !myHunks.get(myHunks.size()-1).isNoNewLineAtEnd()) {\n        newText.append(\"\\n\");\n      }\n    }\n    return result;\n  }","commit_id":"1e644343da95ee76e1ce293a33e43c31814432c6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private PatchHunk readNextHunkContext() throws PatchSyntaxException {\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      if (curLine.startsWith(CONTEXT_FILE_PREFIX)) {\n        return null;\n      }\n      if (curLine.startsWith(CONTEXT_HUNK_PREFIX)) {\n        break;\n      }\n      myLineIndex++;\n    }\n    if (myLineIndex == myLines.length) {\n      return null;\n    }\n    myLineIndex++;\n    Matcher beforeMatcher = ourContextBeforeHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!beforeMatcher.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown before hunk start syntax\");\n    }\n    myLineIndex++;\n    List<String> beforeLines = readContextDiffLines();\n    if (myLineIndex == myLines.length) {\n      throw new PatchSyntaxException(myLineIndex, \"Missing after hunk\");\n    }\n    Matcher afterMatcher = ourContextAfterHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!afterMatcher.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown after hunk start syntax\");\n    }\n    myLineIndex++;\n    List<String> afterLines = readContextDiffLines();\n    int startLineBefore = Integer.parseInt(beforeMatcher.group(1));\n    int endLineBefore = Integer.parseInt(beforeMatcher.group(2));\n    int startLineAfter = Integer.parseInt(afterMatcher.group(1));\n    int endLineAfter = Integer.parseInt(afterMatcher.group(2));\n    PatchHunk hunk = new PatchHunk(startLineBefore, endLineBefore, startLineAfter, endLineAfter);\n\n    int beforeLineIndex = 0;\n    int afterLineIndex = 0;\n    if (beforeLines.size() == 0) {\n      for(String line: afterLines) {\n        hunk.addLine(parsePatchLine(line, 2));\n      }\n    }\n    else if (afterLines.size() == 0) {\n      for(String line: beforeLines) {\n        hunk.addLine(parsePatchLine(line, 2));\n      }\n    }\n    else {\n      while(beforeLineIndex < beforeLines.size() && afterLineIndex < afterLines.size()) {\n        String beforeLine = beforeLines.get(beforeLineIndex);\n        String afterLine = afterLines.get(afterLineIndex);\n        if (beforeLine.startsWith(\" \") && afterLine.startsWith(\" \")) {\n          addContextDiffLine(hunk, beforeLine, PatchLine.Type.CONTEXT);\n          beforeLineIndex++;\n          afterLineIndex++;\n        }\n        else if (beforeLine.startsWith(\"-\")) {\n          addContextDiffLine(hunk, beforeLine, PatchLine.Type.REMOVE);\n          beforeLineIndex++;\n        }\n        else if (afterLine.startsWith(\"+\")) {\n          addContextDiffLine(hunk, afterLine, PatchLine.Type.ADD);\n          afterLineIndex++;\n        }\n        else if (beforeLine.startsWith(\"!\") && afterLine.startsWith(\"!\")) {\n          while(beforeLineIndex < beforeLines.size() && beforeLines.get(beforeLineIndex).startsWith(\"! \")) {\n            addContextDiffLine(hunk, beforeLines.get(beforeLineIndex), PatchLine.Type.REMOVE);\n            beforeLineIndex++;\n          }\n\n          while(afterLineIndex < afterLines.size() && afterLines.get(afterLineIndex).startsWith(\"! \")) {\n            addContextDiffLine(hunk, afterLines.get(afterLineIndex), PatchLine.Type.ADD);\n            afterLineIndex++;\n          }\n        }\n        else {\n          throw new PatchSyntaxException(-1, \"Unknown line prefix\");\n        }\n      }\n    }\n    return hunk;\n  }","id":14325,"modified_method":"@Nullable\n  private PatchHunk readNextHunkContext() throws PatchSyntaxException {\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      if (curLine.startsWith(CONTEXT_FILE_PREFIX)) {\n        return null;\n      }\n      if (curLine.startsWith(CONTEXT_HUNK_PREFIX)) {\n        break;\n      }\n      myLineIndex++;\n    }\n    if (myLineIndex == myLines.length) {\n      return null;\n    }\n    myLineIndex++;\n    Matcher beforeMatcher = ourContextBeforeHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!beforeMatcher.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown before hunk start syntax\");\n    }\n    myLineIndex++;\n    List<String> beforeLines = readContextDiffLines();\n    if (myLineIndex == myLines.length) {\n      throw new PatchSyntaxException(myLineIndex, \"Missing after hunk\");\n    }\n    Matcher afterMatcher = ourContextAfterHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!afterMatcher.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown after hunk start syntax\");\n    }\n    myLineIndex++;\n    List<String> afterLines = readContextDiffLines();\n    int startLineBefore = Integer.parseInt(beforeMatcher.group(1));\n    int endLineBefore = Integer.parseInt(beforeMatcher.group(2));\n    int startLineAfter = Integer.parseInt(afterMatcher.group(1));\n    int endLineAfter = Integer.parseInt(afterMatcher.group(2));\n    PatchHunk hunk = new PatchHunk(startLineBefore, endLineBefore, startLineAfter, endLineAfter);\n\n    int beforeLineIndex = 0;\n    int afterLineIndex = 0;\n    PatchLine lastBeforePatchLine = null;\n    PatchLine lastAfterPatchLine = null;\n    if (beforeLines.size() == 0) {\n      for(String line: afterLines) {\n        hunk.addLine(parsePatchLine(line, 2));\n      }\n    }\n    else if (afterLines.size() == 0) {\n      for(String line: beforeLines) {\n        hunk.addLine(parsePatchLine(line, 2));\n      }\n    }\n    else {\n      while(beforeLineIndex < beforeLines.size() || afterLineIndex < afterLines.size()) {\n        String beforeLine = beforeLineIndex >= beforeLines.size() ? null : beforeLines.get(beforeLineIndex);\n        String afterLine = afterLineIndex >= afterLines.size() ? null : afterLines.get(afterLineIndex);\n        if (startsWith(beforeLine, NO_NEWLINE_SIGNATURE) && lastBeforePatchLine != null) {\n          lastBeforePatchLine.setSuppressNewLine(true);\n          beforeLineIndex++;\n        }\n        else if (startsWith(afterLine, NO_NEWLINE_SIGNATURE) && lastAfterPatchLine != null) {\n          lastAfterPatchLine.setSuppressNewLine(true);\n          afterLineIndex++;\n        }\n        else if (startsWith(beforeLine, \" \") && startsWith(afterLine, \" \")) {\n          addContextDiffLine(hunk, beforeLine, PatchLine.Type.CONTEXT);\n          beforeLineIndex++;\n          afterLineIndex++;\n        }\n        else if (startsWith(beforeLine, \"-\")) {\n          lastBeforePatchLine = addContextDiffLine(hunk, beforeLine, PatchLine.Type.REMOVE);\n          beforeLineIndex++;\n        }\n        else if (startsWith(afterLine, \"+\")) {\n          lastAfterPatchLine = addContextDiffLine(hunk, afterLine, PatchLine.Type.ADD);\n          afterLineIndex++;\n        }\n        else if (startsWith(beforeLine, \"!\") && startsWith(afterLine, \"!\")) {\n          while(beforeLineIndex < beforeLines.size() && beforeLines.get(beforeLineIndex).startsWith(\"! \")) {\n            lastBeforePatchLine = addContextDiffLine(hunk, beforeLines.get(beforeLineIndex), PatchLine.Type.REMOVE);\n            beforeLineIndex++;\n          }\n\n          while(afterLineIndex < afterLines.size() && afterLines.get(afterLineIndex).startsWith(\"! \")) {\n            lastAfterPatchLine = addContextDiffLine(hunk, afterLines.get(afterLineIndex), PatchLine.Type.ADD);\n            afterLineIndex++;\n          }\n        }\n        else {\n          throw new PatchSyntaxException(-1, \"Unknown line prefix\");\n        }\n      }\n    }\n    return hunk;\n  }","commit_id":"1e644343da95ee76e1ce293a33e43c31814432c6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private PatchHunk readNextHunkUnified() throws PatchSyntaxException {\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      if (curLine.startsWith(\"--- \")) {\n        return null;\n      }\n      if (curLine.startsWith(\"@@ \")) {\n        break;\n      }\n      myLineIndex++;\n    }\n    if (myLineIndex == myLines.length) {\n      return null;\n    }\n\n    Matcher m = ourUnifiedHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!m.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown hunk start syntax\");\n    }\n    int startLineBefore = Integer.parseInt(m.group(1));\n    int endLineBefore = Integer.parseInt(m.group(2));\n    int startLineAfter = Integer.parseInt(m.group(3));\n    int endLineAfter = Integer.parseInt(m.group(4));\n    PatchHunk hunk = new PatchHunk(startLineBefore, endLineBefore, startLineAfter, endLineAfter);\n    myLineIndex++;\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      final PatchLine line = parsePatchLine(curLine, 1);\n      if (line == null) {\n        break;\n      }\n      hunk.addLine(line);\n      myLineIndex++;\n    }\n    return hunk;\n  }","id":14326,"modified_method":"@Nullable\n  private PatchHunk readNextHunkUnified() throws PatchSyntaxException {\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      if (curLine.startsWith(\"--- \")) {\n        return null;\n      }\n      if (curLine.startsWith(\"@@ \")) {\n        break;\n      }\n      myLineIndex++;\n    }\n    if (myLineIndex == myLines.length) {\n      return null;\n    }\n\n    Matcher m = ourUnifiedHunkStartPattern.matcher(myLines [myLineIndex]);\n    if (!m.matches()) {\n      throw new PatchSyntaxException(myLineIndex, \"Unknown hunk start syntax\");\n    }\n    int startLineBefore = Integer.parseInt(m.group(1));\n    int endLineBefore = Integer.parseInt(m.group(2));\n    int startLineAfter = Integer.parseInt(m.group(3));\n    int endLineAfter = Integer.parseInt(m.group(4));\n    PatchHunk hunk = new PatchHunk(startLineBefore, endLineBefore, startLineAfter, endLineAfter);\n    myLineIndex++;\n    PatchLine lastLine = null;\n    while(myLineIndex < myLines.length) {\n      String curLine = myLines [myLineIndex];\n      if (lastLine != null && curLine.startsWith(NO_NEWLINE_SIGNATURE)) {\n        lastLine.setSuppressNewLine(true);\n        myLineIndex++;\n        continue;\n      }\n      lastLine = parsePatchLine(curLine, 1);\n      if (lastLine == null) {\n        break;\n      }\n      hunk.addLine(lastLine);\n      myLineIndex++;\n    }\n    return hunk;\n  }","commit_id":"1e644343da95ee76e1ce293a33e43c31814432c6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private List<String> readContextDiffLines() {\n    ArrayList<String> result = new ArrayList<String>();\n    while(myLineIndex < myLines.length) {\n      final String line = myLines[myLineIndex];\n      if (!line.startsWith(\" \") && !line.startsWith(\"+ \") && !line.startsWith(\"- \") && !line.startsWith(\"! \")) {\n        break;\n      }\n      result.add(line);\n      myLineIndex++;\n    }\n    return result;\n  }","id":14327,"modified_method":"private List<String> readContextDiffLines() {\n    ArrayList<String> result = new ArrayList<String>();\n    while(myLineIndex < myLines.length) {\n      final String line = myLines[myLineIndex];\n      if (!line.startsWith(\" \") && !line.startsWith(\"+ \") && !line.startsWith(\"- \") && !line.startsWith(\"! \") &&\n          !line.startsWith(NO_NEWLINE_SIGNATURE)) {\n        break;\n      }\n      result.add(line);\n      myLineIndex++;\n    }\n    return result;\n  }","commit_id":"1e644343da95ee76e1ce293a33e43c31814432c6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void addContextDiffLine(final PatchHunk hunk, final String line, final PatchLine.Type type) {\n    hunk.addLine(new PatchLine(type, line.length() < 2 ? \"\" : line.substring(2)));\n  }","id":14328,"modified_method":"private static PatchLine addContextDiffLine(final PatchHunk hunk, final String line, final PatchLine.Type type) {\n    final PatchLine patchLine = new PatchLine(type, line.length() < 2 ? \"\" : line.substring(2));\n    hunk.addLine(patchLine);\n    return patchLine;\n  }","commit_id":"1e644343da95ee76e1ce293a33e43c31814432c6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static String propertyTagAction(String property, String action, String defaultValue, CmsFlexRequest req) \n    throws CmsException\n    {\n        String result = null;\n        \n        if (\"parent\".equals(action)) {                    \n            // Read properties of parent (i.e. top requested) file\n            result = CmsPropertyLookup.lookupProperty(req.getCmsObject(), req.getCmsRequestedResource(), property, false);                  \n        } else if (\"this\".equals(action)) {\n            // Read properties of this file\n            result = CmsPropertyLookup.lookupProperty(req.getCmsObject(), req.getCmsResource(), property, false);\n        } else if (\"search-this\".equals(action)) {\n            // Try to find property on this file and all parent folders\n            result = CmsPropertyLookup.lookupProperty(req.getCmsObject(), req.getCmsResource(), property, true);\n        } else if (\"search-parent\".equals(action) || \"search\".equals(action)) {\n            // Try to find property on parent file and all parent folders\n            result = CmsPropertyLookup.lookupProperty(req.getCmsObject(), req.getCmsRequestedResource(), property, true);\n        } else {\n            // Read properties of the file named in the attribute\n            result = CmsPropertyLookup.lookupProperty(req.getCmsObject(), req.toAbsolute(action), property, false);                  \n        }\n\n        if ((defaultValue != null) && (result == null)) {\n            result = defaultValue;\n        }\n                        \n        return result;\n    }","id":14329,"modified_method":"public static String propertyTagAction(String property, String action, String defaultValue, CmsFlexRequest req) \n    throws CmsException\n    {\n        // Make sure that no null String is returned\n        if (defaultValue == null) defaultValue = \"\";\n        \n        if (\"parent\".equals(action)) {                    \n            // Read properties of parent (i.e. top requested) file\n            return req.getCmsObject().readProperty(req.getCmsRequestedResource(), property, false, defaultValue);                  \n        } else if (\"this\".equals(action)) {\n            // Read properties of this file\n            return  req.getCmsObject().readProperty(req.getCmsResource(), property, false, defaultValue);\n        } else if (\"search-this\".equals(action)) {\n            // Try to find property on this file and all parent folders\n            return req.getCmsObject().readProperty(req.getCmsResource(), property, true, defaultValue);\n        } else if (\"search-parent\".equals(action) || \"search\".equals(action)) {\n            // Try to find property on parent file and all parent folders\n            return  req.getCmsObject().readProperty(req.getCmsRequestedResource(), property, true, defaultValue);\n        } else {\n            // Read properties of the file named in the attribute\n            return  req.getCmsObject().readProperty(req.toAbsolute(action), property, false, defaultValue);\n        }\n    }","commit_id":"a41d09bda3121cfc81e0286786b49c6cf2b650be","url":"https://github.com/alkacon/opencms-core"},{"original_method":"public Address release( ) {\n    this.transition( State.allocated, State.unallocated, false, true, new SplitTransition( Transition.unallocating ) {\n      public void top( ) {\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_RELEASE ).withDetails( Address.this.userId, Address.this.name, \"type\", Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = UNALLOCATED_USERID;\n        Address.removeAddress( Address.this.name );\n        Address.this.state.attemptMark( State.unallocated, false );\n      }\n      \n      public void bottom( ) {}\n    } );\n    return this;\n  }","id":14330,"modified_method":"public Address release( ) {\n    SplitTransition release = new SplitTransition( Transition.unallocating ) {\n      public void top( ) {\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_RELEASE ).withDetails( Address.this.userId, Address.this.name, \"type\", Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = UNALLOCATED_USERID;\n        Address.removeAddress( Address.this.name );\n        Address.this.state.attemptMark( State.unallocated, false );\n      }\n      \n      public void bottom( ) {}\n    };\n    if( State.impending.equals( this.state.getReference( ) ) ) {\n      this.transition( State.impending, State.unallocated, true, true, release );\n    } else {\n      this.transition( State.allocated, State.unallocated, false, true, release );\n    }    \n    return this;\n  }","commit_id":"f300f8fad88443b66528c426efdfa12a081f8863","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address unassign( ) {\n    this.transition( State.assigned, State.allocated, false, true, //\n                     new SplitTransition( Transition.unassigning ) {\n                       public void top( ) {\n                         String userId = Address.this.userId;\n                         try {\n                           VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n                           EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGNING )\n                                      .withDetails( vm.getOwnerId( ), Address.this.getName( ), \"instanceid\", vm.getInstanceId( ) )\n                                      .withDetails( \"type\", Address.this.isSystemOwned( )\n                                        ? \"SYSTEM\"\n                                        : \"USER\" )\n                                      .withDetails( \"cluster\", Address.this.getCluster( ) ).info( );\n                         } catch ( NoSuchElementException e ) {}\n                         EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN )\n                                    .withDetails( userId, Address.this.name, \"instance\", Address.this.instanceId )\n                                    .withDetails( \"instance-address\", Address.this.instanceAddress ).withDetails( \"type\", Address.this.isSystemOwned( )\n                                      ? \"SYSTEM\"\n                                      : \"USER\" ).info( );\n                       }\n                       \n                       public void bottom( ) {\n                         Address.this.instanceId = UNASSIGNED_INSTANCEID;\n                         Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n                       }\n                     } );\n    return this;\n  }","id":14331,"modified_method":"public Address unassign( ) {\n    SplitTransition unassign = new SplitTransition( Transition.unassigning ) {\n      public void top( ) {\n        String userId = Address.this.userId;\n        try {\n          VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n          EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGNING )\n                     .withDetails( vm.getOwnerId( ), Address.this.getName( ), \"instanceid\", vm.getInstanceId( ) )\n                     .withDetails( \"type\", Address.this.isSystemOwned( )\n                       ? \"SYSTEM\"\n                       : \"USER\" )\n                     .withDetails( \"cluster\", Address.this.getCluster( ) ).info( );\n        } catch ( NoSuchElementException e ) {}\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN )\n                   .withDetails( userId, Address.this.name, \"instance\", Address.this.instanceId )\n                   .withDetails( \"instance-address\", Address.this.instanceAddress ).withDetails( \"type\", Address.this.isSystemOwned( )\n                     ? \"SYSTEM\"\n                     : \"USER\" ).info( );\n      }\n      \n      public void bottom( ) {\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n      }\n    };\n    if( State.impending.equals( this.state.getReference( ) ) ) {\n      this.transition( State.impending, State.allocated, true, true, unassign );\n    } else {\n      this.transition( State.assigned, State.allocated, false, true, unassign );\n    }\n    return this;\n  }","commit_id":"f300f8fad88443b66528c426efdfa12a081f8863","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"/**\n   * Fire the response on all listeners.\n   * \n   * @param response\n   */\n  @Override\n  public void fire( R response ) {\n    for ( Callback<R> cb : this.successCallbacks ) {\n      try {\n        EventRecord.here( cb.getClass( ), EventType.CALLBACK, \"fire(\" + response.getClass( ).toString( ) + \")\" ).debug( );\n        cb.fire( response );\n      } catch ( Throwable t ) {\n        LOG.error( \"Exception occurred while trying to call: \" + cb.getClass( ).getSimpleName( ) + \".apply( \" + t.getMessage( ) + \" )\" );\n        LOG.error( t, t );\n      }\n    }\n  }","id":14332,"modified_method":"/**\n   * Fire the response on all listeners.\n   * \n   * @param response\n   */\n  @Override\n  public void fire( R response ) {\n    for ( Callback<R> cb : this.successCallbacks ) {\n      try {\n        EventRecord.here( cb.getClass( ), EventType.CALLBACK, \"fire(\" + response.getClass( ).getName( ) + \")\" ).debug( );\n        cb.fire( response );\n      } catch ( Throwable t ) {\n        LOG.error( \"Exception occurred while trying to call: \" + cb.getClass( ).getSimpleName( ) + \".apply( \" + t.getMessage( ) + \" )\" );\n        LOG.error( t, t );\n      }\n    }\n  }","commit_id":"f300f8fad88443b66528c426efdfa12a081f8863","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"/**\n   * Trigger the failure case.\n   * \n   * @param t\n   */\n  @Override\n  public void fireException( Throwable t ) {\n    for ( Callback cb : this.failureCallbacks ) {\n      try {\n        EventRecord.here( cb.getClass( ), EventType.CALLBACK, \"fireException(\" + t.getClass( ).getSimpleName( ) + \")\" ).debug( );\n        cb.fire( t );\n      } catch ( Throwable t2 ) {\n        LOG.error( \"Exception occurred while trying to call: \" + cb.getClass( ).toString( ) + \".failure( \" + t.getMessage( ) + \" )\" );\n        LOG.error( t2, t2 );\n      }\n    }\n  }","id":14333,"modified_method":"/**\n   * Trigger the failure case.\n   * \n   * @param t\n   */\n  @Override\n  public void fireException( Throwable t ) {\n    for ( Callback cb : this.failureCallbacks ) {\n      try {\n        EventRecord.here( cb.getClass( ), EventType.CALLBACK, \"fireException(\" + t.getClass( ).getName( ) + \")\" ).debug( );\n        cb.fire( t );\n      } catch ( Throwable t2 ) {\n        LOG.error( \"Exception occurred while trying to call: \" + cb.getClass( ).toString( ) + \".failure( \" + t.getMessage( ) + \" )\" );\n        LOG.error( t2, t2 );\n      }\n    }\n  }","commit_id":"f300f8fad88443b66528c426efdfa12a081f8863","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private static void markAsAllocated( Cluster cluster, ClusterAddressInfo addrInfo, Address address ) {\n      address.allocate( Component.eucalyptus.name( ) );\n      try {\n        address.clearPending( );\n      } catch ( IllegalStateException e ) {/* might not be pending still valid. */}\n      cluster.getState( ).clearOrphan( addrInfo );\n    }","id":14334,"modified_method":"private static void markAsAllocated( Cluster cluster, ClusterAddressInfo addrInfo, Address address ) {\n      try {\n        address.allocate( Component.eucalyptus.name( ) );\n        address.clearPending( );\n        cluster.getState( ).clearOrphan( addrInfo );\n      } catch ( IllegalStateException e ) {\n        LOG.error( e, e );\n      }\n    }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address( String address, String cluster, String userId, String instanceId, String instanceAddress ) {\n    this( address );\n    this.cluster = cluster;\n    this.userId = userId;\n    this.instanceId = instanceId;\n    this.instanceAddress = instanceAddress;\n    this.transition = QUIESCENT;\n    this.state = new AtomicMarkableReference<State>( State.unallocated, false );\n    this.init( );\n  }","id":14335,"modified_method":"public Address( String address, String cluster, String userId, String instanceId, String instanceAddress ) {\n    this( address );\n    this.cluster = cluster;\n    this.userId = userId;\n    this.instanceId = instanceId;\n    this.instanceAddress = instanceAddress;\n    this.transition = QUIESCENT;\n    this.init( );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public DescribeAddressesResponseItemType getDescription( boolean isAdmin ) {\n    String name = this.getName( );\n    String desc = null;\n    if ( isAdmin ) {\n      desc = String.format( \"%s (%s)\", this.getInstanceId( ), this.getUserId( ) );\n    } else {\n      desc = UNASSIGNED_INSTANCEID.equals( this.getInstanceId( ) ) ? null : this.getInstanceId( );\n    }\n    return new DescribeAddressesResponseItemType( name, desc );\n  }","id":14336,"modified_method":"public DescribeAddressesResponseItemType getDescription( boolean isAdmin ) {\n    String name = this.getName( );\n    String desc = null;\n    if ( isAdmin ) {\n      desc = String.format( \"%s (%s)\", PENDING_ASSIGNMENT.equals( this.getInstanceId( ) ) ? UNASSIGNED_INSTANCEID : this.getInstanceId( ), this.getUserId( ) );\n    } else {\n      desc = UNASSIGNED_INSTANCEID.equals( this.getInstanceId( ) ) || PENDING_ASSIGNMENT.equals( this.getInstanceId( ) ) ? null : this.getInstanceId( );\n    }\n    return new DescribeAddressesResponseItemType( name, desc );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address pendingAssignment( ) {\n    this.transition( State.allocated, State.impending, false, true, //\n                     new SplitTransition( Transition.system ) {\n                       public void bottom( ) {\n                         Address.this.state.set( State.allocated, false );\n                       }\n                       \n                       public void top( ) {}\n                     } );\n    return this;\n  }","id":14337,"modified_method":"public Address pendingAssignment( ) {\n    this.transition( State.unallocated, State.impending, false, true, new SplitTransition( Transition.allocating ) {\n      public void top( ) {\n        Address.this.instanceId = PENDING_ASSIGNMENT;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = \"eucalyptus\";\n        try {\n          Addresses.getInstance( ).enable( Address.this.name );\n        } catch ( NoSuchElementException e ) {\n          try {\n            Addresses.getInstance( ).register( Address.this );\n          } catch ( NoSuchElementException e1 ) {\n            LOG.debug( e );\n          }\n        }\n      }\n    } );\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public String toString( ) {\n    return LogUtil.dumpObject( this );\n  }","id":14338,"modified_method":"@Override\n  public String toString( ) {\n    return LogUtil.dumpObject( this ).replaceAll( \"\\\\w*=\\\\s\", \"\" );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public void init( ) {//Should only EVER be called externally after loading from the db\n    this.state = new AtomicMarkableReference<State>( State.unallocated, false );\n    this.transition = QUIESCENT;\n    if ( this.userId == null ) {\n      this.userId = UNALLOCATED_USERID;\n    }\n    if ( this.instanceAddress == null || this.instanceId == null ) {\n      this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n      this.instanceId = UNASSIGNED_INSTANCEID;\n    }\n    if ( UNALLOCATED_USERID.equals( this.userId ) ) {\n      this.state.set( State.unallocated, true );\n      this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n      this.instanceId = UNASSIGNED_INSTANCEID;\n      Addresses.getInstance( ).registerDisabled( this );\n      this.state.set( State.unallocated, false );\n    } else if ( !this.instanceId.equals( UNASSIGNED_INSTANCEID ) ) {\n      this.state.set( State.assigned, true );\n      Addresses.getInstance( ).register( this );\n      this.state.set( State.assigned, false );\n    } else {\n      this.state.set( State.allocated, true );\n      if ( this.isSystemOwned( ) ) {\n        Addresses.getInstance( ).registerDisabled( this );\n        this.userId = UNALLOCATED_USERID;\n        this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.removeAddress( this.name );\n        this.state.set( State.unallocated, false );\n      } else {\n        Addresses.getInstance( ).register( this );\n        this.state.set( State.allocated, false );\n      }\n    }\n    LOG.debug( \"Initialized address: \" + this.toString( ) );\n  }","id":14339,"modified_method":"public void init( ) {//Should only EVER be called externally after loading from the db\n    this.transition = QUIESCENT;\n    if ( this.userId == null ) {\n      this.userId = UNALLOCATED_USERID;\n    }\n    if ( this.instanceAddress == null || this.instanceId == null ) {\n      this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n      this.instanceId = UNASSIGNED_INSTANCEID;\n    }\n    if ( UNALLOCATED_USERID.equals( this.userId ) ) {\n      this.state.set( State.unallocated, true );\n      this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n      this.instanceId = UNASSIGNED_INSTANCEID;\n      Addresses.getInstance( ).registerDisabled( this );\n      this.state.set( State.unallocated, false );\n    } else if ( !this.instanceId.equals( UNASSIGNED_INSTANCEID ) ) {\n      this.state.set( State.assigned, true );\n      Addresses.getInstance( ).register( this );\n      this.state.set( State.assigned, false );\n    } else {\n      this.state.set( State.allocated, true );\n      if ( this.isSystemOwned( ) ) {\n        Addresses.getInstance( ).registerDisabled( this );\n        this.userId = UNALLOCATED_USERID;\n        this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.removeAddress( this.name );\n        this.state.set( State.unallocated, false );\n      } else {\n        Addresses.getInstance( ).register( this );\n        this.state.set( State.allocated, false );\n      }\n    }\n    LOG.debug( \"Initialized address: \" + this.toString( ) );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address unassign( ) {\n    this.transition( State.assigned, State.allocated, false, true, //\n                     new SplitTransition( Transition.unassigning ) {\n                       public void top( ) {\n                         if ( !Address.this.isSystemOwned( ) ) {\n                           EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=\" + Address.this.userId )\n                                      .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                      .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                         } else {\n                           try {\n                             VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n                             EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=\" + vm.getOwnerId( ) )\n                                        .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                        .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                           } catch ( NoSuchElementException e ) {\n                             EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=<unknown>\" )\n                                        .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                        .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                           }\n                         }\n                       }\n                       \n                       public void bottom( ) {\n                         Address.this.instanceId = UNASSIGNED_INSTANCEID;\n                         Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n                       }\n                     } );\n    return this;\n  }","id":14340,"modified_method":"public Address unassign( ) {\n    if( this.isSystemOwned( ) ) {\n      this.transition( State.assigned, State.unallocated, false, true, //\n                       new SplitTransition( Transition.unassigning ) {\n                         @Override\n                         public void top( ) {}\n                         \n                         @Override\n                         public void bottom( ) {\n                           EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=\" + Address.this.userId )\n                           .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                           .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                           Address.this.instanceId = UNASSIGNED_INSTANCEID;\n                           Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n                           Address.this.userId = UNALLOCATED_USERID;\n                           Address.removeAddress( Address.this.name );\n                           super.bottom( );\n                         }\n                       } );\n    } else {\n      this.transition( State.assigned, State.allocated, false, true, new SplitTransition( Transition.unassigning ) {\n        public void top( ) {}\n        public void bottom( ) {\n          try {\n            VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n            EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=\" + vm.getOwnerId( ) )\n                       .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                       .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n          } catch ( NoSuchElementException e ) {\n            EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_UNASSIGN, \"user=<unknown>\" )\n                       .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                       .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n          }\n          Address.this.instanceId = UNASSIGNED_INSTANCEID;\n          Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n          super.bottom( );\n        }\n      } );\n    }\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address allocate( final String userId ) {\n    this.transition( State.unallocated, State.allocated, false, true, new SplitTransition( Transition.allocating ) {\n      public void top( ) {\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = userId;\n        Address.addAddress( Address.this );\n        try {\n          Addresses.getInstance( ).register( Address.this );\n        } catch ( NoSuchElementException e ) {\n          LOG.debug( e );\n        }\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ALLOCATE, \"user=\" + Address.this.userId, \"address=\" + Address.this.name,\n                          Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.state.attemptMark( State.allocated, false );\n      }\n      \n      public void bottom( ) {}\n    } );\n    return this;\n  }","id":14341,"modified_method":"public Address allocate( final String userId ) {\n    this.transition( State.unallocated, State.allocated, false, true, new SplitTransition( Transition.allocating ) {\n      public void top( ) {\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = userId;\n        try {\n          Addresses.getInstance( ).enable( Address.this.name );\n        } catch ( NoSuchElementException e ) {\n          try {\n            Addresses.getInstance( ).register( Address.this );\n          } catch ( NoSuchElementException e1 ) {\n            LOG.debug( e );\n          }\n        }\n        if( !Address.this.isSystemOwned( ) ) {\n          Address.addAddress( Address.this );\n        }\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ALLOCATE, \"user=\" + Address.this.userId, \"address=\" + Address.this.name,\n                          Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.state.attemptMark( State.allocated, false );\n        super.bottom( );\n      }\n      \n      public void bottom( ) {}\n    } );\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address assign( final String instanceId, final String instanceAddr ) {\n    this.state.compareAndSet( State.impending, State.allocated, true, false );\n    this.transition( State.allocated, State.assigned, false, true, //\n                     new SplitTransition( Transition.assigning ) {\n                       public void top( ) {\n                         Address.this.setInstanceId( instanceId );\n                         Address.this.setInstanceAddress( instanceAddr );\n                       }\n                       \n                       public void bottom( ) {\n                         if ( !Address.this.isSystemOwned( ) ) {\n                           EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=\"+Address.this.userId ) \n                             .append( \"address=\"+Address.this.name, \"instance=\"+Address.this.instanceId, \"instance-address=\" )\n                             .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                         } else {\n                           try {\n                             VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n                             EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=\" + vm.getOwnerId( ) )\n                                        .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                        .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                           } catch ( NoSuchElementException e ) {\n                             EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=<unknown>\" )\n                                        .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                        .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                           }\n                         }\n                       }\n                     } );\n    return this;\n  }","id":14342,"modified_method":"public Address assign( final String instanceId, final String instanceAddr ) {\n    if( this.state.compareAndSet( State.impending, State.impending, true, true ) ) {\n      this.transition( State.impending, State.assigned, true, true, //\n                       new SplitTransition( Transition.assigning ) {\n                         public void top( ) {\n                           Address.this.setInstanceId( instanceId );\n                           Address.this.setInstanceAddress( instanceAddr );\n                         }\n\n                        @Override\n                        public void bottom( ) {\n                          EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=\"+Address.this.userId ) \n                          .append( \"address=\"+Address.this.name, \"instance=\"+Address.this.instanceId, \"instance-address=\" )\n                          .append( Address.this.instanceAddress, \"SYSTEM\" ).info( );\n                          super.bottom( );\n                        }\n                       } );\n    } else {\n      this.transition( State.allocated, State.assigned, false, true, //\n                       new SplitTransition( Transition.assigning ) {\n                         public void top( ) {\n                           Address.this.setInstanceId( instanceId );\n                           Address.this.setInstanceAddress( instanceAddr );\n                         }\n\n                        @Override\n                        public void bottom( ) {\n                          try {\n                            VmInstance vm = VmInstances.getInstance( ).lookup( Address.this.getInstanceId( ) );\n                            EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=\" + vm.getOwnerId( ) )\n                                       .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                       .append( Address.this.instanceAddress, \"USER\" ).info( );\n                          } catch ( NoSuchElementException e ) {\n                            EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_ASSIGN, \"user=<unknown>\" )\n                                       .append( \"address=\" + Address.this.name, \"instance=\" + Address.this.instanceId, \"instance-address=\" )\n                                       .append( Address.this.instanceAddress, \"USER\" ).info( );\n                          }\n                          super.bottom( );\n                        }\n                         \n                       } );\n    }\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address clearPending( ) {\n    if ( !this.state.isMarked( ) ) {\n      throw new IllegalStateException( \"Trying to clear an address which is not currently pending.\" );\n    } else {\n      EventRecord\n                 .caller( this.getClass( ), EventType.ADDRESS_STATE, this.state.getReference( ), \"BOTTOM\", this.transition.getName( ).name( ), this.toString( ) )\n                 .debug( );\n      try {\n        this.transition.bottom( );\n      } finally {\n        this.transition = QUIESCENT;\n        this.state.set( this.state.getReference( ), false );\n      }\n    }\n    return this;\n  }","id":14343,"modified_method":"public Address clearPending( ) {\n    if ( !this.state.isMarked( ) ) {\n      throw new IllegalStateException( \"Trying to clear an address which is not currently pending.\" );\n    } else {\n      EventRecord.caller( this.getClass( ), EventType.ADDRESS_STATE, this.state.getReference( ), \"BOTTOM\", this.transition.getName( ).name( ), this.toString( ) )\n                 .debug( );\n      try {\n        this.transition.bottom( );\n      } finally {\n        this.transition = QUIESCENT;\n      }\n    }\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public abstract void bottom( );","id":14344,"modified_method":"public void bottom( ) {\n      Address.this.state.set( Address.this.state.getReference( ), false );        \n    }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address( String address, String cluster ) {\n    this( address );\n    this.userId = UNALLOCATED_USERID;\n    this.instanceId = UNASSIGNED_INSTANCEID;\n    this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n    this.cluster = cluster;\n    this.transition = QUIESCENT;\n    this.state = new AtomicMarkableReference<State>( State.unallocated, false );\n    this.init( );\n  }","id":14345,"modified_method":"public Address( String address, String cluster ) {\n    this( address );\n    this.userId = UNALLOCATED_USERID;\n    this.instanceId = UNASSIGNED_INSTANCEID;\n    this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n    this.cluster = cluster;\n    this.transition = QUIESCENT;\n    this.init( );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public Address release( ) {\n    this.transition( State.allocated, State.unallocated, false, true, new SplitTransition( Transition.unallocating ) {\n      public void top( ) {\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_RELEASE, \"user=\" + Address.this.userId, \"address=\" + Address.this.name,\n                          Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = UNALLOCATED_USERID;\n        Address.removeAddress( Address.this.name );\n        Address.this.state.attemptMark( State.unallocated, false );\n      }\n      \n      public void bottom( ) {}\n    } );\n    return this;\n  }","id":14346,"modified_method":"public Address release( ) {\n    SplitTransition release = new SplitTransition( Transition.unallocating ) {\n      public void top( ) {\n        EventRecord.here( Address.class, EventClass.ADDRESS, EventType.ADDRESS_RELEASE, \"user=\" + Address.this.userId, \"address=\" + Address.this.name,\n                          Address.this.isSystemOwned( ) ? \"SYSTEM\" : \"USER\" ).info( );\n        Address.this.instanceId = UNASSIGNED_INSTANCEID;\n        Address.this.instanceAddress = UNASSIGNED_INSTANCEADDR;\n        Address.this.userId = UNALLOCATED_USERID;\n        Address.removeAddress( Address.this.name );\n        super.bottom( );\n      }\n    };\n    if( State.impending.equals( this.state.getReference( ) ) ) {\n      this.transition( State.impending, State.unallocated, true, true, release );\n    } else {\n      this.transition( State.allocated, State.unallocated, false, true, release );\n    }\n    return this;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private static void addAddress( Address address ) {\n    Address addr = new Address( address.getName( ), address.getCluster( ) );\n    EntityWrapper<Address> db = new EntityWrapper<Address>( );\n    try {\n      addr = db.getUnique( new Address( address.getName( ) ) );\n      addr.setUserId( address.getUserId( ) );\n      db.commit( );\n    } catch ( Throwable e ) {\n      try {\n        db.add( address );\n        db.commit( );\n      } catch ( Throwable e1 ) {\n        db.rollback( );\n      }\n    }\n  }","id":14347,"modified_method":"private static void addAddress( Address address ) {\n    EntityWrapper<Address> db = new EntityWrapper<Address>( );\n    try {\n      Address addr = db.getUnique( new Address( address.getName( ) ) );\n      addr.setUserId( address.getUserId( ) );\n      db.commit( );\n    } catch ( Throwable e ) {\n      try {\n        db.add( address );\n        db.commit( );\n      } catch ( Throwable e1 ) {\n        db.rollback( );\n      }\n    }\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private static AbstractSystemAddressManager getProvider( ) {\n    String provider = \"\" + edu.ucsb.eucalyptus.cloud.entities.SystemConfiguration.getSystemConfiguration( ).isDoDynamicPublicAddresses( )\n                      + Iterables.all( Clusters.getInstance( ).listValues( ), new Predicate<Cluster>( ) {\n                        @Override\n                        public boolean apply( Cluster arg0 ) {\n                          return arg0.getState( ).isAddressingInitialized( ) ? arg0.getState( ).hasPublicAddressing( ) : true;\n                        }\n                      } );\n    try {\n      if ( Addresses.systemAddressManager == null ) {\n        Addresses.systemAddressManager = ( AbstractSystemAddressManager ) managerMap.get( provider ).newInstance( );\n        LOG.info( \"Setting the address manager to be: \" + systemAddressManager.getClass( ).getSimpleName( ) );\n      } else if ( !Addresses.systemAddressManager.getClass( ).equals( managerMap.get( provider ) ) ) {\n        AbstractSystemAddressManager oldMgr = Addresses.systemAddressManager;\n        Addresses.systemAddressManager = ( AbstractSystemAddressManager ) managerMap.get( provider ).newInstance( );\n        Addresses.systemAddressManager.inheritReservedAddresses( oldMgr.getReservedAddresses( ) );\n        LOG.info( \"Setting the address manager to be: \" + systemAddressManager.getClass( ).getSimpleName( ) );\n      } else {\n        Addresses.systemAddressManager.inheritReservedAddresses( Addresses.systemAddressManager.getReservedAddresses( ) );\n      }\n    } catch ( Throwable e ) {\n      LOG.debug( e, e );\n    }\n    return Addresses.systemAddressManager;\n  }","id":14348,"modified_method":"private static AbstractSystemAddressManager getProvider( ) {\n    String provider = \"\" + edu.ucsb.eucalyptus.cloud.entities.SystemConfiguration.getSystemConfiguration( ).isDoDynamicPublicAddresses( )\n                      + Iterables.all( Clusters.getInstance( ).listValues( ), new Predicate<Cluster>( ) {\n                        @Override\n                        public boolean apply( Cluster arg0 ) {\n                          return arg0.getState( ).isAddressingInitialized( ) ? arg0.getState( ).hasPublicAddressing( ) : true;\n                        }\n                      } );\n    try {\n      if ( Addresses.systemAddressManager == null ) {\n        Addresses.systemAddressManager = ( AbstractSystemAddressManager ) managerMap.get( provider ).newInstance( );\n        LOG.info( \"Setting the address manager to be: \" + systemAddressManager.getClass( ).getSimpleName( ) );\n      } else if ( !Addresses.systemAddressManager.getClass( ).equals( managerMap.get( provider ) ) ) {\n        AbstractSystemAddressManager oldMgr = Addresses.systemAddressManager;\n        Addresses.systemAddressManager = ( AbstractSystemAddressManager ) managerMap.get( provider ).newInstance( );\n        Addresses.systemAddressManager.inheritReservedAddresses( oldMgr.getReservedAddresses( ) );\n        LOG.info( \"Setting the address manager to be: \" + systemAddressManager.getClass( ).getSimpleName( ) );\n      } \n    } catch ( Throwable e ) {\n      LOG.debug( e, e );\n    }\n    return Addresses.systemAddressManager;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public void assignSystemAddress( VmInstance vm ) throws NotEnoughResourcesAvailable {\n    Address addr = this.allocateNext( Component.eucalyptus.name( ) );\n    AddressCategory.assign( addr, vm ).dispatch( addr.getCluster( ) );\n  }","id":14349,"modified_method":"@Override\n  public void assignSystemAddress( VmInstance vm ) throws NotEnoughResourcesAvailable {\n    Address addr = this.allocateSystemAddresses( vm.getPlacement( ), 1 ).get( 0 );\n    AddressCategory.assign( addr, vm ).dispatch( addr.getCluster( ) );\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public List<Address> allocateSystemAddresses( String cluster, int count ) throws NotEnoughResourcesAvailable {\n    List<Address> addressList = Lists.newArrayList( );\n    if ( Addresses.getInstance( ).listDisabledValues( ).size( ) < count ) throw new NotEnoughResourcesAvailable( \"Not enough resources available: addresses (try --addressing private)\" );\n    for ( Address addr : Addresses.getInstance( ).listDisabledValues( ) ) {\n      if ( cluster.equals( addr.getCluster( ) ) ) {\n        addressList.add( addr.allocate( Component.eucalyptus.name( ) ) );\n        addr.pendingAssignment( );\n        if ( --count == 0 ) {\n          break;\n        }\n      }\n    }\n    if ( count != 0 ) {\n      for( Address addr : addressList ) {\n        addr.release( );\n      }\n      throw new NotEnoughResourcesAvailable( \"Not enough resources available: addresses (try --addressing private)\" );\n    } \n    return addressList;\n  }","id":14350,"modified_method":"@Override\n  public List<Address> allocateSystemAddresses( String cluster, int count ) throws NotEnoughResourcesAvailable {\n    List<Address> addressList = Lists.newArrayList( );\n    if ( Addresses.getInstance( ).listDisabledValues( ).size( ) < count ) throw new NotEnoughResourcesAvailable( \"Not enough resources available: addresses (try --addressing private)\" );\n    for ( Address addr : Addresses.getInstance( ).listDisabledValues( ) ) {\n      try {\n        if ( cluster.equals( addr.getCluster( ) ) && addressList.add( addr.pendingAssignment( ) ) && --count == 0 ) break;\n      } catch ( IllegalStateException e ) {\n        LOG.error( e , e );\n      }\n    }\n    if ( count != 0 ) {\n      for( Address addr : addressList ) {\n        try {\n          addr.release( );\n        } catch ( IllegalStateException e ) {\n          LOG.error( e , e );\n        }\n      }\n      throw new NotEnoughResourcesAvailable( \"Not enough resources available: addresses (try --addressing private)\" );\n    } \n    return addressList;\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@SuppressWarnings( \"unchecked\" )\n  @Override\n  public void inheritReservedAddresses( List<Address> previouslyReservedAddresses ) {\n    for ( final Address addr : previouslyReservedAddresses ) {\n      if( !addr.isAssigned( ) ) {\n        Addresses.release( addr );\n      }\n    }\n  }","id":14351,"modified_method":"@SuppressWarnings( \"unchecked\" )\n  @Override\n  public void inheritReservedAddresses( List<Address> previouslyReservedAddresses ) {\n    for ( final Address addr : previouslyReservedAddresses ) {\n      if( !addr.isAssigned( ) && !addr.isPending() && addr.isSystemOwned() && Address.UNASSIGNED_INSTANCEID.equals( addr.getInstanceId() ) ) {\n        Addresses.release( addr );\n      }\n    }\n  }","commit_id":"b47ec782fe4e09e38b9e157ad87a0407b5e83820","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n    public void write(final Writer writer, final SolrQueryRequest request, final SolrQueryResponse rsp) throws IOException {\n        assert rsp.getValues().get(\"responseHeader\") != null;\n        assert rsp.getValues().get(\"response\") != null;\n\n        @SuppressWarnings(\"unchecked\")\n        SimpleOrderedMap<Object> responseHeader = (SimpleOrderedMap<Object>) rsp.getResponseHeader();\n        DocSlice response = (DocSlice) rsp.getValues().get(\"response\");\n\n        // parse response header\n        ResHead resHead = new ResHead();\n        NamedList<?> val0 = (NamedList<?>) responseHeader.get(\"params\");\n        resHead.rows = Integer.parseInt((String) val0.get(\"rows\"));\n        resHead.offset = response.offset(); // equal to 'start'\n        resHead.numFound = response.matches();\n        //resHead.df = (String) val0.get(\"df\");\n        //resHead.q = (String) val0.get(\"q\");\n        //resHead.wt = (String) val0.get(\"wt\");\n        //resHead.status = (Integer) responseHeader.get(\"status\");\n        //resHead.QTime = (Integer) responseHeader.get(\"QTime\");\n        //resHead.maxScore = response.maxScore();\n\n        // write header\n        writer.write(XML_START);\n        paramTag(writer, \"start\", Integer.toString(resHead.offset));\n        paramTag(writer, \"num\", Integer.toString(resHead.rows));\n\n        // parse body\n        final int responseCount = response.size();\n        SolrIndexSearcher searcher = request.getSearcher();\n        DocIterator iterator = response.iterator();\n        for (int i = 0; i < responseCount; i++) {\n            OpensearchResponseWriter.openTag(writer, \"R\");\n            int id = iterator.nextDoc();\n            Document doc = searcher.doc(id, SOLR_FIELDS);\n            List<Fieldable> fields = doc.getFields();\n            int fieldc = fields.size();\n            List<String> texts = new ArrayList<String>();\n            String description = \"\";\n            for (int j = 0; j < fieldc; j++) {\n                Fieldable value = fields.get(j);\n                String fieldName = value.name();\n\n                // apply generic matching rule\n                String stag = field2tag.get(fieldName);\n                if (stag != null) {\n                    OpensearchResponseWriter.solitaireTag(writer, stag, value.stringValue());\n                    continue;\n                }\n\n/*\n<RK><\/RK>\n<FS NAME=\"date\" VALUE=\"\"/>\n<S><\/S>\n<HAS><L/><C SZ=\"7k\" CID=\"XN-uikfmLv0J\" ENC=\"UTF-8\"/><\/HAS>\n*/\n\n                // if the rule is not generic, use the specific here\n                if (YaCySchema.sku.name().equals(fieldName)) {\n                    String U = value.stringValue();\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.U.name(), U);\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.UE.name(), U);\n                    continue;\n                }\n                if (YaCySchema.title.name().equals(fieldName)) {\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.T.name(), value.stringValue());\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.description.name().equals(fieldName)) {\n                    description = value.stringValue();\n                    OpensearchResponseWriter.solitaireTag(writer, DublinCore.Description.getURIref(), description);\n                    texts.add(description);\n                    continue;\n                }\n                if (YaCySchema.text_t.name().equals(fieldName)) {\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.h1_txt.name().equals(fieldName) || YaCySchema.h2_txt.name().equals(fieldName) ||\n                    YaCySchema.h3_txt.name().equals(fieldName) || YaCySchema.h4_txt.name().equals(fieldName) ||\n                    YaCySchema.h5_txt.name().equals(fieldName) || YaCySchema.h6_txt.name().equals(fieldName)) {\n                    // because these are multi-valued fields, there can be several of each\n                    texts.add(value.stringValue());\n                    continue;\n                }\n            }\n            // compute snippet from texts\n            OpensearchResponseWriter.solitaireTag(writer, RSSMessage.Token.description.name(), description);\n            OpensearchResponseWriter.solitaireTag(writer, GSAToken.ENT_SOURCE.name(), \"YaCy\");\n            OpensearchResponseWriter.closeTag(writer, \"R\");\n        }\n\n        writer.write(XML_STOP);\n    }","id":14352,"modified_method":"@Override\n    public void write(final Writer writer, final SolrQueryRequest request, final SolrQueryResponse rsp) throws IOException {\n        assert rsp.getValues().get(\"responseHeader\") != null;\n        assert rsp.getValues().get(\"response\") != null;\n\n        @SuppressWarnings(\"unchecked\")\n        SimpleOrderedMap<Object> responseHeader = (SimpleOrderedMap<Object>) rsp.getResponseHeader();\n        DocSlice response = (DocSlice) rsp.getValues().get(\"response\");\n\n        // parse response header\n        ResHead resHead = new ResHead();\n        NamedList<?> val0 = (NamedList<?>) responseHeader.get(\"params\");\n        resHead.rows = Integer.parseInt((String) val0.get(\"rows\"));\n        resHead.offset = response.offset(); // equal to 'start'\n        resHead.numFound = response.matches();\n        //resHead.df = (String) val0.get(\"df\");\n        //resHead.q = (String) val0.get(\"q\");\n        //resHead.wt = (String) val0.get(\"wt\");\n        //resHead.status = (Integer) responseHeader.get(\"status\");\n        //resHead.QTime = (Integer) responseHeader.get(\"QTime\");\n        //resHead.maxScore = response.maxScore();\n\n        // write header\n        writer.write(XML_START);\n        paramTag(writer, \"start\", Integer.toString(resHead.offset));\n        paramTag(writer, \"num\", Integer.toString(resHead.rows));\n\n        // parse body\n        final int responseCount = response.size();\n        SolrIndexSearcher searcher = request.getSearcher();\n        DocIterator iterator = response.iterator();\n        for (int i = 0; i < responseCount; i++) {\n            OpensearchResponseWriter.openTag(writer, \"R\");\n            int id = iterator.nextDoc();\n            Document doc = searcher.doc(id, SOLR_FIELDS);\n            List<Fieldable> fields = doc.getFields();\n            int fieldc = fields.size();\n            List<String> texts = new ArrayList<String>();\n            String description = \"\";\n            for (int j = 0; j < fieldc; j++) {\n                Fieldable value = fields.get(j);\n                String fieldName = value.name();\n\n                // apply generic matching rule\n                String stag = field2tag.get(fieldName);\n                if (stag != null) {\n                    OpensearchResponseWriter.solitaireTag(writer, stag, value.stringValue());\n                    continue;\n                }\n\n/*\n<RK><\/RK>\n<FS NAME=\"date\" VALUE=\"\"/>\n<S><\/S>\n<HAS><L/><C SZ=\"7k\" CID=\"XN-uikfmLv0J\" ENC=\"UTF-8\"/><\/HAS>\n*/\n\n                // if the rule is not generic, use the specific here\n                if (YaCySchema.sku.name().equals(fieldName)) {\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.U.name(), CharacterCoding.unicode2xml(value.stringValue(), true));\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.UE.name(), CharacterCoding.unicode2html(value.stringValue(), true));\n                    continue;\n                }\n                if (YaCySchema.title.name().equals(fieldName)) {\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.T.name(), CharacterCoding.unicode2xml(value.stringValue(), true));\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.description.name().equals(fieldName)) {\n                    description = value.stringValue();\n                    OpensearchResponseWriter.solitaireTag(writer, DublinCore.Description.getURIref(), CharacterCoding.unicode2xml(description, true));\n                    texts.add(description);\n                    continue;\n                }\n                if (YaCySchema.last_modified.name().equals(fieldName)) {\n                    Date d = new Date(Long.parseLong(value.stringValue()));\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.CACHE_LAST_MODIFIED.name(), HeaderFramework.formatRFC1123(d));\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.load_date_dt.name().equals(fieldName)) {\n                    Date d = new Date(Long.parseLong(value.stringValue()));\n                    OpensearchResponseWriter.solitaireTag(writer, GSAToken.CRAWLDATE.name(), HeaderFramework.formatRFC1123(d));\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.text_t.name().equals(fieldName)) {\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.h1_txt.name().equals(fieldName) || YaCySchema.h2_txt.name().equals(fieldName) ||\n                    YaCySchema.h3_txt.name().equals(fieldName) || YaCySchema.h4_txt.name().equals(fieldName) ||\n                    YaCySchema.h5_txt.name().equals(fieldName) || YaCySchema.h6_txt.name().equals(fieldName)) {\n                    // because these are multi-valued fields, there can be several of each\n                    texts.add(value.stringValue());\n                    continue;\n                }\n            }\n            // compute snippet from texts\n            OpensearchResponseWriter.solitaireTag(writer, RSSMessage.Token.description.name(), CharacterCoding.unicode2xml(description, true));\n            OpensearchResponseWriter.solitaireTag(writer, GSAToken.ENT_SOURCE.name(), \"YaCy\");\n            OpensearchResponseWriter.closeTag(writer, \"R\");\n        }\n\n        writer.write(XML_STOP);\n    }","commit_id":"89fe13e73d64da77170d06ad8874c5bfe5b612d0","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"@Override\n    public void write(final Writer writer, final SolrQueryRequest request, final SolrQueryResponse rsp) throws IOException {\n        assert rsp.getValues().get(\"responseHeader\") != null;\n        assert rsp.getValues().get(\"response\") != null;\n\n        @SuppressWarnings(\"unchecked\")\n        SimpleOrderedMap<Object> responseHeader = (SimpleOrderedMap<Object>) rsp.getResponseHeader();\n        DocSlice response = (DocSlice) rsp.getValues().get(\"response\");\n\n        // parse response header\n        ResHead resHead = new ResHead();\n        NamedList<?> val0 = (NamedList<?>) responseHeader.get(\"params\");\n        resHead.rows = Integer.parseInt((String) val0.get(\"rows\"));\n        resHead.offset = response.offset(); // equal to 'start'\n        resHead.numFound = response.matches();\n        //resHead.df = (String) val0.get(\"df\");\n        //resHead.q = (String) val0.get(\"q\");\n        //resHead.wt = (String) val0.get(\"wt\");\n        //resHead.status = (Integer) responseHeader.get(\"status\");\n        //resHead.QTime = (Integer) responseHeader.get(\"QTime\");\n        //resHead.maxScore = response.maxScore();\n\n        // write header\n        writer.write(XML_START);\n        openTag(writer, \"channel\");\n        solitaireTag(writer, \"opensearch:totalResults\", Integer.toString(resHead.numFound));\n        solitaireTag(writer, \"opensearch:startIndex\", Integer.toString(resHead.offset));\n        solitaireTag(writer, \"opensearch:itemsPerPage\", Integer.toString(resHead.rows));\n        solitaireTag(writer, RSSMessage.Token.title.name(), this.title);\n        //solitaireTag(writer, \"description\", \"\");\n        //solitaireTag(writer, \"link\", \"\");\n        //solitaireTag(writer, \"image\", \"\");\n\n        // parse body\n        final int responseCount = response.size();\n        SolrIndexSearcher searcher = request.getSearcher();\n        DocIterator iterator = response.iterator();\n        for (int i = 0; i < responseCount; i++) {\n            openTag(writer, \"item\");\n            int id = iterator.nextDoc();\n            Document doc = searcher.doc(id, SOLR_FIELDS);\n            List<Fieldable> fields = doc.getFields();\n            int fieldc = fields.size();\n            List<String> texts = new ArrayList<String>();\n            String description = \"\";\n            for (int j = 0; j < fieldc; j++) {\n                Fieldable value = fields.get(j);\n                String fieldName = value.name();\n\n                // apply generic matching rule\n                String stag = field2tag.get(fieldName);\n                if (stag != null) {\n                    solitaireTag(writer, stag, value.stringValue());\n                    continue;\n                }\n\n                // if the rule is not generic, use the specific here\n                if (YaCySchema.id.name().equals(fieldName)) {\n                    solitaireTag(writer, RSSMessage.Token.guid.name(), value.stringValue(), \"isPermaLink=\\\"false\\\"\");\n                    continue;\n                }\n                if (YaCySchema.title.name().equals(fieldName)) {\n                    solitaireTag(writer, RSSMessage.Token.title.name(), value.stringValue());\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.description.name().equals(fieldName)) {\n                    description = value.stringValue();\n                    solitaireTag(writer, DublinCore.Description.getURIref(), description);\n                    texts.add(description);\n                    continue;\n                }\n                if (YaCySchema.text_t.name().equals(fieldName)) {\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.h1_txt.name().equals(fieldName) || YaCySchema.h2_txt.name().equals(fieldName) ||\n                    YaCySchema.h3_txt.name().equals(fieldName) || YaCySchema.h4_txt.name().equals(fieldName) ||\n                    YaCySchema.h5_txt.name().equals(fieldName) || YaCySchema.h6_txt.name().equals(fieldName)) {\n                    // because these are multi-valued fields, there can be several of each\n                    texts.add(value.stringValue());\n                    continue;\n                }\n            }\n            // compute snippet from texts\n            solitaireTag(writer, RSSMessage.Token.description.name(), description);\n            closeTag(writer, \"item\");\n        }\n\n        closeTag(writer, \"channel\");\n        writer.write(XML_STOP);\n    }","id":14353,"modified_method":"@Override\n    public void write(final Writer writer, final SolrQueryRequest request, final SolrQueryResponse rsp) throws IOException {\n        assert rsp.getValues().get(\"responseHeader\") != null;\n        assert rsp.getValues().get(\"response\") != null;\n\n        @SuppressWarnings(\"unchecked\")\n        SimpleOrderedMap<Object> responseHeader = (SimpleOrderedMap<Object>) rsp.getResponseHeader();\n        DocSlice response = (DocSlice) rsp.getValues().get(\"response\");\n\n        // parse response header\n        ResHead resHead = new ResHead();\n        NamedList<?> val0 = (NamedList<?>) responseHeader.get(\"params\");\n        resHead.rows = Integer.parseInt((String) val0.get(\"rows\"));\n        resHead.offset = response.offset(); // equal to 'start'\n        resHead.numFound = response.matches();\n        //resHead.df = (String) val0.get(\"df\");\n        //resHead.q = (String) val0.get(\"q\");\n        //resHead.wt = (String) val0.get(\"wt\");\n        //resHead.status = (Integer) responseHeader.get(\"status\");\n        //resHead.QTime = (Integer) responseHeader.get(\"QTime\");\n        //resHead.maxScore = response.maxScore();\n\n        // write header\n        writer.write(XML_START);\n        openTag(writer, \"channel\");\n        solitaireTag(writer, \"opensearch:totalResults\", Integer.toString(resHead.numFound));\n        solitaireTag(writer, \"opensearch:startIndex\", Integer.toString(resHead.offset));\n        solitaireTag(writer, \"opensearch:itemsPerPage\", Integer.toString(resHead.rows));\n        solitaireTag(writer, RSSMessage.Token.title.name(), this.title);\n        writer.write(\"<atom:link rel=\\\"search\\\" href=\\\"http://localhost:8090/opensearchdescription.xml\\\" type=\\\"application/opensearchdescription+xml\\\"/>\");\n        solitaireTag(writer, \"description\", \"Search Result\");\n        //solitaireTag(writer, \"link\", \"\");\n        //solitaireTag(writer, \"image\", \"\");\n\n        // parse body\n        final int responseCount = response.size();\n        SolrIndexSearcher searcher = request.getSearcher();\n        DocIterator iterator = response.iterator();\n        for (int i = 0; i < responseCount; i++) {\n            openTag(writer, \"item\");\n            int id = iterator.nextDoc();\n            Document doc = searcher.doc(id, SOLR_FIELDS);\n            List<Fieldable> fields = doc.getFields();\n            int fieldc = fields.size();\n            List<String> texts = new ArrayList<String>();\n            String description = \"\";\n            for (int j = 0; j < fieldc; j++) {\n                Fieldable value = fields.get(j);\n                String fieldName = value.name();\n\n                // apply generic matching rule\n                String stag = field2tag.get(fieldName);\n                if (stag != null) {\n                    solitaireTag(writer, stag, CharacterCoding.unicode2xml(value.stringValue(), true));\n                    continue;\n                }\n\n                // if the rule is not generic, use the specific here\n                if (YaCySchema.id.name().equals(fieldName)) {\n                    solitaireTag(writer, RSSMessage.Token.guid.name(), value.stringValue(), \"isPermaLink=\\\"false\\\"\");\n                    continue;\n                }\n                if (YaCySchema.title.name().equals(fieldName)) {\n                    solitaireTag(writer, RSSMessage.Token.title.name(), CharacterCoding.unicode2xml(value.stringValue(), true));\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.last_modified.name().equals(fieldName)) {\n                    Date d = new Date(Long.parseLong(value.stringValue()));\n                    solitaireTag(writer, RSSMessage.Token.pubDate.name(), HeaderFramework.formatRFC1123(d));\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.description.name().equals(fieldName)) {\n                    description = value.stringValue();\n                    solitaireTag(writer, DublinCore.Description.getURIref(), CharacterCoding.unicode2xml(description, true));\n                    texts.add(description);\n                    continue;\n                }\n                if (YaCySchema.text_t.name().equals(fieldName)) {\n                    texts.add(value.stringValue());\n                    continue;\n                }\n                if (YaCySchema.h1_txt.name().equals(fieldName) || YaCySchema.h2_txt.name().equals(fieldName) ||\n                    YaCySchema.h3_txt.name().equals(fieldName) || YaCySchema.h4_txt.name().equals(fieldName) ||\n                    YaCySchema.h5_txt.name().equals(fieldName) || YaCySchema.h6_txt.name().equals(fieldName)) {\n                    // because these are multi-valued fields, there can be several of each\n                    texts.add(value.stringValue());\n                    continue;\n                }\n            }\n            // compute snippet from texts\n            solitaireTagNocheck(writer, RSSMessage.Token.description.name(), CharacterCoding.unicode2xml(description, true));\n            closeTag(writer, \"item\");\n        }\n\n        closeTag(writer, \"channel\");\n        writer.write(XML_STOP);\n    }","commit_id":"89fe13e73d64da77170d06ad8874c5bfe5b612d0","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static void solitaireTag(final Writer writer, final String tagname, String value) throws IOException {\n        if (value == null || value.length() == 0) return;\n        writer.write(\"<\"); writer.write(tagname); writer.write('>');\n        writer.write(value);\n        writer.write(\"<\/\"); writer.write(tagname); writer.write('>'); writer.write(lb);\n    }","id":14354,"modified_method":"public static void solitaireTag(final Writer writer, final String tagname, String value) throws IOException {\n        if (value == null || value.length() == 0) return;\n        solitaireTagNocheck(writer, tagname, value);\n    }","commit_id":"89fe13e73d64da77170d06ad8874c5bfe5b612d0","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public void testSendWithGetPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GET, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[1]);\n    }","id":14355,"modified_method":"public void testSendWithGetPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GET, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[1]);\n    }","commit_id":"b6bc012f0481287f198e16af6cda3e5ed1b9254e","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GET, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n    }","id":14356,"modified_method":"public void testSendWithGetPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GET, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n    }","commit_id":"b6bc012f0481287f198e16af6cda3e5ed1b9254e","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetNextPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GETNEXT, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n        // Expect the *next* value, so for .1.3.5.1.1.5.0\n        assertSnmpValueEquals(\"values[1]\", SnmpValue.SNMP_COUNTER32, 42, values[1]);\n    }","id":14357,"modified_method":"public void testSendWithGetNextPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        /*\n         * Build the PDU first, since there isn't any value in doing other\n         * work like setting up the session if we don't have anything to send.\n         */\n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GETNEXT, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n        // Expect the *next* value, so for .1.3.5.1.1.5.0\n        assertSnmpValueEquals(\"values[1]\", SnmpValue.SNMP_COUNTER32, 42, values[1]);\n    }","commit_id":"b6bc012f0481287f198e16af6cda3e5ed1b9254e","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetNextPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GETNEXT, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n    }","id":14358,"modified_method":"public void testSendWithGetNextPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GETNEXT, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n    }","commit_id":"b6bc012f0481287f198e16af6cda3e5ed1b9254e","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetNextPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GETNEXT, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n        // Expect the *next* value, so for .1.3.5.1.1.5.0\n        assertSnmpValueEquals(\"values[1]\", SnmpValue.SNMP_COUNTER32, 42, values[1]);\n    }","id":14359,"modified_method":"public void testSendWithGetNextPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        /*\n         * Build the PDU first, since there isn't any value in doing other\n         * work like setting up the session if we don't have anything to send.\n         */\n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GETNEXT, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n        // Expect the *next* value, so for .1.3.5.1.1.5.0\n        assertSnmpValueEquals(\"values[1]\", SnmpValue.SNMP_COUNTER32, 42, values[1]);\n    }","commit_id":"6f4b7128a24c434dcf4ccb985c0f6e6935c4b8cb","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GET, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[1]);\n    }","id":14360,"modified_method":"public void testSendWithGetPduMultipleValues() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] {\n                SnmpObjId.get(\".1.3.5.1.1.3.0\"),\n                SnmpObjId.get(\".1.3.5.1.1.4.0\"),\n        };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GET, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 2, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[1]);\n    }","commit_id":"6f4b7128a24c434dcf4ccb985c0f6e6935c4b8cb","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GET, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n    }","id":14361,"modified_method":"public void testSendWithGetPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GET, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_INT32, 42, values[0]);\n    }","commit_id":"6f4b7128a24c434dcf4ccb985c0f6e6935c4b8cb","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSendWithGetNextPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        \n        SnmpValue[] values = m_strategy.send(new Snmp4JAgentConfig(getAgentConfig()), PDU.GETNEXT, oids);\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n    }","id":14362,"modified_method":"public void testSendWithGetNextPduSingleValue() throws Exception {\n        SnmpObjId[] oids = new SnmpObjId[] { SnmpObjId.get(\".1.3.5.1.1.3.0\") };\n        Snmp4JAgentConfig agentConfig = new Snmp4JAgentConfig(getAgentConfig());\n        SnmpValue[] retvalues = null;\n        \n        PDU pdu = m_strategy.buildPdu(agentConfig, PDU.GETNEXT, oids, null);\n        if (pdu != null) {\n            retvalues = m_strategy.send(agentConfig, pdu, true);\n        }\n        \n        SnmpValue[] values = retvalues;\n        \n        assertNotNull(\"values should not be null\", values);\n        assertEquals(\"values list size\", 1, values.length);\n        // Expect the *next* value, so for .1.3.5.1.1.4.0\n        assertSnmpValueEquals(\"values[0]\", SnmpValue.SNMP_GAUGE32, 42, values[0]);\n    }","commit_id":"6f4b7128a24c434dcf4ccb985c0f6e6935c4b8cb","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n\r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","id":14363,"modified_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n\r\n    // SET CONTENT ENCDOING\r\n    if(contentEncoding != null && contentEncoding.length() > 0) {\r\n    \twriteLine(\"Content-Encoding: \" + contentEncoding);\r\n    }\r\n    \r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","commit_id":"abda617c981f75e088a0a618f5cdc4433d2c0a70","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    final byte[] binaryContent = empty ? null : OBinaryProtocol.string2bytes(content);\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","id":14364,"modified_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    byte[] binaryContent = null;\r\n    if(!empty) {\r\n    \tif(contentEncoding.equals(OHttpUtils.CONTENT_ACCEPT_GZIP_ENCODED)) \r\n    \t\tbinaryContent = compress(content);\r\n    \telse\r\n    \t\tbinaryContent = OBinaryProtocol.string2bytes(content);\r\n    }\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","commit_id":"abda617c981f75e088a0a618f5cdc4433d2c0a70","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void service() throws ONetworkProtocolException, IOException {\r\n    ++connection.data.totalRequests;\r\n    connection.data.commandInfo = null;\r\n    connection.data.commandDetail = null;\r\n\r\n    final String callbackF;\r\n    if ((request.parameters != null) && request.parameters.containsKey(OHttpUtils.CALLBACK_PARAMETER_NAME))\r\n      callbackF = request.parameters.get(OHttpUtils.CALLBACK_PARAMETER_NAME);\r\n    else\r\n      callbackF = null;\r\n\r\n    response = new OHttpResponse(channel.outStream, request.httpVersion, additionalResponseHeaders, responseCharSet,\r\n        connection.data.serverInfo, request.sessionId, callbackF);\r\n\r\n    final long begin = System.currentTimeMillis();\r\n\r\n    boolean isChain;\r\n    do {\r\n      isChain = false;\r\n      final String command;\r\n      if (request.url.length() < 2) {\r\n        command = \"\";\r\n      } else {\r\n        command = request.url.substring(1);\r\n      }\r\n\r\n      final String commandString = getCommandString(command);\r\n\r\n      final OServerCommand cmd = (OServerCommand) cmdManager.getCommand(commandString);\r\n      if (cmd != null)\r\n        try {\r\n          if (cmd.beforeExecute(request, response))\r\n            // EXECUTE THE COMMAND\r\n            isChain = cmd.execute(request, response);\r\n\r\n        } catch (Exception e) {\r\n          handleError(e);\r\n        }\r\n      else {\r\n        try {\r\n          OLogManager.instance().warn(\r\n              this,\r\n              \"->\" + channel.socket.getInetAddress().getHostAddress() + \": Command not found: \" + request.httpMethod + \".\"\r\n                  + URLDecoder.decode(command, \"UTF-8\"));\r\n\r\n          sendTextContent(OHttpUtils.STATUS_INVALIDMETHOD_CODE, OHttpUtils.STATUS_INVALIDMETHOD_DESCRIPTION, null,\r\n              OHttpUtils.CONTENT_TEXT_PLAIN, \"Command not found: \" + command);\r\n        } catch (IOException e1) {\r\n          sendShutdown();\r\n        }\r\n      }\r\n    } while (isChain);\r\n\r\n    connection.data.lastCommandInfo = connection.data.commandInfo;\r\n    connection.data.lastCommandDetail = connection.data.commandDetail;\r\n\r\n    connection.data.lastCommandExecutionTime = System.currentTimeMillis() - begin;\r\n    connection.data.totalCommandExecutionTime += connection.data.lastCommandExecutionTime;\r\n  }","id":14365,"modified_method":"public void service() throws ONetworkProtocolException, IOException {\r\n    ++connection.data.totalRequests;\r\n    connection.data.commandInfo = null;\r\n    connection.data.commandDetail = null;\r\n\r\n    final String callbackF;\r\n    if ((request.parameters != null) && request.parameters.containsKey(OHttpUtils.CALLBACK_PARAMETER_NAME))\r\n      callbackF = request.parameters.get(OHttpUtils.CALLBACK_PARAMETER_NAME);\r\n    else\r\n      callbackF = null;\r\n\r\n    response = new OHttpResponse(channel.outStream, request.httpVersion, additionalResponseHeaders, responseCharSet,\r\n        connection.data.serverInfo, request.sessionId, callbackF);\r\n    if(request.contentEncoding != null && request.contentEncoding.equals(OHttpUtils.CONTENT_ACCEPT_GZIP_ENCODED)) {\r\n    \tresponse.setContentEncoding(OHttpUtils.CONTENT_ACCEPT_GZIP_ENCODED);\r\n    }\r\n\r\n    final long begin = System.currentTimeMillis();\r\n\r\n    boolean isChain;\r\n    do {\r\n      isChain = false;\r\n      final String command;\r\n      if (request.url.length() < 2) {\r\n        command = \"\";\r\n      } else {\r\n        command = request.url.substring(1);\r\n      }\r\n\r\n      final String commandString = getCommandString(command);\r\n\r\n      final OServerCommand cmd = (OServerCommand) cmdManager.getCommand(commandString);\r\n      if (cmd != null)\r\n        try {\r\n          if (cmd.beforeExecute(request, response))\r\n            // EXECUTE THE COMMAND\r\n            isChain = cmd.execute(request, response);\r\n\r\n        } catch (Exception e) {\r\n          handleError(e);\r\n        }\r\n      else {\r\n        try {\r\n          OLogManager.instance().warn(\r\n              this,\r\n              \"->\" + channel.socket.getInetAddress().getHostAddress() + \": Command not found: \" + request.httpMethod + \".\"\r\n                  + URLDecoder.decode(command, \"UTF-8\"));\r\n\r\n          sendTextContent(OHttpUtils.STATUS_INVALIDMETHOD_CODE, OHttpUtils.STATUS_INVALIDMETHOD_DESCRIPTION, null,\r\n              OHttpUtils.CONTENT_TEXT_PLAIN, \"Command not found: \" + command);\r\n        } catch (IOException e1) {\r\n          sendShutdown();\r\n        }\r\n      }\r\n    } while (isChain);\r\n\r\n    connection.data.lastCommandInfo = connection.data.commandInfo;\r\n    connection.data.lastCommandDetail = connection.data.commandDetail;\r\n\r\n    connection.data.lastCommandExecutionTime = System.currentTimeMillis() - begin;\r\n    connection.data.totalCommandExecutionTime += connection.data.lastCommandExecutionTime;\r\n  }","commit_id":"abda617c981f75e088a0a618f5cdc4433d2c0a70","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public void config(final OServer iServer, final Socket iSocket, final OContextConfiguration iConfiguration,\r\n      final Object[] commands) throws IOException {\r\n    final String addHeaders = iConfiguration.getValueAsString(\"network.http.additionalResponseHeaders\", null);\r\n    if (addHeaders != null)\r\n      additionalResponseHeaders = addHeaders.split(\";\");\r\n\r\n    // CREATE THE CLIENT CONNECTION\r\n    connection = OClientConnectionManager.instance().connect(iSocket, this);\r\n\r\n    server = iServer;\r\n    requestMaxContentLength = iConfiguration.getValueAsInteger(OGlobalConfiguration.NETWORK_HTTP_MAX_CONTENT_LENGTH);\r\n    socketTimeout = iConfiguration.getValueAsInteger(OGlobalConfiguration.NETWORK_SOCKET_TIMEOUT);\r\n    responseCharSet = iConfiguration.getValueAsString(OGlobalConfiguration.NETWORK_HTTP_CONTENT_CHARSET);\r\n\r\n    channel = new OChannelTextServer(iSocket, iConfiguration);\r\n    channel.connected();\r\n\r\n    request = new OHttpRequest(this, channel.inStream, connection.data, iConfiguration);\r\n\r\n    connection.data.caller = channel.toString();\r\n\r\n    listeningAddress = getListeningAddress();\r\n\r\n    start();\r\n  }","id":14366,"modified_method":"@Override\r\n  public void config(final OServer iServer, final Socket iSocket, final OContextConfiguration iConfiguration,\r\n      final List<?> iStatelessCommands, List<?> iStatefulCommands) throws IOException {\r\n    final String addHeaders = iConfiguration.getValueAsString(\"network.http.additionalResponseHeaders\", null);\r\n    if (addHeaders != null)\r\n      additionalResponseHeaders = addHeaders.split(\";\");\r\n\r\n    // CREATE THE CLIENT CONNECTION\r\n    connection = OClientConnectionManager.instance().connect(iSocket, this);\r\n\r\n    server = iServer;\r\n    requestMaxContentLength = iConfiguration.getValueAsInteger(OGlobalConfiguration.NETWORK_HTTP_MAX_CONTENT_LENGTH);\r\n    socketTimeout = iConfiguration.getValueAsInteger(OGlobalConfiguration.NETWORK_SOCKET_TIMEOUT);\r\n    responseCharSet = iConfiguration.getValueAsString(OGlobalConfiguration.NETWORK_HTTP_CONTENT_CHARSET);\r\n\r\n    channel = new OChannelTextServer(iSocket, iConfiguration);\r\n    channel.connected();\r\n\r\n    request = new OHttpRequest(this, channel.inStream, connection.data, iConfiguration);\r\n\r\n    connection.data.caller = channel.toString();\r\n\r\n    listeningAddress = getListeningAddress();\r\n\r\n    start();\r\n  }","commit_id":"abda617c981f75e088a0a618f5cdc4433d2c0a70","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    final byte[] binaryContent = empty ? null : OBinaryProtocol.string2bytes(content);\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","id":14367,"modified_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    byte[] binaryContent = null;\r\n    if(!empty) {\r\n      if(contentEncoding != null && contentEncoding.equals(OHttpUtils.CONTENT_ACCEPT_GZIP_ENCODED))\r\n        binaryContent = compress(content);\r\n      else\r\n        binaryContent = OBinaryProtocol.string2bytes(content);\r\n    }\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","commit_id":"348c9b26c11c22d2736953851f5e6958b8948dba","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n\r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","id":14368,"modified_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n    \r\n    // SET CONTENT ENCDOING\r\n    if(contentEncoding != null && contentEncoding.length() > 0) {\r\n      writeLine(\"Content-Encoding: \" + contentEncoding);\r\n    }\r\n    \r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","commit_id":"348c9b26c11c22d2736953851f5e6958b8948dba","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    final byte[] binaryContent = empty ? null : OBinaryProtocol.string2bytes(content);\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","id":14369,"modified_method":"public void send(final int iCode, final String iReason, final String iContentType, final Object iContent, final String iHeaders,\r\n      final boolean iKeepAlive) throws IOException {\r\n    if (sendStarted)\r\n      // AVOID TO SEND RESPONSE TWICE\r\n      return;\r\n    sendStarted = true;\r\n\r\n    final String content;\r\n    final String contentType;\r\n\r\n    if (callbackFunction != null) {\r\n      content = callbackFunction + \"(\" + iContent + \")\";\r\n      contentType = \"text/javascript\";\r\n    } else {\r\n      content = iContent != null ? iContent.toString() : null;\r\n      contentType = iContentType;\r\n    }\r\n\r\n    final boolean empty = content == null || content.length() == 0;\r\n\r\n    writeStatus(empty && iCode == 200 ? 204 : iCode, iReason);\r\n    writeHeaders(contentType, iKeepAlive);\r\n\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n\r\n    if (iHeaders != null)\r\n      writeLine(iHeaders);\r\n\r\n    final String sessId = sessionId != null ? sessionId : \"-\";\r\n\r\n    writeLine(\"Set-Cookie: \" + OHttpUtils.OSESSIONID + \"=\" + sessId + \"; Path=/; HttpOnly\");\r\n\r\n    byte[] binaryContent = null;\r\n    if(!empty) {\r\n      if(contentEncoding != null && contentEncoding.equals(OHttpUtils.CONTENT_ACCEPT_GZIP_ENCODED))\r\n        binaryContent = compress(content);\r\n      else\r\n        binaryContent = OBinaryProtocol.string2bytes(content);\r\n    }\r\n\r\n    writeLine(OHttpUtils.HEADER_CONTENT_LENGTH + (empty ? 0 : binaryContent.length));\r\n\r\n    writeLine(null);\r\n\r\n    if (binaryContent != null)\r\n      out.write(binaryContent);\r\n    out.flush();\r\n  }","commit_id":"f60048aced7c0bace7f5c85f003f9765098c36b2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n\r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","id":14370,"modified_method":"public void writeHeaders(final String iContentType, final boolean iKeepAlive) throws IOException {\r\n    if (headers != null)\r\n      writeLine(headers);\r\n\r\n    writeLine(\"Date: \" + new Date());\r\n    writeLine(\"Content-Type: \" + iContentType + \"; charset=\" + characterSet);\r\n    writeLine(\"Server: \" + serverInfo);\r\n    writeLine(\"Connection: \" + (iKeepAlive ? \"Keep-Alive\" : \"close\"));\r\n    \r\n    // SET CONTENT ENCDOING\r\n    if(contentEncoding != null && contentEncoding.length() > 0) {\r\n      writeLine(\"Content-Encoding: \" + contentEncoding);\r\n    }\r\n    \r\n    // INCLUDE COMMON CUSTOM HEADERS\r\n    if (additionalHeaders != null)\r\n      for (String h : additionalHeaders)\r\n        writeLine(h);\r\n  }","commit_id":"f60048aced7c0bace7f5c85f003f9765098c36b2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\n    protected FileStore setupSecondary(File d) throws IOException {\n        secondaryStore = getSecondaryStoreDir();\n        FileDataStore fds = new FileDataStore();\n        fds.setMinRecordLength(4092);\n        fds.init(secondaryStore.getAbsolutePath());\n        DataStoreBlobStore blobStore = new DataStoreBlobStore(fds);\n        return new FileStore(blobStore, d, 1, false);\n    }","id":14371,"modified_method":"@Override\r\n    protected FileStore setupSecondary(File d) throws IOException {\r\n        secondaryStore = createTmpTargetDir(\"ExternalStoreITSecondary\");\r\n        return setupFileDataStore(d, secondaryStore.getAbsolutePath());\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    protected FileStore setupPrimary(File d) throws IOException {\n        primaryStore = getPrimaryStoreDir();\n        FileDataStore fds = new FileDataStore();\n        fds.setMinRecordLength(4092);\n        fds.init(primaryStore.getAbsolutePath());\n        DataStoreBlobStore blobStore = new DataStoreBlobStore(fds);\n        return new FileStore(blobStore, d, 1, false);\n    }","id":14372,"modified_method":"@Override\r\n    protected FileStore setupPrimary(File d) throws IOException {\r\n        primaryStore = createTmpTargetDir(\"ExternalStoreITPrimary\");\r\n        return setupFileDataStore(d, primaryStore.getAbsolutePath());\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    protected FileStore setupPrimary(File d) throws IOException {\n        externalStore = getPrimaryStoreDir();\n        FileDataStore fds = new FileDataStore();\n        fds.setMinRecordLength(4092);\n        fds.init(externalStore.getAbsolutePath());\n        DataStoreBlobStore blobStore = new DataStoreBlobStore(fds);\n        return new FileStore(blobStore, d, 1, false);\n    }","id":14373,"modified_method":"@Override\r\n    protected FileStore setupPrimary(File d) throws IOException {\r\n        externalStore = createTmpTargetDir(\"ExternalCommonStoreIT\");\r\n        return setupFileDataStore(d, externalStore.getAbsolutePath());\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    protected FileStore setupSecondary(File d) throws IOException {\n        FileDataStore fds = new FileDataStore();\n        fds.setMinRecordLength(4092);\n        fds.init(externalStore.getAbsolutePath());\n        DataStoreBlobStore blobStore = new DataStoreBlobStore(fds);\n        return new FileStore(blobStore, d, 1, false);\n    }","id":14374,"modified_method":"@Override\r\n    protected FileStore setupSecondary(File d) throws IOException {\r\n        return setupFileDataStore(d, externalStore.getAbsolutePath());\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Test\r\n    public void testClientEmptyConfigNoServer() throws Exception {\r\n        final StandbyClient client = new StandbyClient(\"127.0.0.1\", this.port, this.storeC);\r\n        client.start();\r\n\r\n        final MBeanServer jmxServer = ManagementFactory.getPlatformMBeanServer();\r\n        ObjectName status = new ObjectName(StandbyStatusMBean.JMX_NAME + \",id=*\");\r\n        try {\r\n            Set<ObjectName> instances = jmxServer.queryNames(status, null);\r\n            assertEquals(1, instances.size());\r\n            status = instances.toArray(new ObjectName[0])[0];\r\n            assertEquals(new ObjectName(client.getMBeanName()), status);\r\n            assertTrue(jmxServer.isRegistered(status));\r\n\r\n            String m = jmxServer.getAttribute(status, \"Mode\").toString();\r\n            if (!m.startsWith(\"client: \")) fail(\"unexpected mode \" + m);\r\n\r\n            assertEquals(\"1\", jmxServer.getAttribute(status, \"FailedRequests\").toString());\r\n            assertEquals(\"-1\", jmxServer.getAttribute(status, \"SecondsSinceLastSuccess\").toString());\r\n\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            jmxServer.invoke(status, \"stop\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n            jmxServer.invoke(status, \"start\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n        } finally {\r\n            client.close();\r\n        }\r\n\r\n        assertTrue(!jmxServer.isRegistered(status));\r\n    }","id":14375,"modified_method":"@Test\r\n    public void testClientEmptyConfigNoServer() throws Exception {\r\n        final StandbyClient client = new StandbyClient(\"127.0.0.1\", this.port, this.storeC);\r\n        client.start();\r\n\r\n        final MBeanServer jmxServer = ManagementFactory.getPlatformMBeanServer();\r\n        ObjectName status = new ObjectName(StandbyStatusMBean.JMX_NAME + \",id=*\");\r\n        try {\r\n            Set<ObjectName> instances = jmxServer.queryNames(status, null);\r\n            assertEquals(1, instances.size());\r\n            status = instances.toArray(new ObjectName[0])[0];\r\n            assertEquals(new ObjectName(client.getMBeanName()), status);\r\n            assertTrue(jmxServer.isRegistered(status));\r\n\r\n            String m = jmxServer.getAttribute(status, \"Mode\").toString();\r\n            if (!m.startsWith(\"client: \")) fail(\"unexpected mode \" + m);\r\n\r\n            assertEquals(\"0\", jmxServer.getAttribute(status, \"FailedRequests\").toString());\r\n            assertEquals(\"-1\", jmxServer.getAttribute(status, \"SecondsSinceLastSuccess\").toString());\r\n\r\n            assertEquals(StandbyStatusMBean.STATUS_INITIALIZING, jmxServer.getAttribute(status, \"Status\"));\r\n\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            jmxServer.invoke(status, \"stop\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n            jmxServer.invoke(status, \"start\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n        } finally {\r\n            client.close();\r\n        }\r\n\r\n        assertTrue(!jmxServer.isRegistered(status));\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Test\r\n    public void testServerEmptyConfig() throws Exception {\r\n        final StandbyServer server = new StandbyServer(this.port, this.storeS);\r\n        server.start();\r\n\r\n        final MBeanServer jmxServer = ManagementFactory.getPlatformMBeanServer();\r\n        ObjectName status = new ObjectName(StandbyStatusMBean.JMX_NAME + \",id=*\");\r\n        try {\r\n            Set<ObjectName> instances = jmxServer.queryNames(status, null);\r\n            assertEquals(1, instances.size());\r\n            status = instances.toArray(new ObjectName[0])[0];\r\n            assertEquals(new ObjectName(server.getMBeanName()), status);\r\n            assertTrue(jmxServer.isRegistered(status));\r\n\r\n            assertEquals(\"master\", jmxServer.getAttribute(status, \"Mode\"));\r\n            String m = jmxServer.getAttribute(status, \"Status\").toString();\r\n            if (!m.equals(StandbyStatusMBean.STATUS_STARTING) && !m.equals(\"channel unregistered\"))\r\n                fail(\"unexpected Status\" + m);\r\n\r\n            assertEquals(StandbyStatusMBean.STATUS_STARTING, jmxServer.getAttribute(status, \"Status\"));\r\n            assertEquals(true, jmxServer.getAttribute(status, \"Running\"));\r\n            jmxServer.invoke(status, \"stop\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n            jmxServer.invoke(status, \"start\", null, null);\r\n\r\n            assertEquals(true, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STARTING, jmxServer.getAttribute(status, \"Status\"));\r\n        } finally {\r\n            server.close();\r\n        }\r\n\r\n        assertTrue(!jmxServer.isRegistered(status));\r\n    }","id":14376,"modified_method":"@Test\r\n    public void testServerEmptyConfig() throws Exception {\r\n        final StandbyServer server = new StandbyServer(this.port, this.storeS);\r\n        server.start();\r\n\r\n        final MBeanServer jmxServer = ManagementFactory.getPlatformMBeanServer();\r\n        ObjectName status = new ObjectName(StandbyStatusMBean.JMX_NAME + \",id=*\");\r\n        try {\r\n            Set<ObjectName> instances = jmxServer.queryNames(status, null);\r\n            assertEquals(1, instances.size());\r\n            status = instances.toArray(new ObjectName[0])[0];\r\n            assertEquals(new ObjectName(server.getMBeanName()), status);\r\n            assertTrue(jmxServer.isRegistered(status));\r\n\r\n            assertEquals(\"primary\", jmxServer.getAttribute(status, \"Mode\"));\r\n            String m = jmxServer.getAttribute(status, \"Status\").toString();\r\n            if (!m.equals(StandbyStatusMBean.STATUS_STARTING) && !m.equals(\"channel unregistered\"))\r\n                fail(\"unexpected Status \" + m);\r\n\r\n            assertEquals(StandbyStatusMBean.STATUS_STARTING, jmxServer.getAttribute(status, \"Status\"));\r\n            assertEquals(true, jmxServer.getAttribute(status, \"Running\"));\r\n            jmxServer.invoke(status, \"stop\", null, null);\r\n            assertEquals(false, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_STOPPED, jmxServer.getAttribute(status, \"Status\"));\r\n            jmxServer.invoke(status, \"start\", null, null);\r\n\r\n            assertEquals(true, jmxServer.getAttribute(status, \"Running\"));\r\n            assertEquals(StandbyStatusMBean.STATUS_RUNNING, jmxServer.getAttribute(status, \"Status\"));\r\n        } finally {\r\n            server.close();\r\n        }\r\n\r\n        assertTrue(!jmxServer.isRegistered(status));\r\n    }","commit_id":"a91fc4e4b199d887d1c8e7e8761648c06978a00f","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                applyEntry( entry );\n            }\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                LogIoUtils.writeLogEntry( entry, writeBuffer );\n                return true;\n            }\n            return false;\n        }","id":14377,"modified_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                if ( entry instanceof LogEntry.Commit )\n                {\n                    // hack to get done record written after commit record\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                    applyEntry( entry );\n                }\n                else\n                {\n                    applyEntry( entry );\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                }\n                return true;\n            }\n            return false;\n        }","commit_id":"4acb00f862c482efe76daf420cdd09c380ac1b6f","url":"https://github.com/neo4j/neo4j"},{"original_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                applyEntry( entry );\n            }\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                LogIoUtils.writeLogEntry( entry, writeBuffer );\n                return true;\n            }\n            return false;\n        }","id":14378,"modified_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                if ( entry instanceof LogEntry.Commit )\n                {\n                    // hack to get done record written after commit record\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                    applyEntry( entry );\n                }\n                else\n                {\n                    applyEntry( entry );\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                }\n                return true;\n            }\n            return false;\n        }","commit_id":"7d76d6ff242b6c46fe5ec5cd4027bae07dca9533","url":"https://github.com/neo4j/neo4j"},{"original_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                applyEntry( entry );\n            }\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                LogIoUtils.writeLogEntry( entry, writeBuffer );\n                return true;\n            }\n            return false;\n        }","id":14379,"modified_method":"boolean readAndApplyAndWriteEntry( int newXidIdentifier ) throws IOException\n        {\n            LogEntry entry = LogIoUtils.readEntry( buffer, byteChannel, cf );\n            if ( entry != null )\n            {\n                entry.setIdentifier( newXidIdentifier );\n                if ( entry instanceof LogEntry.Commit )\n                {\n                    // hack to get done record written after commit record\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                    applyEntry( entry );\n                }\n                else\n                {\n                    applyEntry( entry );\n                    LogIoUtils.writeLogEntry( entry, writeBuffer );\n                }\n                return true;\n            }\n            return false;\n        }","commit_id":"1614595aa009acfe61f799ab0ba3be4559431278","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void testNoFilter() throws Exception\n    {\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            new Thread(new Worker(i)).start();\n        }\n\n        _doneRequests.await(10, TimeUnit.SECONDS);\n\n        if (TestServlet.__maxSleepers <= MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            Assert.assertThat(TestServlet.__maxSleepers, Matchers.lessThanOrEqualTo(NUM_CONNECTIONS));\n    }","id":14380,"modified_method":"@Test\n    public void testNoFilter() throws Exception\n    {\n        List<Worker> workers = new ArrayList<>();\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            workers.add(new Worker(i));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(NUM_CONNECTIONS);\n        List<Future<Void>> futures = executor.invokeAll(workers, 10, TimeUnit.SECONDS);\n\n        rethrowExceptions(futures);\n\n        if (TestServlet.__maxSleepers <= MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            assertThat(TestServlet.__maxSleepers, Matchers.lessThanOrEqualTo(NUM_CONNECTIONS));\n    }","commit_id":"650db59e69e9068635c372631c11deec2435b7e0","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Test\n    public void testQosFilter() throws Exception\n    {\n        FilterHolder holder = new FilterHolder(QoSFilter2.class);\n        holder.setAsyncSupported(true);\n        holder.setInitParameter(QoSFilter.MAX_REQUESTS_INIT_PARAM, String.valueOf(MAX_QOS));\n        _tester.getContext().getServletHandler().addFilterWithMapping(holder, \"/*\", EnumSet.of(DispatcherType.REQUEST, DispatcherType.ASYNC));\n\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            new Thread(new Worker2(i)).start();\n        }\n\n        _doneRequests.await(20, TimeUnit.SECONDS);\n        if (TestServlet.__maxSleepers < MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            Assert.assertEquals(TestServlet.__maxSleepers, MAX_QOS);\n    }","id":14381,"modified_method":"@Test\n    public void testQosFilter() throws Exception\n    {\n        FilterHolder holder = new FilterHolder(QoSFilter2.class);\n        holder.setAsyncSupported(true);\n        holder.setInitParameter(QoSFilter.MAX_REQUESTS_INIT_PARAM, String.valueOf(MAX_QOS));\n        _tester.getContext().getServletHandler().addFilterWithMapping(holder, \"/*\", EnumSet.of(DispatcherType.REQUEST, DispatcherType.ASYNC));\n\n        List<Worker2> workers = new ArrayList<>();\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            workers.add(new Worker2(i));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(NUM_CONNECTIONS);\n        List<Future<Void>> futures = executor.invokeAll(workers, 20, TimeUnit.SECONDS);\n\n        rethrowExceptions(futures);\n\n        if (TestServlet.__maxSleepers < MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            Assert.assertEquals(TestServlet.__maxSleepers, MAX_QOS);\n    }","commit_id":"650db59e69e9068635c372631c11deec2435b7e0","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Test\n    public void testBlockingQosFilter() throws Exception\n    {\n        FilterHolder holder = new FilterHolder(QoSFilter2.class);\n        holder.setAsyncSupported(true);\n        holder.setInitParameter(QoSFilter.MAX_REQUESTS_INIT_PARAM, \"\" + MAX_QOS);\n        _tester.getContext().getServletHandler().addFilterWithMapping(holder, \"/*\", EnumSet.of(DispatcherType.REQUEST, DispatcherType.ASYNC));\n\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            new Thread(new Worker(i)).start();\n        }\n\n        _doneRequests.await(10, TimeUnit.SECONDS);\n        if (TestServlet.__maxSleepers < MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            Assert.assertEquals(TestServlet.__maxSleepers, MAX_QOS);\n    }","id":14382,"modified_method":"@Test\n    public void testBlockingQosFilter() throws Exception\n    {\n        FilterHolder holder = new FilterHolder(QoSFilter2.class);\n        holder.setAsyncSupported(true);\n        holder.setInitParameter(QoSFilter.MAX_REQUESTS_INIT_PARAM, \"\" + MAX_QOS);\n        _tester.getContext().getServletHandler().addFilterWithMapping(holder, \"/*\", EnumSet.of(DispatcherType.REQUEST, DispatcherType.ASYNC));\n\n        List<Worker> workers = new ArrayList<>();\n        for (int i = 0; i < NUM_CONNECTIONS; ++i)\n        {\n            workers.add(new Worker(i));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(NUM_CONNECTIONS);\n        List<Future<Void>> futures = executor.invokeAll(workers, 10, TimeUnit.SECONDS);\n\n        rethrowExceptions(futures);\n\n        if (TestServlet.__maxSleepers < MAX_QOS)\n            LOG.warn(\"TEST WAS NOT PARALLEL ENOUGH!\");\n        else\n            Assert.assertEquals(TestServlet.__maxSleepers, MAX_QOS);\n    }","commit_id":"650db59e69e9068635c372631c11deec2435b7e0","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Before\n    public void setUp() throws Exception\n    {\n        _tester = new ServletTester();\n        _tester.setContextPath(\"/context\");\n        _tester.addServlet(TestServlet.class, \"/test\");\n        TestServlet.__maxSleepers = 0;\n        TestServlet.__sleepers = 0;\n\n        _connectors = new LocalConnector[NUM_CONNECTIONS];\n        for (int i = 0; i < _connectors.length; ++i)\n            _connectors[i] = _tester.createLocalConnector();\n\n        _doneRequests = new CountDownLatch(NUM_CONNECTIONS * NUM_LOOPS);\n\n        _tester.start();\n    }","id":14383,"modified_method":"@Before\n    public void setUp() throws Exception\n    {\n        _tester = new ServletTester();\n        _tester.setContextPath(\"/context\");\n        _tester.addServlet(TestServlet.class, \"/test\");\n        TestServlet.__maxSleepers = 0;\n        TestServlet.__sleepers = 0;\n\n        _connectors = new LocalConnector[NUM_CONNECTIONS];\n        for (int i = 0; i < _connectors.length; ++i)\n            _connectors[i] = _tester.createLocalConnector();\n\n        _tester.start();\n    }","commit_id":"650db59e69e9068635c372631c11deec2435b7e0","url":"https://github.com/eclipse/jetty.project"},{"original_method":"/**\n     * Gets the content of a defined section in a given template file and its subtemplates\n     * with the given parameters.\n     *\n     * @see getContent(CmsObject cms, String templateFile, String elementName, Hashtable parameters)\n     * @param cms CmsObject Object for accessing system resources.\n     * @param templateFile Filename of the template file.\n     * @param elementName Element name of this template in our parent template.\n     * @param parameters Hashtable with all template class parameters.\n     * @param templateSelector template section that should be processed.\n     */\n    public byte[] getContent(CmsObject cms, String templateFile, String elementName, Hashtable parameters, String templateSelector) throws CmsException {\n        if(I_CmsLogChannels.C_PREPROCESSOR_IS_LOGGING && A_OpenCms.isLogging() && C_DEBUG) {\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"getting content of element \" + ((elementName == null) ? \"<root>\" : elementName));\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"template file is: \" + templateFile);\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"selected template section is: \" + ((templateSelector == null) ? \"<default>\" : templateSelector));\n        }\n        CmsXmlTemplateFile templateDocument = getOwnTemplateFile(cms, templateFile, elementName, parameters, templateSelector);\n        //CmsRequestContext reqCont = cms.getRequestContext();\n        I_CmsRegistry reg = cms.getRegistry();\n        I_CmsSession session = cms.getRequestContext().getSession(true);\n        String step = (String)parameters.get(C_STEP);\n        SimpleDateFormat dateFormat = new java.text.SimpleDateFormat(\"dd.MM.yyyy\");\n        if((step == null) || \"\".equals(step)) {\n            templateDocument.setData(C_PACKETNAME, \"\");\n            templateDocument.setData(C_VERSION, \"1\");\n            templateDocument.setData(C_MODULENAME, \"\");\n            templateDocument.setData(C_DESCRIPTION, \"\");\n            templateDocument.setData(C_VIEW, \"\");\n            templateDocument.setData(C_ADMINPOINT, \"\");\n            templateDocument.setData(C_MAINTENANCE, \"\");\n            templateDocument.setData(C_AUTHOR, \"\");\n            templateDocument.setData(C_EMAIL, \"\");\n            templateDocument.setData(C_MODULE_TYPE, \"checked\");\n\n            //  set the current date:\n            templateDocument.setData(C_DATE, dateFormat.format(new Date()));\n        }else {\n            if(\"OK\".equals(step) || \"Ok\".equals(step)) {\n                String packetname = (String)parameters.get(C_PACKETNAME);\n                String modulename = (String)parameters.get(C_MODULENAME);\n                String version = (String)parameters.get(C_VERSION);\n                String description = (String)parameters.get(C_DESCRIPTION);\n                String view = (String)parameters.get(C_VIEW);\n                String adminpoint = (String)parameters.get(C_ADMINPOINT);\n                String maintenance = (String)parameters.get(C_MAINTENANCE);\n                String author = (String)parameters.get(C_AUTHOR);\n                String email = (String)parameters.get(C_EMAIL);\n                String createDate = (String)parameters.get(C_DATE);\n                String moduleType = (String)parameters.get(C_MODULE_TYPE);\n                \n                boolean moduleExists = reg.moduleExists(packetname);\n                int v = -1;\n                try {\n                    v = Integer.parseInt(version);\n                }catch(Exception e) {\n                }\n                if((!checkName(packetname)) || (version == null) || (\"\".equals(version)) || moduleExists || (v < 0)) {\n                    Hashtable sessionData = new Hashtable();\n                    sessionData.put(C_MODULENAME, getStringValue(modulename));\n                    sessionData.put(C_VERSION, getStringValue(version));\n                    sessionData.put(C_DESCRIPTION, getStringValue(description));\n                    sessionData.put(C_VIEW, getStringValue(view));\n                    sessionData.put(C_ADMINPOINT, getStringValue(adminpoint));\n                    sessionData.put(C_MAINTENANCE, getStringValue(maintenance));\n                    sessionData.put(C_AUTHOR, getStringValue(author));\n                    sessionData.put(C_EMAIL, getStringValue(email));\n                    sessionData.put(C_DATE, getStringValue(createDate));\n                    sessionData.put(C_MODULE_TYPE, getStringValue(moduleType));\n                    session.putValue(C_SESSION_DATA, sessionData);\n                    if(moduleExists) {\n                        templateSelector = \"errorexists\";\n                    }else {\n                        templateSelector = \"errornoname\";\n                    }\n                }else {\n                    tryToCreateFolder(cms, \"/system/\", \"modules\");\n\n                    // create the module (first test if we are in a project including /system/\n                    try {\n                        cms.createResource(\"/system/modules/\", packetname, C_TYPE_FOLDER_NAME);\n                    }catch(CmsException e) {\n                        if(e.getType() != e.C_FILE_EXISTS) {\n\n                            //couldn't create Module\n                            templateDocument.setData(\"details\", Utils.getStackTrace(e));\n                            return startProcessing(cms, templateDocument, elementName, parameters, \"errorProject\");\n                        }else {\n                            try {\n                                cms.readFolder(\"/system/modules/\" + packetname + \"/\");\n                            }catch(CmsException ex) {\n                                // Folder exist but is deleted\n                                templateDocument.setData(\"details\", \"Sorry, you have to publish this Project and create a new one.\\n\" + Utils.getStackTrace(e));\n                                return startProcessing(cms, templateDocument, elementName, parameters, \"errorProject\");\n                            }\n                        }\n                    }\n                    long createDateLong = 0;\n                    try {\n                        createDateLong = dateFormat.parse(createDate).getTime();\n                    }catch(Exception exc) {\n                        createDateLong = (new Date()).getTime();\n                    }\n                    reg.createModule(packetname, getStringValue(modulename), getStringValue(description), getStringValue(author), createDateLong, v);\n                    reg.setModuleAuthorEmail(packetname, getStringValue(email));\n                    reg.setModuleMaintenanceEventClass(packetname, getStringValue(maintenance));\n                    \n                    if (moduleType!=null && moduleType.equals(\"checked\")) {\n                        reg.setModuleType( packetname, CmsRegistry.C_MODULE_TYPE_SIMPLE );\n                    }\n                    else {\n                        reg.setModuleType( packetname, CmsRegistry.C_MODULE_TYPE_TRADITIONAL );\n                    }\n\n                    tryToCreateFolder(cms, \"/\", \"moduledemos\");\n                    tryToCreateFolder(cms, \"/moduledemos/\", packetname);\n\n                    String modulePath = \"/system/modules/\" + packetname + \"/\";\n                    // create the class folder:\n                    tryToCreateFolder(cms, modulePath, \"classes\");\n                    Vector cFolders = new Vector();\n                    String workString = packetname;\n                    while(workString.lastIndexOf('.') > -1) {\n                        cFolders.addElement(workString.substring(workString.lastIndexOf('.') + 1));\n                        workString = workString.substring(0, workString.lastIndexOf('.'));\n                    }\n                    tryToCreateFolder(cms, modulePath+\"classes/\", workString);\n                    workString = modulePath + \"classes/\" + workString + \"/\";\n                    for(int i = cFolders.size() - 1;i >= 0;i--) {\n                        tryToCreateFolder(cms, workString, (String)cFolders.elementAt(i));\n                        workString = workString + (String)cFolders.elementAt(i) + \"/\";\n                    }\n\n                    tryToCreateFolder(cms, modulePath, \"lib\");\n                    tryToCreateFolder(cms, modulePath, I_CmsWpConstants.C_TEMPLATEDIR);\n\n                    tryToCreateFolder(cms, modulePath, \"contenttemplates\");\n                    tryToCreateFolder(cms, modulePath, \"frametemplates\");\n                    tryToCreateFolder(cms, modulePath, I_CmsWpConstants.C_DEFAULTBODIESDIR);\n                    tryToCreateFolder(cms, modulePath, \"elements\");\n                    tryToCreateFolder(cms, modulePath, \"language\");\n                    tryToCreateFolder(cms, modulePath + \"language/\", I_CmsWpConstants.C_DEFAULT_LANGUAGE);\n                    // tryToCreateFolder(cms, modulePath + \"language/\", \"de\");\n                    tryToCreateFolder(cms, modulePath, \"doc\");\n                    reg.setModuleDocumentPath(packetname, modulePath + \"doc/index.html\");\n                    if(\"checked\".equals(view)) {\n                        reg.setModuleView(packetname, packetname.replace('.', '_') + \".view\", modulePath + \"view/index.html\");\n                        tryToCreateFolder(cms, modulePath, \"view\");\n                    }\n                    if(\"checked\".equals(adminpoint)) {\n                        tryToCreateFolder(cms, modulePath, \"administration\");\n                        tryToCreateFolder(cms, modulePath, \"pics\");\n                    }\n                    try {\n                        cms.getRequestContext().getResponse().sendCmsRedirect(getConfigFile(cms).getWorkplaceAdministrationPath() + \"module/index.html\");\n                    }catch(Exception e) {\n                        throw new CmsException(\"Redirect fails :system/workplace/administration/module/index.html\", CmsException.C_UNKNOWN_EXCEPTION, e);\n                    }\n                    return null;\n                }\n            }else {\n                if(\"fromerrorpage\".equals(step)) {\n                    Hashtable sessionData = (Hashtable)session.getValue(C_SESSION_DATA);\n                    session.removeValue(C_SESSION_DATA);\n                    templateDocument.setData(C_PACKETNAME, \"\");\n                    templateDocument.setData(C_VERSION, (String)sessionData.get(C_VERSION));\n                    templateDocument.setData(C_MODULENAME, (String)sessionData.get(C_MODULENAME));\n                    templateDocument.setData(C_DESCRIPTION, (String)sessionData.get(C_DESCRIPTION));\n                    templateDocument.setData(C_VIEW, (String)sessionData.get(C_VIEW));\n                    templateDocument.setData(C_ADMINPOINT, (String)sessionData.get(C_ADMINPOINT));\n                    templateDocument.setData(C_MAINTENANCE, (String)sessionData.get(C_MAINTENANCE));\n                    templateDocument.setData(C_AUTHOR, (String)sessionData.get(C_AUTHOR));\n                    templateDocument.setData(C_EMAIL, (String)sessionData.get(C_EMAIL));\n                    templateDocument.setData(C_DATE, (String)sessionData.get(C_DATE));\n                    templateDocument.setData(C_MODULE_TYPE, (String)sessionData.get(C_MODULE_TYPE));\n                    templateSelector = \"\";\n                }\n            }\n        }\n\n        // Now load the template file and start the processing\n        return startProcessing(cms, templateDocument, elementName, parameters, templateSelector);\n    }","id":14384,"modified_method":"/**\n     * Gets the content of a defined section in a given template file and its subtemplates\n     * with the given parameters.\n     *\n     * @see getContent(CmsObject cms, String templateFile, String elementName, Hashtable parameters)\n     * @param cms CmsObject Object for accessing system resources.\n     * @param templateFile Filename of the template file.\n     * @param elementName Element name of this template in our parent template.\n     * @param parameters Hashtable with all template class parameters.\n     * @param templateSelector template section that should be processed.\n     */\n    public byte[] getContent(CmsObject cms, String templateFile, String elementName, Hashtable parameters, String templateSelector) throws CmsException {\n        if(I_CmsLogChannels.C_PREPROCESSOR_IS_LOGGING && A_OpenCms.isLogging() && C_DEBUG) {\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"getting content of element \" + ((elementName == null) ? \"<root>\" : elementName));\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"template file is: \" + templateFile);\n            A_OpenCms.log(C_OPENCMS_DEBUG, this.getClassName() + \"selected template section is: \" + ((templateSelector == null) ? \"<default>\" : templateSelector));\n        }\n        CmsXmlTemplateFile templateDocument = getOwnTemplateFile(cms, templateFile, elementName, parameters, templateSelector);\n        //CmsRequestContext reqCont = cms.getRequestContext();\n        I_CmsRegistry reg = cms.getRegistry();\n        I_CmsSession session = cms.getRequestContext().getSession(true);\n        String step = (String)parameters.get(C_STEP);\n        SimpleDateFormat dateFormat = new java.text.SimpleDateFormat(\"dd.MM.yyyy\");\n        if((step == null) || \"\".equals(step)) {\n            templateDocument.setData(C_PACKETNAME, \"\");\n            templateDocument.setData(C_VERSION, \"1\");\n            templateDocument.setData(C_MODULENAME, \"\");\n            templateDocument.setData(C_DESCRIPTION, \"\");\n            templateDocument.setData(C_VIEW, \"\");\n            templateDocument.setData(C_ADMINPOINT, \"\");\n            templateDocument.setData(C_MAINTENANCE, \"\");\n            templateDocument.setData(C_AUTHOR, \"\");\n            templateDocument.setData(C_EMAIL, \"\");\n            templateDocument.setData(C_MODULE_TYPE, \"checked\");\n            //  set the current date:\n            templateDocument.setData(C_DATE, dateFormat.format(new Date()));\n        }else {\n            if(\"OK\".equals(step) || \"Ok\".equals(step)) {\n                String packagename = (String)parameters.get(C_PACKETNAME);\n                String modulename = (String)parameters.get(C_MODULENAME);\n                String version = (String)parameters.get(C_VERSION);\n                String description = (String)parameters.get(C_DESCRIPTION);\n                String view = (String)parameters.get(C_VIEW);\n                String adminpoint = (String)parameters.get(C_ADMINPOINT);\n                String maintenance = (String)parameters.get(C_MAINTENANCE);\n                String author = (String)parameters.get(C_AUTHOR);\n                String email = (String)parameters.get(C_EMAIL);\n                String createDate = (String)parameters.get(C_DATE);\n                String moduleType = (String)parameters.get(C_MODULE_TYPE);\n                \n                boolean moduleExists = reg.moduleExists(packagename);\n                int v = -1;\n                try {\n                    v = Integer.parseInt(version);\n                }catch(Exception e) {\n                }\n                if((!checkName(packagename)) || (version == null) || (\"\".equals(version)) || moduleExists || (v < 0)) {\n                    Hashtable sessionData = new Hashtable();\n                    sessionData.put(C_MODULENAME, getStringValue(modulename));\n                    sessionData.put(C_VERSION, getStringValue(version));\n                    sessionData.put(C_DESCRIPTION, getStringValue(description));\n                    sessionData.put(C_VIEW, getStringValue(view));\n                    sessionData.put(C_ADMINPOINT, getStringValue(adminpoint));\n                    sessionData.put(C_MAINTENANCE, getStringValue(maintenance));\n                    sessionData.put(C_AUTHOR, getStringValue(author));\n                    sessionData.put(C_EMAIL, getStringValue(email));\n                    sessionData.put(C_DATE, getStringValue(createDate));\n                    sessionData.put(C_MODULE_TYPE, getStringValue(moduleType));\n                    session.putValue(C_SESSION_DATA, sessionData);\n                    if(moduleExists) {\n                        templateSelector = \"errorexists\";\n                    }else {\n                        templateSelector = \"errornoname\";\n                    }\n                }else {\n                    tryToCreateFolder(cms, \"/system/\", \"modules\");\n                    // create the module (first test if we are in a project including /system/\n                    try {\n                        cms.createResource(C_VFS_PATH_MODULES, packagename, C_TYPE_FOLDER_NAME);\n                    }catch(CmsException e) {\n                        if(e.getType() != e.C_FILE_EXISTS) {\n                            // couldn't create Module\n                            templateDocument.setData(\"details\", Utils.getStackTrace(e));\n                            return startProcessing(cms, templateDocument, elementName, parameters, \"errorProject\");\n                        }else {\n                            try {\n                                cms.readFolder(C_VFS_PATH_MODULES + packagename + \"/\");\n                            }catch(CmsException ex) {\n                                // folder exist but is deleted\n                                templateDocument.setData(\"details\", \"Sorry, you have to publish this Project and create a new one.\\n\" + Utils.getStackTrace(e));\n                                return startProcessing(cms, templateDocument, elementName, parameters, \"errorProject\");\n                            }\n                        }\n                    }\n                    long createDateLong = 0;\n                    try {\n                        createDateLong = dateFormat.parse(createDate).getTime();\n                    }catch(Exception exc) {\n                        createDateLong = (new Date()).getTime();\n                    }\n                    reg.createModule(packagename, getStringValue(modulename), getStringValue(description), getStringValue(author), createDateLong, v);\n                    reg.setModuleAuthorEmail(packagename, getStringValue(email));\n                    reg.setModuleMaintenanceEventClass(packagename, getStringValue(maintenance));\n                    \n                    boolean isSimpleModule = false;\n                    if (moduleType!=null && moduleType.equals(\"checked\")) {\n                        reg.setModuleType( packagename, CmsRegistry.C_MODULE_TYPE_SIMPLE );\n                        isSimpleModule = true;\n                    } else {\n                        reg.setModuleType( packagename, CmsRegistry.C_MODULE_TYPE_TRADITIONAL );\n                    }\n\n                    /*\n                    // Moduldemo folder is deprecated since 5.0 beta 2\n                    tryToCreateFolder(cms, \"/\", \"moduledemos\");\n                    tryToCreateFolder(cms, \"/moduledemos/\", packetname);\n                    */\n                    \n                    String modulePath = C_VFS_PATH_MODULES + packagename + \"/\";\n                    \n                    // as default dont export any module data                    \n                    cms.writeProperty(modulePath, C_PROPERTY_EXPORT, \"false\");\n                    \n                    // create the class folder:\n                    tryToCreateFolder(cms, modulePath, \"classes\");\n                    // create all package folders beneth class folder\n                    Vector cFolders = new Vector();\n                    String workString = packagename;\n                    while(workString.lastIndexOf('.') > -1) {\n                        cFolders.addElement(workString.substring(workString.lastIndexOf('.') + 1));\n                        workString = workString.substring(0, workString.lastIndexOf('.'));\n                    }\n                    tryToCreateFolder(cms, modulePath+\"classes/\", workString);\n                    workString = modulePath + \"classes/\" + workString + \"/\";\n                    for(int i = cFolders.size() - 1;i >= 0;i--) {\n                        tryToCreateFolder(cms, workString, (String)cFolders.elementAt(i));\n                        workString = workString + (String)cFolders.elementAt(i) + \"/\";\n                    }                    \n                    // create the lib folder, will get exportet to the \"real\" file system\n                    tryToCreateFolder(cms, modulePath, \"lib\");\n                    // create the templates folder\n                    tryToCreateFolder(cms, modulePath, I_CmsWpConstants.C_VFS_DIR_TEMPLATES);\n                    // create the \"default_bodies\" folder \n                    tryToCreateFolder(cms, modulePath, I_CmsWpConstants.C_VFS_DIR_DEFAULTBODIES);\n                    // crate \"elements\" folder\n                    tryToCreateFolder(cms, modulePath, \"elements\");\n\n                    if (isSimpleModule) {\n                        // simple module type \n                        reg.setModuleDocumentPath(packagename, modulePath + \"index.html\");                        \n                    } else {\n                        // traditional module type, create more directories\n                        tryToCreateFolder(cms, modulePath, \"contenttemplates\");\n                        tryToCreateFolder(cms, modulePath, \"frametemplates\");\n                        tryToCreateFolder(cms, modulePath, \"doc\");\n                        reg.setModuleDocumentPath(packagename, modulePath + \"doc/index.html\");\n                    }\n                    // initialize if we need a 'locales' subdirectory in our new module\n                    boolean needsLocaleDir = !isSimpleModule;\n                                        \n                    if(\"checked\".equals(view)) {\n                        reg.setModuleView(packagename, packagename.replace('.', '_') + \".view\", modulePath + \"view/index.html\");\n                        tryToCreateFolder(cms, modulePath, \"view\");\n                        needsLocaleDir = true;\n                    }\n                    if(\"checked\".equals(adminpoint)) {\n                        tryToCreateFolder(cms, modulePath, \"administration\");\n                        // create \"pics\" folder (required for workplace extension images)\n                        tryToCreateFolder(cms, modulePath, \"pics\");\n                        needsLocaleDir = true;\n                    }\n                    if (needsLocaleDir) {\n                        // create \"locales\" folder (required for workplace extension resource files)\n                        tryToCreateFolder(cms, modulePath, I_CmsWpConstants.C_VFS_DIR_LOCALES);\n                        tryToCreateFolder(cms, modulePath + I_CmsWpConstants.C_VFS_DIR_LOCALES, I_CmsWpConstants.C_DEFAULT_LANGUAGE);\n                    }\n                    \n                    try {\n                        cms.getRequestContext().getResponse().sendCmsRedirect(getConfigFile(cms).getWorkplaceAdministrationPath() + \"module/index.html\");\n                    }catch(Exception e) {\n                        throw new CmsException(\"Redirect fails :system/workplace/administration/module/index.html\", CmsException.C_UNKNOWN_EXCEPTION, e);\n                    }\n                    return null;\n                }\n            }else {\n                if(\"fromerrorpage\".equals(step)) {\n                    Hashtable sessionData = (Hashtable)session.getValue(C_SESSION_DATA);\n                    session.removeValue(C_SESSION_DATA);\n                    templateDocument.setData(C_PACKETNAME, \"\");\n                    templateDocument.setData(C_VERSION, (String)sessionData.get(C_VERSION));\n                    templateDocument.setData(C_MODULENAME, (String)sessionData.get(C_MODULENAME));\n                    templateDocument.setData(C_DESCRIPTION, (String)sessionData.get(C_DESCRIPTION));\n                    templateDocument.setData(C_VIEW, (String)sessionData.get(C_VIEW));\n                    templateDocument.setData(C_ADMINPOINT, (String)sessionData.get(C_ADMINPOINT));\n                    templateDocument.setData(C_MAINTENANCE, (String)sessionData.get(C_MAINTENANCE));\n                    templateDocument.setData(C_AUTHOR, (String)sessionData.get(C_AUTHOR));\n                    templateDocument.setData(C_EMAIL, (String)sessionData.get(C_EMAIL));\n                    templateDocument.setData(C_DATE, (String)sessionData.get(C_DATE));\n                    templateDocument.setData(C_MODULE_TYPE, (String)sessionData.get(C_MODULE_TYPE));\n                    templateSelector = \"\";\n                }\n            }\n        }\n\n        // Now load the template file and start the processing\n        return startProcessing(cms, templateDocument, elementName, parameters, templateSelector);\n    }","commit_id":"7520cd95b083c5eb5afd6df3751224195f858449","url":"https://github.com/alkacon/opencms-core"},{"original_method":"@Override\n        public int compareTo(MatchResult o) {\n            if (this.getExact() < o.getExact()) {\n                return -1;\n            } else if (this.getExact() > o.getExact()) {\n                return 1;\n            } else {\n                if (this.getAssignable() < o.getAssignable()) {\n                    return -1;\n                } else if (this.getAssignable() > o.getAssignable()) {\n                    return 1;\n                } else {\n                    if (this.getCoercible() < o.getCoercible()) {\n                        return -1;\n                    } else if (this.getCoercible() > o.getCoercible()) {\n                        return 1;\n                    } else {\n                        return 0;\n                    }\n                }\n            }\n        }","id":14385,"modified_method":"@Override\n        public int compareTo(MatchResult o) {\n            int cmp = Integer.compare(this.getExact(), o.getExact());\n            if (cmp == 0) {\n                cmp = Integer.compare(this.getAssignable(), o.getAssignable());\n                if (cmp == 0) {\n                    cmp = Integer.compare(this.getCoercible(), o.getCoercible());\n                }\n            }\n            return cmp;\n        }","commit_id":"0ed51fb78a6465ccea4d469cc4af105fd0edde0d","url":"https://github.com/apache/tomcat"},{"original_method":"@Override\n        public int compareTo(MatchResult o) {\n            if (this.getExact() < o.getExact()) {\n                return -1;\n            } else if (this.getExact() > o.getExact()) {\n                return 1;\n            } else {\n                if (this.getAssignable() < o.getAssignable()) {\n                    return -1;\n                } else if (this.getAssignable() > o.getAssignable()) {\n                    return 1;\n                } else {\n                    if (this.getCoercible() < o.getCoercible()) {\n                        return -1;\n                    } else if (this.getCoercible() > o.getCoercible()) {\n                        return 1;\n                    } else {\n                        return 0;\n                    }\n                }\n            }\n        }","id":14386,"modified_method":"@Override\n        public int compareTo(MatchResult o) {\n            int cmp = Integer.compare(this.getExact(), o.getExact());\n            if (cmp == 0) {\n                cmp = Integer.compare(this.getAssignable(), o.getAssignable());\n                if (cmp == 0) {\n                    cmp = Integer.compare(this.getCoercible(), o.getCoercible());\n                }\n            }\n            return cmp;\n        }","commit_id":"0ed51fb78a6465ccea4d469cc4af105fd0edde0d","url":"https://github.com/apache/tomcat"},{"original_method":"static ModelNode getSubsystem(Locale locale) {\n        final ResourceBundle bundle = getResourceBundle(locale);\n\n        final ModelNode subsystem = new ModelNode();\n\n        subsystem.get(ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"txn\"));\n        subsystem.get(ModelDescriptionConstants.HEAD_COMMENT_ALLOWED).set(true);\n        subsystem.get(ModelDescriptionConstants.TAIL_COMMENT_ALLOWED).set(true);\n        subsystem.get(ModelDescriptionConstants.NAMESPACE).set(Namespace.TRANSACTIONS_1_0.getUriString());\n        // core-environment\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(true);\n        // core-environment.node-identifier\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.node-identifier\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.DEFAULT).set(1);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.REQUIRED).set(false);\n        // core-environment/process-id\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.process-id\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.REQUIRED).set(true);\n        // core-environment/process-id/uuid\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.process-id.uuid\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.MIN_LENGTH).set(0);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.REQUIRED).set(false);\n\n        /* Not currently used\n        subsystem.get(ATTRIBUTES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, DESCRIPTION).set(bundle.getString(\"core-environment.socket-process-id-max-ports\"));\n        subsystem.get(ATTRIBUTES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, TYPE).set(ModelType.INT);\n        subsystem.get(ATTRIBUTES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, DEFAULT).set(10);\n        subsystem.get(ATTRIBUTES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, REQUIRED).set(false);\n        */\n\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(true);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment.socket-binding\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.REQUIRED).set(true);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment.status-socket-binding\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.REQUIRED).set(true);\n\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment.recovery-listener\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.TYPE).set(ModelType.BOOLEAN);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.REQUIRED).set(false);\n\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment.enable-statistics\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.TYPE).set(ModelType.BOOLEAN);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.DEFAULT).set(true);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_TSM_STATUS, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment.enable-tsm-status\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_TSM_STATUS, ModelDescriptionConstants.TYPE).set(ModelType.BOOLEAN);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_TSM_STATUS, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_TSM_STATUS, ModelDescriptionConstants.DEFAULT).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment.default-timeout\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.TYPE).set(ModelType.BOOLEAN);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.DEFAULT).set(300);\n\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store.relative-to\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.REQUIRED).set(false);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store.path\"));\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        subsystem.get(ModelDescriptionConstants.ATTRIBUTES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.REQUIRED).set(false);\n\n        for (TxStatsHandler.TxStat stat : EnumSet.allOf(TxStatsHandler.TxStat.class)) {\n            String statString = stat.toString();\n            subsystem.get(ModelDescriptionConstants.ATTRIBUTES, statString, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(statString));\n            subsystem.get(ModelDescriptionConstants.ATTRIBUTES, statString, ModelDescriptionConstants.TYPE).set(ModelType.LONG);\n        }\n\n        return subsystem;\n    }","id":14387,"modified_method":"static ModelNode getSubsystem(Locale locale) {\n        final ResourceBundle bundle = getResourceBundle(locale);\n\n        final ModelNode subsystem = new ModelNode();\n\n        subsystem.get(ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"txn\"));\n        subsystem.get(ModelDescriptionConstants.HEAD_COMMENT_ALLOWED).set(true);\n        subsystem.get(ModelDescriptionConstants.TAIL_COMMENT_ALLOWED).set(true);\n        subsystem.get(ModelDescriptionConstants.NAMESPACE).set(Namespace.TRANSACTIONS_1_0.getUriString());\n\n        for (TxStatsHandler.TxStat stat : EnumSet.allOf(TxStatsHandler.TxStat.class)) {\n            String statString = stat.toString();\n            subsystem.get(ModelDescriptionConstants.ATTRIBUTES, statString, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(statString));\n            subsystem.get(ModelDescriptionConstants.ATTRIBUTES, statString, ModelDescriptionConstants.TYPE).set(ModelType.LONG);\n        }\n\n        subsystem.get(CHILDREN, CommonAttributes.CORE_ENVIRONMENT, DESCRIPTION).set(bundle.getString(\"core-environment\"));\n        subsystem.get(CHILDREN, CommonAttributes.CORE_ENVIRONMENT, MAX_OCCURS).set(1);\n\n        subsystem.get(CHILDREN, CommonAttributes.RECOVERY_ENVIRONMENT, DESCRIPTION).set(bundle.getString(\"recovery-environment\"));\n        subsystem.get(CHILDREN, CommonAttributes.RECOVERY_ENVIRONMENT, MAX_OCCURS).set(1);\n\n        subsystem.get(CHILDREN, CommonAttributes.COORDINATOR_ENVIRONMENT, DESCRIPTION).set(bundle.getString(\"coordinator-environment\"));\n        subsystem.get(CHILDREN, CommonAttributes.COORDINATOR_ENVIRONMENT, MAX_OCCURS).set(1);\n\n        subsystem.get(CHILDREN, CommonAttributes.OBJECT_STORE, DESCRIPTION).set(bundle.getString(\"object-store\"));\n        subsystem.get(CHILDREN, CommonAttributes.OBJECT_STORE, MAX_OCCURS).set(1);\n\n\n        return subsystem;\n    }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"static ModelNode getSubsystemAdd(Locale locale) {\n        final ResourceBundle bundle = getResourceBundle(locale);\n\n        final ModelNode op = new ModelNode();\n\n        op.get(ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"txn.add\"));\n        op.get(ModelDescriptionConstants.HEAD_COMMENT_ALLOWED).set(true);\n        op.get(ModelDescriptionConstants.TAIL_COMMENT_ALLOWED).set(true);\n        op.get(ModelDescriptionConstants.NAMESPACE).set(Namespace.TRANSACTIONS_1_0.getUriString());\n\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(true);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.node-identifier\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.DEFAULT).set(1);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.NODE_IDENTIFIER, ModelDescriptionConstants.REQUIRED).set(false);\n        // core-environment/process-id\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.process-id\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.PROCESS_ID, ModelDescriptionConstants.REQUIRED).set(true);\n        // core-environment/process-id/uuid\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"core-environment.process-id.uuid\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.MIN_LENGTH).set(0);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.CORE_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.UUID, ModelDescriptionConstants.REQUIRED).set(false);\n\n        /* Not currently used\n        subsystem.get(REQUEST_PROPERTIES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, DESCRIPTION).set(bundle.getString(\"core-environment.socket-process-id-max-ports\"));\n        subsystem.get(REQUEST_PROPERTIES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, TYPE).set(ModelType.INT);\n        subsystem.get(REQUEST_PROPERTIES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, DEFAULT).set(10);\n        subsystem.get(REQUEST_PROPERTIES, CORE_ENVIRONMENT, VALUE_TYPE, SOCKET_PROCESS_ID_MAX_PORTS, REQUIRED).set(false);\n        */\n\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(true);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment.socket-binding\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.BINDING, ModelDescriptionConstants.REQUIRED).set(true);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"recovery-environment.status-socket-binding\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.MIN_LENGTH).set(1);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.RECOVERY_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.STATUS_BINDING, ModelDescriptionConstants.REQUIRED).set(true);\n\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.REQUIRED).set(false);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment.enable-statistics\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.TYPE).set(ModelType.BOOLEAN);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.REQUIRED).set(false);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.ENABLE_STATISTICS, ModelDescriptionConstants.DEFAULT).set(true);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"coordinator-environment.default-timeout\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.TYPE).set(ModelType.INT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.REQUIRED).set(false);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.COORDINATOR_ENVIRONMENT, ModelDescriptionConstants.VALUE_TYPE, CommonAttributes.DEFAULT_TIMEOUT, ModelDescriptionConstants.DEFAULT).set(300);\n\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.TYPE).set(ModelType.OBJECT);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.REQUIRED).set(false);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store.relative-to\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.RELATIVE_TO, ModelDescriptionConstants.REQUIRED).set(false);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"object-store.path\"));\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.TYPE).set(ModelType.STRING);\n        op.get(ModelDescriptionConstants.REQUEST_PROPERTIES, CommonAttributes.OBJECT_STORE, ModelDescriptionConstants.VALUE_TYPE, ModelDescriptionConstants.PATH, ModelDescriptionConstants.REQUIRED).set(false);\n\n        op.get(ModelDescriptionConstants.REPLY_PROPERTIES).setEmptyObject();\n\n        return op;\n    }","id":14388,"modified_method":"static ModelNode getSubsystemAdd(Locale locale) {\n        final ResourceBundle bundle = getResourceBundle(locale);\n\n        final ModelNode op = new ModelNode();\n        op.get(ModelDescriptionConstants.DESCRIPTION).set(bundle.getString(\"txn.add\"));\n        op.get(OPERATION_NAME).set(ADD);\n\n        op.get(REQUEST_PROPERTIES).setEmptyObject();\n        op.get(ModelDescriptionConstants.REPLY_PROPERTIES).setEmptyObject();\n\n        return op;\n    }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n         * Handle the process-id child elements\n         * @param reader\n         * @return\n         * @throws XMLStreamException\n         */\n        static ModelNode parseProcessIdEnvironmentElement(XMLExtendedStreamReader reader) throws XMLStreamException {\n\n            final ModelNode processId = new ModelNode();\n\n            // elements\n            final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n            while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n                final Element element = Element.forName(reader.getLocalName());\n                switch (element) {\n                  case UUID:\n                      if (!encountered.add(element)) {\n                          throw duplicateNamedElement(reader, reader.getLocalName());\n                      }\n                      processId.get(CommonAttributes.UUID).set(element.getLocalName());\n                      requireNoContent(reader);\n                      break;\n                  case SOCKET: {\n                      if (!encountered.add(element)) {\n                          throw duplicateNamedElement(reader, reader.getLocalName());\n                      }\n                    ModelNode socketId = parseSocketProcessIdElement(reader);\n                    processId.get(CommonAttributes.SOCKET).set(socketId);\n                    break;\n                  }\n                  default:\n                     throw unexpectedElement(reader);\n               }\n            }\n\n            return processId;\n        }","id":14389,"modified_method":"/**\n         * Handle the core-environment element and children\n         * @param reader\n         * @return ModelNode for the core-environment\n         * @throws XMLStreamException\n         */\n        static void parseCoreEnvironmentElement(final XMLExtendedStreamReader reader, final List<ModelNode> list, final ModelNode parentAddress) throws XMLStreamException {\n            final ModelNode env = parentAddress.clone();\n            final ModelNode operation = new ModelNode();\n            operation.get(OP).set(ADD);\n            env.add(CORE_ENVIRONMENT, CORE_ENVIRONMENT);\n            env.protect();\n\n            operation.get(OP_ADDR).set(env);\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case NODE_IDENTIFIER:\n                        operation.get(NODE_IDENTIFIER).set(value);\n                        break;\n                    default:\n                        throw unexpectedAttribute(reader, i);\n                }\n            }\n            // elements\n            final EnumSet<Element> required = EnumSet.of(Element.PROCESS_ID);\n            final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n            while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n                final Element element = Element.forName(reader.getLocalName());\n                required.remove(element);\n                switch (element) {\n                  case PROCESS_ID : {\n                      if (!encountered.add(element)) {\n                          throw duplicateNamedElement(reader, reader.getLocalName());\n                      }\n                    ModelNode processId = parseProcessIdEnvironmentElement(reader);\n                    operation.get(CommonAttributes.PROCESS_ID).set(processId);\n\n                    break;\n                  }\n                  default:\n                     throw unexpectedElement(reader);\n                }\n            }\n            if (! required.isEmpty()) {\n                throw missingRequired(reader, required);\n            }\n            list.add(operation);\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n            ModelNode add = createEmptyAddOperation();\n\n            final ModelNode model = context.readModel(PathAddress.EMPTY_ADDRESS);\n\n            if (model.hasDefined(CORE_ENVIRONMENT)) {\n                add.get(CORE_ENVIRONMENT).set(model.get(CORE_ENVIRONMENT));\n            }\n            if (model.hasDefined(RECOVERY_ENVIRONMENT)) {\n                add.get(RECOVERY_ENVIRONMENT).set(model.get(RECOVERY_ENVIRONMENT));\n            }\n            if (model.hasDefined(COORDINATOR_ENVIRONMENT)) {\n                add.get(COORDINATOR_ENVIRONMENT).set(model.get(COORDINATOR_ENVIRONMENT));\n            }\n\n            if (model.hasDefined(OBJECT_STORE)) {\n                add.get(OBJECT_STORE).set(model.get(OBJECT_STORE));\n            }\n\n            context.getResult().add(add);\n\n            context.completeStep();\n        }","id":14390,"modified_method":"public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n            ModelNode add = createEmptyAddOperation();\n\n            final ModelNode model = context.readModel(PathAddress.EMPTY_ADDRESS);\n\n            context.getResult().add(add);\n\n            context.completeStep();\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"static ModelNode parseRecoveryEnvironmentElement(XMLExtendedStreamReader reader) throws XMLStreamException {\n            final ModelNode env = new ModelNode();\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case BINDING:\n                        env.get(BINDING).set(value);\n                        break;\n                    case STATUS_BINDING:\n                        env.get(STATUS_BINDING).set(value);\n                        break;\n                    case RECOVERY_LISTENER:\n                        env.get(RECOVERY_LISTENER).set(value);\n                        break;\n                    default:\n                        unexpectedAttribute(reader, i);\n                }\n            }\n            if(! env.has(BINDING)) {\n                throw missingRequired(reader, Collections.singleton(Attribute.BINDING));\n            }\n            // Handle elements\n            requireNoContent(reader);\n            return env;\n        }","id":14391,"modified_method":"static void parseRecoveryEnvironmentElement(final XMLExtendedStreamReader reader, final List<ModelNode> list, final ModelNode parentAddress) throws XMLStreamException {\n            final ModelNode recoveryEnvAddress = parentAddress.clone();\n            final ModelNode operation = new ModelNode();\n            operation.get(OP).set(ADD);\n            recoveryEnvAddress.add(RECOVERY_ENVIRONMENT, RECOVERY_ENVIRONMENT);\n            recoveryEnvAddress.protect();\n\n            operation.get(OP_ADDR).set(recoveryEnvAddress);\n\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case BINDING:\n                        operation.get(BINDING).set(value);\n                        break;\n                    case STATUS_BINDING:\n                        operation.get(STATUS_BINDING).set(value);\n                        break;\n                    case RECOVERY_LISTENER:\n                        operation.get(RECOVERY_LISTENER).set(value);\n                        break;\n                    default:\n                        unexpectedAttribute(reader, i);\n                }\n            }\n            if(! operation.hasDefined(BINDING)) {\n                throw missingRequired(reader, Collections.singleton(Attribute.BINDING));\n            }\n            // Handle elements\n            requireNoContent(reader);\n            list.add(operation);\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"/** {@inheritDoc} */\n    @Override\n    public void initialize(ExtensionContext context) {\n        ROOT_LOGGER.debug(\"Initializing Transactions Extension\");\n        final SubsystemRegistration subsystem = context.registerSubsystem(SUBSYSTEM_NAME);\n        final ManagementResourceRegistration registration = subsystem.registerSubsystemModel(TransactionSubsystemProviders.SUBSYSTEM);\n        registration.registerOperationHandler(ADD, TransactionSubsystemAdd.INSTANCE, TransactionSubsystemProviders.SUBSYSTEM_ADD, false);\n        registration.registerOperationHandler(DESCRIBE, TransactionDescribeHandler.INSTANCE, TransactionDescribeHandler.INSTANCE, false, OperationEntry.EntryType.PRIVATE);\n        for (TxStatsHandler.TxStat stat : EnumSet.allOf(TxStatsHandler.TxStat.class)) {\n            registration.registerMetric(stat.toString(), TxStatsHandler.INSTANCE);\n        }\n        subsystem.registerXMLElementWriter(parser);\n    }","id":14392,"modified_method":"/** {@inheritDoc} */\n    @Override\n    public void initialize(ExtensionContext context) {\n        ROOT_LOGGER.debug(\"Initializing Transactions Extension\");\n        final SubsystemRegistration subsystem = context.registerSubsystem(SUBSYSTEM_NAME);\n        final ManagementResourceRegistration registration = subsystem.registerSubsystemModel(TransactionSubsystemProviders.SUBSYSTEM);\n        registration.registerOperationHandler(ADD, TransactionSubsystemAdd.INSTANCE, TransactionSubsystemProviders.SUBSYSTEM_ADD, false);\n        registration.registerOperationHandler(DESCRIBE, TransactionDescribeHandler.INSTANCE, TransactionDescribeHandler.INSTANCE, false, OperationEntry.EntryType.PRIVATE);\n\n        final ManagementResourceRegistration recoveryEnv = registration.registerSubModel(PathElement.pathElement(RECOVERY_ENVIRONMENT),\n                TransactionSubsystemProviders.RECOVERY_ENVIRONMENT_DESC);\n        recoveryEnv.registerOperationHandler(ADD, RecoveryEnvironmentAdd.INSTANCE, TransactionSubsystemProviders.ADD_RECOVERY_ENVIRONMENT_DESC, false);\n        recoveryEnv.registerOperationHandler(REMOVE, RecoveryEnvironmentRemove.INSTANCE, TransactionSubsystemProviders.REMOVE_RECOVERY_ENVIRONMENT_DESC, false);\n\n        final ManagementResourceRegistration coreEnv = registration.registerSubModel(PathElement.pathElement(CORE_ENVIRONMENT),\n                TransactionSubsystemProviders.CORE_ENVIRONMENT_DESC);\n        coreEnv.registerOperationHandler(ADD, CoreEnvironmentAdd.INSTANCE, TransactionSubsystemProviders.ADD_CORE_ENVIRONMENT_DESC, false);\n        coreEnv.registerOperationHandler(REMOVE, CoreEnvironmentRemove.INSTANCE, TransactionSubsystemProviders.REMOVE_CORE_ENVIRONMENT_DESC, false);\n\n        final ManagementResourceRegistration coordinatorEnv = registration.registerSubModel(PathElement.pathElement(COORDINATOR_ENVIRONMENT),\n                TransactionSubsystemProviders.COORDINATOR_ENVIRONMENT_DESC);\n        coordinatorEnv.registerOperationHandler(ADD, CoordinatorEnvironmentAdd.INSTANCE, TransactionSubsystemProviders.ADD_COORDINATOR_ENVIRONMENT_DESC, false);\n        coordinatorEnv.registerOperationHandler(REMOVE, CoordinatorEnvironmentRemove.INSTANCE, TransactionSubsystemProviders.REMOVE_COORDINATOR_ENVIRONMENT_DESC, false);\n\n        final ManagementResourceRegistration objectStore = registration.registerSubModel(PathElement.pathElement(OBJECT_STORE),\n                TransactionSubsystemProviders.OBJECT_STORE_DESC);\n        objectStore.registerOperationHandler(ADD, ObjectStoreAdd.INSTANCE, TransactionSubsystemProviders.ADD_OBJECT_STORE_DESC, false);\n        objectStore.registerOperationHandler(REMOVE, ObjectStoreRemove.INSTANCE, TransactionSubsystemProviders.REMOVE_OBJECT_STORE_DESC, false);\n\n        for (TxStatsHandler.TxStat stat : EnumSet.allOf(TxStatsHandler.TxStat.class)) {\n            registration.registerMetric(stat.toString(), TxStatsHandler.INSTANCE);\n        }\n        subsystem.registerXMLElementWriter(parser);\n    }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"/** {@inheritDoc} */\n        @Override\n        public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n\n            context.startSubsystemElement(Namespace.CURRENT.getUriString(), false);\n\n            ModelNode node = context.getModelNode();\n\n            if (has(node, CORE_ENVIRONMENT)) {\n                writer.writeStartElement(Element.CORE_ENVIRONMENT.getLocalName());\n                final ModelNode core = node.get(CORE_ENVIRONMENT);\n                if (has(core, PROCESS_ID)) {\n                    writeProcessId(writer, core.get(PROCESS_ID));\n                }\n                if (has(core, NODE_IDENTIFIER)) {\n                    writeAttribute(writer, Attribute.NODE_IDENTIFIER, core.get(NODE_IDENTIFIER));\n                }\n                writer.writeEndElement();\n            }\n            if (has(node, RECOVERY_ENVIRONMENT)) {\n                writer.writeStartElement(Element.RECOVERY_ENVIRONMENT.getLocalName());\n                final ModelNode env = node.get(RECOVERY_ENVIRONMENT);\n                if (has(env, BINDING)) {\n                    writeAttribute(writer, Attribute.BINDING, env.get(BINDING));\n                }\n                if (has(env, STATUS_BINDING)) {\n                    writeAttribute(writer, Attribute.STATUS_BINDING, env.get(STATUS_BINDING));\n                }\n                if (has(env, RECOVERY_LISTENER)) {\n                    writeAttribute(writer, Attribute.RECOVERY_LISTENER, env.get(RECOVERY_LISTENER));\n                }\n                writer.writeEndElement();\n            }\n            if (has(node, COORDINATOR_ENVIRONMENT)) {\n                writer.writeStartElement(Element.COORDINATOR_ENVIRONMENT.getLocalName());\n                final ModelNode env = node.get(COORDINATOR_ENVIRONMENT);\n                if (has(env, ENABLE_STATISTICS)) {\n                    writeAttribute(writer, Attribute.ENABLE_STATISTICS, env.get(ENABLE_STATISTICS));\n                }\n                if (has(env, ENABLE_TSM_STATUS)) {\n                    writeAttribute(writer, Attribute.ENABLE_TSM_STATUS, env.get(ENABLE_TSM_STATUS));\n                }\n                if (has(env, DEFAULT_TIMEOUT)) {\n                    writeAttribute(writer, Attribute.DEFAULT_TIMEOUT, env.get(DEFAULT_TIMEOUT));\n                }\n                writer.writeEndElement();\n            }\n            if (has(node, OBJECT_STORE)) {\n                writer.writeStartElement(Element.OBJECT_STORE.getLocalName());\n                final ModelNode env = node.get(OBJECT_STORE);\n                if (has(env, RELATIVE_TO)) {\n                    writeAttribute(writer, Attribute.RELATIVE_TO, env.get(RELATIVE_TO));\n                }\n                if (has(env, PATH)) {\n                    writeAttribute(writer, Attribute.PATH, env.get(PATH));\n                }\n                writer.writeEndElement();\n            }\n            writer.writeEndElement();\n        }","id":14393,"modified_method":"/** {@inheritDoc} */\n        @Override\n        public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n\n            context.startSubsystemElement(Namespace.CURRENT.getUriString(), false);\n\n            ModelNode node = context.getModelNode();\n\n            if (hasDefined(node, CORE_ENVIRONMENT) && node.get(CORE_ENVIRONMENT).asPropertyList().size() != 0) {\n                writer.writeStartElement(Element.CORE_ENVIRONMENT.getLocalName());\n                final ModelNode core = node.get(CORE_ENVIRONMENT).asPropertyList().get(0).getValue();\n                if (hasDefined(core, NODE_IDENTIFIER)) {\n                    writeAttribute(writer, Attribute.NODE_IDENTIFIER, core.get(NODE_IDENTIFIER));\n                }\n                if (hasDefined(core, PROCESS_ID)) {\n                    writeProcessId(writer, core.get(PROCESS_ID));\n                }\n                writer.writeEndElement();\n            }\n            if (hasDefined(node, RECOVERY_ENVIRONMENT) && node.get(RECOVERY_ENVIRONMENT).asPropertyList().size() != 0) {\n                writer.writeStartElement(Element.RECOVERY_ENVIRONMENT.getLocalName());\n                final ModelNode env = node.get(RECOVERY_ENVIRONMENT).asPropertyList().get(0).getValue();\n                if (hasDefined(env, BINDING)) {\n                    writeAttribute(writer, Attribute.BINDING, env.get(BINDING));\n                }\n                if (hasDefined(env, STATUS_BINDING)) {\n                    writeAttribute(writer, Attribute.STATUS_BINDING, env.get(STATUS_BINDING));\n                }\n                if (hasDefined(env, RECOVERY_LISTENER)) {\n                    writeAttribute(writer, Attribute.RECOVERY_LISTENER, env.get(RECOVERY_LISTENER));\n                }\n                writer.writeEndElement();\n            }\n            if (hasDefined(node, COORDINATOR_ENVIRONMENT) && node.get(COORDINATOR_ENVIRONMENT).asPropertyList().size() != 0) {\n                writer.writeStartElement(Element.COORDINATOR_ENVIRONMENT.getLocalName());\n                final ModelNode env = node.get(COORDINATOR_ENVIRONMENT).asPropertyList().get(0).getValue();\n                if (hasDefined(env, ENABLE_STATISTICS)) {\n                    writeAttribute(writer, Attribute.ENABLE_STATISTICS, env.get(ENABLE_STATISTICS));\n                }\n                if (hasDefined(env, ENABLE_TSM_STATUS)) {\n                    writeAttribute(writer, Attribute.ENABLE_TSM_STATUS, env.get(ENABLE_TSM_STATUS));\n                }\n                if (hasDefined(env, DEFAULT_TIMEOUT)) {\n                    writeAttribute(writer, Attribute.DEFAULT_TIMEOUT, env.get(DEFAULT_TIMEOUT));\n                }\n                writer.writeEndElement();\n            }\n            if (hasDefined(node, OBJECT_STORE) && node.get(OBJECT_STORE).asPropertyList().size() != 0) {\n                writer.writeStartElement(Element.OBJECT_STORE.getLocalName());\n                final ModelNode env = node.get(OBJECT_STORE).asPropertyList().get(0).getValue();\n                if (hasDefined(env, RELATIVE_TO)) {\n                    writeAttribute(writer, Attribute.RELATIVE_TO, env.get(RELATIVE_TO));\n                }\n                if (hasDefined(env, PATH)) {\n                    writeAttribute(writer, Attribute.PATH, env.get(PATH));\n                }\n                writer.writeEndElement();\n            }\n            writer.writeEndElement();\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void writeProcessId(final XMLExtendedStreamWriter writer, final ModelNode value) throws XMLStreamException {\n            writer.writeStartElement(Element.PROCESS_ID.getLocalName());\n            if(has(value, Element.UUID.getLocalName())) {\n                writer.writeEmptyElement(Element.UUID.getLocalName());\n            }\n            else if(has(value, Element.SOCKET.getLocalName())) {\n                writer.writeStartElement(Element.SOCKET.getLocalName());\n                if (has(value, BINDING)) {\n                    writeAttribute(writer, Attribute.BINDING, value.get(BINDING));\n                }\n                if (has(value, SOCKET_PROCESS_ID_MAX_PORTS)) {\n                    writeAttribute(writer, Attribute.SOCKET_PROCESS_ID_MAX_PORTS, value.get(SOCKET_PROCESS_ID_MAX_PORTS));\n                }\n                writer.writeEndElement();\n            }\n            writer.writeEndElement();\n        }","id":14394,"modified_method":"private void writeProcessId(final XMLExtendedStreamWriter writer, final ModelNode value) throws XMLStreamException {\n            writer.writeStartElement(Element.PROCESS_ID.getLocalName());\n            if(hasDefined(value, Element.UUID.getLocalName())) {\n                writer.writeEmptyElement(Element.UUID.getLocalName());\n            }\n            else if(hasDefined(value, Element.SOCKET.getLocalName())) {\n                writer.writeStartElement(Element.SOCKET.getLocalName());\n                if (hasDefined(value, BINDING)) {\n                    writeAttribute(writer, Attribute.BINDING, value.get(BINDING));\n                }\n                if (hasDefined(value, SOCKET_PROCESS_ID_MAX_PORTS)) {\n                    writeAttribute(writer, Attribute.SOCKET_PROCESS_ID_MAX_PORTS, value.get(SOCKET_PROCESS_ID_MAX_PORTS));\n                }\n                writer.writeEndElement();\n            }\n            writer.writeEndElement();\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"private boolean has(ModelNode node, String name) {\n            return node.has(name) && node.get(name).isDefined();\n        }","id":14395,"modified_method":"private boolean hasDefined(ModelNode node, String name) {\n            return node.hasDefined(name) && node.get(name).isDefined();\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"static ModelNode parseObjectStoreEnvironmentElement(XMLExtendedStreamReader reader) throws XMLStreamException {\n            final ModelNode store = new ModelNode();\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case RELATIVE_TO:\n                        store.get(RELATIVE_TO).set(value);\n                        break;\n                    case PATH:\n                        store.get(PATH).set(value);\n                        break;\n                    default:\n                        throw unexpectedAttribute(reader, i);\n                }\n            }\n            // Handle elements\n            requireNoContent(reader);\n            return store;\n        }","id":14396,"modified_method":"static void parseObjectStoreEnvironmentElementAndEnrichOperation(final XMLExtendedStreamReader reader, ModelNode operation) throws XMLStreamException {\n\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case RELATIVE_TO:\n                        operation.get(RELATIVE_TO).set(value);\n                        break;\n                    case PATH:\n                        operation.get(PATH).set(value);\n                        break;\n                    default:\n                        throw unexpectedAttribute(reader, i);\n                }\n            }\n            // Handle elements\n            requireNoContent(reader);\n\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n         * Handle the core-environment element and children\n         * @param reader\n         * @return ModelNode for the core-environment\n         * @throws XMLStreamException\n         */\n        static ModelNode parseCoreEnvironmentElement(XMLExtendedStreamReader reader) throws XMLStreamException {\n\n            final ModelNode env = new ModelNode();\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case NODE_IDENTIFIER:\n                        env.get(NODE_IDENTIFIER).set(value);\n                        break;\n                    default:\n                        throw unexpectedAttribute(reader, i);\n                }\n            }\n            // elements\n            final EnumSet<Element> required = EnumSet.of(Element.PROCESS_ID);\n            final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n            while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n                final Element element = Element.forName(reader.getLocalName());\n                required.remove(element);\n                switch (element) {\n                  case PROCESS_ID : {\n                      if (!encountered.add(element)) {\n                          throw duplicateNamedElement(reader, reader.getLocalName());\n                      }\n                    ModelNode processId = parseProcessIdEnvironmentElement(reader);\n                    env.get(CommonAttributes.PROCESS_ID).set(processId);\n\n                    break;\n                  }\n                  default:\n                     throw unexpectedElement(reader);\n                }\n            }\n            if (! required.isEmpty()) {\n                throw missingRequired(reader, required);\n            }\n            return env;\n        }","id":14397,"modified_method":"static void parseCoordinatorEnvironmentElement(final XMLExtendedStreamReader reader, final List<ModelNode> list, final ModelNode parentAddress) throws XMLStreamException {\n            final ModelNode env = parentAddress.clone();\n            final ModelNode operation = new ModelNode();\n            operation.get(OP).set(ADD);\n            env.add(COORDINATOR_ENVIRONMENT, COORDINATOR_ENVIRONMENT);\n            env.protect();\n\n            operation.get(OP_ADDR).set(env);\n            final int count = reader.getAttributeCount();\n            for (int i = 0; i < count; i ++) {\n                requireNoNamespaceAttribute(reader, i);\n                final String value = reader.getAttributeValue(i);\n                final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n                switch (attribute) {\n                    case ENABLE_STATISTICS:\n                        operation.get(ENABLE_STATISTICS).set(value);\n                        break;\n                    case ENABLE_TSM_STATUS:\n                        operation.get(ENABLE_TSM_STATUS).set(value);\n                        break;\n                    case DEFAULT_TIMEOUT:\n                        operation.get(DEFAULT_TIMEOUT).set(value);\n                        break;\n                    default:\n                        throw unexpectedAttribute(reader, i);\n                }\n            }\n            // Handle elements\n            requireNoContent(reader);\n            list.add(operation);\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"/** {@inheritDoc} */\n        @Override\n        public void readElement(XMLExtendedStreamReader reader, List<ModelNode> list) throws XMLStreamException {\n            // no attributes\n            if (reader.getAttributeCount() > 0) {\n                throw unexpectedAttribute(reader, 0);\n            }\n\n            final ModelNode subsystem = createEmptyAddOperation();\n            list.add(subsystem);\n\n\n            // elements\n            final EnumSet<Element> required = EnumSet.of(Element.RECOVERY_ENVIRONMENT, Element.CORE_ENVIRONMENT);\n            final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n            while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n                switch (Namespace.forUri(reader.getNamespaceURI())) {\n                    case TRANSACTIONS_1_0: {\n                        final Element element = Element.forName(reader.getLocalName());\n                        required.remove(element);\n                        if (! encountered.add(element)) {\n                            throw unexpectedElement(reader);\n                        }\n                        switch (element) {\n                            case RECOVERY_ENVIRONMENT: {\n                                final ModelNode model = parseRecoveryEnvironmentElement(reader);\n                                subsystem.get(CommonAttributes.RECOVERY_ENVIRONMENT).set(model) ;\n                                break;\n                            }\n                            case CORE_ENVIRONMENT: {\n                                final ModelNode model = parseCoreEnvironmentElement(reader);\n                                subsystem.get(CommonAttributes.CORE_ENVIRONMENT).set(model) ;\n                                break;\n                            }\n                            case COORDINATOR_ENVIRONMENT: {\n                                final ModelNode model = parseCoordinatorEnvironmentElement(reader);\n                                subsystem.get(CommonAttributes.COORDINATOR_ENVIRONMENT).set(model) ;\n                                break;\n                            }\n                            case OBJECT_STORE: {\n                                final ModelNode model = parseObjectStoreEnvironmentElement(reader);\n                                subsystem.get(CommonAttributes.OBJECT_STORE).set(model) ;\n                                break;\n                            }\n                            default: {\n                                throw unexpectedElement(reader);\n                            }\n                        }\n                        break;\n                    }\n                    default: {\n                        throw unexpectedElement(reader);\n                    }\n                }\n            }\n            if (! required.isEmpty()) {\n                throw missingRequiredElement(reader, required);\n            }\n        }","id":14398,"modified_method":"/** {@inheritDoc} */\n        @Override\n        public void readElement(XMLExtendedStreamReader reader, List<ModelNode> list) throws XMLStreamException {\n            // no attributes\n            if (reader.getAttributeCount() > 0) {\n                throw unexpectedAttribute(reader, 0);\n            }\n\n            final ModelNode address = new ModelNode();\n            address.add(ModelDescriptionConstants.SUBSYSTEM, SUBSYSTEM_NAME);\n            address.protect();\n\n            final ModelNode subsystem = new ModelNode();\n            subsystem.get(OP).set(ADD);\n            subsystem.get(OP_ADDR).set(address);\n\n            list.add(subsystem);\n\n            //Object store is always required\n            final ModelNode objectStoreNode = address.clone();\n            final ModelNode objectStoreOperation = new ModelNode();\n            objectStoreOperation.get(OP).set(ADD);\n            objectStoreNode.add(OBJECT_STORE, OBJECT_STORE);\n            objectStoreNode.protect();\n            objectStoreOperation.get(OP_ADDR).set(objectStoreNode);\n\n\n            // elements\n            final EnumSet<Element> required = EnumSet.of(Element.RECOVERY_ENVIRONMENT, Element.CORE_ENVIRONMENT);\n            final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n            while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n                switch (Namespace.forUri(reader.getNamespaceURI())) {\n                    case TRANSACTIONS_1_0: {\n                        final Element element = Element.forName(reader.getLocalName());\n                        required.remove(element);\n                        if (! encountered.add(element)) {\n                            throw unexpectedElement(reader);\n                        }\n                        switch (element) {\n                            case RECOVERY_ENVIRONMENT: {\n                                parseRecoveryEnvironmentElement(reader, list, address);\n                                break;\n                            }\n                            case CORE_ENVIRONMENT: {\n                                parseCoreEnvironmentElement(reader, list, address);\n                                break;\n                            }\n                            case COORDINATOR_ENVIRONMENT: {\n                                parseCoordinatorEnvironmentElement(reader, list, address);\n                                break;\n                            }\n                            case OBJECT_STORE: {\n                                parseObjectStoreEnvironmentElementAndEnrichOperation(reader, objectStoreOperation);\n                                break;\n                            }\n                            default: {\n                                throw unexpectedElement(reader);\n                            }\n                        }\n                        break;\n                    }\n                    default: {\n                        throw unexpectedElement(reader);\n                    }\n                }\n            }\n            list.add(objectStoreOperation);\n            if (! required.isEmpty()) {\n                throw missingRequiredElement(reader, required);\n            }\n        }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        //This is just copied from standalone.xml testing more combinations would be good\n        return\n            \"<subsystem xmlns=\\\"urn:jboss:domain:transactions:1.0\\\">\" +\n            \"    <recovery-environment socket-binding=\\\"txn-recovery-environment\\\" status-socket-binding=\\\"txn-status-manager\\\"/>\" +\n            \"    <core-environment>\" +\n            \"        <process-id>\" +\n            \"            <uuid />\" +\n            \"        <\/process-id>\" +\n            \"    <\/core-environment>\" +\n            \"    <coordinator-environment default-timeout=\\\"300\\\"/>\" +\n            \"<\/subsystem>\";\n    }","id":14399,"modified_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        //This is just copied from standalone.xml testing more combinations would be good\n        return\n            \"<subsystem xmlns=\\\"urn:jboss:domain:transactions:1.0\\\" >\" +\n            \"    <recovery-environment socket-binding=\\\"txn-recovery-environment\\\" status-socket-binding=\\\"txn-status-manager\\\"/>\" +\n            \"    <core-environment>\" +\n            \"        <process-id>\" +\n            \"            <uuid />\" +\n            \"        <\/process-id>\" +\n            \"    <\/core-environment>\" +\n            \"    <coordinator-environment default-timeout=\\\"300\\\"/>\" +\n            \"<\/subsystem>\";\n    }","commit_id":"33ad19781dc7f9d3694a86744a9d4c2ea0bcf546","url":"https://github.com/wildfly/wildfly"},{"original_method":"@BeforeClass\n  public static void setupBeforeClass() throws Exception {\n    TEST_UTIL = new HBaseTestingUtility();\n    Configuration conf = TEST_UTIL.getConfiguration();\n    SecureTestUtil.enableSecurity(conf);\n    String baseuser = User.getCurrent().getShortName();\n    conf.set(\"hbase.superuser\", conf.get(\"hbase.superuser\", \"\") +\n        String.format(\",%s.hfs.0,%s.hfs.1,%s.hfs.2\", baseuser, baseuser, baseuser));\n    TEST_UTIL.startMiniCluster();\n    TEST_UTIL.waitTableEnabled(AccessControlLists.ACL_TABLE_NAME.getName());\n\n    ADMIN = User.createUserForTesting(conf, \"admin\", new String[]{\"supergroup\"});\n    READER = User.createUserForTesting(conf, \"reader\", new String[0]);\n    LIMITED = User.createUserForTesting(conf, \"limited\", new String[0]);\n    DENIED = User.createUserForTesting(conf, \"denied\", new String[0]);\n  }","id":14400,"modified_method":"@BeforeClass\n  public static void setupBeforeClass() throws Exception {\n    TEST_UTIL = new HBaseTestingUtility();\n    Configuration conf = TEST_UTIL.getConfiguration();\n    SecureTestUtil.enableSecurity(conf);\n    String baseuser = User.getCurrent().getShortName();\n    conf.set(\"hbase.superuser\", conf.get(\"hbase.superuser\", \"\") +\n        String.format(\",%s.hfs.0,%s.hfs.1,%s.hfs.2\", baseuser, baseuser, baseuser));\n    TEST_UTIL.startMiniCluster();\n    TEST_UTIL.waitTableEnabled(AccessControlLists.ACL_TABLE_NAME.getName());\n\n    READER = User.createUserForTesting(conf, \"reader\", new String[0]);\n    LIMITED = User.createUserForTesting(conf, \"limited\", new String[0]);\n    DENIED = User.createUserForTesting(conf, \"denied\", new String[0]);\n  }","commit_id":"33df9fac20c61b28bccdd5493291e4ed1e68680d","url":"https://github.com/apache/hbase"},{"original_method":"private void doQualifierAccess(final HTable table) throws IOException, InterruptedException {\n    // set permissions\n    ADMIN.runAs(new PrivilegedExceptionAction<Object>() {\n      @Override\n      public Object run() throws Exception {\n        HTable aclmeta = new HTable(TEST_UTIL.getConfiguration(),\n            AccessControlLists.ACL_TABLE_NAME);\n        try {\n          byte[] table = Bytes.toBytes(name.getMethodName());\n          BlockingRpcChannel service = aclmeta.coprocessorService(table);\n          AccessControlService.BlockingInterface protocol =\n            AccessControlService.newBlockingStub(service);\n          ProtobufUtil.grant(protocol, READER.getShortName(),\n            TABLE, null, null, Permission.Action.READ);\n          ProtobufUtil.grant(protocol, LIMITED.getShortName(),\n            TABLE, FAMILY, PUBLIC_COL, Permission.Action.READ);\n          return null;\n        } finally {\n          aclmeta.close();\n        }\n      }\n    });\n\n    // put some test data\n    List<Put> puts = new ArrayList<Put>(100);\n    for (int i=0; i<100; i++) {\n      Put p = new Put(Bytes.toBytes(i));\n      p.add(FAMILY, PRIVATE_COL, Bytes.toBytes(\"secret \"+i));\n      p.add(FAMILY, PUBLIC_COL, Bytes.toBytes(\"info \"+i));\n      puts.add(p);\n    }\n    table.put(puts);\n\n    // test read\n    READER.runAs(new PrivilegedExceptionAction<Object>() {\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertTrue(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertEquals(\"secret \"+rownum, Bytes.toString(r.getValue(FAMILY, PRIVATE_COL)));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \"+rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 100 rows returned\", 100, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n\n    // test read with qualifier filter\n    LIMITED.runAs(new PrivilegedExceptionAction<Object>() {\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertFalse(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \" + rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 100 rows returned\", 100, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n\n    // test as user with no permission\n    DENIED.runAs(new PrivilegedExceptionAction<Object>(){\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertFalse(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \" + rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 0 rows returned\", 0, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n  }","id":14401,"modified_method":"private void doQualifierAccess(final HTable table) throws Exception {\n    // set permissions\n    SecureTestUtil.grantOnTable(TEST_UTIL, READER.getShortName(), TABLE, null, null,\n      Permission.Action.READ);\n    SecureTestUtil.grantOnTable(TEST_UTIL, LIMITED.getShortName(), TABLE, FAMILY, PUBLIC_COL,\n      Permission.Action.READ);\n\n    // put some test data\n    List<Put> puts = new ArrayList<Put>(100);\n    for (int i=0; i<100; i++) {\n      Put p = new Put(Bytes.toBytes(i));\n      p.add(FAMILY, PRIVATE_COL, Bytes.toBytes(\"secret \"+i));\n      p.add(FAMILY, PUBLIC_COL, Bytes.toBytes(\"info \"+i));\n      puts.add(p);\n    }\n    table.put(puts);\n\n    // test read\n    READER.runAs(new PrivilegedExceptionAction<Object>() {\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertTrue(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertEquals(\"secret \"+rownum, Bytes.toString(r.getValue(FAMILY, PRIVATE_COL)));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \"+rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 100 rows returned\", 100, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n\n    // test read with qualifier filter\n    LIMITED.runAs(new PrivilegedExceptionAction<Object>() {\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertFalse(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \" + rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 100 rows returned\", 100, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n\n    // test as user with no permission\n    DENIED.runAs(new PrivilegedExceptionAction<Object>(){\n      public Object run() throws Exception {\n        Configuration conf = new Configuration(TEST_UTIL.getConfiguration());\n        // force a new RS connection\n        conf.set(\"testkey\", UUID.randomUUID().toString());\n        HTable t = new HTable(conf, TABLE);\n        try {\n          ResultScanner rs = t.getScanner(new Scan());\n          int rowcnt = 0;\n          for (Result r : rs) {\n            rowcnt++;\n            int rownum = Bytes.toInt(r.getRow());\n            assertFalse(r.containsColumn(FAMILY, PRIVATE_COL));\n            assertTrue(r.containsColumn(FAMILY, PUBLIC_COL));\n            assertEquals(\"info \" + rownum, Bytes.toString(r.getValue(FAMILY, PUBLIC_COL)));\n          }\n          assertEquals(\"Expected 0 rows returned\", 0, rowcnt);\n          return null;\n        } finally {\n          t.close();\n        }\n      }\n    });\n  }","commit_id":"33df9fac20c61b28bccdd5493291e4ed1e68680d","url":"https://github.com/apache/hbase"},{"original_method":"@Test\n  public void testVisibilityLabelsForUserWithNoAuths() throws Throwable {\n    String user = \"admin\";\n    String[] auths = { SECRET };\n    VisibilityClient.clearAuths(conf, auths, user); // Removing all auths if any.\n    VisibilityClient.setAuths(conf, auths, \"user1\");\n    TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n    final HTable table = createTableAndWriteDataWithLabels(tableName, SECRET);\n    HTable acl = new HTable(conf, AccessControlLists.ACL_TABLE_NAME);\n    try {\n      BlockingRpcChannel service = acl.coprocessorService(tableName.getName());\n      AccessControlService.BlockingInterface protocol = AccessControlService\n          .newBlockingStub(service);\n      ProtobufUtil.grant(protocol, NORMAL_USER1.getShortName(), tableName, null, null,\n          Permission.Action.READ);\n      ProtobufUtil.grant(protocol, NORMAL_USER2.getShortName(), tableName, null, null,\n          Permission.Action.READ);\n    } finally {\n      acl.close();\n    }\n\n   PrivilegedExceptionAction<Void> getAction = new PrivilegedExceptionAction<Void>() {\n      public Void run() throws Exception {\n        Get g = new Get(row1);\n        g.setAuthorizations(new Authorizations(SECRET, CONFIDENTIAL));\n        HTable t = new HTable(conf, table.getTableName());\n        try {\n          Result result = t.get(g);\n          assertTrue(result.isEmpty());\n        } finally {\n          t.close();\n        }\n        return null;\n      }\n    };\n    NORMAL_USER2.runAs(getAction);\n  }","id":14402,"modified_method":"@Test\n  public void testVisibilityLabelsForUserWithNoAuths() throws Throwable {\n    String user = \"admin\";\n    String[] auths = { SECRET };\n    VisibilityClient.clearAuths(conf, auths, user); // Removing all auths if any.\n    VisibilityClient.setAuths(conf, auths, \"user1\");\n    TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n    final HTable table = createTableAndWriteDataWithLabels(tableName, SECRET);\n    SecureTestUtil.grantOnTable(TEST_UTIL, NORMAL_USER1.getShortName(), tableName,\n      null, null, Permission.Action.READ);\n    SecureTestUtil.grantOnTable(TEST_UTIL, NORMAL_USER2.getShortName(), tableName,\n      null, null, Permission.Action.READ);\n    PrivilegedExceptionAction<Void> getAction = new PrivilegedExceptionAction<Void>() {\n      public Void run() throws Exception {\n        Get g = new Get(row1);\n        g.setAuthorizations(new Authorizations(SECRET, CONFIDENTIAL));\n        HTable t = new HTable(conf, table.getTableName());\n        try {\n          Result result = t.get(g);\n          assertTrue(result.isEmpty());\n        } finally {\n          t.close();\n        }\n        return null;\n      }\n    };\n    NORMAL_USER2.runAs(getAction);\n  }","commit_id":"33df9fac20c61b28bccdd5493291e4ed1e68680d","url":"https://github.com/apache/hbase"},{"original_method":"@BeforeClass\n  public static void setupBeforeClass() throws Exception {\n    // setup configuration\n    conf = TEST_UTIL.getConfiguration();\n    SecureTestUtil.enableSecurity(conf);\n    conf.set(\"hbase.coprocessor.master.classes\", AccessController.class.getName() + \",\"\n        + VisibilityController.class.getName());\n    conf.set(\"hbase.coprocessor.region.classes\", AccessController.class.getName() + \",\"\n        + VisibilityController.class.getName());\n    TEST_UTIL.startMiniCluster(2);\n\n    TEST_UTIL.waitTableEnabled(AccessControlLists.ACL_TABLE_NAME.getName(), 50000);\n    // Wait for the labels table to become available\n    TEST_UTIL.waitTableEnabled(LABELS_TABLE_NAME.getName(), 50000);\n    addLabels();\n\n    // Create users for testing\n    SUPERUSER = User.createUserForTesting(conf, \"admin\", new String[] { \"supergroup\" });\n    NORMAL_USER1 = User.createUserForTesting(conf, \"user1\", new String[] {});\n    NORMAL_USER2 = User.createUserForTesting(conf, \"user2\", new String[] {});\n    // Grant NORMAL_USER EXEC privilege on the labels table. For the purposes of this\n    // test, we want to insure that access is denied even with the ability to access\n    // the endpoint.\n    HTable acl = new HTable(conf, AccessControlLists.ACL_TABLE_NAME);\n    try {\n      BlockingRpcChannel service = acl.coprocessorService(LABELS_TABLE_NAME.getName());\n      AccessControlService.BlockingInterface protocol =\n        AccessControlService.newBlockingStub(service);\n      ProtobufUtil.grant(protocol, NORMAL_USER1.getShortName(), LABELS_TABLE_NAME, null, null,\n        Permission.Action.EXEC);\n      ProtobufUtil.grant(protocol, NORMAL_USER2.getShortName(), LABELS_TABLE_NAME, null, null,\n          Permission.Action.EXEC);\n    } finally {\n      acl.close();\n    }\n  }","id":14403,"modified_method":"@BeforeClass\n  public static void setupBeforeClass() throws Exception {\n    // setup configuration\n    conf = TEST_UTIL.getConfiguration();\n    SecureTestUtil.enableSecurity(conf);\n    conf.set(\"hbase.coprocessor.master.classes\", AccessController.class.getName() + \",\"\n        + VisibilityController.class.getName());\n    conf.set(\"hbase.coprocessor.region.classes\", AccessController.class.getName() + \",\"\n        + VisibilityController.class.getName());\n    TEST_UTIL.startMiniCluster(2);\n\n    TEST_UTIL.waitTableEnabled(AccessControlLists.ACL_TABLE_NAME.getName(), 50000);\n    // Wait for the labels table to become available\n    TEST_UTIL.waitTableEnabled(LABELS_TABLE_NAME.getName(), 50000);\n    addLabels();\n\n    // Create users for testing\n    SUPERUSER = User.createUserForTesting(conf, \"admin\", new String[] { \"supergroup\" });\n    NORMAL_USER1 = User.createUserForTesting(conf, \"user1\", new String[] {});\n    NORMAL_USER2 = User.createUserForTesting(conf, \"user2\", new String[] {});\n    // Grant users EXEC privilege on the labels table. For the purposes of this\n    // test, we want to insure that access is denied even with the ability to access\n    // the endpoint.\n    SecureTestUtil.grantOnTable(TEST_UTIL, NORMAL_USER1.getShortName(), LABELS_TABLE_NAME,\n      null, null, Permission.Action.EXEC);\n    SecureTestUtil.grantOnTable(TEST_UTIL, NORMAL_USER2.getShortName(), LABELS_TABLE_NAME,\n      null, null, Permission.Action.EXEC);\n  }","commit_id":"33df9fac20c61b28bccdd5493291e4ed1e68680d","url":"https://github.com/apache/hbase"},{"original_method":"@Test\n  public void testScanForUserWithFewerLabelAuthsThanLabelsInScanAuthorizations() throws Throwable {\n    String[] auths = { SECRET };\n    String user = \"user2\";\n    VisibilityClient.setAuths(conf, auths, user);\n    TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n    final HTable table = createTableAndWriteDataWithLabels(tableName, SECRET + \"&\" + CONFIDENTIAL\n        + \"&!\" + PRIVATE, SECRET + \"&!\" + PRIVATE);\n    HTable acl = new HTable(conf, AccessControlLists.ACL_TABLE_NAME);\n    try {\n      BlockingRpcChannel service = acl.coprocessorService(tableName.getName());\n      AccessControlService.BlockingInterface protocol = AccessControlService\n          .newBlockingStub(service);\n      ProtobufUtil.grant(protocol, NORMAL_USER2.getShortName(), tableName, null, null,\n          Permission.Action.READ);\n    } finally {\n      acl.close();\n    }\n    PrivilegedExceptionAction<Void> scanAction = new PrivilegedExceptionAction<Void>() {\n      public Void run() throws Exception {\n        Scan s = new Scan();\n        s.setAuthorizations(new Authorizations(SECRET, CONFIDENTIAL));\n        HTable t = new HTable(conf, table.getTableName());\n        try {\n          ResultScanner scanner = t.getScanner(s);\n          Result result = scanner.next();\n          assertTrue(!result.isEmpty());\n          assertTrue(Bytes.equals(Bytes.toBytes(\"row2\"), result.getRow()));\n          result = scanner.next();\n          assertNull(result);\n        } finally {\n          t.close();\n        }\n        return null;\n      }\n    };\n    NORMAL_USER2.runAs(scanAction);\n  }","id":14404,"modified_method":"@Test\n  public void testScanForUserWithFewerLabelAuthsThanLabelsInScanAuthorizations() throws Throwable {\n    String[] auths = { SECRET };\n    String user = \"user2\";\n    VisibilityClient.setAuths(conf, auths, user);\n    TableName tableName = TableName.valueOf(TEST_NAME.getMethodName());\n    final HTable table = createTableAndWriteDataWithLabels(tableName, SECRET + \"&\" + CONFIDENTIAL\n        + \"&!\" + PRIVATE, SECRET + \"&!\" + PRIVATE);\n    SecureTestUtil.grantOnTable(TEST_UTIL, NORMAL_USER2.getShortName(), tableName,\n      null, null, Permission.Action.READ);\n    PrivilegedExceptionAction<Void> scanAction = new PrivilegedExceptionAction<Void>() {\n      public Void run() throws Exception {\n        Scan s = new Scan();\n        s.setAuthorizations(new Authorizations(SECRET, CONFIDENTIAL));\n        HTable t = new HTable(conf, table.getTableName());\n        try {\n          ResultScanner scanner = t.getScanner(s);\n          Result result = scanner.next();\n          assertTrue(!result.isEmpty());\n          assertTrue(Bytes.equals(Bytes.toBytes(\"row2\"), result.getRow()));\n          result = scanner.next();\n          assertNull(result);\n        } finally {\n          t.close();\n        }\n        return null;\n      }\n    };\n    NORMAL_USER2.runAs(scanAction);\n  }","commit_id":"33df9fac20c61b28bccdd5493291e4ed1e68680d","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n    public boolean isDone() {\n        return isDone(state);\n    }","id":14405,"modified_method":"@Override\n    public boolean isDone() {\n        return isDoneState(state);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"protected V getResult() {\n        Object state = this.state;\n\n        if (!isDone(state)) {\n            return null;\n        }\n\n        if (state instanceof Throwable) {\n            sneakyThrow((Throwable) state);\n        }\n\n        return (V) state;\n    }","id":14406,"modified_method":"protected V getResult() {\n        Object state = this.state;\n\n        if (isCancelledState(state)) {\n            return null;\n        }\n\n        if (!isDoneState(state)) {\n            return null;\n        }\n\n        if (state instanceof Throwable) {\n            sneakyThrow((Throwable) state);\n        }\n\n        return (V) state;\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public void andThen(ExecutionCallback<V> callback, Executor executor) {\n        isNotNull(callback, \"callback\");\n        isNotNull(executor, \"executor\");\n\n        for (; ; ) {\n            Object currentState = this.state;\n\n            if (isDone(currentState)) {\n                runAsynchronous(callback, executor, currentState);\n                return;\n            }\n\n            ExecutionCallbackNode newState\n                    = new ExecutionCallbackNode<V>(callback, executor, (ExecutionCallbackNode) currentState);\n\n            if (STATE.compareAndSet(this, currentState, newState)) {\n                // we have successfully scheduled the callback.\n                return;\n            }\n\n            // we failed to update the state. This can mean 2 things:\n            // either a result was set, which we'll see when retrying this loop\n            // or a different thread also called andThen, which we'll deal with when we retry the loop.\n        }\n    }","id":14407,"modified_method":"@Override\n    public void andThen(ExecutionCallback<V> callback, Executor executor) {\n        isNotNull(callback, \"callback\");\n        isNotNull(executor, \"executor\");\n\n        for (; ; ) {\n            Object currentState = this.state;\n\n            if (isCancelledState(currentState)) {\n                return;\n            }\n\n            if (isDoneState(currentState)) {\n                runAsynchronous(callback, executor, currentState);\n                return;\n            }\n\n            ExecutionCallbackNode newState\n                    = new ExecutionCallbackNode<V>(callback, executor, (ExecutionCallbackNode) currentState);\n\n            if (STATE.compareAndSet(this, currentState, newState)) {\n                // we have successfully scheduled the callback.\n                return;\n            }\n\n            // we failed to update the state. This can mean 2 things:\n            // either a result was set, which we'll see when retrying this loop\n            // or a different thread also called andThen, which we'll deal with when we retry the loop.\n        }\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void setResult(Object result) {\n        for (; ; ) {\n            Object currentState = this.state;\n\n            if (isDone(currentState)) {\n                return;\n            }\n\n            if (STATE.compareAndSet(this, currentState, result)) {\n                runAsynchronous((ExecutionCallbackNode) currentState, result);\n                break;\n            }\n        }\n    }","id":14408,"modified_method":"public void setResult(Object result) {\n        for (; ; ) {\n            Object currentState = this.state;\n\n            if (isDoneState(currentState)) {\n                return;\n            }\n\n            if (STATE.compareAndSet(this, currentState, result)) {\n                done();\n                notifyThreadsWaitingOnGet();\n                runAsynchronous((ExecutionCallbackNode) currentState, result);\n                break;\n            }\n        }\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private boolean isDone(Object state) {\n        return !(state instanceof ExecutionCallbackNode);\n    }","id":14409,"modified_method":"/**\n     * Returns {@code true} if the task with the given state completed - analogously to the Future's contract.\n     * Completion may be due to normal termination, an exception, or\n     * cancellation -- in all of these cases, this method will return\n     * {@code true}.\n     *\n     * @return {@code true} if this task completed\n     */\n    private static boolean isDoneState(Object state) {\n        return !(state instanceof ExecutionCallbackNode);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void getResult_whenPendingCallback() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class));\n\n        Object result = future.getResult();\n\n        assertNull(result);\n    }","id":14410,"modified_method":"@Test\n    public void getResult_whenPendingCallback() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class));\n\n        Object result = future.getResult();\n\n        assertNull(\"Internal result should be null initially\", result);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void andThen_whenInitialState() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n\n        ExecutionCallback callback = mock(ExecutionCallback.class);\n        future.andThen(callback, executor);\n\n        ExecutionCallbackNode node = assertInstanceOf(ExecutionCallbackNode.class, future.state);\n        assertSame(node.callback, callback);\n        assertSame(node.executor, executor);\n        assertSame(node.next, AbstractCompletableFuture.INITIAL_STATE);\n        verifyZeroInteractions(callback);\n    }","id":14411,"modified_method":"@Test\n    public void andThen_whenInitialState() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        ExecutionCallback callback = mock(ExecutionCallback.class);\n\n        future.andThen(callback, executor);\n\n        verifyZeroInteractions(callback);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void andThen_whenResultAvailable() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        final Object result = \"result\";\n        future.setResult(result);\n\n        final ExecutionCallback callback = mock(ExecutionCallback.class);\n        future.andThen(callback, executor);\n\n        assertSame(result, future.state);\n\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                verify(callback).onResponse(result);\n            }\n        });\n    }","id":14412,"modified_method":"@Test\n    public void andThen_whenResultAvailable() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        final Object result = \"result\";\n        final ExecutionCallback callback = mock(ExecutionCallback.class);\n\n        future.setResult(result);\n        future.andThen(callback, executor);\n\n        assertSame(result, future.get());\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                verify(callback).onResponse(result);\n            }\n        });\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void setResult_whenNoPendingCallback() {\n        setResult_whenNoPendingCallback(null);\n        setResult_whenNoPendingCallback(\"foo\");\n    }","id":14413,"modified_method":"@Test\n    public void setResult_whenPendingCallback_ordinaryResult() {\n        setResult_whenPendingCallback_callbacksExecutedCorrectly(\"foo\");\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void isDone_whenCallbackRegistered() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class));\n\n        boolean result = future.isDone();\n\n        assertFalse(result);\n    }","id":14414,"modified_method":"@Test\n    public void future_notExecuted_callbackRegistered_notDoneNotCancelled() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class));\n\n        assertFalse(\"New future should not be done\", future.isDone());\n        assertFalse(\"New future should not be cancelled\", future.isCancelled());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void getResult_whenInitialState() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n\n        Object result = future.getResult();\n\n        assertNull(result);\n    }","id":14415,"modified_method":"@Test\n    public void getResult_whenInitialState() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n\n        Object result = future.getResult();\n\n        assertNull(\"Internal result should be null initially\", result);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void getResult_whenNullResult() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.setResult(null);\n\n        Object result = future.getResult();\n\n        assertNull(result);\n    }","id":14416,"modified_method":"@Test\n    public void getResult_whenNullResult() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.setResult(null);\n\n        Object result = future.getResult();\n\n        assertNull(\"Internal result should be null when set to null\", result);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void andThen_whenPendingCallback() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n\n        ExecutionCallback callback1 = mock(ExecutionCallback.class);\n        future.andThen(callback1, executor);\n\n        ExecutionCallback callback2 = mock(ExecutionCallback.class);\n        future.andThen(callback2, executor);\n\n        ExecutionCallbackNode secondNode = assertInstanceOf(ExecutionCallbackNode.class, future.state);\n        assertSame(secondNode.callback, callback2);\n        assertSame(secondNode.executor, executor);\n\n        ExecutionCallbackNode firstNode = secondNode.next;\n        assertSame(firstNode.callback, callback1);\n        assertSame(firstNode.executor, executor);\n        assertSame(firstNode.next, AbstractCompletableFuture.INITIAL_STATE);\n\n        verifyZeroInteractions(callback1);\n        verifyZeroInteractions(callback2);\n    }","id":14417,"modified_method":"@Test\n    public void andThen_whenPendingCallback() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        ExecutionCallback callback1 = mock(ExecutionCallback.class);\n        ExecutionCallback callback2 = mock(ExecutionCallback.class);\n\n        future.andThen(callback1, executor);\n        future.andThen(callback2, executor);\n\n        verifyZeroInteractions(callback1);\n        verifyZeroInteractions(callback2);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test(expected = IllegalArgumentException.class)\n    public void andThen_whenNullExecutor() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class), null);\n    }","id":14418,"modified_method":"@Test(expected = IllegalArgumentException.class)\n    public void andThen_whenNullExecutor_exceptionThrown() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(mock(ExecutionCallback.class), null);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void setResult_whenNoPendingCallback(Object result) {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n\n        future.setResult(result);\n\n        assertSame(result, future.state);\n    }","id":14419,"modified_method":"@Test\n    public void setResult_whenPendingCallback_exceptionResult() {\n        setResult_whenPendingCallback_callbacksExecutedCorrectly(new Exception());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void setResult_whenPendingCallback() {\n        setResult_whenPendingCallback(null);\n        setResult_whenPendingCallback(\"foo\");\n        setResult_whenPendingCallback(new Exception());\n    }","id":14420,"modified_method":"@Test\n    public void setResult_whenPendingCallback_nullResult() {\n        setResult_whenPendingCallback_callbacksExecutedCorrectly(null);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test(expected = IllegalArgumentException.class)\n    public void andThen_whenNullCallback() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(null, executor);\n    }","id":14421,"modified_method":"@Test(expected = IllegalArgumentException.class)\n    public void andThen_whenNullCallback_exceptionThrown() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        future.andThen(null, executor);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void setResult_whenPendingCallback(final Object result) {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        final ExecutionCallback callback1 = mock(ExecutionCallback.class);\n        final ExecutionCallback callback2 = mock(ExecutionCallback.class);\n        future.andThen(callback1);\n        future.andThen(callback2);\n\n        future.setResult(result);\n\n        assertSame(result, future.state);\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                if (result instanceof Throwable) {\n                    verify(callback1).onFailure((Throwable) result);\n                } else {\n                    verify(callback1).onResponse(result);\n                }\n            }\n        });\n\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                if (result instanceof Throwable) {\n                    verify(callback2).onFailure((Throwable) result);\n                } else {\n                    verify(callback2).onResponse(result);\n                }\n            }\n        });\n    }","id":14422,"modified_method":"public void setResult_whenPendingCallback_callbacksExecutedCorrectly(final Object result) {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        final ExecutionCallback callback1 = mock(ExecutionCallback.class);\n        final ExecutionCallback callback2 = mock(ExecutionCallback.class);\n        future.andThen(callback1);\n        future.andThen(callback2);\n\n        future.setResult(result);\n\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                if (result instanceof Throwable) {\n                    verify(callback1).onFailure((Throwable) result);\n                } else {\n                    verify(callback1).onResponse(result);\n                }\n            }\n        });\n        assertTrueEventually(new AssertTask() {\n            @Override\n            public void run() throws Exception {\n                if (result instanceof Throwable) {\n                    verify(callback2).onFailure((Throwable) result);\n                } else {\n                    verify(callback2).onResponse(result);\n                }\n            }\n        });\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void setResult_whenResultAlreadySet() {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        Object initialResult = \"firstresult\";\n\n        future.setResult(initialResult);\n\n        future.setResult(\"secondresult\");\n        assertSame(initialResult, future.state);\n    }","id":14423,"modified_method":"@Test\n    public void setResult_whenResultAlreadySet_secondResultDiscarded() throws Exception {\n        FutureImpl future = new FutureImpl(nodeEngine, logger);\n        Object initialResult = \"firstresult\", secondResult = \"secondresult\";\n\n        future.setResult(initialResult);\n        future.setResult(secondResult);\n\n        assertSame(initialResult, future.get());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public void run() {\n        try {\n            super.run();\n        } finally {\n            fireCallbacks();\n        }\n    }","id":14424,"modified_method":"@Override\n    public void run() {\n        if (isDone()) {\n            return;\n        }\n\n        if (runner != null || !RUNNER.compareAndSet(this, null, Thread.currentThread())) {\n            // prevents concurrent calls to run\n            return;\n        }\n\n        try {\n            Callable c = callable;\n            if (c != null) {\n                Object result = null;\n                try {\n                    result = c.call();\n                } catch (Throwable ex) {\n                    result = new ExecutionException(ex);\n                } finally {\n                    setResult(result);\n                }\n            }\n        } finally {\n            // runner must be non-null until state is settled in setResult() to\n            // prevent concurrent calls to run()\n            runner = null;\n        }\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public CompletableFutureTask(Runnable runnable, V result, ExecutorService asyncExecutor) {\n        super(runnable, result);\n        this.asyncExecutor = asyncExecutor;\n        this.callbackUpdater = AtomicReferenceFieldUpdater.newUpdater(\n                CompletableFutureTask.class, ExecutionCallbackNode.class, \"callbackHead\");\n    }","id":14425,"modified_method":"public CompletableFutureTask(Runnable runnable, V result, ExecutorService asyncExecutor) {\n        super(asyncExecutor, Logger.getLogger(CompletableFutureTask.class));\n        this.callable = Executors.callable(runnable, result);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public CompletableFutureTask(Callable<V> callable, ExecutorService asyncExecutor) {\n        super(callable);\n        this.asyncExecutor = asyncExecutor;\n        this.callbackUpdater = AtomicReferenceFieldUpdater.newUpdater(\n                CompletableFutureTask.class, ExecutionCallbackNode.class, \"callbackHead\");\n    }","id":14426,"modified_method":"public CompletableFutureTask(Callable<V> callable, ExecutorService asyncExecutor) {\n        super(asyncExecutor, Logger.getLogger(CompletableFutureTask.class));\n        this.callable = callable;\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Before\n    public void setUp() throws Exception {\n        NodeEngine nodeEngine = getNode(createHazelcastInstance()).getNodeEngine();\n        executionService = nodeEngine.getExecutionService();\n        startLatch = new CountDownLatch(1);\n        ref1 = new AtomicReference<Object>();\n        ref2 = new AtomicReference<Object>();\n    }","id":14427,"modified_method":"@Before\n    public void setUp() throws Exception {\n        NodeEngine nodeEngine = getNode(createHazelcastInstance()).getNodeEngine();\n        executionService = nodeEngine.getExecutionService();\n        startLogicLatch = new CountDownLatch(1);\n        executedLogic = new CountDownLatch(1);\n        finishedLatch = new CountDownLatch(1);\n        inExecutionLatch = new CountDownLatch(1);\n        reference1 = new AtomicReference<Object>();\n        reference2 = new AtomicReference<Object>();\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private static Runnable throwException() {\n        return new Runnable() { @Override public void run() {\n            throw TEST_EXCEPTION;\n        }};\n    }","id":14428,"modified_method":"@Test(timeout = 60000)\n    public void get_taskThrowsException() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTaskNoCallbacks(THROW_TEST_EXCEPTION);\n        submitReleasingTask(100);\n\n        expected.expect(ExecutionException.class);\n        f.get();\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void postregisterTwoCallbacks_withFailure() throws Exception {\n        doneLatch = new CountDownLatch(2);\n        final ICompletableFuture<String> f = submit(openStartLatch(), throwException());\n        assertOpenEventually(startLatch);\n        f.andThen(setRefAndBumpDoneLatch(ref1));\n        f.andThen(setRefAndBumpDoneLatch(ref2));\n        assertOpenEventually(doneLatch);\n        assertTestException(ref1, ref2);\n    }","id":14429,"modified_method":"@Test\n    public void postregisterTwoCallbacks_taskThrowsException() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTask(expectedNumberOfCallbacks(2), THROW_TEST_EXCEPTION);\n        releaseAwaitingTask();\n        assertTaskFinishedEventually();\n\n        f.andThen(storeTaskResponseToReference(reference1));\n        f.andThen(storeTaskResponseToReference(reference2));\n\n        assertCallbacksExecutedEventually();\n        assertTestExceptionThrown(reference1, reference2);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void preregisterCallback() throws Exception {\n        doneLatch = new CountDownLatch(1);\n        final ICompletableFuture<String> f = submit(awaitStartLatch());\n        f.andThen(setRefAndBumpDoneLatch(ref1));\n        startLatch.countDown();\n        assertOpenEventually(doneLatch);\n        assertEquals(\"success\", ref1.get());\n    }","id":14430,"modified_method":"@Test\n    public void preregisterCallback() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTask(expectedNumberOfCallbacks(1), NO_EXCEPTION);\n        f.andThen(storeTaskResponseToReference(reference1));\n\n        releaseAwaitingTask();\n\n        assertCallbacksExecutedEventually();\n        assertEquals(\"success\", reference1.get());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void postregisterTwoCallbacks() throws Exception {\n        doneLatch = new CountDownLatch(2);\n        final ICompletableFuture<String> f = submit(openStartLatch());\n        assertOpenEventually(startLatch);\n        f.andThen(setRefAndBumpDoneLatch(ref1));\n        f.andThen(setRefAndBumpDoneLatch(ref2));\n        assertOpenEventually(doneLatch);\n        assertEquals(\"success\", ref1.get());\n        assertEquals(\"success\", ref2.get());\n    }","id":14431,"modified_method":"@Test\n    public void postregisterTwoCallbacks() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTask(expectedNumberOfCallbacks(2), NO_EXCEPTION);\n        releaseAwaitingTask();\n        assertTaskFinishedEventually();\n\n        f.andThen(storeTaskResponseToReference(reference1));\n        f.andThen(storeTaskResponseToReference(reference2));\n\n        assertCallbacksExecutedEventually();\n        assertEquals(\"success\", reference1.get());\n        assertEquals(\"success\", reference2.get());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private static void assertTestException(AtomicReference<?>... refs) {\n        for (AtomicReference<?> ref : refs)\n            assertThat(\"ExecutionException expected\", ref.get(), instanceOf(ExecutionException.class));\n        for (AtomicReference<?> ref : refs)\n            assertThat(\"TEST_EXCEPTION expected as cause\", ((Throwable) ref.get()).getCause(),\n                Matchers.<Throwable>sameInstance(TEST_EXCEPTION));\n    }","id":14432,"modified_method":"private static void assertTestExceptionThrown(AtomicReference<?>... refs) {\n        for (AtomicReference<?> ref : refs)\n            assertThat(\"ExecutionException expected\", ref.get(), instanceOf(ExecutionException.class));\n        for (AtomicReference<?> ref : refs)\n            assertThat(\"TEST_EXCEPTION expected as cause\", ((Throwable) ref.get()).getCause(),\n                    Matchers.<Throwable>sameInstance(THROW_TEST_EXCEPTION));\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private ExecutionCallback<String> setRefAndBumpDoneLatch(final AtomicReference<Object> ref) {\n        return new ExecutionCallback<String>() {\n            @Override public void onResponse(String response) {\n                doit(response);\n            }\n            @Override public void onFailure(Throwable t) {\n                doit(t);\n            }\n            private void doit(Object response) {\n                ref.set(response);\n                doneLatch.countDown();\n            }\n        };\n    }","id":14433,"modified_method":"private ExecutionCallback<String> storeTaskResponseToReference(final AtomicReference<Object> ref) {\n        return new ExecutionCallback<String>() {\n            @Override\n            public void onResponse(String response) {\n                doit(response);\n            }\n\n            @Override\n            public void onFailure(Throwable t) {\n                doit(t);\n            }\n\n            private void doit(Object response) {\n                ref.set(response);\n                callbacksDoneLatch.countDown();\n            }\n        };\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void preregisterTwoCallbacks() throws Exception {\n        doneLatch = new CountDownLatch(2);\n        final ICompletableFuture<String> f = submit(awaitStartLatch());\n        f.andThen(setRefAndBumpDoneLatch(ref1));\n        f.andThen(setRefAndBumpDoneLatch(ref2));\n        startLatch.countDown();\n        assertOpenEventually(doneLatch);\n        assertEquals(\"success\", ref1.get());\n        assertEquals(\"success\", ref2.get());\n    }","id":14434,"modified_method":"@Test\n    public void preregisterTwoCallbacks() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTask(expectedNumberOfCallbacks(2), NO_EXCEPTION);\n        f.andThen(storeTaskResponseToReference(reference1));\n        f.andThen(storeTaskResponseToReference(reference2));\n\n        releaseAwaitingTask();\n\n        assertCallbacksExecutedEventually();\n        assertEquals(\"success\", reference1.get());\n        assertEquals(\"success\", reference2.get());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private ICompletableFuture<String> submit(final Runnable... rs) {\n        return executionService.asCompletableFuture(executionService.submit(\"default\", new Callable<String>() {\n            @Override\n            public String call() {\n                for (Runnable r : rs) r.run();\n                return \"success\";\n            }\n        }));\n    }","id":14435,"modified_method":"private void submit(final Runnable runnable) {\n        executionService.submit(\"default\", runnable);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void postregisterCallback() throws Exception {\n        doneLatch = new CountDownLatch(1);\n        final ICompletableFuture<String> f = submit(openStartLatch());\n        assertOpenEventually(startLatch);\n        f.andThen(setRefAndBumpDoneLatch(ref1));\n        assertOpenEventually(doneLatch);\n        assertEquals(\"success\", ref1.get());\n    }","id":14436,"modified_method":"@Test\n    @Repeat(10)\n    // https://github.com/hazelcast/hazelcast/issues/6020\n    public void postregisterCallback() throws Exception {\n        ICompletableFuture<String> f = submitAwaitingTask(expectedNumberOfCallbacks(1), NO_EXCEPTION);\n        releaseAwaitingTask();\n        assertTaskFinishedEventually();\n\n        f.andThen(storeTaskResponseToReference(reference1));\n\n        assertCallbacksExecutedEventually();\n        assertEquals(\"success\", reference1.get());\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public void setResult(Object result) {\n        try {\n            Object finalResult = result;\n            if (finalResult instanceof Throwable && !(finalResult instanceof CancellationException)) {\n                super.setResult(new ExecutionException((Throwable) finalResult));\n                return;\n            }\n            // If collator is available we need to execute it now\n            if (collator != null) {\n                try {\n                    finalResult = collator.collate(((Map) finalResult).entrySet());\n                } catch (Exception e) {\n                    // Possible exception while collating\n                    finalResult = e;\n                }\n            }\n            if (finalResult instanceof Throwable && !(finalResult instanceof CancellationException)) {\n                finalResult = new ExecutionException((Throwable) finalResult);\n            }\n            super.setResult(finalResult);\n        } finally {\n            latch.countDown();\n        }\n    }","id":14437,"modified_method":"@Override\n    public void setResult(Object result) {\n        Object finalResult = result;\n        if (finalResult instanceof Throwable && !(finalResult instanceof CancellationException)) {\n            super.setResult(new ExecutionException((Throwable) finalResult));\n            return;\n        }\n        // If collator is available we need to execute it now\n        if (collator != null) {\n            try {\n                finalResult = collator.collate(((Map) finalResult).entrySet());\n            } catch (Exception e) {\n                // Possible exception while collating\n                finalResult = e;\n            }\n        }\n        if (finalResult instanceof Throwable && !(finalResult instanceof CancellationException)) {\n            finalResult = new ExecutionException((Throwable) finalResult);\n        }\n        super.setResult(finalResult);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public boolean cancel(boolean mayInterruptIfRunning) {\n        Address jobOwner = mapReduceService.getLocalAddress();\n        if (!mapReduceService.registerJobSupervisorCancellation(name, jobId, jobOwner)) {\n            return false;\n        }\n        JobSupervisor supervisor = mapReduceService.getJobSupervisor(name, jobId);\n        if (supervisor == null || !supervisor.isOwnerNode()) {\n            return false;\n        }\n        Exception exception = new CancellationException(\"Operation was cancelled by the user\");\n        cancelled = supervisor.cancelAndNotify(exception);\n        return cancelled;\n    }","id":14438,"modified_method":"@Override\n    public boolean cancel(boolean mayInterruptIfRunning) {\n        Address jobOwner = mapReduceService.getLocalAddress();\n        if (!mapReduceService.registerJobSupervisorCancellation(name, jobId, jobOwner)) {\n            return false;\n        }\n        JobSupervisor supervisor = mapReduceService.getJobSupervisor(name, jobId);\n        if (supervisor == null || !supervisor.isOwnerNode()) {\n            return false;\n        }\n        Exception exception = new CancellationException(\"Operation was cancelled by the user\");\n        cancelled = supervisor.cancelAndNotify(exception) && super.cancel(mayInterruptIfRunning);\n        return cancelled;\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public TrackableJobFuture(String name, String jobId, JobTracker jobTracker, NodeEngine nodeEngine, Collator collator) {\n        super(nodeEngine, nodeEngine.getLogger(TrackableJobFuture.class));\n        this.name = name;\n        this.jobId = jobId;\n        this.jobTracker = jobTracker;\n        this.collator = collator;\n        this.latch = new CountDownLatch(1);\n        this.mapReduceService = ((NodeEngineImpl) nodeEngine).getService(MapReduceService.SERVICE_NAME);\n    }","id":14439,"modified_method":"public TrackableJobFuture(String name, String jobId, JobTracker jobTracker, NodeEngine nodeEngine, Collator collator) {\n        super(nodeEngine, nodeEngine.getLogger(TrackableJobFuture.class));\n        this.name = name;\n        this.jobId = jobId;\n        this.jobTracker = jobTracker;\n        this.collator = collator;\n        this.mapReduceService = ((NodeEngineImpl) nodeEngine).getService(MapReduceService.SERVICE_NAME);\n    }","commit_id":"085698548a0e8ea44533f5bbe50b68a2417a7b5c","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","id":14440,"modified_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        int maxNumTerms = 25;\n        float boost = 1.0f;\n        String likeText = null;\n        float minSimilarity = 0.5f;\n        int prefixLength = 0;\n        boolean ignoreTF = false;\n\n        XContentParser.Token token = parser.nextToken();\n        assert token == XContentParser.Token.FIELD_NAME;\n        String fieldName = parser.currentName();\n\n        // now, we move after the field name, which starts the object\n        token = parser.nextToken();\n        assert token == XContentParser.Token.START_OBJECT;\n\n\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    likeText = parser.text();\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    maxNumTerms = parser.intValue();\n                } else if (\"boost\".equals(currentFieldName)) {\n                    boost = parser.floatValue();\n                } else if (\"ignore_tf\".equals(currentFieldName) || \"ignoreTF\".equals(currentFieldName)) {\n                    ignoreTF = parser.booleanValue();\n                } else if (\"min_similarity\".equals(currentFieldName) || \"minSimilarity\".equals(currentFieldName)) {\n                    minSimilarity = parser.floatValue();\n                } else if (\"prefix_length\".equals(currentFieldName) || \"prefixLength\".equals(currentFieldName)) {\n                    prefixLength = parser.intValue();\n                }\n            }\n        }\n\n        if (likeText == null) {\n            throw new QueryParsingException(parseContext.index(), \"fuzzy_like_This_field requires 'like_text' to be specified\");\n        }\n\n        Analyzer analyzer = null;\n        MapperService.SmartNameFieldMappers smartNameFieldMappers = parseContext.smartFieldMappers(fieldName);\n        if (smartNameFieldMappers != null) {\n            if (smartNameFieldMappers.hasMapper()) {\n                fieldName = smartNameFieldMappers.mapper().names().indexName();\n                analyzer = smartNameFieldMappers.mapper().searchAnalyzer();\n            }\n        }\n        if (analyzer == null) {\n            analyzer = parseContext.mapperService().searchAnalyzer();\n        }\n\n        FuzzyLikeThisQuery query = new FuzzyLikeThisQuery(maxNumTerms, analyzer);\n        query.addTerms(likeText, fieldName, minSimilarity, prefixLength);\n        query.setBoost(boost);\n        query.setIgnoreTF(ignoreTF);\n\n        // move to the next end object, to close the field name\n        token = parser.nextToken();\n        assert token == XContentParser.Token.END_OBJECT;\n\n        return wrapSmartNameQuery(query, smartNameFieldMappers, parseContext);\n    }","id":14441,"modified_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        int maxNumTerms = 25;\n        float boost = 1.0f;\n        String likeText = null;\n        float minSimilarity = 0.5f;\n        int prefixLength = 0;\n        boolean ignoreTF = false;\n        Analyzer analyzer = null;\n\n        XContentParser.Token token = parser.nextToken();\n        assert token == XContentParser.Token.FIELD_NAME;\n        String fieldName = parser.currentName();\n\n        // now, we move after the field name, which starts the object\n        token = parser.nextToken();\n        assert token == XContentParser.Token.START_OBJECT;\n\n\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    likeText = parser.text();\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    maxNumTerms = parser.intValue();\n                } else if (\"boost\".equals(currentFieldName)) {\n                    boost = parser.floatValue();\n                } else if (\"ignore_tf\".equals(currentFieldName) || \"ignoreTF\".equals(currentFieldName)) {\n                    ignoreTF = parser.booleanValue();\n                } else if (\"min_similarity\".equals(currentFieldName) || \"minSimilarity\".equals(currentFieldName)) {\n                    minSimilarity = parser.floatValue();\n                } else if (\"prefix_length\".equals(currentFieldName) || \"prefixLength\".equals(currentFieldName)) {\n                    prefixLength = parser.intValue();\n                } else if (\"analyzer\".equals(currentFieldName)) {\n                    analyzer = parseContext.analysisService().analyzer(parser.text());\n                }\n            }\n        }\n\n        if (likeText == null) {\n            throw new QueryParsingException(parseContext.index(), \"fuzzy_like_This_field requires 'like_text' to be specified\");\n        }\n\n        MapperService.SmartNameFieldMappers smartNameFieldMappers = parseContext.smartFieldMappers(fieldName);\n        if (smartNameFieldMappers != null) {\n            if (smartNameFieldMappers.hasMapper()) {\n                fieldName = smartNameFieldMappers.mapper().names().indexName();\n                if (analyzer == null) {\n                    analyzer = smartNameFieldMappers.mapper().searchAnalyzer();\n                }\n            }\n        }\n        if (analyzer == null) {\n            analyzer = parseContext.mapperService().searchAnalyzer();\n        }\n\n        FuzzyLikeThisQuery query = new FuzzyLikeThisQuery(maxNumTerms, analyzer);\n        query.addTerms(likeText, fieldName, minSimilarity, prefixLength);\n        query.setBoost(boost);\n        query.setIgnoreTF(ignoreTF);\n\n        // move to the next end object, to close the field name\n        token = parser.nextToken();\n        assert token == XContentParser.Token.END_OBJECT;\n\n        return wrapSmartNameQuery(query, smartNameFieldMappers, parseContext);\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        builder.endObject();\n    }","id":14442,"modified_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        builder.endObject();\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        int maxNumTerms = 25;\n        float boost = 1.0f;\n        List<String> fields = null;\n        String likeText = null;\n        float minSimilarity = 0.5f;\n        int prefixLength = 0;\n        boolean ignoreTF = false;\n\n        XContentParser.Token token;\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    likeText = parser.text();\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    maxNumTerms = parser.intValue();\n                } else if (\"boost\".equals(currentFieldName)) {\n                    boost = parser.floatValue();\n                } else if (\"ignore_tf\".equals(currentFieldName) || \"ignoreTF\".equals(currentFieldName)) {\n                    ignoreTF = parser.booleanValue();\n                } else if (\"min_similarity\".equals(currentFieldName) || \"minSimilarity\".equals(currentFieldName)) {\n                    minSimilarity = parser.floatValue();\n                } else if (\"prefix_length\".equals(currentFieldName) || \"prefixLength\".equals(currentFieldName)) {\n                    prefixLength = parser.intValue();\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"fields\".equals(currentFieldName)) {\n                    fields = Lists.newArrayList();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        fields.add(parseContext.indexName(parser.text()));\n                    }\n                }\n            }\n        }\n\n        if (likeText == null) {\n            throw new QueryParsingException(parseContext.index(), \"fuzzy_like_this requires 'like_text' to be specified\");\n        }\n\n        FuzzyLikeThisQuery query = new FuzzyLikeThisQuery(maxNumTerms, parseContext.mapperService().searchAnalyzer());\n        if (fields == null) {\n            // add the default _all field\n            query.addTerms(likeText, AllFieldMapper.NAME, minSimilarity, prefixLength);\n        } else {\n            for (String field : fields) {\n                query.addTerms(likeText, field, minSimilarity, prefixLength);\n            }\n        }\n        query.setBoost(boost);\n        query.setIgnoreTF(ignoreTF);\n\n        return query;\n    }","id":14443,"modified_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        int maxNumTerms = 25;\n        float boost = 1.0f;\n        List<String> fields = null;\n        String likeText = null;\n        float minSimilarity = 0.5f;\n        int prefixLength = 0;\n        boolean ignoreTF = false;\n        Analyzer analyzer = null;\n\n        XContentParser.Token token;\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    likeText = parser.text();\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    maxNumTerms = parser.intValue();\n                } else if (\"boost\".equals(currentFieldName)) {\n                    boost = parser.floatValue();\n                } else if (\"ignore_tf\".equals(currentFieldName) || \"ignoreTF\".equals(currentFieldName)) {\n                    ignoreTF = parser.booleanValue();\n                } else if (\"min_similarity\".equals(currentFieldName) || \"minSimilarity\".equals(currentFieldName)) {\n                    minSimilarity = parser.floatValue();\n                } else if (\"prefix_length\".equals(currentFieldName) || \"prefixLength\".equals(currentFieldName)) {\n                    prefixLength = parser.intValue();\n                } else if (\"analyzer\".equals(currentFieldName)) {\n                    analyzer = parseContext.analysisService().analyzer(parser.text());\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"fields\".equals(currentFieldName)) {\n                    fields = Lists.newArrayList();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        fields.add(parseContext.indexName(parser.text()));\n                    }\n                }\n            }\n        }\n\n        if (likeText == null) {\n            throw new QueryParsingException(parseContext.index(), \"fuzzy_like_this requires 'like_text' to be specified\");\n        }\n\n        if (analyzer == null) {\n            analyzer = parseContext.mapperService().searchAnalyzer();\n        }\n\n        FuzzyLikeThisQuery query = new FuzzyLikeThisQuery(maxNumTerms, analyzer);\n        if (fields == null) {\n            // add the default _all field\n            query.addTerms(likeText, AllFieldMapper.NAME, minSimilarity, prefixLength);\n        } else {\n            for (String field : fields) {\n                query.addTerms(likeText, field, minSimilarity, prefixLength);\n            }\n        }\n        query.setBoost(boost);\n        query.setIgnoreTF(ignoreTF);\n\n        return query;\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThisField requires 'like_text' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","id":14444,"modified_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThisField requires 'like_text' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        XContentParser.Token token = parser.nextToken();\n        assert token == XContentParser.Token.FIELD_NAME;\n        String fieldName = parser.currentName();\n\n        // now, we move after the field name, which starts the object\n        token = parser.nextToken();\n        assert token == XContentParser.Token.START_OBJECT;\n\n\n        MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();\n        mltQuery.setSimilarity(parseContext.searchSimilarity());\n\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName)) {\n                    mltQuery.setLikeText(parser.text());\n                } else if (\"min_term_freq\".equals(currentFieldName) || \"minTermFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinTermFrequency(parser.intValue());\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    mltQuery.setMaxQueryTerms(parser.intValue());\n                } else if (\"min_doc_freq\".equals(currentFieldName) || \"minDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinDocFreq(parser.intValue());\n                } else if (\"max_doc_freq\".equals(currentFieldName) || \"maxDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMaxDocFreq(parser.intValue());\n                } else if (\"min_word_len\".equals(currentFieldName) || \"minWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMinWordLen(parser.intValue());\n                } else if (\"max_word_len\".equals(currentFieldName) || \"maxWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMaxWordLen(parser.intValue());\n                } else if (\"boost_terms\".equals(currentFieldName) || \"boostTerms\".equals(currentFieldName)) {\n                    mltQuery.setBoostTerms(true);\n                    mltQuery.setBoostTermsFactor(parser.floatValue());\n                } else if (\"percent_terms_to_match\".equals(currentFieldName) || \"percentTermsToMatch\".equals(currentFieldName)) {\n                    mltQuery.setPercentTermsToMatch(parser.floatValue());\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"stop_words\".equals(currentFieldName) || \"stopWords\".equals(currentFieldName)) {\n                    Set<String> stopWords = Sets.newHashSet();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        stopWords.add(parser.text());\n                    }\n                    mltQuery.setStopWords(stopWords);\n                }\n            }\n        }\n\n        if (mltQuery.getLikeText() == null) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this_field requires 'like_text' to be specified\");\n        }\n\n        // move to the next end object, to close the field name\n        token = parser.nextToken();\n        assert token == XContentParser.Token.END_OBJECT;\n\n        MapperService.SmartNameFieldMappers smartNameFieldMappers = parseContext.smartFieldMappers(fieldName);\n        if (smartNameFieldMappers != null) {\n            if (smartNameFieldMappers.hasMapper()) {\n                fieldName = smartNameFieldMappers.mapper().names().indexName();\n                mltQuery.setAnalyzer(smartNameFieldMappers.mapper().searchAnalyzer());\n            }\n        }\n        if (mltQuery.getAnalyzer() == null) {\n            mltQuery.setAnalyzer(parseContext.mapperService().searchAnalyzer());\n        }\n        mltQuery.setMoreLikeFields(new String[]{fieldName});\n        return wrapSmartNameQuery(mltQuery, smartNameFieldMappers, parseContext);\n    }","id":14445,"modified_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        XContentParser.Token token = parser.nextToken();\n        assert token == XContentParser.Token.FIELD_NAME;\n        String fieldName = parser.currentName();\n\n        // now, we move after the field name, which starts the object\n        token = parser.nextToken();\n        assert token == XContentParser.Token.START_OBJECT;\n\n\n        MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();\n        mltQuery.setSimilarity(parseContext.searchSimilarity());\n        Analyzer analyzer = null;\n\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName)) {\n                    mltQuery.setLikeText(parser.text());\n                } else if (\"min_term_freq\".equals(currentFieldName) || \"minTermFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinTermFrequency(parser.intValue());\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    mltQuery.setMaxQueryTerms(parser.intValue());\n                } else if (\"min_doc_freq\".equals(currentFieldName) || \"minDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinDocFreq(parser.intValue());\n                } else if (\"max_doc_freq\".equals(currentFieldName) || \"maxDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMaxDocFreq(parser.intValue());\n                } else if (\"min_word_len\".equals(currentFieldName) || \"minWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMinWordLen(parser.intValue());\n                } else if (\"max_word_len\".equals(currentFieldName) || \"maxWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMaxWordLen(parser.intValue());\n                } else if (\"boost_terms\".equals(currentFieldName) || \"boostTerms\".equals(currentFieldName)) {\n                    mltQuery.setBoostTerms(true);\n                    mltQuery.setBoostTermsFactor(parser.floatValue());\n                } else if (\"percent_terms_to_match\".equals(currentFieldName) || \"percentTermsToMatch\".equals(currentFieldName)) {\n                    mltQuery.setPercentTermsToMatch(parser.floatValue());\n                } else if (\"analyzer\".equals(currentFieldName)) {\n                    analyzer = parseContext.analysisService().analyzer(parser.text());\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"stop_words\".equals(currentFieldName) || \"stopWords\".equals(currentFieldName)) {\n                    Set<String> stopWords = Sets.newHashSet();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        stopWords.add(parser.text());\n                    }\n                    mltQuery.setStopWords(stopWords);\n                }\n            }\n        }\n\n        if (mltQuery.getLikeText() == null) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this_field requires 'like_text' to be specified\");\n        }\n\n        // move to the next end object, to close the field name\n        token = parser.nextToken();\n        assert token == XContentParser.Token.END_OBJECT;\n\n        MapperService.SmartNameFieldMappers smartNameFieldMappers = parseContext.smartFieldMappers(fieldName);\n        if (smartNameFieldMappers != null) {\n            if (smartNameFieldMappers.hasMapper()) {\n                fieldName = smartNameFieldMappers.mapper().names().indexName();\n                if (analyzer == null) {\n                    analyzer = smartNameFieldMappers.mapper().searchAnalyzer();\n                }\n            }\n        }\n        if (analyzer == null) {\n            analyzer = parseContext.mapperService().searchAnalyzer();\n        }\n        mltQuery.setAnalyzer(analyzer);\n        mltQuery.setMoreLikeFields(new String[]{fieldName});\n        return wrapSmartNameQuery(mltQuery, smartNameFieldMappers, parseContext);\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        builder.endObject();\n    }","id":14446,"modified_method":"@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        builder.endObject();\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();\n        mltQuery.setMoreLikeFields(new String[]{AllFieldMapper.NAME});\n        mltQuery.setSimilarity(parseContext.searchSimilarity());\n\n        XContentParser.Token token;\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    mltQuery.setLikeText(parser.text());\n                } else if (\"min_term_freq\".equals(currentFieldName) || \"minTermFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinTermFrequency(parser.intValue());\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    mltQuery.setMaxQueryTerms(parser.intValue());\n                } else if (\"min_doc_freq\".equals(currentFieldName) || \"minDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinDocFreq(parser.intValue());\n                } else if (\"max_doc_freq\".equals(currentFieldName) || \"maxDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMaxDocFreq(parser.intValue());\n                } else if (\"min_word_len\".equals(currentFieldName) || \"minWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMinWordLen(parser.intValue());\n                } else if (\"max_word_len\".equals(currentFieldName) || \"maxWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMaxWordLen(parser.intValue());\n                } else if (\"boost_terms\".equals(currentFieldName) || \"boostTerms\".equals(currentFieldName)) {\n                    mltQuery.setBoostTerms(true);\n                    mltQuery.setBoostTermsFactor(parser.floatValue());\n                } else if (\"percent_terms_to_match\".equals(currentFieldName) || \"percentTermsToMatch\".equals(currentFieldName)) {\n                    mltQuery.setPercentTermsToMatch(parser.floatValue());\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"stop_words\".equals(currentFieldName) || \"stopWords\".equals(currentFieldName)) {\n                    Set<String> stopWords = Sets.newHashSet();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        stopWords.add(parser.text());\n                    }\n                    mltQuery.setStopWords(stopWords);\n                } else if (\"fields\".equals(currentFieldName)) {\n                    List<String> fields = Lists.newArrayList();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        fields.add(parseContext.indexName(parser.text()));\n                    }\n                    mltQuery.setMoreLikeFields(fields.toArray(new String[fields.size()]));\n                }\n            }\n        }\n\n        if (mltQuery.getLikeText() == null) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this requires 'like_text' to be specified\");\n        }\n        if (mltQuery.getMoreLikeFields() == null || mltQuery.getMoreLikeFields().length == 0) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this requires 'fields' to be specified\");\n        }\n\n        mltQuery.setAnalyzer(parseContext.mapperService().searchAnalyzer());\n        return mltQuery;\n    }","id":14447,"modified_method":"@Override public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {\n        XContentParser parser = parseContext.parser();\n\n        MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();\n        mltQuery.setMoreLikeFields(new String[]{AllFieldMapper.NAME});\n        mltQuery.setSimilarity(parseContext.searchSimilarity());\n        Analyzer analyzer = null;\n\n        XContentParser.Token token;\n        String currentFieldName = null;\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n            if (token == XContentParser.Token.FIELD_NAME) {\n                currentFieldName = parser.currentName();\n            } else if (token.isValue()) {\n                if (\"like_text\".equals(currentFieldName) || \"likeText\".equals(currentFieldName)) {\n                    mltQuery.setLikeText(parser.text());\n                } else if (\"min_term_freq\".equals(currentFieldName) || \"minTermFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinTermFrequency(parser.intValue());\n                } else if (\"max_query_terms\".equals(currentFieldName) || \"maxQueryTerms\".equals(currentFieldName)) {\n                    mltQuery.setMaxQueryTerms(parser.intValue());\n                } else if (\"min_doc_freq\".equals(currentFieldName) || \"minDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMinDocFreq(parser.intValue());\n                } else if (\"max_doc_freq\".equals(currentFieldName) || \"maxDocFreq\".equals(currentFieldName)) {\n                    mltQuery.setMaxDocFreq(parser.intValue());\n                } else if (\"min_word_len\".equals(currentFieldName) || \"minWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMinWordLen(parser.intValue());\n                } else if (\"max_word_len\".equals(currentFieldName) || \"maxWordLen\".equals(currentFieldName)) {\n                    mltQuery.setMaxWordLen(parser.intValue());\n                } else if (\"boost_terms\".equals(currentFieldName) || \"boostTerms\".equals(currentFieldName)) {\n                    mltQuery.setBoostTerms(true);\n                    mltQuery.setBoostTermsFactor(parser.floatValue());\n                } else if (\"percent_terms_to_match\".equals(currentFieldName) || \"percentTermsToMatch\".equals(currentFieldName)) {\n                    mltQuery.setPercentTermsToMatch(parser.floatValue());\n                } else if (\"analyzer\".equals(currentFieldName)) {\n                    analyzer = parseContext.analysisService().analyzer(parser.text());\n                }\n            } else if (token == XContentParser.Token.START_ARRAY) {\n                if (\"stop_words\".equals(currentFieldName) || \"stopWords\".equals(currentFieldName)) {\n                    Set<String> stopWords = Sets.newHashSet();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        stopWords.add(parser.text());\n                    }\n                    mltQuery.setStopWords(stopWords);\n                } else if (\"fields\".equals(currentFieldName)) {\n                    List<String> fields = Lists.newArrayList();\n                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                        fields.add(parseContext.indexName(parser.text()));\n                    }\n                    mltQuery.setMoreLikeFields(fields.toArray(new String[fields.size()]));\n                }\n            }\n        }\n\n        if (mltQuery.getLikeText() == null) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this requires 'like_text' to be specified\");\n        }\n        if (mltQuery.getMoreLikeFields() == null || mltQuery.getMoreLikeFields().length == 0) {\n            throw new QueryParsingException(parseContext.index(), \"more_like_this requires 'fields' to be specified\");\n        }\n\n        if (analyzer == null) {\n            analyzer = parseContext.mapperService().searchAnalyzer();\n        }\n\n        mltQuery.setAnalyzer(analyzer);\n        return mltQuery;\n    }","commit_id":"64bf849cb14c6c378206ae1702d931137a3cf365","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void removeAppendAttributes(Txn transaction, NodeList removeList, NodeList appendList) {\n\t\tfinal int level = ((DocumentImpl)getOwnerDocument()).getTreeLevel(getGID());\t\t\n\t\tfinal long lastChild = lastChildID();\t\t\n\t\ttry {\n\t\t\ttry {\n\t\t\t\tfor (int i=0; i<removeList.getLength(); i++) {\n\t\t\t\t\tNode oldChild = removeList.item(i);\n\t\t\t\t\tif (!(oldChild instanceof StoredNode))\n\t\t\t\t\t\tthrow new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n\t\t\t\t\tStoredNode old = (StoredNode) oldChild;\n\t\t\t\t\tif (old.getParentGID() != getGID())\n\t\t\t\t\t\tthrow new DOMException(DOMException.NOT_FOUND_ERR, \"node is not a child of this element\");\n                    getBroker().removeNode(transaction, old, old.getPath(), null);\n\t\t\t\t\tif(old.getGID() < lastChild) ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n\t\t\t\t\tchildren--;\n\t\t\t\t\tattributes--;\n\t\t\t\t}\n\t\t\t} finally {\n                getBroker().endRemove();\n\t\t\t}\t\t\t\n\t\t\tif (children == 0) {\n\t\t\t   appendChildren(transaction, firstChildID(), new NodeImplRef(this), getPath(), appendList, true);\n\t\t\t} else {\n\t\t\t    StoredNode lastAttrib = getLastAttribute();\n\t\t\t    if (lastAttrib == null || lastAttrib.getGID() != lastChildID())\n                    appendChildren(transaction, firstChildID() + 1, new NodeImplRef(this), getPath(), appendList, true);                    \n\t\t\t    else\n                    appendChildren(transaction, lastChildID() + 1, new NodeImplRef(lastAttrib), getPath(), appendList, true);\t\t\t        \n\t\t\t}\n\t\t\tattributes += appendList.getLength();\n\t\t} finally {\n            getBroker().update(transaction, this);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n\t\t}\n\t}","id":14448,"modified_method":"public void removeAppendAttributes(Txn transaction, NodeList removeList, NodeList appendList) {\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n\t\tfinal int level = owner.getTreeLevel(getGID());\t\t\n\t\tfinal long lastChild = lastChildID();\t\t\n\t\ttry {\n\t\t\ttry {\n\t\t\t\tfor (int i=0; i<removeList.getLength(); i++) {\n\t\t\t\t\tNode oldChild = removeList.item(i);\n\t\t\t\t\tif (!(oldChild instanceof StoredNode))\n\t\t\t\t\t\tthrow new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n\t\t\t\t\tStoredNode old = (StoredNode) oldChild;\n\t\t\t\t\tif (old.getParentGID() != getGID())\n\t\t\t\t\t\tthrow new DOMException(DOMException.NOT_FOUND_ERR, \"node is not a child of this element\");\n                    getBroker().removeNode(transaction, old, old.getPath(), null);\n\t\t\t\t\tif(old.getGID() < lastChild) owner.getMetadata().setReindexRequired(level + 1);\n\t\t\t\t\tchildren--;\n\t\t\t\t\tattributes--;\n\t\t\t\t}\n\t\t\t} finally {\n                getBroker().endRemove();\n\t\t\t}\t\t\t\n\t\t\tif (children == 0) {\n\t\t\t   appendChildren(transaction, firstChildID(), new NodeImplRef(this), getPath(), appendList, true);\n\t\t\t} else {\n\t\t\t    StoredNode lastAttrib = getLastAttribute();\n\t\t\t    if (lastAttrib == null || lastAttrib.getGID() != lastChildID())\n                    appendChildren(transaction, firstChildID() + 1, new NodeImplRef(this), getPath(), appendList, true);                    \n\t\t\t    else\n                    appendChildren(transaction, lastChildID() + 1, new NodeImplRef(lastAttrib), getPath(), appendList, true);\t\t\t        \n\t\t\t}\n\t\t\tattributes += appendList.getLength();\n\t\t} finally {\n            getBroker().update(transaction, this);\n            getBroker().reindex(transaction, owner, owner, null);\n\t\t}\n\t}","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"public Node replaceChild(Txn transaction, Node newChild, Node oldChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        StoredNode old = (StoredNode) oldChild;\n        if (old.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");        \n        StoredNode previous = (StoredNode) old.getPreviousSibling();\n        if (previous == null)\n            previous = this;\n        else\n            previous = getLastNode(previous);\n        getBroker().removeAll(transaction, old, old.getPath());\n        getBroker().endRemove();\n        appendChild(transaction, old.getGID(), new NodeImplRef(previous), getPath(), newChild, true);\n        // reindex if required\n        getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n        getBroker().storeDocument(transaction, ((DocumentImpl)getOwnerDocument()));\n        return oldChild;\t// method is spec'd to return the old child, even though that's probably useless in this case\n    }","id":14449,"modified_method":"public Node replaceChild(Txn transaction, Node newChild, Node oldChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        StoredNode oldNode = (StoredNode) oldChild;\n        if (oldNode.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");        \n        StoredNode previous = (StoredNode) oldNode.getPreviousSibling();\n        if (previous == null)\n            previous = this;\n        else\n            previous = getLastNode(previous);\n        getBroker().removeAll(transaction, oldNode, oldNode.getPath());\n        getBroker().endRemove();\n        appendChild(transaction, oldNode.getGID(), new NodeImplRef(previous), getPath(), newChild, true);\n        // reindex if required\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        getBroker().reindex(transaction, owner, owner, null);\n        getBroker().storeDocument(transaction, owner);\n        return oldChild;\t// method is spec'd to return the old child, even though that's probably useless in this case\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Insert a list of nodes at the position before the reference\n     * child.\n     */\n    public void insertBefore(Txn transaction, NodeList nodes, Node refChild) throws DOMException {\n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");        \n        if (refChild == null) {\n            //TODO : use NodeImpl.UNKNOWN_NODE_IMPL_GID ? -pb\n            appendChildren(transaction, nodes, -1);\n            return;\n        }\n        StoredNode ref = (StoredNode) refChild;\n        final long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        final int level = ((DocumentImpl)getOwnerDocument()).getTreeLevel(getGID());\n        if (ref.getGID() == first)\n            appendChildren(transaction, first, new NodeImplRef(this), getPath(), nodes, false);\n        else {\n            StoredNode prev = (StoredNode) ref.getPreviousSibling();\n            appendChildren(transaction, ref.getGID(), new NodeImplRef(getLastNode(prev)), getPath(), nodes, false);\n        }\n        getBroker().update(transaction, this);\n        int reindex = ((DocumentImpl)getOwnerDocument()).getMetadata().reindexRequired();\n        if (reindex > -1) {\n            ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n        }\n        else {\n            ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), this);\n        }\n    }","id":14450,"modified_method":"/**\n     * Insert a list of nodes at the position before the reference\n     * child.\n     */\n    public void insertBefore(Txn transaction, NodeList nodes, Node refChild) throws DOMException {\n        if (refChild == null) {\n            //TODO : use NodeImpl.UNKNOWN_NODE_IMPL_GID ? -pb\n            appendChildren(transaction, nodes, -1);\n            return;\n        }\n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\"); \n        final StoredNode ref = (StoredNode) refChild;\n        final long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        final int level = owner.getTreeLevel(getGID());\n        if (ref.getGID() == first)\n            appendChildren(transaction, first, new NodeImplRef(this), getPath(), nodes, false);\n        else {\n            StoredNode prev = (StoredNode) ref.getPreviousSibling();\n            appendChildren(transaction, ref.getGID(), new NodeImplRef(getLastNode(prev)), getPath(), nodes, false);\n        }\n        getBroker().update(transaction, this);\n        int reindex = owner.getMetadata().reindexRequired();\n        if (reindex == DocumentMetadata.REINDEX_ALL) {\n            owner.getMetadata().setReindexRequired(0);\n            getBroker().reindex(transaction, owner, owner, this);\n        } else {\n            owner.getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, owner, owner, null);\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Update a child node. This method will only update the child node\n     * but not its potential descendant nodes.\n     *\n     * @param oldChild\n     * @param newChild\n     * @throws DOMException\n     */\n    public void updateChild(Txn transaction, Node oldChild, Node newChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        if (!(newChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        StoredNode old = (StoredNode) oldChild;\n        StoredNode newNode = (StoredNode) newChild;\n        if (old.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");\n        if (newNode.getNodeType() == Node.ATTRIBUTE_NODE) {\n        \tif (newNode.getQName().equalsSimple(Namespaces.XML_ID_QNAME)) {\n\t\t\t\t\t// an xml:id attribute. Normalize the attribute and set its type to ID\n        \t\tAttrImpl attr = (AttrImpl) newNode;\n        \t\tattr.setValue(StringValue.trimWhitespace(StringValue.collapseWhitespace(attr.getValue())));\n        \t\tattr.setType(AttrImpl.ID);\n        \t}\n        }        \n        StoredNode previous = (StoredNode) old.getPreviousSibling();\n        if (previous == null)\n            previous = this;\n        else\n            previous = getLastNode(previous);\n        getBroker().removeNode(transaction, old, old.getPath(), null);\n        getBroker().endRemove();\n        newNode.setGID(old.getGID());\n        getBroker().insertAfter(transaction, previous, newNode);\n        NodePath path = newNode.getPath();\n        getBroker().index(transaction, newNode, path);\n\t\tif (newNode.getNodeType() == Node.ELEMENT_NODE)\n            getBroker().endElement(newNode, path, null);\n        getBroker().flush();\n    }","id":14451,"modified_method":"/**\n     * Update a child node. This method will only update the child node\n     * but not its potential descendant nodes.\n     *\n     * @param oldChild\n     * @param newChild\n     * @throws DOMException\n     */\n    public void updateChild(Txn transaction, Node oldChild, Node newChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        if (!(newChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        StoredNode oldNode = (StoredNode) oldChild;\n        StoredNode newNode = (StoredNode) newChild;\n        if (oldNode.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");\n        if (newNode.getNodeType() == Node.ATTRIBUTE_NODE) {\n        \tif (newNode.getQName().equalsSimple(Namespaces.XML_ID_QNAME)) {\n\t\t\t\t\t// an xml:id attribute. Normalize the attribute and set its type to ID\n        \t\tAttrImpl attr = (AttrImpl) newNode;\n        \t\tattr.setValue(StringValue.trimWhitespace(StringValue.collapseWhitespace(attr.getValue())));\n        \t\tattr.setType(AttrImpl.ID);\n        \t}\n        }        \n        StoredNode previousNode = (StoredNode) oldNode.getPreviousSibling();\n        if (previousNode == null)\n            previousNode = this;\n        else\n            previousNode = getLastNode(previousNode);\n        getBroker().removeNode(transaction, oldNode, oldNode.getPath(), null);\n        getBroker().endRemove();\n        newNode.setGID(oldNode.getGID());\n        getBroker().insertAfter(transaction, previousNode, newNode);\n        NodePath path = newNode.getPath();\n        getBroker().index(transaction, newNode, path);\n\t\tif (newNode.getNodeType() == Node.ELEMENT_NODE)\n            getBroker().endElement(newNode, path, null);\n        getBroker().flush();\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Insert a list of nodes at the position following the reference\n     * child.\n     */\n    public void insertAfter(Txn transaction, NodeList nodes, Node refChild) throws DOMException {\n        if (refChild == null) {\n            //TODO : use NodeImpl.UNKNOWN_NODE_IMPL_GID ? -pb\n            appendChildren(null, nodes, -1);\n            return;\n        }\n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type: \");        \n        final StoredNode ref = (StoredNode) refChild;\n        final long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        final int level = ((DocumentImpl)getOwnerDocument()).getTreeLevel(getGID());\n        appendChildren(transaction, ref.getGID() + 1, new NodeImplRef(getLastNode(ref)), getPath(), nodes, false);\n        getBroker().update(transaction, this);\n        int reindex = ((DocumentImpl)getOwnerDocument()).getMetadata().reindexRequired();\n        if (reindex > -1) {\n            ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n        }\n        else {\n            ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), this);\n        }\n    }","id":14452,"modified_method":"/**\n     * Insert a list of nodes at the position following the reference\n     * child.\n     */\n    public void insertAfter(Txn transaction, NodeList nodes, Node refChild) throws DOMException {\n        if (refChild == null) {\n            //TODO : use NodeImpl.UNKNOWN_NODE_IMPL_GID ? -pb\n            appendChildren(null, nodes, -1);\n            return;\n        } \n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type: \");          \n        final StoredNode ref = (StoredNode) refChild;\n        final long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        final int level = owner.getTreeLevel(getGID());\n        appendChildren(transaction, ref.getGID() + 1, new NodeImplRef(getLastNode(ref)), getPath(), nodes, false);\n        getBroker().update(transaction, this);\n        int reindex = owner.getMetadata().reindexRequired();\n        if (reindex == DocumentMetadata.REINDEX_ALL) {\n            owner.getMetadata().setReindexRequired(0);\n            getBroker().reindex(transaction, owner, owner, this);\n        } else {\n            owner.getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, owner, owner, null);\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Update the contents of this element. The passed list of nodes\n     * becomes the new content.\n     *\n     * @param newContent\n     * @throws DOMException\n     */\n    public void update(Txn transaction, NodeList newContent) throws DOMException {\n        final NodePath path = getPath();        \n        // remove old child nodes\n        NodeList nodes = getChildNodes();\n        StoredNode child, last = this;\n        long firstChildId = firstChildID();\n        int i = nodes.getLength();\n        for (; i > 0; i--) {\n            child = (StoredNode) nodes.item(i - 1);\n            if (child.getNodeType() == Node.ATTRIBUTE_NODE) {\n                firstChildId = child.getGID() + 1;\n                last = child;\n                break;\n            }\n            if (child.getNodeType() == Node.ELEMENT_NODE)\n                path.addComponent(child.getQName());\n            getBroker().removeAll(transaction, child, path);\n            if (child.getNodeType() == Node.ELEMENT_NODE)\n                path.removeLastComponent();\n        }\n        getBroker().endRemove();\n        children = i;\n        // append new content\n        appendChildren(transaction, firstChildId, new NodeImplRef(last), getPath(), newContent, true);\n        getBroker().update(transaction, this);\n        // reindex if required\n        getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), (DocumentImpl)getOwnerDocument(), null);\n    }","id":14453,"modified_method":"/**\n     * Update the contents of this element. The passed list of nodes\n     * becomes the new content.\n     *\n     * @param newContent\n     * @throws DOMException\n     */\n    public void update(Txn transaction, NodeList newContent) throws DOMException {\n        final NodePath path = getPath();        \n        // remove old child nodes\n        NodeList nodes = getChildNodes();\n        StoredNode child, last = this;\n        long firstChildId = firstChildID();\n        int i = nodes.getLength();\n        for (; i > 0; i--) {\n            child = (StoredNode) nodes.item(i - 1);\n            if (child.getNodeType() == Node.ATTRIBUTE_NODE) {\n                firstChildId = child.getGID() + 1;\n                last = child;\n                break;\n            }\n            if (child.getNodeType() == Node.ELEMENT_NODE)\n                path.addComponent(child.getQName());\n            getBroker().removeAll(transaction, child, path);\n            if (child.getNodeType() == Node.ELEMENT_NODE)\n                path.removeLastComponent();\n        }\n        getBroker().endRemove();\n        children = i;\n        // append new content\n        appendChildren(transaction, firstChildId, new NodeImplRef(last), getPath(), newContent, true);\n        getBroker().update(transaction, this);\n        // reindex if required\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        getBroker().reindex(transaction, owner, owner, null);\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"private void removeAll(Txn transaction, StoredNode node, NodePath currentPath) {\n        switch (node.getNodeType()) {\n            case Node.ELEMENT_NODE:\n\t\t\t\tString content = null;\n\t\t\t\tIndexSpec idxSpec = \n                    ((DocumentImpl)getOwnerDocument()).getCollection().getIdxConf(((DocumentImpl)getOwnerDocument()).broker);\n\t\t\t\tif (idxSpec != null) {\n\t\t\t\t\tGeneralRangeIndexSpec spec = idxSpec.getIndexByPath(currentPath);\n\t\t\t\t\tRangeIndexSpec qnIdx = idxSpec.getIndexByQName(node.getQName());\n\t\t\t\t\tif (spec != null || qnIdx != null) {\n\t\t\t\t\t\tNodeProxy p = new NodeProxy((DocumentImpl)node.getOwnerDocument(), node.getGID(), node.getInternalAddress());\n\t\t\t\t\t\tcontent = getBroker().getNodeValue(p, false);\n\t\t\t\t\t}\n\t\t\t\t}\n                NodeList children = node.getChildNodes();\n                StoredNode child;\n                for (int i = children.getLength() - 1; i >= 0; i--) {\n                    child = (StoredNode) children.item(i);\n                    if (child.getNodeType() == Node.ELEMENT_NODE) {\n                        currentPath.addComponent(((ElementImpl) child).getQName());\n                        removeAll(transaction, child, currentPath);\n                        currentPath.removeLastComponent();\n                    }\n                    else\n                        removeAll(transaction, child, currentPath);\n                }\n                getBroker().removeNode(transaction, node, currentPath, content);\n                break;\n            default :\n                getBroker().removeNode(transaction, node, currentPath, null);\n                break;\n            //TODO : manage unknown type ! -pb\n        }\n    }","id":14454,"modified_method":"private void removeAll(Txn transaction, StoredNode node, NodePath currentPath) {\n        switch (node.getNodeType()) {\n            case Node.ELEMENT_NODE:\n\t\t\t\tString content = null;\n                final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n\t\t\t\tIndexSpec idxSpec = \n                    owner.getCollection().getIdxConf(owner.broker);\n\t\t\t\tif (idxSpec != null) {\n\t\t\t\t\tGeneralRangeIndexSpec spec = idxSpec.getIndexByPath(currentPath);\n\t\t\t\t\tRangeIndexSpec qnIdx = idxSpec.getIndexByQName(node.getQName());\n\t\t\t\t\tif (spec != null || qnIdx != null) {\n\t\t\t\t\t\tNodeProxy p = new NodeProxy(owner, node.getGID(), node.getInternalAddress());\n\t\t\t\t\t\tcontent = getBroker().getNodeValue(p, false);\n\t\t\t\t\t}\n\t\t\t\t}\n                NodeList children = node.getChildNodes();\n                StoredNode child;\n                for (int i = children.getLength() - 1; i >= 0; i--) {\n                    child = (StoredNode) children.item(i);\n                    if (child.getNodeType() == Node.ELEMENT_NODE) {\n                        currentPath.addComponent(((ElementImpl) child).getQName());\n                        removeAll(transaction, child, currentPath);\n                        currentPath.removeLastComponent();\n                    }\n                    else\n                        removeAll(transaction, child, currentPath);\n                }\n                getBroker().removeNode(transaction, node, currentPath, content);\n                break;\n            default :\n                getBroker().removeNode(transaction, node, currentPath, null);\n                break;\n            //TODO : manage unknown type ! -pb\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"private void checkTree(int size) throws EXistException {\n        DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        // check if the tree structure needs to be changed\n        int level = owner.getTreeLevel(getGID());\n        if (owner.getMaxDepth() == level + 1) {\n            owner.incMaxDepth();\n            LOG.debug(\"Incrementing maxDepth to '\" + owner.getMaxDepth() + \"'\");\n        }\n        if (owner.getTreeLevelOrder(level + 1) < children + size) {\n            // recompute the order of the tree\n            owner.setTreeLevelOrder(level + 1, children + size + getBroker().getXUpdateGrowthFactor());\n            owner.calculateTreeLevelStartPoints(false);\n            int reindex = owner.getMetadata().reindexRequired();\n            if (reindex < 0 || reindex > level + 1) {\n                owner.getMetadata().setReindexRequired(level + 1);\n            }\n        }\n    }","id":14455,"modified_method":"private void checkTree(int size) throws EXistException {\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        // check if the tree structure needs to be changed\n        int level = owner.getTreeLevel(getGID());\n        if (owner.getMaxDepth() == level + 1) {\n            owner.incMaxDepth();\n            LOG.debug(\"Incrementing maxDepth to '\" + owner.getMaxDepth() + \"'\");\n        }\n        if (owner.getTreeLevelOrder(level + 1) < children + size) {\n            // recompute the order of the tree\n            owner.setTreeLevelOrder(level + 1, children + size + getBroker().getXUpdateGrowthFactor());\n            owner.calculateTreeLevelStartPoints(false);\n            int reindex = owner.getMetadata().reindexRequired();\n            if (reindex == DocumentMetadata.REINDEX_ALL || reindex > level + 1) {\n                owner.getMetadata().setReindexRequired(level + 1);\n            }\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"private Node appendChild(Txn transaction, long gid, NodeImplRef last, NodePath lastPath, Node child, boolean index)\n            throws DOMException {\n        if (last == null || last.getNode() == null)\n            //TODO : same test as above ? -pb\n            throw new DOMException(DOMException.INVALID_MODIFICATION_ERR, \"invalid node\"); \n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        switch (child.getNodeType()) {\n    \t\tcase Node.DOCUMENT_FRAGMENT_NODE :\n    \t\t    appendChildren(transaction, gid, last, lastPath, child.getChildNodes(),index);\n    \t\t    return null;    // TODO: implement document fragments so we can return all newly appended children\n            case Node.ELEMENT_NODE :                \n                // create new element\n                final ElementImpl elem =\n                    new ElementImpl(\n                            new QName(child.getLocalName() == null ? child.getNodeName() : child.getLocalName(),\n                            child.getNamespaceURI(),\n                            child.getPrefix())\n                    );\n                elem.setGID(gid);\n                elem.setOwnerDocument(owner);\n                final NodeListImpl ch = new NodeListImpl();\n                final NamedNodeMap attribs = child.getAttributes();\n                for (int i = 0; i < attribs.getLength(); i++) {\n                    Attr attr = (Attr) attribs.item(i);\n                    ch.add(attr);\n                }\n\t\t\t\tNodeList cl = child.getChildNodes();\n\t\t\t\tfor (int i = 0; i < cl.getLength(); i++) {\n\t\t\t\t\tNode n = cl.item(i);\n\t\t\t\t\tif (n.getNodeType() != Node.ATTRIBUTE_NODE)\n\t\t\t\t\t\tch.add(n);\n\t\t\t\t}\n                elem.setChildCount(ch.getLength());\n                elem.setAttributes((short) (elem.getAttributesCount() + attribs.getLength()));\n                lastPath.addComponent(elem.getQName());\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), elem);                \n                \n                // index now?\n                int reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid)))                       \n                    getBroker().index(transaction, elem, lastPath);\n                \n                elem.setChildCount(0);\n                try {\n                    elem.checkTree(ch.getLength());\n                }\n                catch (EXistException e) {\n                    throw new DOMException(DOMException.INVALID_MODIFICATION_ERR,\n                            \"max. document size exceeded\");\n                }\n                // process child nodes\n                last.setNode(elem);\n                elem.appendChildren(transaction, elem.firstChildID(), last, lastPath, ch, index);\n                \n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid)))                       \n                    getBroker().endElement(elem, lastPath, null);\n                \n                lastPath.removeLastComponent();\n                return elem;\n            case Node.TEXT_NODE :                \n                final TextImpl text = new TextImpl(((Text) child).getData());\n                text.setGID(gid);\n                text.setOwnerDocument(((DocumentImpl)getOwnerDocument()));\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), text);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid)))\n                    getBroker().index(transaction, text, lastPath);\n                last.setNode(text);               \n                return text;\n\n            case Node.ATTRIBUTE_NODE:\n                Attr attr = (Attr) child;\n                String ns = attr.getNamespaceURI();\n                String prefix = (Namespaces.XML_NS.equals(ns) ? \"xml\" : attr.getPrefix());\n                String name = attr.getLocalName();\n                if (name == null) name = attr.getName();\n                QName attrName = new QName(name, ns, prefix);\n                final AttrImpl attrib = new AttrImpl(attrName, attr.getValue());\n                attrib.setGID(gid);\n                attrib.setOwnerDocument(((DocumentImpl)getOwnerDocument()));\n                if (ns != null && attrName.compareTo(Namespaces.XML_ID_QNAME) == Constants.EQUAL) {\n                    // an xml:id attribute. Normalize the attribute and set its type to ID\n                    attrib.setValue(StringValue.trimWhitespace(StringValue.collapseWhitespace(attrib.getValue())));\n                    attrib.setType(AttrImpl.ID);\n                }\n                getBroker().insertAfter(transaction, last.getNode(), attrib);\n                // index now?\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid))) {\n                    getBroker().index(transaction, attrib, lastPath);\n                }\n                last.setNode(attrib); \n                return attrib;\n            case Node.COMMENT_NODE:\n                final CommentImpl comment = new CommentImpl(((Comment) child).getData());\n                comment.setGID(gid);\n                comment.setOwnerDocument(((DocumentImpl)getOwnerDocument()));\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), comment);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid)))\n                    getBroker().index(transaction, comment, lastPath);\n                last.setNode(comment);                 \n                return comment;\n            case Node.PROCESSING_INSTRUCTION_NODE:\n                final ProcessingInstructionImpl pi =\n                    new ProcessingInstructionImpl(gid,\n                            ((ProcessingInstruction) child).getTarget(),\n                            ((ProcessingInstruction) child).getData());\n                pi.setOwnerDocument(owner);\n                //          insert the node\n                getBroker().insertAfter(transaction, last.getNode(), pi);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex < 0 || reindex > owner.getTreeLevel(gid)))                   \n                    getBroker().index(transaction, pi, lastPath);\n                last.setNode(pi);\n                return pi; \n            default :\n                throw new DOMException(DOMException.INVALID_MODIFICATION_ERR,\n                        \"unknown node type: \"\n                        + child.getNodeType()\n                        + \" \"\n                        + child.getNodeName());\n        }\n    }","id":14456,"modified_method":"private Node appendChild(Txn transaction, long gid, NodeImplRef last, NodePath lastPath, Node child, boolean index)\n            throws DOMException {\n        if (last == null || last.getNode() == null)\n            //TODO : same test as above ? -pb\n            throw new DOMException(DOMException.INVALID_MODIFICATION_ERR, \"invalid node\"); \n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        switch (child.getNodeType()) {\n    \t\tcase Node.DOCUMENT_FRAGMENT_NODE :\n    \t\t    appendChildren(transaction, gid, last, lastPath, child.getChildNodes(),index);\n    \t\t    return null;    // TODO: implement document fragments so we can return all newly appended children\n            case Node.ELEMENT_NODE :                \n                // create new element\n                final ElementImpl elem =\n                    new ElementImpl(\n                        new QName(child.getLocalName() == null ? child.getNodeName() : child.getLocalName(),\n                        child.getNamespaceURI(),\n                        child.getPrefix())\n                    );\n                elem.setGID(gid);\n                elem.setOwnerDocument(owner);\n                final NodeListImpl ch = new NodeListImpl();\n                final NamedNodeMap attribs = child.getAttributes();\n                for (int i = 0; i < attribs.getLength(); i++) {\n                    Attr attr = (Attr) attribs.item(i);\n                    ch.add(attr);\n                }\n\t\t\t\tNodeList cl = child.getChildNodes();\n\t\t\t\tfor (int i = 0; i < cl.getLength(); i++) {\n\t\t\t\t\tNode n = cl.item(i);\n\t\t\t\t\tif (n.getNodeType() != Node.ATTRIBUTE_NODE)\n\t\t\t\t\t\tch.add(n);\n\t\t\t\t}\n                elem.setChildCount(ch.getLength());\n                elem.setAttributes((short) (elem.getAttributesCount() + attribs.getLength()));\n                lastPath.addComponent(elem.getQName());\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), elem);                \n                \n                // index now?\n                int reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid)))                       \n                    getBroker().index(transaction, elem, lastPath);\n                \n                elem.setChildCount(0);\n                try {\n                    elem.checkTree(ch.getLength());\n                }\n                catch (EXistException e) {\n                    throw new DOMException(DOMException.INVALID_MODIFICATION_ERR,\n                            \"max. document size exceeded\");\n                }\n                // process child nodes\n                last.setNode(elem);\n                elem.appendChildren(transaction, elem.firstChildID(), last, lastPath, ch, index);\n                \n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid)))                       \n                    getBroker().endElement(elem, lastPath, null);\n                \n                lastPath.removeLastComponent();\n                return elem;\n            case Node.TEXT_NODE :                \n                final TextImpl text = new TextImpl(((Text) child).getData());\n                text.setGID(gid);\n                text.setOwnerDocument(owner);\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), text);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid)))\n                    getBroker().index(transaction, text, lastPath);\n                last.setNode(text);               \n                return text;\n            case Node.ATTRIBUTE_NODE:\n                Attr attr = (Attr) child;\n                String ns = attr.getNamespaceURI();\n                String prefix = (Namespaces.XML_NS.equals(ns) ? \"xml\" : attr.getPrefix());\n                String name = attr.getLocalName();\n                if (name == null) name = attr.getName();\n                QName attrName = new QName(name, ns, prefix);\n                final AttrImpl attrib = new AttrImpl(attrName, attr.getValue());\n                attrib.setGID(gid);\n                attrib.setOwnerDocument(owner);\n                if (ns != null && attrName.compareTo(Namespaces.XML_ID_QNAME) == Constants.EQUAL) {\n                    // an xml:id attribute. Normalize the attribute and set its type to ID\n                    attrib.setValue(StringValue.trimWhitespace(StringValue.collapseWhitespace(attrib.getValue())));\n                    attrib.setType(AttrImpl.ID);\n                }\n                getBroker().insertAfter(transaction, last.getNode(), attrib);\n                // index now?\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid))) {\n                    getBroker().index(transaction, attrib, lastPath);\n                }\n                last.setNode(attrib); \n                return attrib;\n            case Node.COMMENT_NODE:\n                final CommentImpl comment = new CommentImpl(((Comment) child).getData());\n                comment.setGID(gid);\n                comment.setOwnerDocument(owner);\n                // insert the node\n                getBroker().insertAfter(transaction, last.getNode(), comment);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid)))\n                    getBroker().index(transaction, comment, lastPath);\n                last.setNode(comment);                 \n                return comment;\n            case Node.PROCESSING_INSTRUCTION_NODE:\n                final ProcessingInstructionImpl pi =\n                    new ProcessingInstructionImpl(gid,\n                            ((ProcessingInstruction) child).getTarget(),\n                            ((ProcessingInstruction) child).getData());\n                pi.setOwnerDocument(owner);\n                //          insert the node\n                getBroker().insertAfter(transaction, last.getNode(), pi);\n                reindex = owner.getMetadata().reindexRequired();\n                if (index && (reindex == DocumentMetadata.REINDEX_ALL || reindex > owner.getTreeLevel(gid)))                   \n                    getBroker().index(transaction, pi, lastPath);\n                last.setNode(pi);\n                return pi; \n            default :\n                throw new DOMException(DOMException.INVALID_MODIFICATION_ERR,\n                    \"unknown node type: \"\n                    + child.getNodeType()\n                    + \" \"\n                    + child.getNodeName());\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Append a child to this node. This method does not rearrange the\n     * node tree and is only used internally by the parser.\n     *\n     * @param child\n     * @throws DOMException\n     */\n    public void appendChildInternal(StoredNode child) throws DOMException {\n        //TOUNDERSTAND : what are the semantics of this 0 ? -pb\n        if (getGID() > 0) {\n            child.setGID(firstChildID() + children);            \n            if (child.getGID() == StoredNode.NODE_IMPL_UNKNOWN_GID) {\n                DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n                final int level = owner.getTreeLevel(getGID());\n                final int order = owner.getTreeLevelOrder(level);\n                throw new DOMException(DOMException.INVALID_STATE_ERR,\n                        \"internal error: node \"\n                        + getGID()\n                        + \"; first-child: \"\n                        + firstChildID()\n                        + \"; level: \"\n                        + level\n                        + \"; maxDepth: \"\n                        + owner.getMaxDepth()\n                        + \"; order(level+1): \"\n                        + order\n                        + \"; start0: \"\n                        + owner.getLevelStartPoint(level)\n                        + \"; start1: \"\n                        + owner.getLevelStartPoint(level + 1));\n            }\n        }\n        else\n            //TOUNDERSTAND : what are the semantics of this 0 ? -pb\n            child.setGID(0);\n        ++children;\n    }","id":14457,"modified_method":"/**\n     * Append a child to this node. This method does not rearrange the\n     * node tree and is only used internally by the parser.\n     *\n     * @param child\n     * @throws DOMException\n     */\n    public void appendChildInternal(StoredNode child) throws DOMException {\n        //TOUNDERSTAND : what are the semantics of this 0 ? -pb\n        if (getGID() > 0) {\n            child.setGID(firstChildID() + children);            \n            if (child.getGID() == StoredNode.NODE_IMPL_UNKNOWN_GID) {\n                final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n                final int level = owner.getTreeLevel(getGID());\n                final int order = owner.getTreeLevelOrder(level);\n                throw new DOMException(DOMException.INVALID_STATE_ERR,\n                        \"internal error: node \"\n                        + getGID()\n                        + \"; first-child: \"\n                        + firstChildID()\n                        + \"; level: \"\n                        + level\n                        + \"; maxDepth: \"\n                        + owner.getMaxDepth()\n                        + \"; order(level+1): \"\n                        + order\n                        + \"; start0: \"\n                        + owner.getLevelStartPoint(level)\n                        + \"; start1: \"\n                        + owner.getLevelStartPoint(level + 1));\n            }\n        }\n        else\n            //TOUNDERSTAND : what are the semantics of this 0 ? -pb\n            child.setGID(0);\n        ++children;\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * @see org.w3c.dom.Node#insertBefore(org.w3c.dom.Node, org.w3c.dom.Node)\n     */\n    public Node insertBefore(Node newChild, Node refChild) throws DOMException {\n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");        \n        if (refChild == null)\n            return appendChild(newChild);\n        StoredNode ref = (StoredNode) refChild;\n        long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        Node result;\n        try {\n            TransactionManager transact = getBroker().getBrokerPool().getTransactionManager();\n            Txn transaction = transact.beginTransaction();\n            if (ref.getGID() == first)\n                result = appendChild(null, first, new NodeImplRef(this), getPath(), newChild, false);\n            else {\n                StoredNode prev = (StoredNode) ref.getPreviousSibling();\n                result = appendChild(null, ref.getGID(), new NodeImplRef(getLastNode(prev)), getPath(), newChild, false);\n            }\n            getBroker().update(null, this);\n            getBroker().reindex(null, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n            getBroker().storeDocument(null, ((DocumentImpl)getOwnerDocument()));\n            transact.commit(transaction);\n            return result;\n        } catch(TransactionException e) {\n            //TODO : rollback ? -pb\n            throw new DOMException(DOMException.NO_MODIFICATION_ALLOWED_ERR, e.getMessage());\n        }\n    }","id":14458,"modified_method":"/**\n     * @see org.w3c.dom.Node#insertBefore(org.w3c.dom.Node, org.w3c.dom.Node)\n     */\n    public Node insertBefore(Node newChild, Node refChild) throws DOMException {\n        if (refChild == null)\n            return appendChild(newChild);\n        if (!(refChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\"); \n        final StoredNode ref = (StoredNode) refChild;\n        final long first = firstChildID();\n        if (ref.getGID() < first || ref.getGID() > ref.getGID() + children - 1)\n            throw new DOMException(DOMException.HIERARCHY_REQUEST_ERR,\n                    \"reference node is not a child of the selected node\");\n        Node result;\n        try {\n            TransactionManager transact = getBroker().getBrokerPool().getTransactionManager();\n            Txn transaction = transact.beginTransaction();\n            if (ref.getGID() == first)\n                result = appendChild(null, first, new NodeImplRef(this), getPath(), newChild, false);\n            else {\n                StoredNode prev = (StoredNode) ref.getPreviousSibling();\n                result = appendChild(null, ref.getGID(), new NodeImplRef(getLastNode(prev)), getPath(), newChild, false);\n            }\n            getBroker().update(null, this);\n            final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n            getBroker().reindex(null, owner, owner, null);\n            getBroker().storeDocument(null, owner);\n            transact.commit(transaction);\n            return result;\n        } catch(TransactionException e) {\n            //TODO : rollback ? -pb\n            throw new DOMException(DOMException.NO_MODIFICATION_ALLOWED_ERR, e.getMessage());\n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * @see org.w3c.dom.Node#removeChild(org.w3c.dom.Node)\n     */\n    public Node removeChild(Txn transaction, Node oldChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        StoredNode old = (StoredNode) oldChild;\n        if (old.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");\n        final int level = ((DocumentImpl)getOwnerDocument()).getTreeLevel(getGID());        \n        final long lastChild = lastChildID();\n        getBroker().removeAll(transaction, old, old.getPath());\n        --children;\n        getBroker().endRemove();\n        getBroker().update(transaction, this);\n        if (old.getGID() < lastChild) {\n            ((DocumentImpl)getOwnerDocument()).getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), this);\n        }\n        return old;\n    }","id":14459,"modified_method":"/**\n     * @see org.w3c.dom.Node#removeChild(org.w3c.dom.Node)\n     */\n    public Node removeChild(Txn transaction, Node oldChild) throws DOMException {\n        if (!(oldChild instanceof StoredNode))\n            throw new DOMException(DOMException.WRONG_DOCUMENT_ERR, \"wrong node type\");\n        final StoredNode oldNode = (StoredNode) oldChild;\n        if (oldNode.getParentGID() != getGID())\n            throw new DOMException(DOMException.NOT_FOUND_ERR,\n                    \"node is not a child of this element\");\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        final int level = owner.getTreeLevel(getGID());        \n        final long lastChild = lastChildID();\n        getBroker().removeAll(transaction, oldNode, oldNode.getPath());\n        --children;\n        getBroker().endRemove();\n        getBroker().update(transaction, this);\n        if (oldNode.getGID() < lastChild) {\n            owner.getMetadata().setReindexRequired(level + 1);\n            getBroker().reindex(transaction, owner, owner, this);\n        }\n        return oldNode;\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * @see org.w3c.dom.Node#getChildNodes()\n     */\n    public NodeList getChildNodes() {\n        if (children == 0)\n            return new NodeListImpl();\n        long first = firstChildID();\n        if (children == 1) {\n            NodeListImpl childList = new NodeListImpl(1);\n            childList.add(((DocumentImpl)getOwnerDocument()).getNode(first));\n            return childList;\n        }\n        NodeList result = ((DocumentImpl)getOwnerDocument()).getRange(first, first + children - 1);\n        return result;\n    }","id":14460,"modified_method":"/**\n     * @see org.w3c.dom.Node#getChildNodes()\n     */\n    public NodeList getChildNodes() {\n        if (children == 0)\n            return new NodeListImpl();\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        long first = firstChildID();\n        if (children == 1) {\n            NodeListImpl childList = new NodeListImpl(1);\n            childList.add(owner.getNode(first));\n            return childList;\n        }\n        NodeList result = owner.getRange(first, first + children - 1);\n        return result;\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"public void appendChildren(Txn transaction, NodeList nodes, int child) throws DOMException {\n    \t// attributes are handled differently. Call checkForAttributes to extract them.\n        nodes = checkForAttributes(transaction, nodes);\n        if (nodes == null || nodes.getLength() == 0) \n            return;       \n        if (children == 0) {\n            // no children: append a new child\n            appendChildren(transaction, firstChildID(), new NodeImplRef(this), getPath(), nodes, true);\n        }\n        else {\n            if (child == 1) {\n                Node firstChild = getFirstChild();\n                insertBefore(transaction, nodes, firstChild);\n            }\n            else {\n                StoredNode prevNode;\n                long pos = firstChildID();\n                if (child > 0 && child <= children) {\n                    pos = firstChildID() + child - 2;\n                    prevNode = getLastNode((StoredNode) ((DocumentImpl)getOwnerDocument()).getNode(pos));\n                    insertAfter(transaction, nodes, prevNode);\n                } else {\n                    prevNode = getLastNode((StoredNode) ((DocumentImpl)getOwnerDocument()).getNode(lastChildID()));\n                    appendChildren(transaction, lastChildID() + 1, new NodeImplRef(prevNode), getPath(), nodes, true);\n                }\n            }\n        }\n        getBroker().update(transaction, this);\n        getBroker().reindex(transaction, (DocumentImpl)getOwnerDocument(), ((DocumentImpl)getOwnerDocument()), null);\n    }","id":14461,"modified_method":"public void appendChildren(Txn transaction, NodeList nodes, int child) throws DOMException {\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        // attributes are handled differently. Call checkForAttributes to extract them.\n        nodes = checkForAttributes(transaction, nodes);\n        if (nodes == null || nodes.getLength() == 0) \n            return;       \n        if (children == 0) {\n            // no children: append a new child\n            appendChildren(transaction, firstChildID(), new NodeImplRef(this), getPath(), nodes, true);\n        }\n        else {\n            if (child == 1) {\n                Node firstChild = getFirstChild();\n                insertBefore(transaction, nodes, firstChild);\n            }\n            else {\n                StoredNode prevNode;\n                long pos = firstChildID();\n                if (child > 0 && child <= children) {\n                    pos = firstChildID() + child - 2;\n                    prevNode = getLastNode((StoredNode) owner.getNode(pos));\n                    insertAfter(transaction, nodes, prevNode);\n                } else {\n                    prevNode = getLastNode((StoredNode) owner.getNode(lastChildID()));\n                    appendChildren(transaction, lastChildID() + 1, new NodeImplRef(prevNode), getPath(), nodes, true);\n                }\n            }\n        }\n        getBroker().update(transaction, this);\n        getBroker().reindex(transaction, owner, owner, null);\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * @see org.w3c.dom.Node#appendChild(org.w3c.dom.Node)\n     */\n    public Node appendChild(Node child) throws DOMException {\n        DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        long childGid;\n        NodeImplRef last = new NodeImplRef();\n        if (children == 0) {\n            childGid = firstChildID();\n            last.setNode(this);            \n        } else {\n            childGid = lastChildID() + 1;\n            last.setNode(getLastNode((StoredNode) owner.getNode(childGid - 1))); \n        }        \n        TransactionManager transact = getBroker().getBrokerPool().getTransactionManager();\n        Txn transaction = transact.beginTransaction();\n        try {\n            checkTree(1);\n            children++;\n            Node node = appendChild(transaction, childGid, last, getPath(), child, true);\n            getBroker().update(transaction, this);\n            getBroker().reindex(transaction, owner, owner, null);\n            getBroker().storeDocument(transaction, owner);\n            transact.commit(transaction);\n            return node;\n        } catch (EXistException e) {\n            transact.abort(transaction);\n            throw new DOMException(DOMException.INVALID_STATE_ERR, e.getMessage()); \n        }\n    }","id":14462,"modified_method":"/**\n     * @see org.w3c.dom.Node#appendChild(org.w3c.dom.Node)\n     */\n    public Node appendChild(Node child) throws DOMException {\n        final DocumentImpl owner = (DocumentImpl)getOwnerDocument();\n        long childGid;\n        NodeImplRef last = new NodeImplRef();\n        if (children == 0) {\n            childGid = firstChildID();\n            last.setNode(this);            \n        } else {\n            childGid = lastChildID() + 1;\n            last.setNode(getLastNode((StoredNode) owner.getNode(childGid - 1))); \n        }        \n        TransactionManager transact = getBroker().getBrokerPool().getTransactionManager();\n        Txn transaction = transact.beginTransaction();\n        try {\n            checkTree(1);\n            children++;\n            Node node = appendChild(transaction, childGid, last, getPath(), child, true);\n            getBroker().update(transaction, this);\n            getBroker().reindex(transaction, owner, owner, null);\n            getBroker().storeDocument(transaction, owner);\n            transact.commit(transaction);\n            return node;\n        } catch (EXistException e) {\n            transact.abort(transaction);\n            throw new DOMException(DOMException.INVALID_STATE_ERR, e.getMessage()); \n        }\n    }","commit_id":"25d86fd5015d9f1801124e2425018bc9126ac9d4","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n\t * Tells if the expression is an assert.fail statement\n\t */\n\tprivate boolean isAssertFailStatement(ASTStatementExpression expression) {\n\t\tif (expression!= null && expression.jjtGetNumChildren()>0 &&\n\t\t\t(expression.jjtGetChild(0) instanceof ASTPrimaryExpression)) {\n\n\t\t\tASTPrimaryExpression astPrimaryExpression =\n\t\t\t\t(ASTPrimaryExpression)expression.jjtGetChild(0);\n\n\t\t\tif (astPrimaryExpression.jjtGetNumChildren()> 0 &&\n\t\t\t\tastPrimaryExpression.jjtGetChild(0)\n\t\t\t\t\tinstanceof ASTPrimaryPrefix) {\n\n\t\t\t\tASTPrimaryPrefix pp =\n\t\t\t\t\t(ASTPrimaryPrefix)astPrimaryExpression.jjtGetChild(0);\n\n\t\t\t\tif (pp.jjtGetNumChildren()>0 &&\n\t\t\t\t\tpp.jjtGetChild(0) instanceof ASTName) {\n\n\t\t\t\t\tString img = ((ASTName)pp.jjtGetChild(0)).getImage();\n\n\t\t\t\t\tif ((img != null) &&\n\t\t\t\t\t\t(img.equals(\"fail\") || img.equals(\"Assert.fail\"))) {\n\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}","id":14463,"modified_method":"/**\n\t * Tells if the expression is an assert.fail statement\n\t */\n\tprivate boolean isAssertFailStatement(\n\t\tASTStatementExpression astStatementExpression) {\n\n\t\tif ((astStatementExpression == null) ||\n\t\t\t(astStatementExpression.jjtGetNumChildren() == 0)) {\n\n\t\t\treturn false;\n\t\t}\n\n\t\tNode node = astStatementExpression.jjtGetChild(0);\n\n\t\tif (!(node instanceof ASTPrimaryExpression)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tASTPrimaryExpression astPrimaryExpression = (ASTPrimaryExpression)node;\n\n\t\tif (astPrimaryExpression.jjtGetNumChildren() == 0) {\n\t\t\treturn false;\n\t\t}\n\n\t\tnode = astPrimaryExpression.jjtGetChild(0);\n\n\t\tif (!(node instanceof ASTPrimaryPrefix)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tASTPrimaryPrefix astPrimaryPrefix = (ASTPrimaryPrefix)node;\n\n\t\tif (astPrimaryPrefix.jjtGetNumChildren() == 0) {\n\t\t\treturn false;\n\t\t}\n\n\t\tnode = astPrimaryPrefix.jjtGetChild(0);\n\n\t\tif (!(node instanceof ASTName)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tASTName astName = (ASTName)node;\n\n\t\tString image = astName.getImage();\n\n\t\tif ((image != null) &&\n\t\t\t(image.equals(\"fail\") || image.equals(\"Assert.fail\"))) {\n\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}","commit_id":"a2c2fa08c9aaa66f8a6e3d5beead2529e93cdc41","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tpublic Object visit(ASTStatementExpression expression, Object data) {\n\t\tif (isAssertFailStatement(expression)) {\n\t\t\tASTTryStatement tryStatement = expression.getFirstParentOfType(\n\t\t\t\tASTTryStatement.class);\n\n\t\t\tif (tryStatement == null) {\n\t\t\t\taddViolation(data, expression);\n\n\t\t\t\treturn data;\n\t\t\t}\n\n\t\t\tASTCatchStatement catchStatement = expression.getFirstParentOfType(\n\t\t\t\tASTCatchStatement.class);\n\n\t\t\tif (catchStatement != null) {\n\t\t\t\taddViolation(data, expression);\n\n\t\t\t\treturn data;\n\t\t\t}\n\n\t\t\tASTBlock tryBlock = tryStatement.getFirstChildOfType(\n\t\t\t\tASTBlock.class);\n\n\t\t\tList<ASTStatementExpression> statementExpressions =\n\t\t\t\ttryBlock.findDescendantsOfType(ASTStatementExpression.class);\n\n\t\t\tASTStatementExpression lastStatementExpression =\n\t\t\t\tstatementExpressions.get(statementExpressions.size() - 1);\n\n\t\t\tif (!lastStatementExpression.equals(expression)) {\n\t\t\t\taddViolation(data, expression);\n\n\t\t\t\treturn data;\n\t\t\t}\n\t\t}\n\n\t\treturn data;\n\t}","id":14464,"modified_method":"@Override\n\tpublic Object visit(\n\t\tASTStatementExpression astStatementExpression, Object data) {\n\n\t\tif (!isAssertFailStatement(astStatementExpression)) {\n\t\t\treturn data;\n\t\t}\n\n\t\tASTTryStatement astTryStatement =\n\t\t\tastStatementExpression.getFirstParentOfType(ASTTryStatement.class);\n\n\t\tif (astTryStatement == null) {\n\t\t\taddViolation(data, astStatementExpression);\n\n\t\t\treturn data;\n\t\t}\n\n\t\tASTCatchStatement astCatchStatement =\n\t\t\tastStatementExpression.getFirstParentOfType(\n\t\t\t\tASTCatchStatement.class);\n\n\t\tif (astCatchStatement != null) {\n\t\t\taddViolation(data, astStatementExpression);\n\n\t\t\treturn data;\n\t\t}\n\n\t\tASTBlock astBlock = astTryStatement.getFirstChildOfType(ASTBlock.class);\n\n\t\tList<ASTStatementExpression> astStatementExpressions =\n\t\t\tastBlock.findDescendantsOfType(ASTStatementExpression.class);\n\n\t\tASTStatementExpression lastASTStatementExpression =\n\t\t\tastStatementExpressions.get(astStatementExpressions.size() - 1);\n\n\t\tif (!lastASTStatementExpression.equals(astStatementExpression)) {\n\t\t\taddViolation(data, astStatementExpression);\n\n\t\t\treturn data;\n\t\t}\n\n\t\treturn data;\n\t}","commit_id":"a2c2fa08c9aaa66f8a6e3d5beead2529e93cdc41","url":"https://github.com/liferay/liferay-portal"},{"original_method":"private static boolean properties_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"properties_1\")) return false;\n    int offset_ = builder_.getCurrentOffset();\n    while (true) {\n      if (!properties_1_0(builder_, level_ + 1)) break;\n      int next_offset_ = builder_.getCurrentOffset();\n      if (offset_ == next_offset_) {\n        empty_element_parsed_guard_(builder_, offset_, \"properties_1\");\n        break;\n      }\n      offset_ = next_offset_;\n    }\n    return true;\n  }","id":14465,"modified_method":"private static boolean properties_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"properties_1\")) return false;\n    int pos_ = current_position_(builder_);\n    while (true) {\n      if (!properties_1_0(builder_, level_ + 1)) break;\n      if (!empty_element_parsed_guard_(builder_, \"properties_1\", pos_)) break;\n      pos_ = current_position_(builder_);\n    }\n    return true;\n  }","commit_id":"7c4cfdd02a47138cc0391b4152b9b0f5321b7548","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static boolean array_elements_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"array_elements_1\")) return false;\n    int offset_ = builder_.getCurrentOffset();\n    while (true) {\n      if (!array_elements_1_0(builder_, level_ + 1)) break;\n      int next_offset_ = builder_.getCurrentOffset();\n      if (offset_ == next_offset_) {\n        empty_element_parsed_guard_(builder_, offset_, \"array_elements_1\");\n        break;\n      }\n      offset_ = next_offset_;\n    }\n    return true;\n  }","id":14466,"modified_method":"private static boolean array_elements_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"array_elements_1\")) return false;\n    int pos_ = current_position_(builder_);\n    while (true) {\n      if (!array_elements_1_0(builder_, level_ + 1)) break;\n      if (!empty_element_parsed_guard_(builder_, \"array_elements_1\", pos_)) break;\n      pos_ = current_position_(builder_);\n    }\n    return true;\n  }","commit_id":"7c4cfdd02a47138cc0391b4152b9b0f5321b7548","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"static boolean json(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"json\")) return false;\n    if (!nextTokenIs(builder_, L_BRACKET) && !nextTokenIs(builder_, L_CURLY)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = object(builder_, level_ + 1);\n    if (!result_) result_ = array(builder_, level_ + 1);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14467,"modified_method":"static boolean json(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"json\")) return false;\n    if (!nextTokenIs(builder_, \"\", L_BRACKET, L_CURLY)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = object(builder_, level_ + 1);\n    if (!result_) result_ = array(builder_, level_ + 1);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"7c4cfdd02a47138cc0391b4152b9b0f5321b7548","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean boolean_literal(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"boolean_literal\")) return false;\n    if (!nextTokenIs(builder_, FALSE) && !nextTokenIs(builder_, TRUE)\n        && replaceVariants(builder_, 2, \"<boolean literal>\")) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_, level_, _COLLAPSE_, \"<boolean literal>\");\n    result_ = consumeToken(builder_, TRUE);\n    if (!result_) result_ = consumeToken(builder_, FALSE);\n    exit_section_(builder_, level_, marker_, BOOLEAN_LITERAL, result_, false, null);\n    return result_;\n  }","id":14468,"modified_method":"public static boolean boolean_literal(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"boolean_literal\")) return false;\n    if (!nextTokenIs(builder_, \"<boolean literal>\", FALSE, TRUE)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_, level_, _COLLAPSE_, \"<boolean literal>\");\n    result_ = consumeToken(builder_, TRUE);\n    if (!result_) result_ = consumeToken(builder_, FALSE);\n    exit_section_(builder_, level_, marker_, BOOLEAN_LITERAL, result_, false, null);\n    return result_;\n  }","commit_id":"7c4cfdd02a47138cc0391b4152b9b0f5321b7548","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public ASTNode parse(IElementType root_, PsiBuilder builder_) {\n    int level_ = 0;\n    boolean result_;\n    builder_ = adapt_builder_(root_, builder_, this, EXTENDS_SETS_);\n    if (root_ == ARRAY) {\n      result_ = array(builder_, level_ + 1);\n    }\n    else if (root_ == BOOLEAN_LITERAL) {\n      result_ = boolean_literal(builder_, level_ + 1);\n    }\n    else if (root_ == LITERAL) {\n      result_ = literal(builder_, level_ + 1);\n    }\n    else if (root_ == NULL_LITERAL) {\n      result_ = null_literal(builder_, level_ + 1);\n    }\n    else if (root_ == NUMBER_LITERAL) {\n      result_ = number_literal(builder_, level_ + 1);\n    }\n    else if (root_ == OBJECT) {\n      result_ = object(builder_, level_ + 1);\n    }\n    else if (root_ == PROPERTY) {\n      result_ = property(builder_, level_ + 1);\n    }\n    else if (root_ == PROPERTY_NAME) {\n      result_ = property_name(builder_, level_ + 1);\n    }\n    else if (root_ == STRING_LITERAL) {\n      result_ = string_literal(builder_, level_ + 1);\n    }\n    else if (root_ == VALUE) {\n      result_ = value(builder_, level_ + 1);\n    }\n    else {\n      Marker marker_ = enter_section_(builder_, level_, _NONE_, null);\n      result_ = parse_root_(root_, builder_, level_);\n      exit_section_(builder_, level_, marker_, root_, result_, true, TOKEN_ADVANCER);\n    }\n    return builder_.getTreeBuilt();\n  }","id":14469,"modified_method":"public ASTNode parse(IElementType root_, PsiBuilder builder_) {\n    boolean result_;\n    builder_ = adapt_builder_(root_, builder_, this, EXTENDS_SETS_);\n    Marker marker_ = enter_section_(builder_, 0, _COLLAPSE_, null);\n    if (root_ == ARRAY) {\n      result_ = array(builder_, 0);\n    }\n    else if (root_ == BOOLEAN_LITERAL) {\n      result_ = boolean_literal(builder_, 0);\n    }\n    else if (root_ == LITERAL) {\n      result_ = literal(builder_, 0);\n    }\n    else if (root_ == NULL_LITERAL) {\n      result_ = null_literal(builder_, 0);\n    }\n    else if (root_ == NUMBER_LITERAL) {\n      result_ = number_literal(builder_, 0);\n    }\n    else if (root_ == OBJECT) {\n      result_ = object(builder_, 0);\n    }\n    else if (root_ == PROPERTY) {\n      result_ = property(builder_, 0);\n    }\n    else if (root_ == PROPERTY_NAME) {\n      result_ = property_name(builder_, 0);\n    }\n    else if (root_ == STRING_LITERAL) {\n      result_ = string_literal(builder_, 0);\n    }\n    else if (root_ == VALUE) {\n      result_ = value(builder_, 0);\n    }\n    else {\n      result_ = parse_root_(root_, builder_, 0);\n    }\n    exit_section_(builder_, 0, marker_, root_, result_, true, TRUE_CONDITION);\n    return builder_.getTreeBuilt();\n  }","commit_id":"7c4cfdd02a47138cc0391b4152b9b0f5321b7548","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"static boolean bitwiseOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"bitwiseOperations\")) return false;\n    if (!nextTokenIs(builder_, NEGATE) && !nextTokenIs(builder_, NOT)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, NEGATE);\n    if (!result_) result_ = consumeToken(builder_, NOT);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14470,"modified_method":"static boolean bitwiseOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"bitwiseOperations\")) return false;\n    if (!nextTokenIs(builder_, \"\", NEGATE, NOT)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, NEGATE);\n    if (!result_) result_ = consumeToken(builder_, NOT);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"private static boolean expressionSequenceRequired_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"expressionSequenceRequired_1\")) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = expressionSequenceRequired_1_0(builder_, level_ + 1);\n    int offset_ = builder_.getCurrentOffset();\n    while (result_) {\n      if (!expressionSequenceRequired_1_0(builder_, level_ + 1)) break;\n      int next_offset_ = builder_.getCurrentOffset();\n      if (offset_ == next_offset_) {\n        empty_element_parsed_guard_(builder_, offset_, \"expressionSequenceRequired_1\");\n        break;\n      }\n      offset_ = next_offset_;\n    }\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14471,"modified_method":"private static boolean expressionSequenceRequired_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"expressionSequenceRequired_1\")) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = expressionSequenceRequired_1_0(builder_, level_ + 1);\n    int pos_ = current_position_(builder_);\n    while (result_) {\n      if (!expressionSequenceRequired_1_0(builder_, level_ + 1)) break;\n      if (!empty_element_parsed_guard_(builder_, \"expressionSequenceRequired_1\", pos_)) break;\n      pos_ = current_position_(builder_);\n    }\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"static boolean setOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"setOperations\")) return false;\n    if (!nextTokenIs(builder_, IN_KEYWORD) && !nextTokenIs(builder_, NOT_IN_KEYWORD)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, NOT_IN_KEYWORD);\n    if (!result_) result_ = consumeToken(builder_, IN_KEYWORD);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14472,"modified_method":"static boolean setOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"setOperations\")) return false;\n    if (!nextTokenIs(builder_, \"\", IN_KEYWORD, NOT_IN_KEYWORD)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, NOT_IN_KEYWORD);\n    if (!result_) result_ = consumeToken(builder_, IN_KEYWORD);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"public ASTNode parse(IElementType root_, PsiBuilder builder_) {\n    int level_ = 0;\n    boolean result_;\n    builder_ = adapt_builder_(root_, builder_, this, EXTENDS_SETS_);\n    if (root_ == BINARY_EXPRESSION) {\n      result_ = expression(builder_, level_ + 1, 3);\n    }\n    else if (root_ == CONDITIONAL_EXPRESSION) {\n      result_ = expression(builder_, level_ + 1, 2);\n    }\n    else if (root_ == EXPRESSION) {\n      result_ = expression(builder_, level_ + 1, -1);\n    }\n    else if (root_ == INDEXED_EXPRESSION) {\n      result_ = indexedExpression(builder_, level_ + 1);\n    }\n    else if (root_ == LITERAL_EXPRESSION) {\n      result_ = literalExpression(builder_, level_ + 1);\n    }\n    else if (root_ == METHOD_CALL_EXPRESSION) {\n      result_ = methodCallExpression(builder_, level_ + 1);\n    }\n    else if (root_ == NEW_EXPRESSION) {\n      result_ = newExpression(builder_, level_ + 1);\n    }\n    else if (root_ == PARENTHESIZED_EXPRESSION) {\n      result_ = parenthesizedExpression(builder_, level_ + 1);\n    }\n    else if (root_ == REFERENCE_EXPRESSION) {\n      result_ = referenceExpression(builder_, level_ + 1);\n    }\n    else if (root_ == SEQUENCE_EXPRESSION) {\n      result_ = sequenceExpression(builder_, level_ + 1);\n    }\n    else if (root_ == UNARY_EXPRESSION) {\n      result_ = unaryExpression(builder_, level_ + 1);\n    }\n    else if (root_ == VARIABLE_ASSIGNMENT_EXPRESSION) {\n      result_ = variableAssignmentExpression(builder_, level_ + 1);\n    }\n    else if (root_ == VARIABLE_EXPRESSION) {\n      result_ = variableExpression(builder_, level_ + 1);\n    }\n    else {\n      Marker marker_ = enter_section_(builder_, level_, _NONE_, null);\n      result_ = parse_root_(root_, builder_, level_);\n      exit_section_(builder_, level_, marker_, root_, result_, true, TOKEN_ADVANCER);\n    }\n    return builder_.getTreeBuilt();\n  }","id":14473,"modified_method":"public ASTNode parse(IElementType root_, PsiBuilder builder_) {\n    boolean result_;\n    builder_ = adapt_builder_(root_, builder_, this, EXTENDS_SETS_);\n    Marker marker_ = enter_section_(builder_, 0, _COLLAPSE_, null);\n    if (root_ == BINARY_EXPRESSION) {\n      result_ = expression(builder_, 0, 3);\n    }\n    else if (root_ == CONDITIONAL_EXPRESSION) {\n      result_ = expression(builder_, 0, 2);\n    }\n    else if (root_ == EXPRESSION) {\n      result_ = expression(builder_, 0, -1);\n    }\n    else if (root_ == INDEXED_EXPRESSION) {\n      result_ = indexedExpression(builder_, 0);\n    }\n    else if (root_ == LITERAL_EXPRESSION) {\n      result_ = literalExpression(builder_, 0);\n    }\n    else if (root_ == METHOD_CALL_EXPRESSION) {\n      result_ = methodCallExpression(builder_, 0);\n    }\n    else if (root_ == NEW_EXPRESSION) {\n      result_ = newExpression(builder_, 0);\n    }\n    else if (root_ == PARENTHESIZED_EXPRESSION) {\n      result_ = parenthesizedExpression(builder_, 0);\n    }\n    else if (root_ == REFERENCE_EXPRESSION) {\n      result_ = referenceExpression(builder_, 0);\n    }\n    else if (root_ == SEQUENCE_EXPRESSION) {\n      result_ = sequenceExpression(builder_, 0);\n    }\n    else if (root_ == UNARY_EXPRESSION) {\n      result_ = unaryExpression(builder_, 0);\n    }\n    else if (root_ == VARIABLE_ASSIGNMENT_EXPRESSION) {\n      result_ = variableAssignmentExpression(builder_, 0);\n    }\n    else if (root_ == VARIABLE_EXPRESSION) {\n      result_ = variableExpression(builder_, 0);\n    }\n    else {\n      result_ = parse_root_(root_, builder_, 0);\n    }\n    exit_section_(builder_, 0, marker_, root_, result_, true, TRUE_CONDITION);\n    return builder_.getTreeBuilt();\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"private static boolean methodCallParameters_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"methodCallParameters_1\")) return false;\n    int offset_ = builder_.getCurrentOffset();\n    while (true) {\n      if (!methodCallParameters_1_0(builder_, level_ + 1)) break;\n      int next_offset_ = builder_.getCurrentOffset();\n      if (offset_ == next_offset_) {\n        empty_element_parsed_guard_(builder_, offset_, \"methodCallParameters_1\");\n        break;\n      }\n      offset_ = next_offset_;\n    }\n    return true;\n  }","id":14474,"modified_method":"private static boolean methodCallParameters_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"methodCallParameters_1\")) return false;\n    int pos_ = current_position_(builder_);\n    while (true) {\n      if (!methodCallParameters_1_0(builder_, level_ + 1)) break;\n      if (!empty_element_parsed_guard_(builder_, \"methodCallParameters_1\", pos_)) break;\n      pos_ = current_position_(builder_);\n    }\n    return true;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"static boolean plusMinusOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"plusMinusOperations\")) return false;\n    if (!nextTokenIs(builder_, PLUS) && !nextTokenIs(builder_, MINUS)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, PLUS);\n    if (!result_) result_ = consumeToken(builder_, MINUS);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14475,"modified_method":"static boolean plusMinusOperations(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"plusMinusOperations\")) return false;\n    if (!nextTokenIs(builder_, \"\", PLUS, MINUS)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, PLUS);\n    if (!result_) result_ = consumeToken(builder_, MINUS);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"private static boolean referenceExpression_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"referenceExpression_1\")) return false;\n    int offset_ = builder_.getCurrentOffset();\n    while (true) {\n      if (!referenceExpression_1_0(builder_, level_ + 1)) break;\n      int next_offset_ = builder_.getCurrentOffset();\n      if (offset_ == next_offset_) {\n        empty_element_parsed_guard_(builder_, offset_, \"referenceExpression_1\");\n        break;\n      }\n      offset_ = next_offset_;\n    }\n    return true;\n  }","id":14476,"modified_method":"private static boolean referenceExpression_1(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"referenceExpression_1\")) return false;\n    int pos_ = current_position_(builder_);\n    while (true) {\n      if (!referenceExpression_1_0(builder_, level_ + 1)) break;\n      if (!empty_element_parsed_guard_(builder_, \"referenceExpression_1\", pos_)) break;\n      pos_ = current_position_(builder_);\n    }\n    return true;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"static boolean booleanLiteralExpression(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"booleanLiteralExpression\")) return false;\n    if (!nextTokenIs(builder_, FALSE_KEYWORD) && !nextTokenIs(builder_, TRUE_KEYWORD)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, TRUE_KEYWORD);\n    if (!result_) result_ = consumeToken(builder_, FALSE_KEYWORD);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14477,"modified_method":"static boolean booleanLiteralExpression(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"booleanLiteralExpression\")) return false;\n    if (!nextTokenIs(builder_, \"\", FALSE_KEYWORD, TRUE_KEYWORD)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, TRUE_KEYWORD);\n    if (!result_) result_ = consumeToken(builder_, FALSE_KEYWORD);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"static boolean textLiteralExpression(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"textLiteralExpression\")) return false;\n    if (!nextTokenIs(builder_, CHARACTER_LITERAL) && !nextTokenIs(builder_, STRING_LITERAL)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, STRING_LITERAL);\n    if (!result_) result_ = consumeToken(builder_, CHARACTER_LITERAL);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","id":14478,"modified_method":"static boolean textLiteralExpression(PsiBuilder builder_, int level_) {\n    if (!recursion_guard_(builder_, level_, \"textLiteralExpression\")) return false;\n    if (!nextTokenIs(builder_, \"\", CHARACTER_LITERAL, STRING_LITERAL)) return false;\n    boolean result_ = false;\n    Marker marker_ = enter_section_(builder_);\n    result_ = consumeToken(builder_, STRING_LITERAL);\n    if (!result_) result_ = consumeToken(builder_, CHARACTER_LITERAL);\n    exit_section_(builder_, marker_, null, result_);\n    return result_;\n  }","commit_id":"dbe3d7892ee86ee369de20b8e6fab65eadec650c","url":"https://github.com/JetBrains/intellij-plugins"},{"original_method":"/**\n     * Handle GET request. In the simplest case just returns the document or\n     * binary resource specified in the path. If the path leads to a collection,\n     * a listing of the collection contents is returned. If it resolves to a binary\n     * resource with mime-type \"application/xquery\", this resource will be\n     * loaded and executed by the XQuery engine.\n     *\n     * The method also recognizes a number of predefined parameters:\n     *\n     * <ul>\n     * <li>_xpath or _query: if specified, the given query is executed on the\n     * current resource or collection.<\/li>\n     *\n     * <li>_howmany: defines how many items from the query result will be\n     * returned.<\/li>\n     *\n     * <li>_start: a start offset into the result set.<\/li>\n     *\n     * <li>_wrap: if set to \"yes\", the query results will be wrapped into a\n     * exist:result element.<\/li>\n     *\n     * <li>_indent: if set to \"yes\", the returned XML will be pretty-printed.\n     * <\/li>\n     *\n     * <li>_source: if set to \"yes\" and a resource with mime-type \"application/xquery\" is requested\n     * then the xquery will not be executed, instead the source of the document will be returned.\n     * Must be enabled in descriptor.xml with the following syntax \n     * <xquery-app><allow-source><xquery path=\"/db/mycollection/myquery.xql\"/><\/allow-source><\/xquery-app>\n     * <\/li>\n     * \n     * <li>_xsl: an URI pointing to an XSL stylesheet that will be applied to\n     * the returned XML.<\/li>\n     *\n     * @param broker\n     * @param request\n     * @param response\n     * @param path\n     * @throws BadRequestException\n     * @throws PermissionDeniedException\n     * @throws NotFoundException\n     */\n    public void doGet(DBBroker broker, HttpServletRequest request, HttpServletResponse response, String path)\n    throws BadRequestException, PermissionDeniedException,\n            NotFoundException, IOException {\n    \t\n    \t//if required, set character encoding\n    \tif (request.getCharacterEncoding() == null)\n\t\t\trequest.setCharacterEncoding(formEncoding);\n    \t\n        // Process special parameters\n        \n        int howmany = 10;\n        int start = 1;\n        boolean wrap = true;\n        boolean source = false;\n        Properties outputProperties = new Properties();\n        String query = request.getParameter(\"_xpath\");\n        if (query == null)\n            query = request.getParameter(\"_query\");\n        \n        String p_howmany = request.getParameter(\"_howmany\");\n        if (p_howmany != null) {\n            try {\n                howmany = Integer.parseInt(p_howmany);\n            } catch (NumberFormatException nfe) {\n                throw new BadRequestException(\n                        \"Parameter _howmany should be an int\");\n            }\n        }\n        String p_start = request.getParameter(\"_start\");\n        if (p_start != null) {\n            try {\n                start = Integer.parseInt(p_start);\n            } catch (NumberFormatException nfe) {\n                throw new BadRequestException(\n                        \"Parameter _start should be an int\");\n            }\n        }\n        String option;\n        if ((option = request.getParameter(\"_wrap\")) != null)\n            wrap = option.equals(\"yes\");\n        if ((option = request.getParameter(\"_indent\")) != null)\n            outputProperties.setProperty(OutputKeys.INDENT, option);\n        if((option = request.getParameter(\"_source\")) != null)\n        \tsource = option.equals(\"yes\");\n        String stylesheet;\n        if ((stylesheet = request.getParameter(\"_xsl\")) != null) {\n            if (stylesheet.equals(\"no\")) {\n                outputProperties.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"no\");\n                outputProperties.remove(EXistOutputKeys.STYLESHEET);\n                stylesheet = null;\n            } else\n                outputProperties.setProperty(EXistOutputKeys.STYLESHEET,\n                        stylesheet);\n        } else\n            outputProperties.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"yes\");\n        LOG.debug(\"stylesheet = \" + stylesheet);\n        LOG.debug(\"query = \" + query);\n        String encoding;\n        if ((encoding = request.getParameter(\"_encoding\")) != null)\n            outputProperties.setProperty(OutputKeys.ENCODING, encoding);\n        else\n            encoding = \"UTF-8\";\n        \n        // Process the request\n        DocumentImpl resource = null;\n        XmldbURI pathUri = XmldbURI.create(path);\n        try {\n            // check if path leads to an XQuery resource\n            resource = broker.getXMLResource(pathUri, Lock.READ_LOCK);\n            if (resource != null)\n            {\n                if (resource.getResourceType() == DocumentImpl.BINARY_FILE && \"application/xquery\".equals(resource.getMetadata().getMimeType()))\n                {\n                \t// found an XQuery resource\n                    \n                \t//Should we display the source of the XQuery or execute it\n                \tDescriptor descriptor = Descriptor.getDescriptorSingleton();\n                \tif(source && descriptor != null)\n                \t{\n                \t\t//show the source\n                \t\t\n                \t\t//check are we allowed to show the xquery source - descriptor.xml\n                \t\tif(descriptor.allowSourceXQuery(path))\n                \t\t{\n                \t\t\t//TODO: change writeResourceAs to use a serializer that will serialize xquery to syntax coloured xhtml, replace the asMimeType parameter with a method for specifying the serializer, or split the code into two methods. - deliriumsky\n                \t\t\t\n                \t\t\t//Show the source of the XQuery\n                \t\t\twriteResourceAs(resource, broker, stylesheet, encoding, \"text/plain\", outputProperties, response);\n                \t\t}\n                \t\telse\n                \t\t{\n                \t\t\t//we are not allowed to show the source - query not allowed in descriptor.xml\n                            response.sendError(HttpServletResponse.SC_FORBIDDEN, \"Permission to view XQuery source for: \" + path + \" denied. Must be explicitly defined in descriptor.xml\");\n                \t\t\treturn;\n                \t\t}\n                \t}\n                \telse\n            \t\t{\n            \t\t\t//Execute the XQuery\n            \t\t\ttry\n\t\t\t\t\t\t{\n                            String result = executeXQuery(broker, resource, request, response, outputProperties);\n                            encoding = outputProperties.getProperty(OutputKeys.ENCODING, encoding);\n                            \n                        \t//only write the response if it is not already committed,\n                        \t//some xquery functions can write directly to the response\n                            if(!response.isCommitted())\n                            {\n                                String mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE, \"text/html\");\n                            \t\n                            \twriteResponse(response, result, mimeType, encoding);\n                            }\n                        }\n            \t\t\tcatch (XPathException e)\n\t\t\t\t\t\t{\n                            response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n                            writeResponse(response, formatXPathException(query, path, e), \"text/html\", encoding);\n                        }\n            \t\t}\n                    return;\n                }\n            }\n            if (query != null) {\n                // query parameter specified\n                try {\n                    String result = search(broker, query, path, howmany, start, outputProperties, wrap, request, response);\n                    encoding = outputProperties.getProperty(OutputKeys.ENCODING, encoding);\n                    \n                \t//only write the response if it is not already committed,\n                \t//some xquery functions can write directly to the response\n                    if(!response.isCommitted())\n                    {\n                    \tString mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE, \"text/html\");\n                    \twriteResponse(response, result, mimeType, encoding);\n                    }\n                    \n                } catch (XPathException e) {\n                    response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n                    writeResponse(response, formatXPathException(query, path, e), \"text/html\", encoding);\n                }\n            } else {\n                // no query parameter: try to load a document from the specified\n                // path\n                if (resource == null) {\n                    // no document: check if path points to a collection\n                    Collection collection = broker.getCollection(pathUri);\n                    if (collection != null) {\n                        if (!collection.getPermissions().validate(\n                                broker.getUser(), Permission.READ))\n                            throw new PermissionDeniedException(\n                                    \"Not allowed to read collection\");\n                        // return a listing of the collection contents\n                        writeResponse(response, printCollection(broker, collection), MimeType.XML_TYPE.getName(), encoding);\n                    } else {\n                        throw new NotFoundException(\"Document \" + path\n                                + \" not found\");\n                    }\n                } else {\n                    // document found: serialize it\n                    writeResourceAs(resource, broker, stylesheet, encoding, null, outputProperties, response);\n                }\n            }\n        } finally {\n            if (resource != null)\n                resource.getUpdateLock().release(Lock.READ_LOCK);\n        }\n    }","id":14479,"modified_method":"/**\n     * Handle GET request. In the simplest case just returns the document or\n     * binary resource specified in the path. If the path leads to a collection,\n     * a listing of the collection contents is returned. If it resolves to a binary\n     * resource with mime-type \"application/xquery\", this resource will be\n     * loaded and executed by the XQuery engine.\n     *\n     * The method also recognizes a number of predefined parameters:\n     *\n     * <ul>\n     * <li>_xpath or _query: if specified, the given query is executed on the\n     * current resource or collection.<\/li>\n     *\n     * <li>_howmany: defines how many items from the query result will be\n     * returned.<\/li>\n     *\n     * <li>_start: a start offset into the result set.<\/li>\n     *\n     * <li>_wrap: if set to \"yes\", the query results will be wrapped into a\n     * exist:result element.<\/li>\n     *\n     * <li>_indent: if set to \"yes\", the returned XML will be pretty-printed.\n     * <\/li>\n     *\n     * <li>_source: if set to \"yes\" and a resource with mime-type \"application/xquery\" is requested\n     * then the xquery will not be executed, instead the source of the document will be returned.\n     * Must be enabled in descriptor.xml with the following syntax \n     * <xquery-app><allow-source><xquery path=\"/db/mycollection/myquery.xql\"/><\/allow-source><\/xquery-app>\n     * <\/li>\n     * \n     * <li>_xsl: an URI pointing to an XSL stylesheet that will be applied to\n     * the returned XML.<\/li>\n     *\n     * @param broker\n     * @param request\n     * @param response\n     * @param path\n     * @throws BadRequestException\n     * @throws PermissionDeniedException\n     * @throws NotFoundException\n     */\n    public void doGet(DBBroker broker, HttpServletRequest request, HttpServletResponse response, String path)\n    throws BadRequestException, PermissionDeniedException,\n            NotFoundException, IOException {\n    \t\n    \t//if required, set character encoding\n    \tif (request.getCharacterEncoding() == null)\n\t\t\trequest.setCharacterEncoding(formEncoding);\n    \t\n        // Process special parameters\n        \n        int howmany = 10;\n        int start = 1;\n        boolean wrap = true;\n        boolean source = false;\n        Properties outputProperties = new Properties(defaultProperties);\n        String query = request.getParameter(\"_xpath\");\n        if (query == null)\n            query = request.getParameter(\"_query\");\n        \n        String p_howmany = request.getParameter(\"_howmany\");\n        if (p_howmany != null) {\n            try {\n                howmany = Integer.parseInt(p_howmany);\n            } catch (NumberFormatException nfe) {\n                throw new BadRequestException(\n                        \"Parameter _howmany should be an int\");\n            }\n        }\n        String p_start = request.getParameter(\"_start\");\n        if (p_start != null) {\n            try {\n                start = Integer.parseInt(p_start);\n            } catch (NumberFormatException nfe) {\n                throw new BadRequestException(\n                        \"Parameter _start should be an int\");\n            }\n        }\n        String option;\n        if ((option = request.getParameter(\"_wrap\")) != null) {\n            wrap = option.equals(\"yes\");\n\t}\n        if ((option = request.getParameter(\"_indent\")) != null) {\n            outputProperties.setProperty(OutputKeys.INDENT, option);\n\t}\n        if((option = request.getParameter(\"_source\")) != null) {\n        \tsource = option.equals(\"yes\");\n\t}\n        String stylesheet;\n        if ((stylesheet = request.getParameter(\"_xsl\")) != null) {\n            if (stylesheet.equals(\"no\")) {\n                outputProperties.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"no\");\n                outputProperties.remove(EXistOutputKeys.STYLESHEET);\n                stylesheet = null;\n            } else {\n                outputProperties.setProperty(EXistOutputKeys.STYLESHEET,\n                        stylesheet);\n\t    }\n        } else {\n            outputProperties.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"yes\");\n\t}\n        LOG.debug(\"stylesheet = \" + stylesheet);\n        LOG.debug(\"query = \" + query);\n        String encoding;\n        if ((encoding = request.getParameter(\"_encoding\")) != null)\n            outputProperties.setProperty(OutputKeys.ENCODING, encoding);\n        else\n            encoding = \"UTF-8\";\n\n\tString mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE);\n        \n        // Process the request\n        DocumentImpl resource = null;\n        XmldbURI pathUri = XmldbURI.create(path);\n        try {\n            // check if path leads to an XQuery resource\n            resource = broker.getXMLResource(pathUri, Lock.READ_LOCK);\n            if (resource != null) {\n                if (resource.getResourceType() == DocumentImpl.BINARY_FILE && MimeType.XQUERY_TYPE.getName().equals(resource.getMetadata().getMimeType())) {\n\t\t    // found an XQuery resource\n                    \n\t\t    //Should we display the source of the XQuery or execute it\n\t\t    Descriptor descriptor = Descriptor.getDescriptorSingleton();\n\t\t    if(source && descriptor != null) {\n\t\t\t//show the source\n\t\t\t\n\t\t\t//check are we allowed to show the xquery source - descriptor.xml\n\t\t\tif(descriptor.allowSourceXQuery(path)) {\n\t\t\t    //TODO: change writeResourceAs to use a serializer that will serialize xquery to syntax coloured xhtml, replace the asMimeType parameter with a method for specifying the serializer, or split the code into two methods. - deliriumsky\n\t\t\t    \n\t\t\t    //Show the source of the XQuery\n\t\t\t    writeResourceAs(resource, broker, stylesheet, encoding, MimeType.TEXT_TYPE.getName(), outputProperties, response);\n\t\t\t} else {\n\t\t\t    //we are not allowed to show the source - query not allowed in descriptor.xml\n                            response.sendError(HttpServletResponse.SC_FORBIDDEN, \"Permission to view XQuery source for: \" + path + \" denied. Must be explicitly defined in descriptor.xml\");\n\t\t\t    return;\n\t\t\t}\n\t\t    } else { //Execute the XQuery\n\t\t\ttry {\n                            String result = executeXQuery(broker, resource, request, response, outputProperties);\n                            encoding = outputProperties.getProperty(OutputKeys.ENCODING);\n\t\t\t    mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE);\n                            \n\t\t\t    //only write the response if it is not already committed,\n\t\t\t    //some xquery functions can write directly to the response\n                            if(!response.isCommitted()) {\n                           \twriteResponse(response, result, mimeType, encoding);\n                            }\n                        } catch (XPathException e) {\n                            response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n\t\t\t    if (MimeType.XML_TYPE.getName().equals(mimeType)) {\n\t\t\t\twriteResponse(response, formatXPathException(query, path, e), mimeType, encoding);\t\t\t\t\n\t\t\t    } else {\n\t\t\t\twriteResponse(response, formatXPathExceptionHtml(query, path, e), MimeType.HTML_TYPE.getName(), encoding);\n\t\t\t    }\n                        }\n\t\t    }\n                    return;\n                }\n            }\n            if (query != null) {\n                // query parameter specified\n                try {\n                    String result = search(broker, query, path, howmany, start, outputProperties, wrap, request, response);\n                    encoding = outputProperties.getProperty(OutputKeys.ENCODING);\n\t\t    mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE);\n                    \n                \t//only write the response if it is not already committed,\n                \t//some xquery functions can write directly to the response\n                    if(!response.isCommitted()) {\n                    \twriteResponse(response, result, mimeType, encoding);\n                    }\n                    \n                } catch (XPathException e) {\n                    response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n\t\t    if (MimeType.XML_TYPE.getName().equals(mimeType)) {\n\t\t\twriteResponse(response, formatXPathException(query, path, e), mimeType, encoding);\t\t\t\t\n\t\t    } else {\n                        writeResponse(response, formatXPathExceptionHtml(query, path, e), MimeType.HTML_TYPE.getName(), encoding);\n                    }\n\t       }\n            } else {\n                // no query parameter: try to load a document from the specified\n                // path\n                if (resource == null) {\n                    // no document: check if path points to a collection\n                    Collection collection = broker.getCollection(pathUri);\n                    if (collection != null) {\n                        if (!collection.getPermissions().validate(\n\t\t\t    broker.getUser(), Permission.READ))\n                            throw new PermissionDeniedException(\n                                    \"Not allowed to read collection\");\n                        // return a listing of the collection contents\n                        writeResponse(response, printCollection(broker, collection), MimeType.XML_TYPE.getName(), encoding);\n                    } else {\n                        throw new NotFoundException(\"Document \" + path\n                                + \" not found\");\n                    }\n                } else {\n                    // document found: serialize it\n                    writeResourceAs(resource, broker, stylesheet, encoding, null, outputProperties, response);\n                }\n            }\n        } finally {\n            if (resource != null)\n                resource.getUpdateLock().release(Lock.READ_LOCK);\n        }\n    }","commit_id":"9c060d23e86db9d1b1460e000e104dc6c8d4196f","url":"https://github.com/eXist-db/exist"},{"original_method":"private void writeResourceAs(DocumentImpl resource, DBBroker broker, String stylesheet, String encoding, String asMimeType, Properties outputProperties, HttpServletResponse response) throws BadRequestException, PermissionDeniedException, IOException\n    {\n    \t//Do we have permission to read the resource\n    \tif (!resource.getPermissions().validate(broker.getUser(), Permission.READ))\n    \t\tthrow new PermissionDeniedException(\"Not allowed to read resource\");\n    \t\n        if (resource.getResourceType() == DocumentImpl.BINARY_FILE)\n        {\n        \t// binary resource\n        \tif(asMimeType != null) //was a mime-type specified?\n        \t{\n        \t\tresponse.setContentType(asMimeType);\n        \t}\n        \telse\n        \t{\n        \t\tresponse.setContentType(resource.getMetadata().getMimeType());\n        \t}\n        \tOutputStream os = response.getOutputStream();\n        \tbroker.readBinaryResource((BinaryDocument) resource, os);\n        \tos.flush();\n        }\n        else\n        {\n            // xml resource\n            Serializer serializer = broker.getSerializer();\n            serializer.reset();\n            \n\n            //Serialize the document\n            try\n\t\t\t{\n                //use a stylesheet if specified in query parameters\n                if (stylesheet != null)\n                {\n                    serializer.setStylesheet(resource, stylesheet);\n                }\n                serializer.setProperties(outputProperties);\n                serializer.prepareStylesheets(resource);\n                if(asMimeType != null) //was a mime-type specified?\n                {\n                \tresponse.setContentType(asMimeType+\"; charset=\"+encoding);\n                }\n                else\n                {\n\t                if (serializer.isStylesheetApplied() || serializer.hasXSLPi(resource) != null)\n\t                {\n\t                \tasMimeType = serializer.getStylesheetProperty(OutputKeys.MEDIA_TYPE);\n\t                \tif (!useDynamicContentType || asMimeType == null)\n\t                \t\tasMimeType = \"text/html\";\n\t                \tLOG.debug(\"media-type: \" + asMimeType);\n\t                    response.setContentType(asMimeType + \"; charset=\"+encoding);\n\t                }\n\t                else\n\t                {\n\t                    response.setContentType(resource.getMetadata().getMimeType()+\"; charset=\"+encoding);\n\t                }\n                }\n                OutputStream is = response.getOutputStream();\n                Writer w = new OutputStreamWriter(is,encoding);\n                serializer.serialize(resource,w);\n                w.flush();\n                w.close();\n            }\n            catch (SAXException saxe)\n\t\t\t{\n                LOG.warn(saxe);\n                throw new BadRequestException(\"Error while serializing XML: \" + saxe.getMessage());\n            } catch (TransformerConfigurationException e) {\n                LOG.warn(e);\n                throw new BadRequestException(e.getMessageAndLocation());\n            }\n        }\n    }","id":14480,"modified_method":"private void writeResourceAs(DocumentImpl resource, DBBroker broker, String stylesheet, String encoding, String asMimeType, Properties outputProperties, HttpServletResponse response) throws BadRequestException, PermissionDeniedException, IOException {\n    \t//Do we have permission to read the resource\n    \tif (!resource.getPermissions().validate(broker.getUser(), Permission.READ)) {\n\t    throw new PermissionDeniedException(\"Not allowed to read resource\");\n\t}\n    \t\n        if (resource.getResourceType() == DocumentImpl.BINARY_FILE) {\n\t    // binary resource\n\t    if(asMimeType != null)  { //was a mime-type specified?\n\t\t\n\t\tresponse.setContentType(asMimeType);\n\t    } else {\n\t\tresponse.setContentType(resource.getMetadata().getMimeType());\n\t    }\n\t    OutputStream os = response.getOutputStream();\n\t    broker.readBinaryResource((BinaryDocument) resource, os);\n\t    os.flush();\n        } else {\n            // xml resource\n            Serializer serializer = broker.getSerializer();\n            serializer.reset();\n            \n\t    \n            //Serialize the document\n            try {\n                //use a stylesheet if specified in query parameters\n                if (stylesheet != null) {\n                    serializer.setStylesheet(resource, stylesheet);\n                }\n                serializer.setProperties(outputProperties);\n                serializer.prepareStylesheets(resource);\n                if(asMimeType != null) { //was a mime-type specified?\n\t\t    response.setContentType(asMimeType+\"; charset=\"+encoding);\n                } else {\n\t\t    if (serializer.isStylesheetApplied() || serializer.hasXSLPi(resource) != null) {\n\t\t\tasMimeType = serializer.getStylesheetProperty(OutputKeys.MEDIA_TYPE);\n\t\t\tif (!useDynamicContentType || asMimeType == null)\n\t\t\t    asMimeType = MimeType.HTML_TYPE.getName();\n\t\t\tLOG.debug(\"media-type: \" + asMimeType);\n\t\t\tresponse.setContentType(asMimeType + \"; charset=\"+encoding);\n\t\t    } else {\n\t\t\tresponse.setContentType(resource.getMetadata().getMimeType()+\"; charset=\"+encoding);\n\t\t    }\n                }\n                OutputStream is = response.getOutputStream();\n                Writer w = new OutputStreamWriter(is,encoding);\n                serializer.serialize(resource,w);\n                w.flush();\n                w.close();\n            } catch (SAXException saxe) {\n                LOG.warn(saxe);\n                throw new BadRequestException(\"Error while serializing XML: \" + saxe.getMessage());\n            } catch (TransformerConfigurationException e) {\n                LOG.warn(e);\n                throw new BadRequestException(e.getMessageAndLocation());\n            }\n        }\n    }","commit_id":"9c060d23e86db9d1b1460e000e104dc6c8d4196f","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * @param query\n     * @param e\n     */\n    private String formatXPathException(String query, String path, XPathException e) {\n        StringWriter writer = new StringWriter();\n        writer.write(QUERY_ERROR_HEAD);\n        writer.write(\"<p class=\\\"path\\\"><span class=\\\"high\\\">Path<\/span>: \");\n        writer.write(\"<a href=\\\"\");\n        writer.write(path);\n        writer.write(\"\\\">\");\n        writer.write(path);\n        writer.write(\"<\/a><\/p>\");\n        \n        writer.write(\"<p class=\\\"errmsg\\\">\");\n        writer.write(e.getMessage());\n        writer.write(\"<\/p>\");\n        if(query != null) {\n            writer.write(\"<p><span class=\\\"high\\\">Query<\/span>:<\/p><pre>\");\n            writer.write(query);\n            writer.write(\"<\/pre>\");\n        }\n        writer.write(\"<\/body><\/html>\");\n        return writer.toString();\n    }","id":14481,"modified_method":"/**\n     * @param query\n     * @param path\n     * @param e\n     */\n    private String formatXPathException(String query, String path, XPathException e) {\n        StringWriter writer = new StringWriter();\n        writer.write(\"<xml version=\\\"1.0\\\" />\");\n        writer.write(\"<exception><path>\");\n        writer.write(path);\n        writer.write(\"<\/path>\");\n        writer.write(\"<message>\");\n        writer.write(e.getMessage());\n        writer.write(\"<\/message>\");\n        if(query != null) {\n            writer.write(\"<query>\");\n            writer.write(query);\n            writer.write(\"<\/query>\");\n        }\n        writer.write(\"<\/exception>\");\n        return writer.toString();\n    }","commit_id":"9c060d23e86db9d1b1460e000e104dc6c8d4196f","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Handles POST requests. If the path leads to a binary resource with\n     * mime-type \"application/xquery\", that resource will be read and executed\n     * by the XQuery engine. Otherwise, the request content is loaded and parsed\n     * as XML. It may either contain an XUpdate or a query request.\n     *\n     * @param broker\n     * @param request\n     * @param response\n     * @param path\n     * @throws BadRequestException\n     * @throws PermissionDeniedException\n     */\n    public void doPost(DBBroker broker, HttpServletRequest request, HttpServletResponse response, String path) throws BadRequestException, PermissionDeniedException, IOException\n    {\t\n    \t//if required, set character encoding\n    \tif (request.getCharacterEncoding() == null)\n\t\t\trequest.setCharacterEncoding(formEncoding);\n    \n        Properties outputProperties = new Properties(defaultProperties);\n        XmldbURI pathUri = XmldbURI.create(path);\n        DocumentImpl resource = null;\n        try {\n            // check if path leads to an XQuery resource.\n            // if yes, the resource is loaded and the XQuery executed.\n            resource = broker.getXMLResource(pathUri, Lock.READ_LOCK);\n            if (resource != null) {\n                if (resource.getResourceType() == DocumentImpl.BINARY_FILE &&\n                        \"application/xquery\".equals(resource.getMetadata().getMimeType())) {\n                    // found an XQuery resource\n                    try {\n                        String result = executeXQuery(broker, resource, request, response, outputProperties);\n                        String encoding = outputProperties.getProperty(OutputKeys.ENCODING, \"UTF-8\");\n                        String mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE, \"text/html\");\n                        writeResponse(response, result, mimeType, encoding);\n                    } catch (XPathException e) {\n                        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n                        writeResponse(response, formatXPathException(null, path, e), \"text/html\", \"UTF-8\");\n                    }\n                    return;\n                }\n            }\n        } finally {\n            if(resource != null)\n                resource.getUpdateLock().release(Lock.READ_LOCK);\n        }\n        \n        // third, normal POST: read the request content and check if\n        // it is an XUpdate or a query request.        \n        int howmany = 10;\n        int start = 1;\n        boolean enclose = true;\n        String mime = MimeType.XML_TYPE.getName();\n        String query = null;\n        TransactionManager transact = broker.getBrokerPool().getTransactionManager();\n        Txn transaction = transact.beginTransaction();\n        try {\n            String content = getRequestContent(request);\n            InputSource src = new InputSource(new StringReader(content));\n            DocumentBuilderFactory docFactory = DocumentBuilderFactory\n                    .newInstance();\n            docFactory.setNamespaceAware(true);\n            DocumentBuilder docBuilder;\n            try {\n                docBuilder = docFactory.newDocumentBuilder();\n            } catch (ParserConfigurationException e) {\n                LOG.warn(e);\n                transact.abort(transaction);\n                throw new BadRequestException(e.getMessage());\n            }\n            Document doc = docBuilder.parse(src);\n            Element root = doc.getDocumentElement();\n            String rootNS = root.getNamespaceURI();\n            if (rootNS != null && rootNS.equals(Namespaces.EXIST_NS)) {\n                if (root.getLocalName().equals(\"query\")) {\n                    // process <query>xpathQuery<\/query>\n                    String option = root.getAttribute(\"start\");\n                    if (option != null)\n                        try {\n                            start = Integer.parseInt(option);\n                        } catch (NumberFormatException e) {\n                        }\n                    option = root.getAttribute(\"max\");\n                    if (option != null)\n                        try {\n                            howmany = Integer.parseInt(option);\n                        } catch (NumberFormatException e) {\n                        }\n                    \n                    option = root.getAttribute(\"enclose\");\n                    if (option != null) {\n                        if (option.equals(\"no\"))\n                            enclose = false;\n                    }\n                    \n                    option = root.getAttribute(\"mime\");\n                    mime = MimeType.XML_TYPE.getName();\n                    if ((option != null) && (!option.equals(\"\"))) {\n                        mime = option;\n                    }\n                    \n                    NodeList children = root.getChildNodes();\n                    for (int i = 0; i < children.getLength(); i++) {\n                        Node child = children.item(i);\n                        if (child.getNodeType() == Node.ELEMENT_NODE\n                                && child.getNamespaceURI().equals(Namespaces.EXIST_NS)) {\n                            if (child.getLocalName().equals(\"text\")) {\n                                StringBuffer buf = new StringBuffer();\n                                Node next = child.getFirstChild();\n                                while (next != null) {\n                                    if (next.getNodeType() == Node.TEXT_NODE\n                                            || next.getNodeType() == Node.CDATA_SECTION_NODE)\n                                        buf.append(next.getNodeValue());\n                                    next = next.getNextSibling();\n                                }\n                                query = buf.toString();\n                            } else if (child.getLocalName().equals(\"properties\")) {\n                                Node node = child.getFirstChild();\n                                while (node != null) {\n                                    if (node.getNodeType() == Node.ELEMENT_NODE\n                                            && node.getNamespaceURI().equals(Namespaces.EXIST_NS)\n                                            && node.getLocalName().equals(\"property\")) {\n                                        Element property = (Element) node;\n                                        String key = property\n                                                .getAttribute(\"name\");\n                                        String value = property\n                                                .getAttribute(\"value\");\n                                        LOG.debug(key + \" = \" + value);\n                                        if (key != null && value != null)\n                                            outputProperties.setProperty(key,\n                                                    value);\n                                    }\n                                    node = node.getNextSibling();\n                                }\n                            }\n                        }\n                    }\n                }\n                // execute query\n                if (query != null) {\n                    writeResponse(response, search(broker, query, path, howmany,\n                            start, outputProperties, enclose, request, response), mime,\n                            outputProperties.getProperty(OutputKeys.ENCODING, \"UTF-8\"));\n                } else {\n                    transact.abort(transaction);\n                    throw new BadRequestException(\"No query specified\");\n                }\n            } else if (rootNS != null && rootNS.equals(XUpdateProcessor.XUPDATE_NS)) {\n                LOG.debug(\"Got xupdate request: \" + content);\n                DocumentSet docs = new DocumentSet();\n                Collection collection = broker.getCollection(pathUri);\n                if (collection != null) {\n                    collection.allDocs(broker, docs, true, true);\n                } else {\n                    DocumentImpl xupdateDoc = (DocumentImpl) broker.getXMLResource(pathUri);\n                    if (xupdateDoc != null) {\n                        if (!xupdateDoc.getPermissions().validate(\n                                broker.getUser(), Permission.READ)) {\n                            transact.abort(transaction);\n                            throw new PermissionDeniedException(\n                                    \"Not allowed to read collection\");\n                        }\n                        docs.add(xupdateDoc);\n                    } else\n                        broker.getAllXMLResources(docs);\n                }\n                \n                XUpdateProcessor processor = new XUpdateProcessor(broker, docs, AccessContext.REST);\n                Modification modifications[] = processor.parse(new InputSource(\n                        new StringReader(content)));\n                long mods = 0;\n                for (int i = 0; i < modifications.length; i++) {\n                    mods += modifications[i].process(transaction);\n                    broker.flush();\n                }\n                transact.commit(transaction);\n                \n                // FD : Returns an XML doc\n                writeResponse(response,\n                        \"<?xml version='1.0'?>\\n\"\n                        + \"<exist:modifications xmlns:exist='\" + Namespaces.EXIST_NS\n                        + \"' count='\" + mods + \"'>\" + mods\n                        + \"modifications processed.<\/exist:modifications>\",\n                        MimeType.XML_TYPE.getName(), \"UTF-8\");\n                // END FD\n            } else {\n                transact.abort(transaction);\n                throw new BadRequestException(\"Unknown XML root element: \"\n                        + root.getNodeName());\n            }\n        } catch (SAXException e) {\n            transact.abort(transaction);\n            Exception cause = e;\n            if (e.getException() != null)\n                cause = e.getException();\n            LOG.debug(\"SAX exception while parsing request: \"\n                    + cause.getMessage(), cause);\n            throw new BadRequestException(\n                    \"SAX exception while parsing request: \"\n                    + cause.getMessage());\n        } catch (ParserConfigurationException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"Parser exception while parsing request: \" + e.getMessage());\n        } catch (XPathException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"Query exception while parsing request: \" + e.getMessage());\n        } catch (IOException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"IO exception while parsing request: \" + e.getMessage());\n        } catch (EXistException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(e.getMessage());\n        } catch (LockException e) {\n            transact.abort(transaction);\n            throw new PermissionDeniedException(e.getMessage());\n        }\n    }","id":14482,"modified_method":"/**\n     * Handles POST requests. If the path leads to a binary resource with\n     * mime-type \"application/xquery\", that resource will be read and executed\n     * by the XQuery engine. Otherwise, the request content is loaded and parsed\n     * as XML. It may either contain an XUpdate or a query request.\n     *\n     * @param broker\n     * @param request\n     * @param response\n     * @param path\n     * @throws BadRequestException\n     * @throws PermissionDeniedException\n     */\n    public void doPost(DBBroker broker, HttpServletRequest request, HttpServletResponse response, String path) throws BadRequestException, PermissionDeniedException, IOException\n    {\t\n    \t//if required, set character encoding\n    \tif (request.getCharacterEncoding() == null)\n\t\t\trequest.setCharacterEncoding(formEncoding);\n    \n        Properties outputProperties = new Properties(defaultProperties);\n        XmldbURI pathUri = XmldbURI.create(path);\n        DocumentImpl resource = null;\n\t\n\tString encoding = outputProperties.getProperty(OutputKeys.ENCODING);\n\tString mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE);\n        try {\n            // check if path leads to an XQuery resource.\n            // if yes, the resource is loaded and the XQuery executed.\n            resource = broker.getXMLResource(pathUri, Lock.READ_LOCK);\n            if (resource != null) {\n                if (resource.getResourceType() == DocumentImpl.BINARY_FILE &&\n\t\t    MimeType.XQUERY_TYPE.getName().equals(resource.getMetadata().getMimeType())) {\n                    // found an XQuery resource\n                    try {\n                        String result = executeXQuery(broker, resource, request, response, outputProperties);\n\t\t\tencoding = outputProperties.getProperty(OutputKeys.ENCODING);\n                        mimeType = outputProperties.getProperty(OutputKeys.MEDIA_TYPE);\n                        writeResponse(response, result, mimeType, encoding);\n                    } catch (XPathException e) {\n                        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n\t\t\tif (MimeType.XML_TYPE.getName().equals(mimeType)) {\n\t\t\t    writeResponse(response, formatXPathException(null, path, e), mimeType, encoding);\t\t\t\t\n\t\t\t} else {\n\t\t\t    writeResponse(response, formatXPathExceptionHtml(null, path, e), MimeType.HTML_TYPE.getName(), encoding);\n\t\t\t}\n                    }\n                    return;\n                }\n            }\n        } finally {\n            if(resource != null)\n                resource.getUpdateLock().release(Lock.READ_LOCK);\n        }\n        \n        // third, normal POST: read the request content and check if\n        // it is an XUpdate or a query request.        \n        int howmany = 10;\n        int start = 1;\n        boolean enclose = true;\n        String mime = MimeType.XML_TYPE.getName();\n        String query = null;\n        TransactionManager transact = broker.getBrokerPool().getTransactionManager();\n        Txn transaction = transact.beginTransaction();\n        try {\n            String content = getRequestContent(request);\n            InputSource src = new InputSource(new StringReader(content));\n            DocumentBuilderFactory docFactory = DocumentBuilderFactory\n                    .newInstance();\n            docFactory.setNamespaceAware(true);\n            DocumentBuilder docBuilder;\n            try {\n                docBuilder = docFactory.newDocumentBuilder();\n            } catch (ParserConfigurationException e) {\n                LOG.warn(e);\n                transact.abort(transaction);\n                throw new BadRequestException(e.getMessage());\n            }\n            Document doc = docBuilder.parse(src);\n            Element root = doc.getDocumentElement();\n            String rootNS = root.getNamespaceURI();\n            if (rootNS != null && rootNS.equals(Namespaces.EXIST_NS)) {\n                if (root.getLocalName().equals(\"query\")) {\n                    // process <query>xpathQuery<\/query>\n                    String option = root.getAttribute(\"start\");\n                    if (option != null)\n                        try {\n                            start = Integer.parseInt(option);\n                        } catch (NumberFormatException e) {\n                        }\n                    option = root.getAttribute(\"max\");\n                    if (option != null)\n                        try {\n                            howmany = Integer.parseInt(option);\n                        } catch (NumberFormatException e) {\n                        }\n                    \n                    option = root.getAttribute(\"enclose\");\n                    if (option != null) {\n                        if (option.equals(\"no\"))\n                            enclose = false;\n                    }\n                    \n                    option = root.getAttribute(\"mime\");\n                    mime = MimeType.XML_TYPE.getName();\n                    if ((option != null) && (!option.equals(\"\"))) {\n                        mime = option;\n                    }\n                    \n                    NodeList children = root.getChildNodes();\n                    for (int i = 0; i < children.getLength(); i++) {\n                        Node child = children.item(i);\n                        if (child.getNodeType() == Node.ELEMENT_NODE\n                                && child.getNamespaceURI().equals(Namespaces.EXIST_NS)) {\n                            if (child.getLocalName().equals(\"text\")) {\n                                StringBuffer buf = new StringBuffer();\n                                Node next = child.getFirstChild();\n                                while (next != null) {\n                                    if (next.getNodeType() == Node.TEXT_NODE\n                                            || next.getNodeType() == Node.CDATA_SECTION_NODE)\n                                        buf.append(next.getNodeValue());\n                                    next = next.getNextSibling();\n                                }\n                                query = buf.toString();\n                            } else if (child.getLocalName().equals(\"properties\")) {\n                                Node node = child.getFirstChild();\n                                while (node != null) {\n                                    if (node.getNodeType() == Node.ELEMENT_NODE\n                                            && node.getNamespaceURI().equals(Namespaces.EXIST_NS)\n                                            && node.getLocalName().equals(\"property\")) {\n                                        Element property = (Element) node;\n                                        String key = property\n                                                .getAttribute(\"name\");\n                                        String value = property\n                                                .getAttribute(\"value\");\n                                        LOG.debug(key + \" = \" + value);\n                                        if (key != null && value != null)\n                                            outputProperties.setProperty(key,\n                                                    value);\n                                    }\n                                    node = node.getNextSibling();\n                                }\n                            }\n                        }\n                    }\n                }\n                // execute query\n                if (query != null) {\n                    writeResponse(response, search(broker, query, path, howmany,\n                            start, outputProperties, enclose, request, response), mime,\n                            outputProperties.getProperty(OutputKeys.ENCODING));\n                } else {\n                    transact.abort(transaction);\n                    throw new BadRequestException(\"No query specified\");\n                }\n            } else if (rootNS != null && rootNS.equals(XUpdateProcessor.XUPDATE_NS)) {\n                LOG.debug(\"Got xupdate request: \" + content);\n                DocumentSet docs = new DocumentSet();\n                Collection collection = broker.getCollection(pathUri);\n                if (collection != null) {\n                    collection.allDocs(broker, docs, true, true);\n                } else {\n                    DocumentImpl xupdateDoc = (DocumentImpl) broker.getXMLResource(pathUri);\n                    if (xupdateDoc != null) {\n                        if (!xupdateDoc.getPermissions().validate(\n                                broker.getUser(), Permission.READ)) {\n                            transact.abort(transaction);\n                            throw new PermissionDeniedException(\n                                    \"Not allowed to read collection\");\n                        }\n                        docs.add(xupdateDoc);\n                    } else\n                        broker.getAllXMLResources(docs);\n                }\n                \n                XUpdateProcessor processor = new XUpdateProcessor(broker, docs, AccessContext.REST);\n                Modification modifications[] = processor.parse(new InputSource(\n                        new StringReader(content)));\n                long mods = 0;\n                for (int i = 0; i < modifications.length; i++) {\n                    mods += modifications[i].process(transaction);\n                    broker.flush();\n                }\n                transact.commit(transaction);\n                \n                // FD : Returns an XML doc\n                writeResponse(response,\n                        \"<?xml version='1.0'?>\\n\"\n                        + \"<exist:modifications xmlns:exist='\" + Namespaces.EXIST_NS\n                        + \"' count='\" + mods + \"'>\" + mods\n                        + \"modifications processed.<\/exist:modifications>\",\n                        MimeType.XML_TYPE.getName(), \"UTF-8\");\n                // END FD\n            } else {\n                transact.abort(transaction);\n                throw new BadRequestException(\"Unknown XML root element: \"\n                        + root.getNodeName());\n            }\n        } catch (SAXException e) {\n            transact.abort(transaction);\n            Exception cause = e;\n            if (e.getException() != null)\n                cause = e.getException();\n            LOG.debug(\"SAX exception while parsing request: \"\n                    + cause.getMessage(), cause);\n            throw new BadRequestException(\n                    \"SAX exception while parsing request: \"\n                    + cause.getMessage());\n        } catch (ParserConfigurationException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"Parser exception while parsing request: \" + e.getMessage());\n        } catch (XPathException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"Query exception while parsing request: \" + e.getMessage());\n        } catch (IOException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(\n                    \"IO exception while parsing request: \" + e.getMessage());\n        } catch (EXistException e) {\n            transact.abort(transaction);\n            throw new BadRequestException(e.getMessage());\n        } catch (LockException e) {\n            transact.abort(transaction);\n            throw new PermissionDeniedException(e.getMessage());\n        }\n    }","commit_id":"9c060d23e86db9d1b1460e000e104dc6c8d4196f","url":"https://github.com/eXist-db/exist"},{"original_method":"private void load() {\n    for (Language l : ModuleRepositoryFacade.getInstance().getAllModules(Language.class)) {\n      SModel dfaModel = LanguageAspect.DATA_FLOW.get(l);\n      if (dfaModel != null && dfaModel.getRootNodes().iterator().hasNext()) {\n        String dfaBuildersClassName = SNodeOperations.getModelLongName(dfaModel) + \".DFABuilders\";\n        Class<? extends DataFlowBuilders> buildersClass = ((Class<? extends DataFlowBuilders>) l.getOwnClass(dfaBuildersClassName));\n        if (buildersClass != null) {\n          try {\n            DataFlowBuilders builders = buildersClass.newInstance();\n            builders.install(this);\n          } catch (InstantiationException e) {\n            if (LOG.isEnabledFor(Level.ERROR)) {\n              LOG.error(\"\", e);\n            }\n          } catch (IllegalAccessException e) {\n            if (LOG.isEnabledFor(Level.ERROR)) {\n              LOG.error(\"\", e);\n            }\n          }\n        }\n      }\n    }\n  }","id":14483,"modified_method":"private void load() {\n    for (Language l : ModuleRepositoryFacade.getInstance().getAllModules(Language.class)) {\n      SModel dfaModel = LanguageAspect.DATA_FLOW.get(l);\n      if (dfaModel != null && dfaModel.getRootNodes().iterator().hasNext()) {\n        String dfaBuildersClassName = SNodeOperations.getModelLongName(dfaModel) + \".DFABuilders\";\n        Class<? extends DataFlowBuilders> buildersClass = null;\n        try {\n          buildersClass = ((Class<? extends DataFlowBuilders>) l.getOwnClass(dfaBuildersClassName));\n        } catch (ClassNotFoundException ignored) {\n        }\n        if (buildersClass != null) {\n          try {\n            DataFlowBuilders builders = buildersClass.newInstance();\n            builders.install(this);\n          } catch (InstantiationException e) {\n            if (LOG.isEnabledFor(Level.ERROR)) {\n              LOG.error(\"\", e);\n            }\n          } catch (IllegalAccessException e) {\n            if (LOG.isEnabledFor(Level.ERROR)) {\n              LOG.error(\"\", e);\n            }\n          }\n        }\n      }\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14484,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14485,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14486,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14487,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14488,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14489,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        e.printStackTrace();\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14490,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private TemplateModel getTemplateModel(String modelName) {\n    Class<TemplateModel> clazz =\n        (Class<TemplateModel>) ClassLoaderManager.getInstance().getClass(ModuleRepositoryFacade.getInstance().getModule(getReference()), modelName);\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","id":14491,"modified_method":"private TemplateModel getTemplateModel(String modelName) {\n    ReloadableModule module = (ReloadableModule) ModuleRepositoryFacade.getInstance().getModule(getReference());\n    Class<TemplateModel> clazz = null;\n    if (module != null) {\n      try {\n        clazz = (Class<TemplateModel>) module.getClass(modelName);\n      } catch (ClassNotFoundException e) {\n        throw new IllegalStateException(\"\", e);\n      }\n    }\n    if (clazz == null) {\n      throw new IllegalStateException(String.format(\"Failed to obtain generator runtime class for model %s\", modelName));\n    }\n    try {\n      return clazz.getConstructor(TemplateModule.class).newInstance(this);\n    } catch (RuntimeException ex) {\n      throw ex;\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"private Class<KeyMap> findKeyMapClassByDeclaration(SNode declaration) {\n    String fqName = BehaviorReflection.invokeVirtual(String.class, declaration, \"virtual_getFqName_1213877404258\", new Object[]{});\n    String namespace = NameUtil.namespaceFromLongName(fqName);\n    assert namespace.endsWith(\".editor\");\n    String languageNamespace = namespace.substring(0, namespace.length() - \".editor\".length());\n    Language language = (Language) MPSModuleRepository.getInstance().getModuleByFqName(languageNamespace);\n    if (language == null) {\n      return null;\n    }\n    return ((Class<KeyMap>) language.getOwnClass(fqName));\n  }","id":14492,"modified_method":"private Class<KeyMap> findKeyMapClassByDeclaration(SNode declaration) {\n    String fqName = BehaviorReflection.invokeVirtual(String.class, declaration, \"virtual_getFqName_1213877404258\", new Object[]{});\n    String namespace = NameUtil.namespaceFromLongName(fqName);\n    assert namespace.endsWith(\".editor\");\n    String languageNamespace = namespace.substring(0, namespace.length() - \".editor\".length());\n    Language language = (Language) MPSModuleRepository.getInstance().getModuleByFqName(languageNamespace);\n    if (language == null) {\n      return null;\n    }\n    try {\n      return ((Class<KeyMap>) language.getOwnClass(fqName));\n    } catch (ClassNotFoundException ignored) {\n      return null;\n    }\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"public Collection<SNode> apply(@NotNull final TemplateExecutionEnvironment environment, @NotNull final TemplateContext context) throws GenerationException {\n    final SNode tnode1 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassConcept\");\n    try {\n      environment.nodeCopied(context, tnode1, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270980\");\n      SNodeAccessUtil.setProperty(tnode1, \"name\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1698302279987411159(new PropertyMacroContext(context, \"Generator\", propertyMacro_g5r92k_c0a0c0b0b0c))));\n      {\n        final SNode tnode2 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n        try {\n          environment.nodeCopied(context, tnode2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6509264768608431317\");\n          tnode2.setReference(\"classifier\", SReference.create(\"classifier\", tnode2, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModuleBase\")));\n        } finally {\n        }\n        if (tnode2 != null) {\n          tnode1.addChild(\"superclass\", tnode2);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode3 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n        try {\n          environment.nodeCopied(context, tnode3, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270981\");\n        } finally {\n        }\n        if (tnode3 != null) {\n          tnode1.addChild(\"visibility\", tnode3);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode4 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode4, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768604\");\n          SNodeAccessUtil.setProperty(tnode4, \"name\", \"MODULE_REF\");\n          {\n            final SNode tnode5 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode5, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768605\");\n            } finally {\n            }\n            if (tnode5 != null) {\n              tnode4.addChild(\"visibility\", tnode5);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode6 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringType\");\n            try {\n              environment.nodeCopied(context, tnode6, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752159993\");\n            } finally {\n            }\n            if (tnode6 != null) {\n              tnode4.addChild(\"type\", tnode6);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode7 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n            try {\n              environment.nodeCopied(context, tnode7, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768608\");\n              SNodeAccessUtil.setProperty(tnode7, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_7633657384060768610(new PropertyMacroContext(context, \"module.reference\", propertyMacro_g5r92k_c0a0c0b0b0e0b0e0b0c))));\n            } finally {\n            }\n            if (tnode7 != null) {\n              tnode4.addChild(\"initializer\", tnode7);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode4 != null) {\n          tnode1.addChild(\"member\", tnode4);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode8 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode8, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\");\n          SNodeAccessUtil.setProperty(tnode8, \"name\", \"sourceLanguage\");\n          {\n            final SNode tnode9 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode9, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570458\");\n            } finally {\n            }\n            if (tnode9 != null) {\n              tnode8.addChild(\"visibility\", tnode9);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode10 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode10, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570466\");\n              environment.resolveInTemplateLater(tnode10, \"classifier\", templateNode_g5r92k_c0a1a1a3a1a5a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/9020561928507177266\", \"Language\", context);\n            } finally {\n            }\n            if (tnode10 != null) {\n              tnode8.addChild(\"type\", tnode10);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode8 != null) {\n          tnode1.addChild(\"member\", tnode8);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist11 = null;\n        if (QueriesGenerated.ifMacro_Condition_1820665478710807083(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0g0b0c))) {\n          final SNode tnode12 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode12, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\");\n            SNodeAccessUtil.setProperty(tnode12, \"name\", \"priorities\");\n            SNodeAccessUtil.setProperty(tnode12, \"isFinal\", \"true\");\n            {\n              final SNode tnode13 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode13, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807076\");\n              } finally {\n              }\n              if (tnode13 != null) {\n                tnode12.addChild(\"visibility\", tnode13);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode14 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode14, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807078\");\n                tnode14.setReference(\"classifier\", SReference.create(\"classifier\", tnode14, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode15 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode15, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807080\");\n                    tnode15.setReference(\"classifier\", SReference.create(\"classifier\", tnode15, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateMappingPriorityRule\")));\n                  } finally {\n                  }\n                  if (tnode15 != null) {\n                    tnode14.addChild(\"parameter\", tnode15);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode14 != null) {\n                tnode12.addChild(\"type\", tnode14);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist11 = TemplateUtil.singletonList(tnode12);\n        }\n        for (SNode child16 : TemplateUtil.asNotNull(tlist11)) {\n          tnode1.addChild(\"member\", child16);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist17 = null;\n        if (QueriesGenerated.ifMacro_Condition_6655394244919403419(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0h0b0c))) {\n          final SNode tnode18 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode18, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\");\n            SNodeAccessUtil.setProperty(tnode18, \"name\", \"models\");\n            SNodeAccessUtil.setProperty(tnode18, \"isFinal\", \"true\");\n            {\n              final SNode tnode19 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode19, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403407\");\n              } finally {\n              }\n              if (tnode19 != null) {\n                tnode18.addChild(\"visibility\", tnode19);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode20 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode20, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403410\");\n                tnode20.setReference(\"classifier\", SReference.create(\"classifier\", tnode20, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode21 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode21, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403414\");\n                    tnode21.setReference(\"classifier\", SReference.create(\"classifier\", tnode21, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                  } finally {\n                  }\n                  if (tnode21 != null) {\n                    tnode20.addChild(\"parameter\", tnode21);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode20 != null) {\n                tnode18.addChild(\"type\", tnode20);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist17 = TemplateUtil.singletonList(tnode18);\n        }\n        for (SNode child22 : TemplateUtil.asNotNull(tlist17)) {\n          tnode1.addChild(\"member\", child22);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist23 = null;\n        if (QueriesGenerated.ifMacro_Condition_1250389701475281189(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0i0b0c))) {\n          final SNode tnode24 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode24, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\");\n            SNodeAccessUtil.setProperty(tnode24, \"name\", \"referencedGenerators\");\n            SNodeAccessUtil.setProperty(tnode24, \"isFinal\", \"true\");\n            {\n              final SNode tnode25 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode25, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281181\");\n              } finally {\n              }\n              if (tnode25 != null) {\n                tnode24.addChild(\"visibility\", tnode25);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode26 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode26, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475313843\");\n                tnode26.setReference(\"classifier\", SReference.create(\"classifier\", tnode26, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode27 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode27, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346538\");\n                    tnode27.setReference(\"classifier\", SReference.create(\"classifier\", tnode27, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                  } finally {\n                  }\n                  if (tnode27 != null) {\n                    tnode26.addChild(\"parameter\", tnode27);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode26 != null) {\n                tnode24.addChild(\"type\", tnode26);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist23 = TemplateUtil.singletonList(tnode24);\n        }\n        for (SNode child28 : TemplateUtil.asNotNull(tlist23)) {\n          tnode1.addChild(\"member\", child28);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode29 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode29, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\");\n          SNodeAccessUtil.setProperty(tnode29, \"name\", \"usedLanguages\");\n          {\n            final SNode tnode30 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode30, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431716\");\n            } finally {\n            }\n            if (tnode30 != null) {\n              tnode29.addChild(\"visibility\", tnode30);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode31 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode31, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431728\");\n              tnode31.setReference(\"classifier\", SReference.create(\"classifier\", tnode31, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode32 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode32, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431746\");\n                  tnode32.setReference(\"classifier\", SReference.create(\"classifier\", tnode32, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode32 != null) {\n                  tnode31.addChild(\"parameter\", tnode32);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode31 != null) {\n              tnode29.addChild(\"type\", tnode31);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode29 != null) {\n          tnode1.addChild(\"member\", tnode29);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode33 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ConstructorDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode33, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270982\");\n          {\n            final SNode tnode34 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VoidType\");\n            try {\n              environment.nodeCopied(context, tnode34, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270983\");\n            } finally {\n            }\n            if (tnode34 != null) {\n              tnode33.addChild(\"returnType\", tnode34);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode35 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode35, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270984\");\n            } finally {\n            }\n            if (tnode35 != null) {\n              tnode33.addChild(\"visibility\", tnode35);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode36 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode36, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270985\");\n              {\n                final SNode tnode37 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode37, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570480\");\n                  {\n                    final SNode tnode38 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode38, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570499\");\n                      {\n                        final SNode tnode39 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                        try {\n                          environment.nodeCopied(context, tnode39, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570482\");\n                          {\n                            final SNode tnode40 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThisExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode40, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570481\");\n                            } finally {\n                            }\n                            if (tnode40 != null) {\n                              tnode39.addChild(\"operand\", tnode40);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode41 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldReferenceOperation\");\n                            try {\n                              environment.nodeCopied(context, tnode41, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570492\");\n                              environment.resolveInTemplateLater(tnode41, \"fieldDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\", \"sourceLanguage\", context);\n                            } finally {\n                            }\n                            if (tnode41 != null) {\n                              tnode39.addChild(\"operation\", tnode41);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode39 != null) {\n                          tnode38.addChild(\"lValue\", tnode39);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode42 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode42, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905150326129\");\n                          environment.resolveInTemplateLater(tnode42, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570437\", \"sourceLanguage\", context);\n                        } finally {\n                        }\n                        if (tnode42 != null) {\n                          tnode38.addChild(\"rValue\", tnode42);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode38 != null) {\n                      tnode37.addChild(\"expression\", tnode38);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode37 != null) {\n                  tnode36.addChild(\"statement\", tnode37);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist43 = null;\n                if (QueriesGenerated.ifMacro_Condition_1820665478710839778(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0c0b0d0b0k0b0c))) {\n                  final SNode tnode44 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode44, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839735\");\n                    {\n                      final SNode tnode45 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode45, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839737\");\n                        {\n                          final SNode tnode46 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode46, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120172655\");\n                            environment.resolveInTemplateLater(tnode46, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a2a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\", \"priorities\", context);\n                          } finally {\n                          }\n                          if (tnode46 != null) {\n                            tnode45.addChild(\"lValue\", tnode46);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode47 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode47, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839741\");\n                            tnode47.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode47, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode47.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode47, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final List<SNode> tlist48 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList48 = QueriesGenerated.sourceNodesQuery_1820665478710839750(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a1a2a1a3a1a01a1a2));\n                              for (SNode itnode48 : loopList48) {\n                                if (itnode48 == null) {\n                                  continue;\n                                }\n                                TemplateContext context48 = context.subContext(null, itnode48);\n                                Collection<SNode> tlist49 = null;\n                                final SNode copySrcInput49 = context48.getInput();\n                                tlist49 = environment.copyNodes(TemplateUtil.singletonList(copySrcInput49), copySrcMacro_g5r92k_b0a0e0c0d0b0c0b0b0b0b0c0b0d0b0k0b0c, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839743\", context48);\n                                if (tlist49 != null) {\n                                  tlist48.addAll(tlist49);\n                                }\n                              }\n                              for (SNode child50 : TemplateUtil.asNotNull(tlist48)) {\n                                tnode47.addChild(\"actualArgument\", child50);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode47 != null) {\n                            tnode45.addChild(\"rValue\", tnode47);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode45 != null) {\n                        tnode44.addChild(\"expression\", tnode45);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist43 = TemplateUtil.singletonList(tnode44);\n                }\n                for (SNode child51 : TemplateUtil.asNotNull(tlist43)) {\n                  tnode36.addChild(\"statement\", child51);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist52 = null;\n                if (QueriesGenerated.ifMacro_Condition_3829836699770777506(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0d0b0d0b0k0b0c))) {\n                  final SNode tnode53 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode53, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777406\");\n                    {\n                      final SNode tnode54 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode54, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777407\");\n                        {\n                          final SNode tnode55 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode55, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120352497\");\n                            environment.resolveInTemplateLater(tnode55, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a3a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\", \"models\", context);\n                          } finally {\n                          }\n                          if (tnode55 != null) {\n                            tnode54.addChild(\"lValue\", tnode55);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode56 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode56, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777409\");\n                            tnode56.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode56, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode56.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode56, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final SNode tnode57 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                              try {\n                                environment.nodeCopied(context, tnode57, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777504\");\n                                tnode57.setReference(\"classifier\", SReference.create(\"classifier\", tnode57, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                              } finally {\n                              }\n                              if (tnode57 != null) {\n                                tnode56.addChild(\"typeArgument\", tnode57);\n                              }\n                              // TODO validate child \n                            }\n                            {\n                              final List<SNode> tlist58 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList58 = QueriesGenerated.sourceNodesQuery_3829836699771395556(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a4a1a2a1a1a1a1a3a1a3a1a01a1a2));\n                              for (SNode itnode58 : loopList58) {\n                                if (itnode58 == null) {\n                                  continue;\n                                }\n                                TemplateContext context58 = context.subContext(null, itnode58);\n                                final SNode tnode59 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalMethodCall\");\n                                try {\n                                  environment.nodeCopied(context58, tnode59, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770929428\");\n                                  environment.resolveInTemplateLater(tnode59, \"baseMethodDeclaration\", templateNode_g5r92k_c0a1a3a2a4a1a2a1a1a1a1a3a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028932\", \"getTemplateModel\", context58);\n                                  {\n                                    final SNode tnode60 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                    try {\n                                      environment.nodeCopied(context58, tnode60, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770960050\");\n                                      SNodeAccessUtil.setProperty(tnode60, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_3829836699771176869(new PropertyMacroContext(context58, \"model.TemplateModelImpl\", propertyMacro_g5r92k_c0a0c0b0b0c0d0c0e0b0c0b0b0b0b0d0b0d0b0k0b0c))));\n                                    } finally {\n                                    }\n                                    if (tnode60 != null) {\n                                      tnode59.addChild(\"actualArgument\", tnode60);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode59 != null) {\n                                  tlist58.add(tnode59);\n                                }\n                              }\n                              for (SNode child61 : TemplateUtil.asNotNull(tlist58)) {\n                                tnode56.addChild(\"actualArgument\", child61);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode56 != null) {\n                            tnode54.addChild(\"rValue\", tnode56);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode54 != null) {\n                        tnode53.addChild(\"expression\", tnode54);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist52 = TemplateUtil.singletonList(tnode53);\n                }\n                for (SNode child62 : TemplateUtil.asNotNull(tlist52)) {\n                  tnode36.addChild(\"statement\", child62);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist63 = null;\n                if (QueriesGenerated.ifMacro_Condition_1250389701475344465(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0e0b0d0b0k0b0c))) {\n                  final SNode tnode64 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode64, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344426\");\n                    {\n                      final SNode tnode65 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode65, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344430\");\n                        {\n                          final SNode tnode66 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode66, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120323782\");\n                            environment.resolveInTemplateLater(tnode66, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a4a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\", \"referencedGenerators\", context);\n                          } finally {\n                          }\n                          if (tnode66 != null) {\n                            tnode65.addChild(\"lValue\", tnode66);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode67 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode67, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344440\");\n                            tnode67.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode67, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode67.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode67, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final List<SNode> tlist68 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList68 = QueriesGenerated.sourceNodesQuery_1250389701475344450(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a1a4a1a3a1a01a1a2));\n                              for (SNode itnode68 : loopList68) {\n                                if (itnode68 == null) {\n                                  continue;\n                                }\n                                TemplateContext context68 = context.subContext(null, itnode68);\n                                final SNode tnode69 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                try {\n                                  environment.nodeCopied(context68, tnode69, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344443\");\n                                  SNodeAccessUtil.setProperty(tnode69, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1250389701475344482(new PropertyMacroContext(context68, \"language.namespace/generator.uuid\", propertyMacro_g5r92k_c0a0c0b0d0c0d0b0c0b0b0b0b0e0b0d0b0k0b0c))));\n                                } finally {\n                                }\n                                if (tnode69 != null) {\n                                  tlist68.add(tnode69);\n                                }\n                              }\n                              for (SNode child70 : TemplateUtil.asNotNull(tlist68)) {\n                                tnode67.addChild(\"actualArgument\", child70);\n                              }\n                              // TODO validate child \n                            }\n                            {\n                              final SNode tnode71 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                              try {\n                                environment.nodeCopied(context, tnode71, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346550\");\n                                tnode71.setReference(\"classifier\", SReference.create(\"classifier\", tnode71, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                              } finally {\n                              }\n                              if (tnode71 != null) {\n                                tnode67.addChild(\"typeArgument\", tnode71);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode67 != null) {\n                            tnode65.addChild(\"rValue\", tnode67);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode65 != null) {\n                        tnode64.addChild(\"expression\", tnode65);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist63 = TemplateUtil.singletonList(tnode64);\n                }\n                for (SNode child72 : TemplateUtil.asNotNull(tlist63)) {\n                  tnode36.addChild(\"statement\", child72);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode73 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode73, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431777\");\n                  {\n                    final SNode tnode74 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode74, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431784\");\n                      {\n                        final SNode tnode75 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode75, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120218113\");\n                          environment.resolveInTemplateLater(tnode75, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a5a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\", \"usedLanguages\", context);\n                        } finally {\n                        }\n                        if (tnode75 != null) {\n                          tnode74.addChild(\"lValue\", tnode75);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode76 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                        try {\n                          environment.nodeCopied(context, tnode76, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431803\");\n                          tnode76.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode76, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                          tnode76.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode76, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                          {\n                            final List<SNode> tlist77 = new ArrayList<SNode>();\n                            final Iterable<SNode> loopList77 = QueriesGenerated.sourceNodesQuery_1250389701475431822(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a5a1a3a1a01a1a2));\n                            for (SNode itnode77 : loopList77) {\n                              if (itnode77 == null) {\n                                continue;\n                              }\n                              TemplateContext context77 = context.subContext(null, itnode77);\n                              final SNode tnode78 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                              try {\n                                environment.nodeCopied(context77, tnode78, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431809\");\n                                SNodeAccessUtil.setProperty(tnode78, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1250389701475432571(new PropertyMacroContext(context77, \"\", propertyMacro_g5r92k_c0a0c0b0d0c0d0b0c0b0b0b0f0b0d0b0k0b0c))));\n                              } finally {\n                              }\n                              if (tnode78 != null) {\n                                tlist77.add(tnode78);\n                              }\n                            }\n                            for (SNode child79 : TemplateUtil.asNotNull(tlist77)) {\n                              tnode76.addChild(\"actualArgument\", child79);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode80 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode80, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475432625\");\n                              tnode80.setReference(\"classifier\", SReference.create(\"classifier\", tnode80, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                            } finally {\n                            }\n                            if (tnode80 != null) {\n                              tnode76.addChild(\"typeArgument\", tnode80);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode76 != null) {\n                          tnode74.addChild(\"rValue\", tnode76);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode74 != null) {\n                      tnode73.addChild(\"expression\", tnode74);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode73 != null) {\n                  tnode36.addChild(\"statement\", tnode73);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode36 != null) {\n              tnode33.addChild(\"body\", tnode36);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode81 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\");\n            try {\n              environment.nodeCopied(context, tnode81, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570437\");\n              SNodeAccessUtil.setProperty(tnode81, \"name\", \"sourceLanguage\");\n              {\n                final SNode tnode82 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode82, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570438\");\n                  environment.resolveInTemplateLater(tnode82, \"classifier\", templateNode_g5r92k_c0a1a1a2a1a4a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/9020561928507177266\", \"Language\", context);\n                } finally {\n                }\n                if (tnode82 != null) {\n                  tnode81.addChild(\"type\", tnode82);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode81 != null) {\n              tnode33.addChild(\"parameter\", tnode81);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode33 != null) {\n          tnode1.addChild(\"member\", tnode33);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode83 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode83, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646507\");\n          SNodeAccessUtil.setProperty(tnode83, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode83, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode83, \"name\", \"getAlias\");\n          SNodeAccessUtil.setProperty(tnode83, \"isFinal\", \"false\");\n          {\n            final SNode tnode84 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode84, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646508\");\n            } finally {\n            }\n            if (tnode84 != null) {\n              tnode83.addChild(\"visibility\", tnode84);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode85 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringType\");\n            try {\n              environment.nodeCopied(context, tnode85, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646534\");\n            } finally {\n            }\n            if (tnode85 != null) {\n              tnode83.addChild(\"returnType\", tnode85);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode86 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode86, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646510\");\n              {\n                final SNode tnode87 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode87, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646525\");\n                  {\n                    final SNode tnode88 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                    try {\n                      environment.nodeCopied(context, tnode88, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646533\");\n                      SNodeAccessUtil.setProperty(tnode88, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_5102832340571646536(new PropertyMacroContext(context, \"\", propertyMacro_g5r92k_c0a0c0b0b0b0b0b0b0h0b0l0b0c))));\n                    } finally {\n                    }\n                    if (tnode88 != null) {\n                      tnode87.addChild(\"expression\", tnode88);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode87 != null) {\n                  tnode86.addChild(\"statement\", tnode87);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode86 != null) {\n              tnode83.addChild(\"body\", tnode86);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode89 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode89, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551109\");\n              tnode89.setReference(\"annotation\", SReference.create(\"annotation\", tnode89, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode89 != null) {\n              tnode83.addChild(\"annotation\", tnode89);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode83 != null) {\n          tnode1.addChild(\"member\", tnode83);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode90 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode90, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646511\");\n          SNodeAccessUtil.setProperty(tnode90, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode90, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode90, \"name\", \"getModels\");\n          SNodeAccessUtil.setProperty(tnode90, \"isFinal\", \"false\");\n          {\n            final SNode tnode91 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode91, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646512\");\n            } finally {\n            }\n            if (tnode91 != null) {\n              tnode90.addChild(\"visibility\", tnode91);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode92 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode92, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646513\");\n              tnode92.setReference(\"classifier\", SReference.create(\"classifier\", tnode92, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode93 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode93, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646514\");\n                  tnode93.setReference(\"classifier\", SReference.create(\"classifier\", tnode93, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                } finally {\n                }\n                if (tnode93 != null) {\n                  tnode92.addChild(\"parameter\", tnode93);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode92 != null) {\n              tnode90.addChild(\"returnType\", tnode92);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode94 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode94, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646515\");\n              {\n                final SNode tnode95 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode95, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919461205\");\n                  {\n                    Collection<SNode> tlist96 = null;\n                    if (QueriesGenerated.ifMacro_Condition_6655394244919461209(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0m0b0c))) {\n                      final SNode tnode97 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode97, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120187445\");\n                        environment.resolveInTemplateLater(tnode97, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a21a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\", \"models\", context);\n                      } finally {\n                      }\n                      tlist96 = TemplateUtil.singletonList(tnode97);\n                    } else {\n                      final SNode tnode98 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode98, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919461219\");\n                      } finally {\n                      }\n                      tlist96 = TemplateUtil.singletonList(tnode98);\n                    }\n                    for (SNode child99 : TemplateUtil.asNotNull(tlist96)) {\n                      tnode95.addChild(\"expression\", child99);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode95 != null) {\n                  tnode94.addChild(\"statement\", tnode95);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode94 != null) {\n              tnode90.addChild(\"body\", tnode94);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode100 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode100, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551115\");\n              tnode100.setReference(\"annotation\", SReference.create(\"annotation\", tnode100, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode100 != null) {\n              tnode90.addChild(\"annotation\", tnode100);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode90 != null) {\n          tnode1.addChild(\"member\", tnode90);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode101 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode101, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646516\");\n          SNodeAccessUtil.setProperty(tnode101, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode101, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode101, \"name\", \"getPriorities\");\n          SNodeAccessUtil.setProperty(tnode101, \"isFinal\", \"false\");\n          {\n            final SNode tnode102 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode102, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646517\");\n            } finally {\n            }\n            if (tnode102 != null) {\n              tnode101.addChild(\"visibility\", tnode102);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode103 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode103, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646518\");\n              tnode103.setReference(\"classifier\", SReference.create(\"classifier\", tnode103, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode104 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode104, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807074\");\n                  tnode104.setReference(\"classifier\", SReference.create(\"classifier\", tnode104, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateMappingPriorityRule\")));\n                } finally {\n                }\n                if (tnode104 != null) {\n                  tnode103.addChild(\"parameter\", tnode104);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode103 != null) {\n              tnode101.addChild(\"returnType\", tnode103);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode105 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode105, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646520\");\n              {\n                final SNode tnode106 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode106, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839794\");\n                  {\n                    Collection<SNode> tlist107 = null;\n                    if (QueriesGenerated.ifMacro_Condition_1820665478710839798(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0n0b0c))) {\n                      final SNode tnode108 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode108, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120198611\");\n                        environment.resolveInTemplateLater(tnode108, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a31a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\", \"priorities\", context);\n                      } finally {\n                      }\n                      tlist107 = TemplateUtil.singletonList(tnode108);\n                    } else {\n                      final SNode tnode109 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode109, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839814\");\n                      } finally {\n                      }\n                      tlist107 = TemplateUtil.singletonList(tnode109);\n                    }\n                    for (SNode child110 : TemplateUtil.asNotNull(tlist107)) {\n                      tnode106.addChild(\"expression\", child110);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode106 != null) {\n                  tnode105.addChild(\"statement\", tnode106);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode105 != null) {\n              tnode101.addChild(\"body\", tnode105);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode111 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode111, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551112\");\n              tnode111.setReference(\"annotation\", SReference.create(\"annotation\", tnode111, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode111 != null) {\n              tnode101.addChild(\"annotation\", tnode111);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode101 != null) {\n          tnode1.addChild(\"member\", tnode101);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode112 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode112, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646521\");\n          SNodeAccessUtil.setProperty(tnode112, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode112, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode112, \"name\", \"getReference\");\n          SNodeAccessUtil.setProperty(tnode112, \"isFinal\", \"false\");\n          {\n            final SNode tnode113 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode113, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646522\");\n            } finally {\n            }\n            if (tnode113 != null) {\n              tnode112.addChild(\"visibility\", tnode113);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode114 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode114, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646523\");\n              tnode114.setReference(\"classifier\", SReference.create(\"classifier\", tnode114, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~SModuleReference\")));\n            } finally {\n            }\n            if (tnode114 != null) {\n              tnode112.addChild(\"returnType\", tnode114);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode115 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode115, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646524\");\n              {\n                final SNode tnode116 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode116, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752227166\");\n                  {\n                    final SNode tnode117 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode117, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752278543\");\n                      {\n                        final SNode tnode118 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                        try {\n                          environment.nodeCopied(context, tnode118, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752252693\");\n                          tnode118.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode118, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade.getInstance():org.jetbrains.mps.openapi.persistence.PersistenceFacade\")));\n                          tnode118.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode118, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade\")));\n                        } finally {\n                        }\n                        if (tnode118 != null) {\n                          tnode117.addChild(\"operand\", tnode118);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode119 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                        try {\n                          environment.nodeCopied(context, tnode119, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752307194\");\n                          tnode119.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode119, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade.createModuleReference(java.lang.String):org.jetbrains.mps.openapi.module.SModuleReference\")));\n                          {\n                            final SNode tnode120 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                            try {\n                              environment.nodeCopied(context, tnode120, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752332768\");\n                              environment.resolveInTemplateLater(tnode120, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a1a1a7a1a41a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768604\", \"MODULE_REF\", context);\n                            } finally {\n                            }\n                            if (tnode120 != null) {\n                              tnode119.addChild(\"actualArgument\", tnode120);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode119 != null) {\n                          tnode117.addChild(\"operation\", tnode119);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode117 != null) {\n                      tnode116.addChild(\"expression\", tnode117);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode116 != null) {\n                  tnode115.addChild(\"statement\", tnode116);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode115 != null) {\n              tnode112.addChild(\"body\", tnode115);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode121 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode121, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551110\");\n              tnode121.setReference(\"annotation\", SReference.create(\"annotation\", tnode121, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode121 != null) {\n              tnode112.addChild(\"annotation\", tnode121);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode112 != null) {\n          tnode1.addChild(\"member\", tnode112);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode122 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode122, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280636\");\n          SNodeAccessUtil.setProperty(tnode122, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode122, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode122, \"name\", \"getUsedLanguages\");\n          SNodeAccessUtil.setProperty(tnode122, \"isFinal\", \"false\");\n          {\n            final SNode tnode123 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode123, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280637\");\n            } finally {\n            }\n            if (tnode123 != null) {\n              tnode122.addChild(\"visibility\", tnode123);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode124 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode124, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280638\");\n              tnode124.setReference(\"classifier\", SReference.create(\"classifier\", tnode124, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode125 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode125, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280639\");\n                  tnode125.setReference(\"classifier\", SReference.create(\"classifier\", tnode125, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode125 != null) {\n                  tnode124.addChild(\"parameter\", tnode125);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode124 != null) {\n              tnode122.addChild(\"returnType\", tnode124);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode126 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode126, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280640\");\n              {\n                final SNode tnode127 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode127, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280646\");\n                  {\n                    final SNode tnode128 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                    try {\n                      environment.nodeCopied(context, tnode128, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120309782\");\n                      environment.resolveInTemplateLater(tnode128, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a7a1a51a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\", \"usedLanguages\", context);\n                    } finally {\n                    }\n                    if (tnode128 != null) {\n                      tnode127.addChild(\"expression\", tnode128);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode127 != null) {\n                  tnode126.addChild(\"statement\", tnode127);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode126 != null) {\n              tnode122.addChild(\"body\", tnode126);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode129 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode129, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551111\");\n              tnode129.setReference(\"annotation\", SReference.create(\"annotation\", tnode129, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode129 != null) {\n              tnode122.addChild(\"annotation\", tnode129);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode122 != null) {\n          tnode1.addChild(\"member\", tnode122);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode130 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode130, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570445\");\n          SNodeAccessUtil.setProperty(tnode130, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode130, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode130, \"name\", \"getSourceLanguage\");\n          SNodeAccessUtil.setProperty(tnode130, \"isFinal\", \"false\");\n          {\n            final SNode tnode131 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode131, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570446\");\n            } finally {\n            }\n            if (tnode131 != null) {\n              tnode130.addChild(\"visibility\", tnode131);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode132 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode132, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570447\");\n              tnode132.setReference(\"classifier\", SReference.create(\"classifier\", tnode132, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel.language(MPS.Core/jetbrains.mps.smodel.language@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~LanguageRuntime\")));\n            } finally {\n            }\n            if (tnode132 != null) {\n              tnode130.addChild(\"returnType\", tnode132);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode133 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode133, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570448\");\n              {\n                final SNode tnode134 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode134, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570449\");\n                  {\n                    final SNode tnode135 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                    try {\n                      environment.nodeCopied(context, tnode135, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120187371\");\n                      environment.resolveInTemplateLater(tnode135, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a7a1a61a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\", \"sourceLanguage\", context);\n                    } finally {\n                    }\n                    if (tnode135 != null) {\n                      tnode134.addChild(\"expression\", tnode135);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode134 != null) {\n                  tnode133.addChild(\"statement\", tnode134);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode133 != null) {\n              tnode130.addChild(\"body\", tnode133);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode136 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode136, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551113\");\n              tnode136.setReference(\"annotation\", SReference.create(\"annotation\", tnode136, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode136 != null) {\n              tnode130.addChild(\"annotation\", tnode136);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode130 != null) {\n          tnode1.addChild(\"member\", tnode130);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode137 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode137, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280641\");\n          SNodeAccessUtil.setProperty(tnode137, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode137, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode137, \"name\", \"getReferencedModules\");\n          SNodeAccessUtil.setProperty(tnode137, \"isFinal\", \"false\");\n          {\n            final SNode tnode138 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode138, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280642\");\n            } finally {\n            }\n            if (tnode138 != null) {\n              tnode137.addChild(\"visibility\", tnode138);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode139 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode139, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280643\");\n              tnode139.setReference(\"classifier\", SReference.create(\"classifier\", tnode139, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode140 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode140, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346537\");\n                  tnode140.setReference(\"classifier\", SReference.create(\"classifier\", tnode140, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode140 != null) {\n                  tnode139.addChild(\"parameter\", tnode140);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode139 != null) {\n              tnode137.addChild(\"returnType\", tnode139);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode141 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode141, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280645\");\n              {\n                final SNode tnode142 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode142, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280648\");\n                  {\n                    Collection<SNode> tlist143 = null;\n                    if (QueriesGenerated.ifMacro_Condition_1250389701475344489(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0r0b0c))) {\n                      final SNode tnode144 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode144, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120268781\");\n                        environment.resolveInTemplateLater(tnode144, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a71a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\", \"referencedGenerators\", context);\n                      } finally {\n                      }\n                      tlist143 = TemplateUtil.singletonList(tnode144);\n                    } else {\n                      final SNode tnode145 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode145, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344493\");\n                      } finally {\n                      }\n                      tlist143 = TemplateUtil.singletonList(tnode145);\n                    }\n                    for (SNode child146 : TemplateUtil.asNotNull(tlist143)) {\n                      tnode142.addChild(\"expression\", child146);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode142 != null) {\n                  tnode141.addChild(\"statement\", tnode142);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode141 != null) {\n              tnode137.addChild(\"body\", tnode141);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode147 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode147, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551114\");\n              tnode147.setReference(\"annotation\", SReference.create(\"annotation\", tnode147, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode147 != null) {\n              tnode137.addChild(\"annotation\", tnode147);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode137 != null) {\n          tnode1.addChild(\"member\", tnode137);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode148 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode148, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028932\");\n          SNodeAccessUtil.setProperty(tnode148, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode148, \"name\", \"getTemplateModel\");\n          SNodeAccessUtil.setProperty(tnode148, \"isSynchronized\", \"false\");\n          SNodeAccessUtil.setProperty(tnode148, \"isFinal\", \"false\");\n          {\n            final SNode tnode149 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode149, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028935\");\n              {\n                final SNode tnode150 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\");\n                try {\n                  environment.nodeCopied(context, tnode150, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401081\");\n                  {\n                    final SNode tnode151 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                    try {\n                      environment.nodeCopied(context, tnode151, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\");\n                      SNodeAccessUtil.setProperty(tnode151, \"name\", \"module\");\n                      {\n                        final SNode tnode152 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                        try {\n                          environment.nodeCopied(context, tnode152, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565460366\");\n                          tnode152.setReference(\"classifier\", SReference.create(\"classifier\", tnode152, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule\")));\n                        } finally {\n                        }\n                        if (tnode152 != null) {\n                          tnode151.addChild(\"type\", tnode152);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode153 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CastExpression\");\n                        try {\n                          environment.nodeCopied(context, tnode153, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565461988\");\n                          {\n                            final SNode tnode154 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode154, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752386838\");\n                              {\n                                final SNode tnode155 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                                try {\n                                  environment.nodeCopied(context, tnode155, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752440665\");\n                                  tnode155.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode155, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade\")));\n                                  tnode155.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode155, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade.getInstance():jetbrains.mps.smodel.ModuleRepositoryFacade\")));\n                                } finally {\n                                }\n                                if (tnode155 != null) {\n                                  tnode154.addChild(\"operand\", tnode155);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode156 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                try {\n                                  environment.nodeCopied(context, tnode156, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752471129\");\n                                  tnode156.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode156, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade.getModule(org.jetbrains.mps.openapi.module.SModuleReference):org.jetbrains.mps.openapi.module.SModule\")));\n                                  {\n                                    final SNode tnode157 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalMethodCall\");\n                                    try {\n                                      environment.nodeCopied(context, tnode157, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752497140\");\n                                      environment.resolveInTemplateLater(tnode157, \"baseMethodDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a3a1a1a1a1a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646521\", \"getReference\", context);\n                                    } finally {\n                                    }\n                                    if (tnode157 != null) {\n                                      tnode156.addChild(\"actualArgument\", tnode157);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode156 != null) {\n                                  tnode154.addChild(\"operation\", tnode156);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode154 != null) {\n                              tnode153.addChild(\"expression\", tnode154);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode158 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode158, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565461989\");\n                              tnode158.setReference(\"classifier\", SReference.create(\"classifier\", tnode158, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule\")));\n                            } finally {\n                            }\n                            if (tnode158 != null) {\n                              tnode153.addChild(\"type\", tnode158);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode153 != null) {\n                          tnode151.addChild(\"initializer\", tnode153);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode151 != null) {\n                      tnode150.addChild(\"localVariableDeclaration\", tnode151);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode150 != null) {\n                  tnode149.addChild(\"statement\", tnode150);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode159 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\");\n                try {\n                  environment.nodeCopied(context, tnode159, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992422\");\n                  {\n                    final SNode tnode160 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                    try {\n                      environment.nodeCopied(context, tnode160, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\");\n                      SNodeAccessUtil.setProperty(tnode160, \"name\", \"clazz\");\n                      {\n                        final SNode tnode161 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                        try {\n                          environment.nodeCopied(context, tnode161, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992420\");\n                          tnode161.setReference(\"classifier\", SReference.create(\"classifier\", tnode161, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class\")));\n                          {\n                            final SNode tnode162 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode162, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769023268\");\n                              tnode162.setReference(\"classifier\", SReference.create(\"classifier\", tnode162, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                            } finally {\n                            }\n                            if (tnode162 != null) {\n                              tnode161.addChild(\"parameter\", tnode162);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode161 != null) {\n                          tnode160.addChild(\"type\", tnode161);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode163 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode163, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565533117\");\n                        } finally {\n                        }\n                        if (tnode163 != null) {\n                          tnode160.addChild(\"initializer\", tnode163);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode160 != null) {\n                      tnode159.addChild(\"localVariableDeclaration\", tnode160);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode159 != null) {\n                  tnode149.addChild(\"statement\", tnode159);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode164 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.IfStatement\");\n                try {\n                  environment.nodeCopied(context, tnode164, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565474852\");\n                  {\n                    final SNode tnode165 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode165, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565474855\");\n                      {\n                        final SNode tnode166 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode166, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505912\");\n                          {\n                            final SNode tnode167 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode167, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505914\");\n                              {\n                                final SNode tnode168 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CastExpression\");\n                                try {\n                                  environment.nodeCopied(context, tnode168, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565329875\");\n                                  {\n                                    final SNode tnode169 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                                    try {\n                                      environment.nodeCopied(context, tnode169, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565331658\");\n                                      tnode169.setReference(\"classifier\", SReference.create(\"classifier\", tnode169, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class\")));\n                                      {\n                                        final SNode tnode170 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                                        try {\n                                          environment.nodeCopied(context, tnode170, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565332714\");\n                                          tnode170.setReference(\"classifier\", SReference.create(\"classifier\", tnode170, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                                        } finally {\n                                        }\n                                        if (tnode170 != null) {\n                                          tnode169.addChild(\"parameter\", tnode170);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode169 != null) {\n                                      tnode168.addChild(\"type\", tnode169);\n                                    }\n                                    // TODO validate child \n                                  }\n                                  {\n                                    final SNode tnode171 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                                    try {\n                                      environment.nodeCopied(context, tnode171, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565418562\");\n                                      {\n                                        final SNode tnode172 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode172, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565418022\");\n                                          environment.resolveInTemplateLater(tnode172, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a2a1a1a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\", \"module\", context);\n                                        } finally {\n                                        }\n                                        if (tnode172 != null) {\n                                          tnode171.addChild(\"operand\", tnode172);\n                                        }\n                                        // TODO validate child \n                                      }\n                                      {\n                                        final SNode tnode173 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                        try {\n                                          environment.nodeCopied(context, tnode173, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565419407\");\n                                          tnode173.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode173, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule.getClass(java.lang.String):java.lang.Class\")));\n                                          {\n                                            final SNode tnode174 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                            try {\n                                              environment.nodeCopied(context, tnode174, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565420853\");\n                                              environment.resolveInTemplateLater(tnode174, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a2a1a1a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\", \"modelName\", context);\n                                            } finally {\n                                            }\n                                            if (tnode174 != null) {\n                                              tnode173.addChild(\"actualArgument\", tnode174);\n                                            }\n                                            // TODO validate child \n                                          }\n                                        } finally {\n                                        }\n                                        if (tnode173 != null) {\n                                          tnode171.addChild(\"operation\", tnode173);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode171 != null) {\n                                      tnode168.addChild(\"expression\", tnode171);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode168 != null) {\n                                  tnode167.addChild(\"rValue\", tnode168);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode175 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                try {\n                                  environment.nodeCopied(context, tnode175, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505918\");\n                                  environment.resolveInTemplateLater(tnode175, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                                } finally {\n                                }\n                                if (tnode175 != null) {\n                                  tnode167.addChild(\"lValue\", tnode175);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode167 != null) {\n                              tnode166.addChild(\"expression\", tnode167);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode166 != null) {\n                          tnode165.addChild(\"statement\", tnode166);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode165 != null) {\n                      tnode164.addChild(\"ifTrue\", tnode165);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode176 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NotEqualsExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode176, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565490205\");\n                      {\n                        final SNode tnode177 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode177, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565491121\");\n                        } finally {\n                        }\n                        if (tnode177 != null) {\n                          tnode176.addChild(\"rightExpression\", tnode177);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode178 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode178, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565489261\");\n                          environment.resolveInTemplateLater(tnode178, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\", \"module\", context);\n                        } finally {\n                        }\n                        if (tnode178 != null) {\n                          tnode176.addChild(\"leftExpression\", tnode178);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode176 != null) {\n                      tnode164.addChild(\"condition\", tnode176);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode164 != null) {\n                  tnode149.addChild(\"statement\", tnode164);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode179 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.IfStatement\");\n                try {\n                  environment.nodeCopied(context, tnode179, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153325762\");\n                  {\n                    final SNode tnode180 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode180, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153325765\");\n                      {\n                        final SNode tnode181 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode181, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153400884\");\n                          {\n                            final SNode tnode182 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.GenericNewExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode182, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153401352\");\n                              {\n                                final SNode tnode183 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassCreator\");\n                                try {\n                                  environment.nodeCopied(context, tnode183, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153455683\");\n                                  tnode183.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode183, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~IllegalStateException.<init>(java.lang.String)\")));\n                                  {\n                                    final SNode tnode184 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                                    try {\n                                      environment.nodeCopied(context, tnode184, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153475042\");\n                                      tnode184.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode184, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                                      tnode184.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode184, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String.format(java.lang.String,java.lang.Object...):java.lang.String\")));\n                                      {\n                                        final SNode tnode185 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                        try {\n                                          environment.nodeCopied(context, tnode185, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153494863\");\n                                          SNodeAccessUtil.setProperty(tnode185, \"value\", \"Failed to obtain generator runtime class for model %s\");\n                                        } finally {\n                                        }\n                                        if (tnode185 != null) {\n                                          tnode184.addChild(\"actualArgument\", tnode185);\n                                        }\n                                        // TODO validate child \n                                      }\n                                      {\n                                        final SNode tnode186 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode186, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153523313\");\n                                          environment.resolveInTemplateLater(tnode186, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a4a1a2a1a1a1a1a1a1a1a1a1a4a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\", \"modelName\", context);\n                                        } finally {\n                                        }\n                                        if (tnode186 != null) {\n                                          tnode184.addChild(\"actualArgument\", tnode186);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode184 != null) {\n                                      tnode183.addChild(\"actualArgument\", tnode184);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode183 != null) {\n                                  tnode182.addChild(\"creator\", tnode183);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode182 != null) {\n                              tnode181.addChild(\"throwable\", tnode182);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode181 != null) {\n                          tnode180.addChild(\"statement\", tnode181);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode180 != null) {\n                      tnode179.addChild(\"ifTrue\", tnode180);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode187 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.EqualsExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode187, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153375317\");\n                      {\n                        final SNode tnode188 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode188, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153382461\");\n                        } finally {\n                        }\n                        if (tnode188 != null) {\n                          tnode187.addChild(\"rightExpression\", tnode188);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode189 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode189, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153361721\");\n                          environment.resolveInTemplateLater(tnode189, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a4a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                        } finally {\n                        }\n                        if (tnode189 != null) {\n                          tnode187.addChild(\"leftExpression\", tnode189);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode187 != null) {\n                      tnode179.addChild(\"condition\", tnode187);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode179 != null) {\n                  tnode149.addChild(\"statement\", tnode179);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode190 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.TryCatchStatement\");\n                try {\n                  environment.nodeCopied(context, tnode190, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998096\");\n                  {\n                    final SNode tnode191 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode191, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998098\");\n                      {\n                        final SNode tnode192 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ReturnStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode192, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770092637\");\n                          {\n                            final SNode tnode193 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode193, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770271856\");\n                              {\n                                final SNode tnode194 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                try {\n                                  environment.nodeCopied(context, tnode194, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770339620\");\n                                  tnode194.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode194, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang.reflect(JDK/java.lang.reflect@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Constructor.newInstance(java.lang.Object...):java.lang.Object\")));\n                                  {\n                                    final SNode tnode195 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThisExpression\");\n                                    try {\n                                      environment.nodeCopied(context, tnode195, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770372519\");\n                                    } finally {\n                                    }\n                                    if (tnode195 != null) {\n                                      tnode194.addChild(\"actualArgument\", tnode195);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode194 != null) {\n                                  tnode193.addChild(\"operation\", tnode194);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode196 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                                try {\n                                  environment.nodeCopied(context, tnode196, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770125445\");\n                                  {\n                                    final SNode tnode197 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                    try {\n                                      environment.nodeCopied(context, tnode197, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770187459\");\n                                      tnode197.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode197, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class.getConstructor(java.lang.Class...):java.lang.reflect.Constructor\")));\n                                      {\n                                        final SNode tnode198 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierClassExpression\");\n                                        try {\n                                          environment.nodeCopied(context, tnode198, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3886626959987239845\");\n                                          tnode198.setReference(\"classifier\", SReference.create(\"classifier\", tnode198, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModule\")));\n                                        } finally {\n                                        }\n                                        if (tnode198 != null) {\n                                          tnode197.addChild(\"actualArgument\", tnode198);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode197 != null) {\n                                      tnode196.addChild(\"operation\", tnode197);\n                                    }\n                                    // TODO validate child \n                                  }\n                                  {\n                                    final SNode tnode199 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                    try {\n                                      environment.nodeCopied(context, tnode199, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770123776\");\n                                      environment.resolveInTemplateLater(tnode199, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a1a1a1a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                                    } finally {\n                                    }\n                                    if (tnode199 != null) {\n                                      tnode196.addChild(\"operand\", tnode199);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode196 != null) {\n                                  tnode193.addChild(\"operand\", tnode196);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode193 != null) {\n                              tnode192.addChild(\"expression\", tnode193);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode192 != null) {\n                          tnode191.addChild(\"statement\", tnode192);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode191 != null) {\n                      tnode190.addChild(\"body\", tnode191);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode200 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CatchClause\");\n                    try {\n                      environment.nodeCopied(context, tnode200, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998099\");\n                      {\n                        final SNode tnode201 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                        try {\n                          environment.nodeCopied(context, tnode201, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998101\");\n                          SNodeAccessUtil.setProperty(tnode201, \"name\", \"ex\");\n                          {\n                            final SNode tnode202 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode202, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153219588\");\n                              tnode202.setReference(\"classifier\", SReference.create(\"classifier\", tnode202, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~RuntimeException\")));\n                            } finally {\n                            }\n                            if (tnode202 != null) {\n                              tnode201.addChild(\"type\", tnode202);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode201 != null) {\n                          tnode200.addChild(\"throwable\", tnode201);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode203 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                        try {\n                          environment.nodeCopied(context, tnode203, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998105\");\n                          {\n                            final SNode tnode204 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                            try {\n                              environment.nodeCopied(context, tnode204, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153283021\");\n                              {\n                                final SNode tnode205 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                try {\n                                  environment.nodeCopied(context, tnode205, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153283657\");\n                                  environment.resolveInTemplateLater(tnode205, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a2a1a2a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998101\", \"ex\", context);\n                                } finally {\n                                }\n                                if (tnode205 != null) {\n                                  tnode204.addChild(\"throwable\", tnode205);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode204 != null) {\n                              tnode203.addChild(\"statement\", tnode204);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode203 != null) {\n                          tnode200.addChild(\"catchBody\", tnode203);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode200 != null) {\n                      tnode190.addChild(\"catchClause\", tnode200);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode206 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CatchClause\");\n                    try {\n                      environment.nodeCopied(context, tnode206, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156725\");\n                      {\n                        final SNode tnode207 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                        try {\n                          environment.nodeCopied(context, tnode207, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156726\");\n                          SNodeAccessUtil.setProperty(tnode207, \"name\", \"ex\");\n                          {\n                            final SNode tnode208 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode208, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153191842\");\n                              tnode208.setReference(\"classifier\", SReference.create(\"classifier\", tnode208, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Exception\")));\n                            } finally {\n                            }\n                            if (tnode208 != null) {\n                              tnode207.addChild(\"type\", tnode208);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode207 != null) {\n                          tnode206.addChild(\"throwable\", tnode207);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode209 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                        try {\n                          environment.nodeCopied(context, tnode209, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156728\");\n                          {\n                            final SNode tnode210 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                            try {\n                              environment.nodeCopied(context, tnode210, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215434\");\n                              {\n                                final SNode tnode211 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.GenericNewExpression\");\n                                try {\n                                  environment.nodeCopied(context, tnode211, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215435\");\n                                  {\n                                    final SNode tnode212 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassCreator\");\n                                    try {\n                                      environment.nodeCopied(context, tnode212, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215436\");\n                                      tnode212.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode212, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~RuntimeException.<init>(java.lang.Throwable)\")));\n                                      {\n                                        final SNode tnode213 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode213, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153218012\");\n                                          environment.resolveInTemplateLater(tnode213, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a2a1a3a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156726\", \"ex\", context);\n                                        } finally {\n                                        }\n                                        if (tnode213 != null) {\n                                          tnode212.addChild(\"actualArgument\", tnode213);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode212 != null) {\n                                      tnode211.addChild(\"creator\", tnode212);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode211 != null) {\n                                  tnode210.addChild(\"throwable\", tnode211);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode210 != null) {\n                              tnode209.addChild(\"statement\", tnode210);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode209 != null) {\n                          tnode206.addChild(\"catchBody\", tnode209);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode206 != null) {\n                      tnode190.addChild(\"catchClause\", tnode206);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode190 != null) {\n                  tnode149.addChild(\"statement\", tnode190);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode149 != null) {\n              tnode148.addChild(\"body\", tnode149);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode214 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode214, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699767969139\");\n            } finally {\n            }\n            if (tnode214 != null) {\n              tnode148.addChild(\"visibility\", tnode214);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode215 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode215, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768008914\");\n              tnode215.setReference(\"classifier\", SReference.create(\"classifier\", tnode215, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n            } finally {\n            }\n            if (tnode215 != null) {\n              tnode148.addChild(\"returnType\", tnode215);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode216 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\");\n            try {\n              environment.nodeCopied(context, tnode216, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\");\n              SNodeAccessUtil.setProperty(tnode216, \"name\", \"modelName\");\n              {\n                final SNode tnode217 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode217, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392370\");\n                  tnode217.setReference(\"classifier\", SReference.create(\"classifier\", tnode217, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode217 != null) {\n                  tnode216.addChild(\"type\", tnode217);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode216 != null) {\n              tnode148.addChild(\"parameter\", tnode216);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode148 != null) {\n          tnode1.addChild(\"member\", tnode148);\n        }\n        // TODO validate child \n      }\n    } finally {\n    }\n    return TemplateUtil.singletonList(tnode1);\n  }","id":14493,"modified_method":"public Collection<SNode> apply(@NotNull final TemplateExecutionEnvironment environment, @NotNull final TemplateContext context) throws GenerationException {\n    final SNode tnode1 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassConcept\");\n    try {\n      environment.nodeCopied(context, tnode1, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270980\");\n      SNodeAccessUtil.setProperty(tnode1, \"name\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1698302279987411159(new PropertyMacroContext(context, \"Generator\", propertyMacro_g5r92k_c0a0c0b0b0c))));\n      {\n        final SNode tnode2 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n        try {\n          environment.nodeCopied(context, tnode2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6509264768608431317\");\n          tnode2.setReference(\"classifier\", SReference.create(\"classifier\", tnode2, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModuleBase\")));\n        } finally {\n        }\n        if (tnode2 != null) {\n          tnode1.addChild(\"superclass\", tnode2);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode3 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n        try {\n          environment.nodeCopied(context, tnode3, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270981\");\n        } finally {\n        }\n        if (tnode3 != null) {\n          tnode1.addChild(\"visibility\", tnode3);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode4 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode4, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768604\");\n          SNodeAccessUtil.setProperty(tnode4, \"name\", \"MODULE_REF\");\n          {\n            final SNode tnode5 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode5, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768605\");\n            } finally {\n            }\n            if (tnode5 != null) {\n              tnode4.addChild(\"visibility\", tnode5);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode6 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringType\");\n            try {\n              environment.nodeCopied(context, tnode6, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752159993\");\n            } finally {\n            }\n            if (tnode6 != null) {\n              tnode4.addChild(\"type\", tnode6);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode7 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n            try {\n              environment.nodeCopied(context, tnode7, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768608\");\n              SNodeAccessUtil.setProperty(tnode7, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_7633657384060768610(new PropertyMacroContext(context, \"module.reference\", propertyMacro_g5r92k_c0a0c0b0b0e0b0e0b0c))));\n            } finally {\n            }\n            if (tnode7 != null) {\n              tnode4.addChild(\"initializer\", tnode7);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode4 != null) {\n          tnode1.addChild(\"member\", tnode4);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode8 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode8, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\");\n          SNodeAccessUtil.setProperty(tnode8, \"name\", \"sourceLanguage\");\n          {\n            final SNode tnode9 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode9, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570458\");\n            } finally {\n            }\n            if (tnode9 != null) {\n              tnode8.addChild(\"visibility\", tnode9);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode10 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode10, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570466\");\n              environment.resolveInTemplateLater(tnode10, \"classifier\", templateNode_g5r92k_c0a1a1a3a1a5a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/9020561928507177266\", \"Language\", context);\n            } finally {\n            }\n            if (tnode10 != null) {\n              tnode8.addChild(\"type\", tnode10);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode8 != null) {\n          tnode1.addChild(\"member\", tnode8);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist11 = null;\n        if (QueriesGenerated.ifMacro_Condition_1820665478710807083(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0g0b0c))) {\n          final SNode tnode12 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode12, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\");\n            SNodeAccessUtil.setProperty(tnode12, \"name\", \"priorities\");\n            SNodeAccessUtil.setProperty(tnode12, \"isFinal\", \"true\");\n            {\n              final SNode tnode13 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode13, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807076\");\n              } finally {\n              }\n              if (tnode13 != null) {\n                tnode12.addChild(\"visibility\", tnode13);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode14 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode14, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807078\");\n                tnode14.setReference(\"classifier\", SReference.create(\"classifier\", tnode14, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode15 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode15, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807080\");\n                    tnode15.setReference(\"classifier\", SReference.create(\"classifier\", tnode15, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateMappingPriorityRule\")));\n                  } finally {\n                  }\n                  if (tnode15 != null) {\n                    tnode14.addChild(\"parameter\", tnode15);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode14 != null) {\n                tnode12.addChild(\"type\", tnode14);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist11 = TemplateUtil.singletonList(tnode12);\n        }\n        for (SNode child16 : TemplateUtil.asNotNull(tlist11)) {\n          tnode1.addChild(\"member\", child16);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist17 = null;\n        if (QueriesGenerated.ifMacro_Condition_6655394244919403419(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0h0b0c))) {\n          final SNode tnode18 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode18, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\");\n            SNodeAccessUtil.setProperty(tnode18, \"name\", \"models\");\n            SNodeAccessUtil.setProperty(tnode18, \"isFinal\", \"true\");\n            {\n              final SNode tnode19 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode19, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403407\");\n              } finally {\n              }\n              if (tnode19 != null) {\n                tnode18.addChild(\"visibility\", tnode19);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode20 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode20, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403410\");\n                tnode20.setReference(\"classifier\", SReference.create(\"classifier\", tnode20, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode21 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode21, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403414\");\n                    tnode21.setReference(\"classifier\", SReference.create(\"classifier\", tnode21, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                  } finally {\n                  }\n                  if (tnode21 != null) {\n                    tnode20.addChild(\"parameter\", tnode21);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode20 != null) {\n                tnode18.addChild(\"type\", tnode20);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist17 = TemplateUtil.singletonList(tnode18);\n        }\n        for (SNode child22 : TemplateUtil.asNotNull(tlist17)) {\n          tnode1.addChild(\"member\", child22);\n        }\n        // TODO validate child \n      }\n      {\n        Collection<SNode> tlist23 = null;\n        if (QueriesGenerated.ifMacro_Condition_1250389701475281189(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0i0b0c))) {\n          final SNode tnode24 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n          try {\n            environment.nodeCopied(context, tnode24, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\");\n            SNodeAccessUtil.setProperty(tnode24, \"name\", \"referencedGenerators\");\n            SNodeAccessUtil.setProperty(tnode24, \"isFinal\", \"true\");\n            {\n              final SNode tnode25 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n              try {\n                environment.nodeCopied(context, tnode25, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281181\");\n              } finally {\n              }\n              if (tnode25 != null) {\n                tnode24.addChild(\"visibility\", tnode25);\n              }\n              // TODO validate child \n            }\n            {\n              final SNode tnode26 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n              try {\n                environment.nodeCopied(context, tnode26, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475313843\");\n                tnode26.setReference(\"classifier\", SReference.create(\"classifier\", tnode26, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n                {\n                  final SNode tnode27 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                  try {\n                    environment.nodeCopied(context, tnode27, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346538\");\n                    tnode27.setReference(\"classifier\", SReference.create(\"classifier\", tnode27, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                  } finally {\n                  }\n                  if (tnode27 != null) {\n                    tnode26.addChild(\"parameter\", tnode27);\n                  }\n                  // TODO validate child \n                }\n              } finally {\n              }\n              if (tnode26 != null) {\n                tnode24.addChild(\"type\", tnode26);\n              }\n              // TODO validate child \n            }\n          } finally {\n          }\n          tlist23 = TemplateUtil.singletonList(tnode24);\n        }\n        for (SNode child28 : TemplateUtil.asNotNull(tlist23)) {\n          tnode1.addChild(\"member\", child28);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode29 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode29, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\");\n          SNodeAccessUtil.setProperty(tnode29, \"name\", \"usedLanguages\");\n          {\n            final SNode tnode30 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode30, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431716\");\n            } finally {\n            }\n            if (tnode30 != null) {\n              tnode29.addChild(\"visibility\", tnode30);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode31 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode31, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431728\");\n              tnode31.setReference(\"classifier\", SReference.create(\"classifier\", tnode31, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode32 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode32, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431746\");\n                  tnode32.setReference(\"classifier\", SReference.create(\"classifier\", tnode32, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode32 != null) {\n                  tnode31.addChild(\"parameter\", tnode32);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode31 != null) {\n              tnode29.addChild(\"type\", tnode31);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode29 != null) {\n          tnode1.addChild(\"member\", tnode29);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode33 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ConstructorDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode33, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270982\");\n          {\n            final SNode tnode34 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VoidType\");\n            try {\n              environment.nodeCopied(context, tnode34, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270983\");\n            } finally {\n            }\n            if (tnode34 != null) {\n              tnode33.addChild(\"returnType\", tnode34);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode35 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode35, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270984\");\n            } finally {\n            }\n            if (tnode35 != null) {\n              tnode33.addChild(\"visibility\", tnode35);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode36 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode36, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1698302279987270985\");\n              {\n                final SNode tnode37 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode37, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570480\");\n                  {\n                    final SNode tnode38 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode38, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570499\");\n                      {\n                        final SNode tnode39 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                        try {\n                          environment.nodeCopied(context, tnode39, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570482\");\n                          {\n                            final SNode tnode40 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThisExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode40, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570481\");\n                            } finally {\n                            }\n                            if (tnode40 != null) {\n                              tnode39.addChild(\"operand\", tnode40);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode41 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.FieldReferenceOperation\");\n                            try {\n                              environment.nodeCopied(context, tnode41, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570492\");\n                              environment.resolveInTemplateLater(tnode41, \"fieldDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\", \"sourceLanguage\", context);\n                            } finally {\n                            }\n                            if (tnode41 != null) {\n                              tnode39.addChild(\"operation\", tnode41);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode39 != null) {\n                          tnode38.addChild(\"lValue\", tnode39);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode42 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode42, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905150326129\");\n                          environment.resolveInTemplateLater(tnode42, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570437\", \"sourceLanguage\", context);\n                        } finally {\n                        }\n                        if (tnode42 != null) {\n                          tnode38.addChild(\"rValue\", tnode42);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode38 != null) {\n                      tnode37.addChild(\"expression\", tnode38);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode37 != null) {\n                  tnode36.addChild(\"statement\", tnode37);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist43 = null;\n                if (QueriesGenerated.ifMacro_Condition_1820665478710839778(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0c0b0d0b0k0b0c))) {\n                  final SNode tnode44 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode44, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839735\");\n                    {\n                      final SNode tnode45 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode45, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839737\");\n                        {\n                          final SNode tnode46 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode46, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120172655\");\n                            environment.resolveInTemplateLater(tnode46, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a2a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\", \"priorities\", context);\n                          } finally {\n                          }\n                          if (tnode46 != null) {\n                            tnode45.addChild(\"lValue\", tnode46);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode47 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode47, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839741\");\n                            tnode47.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode47, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode47.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode47, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final List<SNode> tlist48 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList48 = QueriesGenerated.sourceNodesQuery_1820665478710839750(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a1a2a1a3a1a01a1a2));\n                              for (SNode itnode48 : loopList48) {\n                                if (itnode48 == null) {\n                                  continue;\n                                }\n                                TemplateContext context48 = context.subContext(null, itnode48);\n                                Collection<SNode> tlist49 = null;\n                                final SNode copySrcInput49 = context48.getInput();\n                                tlist49 = environment.copyNodes(TemplateUtil.singletonList(copySrcInput49), copySrcMacro_g5r92k_b0a0e0c0d0b0c0b0b0b0b0c0b0d0b0k0b0c, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839743\", context48);\n                                if (tlist49 != null) {\n                                  tlist48.addAll(tlist49);\n                                }\n                              }\n                              for (SNode child50 : TemplateUtil.asNotNull(tlist48)) {\n                                tnode47.addChild(\"actualArgument\", child50);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode47 != null) {\n                            tnode45.addChild(\"rValue\", tnode47);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode45 != null) {\n                        tnode44.addChild(\"expression\", tnode45);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist43 = TemplateUtil.singletonList(tnode44);\n                }\n                for (SNode child51 : TemplateUtil.asNotNull(tlist43)) {\n                  tnode36.addChild(\"statement\", child51);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist52 = null;\n                if (QueriesGenerated.ifMacro_Condition_3829836699770777506(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0d0b0d0b0k0b0c))) {\n                  final SNode tnode53 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode53, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777406\");\n                    {\n                      final SNode tnode54 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode54, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777407\");\n                        {\n                          final SNode tnode55 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode55, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120352497\");\n                            environment.resolveInTemplateLater(tnode55, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a3a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\", \"models\", context);\n                          } finally {\n                          }\n                          if (tnode55 != null) {\n                            tnode54.addChild(\"lValue\", tnode55);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode56 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode56, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777409\");\n                            tnode56.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode56, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode56.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode56, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final SNode tnode57 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                              try {\n                                environment.nodeCopied(context, tnode57, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770777504\");\n                                tnode57.setReference(\"classifier\", SReference.create(\"classifier\", tnode57, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                              } finally {\n                              }\n                              if (tnode57 != null) {\n                                tnode56.addChild(\"typeArgument\", tnode57);\n                              }\n                              // TODO validate child \n                            }\n                            {\n                              final List<SNode> tlist58 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList58 = QueriesGenerated.sourceNodesQuery_3829836699771395556(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a4a1a2a1a1a1a1a3a1a3a1a01a1a2));\n                              for (SNode itnode58 : loopList58) {\n                                if (itnode58 == null) {\n                                  continue;\n                                }\n                                TemplateContext context58 = context.subContext(null, itnode58);\n                                final SNode tnode59 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalMethodCall\");\n                                try {\n                                  environment.nodeCopied(context58, tnode59, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770929428\");\n                                  environment.resolveInTemplateLater(tnode59, \"baseMethodDeclaration\", templateNode_g5r92k_c0a1a3a2a4a1a2a1a1a1a1a3a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028932\", \"getTemplateModel\", context58);\n                                  {\n                                    final SNode tnode60 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                    try {\n                                      environment.nodeCopied(context58, tnode60, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770960050\");\n                                      SNodeAccessUtil.setProperty(tnode60, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_3829836699771176869(new PropertyMacroContext(context58, \"model.TemplateModelImpl\", propertyMacro_g5r92k_c0a0c0b0b0c0d0c0e0b0c0b0b0b0b0d0b0d0b0k0b0c))));\n                                    } finally {\n                                    }\n                                    if (tnode60 != null) {\n                                      tnode59.addChild(\"actualArgument\", tnode60);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode59 != null) {\n                                  tlist58.add(tnode59);\n                                }\n                              }\n                              for (SNode child61 : TemplateUtil.asNotNull(tlist58)) {\n                                tnode56.addChild(\"actualArgument\", child61);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode56 != null) {\n                            tnode54.addChild(\"rValue\", tnode56);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode54 != null) {\n                        tnode53.addChild(\"expression\", tnode54);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist52 = TemplateUtil.singletonList(tnode53);\n                }\n                for (SNode child62 : TemplateUtil.asNotNull(tlist52)) {\n                  tnode36.addChild(\"statement\", child62);\n                }\n                // TODO validate child \n              }\n              {\n                Collection<SNode> tlist63 = null;\n                if (QueriesGenerated.ifMacro_Condition_1250389701475344465(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0e0b0d0b0k0b0c))) {\n                  final SNode tnode64 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                  try {\n                    environment.nodeCopied(context, tnode64, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344426\");\n                    {\n                      final SNode tnode65 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                      try {\n                        environment.nodeCopied(context, tnode65, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344430\");\n                        {\n                          final SNode tnode66 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                          try {\n                            environment.nodeCopied(context, tnode66, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120323782\");\n                            environment.resolveInTemplateLater(tnode66, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a4a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\", \"referencedGenerators\", context);\n                          } finally {\n                          }\n                          if (tnode66 != null) {\n                            tnode65.addChild(\"lValue\", tnode66);\n                          }\n                          // TODO validate child \n                        }\n                        {\n                          final SNode tnode67 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                          try {\n                            environment.nodeCopied(context, tnode67, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344440\");\n                            tnode67.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode67, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                            tnode67.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode67, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                            {\n                              final List<SNode> tlist68 = new ArrayList<SNode>();\n                              final Iterable<SNode> loopList68 = QueriesGenerated.sourceNodesQuery_1250389701475344450(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a1a4a1a3a1a01a1a2));\n                              for (SNode itnode68 : loopList68) {\n                                if (itnode68 == null) {\n                                  continue;\n                                }\n                                TemplateContext context68 = context.subContext(null, itnode68);\n                                final SNode tnode69 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                try {\n                                  environment.nodeCopied(context68, tnode69, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344443\");\n                                  SNodeAccessUtil.setProperty(tnode69, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1250389701475344482(new PropertyMacroContext(context68, \"language.namespace/generator.uuid\", propertyMacro_g5r92k_c0a0c0b0d0c0d0b0c0b0b0b0b0e0b0d0b0k0b0c))));\n                                } finally {\n                                }\n                                if (tnode69 != null) {\n                                  tlist68.add(tnode69);\n                                }\n                              }\n                              for (SNode child70 : TemplateUtil.asNotNull(tlist68)) {\n                                tnode67.addChild(\"actualArgument\", child70);\n                              }\n                              // TODO validate child \n                            }\n                            {\n                              final SNode tnode71 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                              try {\n                                environment.nodeCopied(context, tnode71, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346550\");\n                                tnode71.setReference(\"classifier\", SReference.create(\"classifier\", tnode71, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                              } finally {\n                              }\n                              if (tnode71 != null) {\n                                tnode67.addChild(\"typeArgument\", tnode71);\n                              }\n                              // TODO validate child \n                            }\n                          } finally {\n                          }\n                          if (tnode67 != null) {\n                            tnode65.addChild(\"rValue\", tnode67);\n                          }\n                          // TODO validate child \n                        }\n                      } finally {\n                      }\n                      if (tnode65 != null) {\n                        tnode64.addChild(\"expression\", tnode65);\n                      }\n                      // TODO validate child \n                    }\n                  } finally {\n                  }\n                  tlist63 = TemplateUtil.singletonList(tnode64);\n                }\n                for (SNode child72 : TemplateUtil.asNotNull(tlist63)) {\n                  tnode36.addChild(\"statement\", child72);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode73 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode73, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431777\");\n                  {\n                    final SNode tnode74 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode74, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431784\");\n                      {\n                        final SNode tnode75 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode75, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120218113\");\n                          environment.resolveInTemplateLater(tnode75, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a5a1a3a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\", \"usedLanguages\", context);\n                        } finally {\n                        }\n                        if (tnode75 != null) {\n                          tnode74.addChild(\"lValue\", tnode75);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode76 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                        try {\n                          environment.nodeCopied(context, tnode76, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431803\");\n                          tnode76.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode76, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil.asCollection(java.lang.Object...):java.util.Collection\")));\n                          tnode76.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode76, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateUtil\")));\n                          {\n                            final List<SNode> tlist77 = new ArrayList<SNode>();\n                            final Iterable<SNode> loopList77 = QueriesGenerated.sourceNodesQuery_1250389701475431822(new SourceSubstituteMacroNodesContext(context, loopMacroRef_g5r92k_b0a0a1a3a1a2a1a1a1a5a1a3a1a01a1a2));\n                            for (SNode itnode77 : loopList77) {\n                              if (itnode77 == null) {\n                                continue;\n                              }\n                              TemplateContext context77 = context.subContext(null, itnode77);\n                              final SNode tnode78 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                              try {\n                                environment.nodeCopied(context77, tnode78, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431809\");\n                                SNodeAccessUtil.setProperty(tnode78, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_1250389701475432571(new PropertyMacroContext(context77, \"\", propertyMacro_g5r92k_c0a0c0b0d0c0d0b0c0b0b0b0f0b0d0b0k0b0c))));\n                              } finally {\n                              }\n                              if (tnode78 != null) {\n                                tlist77.add(tnode78);\n                              }\n                            }\n                            for (SNode child79 : TemplateUtil.asNotNull(tlist77)) {\n                              tnode76.addChild(\"actualArgument\", child79);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode80 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode80, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475432625\");\n                              tnode80.setReference(\"classifier\", SReference.create(\"classifier\", tnode80, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                            } finally {\n                            }\n                            if (tnode80 != null) {\n                              tnode76.addChild(\"typeArgument\", tnode80);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode76 != null) {\n                          tnode74.addChild(\"rValue\", tnode76);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode74 != null) {\n                      tnode73.addChild(\"expression\", tnode74);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode73 != null) {\n                  tnode36.addChild(\"statement\", tnode73);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode36 != null) {\n              tnode33.addChild(\"body\", tnode36);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode81 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\");\n            try {\n              environment.nodeCopied(context, tnode81, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570437\");\n              SNodeAccessUtil.setProperty(tnode81, \"name\", \"sourceLanguage\");\n              {\n                final SNode tnode82 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode82, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570438\");\n                  environment.resolveInTemplateLater(tnode82, \"classifier\", templateNode_g5r92k_c0a1a1a2a1a4a1a01a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/9020561928507177266\", \"Language\", context);\n                } finally {\n                }\n                if (tnode82 != null) {\n                  tnode81.addChild(\"type\", tnode82);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode81 != null) {\n              tnode33.addChild(\"parameter\", tnode81);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode33 != null) {\n          tnode1.addChild(\"member\", tnode33);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode83 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode83, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646507\");\n          SNodeAccessUtil.setProperty(tnode83, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode83, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode83, \"name\", \"getAlias\");\n          SNodeAccessUtil.setProperty(tnode83, \"isFinal\", \"false\");\n          {\n            final SNode tnode84 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode84, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646508\");\n            } finally {\n            }\n            if (tnode84 != null) {\n              tnode83.addChild(\"visibility\", tnode84);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode85 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringType\");\n            try {\n              environment.nodeCopied(context, tnode85, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646534\");\n            } finally {\n            }\n            if (tnode85 != null) {\n              tnode83.addChild(\"returnType\", tnode85);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode86 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode86, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646510\");\n              {\n                final SNode tnode87 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode87, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646525\");\n                  {\n                    final SNode tnode88 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                    try {\n                      environment.nodeCopied(context, tnode88, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646533\");\n                      SNodeAccessUtil.setProperty(tnode88, \"value\", TemplateUtil.asString(QueriesGenerated.propertyMacro_GetPropertyValue_5102832340571646536(new PropertyMacroContext(context, \"\", propertyMacro_g5r92k_c0a0c0b0b0b0b0b0b0h0b0l0b0c))));\n                    } finally {\n                    }\n                    if (tnode88 != null) {\n                      tnode87.addChild(\"expression\", tnode88);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode87 != null) {\n                  tnode86.addChild(\"statement\", tnode87);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode86 != null) {\n              tnode83.addChild(\"body\", tnode86);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode89 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode89, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551109\");\n              tnode89.setReference(\"annotation\", SReference.create(\"annotation\", tnode89, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode89 != null) {\n              tnode83.addChild(\"annotation\", tnode89);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode83 != null) {\n          tnode1.addChild(\"member\", tnode83);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode90 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode90, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646511\");\n          SNodeAccessUtil.setProperty(tnode90, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode90, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode90, \"name\", \"getModels\");\n          SNodeAccessUtil.setProperty(tnode90, \"isFinal\", \"false\");\n          {\n            final SNode tnode91 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode91, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646512\");\n            } finally {\n            }\n            if (tnode91 != null) {\n              tnode90.addChild(\"visibility\", tnode91);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode92 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode92, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646513\");\n              tnode92.setReference(\"classifier\", SReference.create(\"classifier\", tnode92, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode93 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode93, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646514\");\n                  tnode93.setReference(\"classifier\", SReference.create(\"classifier\", tnode93, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                } finally {\n                }\n                if (tnode93 != null) {\n                  tnode92.addChild(\"parameter\", tnode93);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode92 != null) {\n              tnode90.addChild(\"returnType\", tnode92);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode94 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode94, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646515\");\n              {\n                final SNode tnode95 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode95, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919461205\");\n                  {\n                    Collection<SNode> tlist96 = null;\n                    if (QueriesGenerated.ifMacro_Condition_6655394244919461209(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0m0b0c))) {\n                      final SNode tnode97 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode97, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120187445\");\n                        environment.resolveInTemplateLater(tnode97, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a21a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919403406\", \"models\", context);\n                      } finally {\n                      }\n                      tlist96 = TemplateUtil.singletonList(tnode97);\n                    } else {\n                      final SNode tnode98 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode98, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/6655394244919461219\");\n                      } finally {\n                      }\n                      tlist96 = TemplateUtil.singletonList(tnode98);\n                    }\n                    for (SNode child99 : TemplateUtil.asNotNull(tlist96)) {\n                      tnode95.addChild(\"expression\", child99);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode95 != null) {\n                  tnode94.addChild(\"statement\", tnode95);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode94 != null) {\n              tnode90.addChild(\"body\", tnode94);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode100 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode100, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551115\");\n              tnode100.setReference(\"annotation\", SReference.create(\"annotation\", tnode100, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode100 != null) {\n              tnode90.addChild(\"annotation\", tnode100);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode90 != null) {\n          tnode1.addChild(\"member\", tnode90);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode101 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode101, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646516\");\n          SNodeAccessUtil.setProperty(tnode101, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode101, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode101, \"name\", \"getPriorities\");\n          SNodeAccessUtil.setProperty(tnode101, \"isFinal\", \"false\");\n          {\n            final SNode tnode102 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode102, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646517\");\n            } finally {\n            }\n            if (tnode102 != null) {\n              tnode101.addChild(\"visibility\", tnode102);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode103 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode103, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646518\");\n              tnode103.setReference(\"classifier\", SReference.create(\"classifier\", tnode103, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode104 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode104, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807074\");\n                  tnode104.setReference(\"classifier\", SReference.create(\"classifier\", tnode104, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateMappingPriorityRule\")));\n                } finally {\n                }\n                if (tnode104 != null) {\n                  tnode103.addChild(\"parameter\", tnode104);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode103 != null) {\n              tnode101.addChild(\"returnType\", tnode103);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode105 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode105, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646520\");\n              {\n                final SNode tnode106 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode106, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839794\");\n                  {\n                    Collection<SNode> tlist107 = null;\n                    if (QueriesGenerated.ifMacro_Condition_1820665478710839798(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0n0b0c))) {\n                      final SNode tnode108 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode108, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120198611\");\n                        environment.resolveInTemplateLater(tnode108, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a31a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710807075\", \"priorities\", context);\n                      } finally {\n                      }\n                      tlist107 = TemplateUtil.singletonList(tnode108);\n                    } else {\n                      final SNode tnode109 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode109, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1820665478710839814\");\n                      } finally {\n                      }\n                      tlist107 = TemplateUtil.singletonList(tnode109);\n                    }\n                    for (SNode child110 : TemplateUtil.asNotNull(tlist107)) {\n                      tnode106.addChild(\"expression\", child110);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode106 != null) {\n                  tnode105.addChild(\"statement\", tnode106);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode105 != null) {\n              tnode101.addChild(\"body\", tnode105);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode111 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode111, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551112\");\n              tnode111.setReference(\"annotation\", SReference.create(\"annotation\", tnode111, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode111 != null) {\n              tnode101.addChild(\"annotation\", tnode111);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode101 != null) {\n          tnode1.addChild(\"member\", tnode101);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode112 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode112, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646521\");\n          SNodeAccessUtil.setProperty(tnode112, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode112, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode112, \"name\", \"getReference\");\n          SNodeAccessUtil.setProperty(tnode112, \"isFinal\", \"false\");\n          {\n            final SNode tnode113 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode113, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646522\");\n            } finally {\n            }\n            if (tnode113 != null) {\n              tnode112.addChild(\"visibility\", tnode113);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode114 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode114, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646523\");\n              tnode114.setReference(\"classifier\", SReference.create(\"classifier\", tnode114, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~SModuleReference\")));\n            } finally {\n            }\n            if (tnode114 != null) {\n              tnode112.addChild(\"returnType\", tnode114);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode115 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode115, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646524\");\n              {\n                final SNode tnode116 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode116, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752227166\");\n                  {\n                    final SNode tnode117 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode117, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752278543\");\n                      {\n                        final SNode tnode118 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                        try {\n                          environment.nodeCopied(context, tnode118, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752252693\");\n                          tnode118.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode118, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade.getInstance():org.jetbrains.mps.openapi.persistence.PersistenceFacade\")));\n                          tnode118.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode118, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade\")));\n                        } finally {\n                        }\n                        if (tnode118 != null) {\n                          tnode117.addChild(\"operand\", tnode118);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode119 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                        try {\n                          environment.nodeCopied(context, tnode119, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752307194\");\n                          tnode119.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode119, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.persistence(MPS.OpenAPI/org.jetbrains.mps.openapi.persistence@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~PersistenceFacade.createModuleReference(java.lang.String):org.jetbrains.mps.openapi.module.SModuleReference\")));\n                          {\n                            final SNode tnode120 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                            try {\n                              environment.nodeCopied(context, tnode120, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752332768\");\n                              environment.resolveInTemplateLater(tnode120, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a1a1a7a1a41a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7633657384060768604\", \"MODULE_REF\", context);\n                            } finally {\n                            }\n                            if (tnode120 != null) {\n                              tnode119.addChild(\"actualArgument\", tnode120);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode119 != null) {\n                          tnode117.addChild(\"operation\", tnode119);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode117 != null) {\n                      tnode116.addChild(\"expression\", tnode117);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode116 != null) {\n                  tnode115.addChild(\"statement\", tnode116);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode115 != null) {\n              tnode112.addChild(\"body\", tnode115);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode121 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode121, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551110\");\n              tnode121.setReference(\"annotation\", SReference.create(\"annotation\", tnode121, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode121 != null) {\n              tnode112.addChild(\"annotation\", tnode121);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode112 != null) {\n          tnode1.addChild(\"member\", tnode112);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode122 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode122, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280636\");\n          SNodeAccessUtil.setProperty(tnode122, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode122, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode122, \"name\", \"getUsedLanguages\");\n          SNodeAccessUtil.setProperty(tnode122, \"isFinal\", \"false\");\n          {\n            final SNode tnode123 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode123, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280637\");\n            } finally {\n            }\n            if (tnode123 != null) {\n              tnode122.addChild(\"visibility\", tnode123);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode124 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode124, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280638\");\n              tnode124.setReference(\"classifier\", SReference.create(\"classifier\", tnode124, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode125 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode125, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280639\");\n                  tnode125.setReference(\"classifier\", SReference.create(\"classifier\", tnode125, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode125 != null) {\n                  tnode124.addChild(\"parameter\", tnode125);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode124 != null) {\n              tnode122.addChild(\"returnType\", tnode124);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode126 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode126, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280640\");\n              {\n                final SNode tnode127 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode127, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280646\");\n                  {\n                    final SNode tnode128 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                    try {\n                      environment.nodeCopied(context, tnode128, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120309782\");\n                      environment.resolveInTemplateLater(tnode128, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a7a1a51a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475431715\", \"usedLanguages\", context);\n                    } finally {\n                    }\n                    if (tnode128 != null) {\n                      tnode127.addChild(\"expression\", tnode128);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode127 != null) {\n                  tnode126.addChild(\"statement\", tnode127);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode126 != null) {\n              tnode122.addChild(\"body\", tnode126);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode129 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode129, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551111\");\n              tnode129.setReference(\"annotation\", SReference.create(\"annotation\", tnode129, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode129 != null) {\n              tnode122.addChild(\"annotation\", tnode129);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode122 != null) {\n          tnode1.addChild(\"member\", tnode122);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode130 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode130, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570445\");\n          SNodeAccessUtil.setProperty(tnode130, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode130, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode130, \"name\", \"getSourceLanguage\");\n          SNodeAccessUtil.setProperty(tnode130, \"isFinal\", \"false\");\n          {\n            final SNode tnode131 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode131, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570446\");\n            } finally {\n            }\n            if (tnode131 != null) {\n              tnode130.addChild(\"visibility\", tnode131);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode132 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode132, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570447\");\n              tnode132.setReference(\"classifier\", SReference.create(\"classifier\", tnode132, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel.language(MPS.Core/jetbrains.mps.smodel.language@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~LanguageRuntime\")));\n            } finally {\n            }\n            if (tnode132 != null) {\n              tnode130.addChild(\"returnType\", tnode132);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode133 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode133, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570448\");\n              {\n                final SNode tnode134 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode134, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570449\");\n                  {\n                    final SNode tnode135 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                    try {\n                      environment.nodeCopied(context, tnode135, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120187371\");\n                      environment.resolveInTemplateLater(tnode135, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a7a1a61a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/8847459826362570457\", \"sourceLanguage\", context);\n                    } finally {\n                    }\n                    if (tnode135 != null) {\n                      tnode134.addChild(\"expression\", tnode135);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode134 != null) {\n                  tnode133.addChild(\"statement\", tnode134);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode133 != null) {\n              tnode130.addChild(\"body\", tnode133);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode136 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode136, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551113\");\n              tnode136.setReference(\"annotation\", SReference.create(\"annotation\", tnode136, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode136 != null) {\n              tnode130.addChild(\"annotation\", tnode136);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode130 != null) {\n          tnode1.addChild(\"member\", tnode130);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode137 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode137, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280641\");\n          SNodeAccessUtil.setProperty(tnode137, \"isDeprecated\", \"false\");\n          SNodeAccessUtil.setProperty(tnode137, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode137, \"name\", \"getReferencedModules\");\n          SNodeAccessUtil.setProperty(tnode137, \"isFinal\", \"false\");\n          {\n            final SNode tnode138 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PublicVisibility\");\n            try {\n              environment.nodeCopied(context, tnode138, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280642\");\n            } finally {\n            }\n            if (tnode138 != null) {\n              tnode137.addChild(\"visibility\", tnode138);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode139 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode139, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280643\");\n              tnode139.setReference(\"classifier\", SReference.create(\"classifier\", tnode139, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.util(JDK/java.util@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Collection\")));\n              {\n                final SNode tnode140 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode140, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475346537\");\n                  tnode140.setReference(\"classifier\", SReference.create(\"classifier\", tnode140, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode140 != null) {\n                  tnode139.addChild(\"parameter\", tnode140);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode139 != null) {\n              tnode137.addChild(\"returnType\", tnode139);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode141 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode141, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280645\");\n              {\n                final SNode tnode142 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                try {\n                  environment.nodeCopied(context, tnode142, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475280648\");\n                  {\n                    Collection<SNode> tlist143 = null;\n                    if (QueriesGenerated.ifMacro_Condition_1250389701475344489(new IfMacroContext(context, ifMacroRef_g5r92k_b0a0b0b0b0b0b0h0b0r0b0c))) {\n                      final SNode tnode144 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                      try {\n                        environment.nodeCopied(context, tnode144, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3021153905120268781\");\n                        environment.resolveInTemplateLater(tnode144, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a1a7a1a71a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475281180\", \"referencedGenerators\", context);\n                      } finally {\n                      }\n                      tlist143 = TemplateUtil.singletonList(tnode144);\n                    } else {\n                      final SNode tnode145 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                      try {\n                        environment.nodeCopied(context, tnode145, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1250389701475344493\");\n                      } finally {\n                      }\n                      tlist143 = TemplateUtil.singletonList(tnode145);\n                    }\n                    for (SNode child146 : TemplateUtil.asNotNull(tlist143)) {\n                      tnode142.addChild(\"expression\", child146);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode142 != null) {\n                  tnode141.addChild(\"statement\", tnode142);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode141 != null) {\n              tnode137.addChild(\"body\", tnode141);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode147 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AnnotationInstance\");\n            try {\n              environment.nodeCopied(context, tnode147, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752551114\");\n              tnode147.setReference(\"annotation\", SReference.create(\"annotation\", tnode147, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Override\")));\n            } finally {\n            }\n            if (tnode147 != null) {\n              tnode137.addChild(\"annotation\", tnode147);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode137 != null) {\n          tnode1.addChild(\"member\", tnode137);\n        }\n        // TODO validate child \n      }\n      {\n        final SNode tnode148 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\");\n        try {\n          environment.nodeCopied(context, tnode148, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028932\");\n          SNodeAccessUtil.setProperty(tnode148, \"isAbstract\", \"false\");\n          SNodeAccessUtil.setProperty(tnode148, \"name\", \"getTemplateModel\");\n          SNodeAccessUtil.setProperty(tnode148, \"isSynchronized\", \"false\");\n          SNodeAccessUtil.setProperty(tnode148, \"isFinal\", \"false\");\n          {\n            final SNode tnode149 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n            try {\n              environment.nodeCopied(context, tnode149, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768028935\");\n              {\n                final SNode tnode150 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\");\n                try {\n                  environment.nodeCopied(context, tnode150, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401081\");\n                  {\n                    final SNode tnode151 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                    try {\n                      environment.nodeCopied(context, tnode151, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\");\n                      SNodeAccessUtil.setProperty(tnode151, \"name\", \"module\");\n                      {\n                        final SNode tnode152 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                        try {\n                          environment.nodeCopied(context, tnode152, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565460366\");\n                          tnode152.setReference(\"classifier\", SReference.create(\"classifier\", tnode152, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule\")));\n                        } finally {\n                        }\n                        if (tnode152 != null) {\n                          tnode151.addChild(\"type\", tnode152);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode153 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CastExpression\");\n                        try {\n                          environment.nodeCopied(context, tnode153, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565461988\");\n                          {\n                            final SNode tnode154 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode154, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752386838\");\n                              {\n                                final SNode tnode155 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                                try {\n                                  environment.nodeCopied(context, tnode155, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752440665\");\n                                  tnode155.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode155, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade\")));\n                                  tnode155.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode155, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade.getInstance():jetbrains.mps.smodel.ModuleRepositoryFacade\")));\n                                } finally {\n                                }\n                                if (tnode155 != null) {\n                                  tnode154.addChild(\"operand\", tnode155);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode156 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                try {\n                                  environment.nodeCopied(context, tnode156, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752471129\");\n                                  tnode156.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode156, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.smodel(MPS.Core/jetbrains.mps.smodel@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ModuleRepositoryFacade.getModule(org.jetbrains.mps.openapi.module.SModuleReference):org.jetbrains.mps.openapi.module.SModule\")));\n                                  {\n                                    final SNode tnode157 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalMethodCall\");\n                                    try {\n                                      environment.nodeCopied(context, tnode157, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/4081282727752497140\");\n                                      environment.resolveInTemplateLater(tnode157, \"baseMethodDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a3a1a1a1a1a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/5102832340571646521\", \"getReference\", context);\n                                    } finally {\n                                    }\n                                    if (tnode157 != null) {\n                                      tnode156.addChild(\"actualArgument\", tnode157);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode156 != null) {\n                                  tnode154.addChild(\"operation\", tnode156);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode154 != null) {\n                              tnode153.addChild(\"expression\", tnode154);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode158 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode158, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565461989\");\n                              tnode158.setReference(\"classifier\", SReference.create(\"classifier\", tnode158, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule\")));\n                            } finally {\n                            }\n                            if (tnode158 != null) {\n                              tnode153.addChild(\"type\", tnode158);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode153 != null) {\n                          tnode151.addChild(\"initializer\", tnode153);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode151 != null) {\n                      tnode150.addChild(\"localVariableDeclaration\", tnode151);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode150 != null) {\n                  tnode149.addChild(\"statement\", tnode150);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode159 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\");\n                try {\n                  environment.nodeCopied(context, tnode159, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992422\");\n                  {\n                    final SNode tnode160 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                    try {\n                      environment.nodeCopied(context, tnode160, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\");\n                      SNodeAccessUtil.setProperty(tnode160, \"name\", \"clazz\");\n                      {\n                        final SNode tnode161 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                        try {\n                          environment.nodeCopied(context, tnode161, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992420\");\n                          tnode161.setReference(\"classifier\", SReference.create(\"classifier\", tnode161, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class\")));\n                          {\n                            final SNode tnode162 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode162, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769023268\");\n                              tnode162.setReference(\"classifier\", SReference.create(\"classifier\", tnode162, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                            } finally {\n                            }\n                            if (tnode162 != null) {\n                              tnode161.addChild(\"parameter\", tnode162);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode161 != null) {\n                          tnode160.addChild(\"type\", tnode161);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode163 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode163, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565533117\");\n                        } finally {\n                        }\n                        if (tnode163 != null) {\n                          tnode160.addChild(\"initializer\", tnode163);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode160 != null) {\n                      tnode159.addChild(\"localVariableDeclaration\", tnode160);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode159 != null) {\n                  tnode149.addChild(\"statement\", tnode159);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode164 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.IfStatement\");\n                try {\n                  environment.nodeCopied(context, tnode164, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565474852\");\n                  {\n                    final SNode tnode165 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode165, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565474855\");\n                      {\n                        final SNode tnode166 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.TryCatchStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode166, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223993\");\n                          {\n                            final SNode tnode167 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                            try {\n                              environment.nodeCopied(context, tnode167, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223994\");\n                              {\n                                final SNode tnode168 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ExpressionStatement\");\n                                try {\n                                  environment.nodeCopied(context, tnode168, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505912\");\n                                  {\n                                    final SNode tnode169 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.AssignmentExpression\");\n                                    try {\n                                      environment.nodeCopied(context, tnode169, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505914\");\n                                      {\n                                        final SNode tnode170 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CastExpression\");\n                                        try {\n                                          environment.nodeCopied(context, tnode170, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565329875\");\n                                          {\n                                            final SNode tnode171 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                                            try {\n                                              environment.nodeCopied(context, tnode171, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565331658\");\n                                              tnode171.setReference(\"classifier\", SReference.create(\"classifier\", tnode171, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class\")));\n                                              {\n                                                final SNode tnode172 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                                                try {\n                                                  environment.nodeCopied(context, tnode172, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565332714\");\n                                                  tnode172.setReference(\"classifier\", SReference.create(\"classifier\", tnode172, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n                                                } finally {\n                                                }\n                                                if (tnode172 != null) {\n                                                  tnode171.addChild(\"parameter\", tnode172);\n                                                }\n                                                // TODO validate child \n                                              }\n                                            } finally {\n                                            }\n                                            if (tnode171 != null) {\n                                              tnode170.addChild(\"type\", tnode171);\n                                            }\n                                            // TODO validate child \n                                          }\n                                          {\n                                            final SNode tnode173 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                                            try {\n                                              environment.nodeCopied(context, tnode173, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565418562\");\n                                              {\n                                                final SNode tnode174 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                                try {\n                                                  environment.nodeCopied(context, tnode174, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565418022\");\n                                                  environment.resolveInTemplateLater(tnode174, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a2a1a1a1a1a1a1a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\", \"module\", context);\n                                                } finally {\n                                                }\n                                                if (tnode174 != null) {\n                                                  tnode173.addChild(\"operand\", tnode174);\n                                                }\n                                                // TODO validate child \n                                              }\n                                              {\n                                                final SNode tnode175 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                                try {\n                                                  environment.nodeCopied(context, tnode175, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565419407\");\n                                                  tnode175.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode175, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.module(MPS.Core/jetbrains.mps.module@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ReloadableModule.getClass(java.lang.String):java.lang.Class\")));\n                                                  {\n                                                    final SNode tnode176 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                                    try {\n                                                      environment.nodeCopied(context, tnode176, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565420853\");\n                                                      environment.resolveInTemplateLater(tnode176, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a2a1a1a1a1a1a1a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\", \"modelName\", context);\n                                                    } finally {\n                                                    }\n                                                    if (tnode176 != null) {\n                                                      tnode175.addChild(\"actualArgument\", tnode176);\n                                                    }\n                                                    // TODO validate child \n                                                  }\n                                                } finally {\n                                                }\n                                                if (tnode175 != null) {\n                                                  tnode173.addChild(\"operation\", tnode175);\n                                                }\n                                                // TODO validate child \n                                              }\n                                            } finally {\n                                            }\n                                            if (tnode173 != null) {\n                                              tnode170.addChild(\"expression\", tnode173);\n                                            }\n                                            // TODO validate child \n                                          }\n                                        } finally {\n                                        }\n                                        if (tnode170 != null) {\n                                          tnode169.addChild(\"rValue\", tnode170);\n                                        }\n                                        // TODO validate child \n                                      }\n                                      {\n                                        final SNode tnode177 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode177, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565505918\");\n                                          environment.resolveInTemplateLater(tnode177, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                                        } finally {\n                                        }\n                                        if (tnode177 != null) {\n                                          tnode169.addChild(\"lValue\", tnode177);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode169 != null) {\n                                      tnode168.addChild(\"expression\", tnode169);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode168 != null) {\n                                  tnode167.addChild(\"statement\", tnode168);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode167 != null) {\n                              tnode166.addChild(\"body\", tnode167);\n                            }\n                            // TODO validate child \n                          }\n                          {\n                            final SNode tnode178 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CatchClause\");\n                            try {\n                              environment.nodeCopied(context, tnode178, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223989\");\n                              {\n                                final SNode tnode179 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                                try {\n                                  environment.nodeCopied(context, tnode179, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223990\");\n                                  {\n                                    final SNode tnode180 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                                    try {\n                                      environment.nodeCopied(context, tnode180, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139257512\");\n                                      {\n                                        final SNode tnode181 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.GenericNewExpression\");\n                                        try {\n                                          environment.nodeCopied(context, tnode181, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139258033\");\n                                          {\n                                            final SNode tnode182 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassCreator\");\n                                            try {\n                                              environment.nodeCopied(context, tnode182, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139261360\");\n                                              tnode182.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode182, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~IllegalStateException.<init>(java.lang.String,java.lang.Throwable)\")));\n                                              {\n                                                final SNode tnode183 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                                try {\n                                                  environment.nodeCopied(context, tnode183, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139262165\");\n                                                  SNodeAccessUtil.setProperty(tnode183, \"value\", \"\");\n                                                } finally {\n                                                }\n                                                if (tnode183 != null) {\n                                                  tnode182.addChild(\"actualArgument\", tnode183);\n                                                }\n                                                // TODO validate child \n                                              }\n                                              {\n                                                final SNode tnode184 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                                try {\n                                                  environment.nodeCopied(context, tnode184, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139264188\");\n                                                  environment.resolveInTemplateLater(tnode184, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a3a1a1a1a1a1a1a1a1a1a2a1a1a1a1a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223991\", \"e\", context);\n                                                } finally {\n                                                }\n                                                if (tnode184 != null) {\n                                                  tnode182.addChild(\"actualArgument\", tnode184);\n                                                }\n                                                // TODO validate child \n                                              }\n                                            } finally {\n                                            }\n                                            if (tnode182 != null) {\n                                              tnode181.addChild(\"creator\", tnode182);\n                                            }\n                                            // TODO validate child \n                                          }\n                                        } finally {\n                                        }\n                                        if (tnode181 != null) {\n                                          tnode180.addChild(\"throwable\", tnode181);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode180 != null) {\n                                      tnode179.addChild(\"statement\", tnode180);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode179 != null) {\n                                  tnode178.addChild(\"catchBody\", tnode179);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode185 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                                try {\n                                  environment.nodeCopied(context, tnode185, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223991\");\n                                  SNodeAccessUtil.setProperty(tnode185, \"name\", \"e\");\n                                  {\n                                    final SNode tnode186 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                                    try {\n                                      environment.nodeCopied(context, tnode186, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7711149897139223992\");\n                                      tnode186.setReference(\"classifier\", SReference.create(\"classifier\", tnode186, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~ClassNotFoundException\")));\n                                    } finally {\n                                    }\n                                    if (tnode186 != null) {\n                                      tnode185.addChild(\"type\", tnode186);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode185 != null) {\n                                  tnode178.addChild(\"throwable\", tnode185);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode178 != null) {\n                              tnode166.addChild(\"catchClause\", tnode178);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode166 != null) {\n                          tnode165.addChild(\"statement\", tnode166);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode165 != null) {\n                      tnode164.addChild(\"ifTrue\", tnode165);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode187 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NotEqualsExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode187, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565490205\");\n                      {\n                        final SNode tnode188 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode188, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565491121\");\n                        } finally {\n                        }\n                        if (tnode188 != null) {\n                          tnode187.addChild(\"rightExpression\", tnode188);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode189 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode189, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565489261\");\n                          environment.resolveInTemplateLater(tnode189, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a3a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/1224037546565401082\", \"module\", context);\n                        } finally {\n                        }\n                        if (tnode189 != null) {\n                          tnode187.addChild(\"leftExpression\", tnode189);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode187 != null) {\n                      tnode164.addChild(\"condition\", tnode187);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode164 != null) {\n                  tnode149.addChild(\"statement\", tnode164);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode190 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.IfStatement\");\n                try {\n                  environment.nodeCopied(context, tnode190, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153325762\");\n                  {\n                    final SNode tnode191 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode191, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153325765\");\n                      {\n                        final SNode tnode192 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode192, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153400884\");\n                          {\n                            final SNode tnode193 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.GenericNewExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode193, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153401352\");\n                              {\n                                final SNode tnode194 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassCreator\");\n                                try {\n                                  environment.nodeCopied(context, tnode194, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153455683\");\n                                  tnode194.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode194, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~IllegalStateException.<init>(java.lang.String)\")));\n                                  {\n                                    final SNode tnode195 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StaticMethodCall\");\n                                    try {\n                                      environment.nodeCopied(context, tnode195, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153475042\");\n                                      tnode195.setReference(\"classConcept\", SReference.create(\"classConcept\", tnode195, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                                      tnode195.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode195, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String.format(java.lang.String,java.lang.Object...):java.lang.String\")));\n                                      {\n                                        final SNode tnode196 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StringLiteral\");\n                                        try {\n                                          environment.nodeCopied(context, tnode196, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153494863\");\n                                          SNodeAccessUtil.setProperty(tnode196, \"value\", \"Failed to obtain generator runtime class for model %s\");\n                                        } finally {\n                                        }\n                                        if (tnode196 != null) {\n                                          tnode195.addChild(\"actualArgument\", tnode196);\n                                        }\n                                        // TODO validate child \n                                      }\n                                      {\n                                        final SNode tnode197 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode197, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153523313\");\n                                          environment.resolveInTemplateLater(tnode197, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a4a1a2a1a1a1a1a1a1a1a1a1a4a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\", \"modelName\", context);\n                                        } finally {\n                                        }\n                                        if (tnode197 != null) {\n                                          tnode195.addChild(\"actualArgument\", tnode197);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode195 != null) {\n                                      tnode194.addChild(\"actualArgument\", tnode195);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode194 != null) {\n                                  tnode193.addChild(\"creator\", tnode194);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode193 != null) {\n                              tnode192.addChild(\"throwable\", tnode193);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode192 != null) {\n                          tnode191.addChild(\"statement\", tnode192);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode191 != null) {\n                      tnode190.addChild(\"ifTrue\", tnode191);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode198 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.EqualsExpression\");\n                    try {\n                      environment.nodeCopied(context, tnode198, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153375317\");\n                      {\n                        final SNode tnode199 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.NullLiteral\");\n                        try {\n                          environment.nodeCopied(context, tnode199, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153382461\");\n                        } finally {\n                        }\n                        if (tnode199 != null) {\n                          tnode198.addChild(\"rightExpression\", tnode199);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode200 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                        try {\n                          environment.nodeCopied(context, tnode200, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153361721\");\n                          environment.resolveInTemplateLater(tnode200, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a4a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                        } finally {\n                        }\n                        if (tnode200 != null) {\n                          tnode198.addChild(\"leftExpression\", tnode200);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode198 != null) {\n                      tnode190.addChild(\"condition\", tnode198);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode190 != null) {\n                  tnode149.addChild(\"statement\", tnode190);\n                }\n                // TODO validate child \n              }\n              {\n                final SNode tnode201 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.TryCatchStatement\");\n                try {\n                  environment.nodeCopied(context, tnode201, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998096\");\n                  {\n                    final SNode tnode202 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                    try {\n                      environment.nodeCopied(context, tnode202, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998098\");\n                      {\n                        final SNode tnode203 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ReturnStatement\");\n                        try {\n                          environment.nodeCopied(context, tnode203, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770092637\");\n                          {\n                            final SNode tnode204 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                            try {\n                              environment.nodeCopied(context, tnode204, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770271856\");\n                              {\n                                final SNode tnode205 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                try {\n                                  environment.nodeCopied(context, tnode205, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770339620\");\n                                  tnode205.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode205, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang.reflect(JDK/java.lang.reflect@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Constructor.newInstance(java.lang.Object...):java.lang.Object\")));\n                                  {\n                                    final SNode tnode206 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThisExpression\");\n                                    try {\n                                      environment.nodeCopied(context, tnode206, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770372519\");\n                                    } finally {\n                                    }\n                                    if (tnode206 != null) {\n                                      tnode205.addChild(\"actualArgument\", tnode206);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode205 != null) {\n                                  tnode204.addChild(\"operation\", tnode205);\n                                }\n                                // TODO validate child \n                              }\n                              {\n                                final SNode tnode207 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.DotExpression\");\n                                try {\n                                  environment.nodeCopied(context, tnode207, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770125445\");\n                                  {\n                                    final SNode tnode208 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\");\n                                    try {\n                                      environment.nodeCopied(context, tnode208, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770187459\");\n                                      tnode208.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode208, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Class.getConstructor(java.lang.Class...):java.lang.reflect.Constructor\")));\n                                      {\n                                        final SNode tnode209 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierClassExpression\");\n                                        try {\n                                          environment.nodeCopied(context, tnode209, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3886626959987239845\");\n                                          tnode209.setReference(\"classifier\", SReference.create(\"classifier\", tnode209, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModule\")));\n                                        } finally {\n                                        }\n                                        if (tnode209 != null) {\n                                          tnode208.addChild(\"actualArgument\", tnode209);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode208 != null) {\n                                      tnode207.addChild(\"operation\", tnode208);\n                                    }\n                                    // TODO validate child \n                                  }\n                                  {\n                                    final SNode tnode210 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                    try {\n                                      environment.nodeCopied(context, tnode210, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699770123776\");\n                                      environment.resolveInTemplateLater(tnode210, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a2a1a1a1a1a1a1a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768992423\", \"clazz\", context);\n                                    } finally {\n                                    }\n                                    if (tnode210 != null) {\n                                      tnode207.addChild(\"operand\", tnode210);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode207 != null) {\n                                  tnode204.addChild(\"operand\", tnode207);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode204 != null) {\n                              tnode203.addChild(\"expression\", tnode204);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode203 != null) {\n                          tnode202.addChild(\"statement\", tnode203);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode202 != null) {\n                      tnode201.addChild(\"body\", tnode202);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode211 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CatchClause\");\n                    try {\n                      environment.nodeCopied(context, tnode211, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998099\");\n                      {\n                        final SNode tnode212 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                        try {\n                          environment.nodeCopied(context, tnode212, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998101\");\n                          SNodeAccessUtil.setProperty(tnode212, \"name\", \"ex\");\n                          {\n                            final SNode tnode213 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode213, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153219588\");\n                              tnode213.setReference(\"classifier\", SReference.create(\"classifier\", tnode213, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~RuntimeException\")));\n                            } finally {\n                            }\n                            if (tnode213 != null) {\n                              tnode212.addChild(\"type\", tnode213);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode212 != null) {\n                          tnode211.addChild(\"throwable\", tnode212);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode214 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                        try {\n                          environment.nodeCopied(context, tnode214, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998105\");\n                          {\n                            final SNode tnode215 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                            try {\n                              environment.nodeCopied(context, tnode215, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153283021\");\n                              {\n                                final SNode tnode216 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                try {\n                                  environment.nodeCopied(context, tnode216, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153283657\");\n                                  environment.resolveInTemplateLater(tnode216, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a1a1a1a1a2a1a2a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769998101\", \"ex\", context);\n                                } finally {\n                                }\n                                if (tnode216 != null) {\n                                  tnode215.addChild(\"throwable\", tnode216);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode215 != null) {\n                              tnode214.addChild(\"statement\", tnode215);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode214 != null) {\n                          tnode211.addChild(\"catchBody\", tnode214);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode211 != null) {\n                      tnode201.addChild(\"catchClause\", tnode211);\n                    }\n                    // TODO validate child \n                  }\n                  {\n                    final SNode tnode217 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.CatchClause\");\n                    try {\n                      environment.nodeCopied(context, tnode217, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156725\");\n                      {\n                        final SNode tnode218 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\");\n                        try {\n                          environment.nodeCopied(context, tnode218, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156726\");\n                          SNodeAccessUtil.setProperty(tnode218, \"name\", \"ex\");\n                          {\n                            final SNode tnode219 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                            try {\n                              environment.nodeCopied(context, tnode219, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153191842\");\n                              tnode219.setReference(\"classifier\", SReference.create(\"classifier\", tnode219, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~Exception\")));\n                            } finally {\n                            }\n                            if (tnode219 != null) {\n                              tnode218.addChild(\"type\", tnode219);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode218 != null) {\n                          tnode217.addChild(\"throwable\", tnode218);\n                        }\n                        // TODO validate child \n                      }\n                      {\n                        final SNode tnode220 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.StatementList\");\n                        try {\n                          environment.nodeCopied(context, tnode220, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156728\");\n                          {\n                            final SNode tnode221 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ThrowStatement\");\n                            try {\n                              environment.nodeCopied(context, tnode221, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215434\");\n                              {\n                                final SNode tnode222 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.GenericNewExpression\");\n                                try {\n                                  environment.nodeCopied(context, tnode222, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215435\");\n                                  {\n                                    final SNode tnode223 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassCreator\");\n                                    try {\n                                      environment.nodeCopied(context, tnode223, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153215436\");\n                                      tnode223.setReference(\"baseMethodDeclaration\", SReference.create(\"baseMethodDeclaration\", tnode223, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~RuntimeException.<init>(java.lang.Throwable)\")));\n                                      {\n                                        final SNode tnode224 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.VariableReference\");\n                                        try {\n                                          environment.nodeCopied(context, tnode224, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153218012\");\n                                          environment.resolveInTemplateLater(tnode224, \"variableDeclaration\", templateNode_g5r92k_c0a1a1a2a1a1a1a1a1a1a1a2a1a3a1a5a1a5a1a81a1a2, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/7106514738153156726\", \"ex\", context);\n                                        } finally {\n                                        }\n                                        if (tnode224 != null) {\n                                          tnode223.addChild(\"actualArgument\", tnode224);\n                                        }\n                                        // TODO validate child \n                                      }\n                                    } finally {\n                                    }\n                                    if (tnode223 != null) {\n                                      tnode222.addChild(\"creator\", tnode223);\n                                    }\n                                    // TODO validate child \n                                  }\n                                } finally {\n                                }\n                                if (tnode222 != null) {\n                                  tnode221.addChild(\"throwable\", tnode222);\n                                }\n                                // TODO validate child \n                              }\n                            } finally {\n                            }\n                            if (tnode221 != null) {\n                              tnode220.addChild(\"statement\", tnode221);\n                            }\n                            // TODO validate child \n                          }\n                        } finally {\n                        }\n                        if (tnode220 != null) {\n                          tnode217.addChild(\"catchBody\", tnode220);\n                        }\n                        // TODO validate child \n                      }\n                    } finally {\n                    }\n                    if (tnode217 != null) {\n                      tnode201.addChild(\"catchClause\", tnode217);\n                    }\n                    // TODO validate child \n                  }\n                } finally {\n                }\n                if (tnode201 != null) {\n                  tnode149.addChild(\"statement\", tnode201);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode149 != null) {\n              tnode148.addChild(\"body\", tnode149);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode225 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.PrivateVisibility\");\n            try {\n              environment.nodeCopied(context, tnode225, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699767969139\");\n            } finally {\n            }\n            if (tnode225 != null) {\n              tnode148.addChild(\"visibility\", tnode225);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode226 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n            try {\n              environment.nodeCopied(context, tnode226, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699768008914\");\n              tnode226.setReference(\"classifier\", SReference.create(\"classifier\", tnode226, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6ed54515-acc8-4d1e-a16c-9fd6cfe951ea#jetbrains.mps.generator.runtime(MPS.Core/jetbrains.mps.generator.runtime@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~TemplateModel\")));\n            } finally {\n            }\n            if (tnode226 != null) {\n              tnode148.addChild(\"returnType\", tnode226);\n            }\n            // TODO validate child \n          }\n          {\n            final SNode tnode227 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\");\n            try {\n              environment.nodeCopied(context, tnode227, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392371\");\n              SNodeAccessUtil.setProperty(tnode227, \"name\", \"modelName\");\n              {\n                final SNode tnode228 = environment.createOutputNode(\"jetbrains.mps.baseLanguage.structure.ClassifierType\");\n                try {\n                  environment.nodeCopied(context, tnode228, \"tpl/r:1dfaf07d-c77a-451e-91d3-b6f80f0f8508/3829836699769392370\");\n                  tnode228.setReference(\"classifier\", SReference.create(\"classifier\", tnode228, PersistenceFacade.getInstance().createModelReference(\"f:java_stub#6354ebe7-c22a-4a0f-ac54-50b52ab9b065#java.lang(JDK/java.lang@java_stub)\"), PersistenceFacade.getInstance().createNodeId(\"~String\")));\n                } finally {\n                }\n                if (tnode228 != null) {\n                  tnode227.addChild(\"type\", tnode228);\n                }\n                // TODO validate child \n              }\n            } finally {\n            }\n            if (tnode227 != null) {\n              tnode148.addChild(\"parameter\", tnode227);\n            }\n            // TODO validate child \n          }\n        } finally {\n        }\n        if (tnode148 != null) {\n          tnode1.addChild(\"member\", tnode148);\n        }\n        // TODO validate child \n      }\n    } finally {\n    }\n    return TemplateUtil.singletonList(tnode1);\n  }","commit_id":"9e839f69a2cbc1cd9949679ee007e82fd7792e6c","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n    public ModelMap<LanguageSourceSet> getSources() {\n        sources.ensureUsable();\n        return sources.asMutable(\n                ModelTypes.modelMap(LanguageSourceSetInternal.PUBLIC_MODEL_TYPE),\n                RuleContext.nest(modelNode.toString() + \".getSources()\"),\n                Collections.<ModelView<?>>emptyList()\n        ).getInstance();\n    }","id":14494,"modified_method":"@Override\n    public ModelMap<LanguageSourceSet> getSources() {\n        return ModelMaps.asMutableView(sources, LanguageSourceSet.class, modelNode.toString() + \".getSources()\");\n    }","commit_id":"409bff3d0f892298723289cad83279e20fa6050a","url":"https://github.com/gradle/gradle"},{"original_method":"private BaseBinarySpec(BinaryInfo info) {\n        if (info == null) {\n            throw new ModelInstantiationException(\"Direct instantiation of a BaseBinarySpec is not permitted. Use a BinaryTypeBuilder instead.\");\n        }\n        this.owner = info.owner;\n        this.name = info.name;\n        this.publicType = info.publicType;\n        this.typeName = info.implementationType.getSimpleName();\n        this.modelNode = info.modelNode;\n        this.tasks = info.instantiator.newInstance(DefaultBinaryTasksCollection.class, this, info.taskFactory);\n\n        final ModelType<LanguageSourceSet> elementType = ModelType.of(LanguageSourceSet.class);\n        modelNode.addLink(\n            ModelRegistrations.of(\n                modelNode.getPath().child(\"sources\"), ModelReference.of(NodeInitializerRegistry.class), new BiAction<MutableModelNode, List<ModelView<?>>>() {\n                    @Override\n                    public void execute(MutableModelNode node, List<ModelView<?>> modelViews) {\n                        NodeInitializerRegistry nodeInitializerRegistry = (NodeInitializerRegistry) modelViews.get(0).getInstance();\n                        ChildNodeInitializerStrategy<LanguageSourceSet> childFactory =\n                            NodeBackedModelMap.createUsingRegistry(elementType, nodeInitializerRegistry);\n                        node.setPrivateData(ModelType.of(ChildNodeInitializerStrategy.class), childFactory);\n                    }\n                })\n                .descriptor(modelNode.getDescriptor(), \".sources\")\n                .withProjection(\n                    ModelMapModelProjection.unmanaged(elementType, ChildNodeInitializerStrategyAccessors.fromPrivateData())\n                )\n                .build()\n        );\n        sources = modelNode.getLink(\"sources\");\n        assert sources != null;\n    }","id":14495,"modified_method":"private BaseBinarySpec(BinaryInfo info) {\n        if (info == null) {\n            throw new ModelInstantiationException(\"Direct instantiation of a BaseBinarySpec is not permitted. Use a BinaryTypeBuilder instead.\");\n        }\n        this.owner = info.owner;\n        this.name = info.name;\n        this.publicType = info.publicType;\n        this.typeName = info.implementationType.getSimpleName();\n        this.modelNode = info.modelNode;\n        this.tasks = info.instantiator.newInstance(DefaultBinaryTasksCollection.class, this, info.taskFactory);\n\n        sources = ModelMaps.addModelMapNode(modelNode, LanguageSourceSet.class, \"sources\");\n    }","commit_id":"409bff3d0f892298723289cad83279e20fa6050a","url":"https://github.com/gradle/gradle"},{"original_method":"private BaseComponentSpec(ComponentInfo info) {\n        if (info == null) {\n            throw new ModelInstantiationException(\"Direct instantiation of a BaseComponentSpec is not permitted. Use a ComponentTypeBuilder instead.\");\n        }\n\n        this.identifier = info.componentIdentifier;\n        this.typeName = info.typeName;\n\n        modelNode = info.modelNode;\n        modelNode.addLink(\n            ModelRegistrations.of(\n                modelNode.getPath().child(\"binaries\"), ModelReference.of(NodeInitializerRegistry.class), new BiAction<MutableModelNode, List<ModelView<?>>>() {\n                    @Override\n                    public void execute(MutableModelNode node, List<ModelView<?>> modelViews) {\n                        NodeInitializerRegistry nodeInitializerRegistry = (NodeInitializerRegistry) modelViews.get(0).getInstance();\n                        ChildNodeInitializerStrategy<BinarySpec> childFactory = NodeBackedModelMap.createUsingRegistry(ModelType.of(BinarySpec.class), nodeInitializerRegistry);\n                        node.setPrivateData(ModelType.of(ChildNodeInitializerStrategy.class), childFactory);\n                    }\n                })\n                .descriptor(modelNode.getDescriptor(), \".binaries\")\n                .withProjection(\n                    ModelMapModelProjection.unmanaged(\n                        BinarySpec.class,\n                        ChildNodeInitializerStrategyAccessors.fromPrivateData()\n                    )\n                )\n                .build()\n        );\n        binaries = modelNode.getLink(\"binaries\");\n        assert binaries != null;\n\n        modelNode.addLink(\n            ModelRegistrations.of(\n                modelNode.getPath().child(\"sources\"), ModelReference.of(NodeInitializerRegistry.class), new BiAction<MutableModelNode, List<ModelView<?>>>() {\n                    @Override\n                    public void execute(MutableModelNode node, List<ModelView<?>> modelViews) {\n                        NodeInitializerRegistry nodeInitializerRegistry = (NodeInitializerRegistry) modelViews.get(0).getInstance();\n                        ChildNodeInitializerStrategy<LanguageSourceSet> childFactory = NodeBackedModelMap.createUsingRegistry(ModelType.of(LanguageSourceSet.class), nodeInitializerRegistry);\n                        node.setPrivateData(ModelType.of(ChildNodeInitializerStrategy.class), childFactory);\n                    }\n                })\n                .descriptor(modelNode.getDescriptor(), \".sources\")\n                .withProjection(\n                    ModelMapModelProjection.unmanaged(\n                        LanguageSourceSet.class,\n                        ChildNodeInitializerStrategyAccessors.fromPrivateData()\n                    )\n                )\n                .build()\n        );\n        sources = modelNode.getLink(\"sources\");\n        assert sources != null;\n    }","id":14496,"modified_method":"private BaseComponentSpec(ComponentInfo info) {\n        if (info == null) {\n            throw new ModelInstantiationException(\"Direct instantiation of a BaseComponentSpec is not permitted. Use a ComponentTypeBuilder instead.\");\n        }\n\n        this.identifier = info.componentIdentifier;\n        this.typeName = info.typeName;\n\n        modelNode = info.modelNode;\n        binaries = ModelMaps.addModelMapNode(modelNode, BinarySpec.class, \"binaries\");\n        sources = ModelMaps.addModelMapNode(modelNode, LanguageSourceSet.class, \"sources\");\n    }","commit_id":"409bff3d0f892298723289cad83279e20fa6050a","url":"https://github.com/gradle/gradle"},{"original_method":"@Override\n    public ModelMap<BinarySpec> getBinaries() {\n        binaries.ensureUsable();\n        return binaries.asMutable(\n            ModelTypes.modelMap(BinarySpecInternal.PUBLIC_MODEL_TYPE),\n            RuleContext.nest(modelNode.toString() + \".getBinaries()\"),\n            Collections.<ModelView<?>>emptyList()\n        ).getInstance();\n    }","id":14497,"modified_method":"@Override\n    public ModelMap<BinarySpec> getBinaries() {\n        return ModelMaps.asMutableView(binaries, BinarySpec.class, modelNode.toString() + \".getBinaries()\");\n    }","commit_id":"409bff3d0f892298723289cad83279e20fa6050a","url":"https://github.com/gradle/gradle"},{"original_method":"@Override\n    public ModelMap<LanguageSourceSet> getSources() {\n        sources.ensureUsable();\n        return sources.asMutable(\n            ModelTypes.modelMap(LanguageSourceSetInternal.PUBLIC_MODEL_TYPE),\n            RuleContext.nest(modelNode.toString() + \".getSources()\"),\n            Collections.<ModelView<?>>emptyList()\n        ).getInstance();\n    }","id":14498,"modified_method":"@Override\n    public ModelMap<LanguageSourceSet> getSources() {\n        return ModelMaps.asMutableView(sources, LanguageSourceSet.class, modelNode.toString() + \".getSources()\");\n    }","commit_id":"409bff3d0f892298723289cad83279e20fa6050a","url":"https://github.com/gradle/gradle"},{"original_method":"/**\n     * Default stop will stop all Startable children\n     */\n    @Override\n    public void stop() {\n        logApplicationLifecycle(\"Stopping\");\n\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application stopping\");\n        setAttribute(SERVICE_UP, false);\n        ServiceStateLogic.setExpectedState(this, Lifecycle.STOPPING);\n        recordApplicationEvent(Lifecycle.STOPPING);\n        try {\n            doStop();\n        } catch (Exception e) {\n            ServiceStateLogic.setExpectedState(this, Lifecycle.ON_FIRE);\n            recordApplicationEvent(Lifecycle.ON_FIRE);\n            log.warn(\"Error stopping application \" + this + \" (rethrowing): \"+e);\n            throw Exceptions.propagate(e);\n        }\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application stopping\");\n        ServiceStateLogic.setExpectedState(this, Lifecycle.STOPPED);\n        recordApplicationEvent(Lifecycle.STOPPED);\n\n        if (getParent()==null) {\n            synchronized (this) {\n                deployed = false;\n                //TODO review mgmt destroy lifecycle\n                //  we don't necessarily want to forget all about the app on stop, \n                //since operator may be interested in things recently stopped;\n                //but that could be handled by the impl at management\n                //(keeping recently unmanaged things)  \n                //  however unmanaging must be done last, _after_ we stop children and set attributes \n                getEntityManager().unmanage(this);\n            }\n        }\n\n        logApplicationLifecycle(\"Stopped\");\n    }","id":14499,"modified_method":"/**\n     * Default stop will stop all Startable children\n     */\n    @Override\n    public void stop() {\n        logApplicationLifecycle(\"Stopping\");\n\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application stopping\");\n        setAttribute(SERVICE_UP, false);\n        setExpectedStateAndRecordLifecycleEvent(Lifecycle.STOPPING);\n        try {\n            doStop();\n        } catch (Exception e) {\n            setExpectedStateAndRecordLifecycleEvent(Lifecycle.ON_FIRE);\n            log.warn(\"Error stopping application \" + this + \" (rethrowing): \"+e);\n            throw Exceptions.propagate(e);\n        }\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application stopped\");\n        setExpectedStateAndRecordLifecycleEvent(Lifecycle.STOPPED);\n\n        if (getParent()==null) {\n            synchronized (this) {\n                //TODO review mgmt destroy lifecycle\n                //  we don't necessarily want to forget all about the app on stop, \n                //since operator may be interested in things recently stopped;\n                //but that could be handled by the impl at management\n                //(keeping recently unmanaged things)  \n                //  however unmanaging must be done last, _after_ we stop children and set attributes \n                getEntityManager().unmanage(this);\n            }\n        }\n\n        logApplicationLifecycle(\"Stopped\");\n    }","commit_id":"9cbe341a663248ab7471798ee35e8416b82487b6","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"/**\n     * Default start will start all Startable children (child.start(Collection<? extends Location>)),\n     * calling preStart(locations) first and postStart(locations) afterwards.\n     */\n    @Override\n    public void start(Collection<? extends Location> locations) {\n        this.addLocations(locations);\n        Collection<? extends Location> locationsToUse = getLocations();\n        ServiceProblemsLogic.clearProblemsIndicator(this, START);\n        ServiceStateLogic.setExpectedState(this, Lifecycle.STARTING);\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application starting\");\n        recordApplicationEvent(Lifecycle.STARTING);\n        try {\n            preStart(locationsToUse);\n            // if there are other items which should block service_up, they should be done in preStart\n            ServiceStateLogic.ServiceNotUpLogic.clearNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL);\n            \n            doStart(locationsToUse);\n            postStart(locationsToUse);\n        } catch (Exception e) {\n            // TODO should probably remember these problems then clear?  if so, do it here ... or on all effectors?\n//            ServiceProblemsLogic.updateProblemsIndicator(this, START, e);\n            \n            recordApplicationEvent(Lifecycle.ON_FIRE);\n            // no need to log here; the effector invocation should do that\n            throw Exceptions.propagate(e);\n        } finally {\n            ServiceStateLogic.setExpectedState(this, Lifecycle.RUNNING);\n        }\n        \n        deployed = true;\n        recordApplicationEvent(Lifecycle.RUNNING);\n\n        logApplicationLifecycle(\"Started\");\n    }","id":14500,"modified_method":"/**\n     * Default start will start all Startable children (child.start(Collection<? extends Location>)),\n     * calling preStart(locations) first and postStart(locations) afterwards.\n     */\n    @Override\n    public void start(Collection<? extends Location> locations) {\n        this.addLocations(locations);\n        Collection<? extends Location> locationsToUse = getLocations();\n        ServiceProblemsLogic.clearProblemsIndicator(this, START);\n        ServiceStateLogic.ServiceNotUpLogic.updateNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL, \"Application starting\");\n        setExpectedStateAndRecordLifecycleEvent(Lifecycle.STARTING);\n        try {\n            preStart(locationsToUse);\n            // if there are other items which should block service_up, they should be done in preStart\n            ServiceStateLogic.ServiceNotUpLogic.clearNotUpIndicator(this, Attributes.SERVICE_STATE_ACTUAL);\n            \n            doStart(locationsToUse);\n            postStart(locationsToUse);\n        } catch (Exception e) {\n            // TODO should probably remember these problems then clear?  if so, do it here ... or on all effectors?\n//            ServiceProblemsLogic.updateProblemsIndicator(this, START, e);\n            \n            recordApplicationEvent(Lifecycle.ON_FIRE);\n            // no need to log here; the effector invocation should do that\n            throw Exceptions.propagate(e);\n        } finally {\n            ServiceStateLogic.setExpectedState(this, Lifecycle.RUNNING);\n        }\n\n        setExpectedStateAndRecordLifecycleEvent(Lifecycle.RUNNING);\n\n        logApplicationLifecycle(\"Started\");\n    }","commit_id":"9cbe341a663248ab7471798ee35e8416b82487b6","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"private void recordApplicationEvent(Lifecycle state) {\n        try {\n            ((ManagementContextInternal)getManagementContext()).getUsageManager().recordApplicationEvent(this, state);\n        } catch (RuntimeInterruptedException e) {\n            throw e;\n        } catch (RuntimeException e) {\n            if (getManagementContext().isRunning()) {\n                log.warn(\"Problem recording application event '\"+state+\"' for \"+this, e);\n            }\n        }\n    }","id":14501,"modified_method":"protected void recordApplicationEvent(Lifecycle state) {\n        try {\n            ((ManagementContextInternal)getManagementContext()).getUsageManager().recordApplicationEvent(this, state);\n        } catch (RuntimeInterruptedException e) {\n            throw e;\n        } catch (RuntimeException e) {\n            if (getManagementContext().isRunning()) {\n                log.warn(\"Problem recording application event '\"+state+\"' for \"+this, e);\n            }\n        }\n    }","commit_id":"9cbe341a663248ab7471798ee35e8416b82487b6","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public static List<SNode> replaceNodeMenu_StaticFieldReference_getParameterObjects(SNode node) {\n    List<SNode> result = new ArrayList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classifier\", false);\n    if (classifier == null) {\n      return result;\n    }\n    ISearchScope searchScope = new VisibleClassifierMembersScope(((Classifier)SNodeOperations.getAdapter(classifier)), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    ListSequence.fromList(result).addSequence(ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticMethodDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.EnumConstantDeclaration\");\n      }\n\n    }));\n    return result;\n  }","id":14502,"modified_method":"public static List<SNode> replaceNodeMenu_StaticFieldReference_getParameterObjects(SNode node) {\n    ISearchScope searchScope = new ClassifierVisibleStaticMembersScope(((Classifier)SNodeOperations.getAdapter(SLinkOperations.getTarget(node, \"classifier\", false))), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    return ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticMethodDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.EnumConstantDeclaration\");\n      }\n\n    }).toListSequence();\n  }","commit_id":"f767883710b8fea429921d62116e981dd5321b7f","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_StaticMethodCall_getParameterObjects(SNode node) {\n    List<SNode> result = new ArrayList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classConcept\", false);\n    if (classifier == null) {\n      return result;\n    }\n    ISearchScope searchScope = new VisibleClassifierMembersScope(((Classifier)SNodeOperations.getAdapter(classifier)), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    ListSequence.fromList(result).addSequence(ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.EnumConstantDeclaration\");\n      }\n\n    }));\n    return result;\n  }","id":14503,"modified_method":"public static List<SNode> replaceNodeMenu_StaticMethodCall_getParameterObjects(SNode node) {\n    ISearchScope searchScope = new ClassifierVisibleStaticMembersScope(((ClassConcept)SNodeOperations.getAdapter(SLinkOperations.getTarget(node, \"classConcept\", false))), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    return ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.EnumConstantDeclaration\");\n      }\n\n    }).toListSequence();\n  }","commit_id":"f767883710b8fea429921d62116e981dd5321b7f","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_EnumConstantReference_getParameterObjects(SNode node) {\n    List<SNode> result = new ArrayList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"enumClass\", false);\n    if (classifier == null) {\n      return result;\n    }\n    ISearchScope searchScope = new VisibleClassifierMembersScope(((Classifier)SNodeOperations.getAdapter(classifier)), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    ListSequence.fromList(result).addSequence(ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticMethodDeclaration\");\n      }\n\n    }));\n    return result;\n  }","id":14504,"modified_method":"public static List<SNode> replaceNodeMenu_EnumConstantReference_getParameterObjects(SNode node) {\n    ISearchScope searchScope = new ClassifierVisibleStaticMembersScope(((EnumClass)SNodeOperations.getAdapter(SLinkOperations.getTarget(node, \"enumClass\", false))), node, IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> members = (List<SNode>)searchScope.getNodes();\n    return ListSequence.fromList(members).where(new IWhereFilter <SNode>() {\n\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticFieldDeclaration\") || SNodeOperations.isInstanceOf(it, \"jetbrains.mps.baseLanguage.structure.StaticMethodDeclaration\");\n      }\n\n    }).toListSequence();\n  }","commit_id":"f767883710b8fea429921d62116e981dd5321b7f","url":"https://github.com/JetBrains/MPS"},{"original_method":"public String toString() {\n        StringBuffer ret=new StringBuffer();\n        ret.append(\"[GroupRequest:\\n\");\n        ret.append(\"req_id=\").append(req_id).append('\\n');\n        ret.append(\"members: \");\n        for(int i=0; i < membership.length; i++)\n            ret.append(membership[i] + \" \");\n        ret.append(\"\\nresponses: \");\n        for(int i=0; i < responses.length; i++)\n            ret.append(responses[i] + \" \");\n        ret.append(\"\\nreceived: \");\n        for(int i=0; i < received.length; i++)\n            ret.append(receivedToString(received[i]) + \" \");\n        if(suspects.size() > 0)\n            ret.append(\"\\nsuspects: \").append(suspects);\n        ret.append(\"\\nrequest_msg: \").append(request_msg);\n        ret.append(\"\\nrsp_mode: \").append(rsp_mode);\n        ret.append(\"\\ndone: \").append(done);\n        ret.append(\"\\ntimeout: \").append(timeout);\n        ret.append(\"\\nexpected_mbrs: \").append(expected_mbrs);\n        ret.append(\"\\n]\");\n        return ret.toString();\n    }","id":14505,"modified_method":"public String toString() {\n        StringBuffer ret=new StringBuffer();\n        ret.append(\"[GroupRequest:\\n\");\n        ret.append(\"req_id=\").append(req_id).append('\\n');\n\n        Map.Entry entry;\n        Address mbr;\n        Rsp rsp;\n        synchronized(requests) {\n            for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n                entry=(Map.Entry)it.next();\n                mbr=(Address)entry.getKey();\n                rsp=(Rsp)entry.getValue();\n                ret.append(mbr).append(\": \").append(rsp).append(\"\\n\");\n            }\n        }\n        if(suspects.size() > 0)\n            ret.append(\"\\nsuspects: \").append(suspects);\n        ret.append(\"\\nrequest_msg: \").append(request_msg);\n        ret.append(\"\\nrsp_mode: \").append(rsp_mode);\n        ret.append(\"\\ndone: \").append(done);\n        ret.append(\"\\ntimeout: \").append(timeout);\n        ret.append(\"\\nexpected_mbrs: \").append(expected_mbrs);\n        ret.append(\"\\n]\");\n        return ret.toString();\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/** Returns the results as a RspList */\n    public RspList getResults() {\n        RspList retval=new RspList();\n        Address sender;\n        synchronized(rsp_mutex) {\n            for(int i=0; i < membership.length; i++) {\n                sender=membership[i];\n                switch(received[i]) {\n                    case SUSPECTED:\n                        retval.addSuspect(sender);\n                        break;\n                    case RECEIVED:\n                        retval.addRsp(sender, responses[i]);\n                        break;\n                    case NOT_RECEIVED:\n                        retval.addNotReceived(sender);\n                        break;\n                }\n            }\n            return retval;\n        }\n    }","id":14506,"modified_method":"/** Returns the results as a RspList */\n    public RspList getResults() {\n        synchronized(requests) {\n            Collection rsps=requests.values();\n            RspList retval=new RspList(rsps);\n            return retval;\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * This method sets the <code>membership<\/code> variable to the value of\n     * <code>members<\/code>. It requires that the caller already hold the\n     * <code>rsp_mutex<\/code> lock.\n     * @param mbrs The new list of members\n     */\n    public void reset(Vector mbrs) {\n        if(mbrs != null) {\n            int size=mbrs.size();\n            membership=new Address[size];\n            responses=new Object[size];\n            received=new short[size];\n            for(int i=0; i < size; i++) {\n                membership[i]=(Address)mbrs.elementAt(i);\n                responses[i]=null;\n                received[i]=NOT_RECEIVED;\n            }\n            // maintain local membership\n            this.members.clear();\n            this.members.addAll(mbrs);\n        }\n        else {\n            if(membership != null) {\n                for(int i=0; i < membership.length; i++) {\n                    responses[i]=null;\n                    received[i]=NOT_RECEIVED;\n                }\n            }\n        }\n    }","id":14507,"modified_method":"/**\n     * This method sets the <code>membership<\/code> variable to the value of\n     * <code>members<\/code>. It requires that the caller already hold the\n     * <code>rsp_mutex<\/code> lock.\n     * @param mbrs The new list of members\n     */\n    public void reset(Vector mbrs) {\n        if(mbrs != null) {\n            Address mbr;\n            synchronized(requests) {\n                requests.clear();\n                for(int i=0; i < mbrs.size(); i++) {\n                    mbr=(Address)mbrs.elementAt(i);\n                    requests.put(mbr, new Rsp(mbr));\n                }\n            }\n            // maintain local membership\n            synchronized(this.members) {\n                this.members.clear();\n                this.members.addAll(mbrs);\n            }\n        }\n        else {\n            synchronized(requests) {\n                Rsp rsp;\n                for(Iterator it=requests.values().iterator(); it.hasNext();) {\n                    rsp=(Rsp)it.next();\n                    rsp.setReceived(false);\n                    rsp.setValue(null);\n                }\n            }\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/** This method runs with rsp_mutex locked (called by <code>execute()<\/code>). */\n    protected boolean doExecute(long timeout) {\n        long start_time=0;\n        Address mbr, suspect;\n        req_id=getRequestId();\n        reset(null); // clear 'responses' array\n        if(suspects != null) { // mark all suspects in 'received' array\n            for(int i=0; i < suspects.size(); i++) {\n                suspect=(Address)suspects.elementAt(i);\n                for(int j=0; j < membership.length; j++) {\n                    mbr=membership[j];\n                    if(mbr.equals(suspect)) {\n                        received[j]=SUSPECTED;\n                        break; // we can break here because we ensure there are no duplicate members\n                    }\n                }\n            }\n        }\n\n        try {\n           if(log.isTraceEnabled()) log.trace(new StringBuffer(\"sending request (id=\").append(req_id).append(')'));\n            if(corr != null) {\n                java.util.List tmp=members != null? members : null;\n                corr.sendRequest(req_id, tmp, request_msg, rsp_mode == GET_NONE? null : this);\n            }\n            else {\n                transport.send(request_msg);\n            }\n        }\n        catch(Throwable e) {\n            log.error(\"exception=\" + e);\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n\n        if(timeout <= 0) {\n            while(true) { /* Wait for responses: */\n                adjustMembership(); // may not be necessary, just to make sure...\n                if(getResponses()) {\n                    if(corr != null) {\n                        corr.done(req_id);\n                    }\n                    if(log.isTraceEnabled()) {\n                        log.trace(\"received all responses: \" + toString());\n                    }\n                    return true;\n                }\n                try {\n                    rsp_mutex.wait();\n                }\n                catch(Exception e) {\n                }\n            }\n        }\n        else {\n            start_time=System.currentTimeMillis();\n            while(timeout > 0) { /* Wait for responses: */\n                if(getResponses()) {\n                    if(corr != null)\n                        corr.done(req_id);\n                   if(log.isTraceEnabled()) log.trace(\"received all responses: \" + toString());\n                    return true;\n                }\n                timeout=timeout - (System.currentTimeMillis() - start_time);\n                if(timeout > 0) {\n                    try {\n                        rsp_mutex.wait(timeout);\n                    }\n                    catch(Exception e) {\n                        //e.printStackTrace();\n                    }\n                }\n            }\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n    }","id":14508,"modified_method":"/** This method runs with rsp_mutex locked (called by <code>execute()<\/code>). */\n    private boolean doExecute(long timeout) {\n        long start_time=0;\n        Address suspect;\n        req_id=getRequestId();\n        reset(null); // clear 'responses' array\n\n        synchronized(requests) {\n            for(int i=0; i < suspects.size(); i++) {  // mark all suspects in 'received' array\n                suspect=(Address)suspects.elementAt(i);\n                Rsp rsp=(Rsp)requests.get(suspect);\n                if(rsp != null) {\n                    rsp.setSuspected(true);\n                    break; // we can break here because we ensure there are no duplicate members\n                }\n            }\n        }\n\n        try {\n            if(log.isTraceEnabled()) log.trace(new StringBuffer(\"sending request (id=\").append(req_id).append(')'));\n            if(corr != null) {\n                java.util.List tmp=members != null? members : null;\n                corr.sendRequest(req_id, tmp, request_msg, rsp_mode == GET_NONE? null : this);\n            }\n            else {\n                transport.send(request_msg);\n            }\n        }\n        catch(Throwable e) {\n            log.error(\"exception=\" + e);\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n\n        synchronized(requests) {\n            if(timeout <= 0) {\n                while(true) { /* Wait for responses: */\n                    adjustMembership(); // may not be necessary, just to make sure...\n                    if(responsesComplete()) {\n                        if(corr != null) {\n                            corr.done(req_id);\n                        }\n                        if(log.isTraceEnabled()) {\n                            log.trace(\"received all responses: \" + toString());\n                        }\n                        return true;\n                    }\n                    try {\n                        requests.wait();\n                    }\n                    catch(Exception e) {\n                    }\n                }\n            }\n            else {\n                start_time=System.currentTimeMillis();\n                while(timeout > 0) { /* Wait for responses: */\n                    if(responsesComplete()) {\n                        if(corr != null)\n                            corr.done(req_id);\n                        if(log.isTraceEnabled()) log.trace(\"received all responses: \" + toString());\n                        return true;\n                    }\n                    timeout=timeout - (System.currentTimeMillis() - start_time);\n                    if(timeout > 0) {\n                        try {\n                            requests.wait(timeout);\n                        }\n                        catch(Exception e) {\n                        }\n                    }\n                }\n                if(corr != null) {\n                    corr.done(req_id);\n                }\n                return false;\n            }\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Adjusts the 'received' array in the following way:\n     * <ul>\n     * <li>if a member P in 'membership' is not in 'members', P's entry in the 'received' array\n     *     will be marked as SUSPECTED\n     * <li>if P is 'suspected_mbr', then P's entry in the 'received' array will be marked\n     *     as SUSPECTED\n     * <\/ul>\n     * This call requires exclusive access to rsp_mutex (called by getResponses() which has\n     * a the rsp_mutex locked, so this should not be a problem).\n     */\n    void adjustMembership() {\n        Address mbr;\n        if(membership == null || membership.length == 0) {\n            // if(log.isWarnEnabled()) log.warn(\"GroupRequest.adjustMembership()\", \"membership is null\");\n            return;\n        }\n        for(int i=0; i < membership.length; i++) {\n            mbr=membership[i];\n            if((this.members != null && !this.members.contains(mbr))\n                    || suspects.contains(mbr)) {\n                addSuspect(mbr);\n                responses[i]=null;\n                received[i]=SUSPECTED;\n            }\n        }\n    }","id":14509,"modified_method":"/**\n     * Adjusts the 'received' array in the following way:\n     * <ul>\n     * <li>if a member P in 'membership' is not in 'members', P's entry in the 'received' array\n     *     will be marked as SUSPECTED\n     * <li>if P is 'suspected_mbr', then P's entry in the 'received' array will be marked\n     *     as SUSPECTED\n     * <\/ul>\n     * This call requires exclusive access to rsp_mutex (called by getResponses() which has\n     * a the rsp_mutex locked, so this should not be a problem).\n     */\n    private void adjustMembership() {\n        if(requests.size() == 0)\n            return;\n\n        Map.Entry entry;\n        Address mbr;\n        Rsp rsp;\n        for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n            entry=(Map.Entry)it.next();\n            mbr=(Address)entry.getKey();\n            if((!this.members.contains(mbr)) || suspects.contains(mbr)) {\n                addSuspect(mbr);\n                rsp=(Rsp)entry.getValue();\n                rsp.setValue(null);\n                rsp.setSuspected(true);\n            }\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Report to <code>GroupRequest<\/code> that a member is reported as faulty (suspected).\n     * This method would probably be called when getting a suspect message from a failure detector\n     * (where available). It is used to exclude faulty members from the response list.\n     */\n    public void suspect(Address suspected_member) {\n        Address mbr;\n        synchronized(rsp_mutex) { // modify 'suspects' and 'responses' array\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(mbr.equals(suspected_member)) {\n                    addSuspect(suspected_member);\n                    responses[i]=null;\n                    received[i]=SUSPECTED;\n                    rsp_mutex.notifyAll();\n                    break;\n                }\n            }\n        }\n    }","id":14510,"modified_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Report to <code>GroupRequest<\/code> that a member is reported as faulty (suspected).\n     * This method would probably be called when getting a suspect message from a failure detector\n     * (where available). It is used to exclude faulty members from the response list.\n     */\n    public void suspect(Address suspected_member) {\n        Rsp rsp;\n\n        if(suspected_member == null)\n            return;\n\n        addSuspect(suspected_member);\n\n        synchronized(requests) {\n            rsp=(Rsp)requests.get(suspected_member);\n            if(rsp != null) {\n                rsp.setSuspected(true);\n                rsp.setValue(null);\n                requests.notifyAll();\n            }\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Any member of 'membership' that is not in the new view is flagged as\n     * SUSPECTED. Any member in the new view that is <em>not<\/em> in the\n     * membership (ie, the set of responses expected for the current RPC) will\n     * <em>not<\/em> be added to it. If we did this we might run into the\n     * following problem:\n     * <ul>\n     * <li>Membership is {A,B}\n     * <li>A sends a synchronous group RPC (which sleeps for 60 secs in the\n     * invocation handler)\n     * <li>C joins while A waits for responses from A and B\n     * <li>If this would generate a new view {A,B,C} and if this expanded the\n     * response set to {A,B,C}, A would wait forever on C's response because C\n     * never received the request in the first place, therefore won't send a\n     * response.\n     * <\/ul>\n     */\n    public void viewChange(View new_view) {\n        Address mbr;\n        Vector mbrs=new_view != null? new_view.getMembers() : null;\n        if(membership == null || membership.length == 0 || mbrs == null)\n            return;\n\n        synchronized(rsp_mutex) {\n            this.members.clear();\n            this.members.addAll(mbrs);\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(!mbrs.contains(mbr)) {\n                    addSuspect(mbr);\n                    responses[i]=null;\n                    received[i]=SUSPECTED;\n                }\n            }\n            rsp_mutex.notifyAll();\n        }\n    }","id":14511,"modified_method":"/**\n     * Any member of 'membership' that is not in the new view is flagged as\n     * SUSPECTED. Any member in the new view that is <em>not<\/em> in the\n     * membership (ie, the set of responses expected for the current RPC) will\n     * <em>not<\/em> be added to it. If we did this we might run into the\n     * following problem:\n     * <ul>\n     * <li>Membership is {A,B}\n     * <li>A sends a synchronous group RPC (which sleeps for 60 secs in the\n     * invocation handler)\n     * <li>C joins while A waits for responses from A and B\n     * <li>If this would generate a new view {A,B,C} and if this expanded the\n     * response set to {A,B,C}, A would wait forever on C's response because C\n     * never received the request in the first place, therefore won't send a\n     * response.\n     * <\/ul>\n     */\n    public void viewChange(View new_view) {\n        Address mbr;\n        Vector mbrs=new_view != null? new_view.getMembers() : null;\n        if(requests == null || requests.size() == 0 || mbrs == null)\n            return;\n\n        synchronized(this.members) {\n            this.members.clear();\n            this.members.addAll(mbrs);\n        }\n\n        Map.Entry entry;\n        Rsp rsp;\n        boolean modified=false;\n        synchronized(requests) {\n            for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n                entry=(Map.Entry)it.next();\n                mbr=(Address)entry.getKey();\n                if(!mbrs.contains(mbr)) {\n                    addSuspect(mbr);\n                    rsp=(Rsp)entry.getValue();\n                    rsp.setValue(null);\n                    rsp.setSuspected(true);\n                    modified=true;\n                }\n            }\n            if(modified)\n                requests.notifyAll();\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Adds a member to the 'suspects' list. Removes oldest elements from 'suspects' list\n     * to keep the list bounded ('max_suspects' number of elements)\n     */\n    void addSuspect(Address suspected_mbr) {\n        if(!suspects.contains(suspected_mbr)) {\n            suspects.addElement(suspected_mbr);\n            while(suspects.size() >= max_suspects && suspects.size() > 0)\n                suspects.remove(0); // keeps queue bounded\n        }\n    }","id":14512,"modified_method":"/**\n     * Adds a member to the 'suspects' list. Removes oldest elements from 'suspects' list\n     * to keep the list bounded ('max_suspects' number of elements)\n     */\n    private void addSuspect(Address suspected_mbr) {\n        if(!suspects.contains(suspected_mbr)) {\n            suspects.addElement(suspected_mbr);\n            while(suspects.size() >= max_suspects && suspects.size() > 0)\n                suspects.remove(0); // keeps queue bounded\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"protected int determineMajority(int i) {\n        return i < 2? i : (i / 2) + 1;\n    }","id":14513,"modified_method":"private int determineMajority(int i) {\n        return i < 2? i : (i / 2) + 1;\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Adds a response to the response table. When all responses have been received,\n     * <code>execute()<\/code> returns.\n     */\n    public void receiveResponse(Message m) {\n        Address sender=m.getSrc(), mbr;\n        Object val=null;\n        if(done) {\n            if(log.isWarnEnabled()) log.warn(\"command is done; cannot add response !\");\n            return;\n        }\n        if(suspects != null && suspects.size() > 0 && suspects.contains(sender)) {\n            if(log.isWarnEnabled()) log.warn(\"received response from suspected member \" + sender + \"; discarding\");\n            return;\n        }\n        if(m.getLength() > 0) {\n            try {\n                val=m.getObject();\n            }\n            catch(Exception e) {\n                if(log.isErrorEnabled()) log.error(\"exception=\" + e);\n            }\n        }\n        synchronized(rsp_mutex) {\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(mbr.equals(sender)) {\n                    if(received[i] == NOT_RECEIVED) {\n                        responses[i]=val;\n                        received[i]=RECEIVED;\n                       if(log.isTraceEnabled())\n                          log.trace(\"received response for request \" + req_id + \", sender=\" + sender + \", val=\" + val);\n                        rsp_mutex.notifyAll(); // wakes up execute()\n                        break;\n                    }\n                }\n            }\n        }\n    }","id":14514,"modified_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Adds a response to the response table. When all responses have been received,\n     * <code>execute()<\/code> returns.\n     */\n    public void receiveResponse(Message m) {\n        Address sender=m.getSrc();\n        Object val=null;\n        if(done) {\n            if(log.isWarnEnabled()) log.warn(\"command is done; cannot add response !\");\n            return;\n        }\n        if(suspects != null && suspects.size() > 0 && suspects.contains(sender)) {\n            if(log.isWarnEnabled()) log.warn(\"received response from suspected member \" + sender + \"; discarding\");\n            return;\n        }\n        if(m.getLength() > 0) {\n            try {\n                val=m.getObject();\n            }\n            catch(Exception e) {\n                if(log.isErrorEnabled()) log.error(\"exception=\" + e);\n            }\n        }\n\n        synchronized(requests) {\n            Rsp rsp=(Rsp)requests.get(sender);\n            if(rsp != null) {\n                if(rsp.wasReceived() == false) {\n                    rsp.setValue(val);\n                    rsp.setReceived(true);\n                    if(log.isTraceEnabled())\n                        log.trace(new StringBuffer(\"received response for request \").append(req_id).append(\", sender=\").\n                                  append(sender).append(\", val=\").append(val));\n                    requests.notifyAll(); // wakes up execute()\n                }\n            }\n        }\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Sends the message. Returns when n responses have been received, or a\n     * timeout  has occurred. <em>n<\/em> can be the first response, all\n     * responses, or a majority  of the responses.\n     */\n    public boolean execute() {\n        boolean retval;\n        if(corr == null && transport == null) {\n            if(log.isErrorEnabled()) log.error(\"both corr and transport are null, cannot send group request\");\n            return false;\n        }\n        synchronized(rsp_mutex) {\n            done=false;\n            retval=doExecute(timeout);\n            if(retval == false && log.isTraceEnabled())\n                log.trace(\"call did not execute correctly, request is \" + toString());\n            done=true;\n            return retval;\n        }\n    }","id":14515,"modified_method":"/**\n     * Sends the message. Returns when n responses have been received, or a\n     * timeout  has occurred. <em>n<\/em> can be the first response, all\n     * responses, or a majority  of the responses.\n     */\n    public boolean execute() {\n        boolean retval;\n        if(corr == null && transport == null) {\n            if(log.isErrorEnabled()) log.error(\"both corr and transport are null, cannot send group request\");\n            return false;\n        }\n        done=false;\n        retval=doExecute(timeout);\n        if(retval == false && log.isTraceEnabled())\n            log.trace(\"call did not execute correctly, request is \" + toString());\n        done=true;\n        return retval;\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender, Object retval)\n    {\n        this.sender=sender;\n        this.retval=retval;\n        received=true;\n    }","id":14516,"modified_method":"public Rsp(Address sender, Object retval) {\n        this.sender=sender;\n        this.retval=retval;\n        received=true;\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender)\n    {\n        this.sender=sender;\n    }","id":14517,"modified_method":"public Rsp(Address sender) {\n        this.sender=sender;\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender, boolean suspected)\n    {\n        this.sender=sender;\n        this.suspected=suspected;\n    }","id":14518,"modified_method":"public Rsp(Address sender, boolean suspected) {\n        this.sender=sender;\n        this.suspected=suspected;\n    }","commit_id":"c8f5facd8982ec92b688f89804b4efef6bfd957a","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Any member of 'membership' that is not in the new view is flagged as\n     * SUSPECTED. Any member in the new view that is <em>not<\/em> in the\n     * membership (ie, the set of responses expected for the current RPC) will\n     * <em>not<\/em> be added to it. If we did this we might run into the\n     * following problem:\n     * <ul>\n     * <li>Membership is {A,B}\n     * <li>A sends a synchronous group RPC (which sleeps for 60 secs in the\n     * invocation handler)\n     * <li>C joins while A waits for responses from A and B\n     * <li>If this would generate a new view {A,B,C} and if this expanded the\n     * response set to {A,B,C}, A would wait forever on C's response because C\n     * never received the request in the first place, therefore won't send a\n     * response.\n     * <\/ul>\n     */\n    public void viewChange(View new_view) {\n        Address mbr;\n        Vector mbrs=new_view != null? new_view.getMembers() : null;\n        if(membership == null || membership.length == 0 || mbrs == null)\n            return;\n\n        synchronized(rsp_mutex) {\n            this.members.clear();\n            this.members.addAll(mbrs);\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(!mbrs.contains(mbr)) {\n                    addSuspect(mbr);\n                    responses[i]=null;\n                    received[i]=SUSPECTED;\n                }\n            }\n            rsp_mutex.notifyAll();\n        }\n    }","id":14519,"modified_method":"/**\n     * Any member of 'membership' that is not in the new view is flagged as\n     * SUSPECTED. Any member in the new view that is <em>not<\/em> in the\n     * membership (ie, the set of responses expected for the current RPC) will\n     * <em>not<\/em> be added to it. If we did this we might run into the\n     * following problem:\n     * <ul>\n     * <li>Membership is {A,B}\n     * <li>A sends a synchronous group RPC (which sleeps for 60 secs in the\n     * invocation handler)\n     * <li>C joins while A waits for responses from A and B\n     * <li>If this would generate a new view {A,B,C} and if this expanded the\n     * response set to {A,B,C}, A would wait forever on C's response because C\n     * never received the request in the first place, therefore won't send a\n     * response.\n     * <\/ul>\n     */\n    public void viewChange(View new_view) {\n        Address mbr;\n        Vector mbrs=new_view != null? new_view.getMembers() : null;\n        if(requests == null || requests.size() == 0 || mbrs == null)\n            return;\n\n        synchronized(this.members) {\n            this.members.clear();\n            this.members.addAll(mbrs);\n        }\n\n        Map.Entry entry;\n        Rsp rsp;\n        boolean modified=false;\n        synchronized(requests) {\n            for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n                entry=(Map.Entry)it.next();\n                mbr=(Address)entry.getKey();\n                if(!mbrs.contains(mbr)) {\n                    addSuspect(mbr);\n                    rsp=(Rsp)entry.getValue();\n                    rsp.setValue(null);\n                    rsp.setSuspected(true);\n                    modified=true;\n                }\n            }\n            if(modified)\n                requests.notifyAll();\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"public String toString() {\n        StringBuffer ret=new StringBuffer();\n        ret.append(\"[GroupRequest:\\n\");\n        ret.append(\"req_id=\").append(req_id).append('\\n');\n        ret.append(\"members: \");\n        for(int i=0; i < membership.length; i++)\n            ret.append(membership[i] + \" \");\n        ret.append(\"\\nresponses: \");\n        for(int i=0; i < responses.length; i++)\n            ret.append(responses[i] + \" \");\n        ret.append(\"\\nreceived: \");\n        for(int i=0; i < received.length; i++)\n            ret.append(receivedToString(received[i]) + \" \");\n        if(suspects.size() > 0)\n            ret.append(\"\\nsuspects: \").append(suspects);\n        ret.append(\"\\nrequest_msg: \").append(request_msg);\n        ret.append(\"\\nrsp_mode: \").append(rsp_mode);\n        ret.append(\"\\ndone: \").append(done);\n        ret.append(\"\\ntimeout: \").append(timeout);\n        ret.append(\"\\nexpected_mbrs: \").append(expected_mbrs);\n        ret.append(\"\\n]\");\n        return ret.toString();\n    }","id":14520,"modified_method":"public String toString() {\n        StringBuffer ret=new StringBuffer();\n        ret.append(\"[GroupRequest:\\n\");\n        ret.append(\"req_id=\").append(req_id).append('\\n');\n\n        Map.Entry entry;\n        Address mbr;\n        Rsp rsp;\n        synchronized(requests) {\n            for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n                entry=(Map.Entry)it.next();\n                mbr=(Address)entry.getKey();\n                rsp=(Rsp)entry.getValue();\n                ret.append(mbr).append(\": \").append(rsp).append(\"\\n\");\n            }\n        }\n        if(suspects.size() > 0)\n            ret.append(\"\\nsuspects: \").append(suspects);\n        ret.append(\"\\nrequest_msg: \").append(request_msg);\n        ret.append(\"\\nrsp_mode: \").append(rsp_mode);\n        ret.append(\"\\ndone: \").append(done);\n        ret.append(\"\\ntimeout: \").append(timeout);\n        ret.append(\"\\nexpected_mbrs: \").append(expected_mbrs);\n        ret.append(\"\\n]\");\n        return ret.toString();\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/** Returns the results as a RspList */\n    public RspList getResults() {\n        RspList retval=new RspList();\n        Address sender;\n        synchronized(rsp_mutex) {\n            for(int i=0; i < membership.length; i++) {\n                sender=membership[i];\n                switch(received[i]) {\n                    case SUSPECTED:\n                        retval.addSuspect(sender);\n                        break;\n                    case RECEIVED:\n                        retval.addRsp(sender, responses[i]);\n                        break;\n                    case NOT_RECEIVED:\n                        retval.addNotReceived(sender);\n                        break;\n                }\n            }\n            return retval;\n        }\n    }","id":14521,"modified_method":"/** Returns the results as a RspList */\n    public RspList getResults() {\n        synchronized(requests) {\n            Collection rsps=requests.values();\n            RspList retval=new RspList(rsps);\n            return retval;\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"protected int determineMajority(int i) {\n        return i < 2? i : (i / 2) + 1;\n    }","id":14522,"modified_method":"private int determineMajority(int i) {\n        return i < 2? i : (i / 2) + 1;\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * This method sets the <code>membership<\/code> variable to the value of\n     * <code>members<\/code>. It requires that the caller already hold the\n     * <code>rsp_mutex<\/code> lock.\n     * @param mbrs The new list of members\n     */\n    public void reset(Vector mbrs) {\n        if(mbrs != null) {\n            int size=mbrs.size();\n            membership=new Address[size];\n            responses=new Object[size];\n            received=new short[size];\n            for(int i=0; i < size; i++) {\n                membership[i]=(Address)mbrs.elementAt(i);\n                responses[i]=null;\n                received[i]=NOT_RECEIVED;\n            }\n            // maintain local membership\n            this.members.clear();\n            this.members.addAll(mbrs);\n        }\n        else {\n            if(membership != null) {\n                for(int i=0; i < membership.length; i++) {\n                    responses[i]=null;\n                    received[i]=NOT_RECEIVED;\n                }\n            }\n        }\n    }","id":14523,"modified_method":"/**\n     * This method sets the <code>membership<\/code> variable to the value of\n     * <code>members<\/code>. It requires that the caller already hold the\n     * <code>rsp_mutex<\/code> lock.\n     * @param mbrs The new list of members\n     */\n    public void reset(Vector mbrs) {\n        if(mbrs != null) {\n            Address mbr;\n            synchronized(requests) {\n                requests.clear();\n                for(int i=0; i < mbrs.size(); i++) {\n                    mbr=(Address)mbrs.elementAt(i);\n                    requests.put(mbr, new Rsp(mbr));\n                }\n            }\n            // maintain local membership\n            synchronized(this.members) {\n                this.members.clear();\n                this.members.addAll(mbrs);\n            }\n        }\n        else {\n            synchronized(requests) {\n                Rsp rsp;\n                for(Iterator it=requests.values().iterator(); it.hasNext();) {\n                    rsp=(Rsp)it.next();\n                    rsp.setReceived(false);\n                    rsp.setValue(null);\n                }\n            }\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Adds a member to the 'suspects' list. Removes oldest elements from 'suspects' list\n     * to keep the list bounded ('max_suspects' number of elements)\n     */\n    void addSuspect(Address suspected_mbr) {\n        if(!suspects.contains(suspected_mbr)) {\n            suspects.addElement(suspected_mbr);\n            while(suspects.size() >= max_suspects && suspects.size() > 0)\n                suspects.remove(0); // keeps queue bounded\n        }\n    }","id":14524,"modified_method":"/**\n     * Adds a member to the 'suspects' list. Removes oldest elements from 'suspects' list\n     * to keep the list bounded ('max_suspects' number of elements)\n     */\n    private void addSuspect(Address suspected_mbr) {\n        if(!suspects.contains(suspected_mbr)) {\n            suspects.addElement(suspected_mbr);\n            while(suspects.size() >= max_suspects && suspects.size() > 0)\n                suspects.remove(0); // keeps queue bounded\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Report to <code>GroupRequest<\/code> that a member is reported as faulty (suspected).\n     * This method would probably be called when getting a suspect message from a failure detector\n     * (where available). It is used to exclude faulty members from the response list.\n     */\n    public void suspect(Address suspected_member) {\n        Address mbr;\n        synchronized(rsp_mutex) { // modify 'suspects' and 'responses' array\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(mbr.equals(suspected_member)) {\n                    addSuspect(suspected_member);\n                    responses[i]=null;\n                    received[i]=SUSPECTED;\n                    rsp_mutex.notifyAll();\n                    break;\n                }\n            }\n        }\n    }","id":14525,"modified_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Report to <code>GroupRequest<\/code> that a member is reported as faulty (suspected).\n     * This method would probably be called when getting a suspect message from a failure detector\n     * (where available). It is used to exclude faulty members from the response list.\n     */\n    public void suspect(Address suspected_member) {\n        Rsp rsp;\n\n        if(suspected_member == null)\n            return;\n\n        addSuspect(suspected_member);\n\n        synchronized(requests) {\n            rsp=(Rsp)requests.get(suspected_member);\n            if(rsp != null) {\n                rsp.setSuspected(true);\n                rsp.setValue(null);\n                requests.notifyAll();\n            }\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Adjusts the 'received' array in the following way:\n     * <ul>\n     * <li>if a member P in 'membership' is not in 'members', P's entry in the 'received' array\n     *     will be marked as SUSPECTED\n     * <li>if P is 'suspected_mbr', then P's entry in the 'received' array will be marked\n     *     as SUSPECTED\n     * <\/ul>\n     * This call requires exclusive access to rsp_mutex (called by getResponses() which has\n     * a the rsp_mutex locked, so this should not be a problem).\n     */\n    void adjustMembership() {\n        Address mbr;\n        if(membership == null || membership.length == 0) {\n            // if(log.isWarnEnabled()) log.warn(\"GroupRequest.adjustMembership()\", \"membership is null\");\n            return;\n        }\n        for(int i=0; i < membership.length; i++) {\n            mbr=membership[i];\n            if((this.members != null && !this.members.contains(mbr))\n                    || suspects.contains(mbr)) {\n                addSuspect(mbr);\n                responses[i]=null;\n                received[i]=SUSPECTED;\n            }\n        }\n    }","id":14526,"modified_method":"/**\n     * Adjusts the 'received' array in the following way:\n     * <ul>\n     * <li>if a member P in 'membership' is not in 'members', P's entry in the 'received' array\n     *     will be marked as SUSPECTED\n     * <li>if P is 'suspected_mbr', then P's entry in the 'received' array will be marked\n     *     as SUSPECTED\n     * <\/ul>\n     * This call requires exclusive access to rsp_mutex (called by getResponses() which has\n     * a the rsp_mutex locked, so this should not be a problem).\n     */\n    private void adjustMembership() {\n        if(requests.size() == 0)\n            return;\n\n        Map.Entry entry;\n        Address mbr;\n        Rsp rsp;\n        for(Iterator it=requests.entrySet().iterator(); it.hasNext();) {\n            entry=(Map.Entry)it.next();\n            mbr=(Address)entry.getKey();\n            if((!this.members.contains(mbr)) || suspects.contains(mbr)) {\n                addSuspect(mbr);\n                rsp=(Rsp)entry.getValue();\n                rsp.setValue(null);\n                rsp.setSuspected(true);\n            }\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Adds a response to the response table. When all responses have been received,\n     * <code>execute()<\/code> returns.\n     */\n    public void receiveResponse(Message m) {\n        Address sender=m.getSrc(), mbr;\n        Object val=null;\n        if(done) {\n            if(log.isWarnEnabled()) log.warn(\"command is done; cannot add response !\");\n            return;\n        }\n        if(suspects != null && suspects.size() > 0 && suspects.contains(sender)) {\n            if(log.isWarnEnabled()) log.warn(\"received response from suspected member \" + sender + \"; discarding\");\n            return;\n        }\n        if(m.getLength() > 0) {\n            try {\n                val=m.getObject();\n            }\n            catch(Exception e) {\n                if(log.isErrorEnabled()) log.error(\"exception=\" + e);\n            }\n        }\n        synchronized(rsp_mutex) {\n            for(int i=0; i < membership.length; i++) {\n                mbr=membership[i];\n                if(mbr.equals(sender)) {\n                    if(received[i] == NOT_RECEIVED) {\n                        responses[i]=val;\n                        received[i]=RECEIVED;\n                       if(log.isTraceEnabled())\n                          log.trace(\"received response for request \" + req_id + \", sender=\" + sender + \", val=\" + val);\n                        rsp_mutex.notifyAll(); // wakes up execute()\n                        break;\n                    }\n                }\n            }\n        }\n    }","id":14527,"modified_method":"/**\n     * <b>Callback<\/b> (called by RequestCorrelator or Transport).\n     * Adds a response to the response table. When all responses have been received,\n     * <code>execute()<\/code> returns.\n     */\n    public void receiveResponse(Message m) {\n        Address sender=m.getSrc();\n        Object val=null;\n        if(done) {\n            if(log.isWarnEnabled()) log.warn(\"command is done; cannot add response !\");\n            return;\n        }\n        if(suspects != null && suspects.size() > 0 && suspects.contains(sender)) {\n            if(log.isWarnEnabled()) log.warn(\"received response from suspected member \" + sender + \"; discarding\");\n            return;\n        }\n        if(m.getLength() > 0) {\n            try {\n                val=m.getObject();\n            }\n            catch(Exception e) {\n                if(log.isErrorEnabled()) log.error(\"exception=\" + e);\n            }\n        }\n\n        synchronized(requests) {\n            Rsp rsp=(Rsp)requests.get(sender);\n            if(rsp != null) {\n                if(rsp.wasReceived() == false) {\n                    rsp.setValue(val);\n                    rsp.setReceived(true);\n                    if(log.isTraceEnabled())\n                        log.trace(new StringBuffer(\"received response for request \").append(req_id).append(\", sender=\").\n                                  append(sender).append(\", val=\").append(val));\n                    requests.notifyAll(); // wakes up execute()\n                }\n            }\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Sends the message. Returns when n responses have been received, or a\n     * timeout  has occurred. <em>n<\/em> can be the first response, all\n     * responses, or a majority  of the responses.\n     */\n    public boolean execute() {\n        boolean retval;\n        if(corr == null && transport == null) {\n            if(log.isErrorEnabled()) log.error(\"both corr and transport are null, cannot send group request\");\n            return false;\n        }\n        synchronized(rsp_mutex) {\n            done=false;\n            retval=doExecute(timeout);\n            if(retval == false && log.isTraceEnabled())\n                log.trace(\"call did not execute correctly, request is \" + toString());\n            done=true;\n            return retval;\n        }\n    }","id":14528,"modified_method":"/**\n     * Sends the message. Returns when n responses have been received, or a\n     * timeout  has occurred. <em>n<\/em> can be the first response, all\n     * responses, or a majority  of the responses.\n     */\n    public boolean execute() {\n        boolean retval;\n        if(corr == null && transport == null) {\n            if(log.isErrorEnabled()) log.error(\"both corr and transport are null, cannot send group request\");\n            return false;\n        }\n        done=false;\n        retval=doExecute(timeout);\n        if(retval == false && log.isTraceEnabled())\n            log.trace(\"call did not execute correctly, request is \" + toString());\n        done=true;\n        return retval;\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/** This method runs with rsp_mutex locked (called by <code>execute()<\/code>). */\n    protected boolean doExecute(long timeout) {\n        long start_time=0;\n        Address mbr, suspect;\n        req_id=getRequestId();\n        reset(null); // clear 'responses' array\n        if(suspects != null) { // mark all suspects in 'received' array\n            for(int i=0; i < suspects.size(); i++) {\n                suspect=(Address)suspects.elementAt(i);\n                for(int j=0; j < membership.length; j++) {\n                    mbr=membership[j];\n                    if(mbr.equals(suspect)) {\n                        received[j]=SUSPECTED;\n                        break; // we can break here because we ensure there are no duplicate members\n                    }\n                }\n            }\n        }\n\n        try {\n           if(log.isTraceEnabled()) log.trace(new StringBuffer(\"sending request (id=\").append(req_id).append(')'));\n            if(corr != null) {\n                java.util.List tmp=members != null? members : null;\n                corr.sendRequest(req_id, tmp, request_msg, rsp_mode == GET_NONE? null : this);\n            }\n            else {\n                transport.send(request_msg);\n            }\n        }\n        catch(Throwable e) {\n            log.error(\"exception=\" + e);\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n\n        if(timeout <= 0) {\n            while(true) { /* Wait for responses: */\n                adjustMembership(); // may not be necessary, just to make sure...\n                if(getResponses()) {\n                    if(corr != null) {\n                        corr.done(req_id);\n                    }\n                    if(log.isTraceEnabled()) {\n                        log.trace(\"received all responses: \" + toString());\n                    }\n                    return true;\n                }\n                try {\n                    rsp_mutex.wait();\n                }\n                catch(Exception e) {\n                }\n            }\n        }\n        else {\n            start_time=System.currentTimeMillis();\n            while(timeout > 0) { /* Wait for responses: */\n                if(getResponses()) {\n                    if(corr != null)\n                        corr.done(req_id);\n                   if(log.isTraceEnabled()) log.trace(\"received all responses: \" + toString());\n                    return true;\n                }\n                timeout=timeout - (System.currentTimeMillis() - start_time);\n                if(timeout > 0) {\n                    try {\n                        rsp_mutex.wait(timeout);\n                    }\n                    catch(Exception e) {\n                        //e.printStackTrace();\n                    }\n                }\n            }\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n    }","id":14529,"modified_method":"/** This method runs with rsp_mutex locked (called by <code>execute()<\/code>). */\n    private boolean doExecute(long timeout) {\n        long start_time=0;\n        Address suspect;\n        req_id=getRequestId();\n        reset(null); // clear 'responses' array\n\n        synchronized(requests) {\n            for(int i=0; i < suspects.size(); i++) {  // mark all suspects in 'received' array\n                suspect=(Address)suspects.elementAt(i);\n                Rsp rsp=(Rsp)requests.get(suspect);\n                if(rsp != null) {\n                    rsp.setSuspected(true);\n                    break; // we can break here because we ensure there are no duplicate members\n                }\n            }\n        }\n\n        try {\n            if(log.isTraceEnabled()) log.trace(new StringBuffer(\"sending request (id=\").append(req_id).append(')'));\n            if(corr != null) {\n                java.util.List tmp=members != null? members : null;\n                corr.sendRequest(req_id, tmp, request_msg, rsp_mode == GET_NONE? null : this);\n            }\n            else {\n                transport.send(request_msg);\n            }\n        }\n        catch(Throwable e) {\n            log.error(\"exception=\" + e);\n            if(corr != null) {\n                corr.done(req_id);\n            }\n            return false;\n        }\n\n        synchronized(requests) {\n            if(timeout <= 0) {\n                while(true) { /* Wait for responses: */\n                    adjustMembership(); // may not be necessary, just to make sure...\n                    if(responsesComplete()) {\n                        if(corr != null) {\n                            corr.done(req_id);\n                        }\n                        if(log.isTraceEnabled()) {\n                            log.trace(\"received all responses: \" + toString());\n                        }\n                        return true;\n                    }\n                    try {\n                        requests.wait();\n                    }\n                    catch(Exception e) {\n                    }\n                }\n            }\n            else {\n                start_time=System.currentTimeMillis();\n                while(timeout > 0) { /* Wait for responses: */\n                    if(responsesComplete()) {\n                        if(corr != null)\n                            corr.done(req_id);\n                        if(log.isTraceEnabled()) log.trace(\"received all responses: \" + toString());\n                        return true;\n                    }\n                    timeout=timeout - (System.currentTimeMillis() - start_time);\n                    if(timeout > 0) {\n                        try {\n                            requests.wait(timeout);\n                        }\n                        catch(Exception e) {\n                        }\n                    }\n                }\n                if(corr != null) {\n                    corr.done(req_id);\n                }\n                return false;\n            }\n        }\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender)\n    {\n        this.sender=sender;\n    }","id":14530,"modified_method":"public Rsp(Address sender) {\n        this.sender=sender;\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender, Object retval)\n    {\n        this.sender=sender;\n        this.retval=retval;\n        received=true;\n    }","id":14531,"modified_method":"public Rsp(Address sender, Object retval) {\n        this.sender=sender;\n        this.retval=retval;\n        received=true;\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"Rsp(Address sender, boolean suspected)\n    {\n        this.sender=sender;\n        this.suspected=suspected;\n    }","id":14532,"modified_method":"public Rsp(Address sender, boolean suspected) {\n        this.sender=sender;\n        this.suspected=suspected;\n    }","commit_id":"f08688a28e6c5c72b6fa6673bf13bceea3a6fc1c","url":"https://github.com/belaban/JGroups"},{"original_method":"/** set new indexing and translog buffers on this shard.  this may cause the shard to refresh to free up heap. */\n    protected void updateShardBuffers(ShardId shardId, ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {\n        final IndexShard shard = getShard(shardId);\n        if (shard != null) {\n            try {\n                shard.updateBufferSize(shardIndexingBufferSize, shardTranslogBufferSize);\n            } catch (EngineClosedException e) {\n                // ignore\n            } catch (FlushNotAllowedEngineException e) {\n                // ignore\n            } catch (Exception e) {\n                logger.warn(\"failed to set shard {} index buffer to [{}]\", e, shardId, shardIndexingBufferSize);\n            }\n        }\n    }","id":14533,"modified_method":"/** set new indexing and translog buffers on this shard.  this may cause the shard to refresh to free up heap. */\n    protected void updateShardBuffers(IndexShard shard, ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {\n        if (shard != null) {\n            try {\n                shard.updateBufferSize(shardIndexingBufferSize, shardTranslogBufferSize);\n            } catch (EngineClosedException e) {\n                // ignore\n            } catch (FlushNotAllowedEngineException e) {\n                // ignore\n            } catch (Exception e) {\n                logger.warn(\"failed to set shard {} index buffer to [{}]\", e, shard.shardId(), shardIndexingBufferSize);\n            }\n        }\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n        public synchronized void run() {\n            EnumSet<ShardStatusChangeType> changes = purgeDeletedAndClosedShards();\n\n            updateShardStatuses(changes);\n\n            if (changes.isEmpty() == false) {\n                // Something changed: recompute indexing buffers:\n                calcAndSetShardBuffers(\"[\" + changes + \"]\");\n            }\n        }","id":14534,"modified_method":"@Override\n        public synchronized void run() {\n            calcAndSetShardBuffers();\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected List<ShardId> availableShards() {\n        ArrayList<ShardId> list = new ArrayList<>();\n\n        for (IndexService indexService : indicesService) {\n            for (IndexShard indexShard : indexService) {\n                if (shardAvailable(indexShard)) {\n                    list.add(indexShard.shardId());\n                }\n            }\n        }\n        return list;\n    }","id":14535,"modified_method":"protected List<IndexShard> availableShards() {\n        List<IndexShard> activeShards = new ArrayList<>();\n\n        for (IndexService indexService : indicesService) {\n            for (IndexShard shard : indexService) {\n                if (shardAvailable(shard)) {\n                    activeShards.add(shard);\n                }\n            }\n        }\n        return activeShards;\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/** ask this shard to check now whether it is inactive, and reduces its indexing and translog buffers if so.  returns Boolean.TRUE if\n     *  it did deactive, Boolean.FALSE if it did not, and null if the shard is unknown */\n    protected Boolean checkIdle(ShardId shardId) {\n        String ignoreReason; // eclipse compiler does not know it is really final\n        final IndexShard shard = getShard(shardId);\n        if (shard != null) {\n            try {\n                if (shard.checkIdle()) {\n                    logger.debug(\"marking shard {} as inactive (inactive_time[{}]) indexing wise\",\n                            shardId,\n                            shard.getInactiveTime());\n                    return Boolean.TRUE;\n                }\n                return Boolean.FALSE;\n            } catch (EngineClosedException e) {\n                // ignore\n                ignoreReason = \"EngineClosedException\";\n            } catch (FlushNotAllowedEngineException e) {\n                // ignore\n                ignoreReason = \"FlushNotAllowedEngineException\";\n            }\n        } else {\n            ignoreReason = \"shard not found\";\n        }\n        if (ignoreReason != null) {\n            logger.trace(\"ignore [{}] while marking shard {} as inactive\", ignoreReason, shardId);\n        }\n        return null;\n    }","id":14536,"modified_method":"/** ask this shard to check now whether it is inactive, and reduces its indexing and translog buffers if so.  returns Boolean.TRUE if\n     *  it did deactive, Boolean.FALSE if it did not, and null if the shard is unknown */\n    protected Boolean checkIdle(IndexShard shard) {\n        String ignoreReason = null; // eclipse compiler does not know it is really final\n        if (shard != null) {\n            try {\n                if (shard.checkIdle()) {\n                    logger.debug(\"marking shard {} as inactive (inactive_time[{}]) indexing wise\",\n                            shard.shardId(),\n                            shard.getInactiveTime());\n                    return Boolean.TRUE;\n                }\n                return Boolean.FALSE;\n            } catch (EngineClosedException e) {\n                // ignore\n                ignoreReason = \"EngineClosedException\";\n            } catch (FlushNotAllowedEngineException e) {\n                // ignore\n                ignoreReason = \"FlushNotAllowedEngineException\";\n            }\n        } else {\n            ignoreReason = \"shard not found\";\n        }\n        if (ignoreReason != null) {\n            logger.trace(\"ignore [{}] while marking shard {} as inactive\", ignoreReason, shard.shardId());\n        }\n        return null;\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void calcAndSetShardBuffers(String reason) {\n\n            // Count how many shards are now active:\n            int activeShardCount = 0;\n            for (Map.Entry<ShardId,Boolean> ent : shardWasActive.entrySet()) {\n                if (ent.getValue()) {\n                    activeShardCount++;\n                }\n            }\n\n            // TODO: we could be smarter here by taking into account how RAM the IndexWriter on each shard\n            // is actually using (using IW.ramBytesUsed), so that small indices (e.g. Marvel) would not\n            // get the same indexing buffer as large indices.  But it quickly gets tricky...\n            if (activeShardCount == 0) {\n                logger.debug(\"no active shards (reason={})\", reason);\n                return;\n            }\n\n            ByteSizeValue shardIndexingBufferSize = new ByteSizeValue(indexingBuffer.bytes() / activeShardCount);\n            if (shardIndexingBufferSize.bytes() < minShardIndexBufferSize.bytes()) {\n                shardIndexingBufferSize = minShardIndexBufferSize;\n            }\n            if (shardIndexingBufferSize.bytes() > maxShardIndexBufferSize.bytes()) {\n                shardIndexingBufferSize = maxShardIndexBufferSize;\n            }\n\n            ByteSizeValue shardTranslogBufferSize = new ByteSizeValue(translogBuffer.bytes() / activeShardCount);\n            if (shardTranslogBufferSize.bytes() < minShardTranslogBufferSize.bytes()) {\n                shardTranslogBufferSize = minShardTranslogBufferSize;\n            }\n            if (shardTranslogBufferSize.bytes() > maxShardTranslogBufferSize.bytes()) {\n                shardTranslogBufferSize = maxShardTranslogBufferSize;\n            }\n\n            logger.debug(\"recalculating shard indexing buffer (reason={}), total is [{}] with [{}] active shards, each shard set to indexing=[{}], translog=[{}]\", reason, indexingBuffer, activeShardCount, shardIndexingBufferSize, shardTranslogBufferSize);\n\n            for (Map.Entry<ShardId,Boolean> ent : shardWasActive.entrySet()) {\n                if (ent.getValue()) {\n                    // This shard is active\n                    updateShardBuffers(ent.getKey(), shardIndexingBufferSize, shardTranslogBufferSize);\n                }\n            }\n        }","id":14537,"modified_method":"private void calcAndSetShardBuffers() {\n            List<IndexShard> availableShards = availableShards();\n            List<IndexShard> activeShards = new ArrayList<>();\n            for (IndexShard shard : availableShards) {\n                if (!checkIdle(shard)) {\n                    activeShards.add(shard);\n                }\n            }\n            int activeShardCount = activeShards.size();\n\n            // TODO: we could be smarter here by taking into account how RAM the IndexWriter on each shard\n            // is actually using (using IW.ramBytesUsed), so that small indices (e.g. Marvel) would not\n            // get the same indexing buffer as large indices.  But it quickly gets tricky...\n            if (activeShardCount == 0) {\n                logger.debug(\"no active shards\");\n                return;\n            }\n\n            ByteSizeValue shardIndexingBufferSize = new ByteSizeValue(indexingBuffer.bytes() / activeShardCount);\n            if (shardIndexingBufferSize.bytes() < minShardIndexBufferSize.bytes()) {\n                shardIndexingBufferSize = minShardIndexBufferSize;\n            }\n            if (shardIndexingBufferSize.bytes() > maxShardIndexBufferSize.bytes()) {\n                shardIndexingBufferSize = maxShardIndexBufferSize;\n            }\n\n            ByteSizeValue shardTranslogBufferSize = new ByteSizeValue(translogBuffer.bytes() / activeShardCount);\n            if (shardTranslogBufferSize.bytes() < minShardTranslogBufferSize.bytes()) {\n                shardTranslogBufferSize = minShardTranslogBufferSize;\n            }\n            if (shardTranslogBufferSize.bytes() > maxShardTranslogBufferSize.bytes()) {\n                shardTranslogBufferSize = maxShardTranslogBufferSize;\n            }\n\n            logger.debug(\"recalculating shard indexing buffer, total is [{}] with [{}] active shards, each shard set to indexing=[{}], translog=[{}]\", indexingBuffer, activeShardCount, shardIndexingBufferSize, shardTranslogBufferSize);\n\n            for (IndexShard shard : activeShards) {\n                updateShardBuffers(shard, shardIndexingBufferSize, shardTranslogBufferSize);\n            }\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected void assertTwoActiveShards(MockController controller, ByteSizeValue indexBufferSize, ByteSizeValue translogBufferSize) {\n        final ShardId shard1 = new ShardId(\"test\", 1);\n        controller.simulateIndexing(shard1);\n        final ShardId shard2 = new ShardId(\"test\", 2);\n        controller.simulateIndexing(shard2);\n        controller.assertBuffers(shard1, indexBufferSize, translogBufferSize);\n        controller.assertBuffers(shard2, indexBufferSize, translogBufferSize);\n\n    }","id":14538,"modified_method":"protected void assertTwoActiveShards(MockController controller, ByteSizeValue indexBufferSize, ByteSizeValue translogBufferSize) {\n        createIndex(\"test\", Settings.builder().put(SETTING_NUMBER_OF_SHARDS, 2).put(SETTING_NUMBER_OF_REPLICAS, 0).build());\n        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n        IndexService test = indicesService.indexService(\"test\");\n        IndexShard shard0 = test.getShard(0);\n        controller.simulateIndexing(shard0);\n        IndexShard shard1 = test.getShard(1);\n        controller.simulateIndexing(shard1);\n        controller.assertBuffers(shard0, indexBufferSize, translogBufferSize);\n        controller.assertBuffers(shard1, indexBufferSize, translogBufferSize);\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void simulateIndexing(ShardId shardId) {\n            lastIndexTimeNanos.put(shardId, currentTimeInNanos());\n            if (indexingBuffers.containsKey(shardId) == false) {\n                // First time we are seeing this shard; start it off with inactive buffers as IndexShard does:\n                indexingBuffers.put(shardId, IndexingMemoryController.INACTIVE_SHARD_INDEXING_BUFFER);\n                translogBuffers.put(shardId, IndexingMemoryController.INACTIVE_SHARD_TRANSLOG_BUFFER);\n            }\n            activeShards.add(shardId);\n            forceCheck();\n        }","id":14539,"modified_method":"public void simulateIndexing(IndexShard shard) {\n            lastIndexTimeNanos.put(shard, currentTimeInNanos());\n            if (indexingBuffers.containsKey(shard) == false) {\n                // First time we are seeing this shard; start it off with inactive buffers as IndexShard does:\n                indexingBuffers.put(shard, IndexingMemoryController.INACTIVE_SHARD_INDEXING_BUFFER);\n                translogBuffers.put(shard, IndexingMemoryController.INACTIVE_SHARD_TRANSLOG_BUFFER);\n            }\n            activeShards.add(shard);\n            forceCheck();\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n        protected void updateShardBuffers(ShardId shardId, ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {\n            indexingBuffers.put(shardId, shardIndexingBufferSize);\n            translogBuffers.put(shardId, shardTranslogBufferSize);\n        }","id":14540,"modified_method":"@Override\n        protected void updateShardBuffers(IndexShard shard, ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {\n            indexingBuffers.put(shard, shardIndexingBufferSize);\n            translogBuffers.put(shard, shardTranslogBufferSize);\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n        protected Boolean checkIdle(ShardId shardId) {\n            final TimeValue inactiveTime = settings.getAsTime(IndexShard.INDEX_SHARD_INACTIVE_TIME_SETTING, TimeValue.timeValueMinutes(5));\n            Long ns = lastIndexTimeNanos.get(shardId);\n            if (ns == null) {\n                return null;\n            } else if (currentTimeInNanos() - ns >= inactiveTime.nanos()) {\n                indexingBuffers.put(shardId, INACTIVE);\n                translogBuffers.put(shardId, INACTIVE);\n                activeShards.remove(shardId);\n                return true;\n            } else {\n                return false;\n            }\n        }","id":14541,"modified_method":"@Override\n        protected Boolean checkIdle(IndexShard shard) {\n            final TimeValue inactiveTime = settings.getAsTime(IndexShard.INDEX_SHARD_INACTIVE_TIME_SETTING, TimeValue.timeValueMinutes(5));\n            Long ns = lastIndexTimeNanos.get(shard);\n            if (ns == null) {\n                return null;\n            } else if (currentTimeInNanos() - ns >= inactiveTime.nanos()) {\n                indexingBuffers.put(shard, INACTIVE);\n                translogBuffers.put(shard, INACTIVE);\n                activeShards.remove(shard);\n                return true;\n            } else {\n                return false;\n            }\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n        protected List<ShardId> availableShards() {\n            return new ArrayList<>(indexingBuffers.keySet());\n        }","id":14542,"modified_method":"@Override\n        protected List<IndexShard> availableShards() {\n            return new ArrayList<>(indexingBuffers.keySet());\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testShardAdditionAndRemoval() {\n        MockController controller = new MockController(Settings.builder()\n                .put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, \"10mb\")\n                .put(IndexingMemoryController.TRANSLOG_BUFFER_SIZE_SETTING, \"100kb\").build());\n        final ShardId shard1 = new ShardId(\"test\", 1);\n        controller.simulateIndexing(shard1);\n        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n\n        // add another shard\n        final ShardId shard2 = new ShardId(\"test\", 2);\n        controller.simulateIndexing(shard2);\n        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n        controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n\n        // remove first shard\n        controller.deleteShard(shard1);\n        controller.forceCheck();\n        controller.assertBuffers(shard2, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n\n        // remove second shard\n        controller.deleteShard(shard2);\n        controller.forceCheck();\n\n        // add a new one\n        final ShardId shard3 = new ShardId(\"test\", 3);\n        controller.simulateIndexing(shard3);\n        controller.assertBuffers(shard3, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n    }","id":14543,"modified_method":"public void testShardAdditionAndRemoval() {\n        createIndex(\"test\", Settings.builder().put(SETTING_NUMBER_OF_SHARDS, 3).put(SETTING_NUMBER_OF_REPLICAS, 0).build());\n        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n        IndexService test = indicesService.indexService(\"test\");\n\n        MockController controller = new MockController(Settings.builder()\n            .put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, \"10mb\")\n            .put(IndexingMemoryController.TRANSLOG_BUFFER_SIZE_SETTING, \"100kb\").build());\n        IndexShard shard0 = test.getShard(0);\n        controller.simulateIndexing(shard0);\n        controller.assertBuffers(shard0, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n\n        // add another shard\n        IndexShard shard1 = test.getShard(1);\n        controller.simulateIndexing(shard1);\n        controller.assertBuffers(shard0, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n\n        // remove first shard\n        controller.deleteShard(shard0);\n        controller.forceCheck();\n        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n\n        // remove second shard\n        controller.deleteShard(shard1);\n        controller.forceCheck();\n\n        // add a new one\n        IndexShard shard2 = test.getShard(2);\n        controller.simulateIndexing(shard2);\n        controller.assertBuffers(shard2, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void assertBuffers(ShardId id, ByteSizeValue indexing, ByteSizeValue translog) {\n            assertThat(indexingBuffers.get(id), equalTo(indexing));\n            assertThat(translogBuffers.get(id), equalTo(translog));\n        }","id":14544,"modified_method":"public void assertBuffers(IndexShard id, ByteSizeValue indexing, ByteSizeValue translog) {\n            assertThat(indexingBuffers.get(id), equalTo(indexing));\n            assertThat(translogBuffers.get(id), equalTo(translog));\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n        protected boolean shardAvailable(ShardId shardId) {\n            return indexingBuffers.containsKey(shardId);\n        }","id":14545,"modified_method":"@Override\n        protected boolean shardAvailable(IndexShard shard) {\n            return indexingBuffers.containsKey(shard);\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void assertInActive(ShardId id) {\n            assertThat(indexingBuffers.get(id), equalTo(INACTIVE));\n            assertThat(translogBuffers.get(id), equalTo(INACTIVE));\n        }","id":14546,"modified_method":"public void assertInactive(IndexShard id) {\n            assertThat(indexingBuffers.get(id), equalTo(INACTIVE));\n            assertThat(translogBuffers.get(id), equalTo(INACTIVE));\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testActiveInactive() {\n        MockController controller = new MockController(Settings.builder()\n                .put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, \"10mb\")\n                .put(IndexingMemoryController.TRANSLOG_BUFFER_SIZE_SETTING, \"100kb\")\n                .put(IndexShard.INDEX_SHARD_INACTIVE_TIME_SETTING, \"5s\")\n                .build());\n\n        final ShardId shard1 = new ShardId(\"test\", 1);\n        controller.simulateIndexing(shard1);\n        final ShardId shard2 = new ShardId(\"test\", 2);\n        controller.simulateIndexing(shard2);\n        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n        controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n\n        // index into both shards, move the clock and see that they are still active\n        controller.simulateIndexing(shard1);\n        controller.simulateIndexing(shard2);\n\n        controller.incrementTimeSec(10);\n        controller.forceCheck();\n\n        // both shards now inactive\n        controller.assertInActive(shard1);\n        controller.assertInActive(shard2);\n\n        // index into one shard only, see it becomes active\n        controller.simulateIndexing(shard1);\n        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n        controller.assertInActive(shard2);\n\n        controller.incrementTimeSec(3); // increment but not enough to become inactive\n        controller.forceCheck();\n        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n        controller.assertInActive(shard2);\n\n        controller.incrementTimeSec(3); // increment some more\n        controller.forceCheck();\n        controller.assertInActive(shard1);\n        controller.assertInActive(shard2);\n\n        // index some and shard becomes immediately active\n        controller.simulateIndexing(shard2);\n        controller.assertInActive(shard1);\n        controller.assertBuffers(shard2, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n    }","id":14547,"modified_method":"public void testActiveInactive() {\n        createIndex(\"test\", Settings.builder().put(SETTING_NUMBER_OF_SHARDS, 2).put(SETTING_NUMBER_OF_REPLICAS, 0).build());\n        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n        IndexService test = indicesService.indexService(\"test\");\n\n        MockController controller = new MockController(Settings.builder()\n            .put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, \"10mb\")\n            .put(IndexingMemoryController.TRANSLOG_BUFFER_SIZE_SETTING, \"100kb\")\n            .put(IndexShard.INDEX_SHARD_INACTIVE_TIME_SETTING, \"5s\")\n            .build());\n\n        IndexShard shard0 = test.getShard(0);\n        controller.simulateIndexing(shard0);\n        IndexShard shard1 = test.getShard(1);\n        controller.simulateIndexing(shard1);\n        controller.assertBuffers(shard0, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));\n\n        // index into both shards, move the clock and see that they are still active\n        controller.simulateIndexing(shard0);\n        controller.simulateIndexing(shard1);\n\n        controller.incrementTimeSec(10);\n        controller.forceCheck();\n\n        // both shards now inactive\n        controller.assertInactive(shard0);\n        controller.assertInactive(shard1);\n\n        // index into one shard only, see it becomes active\n        controller.simulateIndexing(shard0);\n        controller.assertBuffers(shard0, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n        controller.assertInactive(shard1);\n\n        controller.incrementTimeSec(3); // increment but not enough to become inactive\n        controller.forceCheck();\n        controller.assertBuffers(shard0, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n        controller.assertInactive(shard1);\n\n        controller.incrementTimeSec(3); // increment some more\n        controller.forceCheck();\n        controller.assertInactive(shard0);\n        controller.assertInactive(shard1);\n\n        // index some and shard becomes immediately active\n        controller.simulateIndexing(shard1);\n        controller.assertInactive(shard0);\n        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));\n    }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void deleteShard(ShardId id) {\n            indexingBuffers.remove(id);\n            translogBuffers.remove(id);\n        }","id":14548,"modified_method":"public void deleteShard(IndexShard id) {\n            indexingBuffers.remove(id);\n            translogBuffers.remove(id);\n        }","commit_id":"5341404f014fbfd0c0b67c61546df38625d9b4ad","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public static void setActiveAlarmCallbacks(Core server, List<AlarmCallback> callbacks) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(AlarmCallback callback : callbacks) {\n            Map<String, Object> entry = Maps.newHashMap();\n            entry.put(\"typeclass\", callback.getClass().getCanonicalName());\n            entry.put(\"name\", callback.getName());\n            entry.put(\"requested_config\", callback.getRequestedConfiguration());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"alarm_callbacks\");\n    }","id":14549,"modified_method":"public static void setActiveAlarmCallbacks(Core server, List<AlarmCallback> callbacks) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(AlarmCallback callback : callbacks) {\n            r.add(buildStandardInformation(\n                    callback.getClass().getCanonicalName(),\n                    callback.getName(),\n                    callback.getRequestedConfiguration()\n            ));\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"alarm_callbacks\");\n    }","commit_id":"92bb6e1a998f393c1ce13e42e39ae74a79c86f25","url":"https://github.com/Graylog2/graylog2-server"},{"original_method":"public static void setActiveMessageInputs(Core server, List<MessageInput> inputs) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(MessageInput input : inputs) {\n            Map<String, Object> entry = Maps.newHashMap();\n            entry.put(\"typeclass\", input.getClass().getCanonicalName());\n            entry.put(\"name\", input.getName());\n            entry.put(\"requested_config\", input.getRequestedConfiguration());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"message_inputs\");\n    }","id":14550,"modified_method":"public static void setActiveMessageInputs(Core server, List<MessageInput> inputs) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(MessageInput input : inputs) {\n            r.add(buildStandardInformation(\n                    input.getClass().getCanonicalName(),\n                    input.getName(),\n                    input.getRequestedConfiguration()\n            ));\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"message_inputs\");\n    }","commit_id":"92bb6e1a998f393c1ce13e42e39ae74a79c86f25","url":"https://github.com/Graylog2/graylog2-server"},{"original_method":"public static void setActiveTransports(Core server, List<Transport> transports) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(Transport transport : transports) {\n            Map<String, Object> entry = Maps.newHashMap();\n            entry.put(\"typeclass\", transport.getClass().getCanonicalName());\n            entry.put(\"name\", transport.getName());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"transports\");\n    }","id":14551,"modified_method":"public static void setActiveTransports(Core server, List<Transport> transports) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(Transport transport : transports) {\n            r.add(buildStandardInformation(\n                    transport.getClass().getCanonicalName(),\n                    transport.getName(),\n                    null\n            ));\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"transports\");\n    }","commit_id":"92bb6e1a998f393c1ce13e42e39ae74a79c86f25","url":"https://github.com/Graylog2/graylog2-server"},{"original_method":"public static void setActiveMessageOutputs(Core server, List<MessageOutput> outputs) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(MessageOutput output : outputs) {\n            Map<String, Object> entry = Maps.newHashMap();\n            entry.put(\"typeclass\", output.getClass().getCanonicalName());\n            entry.put(\"name\", output.getName());\n            entry.put(\"requested_config\", output.getRequestedConfiguration());\n            entry.put(\"requested_stream_config\", output.getRequestedStreamConfiguration());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"message_outputs\");\n    }","id":14552,"modified_method":"public static void setActiveMessageOutputs(Core server, List<MessageOutput> outputs) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(MessageOutput output : outputs) {\n            Map<String, Object> entry = buildStandardInformation(\n                    output.getClass().getCanonicalName(),\n                    output.getName(),\n                    output.getRequestedConfiguration()\n            );\n            \n            entry.put(\"requested_stream_config\", output.getRequestedStreamConfiguration());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"message_outputs\");\n    }","commit_id":"92bb6e1a998f393c1ce13e42e39ae74a79c86f25","url":"https://github.com/Graylog2/graylog2-server"},{"original_method":"public static void setActiveInitializers(Core server, List<Initializer> initializers) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(Initializer initializer : initializers) {\n            Map<String, Object> entry = Maps.newHashMap();\n            entry.put(\"typeclass\", initializer.getClass().getCanonicalName());\n            entry.put(\"name\", initializer.getName());\n            entry.put(\"requested_config\", initializer.getRequestedConfiguration());\n            \n            r.add(entry);\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"initializers\");\n    }","id":14553,"modified_method":"public static void setActiveInitializers(Core server, List<Initializer> initializers) {\n        Set<Map<String, Object>> r = Sets.newHashSet();\n        \n        for(Initializer initializer : initializers) {\n            r.add(buildStandardInformation(\n                    initializer.getClass().getCanonicalName(),\n                    initializer.getName(),\n                    initializer.getRequestedConfiguration()\n            ));\n        }\n        \n        server.getMongoBridge().writePluginInformation(r, \"initializers\");\n    }","commit_id":"92bb6e1a998f393c1ce13e42e39ae74a79c86f25","url":"https://github.com/Graylog2/graylog2-server"},{"original_method":"/**\n     * Construct a new instance.\n     */\n    protected AbstractModelElement() {\n        assert getClass() == getElementClass();\n    }","id":14554,"modified_method":"/**\n     * Construct a new instance.\n     */\n    protected AbstractModelElement() {\n        //assert getClass() == getElementClass() : \"\"+getClass() + \" != \" + getElementClass();\n    }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public AcceptorsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      System.out.println(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n               <acceptor name=\"netty\">\n                  <factory-class>org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory<\/factory-class>\n                  <param key=\"host\"  value=\"${jboss.bind.address:localhost}\"/>\n                  <param key=\"port\"  value=\"${hornetq.remoting.netty.port:5445}\"/>\n               <\/acceptor>\n         */\n         switch (element) {\n         case ACCEPTOR:\n            String name = reader.getAttributeValue(0);\n            TransportConfiguration acceptorConfig = ElementUtils.parseTransportConfiguration(reader, name, Element.ACCEPTOR);\n            config.getAcceptorConfigurations().add(acceptorConfig);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.ACCEPTOR.getLocalName()));\n\n   }","id":14555,"modified_method":"public AcceptorsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      boolean trace = log.isTraceEnabled();\n      if(trace)\n         log.trace(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n               <acceptor name=\"netty\">\n                  <factory-class>org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory<\/factory-class>\n                  <param key=\"host\"  value=\"${jboss.bind.address:localhost}\"/>\n                  <param key=\"port\"  value=\"${hornetq.remoting.netty.port:5445}\"/>\n               <\/acceptor>\n         */\n         switch (element) {\n         case ACCEPTOR:\n            String name = reader.getAttributeValue(0);\n            TransportConfiguration acceptorConfig = ElementUtils.parseTransportConfiguration(reader, name, Element.ACCEPTOR);\n            config.getAcceptorConfigurations().add(acceptorConfig);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.ACCEPTOR.getLocalName()));\n      if(trace)\n         log.trace(\"End \" + reader.getLocation() + reader.getLocalName());\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<AcceptorsElement> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14556,"modified_method":"@Override\n   protected Class<AcceptorsElement> getElementClass() {\n      return AcceptorsElement.class;\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public AddressSettingsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      System.out.println(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final Element element = Element.forName(reader.getLocalName());\n         /*\n            <address-settings>\n               <!--default for catch all-->\n               <address-setting match=\"#\">\n                  <dead-letter-address>jms.queue.DLQ<\/dead-letter-address>\n                  <expiry-address>jms.queue.ExpiryQueue<\/expiry-address>\n                  <redelivery-delay>0<\/redelivery-delay>\n                  <max-size-bytes>10485760<\/max-size-bytes>\n                  <message-counter-history-day-limit>10<\/message-counter-history-day-limit>\n                  <address-full-policy>BLOCK<\/address-full-policy>\n               <\/address-setting>\n            <\/address-settings>\n         */\n         switch (element) {\n         case ADDRESS_SETTING:\n            String match = reader.getAttributeValue(0);\n            Pair<String, AddressSettings> settings = parseAddressSettings(reader, match);\n            config.getAddressesSettings().put(settings.a, settings.b);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.ADDRESS_SETTING.getLocalName()));\n   }","id":14557,"modified_method":"public AddressSettingsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      boolean trace = log.isTraceEnabled();\n      if(trace)\n         log.trace(\"Begin \" + reader.getLocation() + reader.getLocalName());      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final Element element = Element.forName(reader.getLocalName());\n         /*\n            <address-settings>\n               <!--default for catch all-->\n               <address-setting match=\"#\">\n                  <dead-letter-address>jms.queue.DLQ<\/dead-letter-address>\n                  <expiry-address>jms.queue.ExpiryQueue<\/expiry-address>\n                  <redelivery-delay>0<\/redelivery-delay>\n                  <max-size-bytes>10485760<\/max-size-bytes>\n                  <message-counter-history-day-limit>10<\/message-counter-history-day-limit>\n                  <address-full-policy>BLOCK<\/address-full-policy>\n               <\/address-setting>\n            <\/address-settings>\n         */\n         switch (element) {\n         case ADDRESS_SETTING:\n            String match = reader.getAttributeValue(0);\n            Pair<String, AddressSettings> settings = parseAddressSettings(reader, match);\n            config.getAddressesSettings().put(settings.a, settings.b);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.ADDRESS_SETTING.getLocalName()));\n      if(trace)\n         log.trace(\"End \" + reader.getLocation() + reader.getLocalName());\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<AddressSettingsElement> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14558,"modified_method":"@Override\n   protected Class<AddressSettingsElement> getElementClass() {\n      return AddressSettingsElement.class;  //To change body of implemented methods use File | Settings | File Templates.\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * Test the stax parsing of the domain-with-messaging.xml configuration\n    */\n   @Test\n   public void testStaxParser() {\n      final ParseResult<ServerModel> parseResult = new ParseResult<ServerModel>();\n      try {\n         final XMLMapper mapper = createXMLMapper();\n         URL configURL = getClass().getResource(\"/domain-with-messaging.xml\");\n         Assert.assertNotNull(\"domain-with-messaging.xml url is not null\", configURL);\n         System.out.println(\"configURL = \" + configURL);\n         BufferedReader reader = new BufferedReader(new InputStreamReader(configURL.openStream()));\n         mapper.parseDocument(parseResult, XMLInputFactory.newInstance().createXMLStreamReader(reader));\n         // Validate the configuration\n         MessagingSubsystemElement mse = MessagingSubsystemParser.getLastSubsystemElement();\n         ConfigurationElement config = mse.getConfiguration();\n         Configuration jmsConfig = config.getConfiguration();\n         Assert.assertEquals(\"bindings-directory\", \"${jboss.server.data.dir}/hornetq/bindings\", jmsConfig.getBindingsDirectory());\n         Assert.assertEquals(\"journal-min-files\", 10, jmsConfig.getJournalMinFiles());\n         Assert.assertEquals(\"paging-directory\", \"${jboss.server.data.dir}/hornetq/paging\", jmsConfig.getPagingDirectory());\n         Map<String, Set<Role>> securityRoleMap = jmsConfig.getSecurityRoles();\n         // Security\n         Assert.assertEquals(\"1 security roles\", 1, securityRoleMap.size());\n         Set<Role> securityRoles = securityRoleMap.values().iterator().next();\n         Role expectedRole = new Role(\"guest\", true, true, false, false, true, true, false);\n         Set<Role> expectedRoles = new HashSet<Role>();\n         expectedRoles.add(expectedRole);\n         Assert.assertEquals(\"guest role\", expectedRoles, securityRoles);\n         Map<String, TransportConfiguration> connectors = jmsConfig.getConnectorConfigurations();\n         Assert.assertEquals(\"3 connectors\", 3, connectors.size());\n         // The expected connector configuration\n         Map<String, Object> c0params = new HashMap<String, Object>();\n         c0params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         c0params.put(\"port\", \"${hornetq.remoting.netty.port:5445}\");\n         c0params.put(\"socket-ref\", \"hq:netty\");\n         TransportConfiguration c0 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyConnectorFactory\",\n            c0params , \"netty\");\n         Map<String, Object> c1params = new HashMap<String, Object>();\n         c1params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         c1params.put(\"port\", \"${hornetq.remoting.netty.batch.port:5455}\");\n         c1params.put(\"batch-delay\", \"50\");\n         c1params.put(\"socket-ref\", \"hq:netty-throughput\");\n         TransportConfiguration c1 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyConnectorFactory\",\n            c1params , \"netty-throughput\");\n         Map<String, Object> c2params = new HashMap<String, Object>();\n         c2params.put(\"server-id\", \"${hornetq.server-id:0}\");\n         TransportConfiguration c2 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.invm.InVMConnectorFactory\",\n            c2params , \"in-vm\");\n         Map<String, TransportConfiguration> expectedConnectors = new HashMap<String, TransportConfiguration>();\n         expectedConnectors.put(c0.getName(), c0);\n         expectedConnectors.put(c1.getName(), c1);\n         expectedConnectors.put(c2.getName(), c2);\n         for(String connKey : expectedConnectors.keySet()) {\n            TransportConfiguration tcex = expectedConnectors.get(connKey);\n            TransportConfiguration tc = connectors.get(connKey);\n            Assert.assertEquals(connKey, tcex, tc);\n         }\n\n         // The expected acceptor configuration\n         Set<TransportConfiguration> acceptors = jmsConfig.getAcceptorConfigurations();\n         Assert.assertEquals(\"3 acceptors\", 3, acceptors.size());\n                  Map<String, Object> a0params = new HashMap<String, Object>();\n         a0params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         a0params.put(\"port\", \"${hornetq.remoting.netty.port:5445}\");\n         a0params.put(\"socket-ref\", \"hq:netty\");         \n         TransportConfiguration a0 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory\",\n            a0params , \"netty\");\n         Map<String, Object> a1params = new HashMap<String, Object>();\n         a1params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         a1params.put(\"port\", \"${hornetq.remoting.netty.batch.port:5455}\");\n         a1params.put(\"batch-delay\", \"50\");\n         a1params.put(\"direct-deliver\", \"false\");\n         a1params.put(\"socket-ref\", \"hq:netty-throughput\");\n         TransportConfiguration a1 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory\",\n            a1params , \"netty-throughput\");\n         Map<String, Object> a2params = new HashMap<String, Object>();\n         a2params.put(\"server-id\", \"0\");\n         TransportConfiguration a2 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.invm.InVMAcceptorFactory\",\n            a2params , \"in-vm\");\n         Map<String, TransportConfiguration> expectedAcceptors = new HashMap<String, TransportConfiguration>();\n         expectedAcceptors.put(a0.getName(), a0);\n         expectedAcceptors.put(a1.getName(), a1);\n         expectedAcceptors.put(a2.getName(), a2);\n         for(TransportConfiguration tc : acceptors) {\n            TransportConfiguration tcex = expectedAcceptors.get(tc.getName());\n            Assert.assertEquals(tc.getName(), tcex, tc);\n         }\n      }\n      catch (Exception e) {\n         throw new RuntimeException(\"domain-with-messaging.xml\", e);\n      }\n\n   }","id":14559,"modified_method":"/**\n    * Test the stax parsing of the standalone-with-messaging.xml configuration\n    */\n   @Test\n   public void testStandaloneStaxParser() {\n      final ParseResult<ServerModel> parseResult = new ParseResult<ServerModel>();\n      // Enable the thread local mode for testing\n      MessagingSubsystemParser.enableThreadLocal(true);\n      try {\n         final XMLMapper mapper = createXMLMapper();\n         URL configURL = getClass().getResource(\"/standalone-with-messaging.xml\");\n         Assert.assertNotNull(\"standalone-with-messaging.xml url is not null\", configURL);\n         System.out.println(\"configURL = \" + configURL);\n         BufferedReader reader = new BufferedReader(new InputStreamReader(configURL.openStream()));\n         mapper.parseDocument(parseResult, XMLInputFactory.newInstance().createXMLStreamReader(reader));\n         // Validate the configuration\n         MessagingSubsystemElement mse = MessagingSubsystemParser.getLastSubsystemElement();\n         ConfigurationElement config = mse.getConfiguration();\n         Configuration jmsConfig = config.getConfiguration();\n         Assert.assertEquals(\"bindings-directory\", \"${jboss.server.data.dir}/hornetq/bindings\", jmsConfig.getBindingsDirectory());\n         Assert.assertEquals(\"journal-type\", JournalType.NIO, jmsConfig.getJournalType());         \n         Assert.assertEquals(\"journal-min-files\", 10, jmsConfig.getJournalMinFiles());\n         Assert.assertEquals(\"paging-directory\", \"${jboss.server.data.dir}/hornetq/paging\", jmsConfig.getPagingDirectory());\n         Map<String, Set<Role>> securityRoleMap = jmsConfig.getSecurityRoles();\n         // Security\n         Assert.assertEquals(\"1 security roles\", 1, securityRoleMap.size());\n         Set<Role> securityRoles = securityRoleMap.values().iterator().next();\n         Role expectedRole = new Role(\"guest\", true, true, false, false, true, true, false);\n         Set<Role> expectedRoles = new HashSet<Role>();\n         expectedRoles.add(expectedRole);\n         Assert.assertEquals(\"guest role\", expectedRoles, securityRoles);\n         Map<String, TransportConfiguration> connectors = jmsConfig.getConnectorConfigurations();\n         Assert.assertEquals(\"3 connectors\", 3, connectors.size());\n         // The expected connector configuration\n         Map<String, Object> c0params = new HashMap<String, Object>();\n         c0params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         c0params.put(\"port\", \"${hornetq.remoting.netty.port:5445}\");\n         c0params.put(\"socket-ref\", \"hq:netty\");\n         TransportConfiguration c0 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyConnectorFactory\",\n            c0params , \"netty\");\n         Map<String, Object> c1params = new HashMap<String, Object>();\n         c1params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         c1params.put(\"port\", \"${hornetq.remoting.netty.batch.port:5455}\");\n         c1params.put(\"batch-delay\", \"50\");\n         c1params.put(\"socket-ref\", \"hq:netty-throughput\");\n         TransportConfiguration c1 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyConnectorFactory\",\n            c1params , \"netty-throughput\");\n         Map<String, Object> c2params = new HashMap<String, Object>();\n         c2params.put(\"server-id\", \"${hornetq.server-id:0}\");\n         TransportConfiguration c2 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.invm.InVMConnectorFactory\",\n            c2params , \"in-vm\");\n         Map<String, TransportConfiguration> expectedConnectors = new HashMap<String, TransportConfiguration>();\n         expectedConnectors.put(c0.getName(), c0);\n         expectedConnectors.put(c1.getName(), c1);\n         expectedConnectors.put(c2.getName(), c2);\n         for(String connKey : expectedConnectors.keySet()) {\n            TransportConfiguration tcex = expectedConnectors.get(connKey);\n            TransportConfiguration tc = connectors.get(connKey);\n            Assert.assertEquals(connKey, tcex, tc);\n         }\n\n         // The expected acceptor configuration\n         Set<TransportConfiguration> acceptors = jmsConfig.getAcceptorConfigurations();\n         Assert.assertEquals(\"3 acceptors\", 3, acceptors.size());\n                  Map<String, Object> a0params = new HashMap<String, Object>();\n         a0params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         a0params.put(\"port\", \"${hornetq.remoting.netty.port:5445}\");\n         a0params.put(\"socket-ref\", \"hq:netty\");         \n         TransportConfiguration a0 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory\",\n            a0params , \"netty\");\n         Map<String, Object> a1params = new HashMap<String, Object>();\n         a1params.put(\"host\", \"${jboss.bind.address:localhost}\");\n         a1params.put(\"port\", \"${hornetq.remoting.netty.batch.port:5455}\");\n         a1params.put(\"batch-delay\", \"50\");\n         a1params.put(\"direct-deliver\", \"false\");\n         a1params.put(\"socket-ref\", \"hq:netty-throughput\");\n         TransportConfiguration a1 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.netty.NettyAcceptorFactory\",\n            a1params , \"netty-throughput\");\n         Map<String, Object> a2params = new HashMap<String, Object>();\n         a2params.put(\"server-id\", \"0\");\n         TransportConfiguration a2 = new TransportConfiguration(\"org.hornetq.core.remoting.impl.invm.InVMAcceptorFactory\",\n            a2params , \"in-vm\");\n         Map<String, TransportConfiguration> expectedAcceptors = new HashMap<String, TransportConfiguration>();\n         expectedAcceptors.put(a0.getName(), a0);\n         expectedAcceptors.put(a1.getName(), a1);\n         expectedAcceptors.put(a2.getName(), a2);\n         for(TransportConfiguration tc : acceptors) {\n            TransportConfiguration tcex = expectedAcceptors.get(tc.getName());\n            Assert.assertEquals(tc.getName(), tcex, tc);\n         }\n      }\n      catch (Exception e) {\n         throw new RuntimeException(\"standalone-with-messaging.xml\", e);\n      }\n      finally {\n         MessagingSubsystemParser.clearLastSubsystemElement();         \n      }\n\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<ConfigurationElement> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14560,"modified_method":"@Override\n   protected Class<ConfigurationElement> getElementClass() {\n      return ConfigurationElement.class;\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public ConfigurationElement(final XMLExtendedStreamReader reader) throws XMLStreamException {\n      System.out.println(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         System.out.println(localName + \" -> \" + element + \", event=\" + StaxEvent.tagToEvent(tag));\n         switch (element) {\n         case ACCEPTORS:\n            AcceptorsElement acceptors = new AcceptorsElement(reader, config);\n            break;\n         case ADDRESS_SETTINGS:\n            AddressSettingsElement ase = new AddressSettingsElement(reader, config);\n            break;\n         case ASYNC_CONNECTION_EXECUTION_ENABLED:\n            break;\n         case BACKUP:\n            break;\n         case BACKUP_CONNECTOR_REF:\n            break;\n         case BINDINGS_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setBindingsDirectory(text);\n            }\n         }\n         break;\n         case BROADCAST_PERIOD:\n            break;\n         case CLUSTERED: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setClustered(Boolean.getBoolean(text));\n            }\n         }\n         break;\n         case CLUSTER_PASSWORD:\n            break;\n         case CLUSTER_USER:\n            break;\n         case CONNECTION_TTL_OVERRIDE:\n            break;\n         case CONNECTORS:\n            ConnectorsElement connectors = new ConnectorsElement(reader, config);\n            break;\n         case CONNECTOR_REF:\n            break;\n         case CREATE_BINDINGS_DIR:\n            break;\n         case CREATE_JOURNAL_DIR:\n            break;\n         case FILE_DEPLOYMENT_ENABLED:\n            break;\n         case GROUP_ADDRESS:\n            break;\n         case GROUP_PORT:\n            break;\n         case GROUPING_HANDLER:\n            break;\n         case ID_CACHE_SIZE:\n            break;\n         case JMX_DOMAIN:\n            break;\n         case JMX_MANAGEMENT_ENABLED:\n            break;\n         case JOURNAL_BUFFER_SIZE:\n            break;\n         case JOURNAL_BUFFER_TIMEOUT:\n            break;\n         case JOURNAL_COMPACT_MIN_FILES:\n            break;\n         case JOURNAL_COMPACT_PERCENTAGE:\n            break;\n         case JOURNAL_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setJournalDirectory(text);\n            }\n         }\n         break;\n         case JOURNAL_MIN_FILES: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setJournalMinFiles(Integer.valueOf(text));\n            }\n         }\n         break;\n         case JOURNAL_SYNC_NON_TRANSACTIONAL:\n            break;\n         case JOURNAL_SYNC_TRANSACTIONAL:\n            break;\n         case JOURNAL_TYPE:\n            break;\n         case JOURNAL_FILE_SIZE:\n            break;\n         case JOURNAL_MAX_IO:\n            break;\n         case LARGE_MESSAGES_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setLargeMessagesDirectory(text);\n            }\n         }\n         break;\n         case LOCAL_BIND_ADDRESS:\n            break;\n         case LOCAL_BIND_PORT:\n            break;\n         case LOG_JOURNAL_WRITE_RATE:\n            break;\n         case MANAGEMENT_ADDRESS:\n            break;\n         case MANAGEMENT_NOTIFICATION_ADDRESS:\n            break;\n         case MEMORY_MEASURE_INTERVAL:\n            break;\n         case MEMORY_WARNING_THRESHOLD:\n            break;\n         case MESSAGE_COUNTER_ENABLED:\n            break;\n         case MESSAGE_COUNTER_MAX_DAY_HISTORY:\n            break;\n         case MESSAGE_COUNTER_SAMPLE_PERIOD:\n            break;\n         case MESSAGE_EXPIRY_SCAN_PERIOD:\n            break;\n         case MESSAGE_EXPIRY_THREAD_PRIORITY:\n            break;\n         case PAGING_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setPagingDirectory(text);\n            }\n         }\n         break;\n         case PERF_BLAST_PAGES:\n            break;\n         case PERSIST_DELIVERY_COUNT_BEFORE_DELIVERY:\n            break;\n         case PERSIST_ID_CACHE:\n            break;\n         case PERSISTENCE_ENABLED:\n            break;\n         case REFRESH_TIMEOUT:\n            break;\n         case REMOTING_INTERCEPTORS:\n            break;\n         case RUN_SYNC_SPEED_TEST:\n            break;\n         case SECURITY_ENABLED:\n            break;\n         case SECURITY_INVALIDATION_INTERVAL:\n            break;\n         case SECURITY_SETTINGS:\n            SecuritySettingsElement sse = new SecuritySettingsElement(reader, config);\n            break;\n         case SERVER_DUMP_INTERVAL:\n            break;\n         case SHARED_STORE:\n            break;\n         case TRANSACTION_TIMEOUT:\n            break;\n         case TRANSACTION_TIMEOUT_SCAN_PERIOD:\n            break;\n         case WILD_CARD_ROUTING_ENABLED:\n            break;\n         case DEAD_LETTER_ADDRESS_NODE_NAME:\n            break;\n         case EXPIRY_ADDRESS_NODE_NAME:\n            break;\n         case REDELIVERY_DELAY_NODE_NAME:\n            break;\n         case MAX_DELIVERY_ATTEMPTS:\n            break;\n         case MAX_SIZE_BYTES_NODE_NAME:\n            break;\n         case ADDRESS_FULL_MESSAGE_POLICY_NODE_NAME:\n            break;\n         case PAGE_SIZE_BYTES_NODE_NAME:\n            break;\n         case MESSAGE_COUNTER_HISTORY_DAY_LIMIT_NODE_NAME:\n            break;\n         case LVQ_NODE_NAME:\n            break;\n         case REDISTRIBUTION_DELAY_NODE_NAME:\n            break;\n         case SEND_TO_DLA_ON_NO_ROUTE:\n            break;\n         case SUBSYSTEM:\n\n            break;\n         default:\n            throw unexpectedElement(reader);\n         }\n      } while (reader.hasNext() && localName.equals(\"subsystem\") == false);\n\n      // Set the log delegate\n      //config.setLogDelegateFactoryClassName();\n      System.out.println(\"End messaging:subsystem, \" + reader.getLocalName() + \", hasNext: \" + reader.hasNext());\n   }","id":14561,"modified_method":"public ConfigurationElement(final XMLExtendedStreamReader reader) throws XMLStreamException {\n      boolean trace = log.isTraceEnabled();\n      if(trace)\n         log.trace(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final Element element = Element.forName(reader.getLocalName());\n         if(trace)\n            log.trace(localName + \" -> \" + element + \", event=\" + ElementUtils.StaxEvent.tagToEvent(tag));\n         switch (element) {\n         case ACCEPTORS:\n            AcceptorsElement acceptors = new AcceptorsElement(reader, config);\n            break;\n         case ADDRESS_SETTINGS:\n            AddressSettingsElement ase = new AddressSettingsElement(reader, config);\n            break;\n         case ASYNC_CONNECTION_EXECUTION_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case BACKUP:\n            unhandledElement(reader, element);\n            break;\n         case BACKUP_CONNECTOR_REF:\n            unhandledElement(reader, element);\n            break;\n         case BINDINGS_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setBindingsDirectory(text);\n            }\n         }\n         break;\n         case BROADCAST_PERIOD:\n            unhandledElement(reader, element);\n            break;\n         case CLUSTERED: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setClustered(Boolean.getBoolean(text));\n            }\n         }\n         break;\n         case CLUSTER_PASSWORD:\n            unhandledElement(reader, element);\n            break;\n         case CLUSTER_USER:\n            unhandledElement(reader, element);\n            break;\n         case CONNECTION_TTL_OVERRIDE:\n            unhandledElement(reader, element);\n            break;\n         case CONNECTORS:\n            ConnectorsElement connectors = new ConnectorsElement(reader, config);\n            break;\n         case CONNECTOR_REF:\n            unhandledElement(reader, element);\n            break;\n         case CREATE_BINDINGS_DIR:\n            unhandledElement(reader, element);\n            break;\n         case CREATE_JOURNAL_DIR:\n            unhandledElement(reader, element);\n            break;\n         case FILE_DEPLOYMENT_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case GROUP_ADDRESS:\n            unhandledElement(reader, element);\n            break;\n         case GROUP_PORT:\n            unhandledElement(reader, element);\n            break;\n         case GROUPING_HANDLER:\n            unhandledElement(reader, element);\n            break;\n         case ID_CACHE_SIZE:\n            unhandledElement(reader, element);\n            break;\n         case JMX_DOMAIN:\n            unhandledElement(reader, element);\n            break;\n         case JMX_MANAGEMENT_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_BUFFER_SIZE:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_BUFFER_TIMEOUT:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_COMPACT_MIN_FILES:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_COMPACT_PERCENTAGE:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setJournalDirectory(text);\n            }\n         }\n         break;\n         case JOURNAL_MIN_FILES: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setJournalMinFiles(Integer.valueOf(text));\n            }\n         }\n         break;\n         case JOURNAL_SYNC_NON_TRANSACTIONAL:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_SYNC_TRANSACTIONAL:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_TYPE:{\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               JournalType jtype = JournalType.valueOf(text);\n               config.setJournalType(jtype);\n            }\n         }\n         break;\n         case JOURNAL_FILE_SIZE:\n            unhandledElement(reader, element);\n            break;\n         case JOURNAL_MAX_IO:\n            unhandledElement(reader, element);\n            break;\n         case LARGE_MESSAGES_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setLargeMessagesDirectory(text);\n            }\n         }\n         break;\n         case LOCAL_BIND_ADDRESS:\n            unhandledElement(reader, element);\n            break;\n         case LOCAL_BIND_PORT:\n            unhandledElement(reader, element);\n            break;\n         case LOG_JOURNAL_WRITE_RATE:\n            unhandledElement(reader, element);\n            break;\n         case MANAGEMENT_ADDRESS:\n            unhandledElement(reader, element);\n            break;\n         case MANAGEMENT_NOTIFICATION_ADDRESS:\n            unhandledElement(reader, element);\n            break;\n         case MEMORY_MEASURE_INTERVAL:\n            unhandledElement(reader, element);\n            break;\n         case MEMORY_WARNING_THRESHOLD:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_COUNTER_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_COUNTER_MAX_DAY_HISTORY:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_COUNTER_SAMPLE_PERIOD:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_EXPIRY_SCAN_PERIOD:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_EXPIRY_THREAD_PRIORITY:\n            unhandledElement(reader, element);\n            break;\n         case PAGING_DIRECTORY: {\n            String text = reader.getElementText();\n            if (text != null && text.length() > 0) {\n               config.setPagingDirectory(text);\n            }\n         }\n         break;\n         case PERF_BLAST_PAGES:\n            unhandledElement(reader, element);\n            break;\n         case PERSIST_DELIVERY_COUNT_BEFORE_DELIVERY:\n            unhandledElement(reader, element);\n            break;\n         case PERSIST_ID_CACHE:\n            unhandledElement(reader, element);\n            break;\n         case PERSISTENCE_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case REFRESH_TIMEOUT:\n            unhandledElement(reader, element);\n            break;\n         case REMOTING_INTERCEPTORS:\n            unhandledElement(reader, element);\n            break;\n         case RUN_SYNC_SPEED_TEST:\n            unhandledElement(reader, element);\n            break;\n         case SECURITY_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case SECURITY_INVALIDATION_INTERVAL:\n            unhandledElement(reader, element);\n            break;\n         case SECURITY_SETTINGS:\n            SecuritySettingsElement sse = new SecuritySettingsElement(reader, config);\n            break;\n         case SERVER_DUMP_INTERVAL:\n            unhandledElement(reader, element);\n            break;\n         case SHARED_STORE:\n            unhandledElement(reader, element);\n            break;\n         case TRANSACTION_TIMEOUT:\n            unhandledElement(reader, element);\n            break;\n         case TRANSACTION_TIMEOUT_SCAN_PERIOD:\n            unhandledElement(reader, element);\n            break;\n         case WILD_CARD_ROUTING_ENABLED:\n            unhandledElement(reader, element);\n            break;\n         case DEAD_LETTER_ADDRESS_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case EXPIRY_ADDRESS_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case REDELIVERY_DELAY_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case MAX_DELIVERY_ATTEMPTS:\n            unhandledElement(reader, element);\n            break;\n         case MAX_SIZE_BYTES_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case ADDRESS_FULL_MESSAGE_POLICY_NODE_NAME:\n               unhandledElement(reader, element);\n            break;\n         case PAGE_SIZE_BYTES_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case MESSAGE_COUNTER_HISTORY_DAY_LIMIT_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case LVQ_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case REDISTRIBUTION_DELAY_NODE_NAME:\n            unhandledElement(reader, element);\n            break;\n         case SEND_TO_DLA_ON_NO_ROUTE:\n            unhandledElement(reader, element);\n            break;\n         case SUBSYSTEM:\n            // The end of the subsystem element\n            break;\n         default:\n            throw unexpectedElement(reader);\n         }\n      } while (reader.hasNext() && localName.equals(\"subsystem\") == false);\n\n      // Set the log delegate\n      //config.setLogDelegateFactoryClassName();\n      if(trace)\n         log.trace(\"End messaging:subsystem, \" + reader.getLocalName() + \", hasNext: \" + reader.hasNext());\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public ConnectorsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      System.out.println(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n            <connector name=\"netty\">\n               <factory-class>org.hornetq.core.remoting.impl.netty.NettyConnectorFactory<\/factory-class>\n               <param key=\"host\"  value=\"${jboss.bind.address:localhost}\"/>\n               <param key=\"port\"  value=\"${hornetq.remoting.netty.port:5445}\"/>\n            <\/connector>\n         */\n         switch (element) {\n         case CONNECTOR:\n            String name = reader.getAttributeValue(0);\n            parseConnector(reader, name, config);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(org.jboss.as.messaging.Element.CONNECTOR.getLocalName()));\n\n   }","id":14562,"modified_method":"public ConnectorsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      boolean trace = log.isTraceEnabled();\n      if(trace)\n         log.trace(\"Begin \" + reader.getLocation() + reader.getLocalName());      // Handle elements\n\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n            <connector name=\"netty\">\n               <factory-class>org.hornetq.core.remoting.impl.netty.NettyConnectorFactory<\/factory-class>\n               <param key=\"host\"  value=\"${jboss.bind.address:localhost}\"/>\n               <param key=\"port\"  value=\"${hornetq.remoting.netty.port:5445}\"/>\n            <\/connector>\n         */\n         switch (element) {\n         case CONNECTOR:\n            String name = reader.getAttributeValue(0);\n            parseConnector(reader, name, config);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(org.jboss.as.messaging.Element.CONNECTOR.getLocalName()));\n      if(trace)\n         log.trace(\"End \" + reader.getLocation() + reader.getLocalName());\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<ConnectorsElement> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14563,"modified_method":"@Override\n   protected Class<ConnectorsElement> getElementClass() {\n      return ConnectorsElement.class;\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * {@inheritDoc}\n    */\n   public synchronized void start(final StartContext context) throws StartException {\n      try {\n         // Update the acceptor/connector port/host values from the\n         // Map the socket bindings onto the connectors/acceptors\n         Collection<TransportConfiguration> acceptors = configuration.getAcceptorConfigurations();\n         Collection<TransportConfiguration> connectors = configuration.getConnectorConfigurations().values();\n         if (connectors != null) {\n            for (TransportConfiguration tc : connectors) {\n               SocketBinding binding = socketBindings.get(tc.getName());\n               if (binding == null) {\n                  throw new StartException(\"Failed to find SocketBinding for connector: \" + tc.getName());\n               }\n               log.debug(\"Applying socket binding: \"+binding);\n               tc.getParams().put(HOST, binding.getSocketAddress().getHostName());\n               tc.getParams().put(PORT, \"\" + binding.getSocketAddress().getPort());\n            }\n         }\n         if (acceptors != null) {\n            for (TransportConfiguration tc : acceptors) {\n               SocketBinding binding = socketBindings.get(tc.getName());\n               if (binding == null) {\n                  throw new StartException(\"Failed to find SocketBinding for acceptor: \" + tc.getName());\n               }\n               log.debug(\"Applying socket binding: \"+binding);\n               tc.getParams().put(HOST, binding.getSocketAddress().getHostName());\n               tc.getParams().put(PORT, \"\" + binding.getSocketAddress().getPort());\n            }\n         }\n\n         // Now start the server\n         server = new HornetQServerImpl(configuration);\n         log.info(\"Starting the HornetQServer...\");\n         server.start();\n      } catch (Exception e) {\n         throw new StartException(\"Failed to start service\", e);\n      }\n   }","id":14564,"modified_method":"/**\n    * {@inheritDoc}\n    */\n   public synchronized void start(final StartContext context) throws StartException {\n      ClassLoader origTCCL = SecurityActions.getContextClassLoader();\n      // Validate whether the AIO native layer can be used\n      JournalType jtype = configuration.getJournalType();\n      if (jtype == JournalType.ASYNCIO) {\n         boolean supportsAIO = AIOSequentialFileFactory.isSupported();\n\n         if (supportsAIO == false) {\n            log.warn(\"AIO wasn't located on this platform, it will fall back to using pure Java NIO. If your platform is Linux, install LibAIO to enable the AIO journal\");\n            configuration.setJournalType(JournalType.NIO);\n         }\n      }\n\n      try {\n         // Update the acceptor/connector port/host values from the\n         // Map the socket bindings onto the connectors/acceptors\n         Collection<TransportConfiguration> acceptors = configuration.getAcceptorConfigurations();\n         Collection<TransportConfiguration> connectors = configuration.getConnectorConfigurations().values();\n         if (connectors != null) {\n            for (TransportConfiguration tc : connectors) {\n               // If there is a socket binding set the HOST/PORT values\n               Object socketRef = tc.getParams().remove(SOCKET_REF);\n               if (socketRef != null) {\n                  String name = socketRef.toString();\n                  SocketBinding binding = socketBindings.get(name);\n                  if (binding == null) {\n                     throw new StartException(\"Failed to find SocketBinding for connector: \" + tc.getName());\n                  }\n                  log.debug(\"Applying socket binding: \" + binding);\n                  tc.getParams().put(HOST, binding.getSocketAddress().getHostName());\n                  tc.getParams().put(PORT, \"\" + binding.getSocketAddress().getPort());\n               }\n            }\n         }\n         if (acceptors != null) {\n            for (TransportConfiguration tc : acceptors) {\n               // If there is a socket binding set the HOST/PORT values\n               Object socketRef = tc.getParams().remove(SOCKET_REF);\n               if (socketRef != null) {\n                  String name = socketRef.toString();\n                  SocketBinding binding = socketBindings.get(name);\n                  if (binding == null) {\n                     throw new StartException(\"Failed to find SocketBinding for connector: \" + tc.getName());\n                  }\n                  log.debug(\"Applying socket binding: \" + binding);\n                  tc.getParams().put(HOST, binding.getSocketAddress().getHostName());\n                  tc.getParams().put(PORT, \"\" + binding.getSocketAddress().getPort());\n               }\n            }\n         }\n\n         // Now start the server\n         server = new HornetQServerImpl(configuration);\n         // HornetQ expects the TCCL to be set to something that can find the log factory class.\n         ClassLoader loader = getClass().getClassLoader();\n         SecurityActions.setContextClassLoader(loader);\n         log.info(\"Starting the HornetQServer...\");\n         server.start();\n      } catch (Exception e) {\n         throw new StartException(\"Failed to start service\", e);\n      }\n      finally {\n         SecurityActions.setContextClassLoader(origTCCL);\n      }\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * {@inheritDoc}\n    */\n   public void registerElementHandlers(final XMLMapper mapper) {\n      mapper.registerRootElement(new QName(Namespace.MESSAGING_1_0.getUriString(), Element.SUBSYSTEM.getLocalName()), MessagingSubsystemParser.getInstance());\n   }","id":14565,"modified_method":"/**\n    * {@inheritDoc}\n    */\n   public void registerElementHandlers(final XMLMapper mapper) {\n      QName messagingNamespace = new QName(Namespace.MESSAGING_1_0.getUriString(), Element.SUBSYSTEM.getLocalName());\n      mapper.registerRootElement(messagingNamespace, MessagingSubsystemParser.getInstance());\n      log.info(\"Registered messaging subsystem under: \"+messagingNamespace);\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * Add the HornetQServer to the subsystem batch\n    */\n   public void activate(final ServiceActivatorContext context) {\n      log.info(\"Activating Messaging Subsystem\");\n      HornetQService hqservice = new HornetQService();\n      Configuration hqConfig = configuration.getConfiguration();\n      hqservice.setConfiguration(hqConfig);\n\n      final BatchBuilder batchBuilder = context.getBatchBuilder();\n\n      final BatchServiceBuilder<HornetQServer> serviceBuilder = batchBuilder.addService(JBOSS_MESSAGING, hqservice);\n      // Add the dependencies on the connectors and acceptors\n      Collection<TransportConfiguration> acceptors = hqConfig.getAcceptorConfigurations();\n      Collection<TransportConfiguration> connectors = hqConfig.getConnectorConfigurations().values();\n      if(connectors != null) {\n         for(TransportConfiguration tc : connectors) {\n            String name = tc.getName();\n            ServiceName connectorSocketName = SocketBinding.JBOSS_BINDING_NAME.append();\n            serviceBuilder.addDependency(connectorSocketName, SocketBinding.class, hqservice.getSocketBindingInjector(name));\n         }\n      }\n      //\n      if(acceptors != null) {\n         for(TransportConfiguration tc : acceptors) {\n            String name = tc.getName();\n            ServiceName connectorSocketName = SocketBinding.JBOSS_BINDING_NAME.append();\n            serviceBuilder.addDependency(connectorSocketName, SocketBinding.class, hqservice.getSocketBindingInjector(name));\n         }\n      }\n\n      serviceBuilder.setInitialMode(ServiceController.Mode.IMMEDIATE);\n   }","id":14566,"modified_method":"/**\n    * Add the HornetQServer to the subsystem batch\n    */\n   public void activate(final ServiceActivatorContext context) {\n      log.info(\"Activating Messaging Subsystem\");\n      HornetQService hqservice = new HornetQService();\n      Configuration hqConfig = configuration.getConfiguration();\n      hqservice.setConfiguration(hqConfig);\n\n      final BatchBuilder batchBuilder = context.getBatchBuilder();\n\n      final BatchServiceBuilder<HornetQServer> serviceBuilder = batchBuilder.addService(JBOSS_MESSAGING, hqservice);\n      // Add the dependencies on the connectors and acceptors\n      Collection<TransportConfiguration> acceptors = hqConfig.getAcceptorConfigurations();\n      Collection<TransportConfiguration> connectors = hqConfig.getConnectorConfigurations().values();\n      if(connectors != null) {\n         for(TransportConfiguration tc : connectors) {\n            Object socketRef = tc.getParams().get(\"socket-ref\");\n            // Add a dependency on a SocketBinding if there is a socket-ref\n            if(socketRef != null) {\n               String name = socketRef.toString();\n               ServiceName socketName = SocketBinding.JBOSS_BINDING_NAME.append(name);\n               serviceBuilder.addDependency(socketName, SocketBinding.class, hqservice.getSocketBindingInjector(name));\n            }\n         }\n      }\n      //\n      if(acceptors != null) {\n         for(TransportConfiguration tc : acceptors) {\n            Object socketRef = tc.getParams().get(\"socket-ref\");\n            // Add a dependency on a SocketBinding if there is a socket-ref\n            if(socketRef != null) {\n               String name = socketRef.toString();\n               ServiceName socketName = SocketBinding.JBOSS_BINDING_NAME.append(name);\n               serviceBuilder.addDependency(socketName, SocketBinding.class, hqservice.getSocketBindingInjector(name));\n            }\n         }\n      }\n\n      serviceBuilder.setInitialMode(ServiceController.Mode.IMMEDIATE);\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * For testing only.\n    */\n   public static MessagingSubsystemElement getLastSubsystemElement() {\n      return LAST_ELEMENT.get();\n   }","id":14567,"modified_method":"public static MessagingSubsystemElement getLastSubsystemElement() {\n      return LAST_ELEMENT.get();\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n    * {@inheritDoc}\n    */\n   public void readElement(final XMLExtendedStreamReader reader, final ParseResult<? super MessagingSubsystemElement> result) throws XMLStreamException {\n      System.out.println(\"MessagingSubsystemElement.readElement\");\n      MessagingSubsystemElement msp = new MessagingSubsystemElement(reader);\n      LAST_ELEMENT.set(msp);\n      result.setResult(msp);\n   }","id":14568,"modified_method":"/**\n    * {@inheritDoc}\n    */\n   public void readElement(final XMLExtendedStreamReader reader, final ParseResult<? super MessagingSubsystemElement> result) throws XMLStreamException {\n      log.debug(\"MessagingSubsystemElement.readElement, event=\"+reader.getEventType());\n      MessagingSubsystemElement msp = new MessagingSubsystemElement(reader);\n      if(useThreadLocal)\n         LAST_ELEMENT.set(msp);\n      result.setResult(msp);\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<NullSubsystemElement<T>> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14569,"modified_method":"@Override\n   protected Class<NullSubsystemElement<Object>> getElementClass() {\n      Class<NullSubsystemElement<Object>> c = (Class<NullSubsystemElement<Object>>) getClass();\n      return c;\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   public void readElement(XMLExtendedStreamReader reader, ParseResult<NullSubsystemElement> result) throws XMLStreamException {\n      System.out.println(getClass().getCanonicalName()+\".readElement, \"+reader.getLocalName());\n      NullSubsystemElement element = new NullSubsystemElement(reader);\n      result.setResult(element);\n   }","id":14570,"modified_method":"@Override\n   public void readElement(XMLExtendedStreamReader reader, ParseResult<NullSubsystemElement<Object>> result) throws XMLStreamException {\n      System.out.println(getClass().getCanonicalName()+\".readElement, \"+reader.getLocalName());\n      NullSubsystemElement<Object> element = new NullSubsystemElement(reader);\n      result.setResult(element);\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public SecuritySettingsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      System.out.println(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n            <security-setting match=\"#\">\n            <permission type=\"createNonDurableQueue\" roles=\"guest\"/>\n            <permission type=\"deleteNonDurableQueue\" roles=\"guest\"/>\n            <permission type=\"consume\" roles=\"guest\"/>\n            <permission type=\"send\" roles=\"guest\"/>\n            <\/security-setting>\n         */\n         switch (element) {\n         case SECURITY_SETTING:\n            String match = reader.getAttributeValue(0);\n            Pair<String, Set<Role>> roles = parseSecurityRoles(reader, match);\n            config.getSecurityRoles().put(roles.a, roles.b);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.SECURITY_SETTING.getLocalName()));\n   }","id":14571,"modified_method":"public SecuritySettingsElement(final XMLExtendedStreamReader reader, Configuration config) throws XMLStreamException {\n      boolean trace = log.isTraceEnabled();\n      if(trace)\n         log.trace(\"Begin \" + reader.getLocation() + reader.getLocalName());\n      // Handle elements\n      int tag = reader.getEventType();\n      String localName = null;\n      do {\n         tag = reader.nextTag();\n         localName = reader.getLocalName();\n         final org.jboss.as.messaging.Element element = org.jboss.as.messaging.Element.forName(reader.getLocalName());\n         /*\n            <security-setting match=\"#\">\n            <permission type=\"createNonDurableQueue\" roles=\"guest\"/>\n            <permission type=\"deleteNonDurableQueue\" roles=\"guest\"/>\n            <permission type=\"consume\" roles=\"guest\"/>\n            <permission type=\"send\" roles=\"guest\"/>\n            <\/security-setting>\n         */\n         switch (element) {\n         case SECURITY_SETTING:\n            String match = reader.getAttributeValue(0);\n            Pair<String, Set<Role>> roles = parseSecurityRoles(reader, match);\n            config.getSecurityRoles().put(roles.a, roles.b);\n            break;\n         }\n      } while (reader.hasNext() && localName.equals(Element.SECURITY_SETTING.getLocalName()));\n      if(trace)\n         log.trace(\"End \" + reader.getLocation() + reader.getLocalName());\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n   protected Class<SecuritySettingsElement> getElementClass() {\n      return null;  //To change body of implemented methods use File | Settings | File Templates.\n   }","id":14572,"modified_method":"@Override\n   protected Class<SecuritySettingsElement> getElementClass() {\n      return SecuritySettingsElement.class;\n   }","commit_id":"e8827754c2c83a7879e858b11471c670d45911e1","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n\n        prop.put(\"showtable\", 0);\n        prop.put(\"showedit\", 0);\n        prop.put(\"showselection\", 0);\n        \n        String table = (post == null) ? \"admin_bookmarks\" : post.get(\"table\", \"admin_bookmarks\");\n        if (table != null && !sb.tables.hasHeap(table)) table = null;\n        \n        // get the user name for the selected table\n        String bmk_user = null;\n        if (table != null)\n        \tbmk_user = table.substring(0,table.indexOf('_'));\n        \n        // currently selected table\n        prop.put(\"showselection_table\", table);\n        \n        // show table selection\n        int count = 0;\n        Iterator<String> ti = sb.tables.tables();\n        String tablename;\n        prop.put(\"showselection\", 1);\n        while (ti.hasNext()) {\n            tablename = ti.next();\n            if(tablename.endsWith(YMarkTables.TABLES.BOOKMARKS.basename())) {\n                prop.put(\"showselection_tables_\" + count + \"_name\", tablename);\n                prop.put(\"showselection_tables_\" + count + \"_selected\", (table != null && table.equals(tablename)) ? 1 : 0);\n                count++;\n            }\n        }\n        prop.put(\"showselection_tables\", count);\n        prop.put(\"showselection_pattern\", \"\");\n\n        if (post == null) return prop; // return rewrite properties\n        \n        // get available tags and folders\n        count = 0;\n        byte[] key;\n        String name;\n        try {\n\t\t\tIterator<byte[]> iter = sb.tables.keys(YMarkTables.TABLES.TAGS.tablename(bmk_user));\n\t\t\twhile(iter.hasNext()) {\n\t\t\t\tkey = iter.next();\n\t\t\t\tname = sb.tables.bookmarks.tags.getKeyname(bmk_user, key);\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagHash\", UTF8.String(key));\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagName\", name);\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagCount\", sb.tables.bookmarks.tags.getBookmarkIds(bmk_user, name).size());\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tprop.put(\"showselection_tags\", count);\n\t\t\tcount = 0;\n\t\t\titer = sb.tables.keys(YMarkTables.TABLES.FOLDERS.tablename(bmk_user));\n\t\t\twhile(iter.hasNext()) {\n\t\t\t\tkey = iter.next();\n\t\t\t\tname = sb.tables.bookmarks.folders.getKeyname(bmk_user, key);\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderHash\", UTF8.String(key));\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderName\", name);\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderCount\", sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, name).size());\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tprop.put(\"showselection_folders\", count);\n\t\t} catch (IOException e) {\n            Log.logException(e);\n\t\t} catch (RowSpaceExceededException e) {\n            Log.logException(e);\n\t\t}\n\t\t\n        final String counts = post.get(\"count\", null);\n        int maxcount = (counts == null || counts.equals(\"all\")) ? Integer.MAX_VALUE : post.getInt(\"count\", 10);\n        String pattern = post.get(\"search\", \"\");\n        Pattern matcher = (pattern.isEmpty() || pattern.equals(\".*\")) ? null : Pattern.compile(\".*\" + pattern + \".*\");\n        prop.put(\"pattern\", pattern);\n        \n        List<String> columns = new ArrayList<String>();\n        for (final Map.Entry<String, String> entry: post.entrySet()) {\n            if (entry.getKey().startsWith(\"col_\")) {\n            \tcolumns.add(entry.getKey().substring(4));\n            }\n        }\n        if (columns.isEmpty() && table != null) try {\n            columns = sb.tables.columns(table);\n        } catch (IOException e) {\n            Log.logException(e);\n        }\n        \n        count = 0;\n        if (table != null) {\n            Iterator<String> cit;\n            String col;\n            try {\n                cit = sb.tables.columns(table).iterator();\n    \t        while(cit.hasNext()) {\n                    col = cit.next();\n                    prop.put(\"showselection_columns_\" + count + \"_col\", col);\n                    prop.put(\"showselection_columns_\" + count + \"_checked\", columns.contains(col) ? 1 : 0);\n                    count++;\n    \t        }\n            } catch (IOException e) {\n                Log.logException(e);\n            }\n        }\n        prop.put(\"showselection_columns\", count);\n        \n        // apply deletion requests\n        if (!post.get(\"deletetable\", \"\").isEmpty()) try {\n            sb.tables.clear(table);\n            sb.tables.clear(YMarkTables.TABLES.FOLDERS.tablename(bmk_user));\n            sb.tables.clear(YMarkTables.TABLES.TAGS.tablename(bmk_user));\n        } catch (IOException e) {\n            Log.logException(e);\n        }\n        \n        // apply rebuildIndex request\n        if (!post.get(\"rebuildindex\", \"\").isEmpty()) try {\n            sb.tables.bookmarks.folders.rebuildIndex(bmk_user);\n            sb.tables.bookmarks.tags.rebuildIndex(bmk_user);\n        }  catch (IOException e) {\n            Log.logException(e);\n        }\n        \n        if (!post.get(\"deleterows\", \"\").isEmpty()) {\n            for (final Map.Entry<String, String> entry: post.entrySet()) {\n                if (entry.getValue().startsWith(\"mark_\")) try {\n                    sb.tables.bookmarks.deleteBookmark(bmk_user, entry.getValue().substring(5).getBytes());\n                } catch (IOException e) {\n                    Log.logException(e);\n                } catch (RowSpaceExceededException e) {\n                    Log.logException(e);\n                }\n            }\n        }\n        \n        if (!post.get(\"commitrow\", \"\").isEmpty()) {\n            final HashMap<String, String> bmk = new HashMap<String, String>();\n            for (final Map.Entry<String, String> entry: post.entrySet()) {\n                if (entry.getKey().startsWith(\"col_\")) {\n                    bmk.put(entry.getKey().substring(4), entry.getValue());\n                }\n            }\n            try {\n                sb.tables.bookmarks.addBookmark(bmk_user, bmk, false);\n            } catch (IOException e) {\n                Log.logException(e);\n            } catch (RowSpaceExceededException e) {\n                Log.logException(e);\n            }\n        }\n        \n        // generate table\n        prop.put(\"showtable\", 0);\n        prop.put(\"showedit\", 0);\n        \n        if (table != null) {\n            \n            if (post.containsKey(\"editrow\")) {\n                // check if we can find a key\n                String pk = null;\n                for (final Map.Entry<String, String> entry: post.entrySet()) {\n                    if (entry.getValue().startsWith(\"mark_\")) {\n                        pk = entry.getValue().substring(5);\n                        break;\n                    }\n                }\n                try {\n                    if (pk != null && sb.tables.has(table, pk.getBytes())) {\n                        setEdit(sb, prop, table, pk, columns);\n                    }\n                } catch (IOException e) {\n                    Log.logException(e);\n                } catch (RowSpaceExceededException e) {\n                    Log.logException(e);\n                }\n            } else if (post.containsKey(\"addrow\")) try {\n                // get a new key\n                final String pk = UTF8.String(sb.tables.createRow(table));\n                setEdit(sb, prop, table, pk, columns);\n            } catch (IOException e) {\n                Log.logException(e);\n            } catch (RowSpaceExceededException e) {\n                Log.logException(e);\n            } else {\n                prop.put(\"showtable\", 1);\n                prop.put(\"showtable_table\", table);\n               \n                \n                try {\n                    prop.put(\"showtable_bmksize\", sb.tables.size(table));\n                    prop.put(\"showtable_tagsize\", sb.tables.size(YMarkTables.TABLES.TAGS.tablename(bmk_user)));\n                    prop.put(\"showtable_foldersize\", sb.tables.size(YMarkTables.TABLES.FOLDERS.tablename(bmk_user)));\n                } catch (IOException e) {\n                    Log.logException(e);\n                    prop.put(\"showtable_bmksize\", 0);\n                    prop.put(\"showtable_tagsize\", 0);\n                    prop.put(\"showtable_foldersize\", 0);\n                }\n                \n                // insert the columns\n                \n                for (int i = 0; i < columns.size(); i++) {\n                    prop.putHTML(\"showtable_columns_\" + i + \"_header\", columns.get(i));\n                }\n                prop.put(\"showtable_columns\", columns.size());\n                \n                // insert all rows\n                try {\n                    maxcount = Math.min(maxcount, sb.tables.size(table));\n                } catch (IOException e) {\n                    Log.logException(e);\n                    maxcount = 0;\n                }\n                count = 0;\n                try {\n                    Iterator<Tables.Row> mapIterator;\n                    if (post.containsKey(\"folders\") && !post.get(\"folders\").isEmpty()) {\n                        mapIterator = sb.tables.orderByPK(sb.tables.bookmarks.folders.getBookmarks(bmk_user, post.get(\"folders\")), maxcount).iterator();\n                    } else if(post.containsKey(\"tags\") && !post.get(\"tags\").isEmpty()) {\n                    \tmapIterator = sb.tables.orderByPK(sb.tables.bookmarks.tags.getBookmarks(bmk_user, post.get(\"tags\")), maxcount).iterator();\n                    } else {\n                    \tmapIterator = sb.tables.orderByPK(sb.tables.iterator(table, matcher), maxcount).iterator();\n                    }\n                    \n                    Tables.Row row;\n                    boolean dark = true;\n                    byte[] cell;\n                    while (mapIterator.hasNext() && count < maxcount) {\n                        row = mapIterator.next();\n                        if (row == null) continue;\n                        \n                        // write table content\n                        prop.put(\"showtable_list_\" + count + \"_dark\", ((dark) ? 1 : 0) ); dark=!dark;\n                        prop.put(\"showtable_list_\" + count + \"_pk\", UTF8.String(row.getPK()));\n                        prop.put(\"showtable_list_\" + count + \"_count\", count);\n                        for (int i = 0; i < columns.size(); i++) {\n                            cell = row.get(columns.get(i));\n                            prop.putHTML(\"showtable_list_\" + count + \"_columns_\" + i + \"_cell\", cell == null ? \"\" : UTF8.String(cell));\n                        }\n                        prop.put(\"showtable_list_\" + count + \"_columns\", columns.size());\n                        count++;\n                    }\n                } catch (IOException e) {\n                    Log.logException(e);\n                } catch (RowSpaceExceededException e) {\n                    Log.logException(e);\n\t\t\t\t}\n                prop.put(\"showtable_list\", count);\n                prop.put(\"showtable_num\", count);\n            }\n            \n        }\n        \n        // adding the peer address\n        prop.put(\"address\", sb.peers.mySeed().getPublicAddress());\n        \n        // return rewrite properties\n        return prop;\n    }","id":14573,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n\n        prop.put(\"showtable\", 0);\n        prop.put(\"showedit\", 0);\n        prop.put(\"showselection\", 0);\n        \n        String table = (post == null) ? \"admin_bookmarks\" : post.get(\"table\", \"admin_bookmarks\");\n        if (table != null && !sb.tables.hasHeap(table)) table = null;\n        \n        // get the user name for the selected table\n        String bmk_user = null;\n        if (table != null)\n        \tbmk_user = table.substring(0,table.indexOf('_'));\n        \n        // currently selected table\n        prop.put(\"showselection_table\", table);\n        \n        // show table selection\n        int count = 0;\n        Iterator<String> ti = sb.tables.tables();\n        String tablename;\n        prop.put(\"showselection\", 1);\n        while (ti.hasNext()) {\n            tablename = ti.next();\n            if(tablename.endsWith(YMarkTables.TABLES.BOOKMARKS.basename())) {\n                prop.put(\"showselection_tables_\" + count + \"_name\", tablename);\n                prop.put(\"showselection_tables_\" + count + \"_selected\", (table != null && table.equals(tablename)) ? 1 : 0);\n                count++;\n            }\n        }\n        prop.put(\"showselection_tables\", count);\n        prop.put(\"showselection_pattern\", \"\");\n\n        if (post == null) return prop; // return rewrite properties\n        \n        // get available tags and folders\n        count = 0;\n        byte[] key;\n        String name;\n        /*\n        try {\n\t\t\tIterator<byte[]> iter = sb.tables.keys(YMarkTables.TABLES.TAGS.tablename(bmk_user));\n\t\t\twhile(iter.hasNext()) {\n\t\t\t\tkey = iter.next();\n\t\t\t\tname = sb.tables.bookmarks.tags.getKeyname(bmk_user, key);\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagHash\", UTF8.String(key));\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagName\", name);\n\t\t\t\tprop.put(\"showselection_tags_\" + count + \"_tagCount\", sb.tables.bookmarks.tags.getBookmarkIds(bmk_user, name).size());\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tprop.put(\"showselection_tags\", count);\n\t\t\tcount = 0;\n\t\t\titer = sb.tables.keys(YMarkTables.TABLES.FOLDERS.tablename(bmk_user));\n\t\t\twhile(iter.hasNext()) {\n\t\t\t\tkey = iter.next();\n\t\t\t\tname = sb.tables.bookmarks.folders.getKeyname(bmk_user, key);\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderHash\", UTF8.String(key));\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderName\", name);\n\t\t\t\tprop.put(\"showselection_folders_\" + count + \"_folderCount\", sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, name).size());\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tprop.put(\"showselection_folders\", count);\n\t\t} catch (IOException e) {\n            Log.logException(e);\n\t\t} catch (RowSpaceExceededException e) {\n            Log.logException(e);\n\t\t}\n\t\t*/\n\t\t\n        final String counts = post.get(\"count\", null);\n        int maxcount = (counts == null || counts.equals(\"all\")) ? Integer.MAX_VALUE : post.getInt(\"count\", 10);\n        String pattern = post.get(\"search\", \"\");\n        Pattern matcher = (pattern.isEmpty() || pattern.equals(\".*\")) ? null : Pattern.compile(\".*\" + pattern + \".*\");\n        prop.put(\"pattern\", pattern);\n        \n        List<String> columns = new ArrayList<String>();\n        for (final Map.Entry<String, String> entry: post.entrySet()) {\n            if (entry.getKey().startsWith(\"col_\")) {\n            \tcolumns.add(entry.getKey().substring(4));\n            }\n        }\n        if (columns.isEmpty() && table != null) try {\n            columns = sb.tables.columns(table);\n        } catch (IOException e) {\n            Log.logException(e);\n        }\n        \n        count = 0;\n        if (table != null) {\n            Iterator<String> cit;\n            String col;\n            try {\n                cit = sb.tables.columns(table).iterator();\n    \t        while(cit.hasNext()) {\n                    col = cit.next();\n                    prop.put(\"showselection_columns_\" + count + \"_col\", col);\n                    prop.put(\"showselection_columns_\" + count + \"_checked\", columns.contains(col) ? 1 : 0);\n                    count++;\n    \t        }\n            } catch (IOException e) {\n                Log.logException(e);\n            }\n        }\n        prop.put(\"showselection_columns\", count);\n        \n        // apply deletion requests\n        if (!post.get(\"deletetable\", \"\").isEmpty()) try {\n            sb.tables.clear(table);\n            sb.tables.clear(YMarkTables.TABLES.FOLDERS.tablename(bmk_user));\n            sb.tables.clear(YMarkTables.TABLES.TAGS.tablename(bmk_user));\n        } catch (IOException e) {\n            Log.logException(e);\n        }\n        \n        \n        // apply rebuildIndex request\n        /*\n        if (!post.get(\"rebuildindex\", \"\").isEmpty()) try {\n            sb.tables.bookmarks.folders.rebuildIndex(bmk_user);\n            sb.tables.bookmarks.tags.rebuildIndex(bmk_user);\n        }  catch (IOException e) {\n            Log.logException(e);\n        }\n        */\n        \n        if (!post.get(\"deleterows\", \"\").isEmpty()) {\n            for (final Map.Entry<String, String> entry: post.entrySet()) {\n                if (entry.getValue().startsWith(\"mark_\")) try {\n                    sb.tables.bookmarks.deleteBookmark(bmk_user, entry.getValue().substring(5).getBytes());\n                } catch (IOException e) {\n                    Log.logException(e);\n                } catch (RowSpaceExceededException e) {\n                    Log.logException(e);\n                }\n            }\n        }\n        \n        if (!post.get(\"commitrow\", \"\").isEmpty()) {\n            final HashMap<String, String> bmk = new HashMap<String, String>();\n            for (final Map.Entry<String, String> entry: post.entrySet()) {\n                if (entry.getKey().startsWith(\"col_\")) {\n                    bmk.put(entry.getKey().substring(4), entry.getValue());\n                }\n            }\n            try {\n                sb.tables.bookmarks.addBookmark(bmk_user, bmk, false);\n            } catch (IOException e) {\n                Log.logException(e);\n            } catch (RowSpaceExceededException e) {\n                Log.logException(e);\n            }\n        }\n        \n        // generate table\n        prop.put(\"showtable\", 0);\n        prop.put(\"showedit\", 0);\n        \n        if (table != null) {\n            \n            if (post.containsKey(\"editrow\")) {\n                // check if we can find a key\n                String pk = null;\n                for (final Map.Entry<String, String> entry: post.entrySet()) {\n                    if (entry.getValue().startsWith(\"mark_\")) {\n                        pk = entry.getValue().substring(5);\n                        break;\n                    }\n                }\n                try {\n                    if (pk != null && sb.tables.has(table, pk.getBytes())) {\n                        setEdit(sb, prop, table, pk, columns);\n                    }\n                } catch (IOException e) {\n                    Log.logException(e);\n                } catch (RowSpaceExceededException e) {\n                    Log.logException(e);\n                }\n            } else if (post.containsKey(\"addrow\")) try {\n                // get a new key\n                final String pk = UTF8.String(sb.tables.createRow(table));\n                setEdit(sb, prop, table, pk, columns);\n            } catch (IOException e) {\n                Log.logException(e);\n            } catch (RowSpaceExceededException e) {\n                Log.logException(e);\n            } else {\n                prop.put(\"showtable\", 1);\n                prop.put(\"showtable_table\", table);\n               \n                \n                try {\n                    prop.put(\"showtable_bmksize\", sb.tables.size(table));\n                    prop.put(\"showtable_tagsize\", sb.tables.size(YMarkTables.TABLES.TAGS.tablename(bmk_user)));\n                    prop.put(\"showtable_foldersize\", sb.tables.size(YMarkTables.TABLES.FOLDERS.tablename(bmk_user)));\n                } catch (IOException e) {\n                    Log.logException(e);\n                    prop.put(\"showtable_bmksize\", 0);\n                    prop.put(\"showtable_tagsize\", 0);\n                    prop.put(\"showtable_foldersize\", 0);\n                }\n                \n                // insert the columns\n                \n                for (int i = 0; i < columns.size(); i++) {\n                    prop.putHTML(\"showtable_columns_\" + i + \"_header\", columns.get(i));\n                }\n                prop.put(\"showtable_columns\", columns.size());\n                \n                // insert all rows\n                try {\n                    maxcount = Math.min(maxcount, sb.tables.size(table));\n                } catch (IOException e) {\n                    Log.logException(e);\n                    maxcount = 0;\n                }\n                count = 0;\n                try {\n                    Iterator<Tables.Row> mapIterator;\n                    if (post.containsKey(\"folders\") && !post.get(\"folders\").isEmpty()) {\n                        // mapIterator = sb.tables.orderByPK(sb.tables.bookmarks.folders.getBookmarks(bmk_user, post.get(\"folders\")), maxcount).iterator();\n                    \tmapIterator = sb.tables.bookmarks.getBookmarksByFolder(bmk_user, post.get(\"folders\"));\n                    } else if(post.containsKey(\"tags\") && !post.get(\"tags\").isEmpty()) {\n                    \t// mapIterator = sb.tables.orderByPK(sb.tables.bookmarks.tags.getBookmarks(bmk_user, post.get(\"tags\")), maxcount).iterator();\n                    \tfinal String[] tagArray = YMarkUtil.cleanTagsString(post.get(YMarkTables.BOOKMARK.TAGS.key())).split(YMarkUtil.TAGS_SEPARATOR); \n                    \tmapIterator = sb.tables.bookmarks.getBookmarksByTag(bmk_user, tagArray);\n                    } else {\n                    \tmapIterator = sb.tables.orderByPK(sb.tables.iterator(table, matcher), maxcount).iterator();\n                    }\n                    \n                    Tables.Row row;\n                    boolean dark = true;\n                    byte[] cell;\n                    while (mapIterator.hasNext() && count < maxcount) {\n                        row = mapIterator.next();\n                        if (row == null) continue;\n                        \n                        // write table content\n                        prop.put(\"showtable_list_\" + count + \"_dark\", ((dark) ? 1 : 0) ); dark=!dark;\n                        prop.put(\"showtable_list_\" + count + \"_pk\", UTF8.String(row.getPK()));\n                        prop.put(\"showtable_list_\" + count + \"_count\", count);\n                        for (int i = 0; i < columns.size(); i++) {\n                            cell = row.get(columns.get(i));\n                            prop.putHTML(\"showtable_list_\" + count + \"_columns_\" + i + \"_cell\", cell == null ? \"\" : UTF8.String(cell));\n                        }\n                        prop.put(\"showtable_list_\" + count + \"_columns\", columns.size());\n                        count++;\n                    }\n                } catch (IOException e) {\n                    Log.logException(e);\n                }\n                prop.put(\"showtable_list\", count);\n                prop.put(\"showtable_num\", count);\n            }\n            \n        }\n        \n        // adding the peer address\n        prop.put(\"address\", sb.peers.mySeed().getPublicAddress());\n        \n        // return rewrite properties\n        return prop;\n    }","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n\n            String url = post.get(YMarkTables.BOOKMARK.URL.key(),YMarkTables.BOOKMARK.URL.deflt());\n\t\t\tboolean hasProtocol = false;\n\t\t\tfor (YMarkTables.PROTOCOLS p : YMarkTables.PROTOCOLS.values()) {\n\t\t\t\thasProtocol = url.toLowerCase().startsWith(p.protocol());\n\t\t\t}\n\t\t\tif (!hasProtocol) {\n\t\t\t    url=YMarkTables.PROTOCOLS.HTTP.protocol(url);\n\t\t\t}\n    \t\t\n        \tfinal HashMap<String,String> data = new HashMap<String,String>();        \n            \n            data.put(YMarkTables.BOOKMARK.URL.key(), url);\n            data.put(YMarkTables.BOOKMARK.TITLE.key(), post.get(YMarkTables.BOOKMARK.TITLE.key(),YMarkTables.BOOKMARK.TITLE.deflt()));\n            data.put(YMarkTables.BOOKMARK.DESC.key(), post.get(YMarkTables.BOOKMARK.DESC.key(),YMarkTables.BOOKMARK.DESC.deflt()));\n            data.put(YMarkTables.BOOKMARK.PUBLIC.key(), post.get(YMarkTables.BOOKMARK.PUBLIC.key(),YMarkTables.BOOKMARK.PUBLIC.deflt()));\n            data.put(YMarkTables.BOOKMARK.TAGS.key(), YMarkTables.cleanTagsString(post.get(YMarkTables.BOOKMARK.TAGS.key(),YMarkTables.BOOKMARK.TAGS.deflt())));\n            data.put(YMarkTables.BOOKMARK.FOLDERS.key(), YMarkTables.cleanFoldersString(post.get(YMarkTables.BOOKMARK.FOLDERS.key(),YMarkTables.FOLDERS_UNSORTED)));\n            \n            try {\n\t\t\t\tsb.tables.bookmarks.addBookmark(bmk_user, data, false);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t    Log.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t}\n            prop.put(\"result\", \"1\");\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n        // return rewrite properties\n        return prop;\n    }","id":14574,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n\n            String url = post.get(YMarkTables.BOOKMARK.URL.key(),YMarkTables.BOOKMARK.URL.deflt());\n\t\t\tboolean hasProtocol = false;\n\t\t\tfor (YMarkTables.PROTOCOLS p : YMarkTables.PROTOCOLS.values()) {\n\t\t\t\thasProtocol = url.toLowerCase().startsWith(p.protocol());\n\t\t\t}\n\t\t\tif (!hasProtocol) {\n\t\t\t    url=YMarkTables.PROTOCOLS.HTTP.protocol(url);\n\t\t\t}\n    \t\t\n        \tfinal HashMap<String,String> data = new HashMap<String,String>();        \n            \n            data.put(YMarkTables.BOOKMARK.URL.key(), url);\n            data.put(YMarkTables.BOOKMARK.TITLE.key(), post.get(YMarkTables.BOOKMARK.TITLE.key(),YMarkTables.BOOKMARK.TITLE.deflt()));\n            data.put(YMarkTables.BOOKMARK.DESC.key(), post.get(YMarkTables.BOOKMARK.DESC.key(),YMarkTables.BOOKMARK.DESC.deflt()));\n            data.put(YMarkTables.BOOKMARK.PUBLIC.key(), post.get(YMarkTables.BOOKMARK.PUBLIC.key(),YMarkTables.BOOKMARK.PUBLIC.deflt()));\n            data.put(YMarkTables.BOOKMARK.TAGS.key(), YMarkUtil.cleanTagsString(post.get(YMarkTables.BOOKMARK.TAGS.key(),YMarkTables.BOOKMARK.TAGS.deflt())));\n            data.put(YMarkTables.BOOKMARK.FOLDERS.key(), YMarkUtil.cleanFoldersString(post.get(YMarkTables.BOOKMARK.FOLDERS.key(),YMarkTables.FOLDERS_UNSORTED)));\n            \n            try {\n\t\t\t\tsb.tables.bookmarks.addBookmark(bmk_user, data, false);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t    Log.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t}\n            prop.put(\"result\", \"1\");\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n        // return rewrite properties\n        return prop;\n    }","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        \n        if(isAdmin || isAuthUser) {     \t\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n            byte[] urlHash = null;\n            try {\n\t        \tif(post.containsKey(YMarkTables.BOOKMARKS_ID)) {\n\t        \t\turlHash = post.get(YMarkTables.BOOKMARKS_ID).getBytes();\n\t        \t} else if(post.containsKey(YMarkTables.BOOKMARK.URL.key())) {\n\t\t\t\t\turlHash = YMarkTables.getBookmarkId(post.get(YMarkTables.BOOKMARK.URL.key()));\n\t        \t} else {\n\t        \t\tprop.put(\"result\", \"0\");\n\t        \t\treturn prop;\n\t        \t}\n\t        \tsb.tables.bookmarks.deleteBookmark(bmk_user, urlHash);\n\t        \tprop.put(\"result\", \"1\");\n\t\t\t} catch (IOException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t}\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }       \n        // return rewrite properties\n        return prop;\n\t}","id":14575,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        \n        if(isAdmin || isAuthUser) {     \t\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n            byte[] urlHash = null;\n            try {\n\t        \tif(post.containsKey(YMarkTables.BOOKMARKS_ID)) {\n\t        \t\turlHash = post.get(YMarkTables.BOOKMARKS_ID).getBytes();\n\t        \t} else if(post.containsKey(YMarkTables.BOOKMARK.URL.key())) {\n\t\t\t\t\turlHash = YMarkUtil.getBookmarkId(post.get(YMarkTables.BOOKMARK.URL.key()));\n\t        \t} else {\n\t        \t\tprop.put(\"result\", \"0\");\n\t        \t\treturn prop;\n\t        \t}\n\t        \tsb.tables.bookmarks.deleteBookmark(bmk_user, urlHash);\n\t        \tprop.put(\"result\", \"1\");\n\t\t\t} catch (IOException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t}\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }       \n        // return rewrite properties\n        return prop;\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n\t\tprop = new serverObjects();        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n            \n        \tString root = YMarkTables.FOLDERS_ROOT;  \t\n        \tString[] foldername = null;\n        \tboolean isFolder = true;\n        \tboolean isBookmark = false;\n        \tboolean isMetadata = false;\n        \tboolean isWordCount = false;\n\n        \tif (post != null){\n        \t\tif (post.containsKey(ROOT)) {\n            \t\tif (post.get(ROOT).equals(SOURCE) || post.get(ROOT).equals(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = \"\";\n            \t\t} else if (post.get(ROOT).startsWith(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = post.get(ROOT);\n            \t\t} else if (post.get(ROOT).startsWith(\"b:\")) {\n            \t\t\tisBookmark = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"m:\")) {\n            \t\t\tisMetadata = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"w:\")) {\n            \t\t\tisWordCount = true;\n            \t\t\tisFolder = false;\n            \t\t}\n        \t\t}\n        \t}\n        \t\n        \tIterator<String> it = null;\n        \tTables.Row bmk_row = null;\n        \tint count = 0;\n        \t\n        \tif(isFolder) {\n\t        \t// loop through folderList  \t\n\t        \ttry {\n\t\t\t\t\tit = sb.tables.bookmarks.folders.getFolders(bmk_user, root);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        \tint n = root.split(YMarkTables.FOLDERS_SEPARATOR).length;\n\t        \tif (n == 0) n = 1;\n\t        \twhile (it.hasNext()) {    \t\t   \t\t\n\t        \t\tString folder = it.next();\n\t        \t\tfoldername = folder.split(YMarkTables.FOLDERS_SEPARATOR);\n\t        \t\tif (foldername.length == n+1) {\n\t        \t\t\tprop.put(\"folders_\"+count+\"_foldername\", foldername[n]);\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_expanded\", \"false\");\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_type\", \"folder\");\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_hash\", folder);\t\t\t\t//TODO: switch from pathString to folderHash\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_url\", \"\");\t\t\t\t\t//TODO: insert folder url\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\t\t//TODO: determine if folder has children\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_comma\", \",\");\n\t    \t    \t\tcount++;\n\t        \t\t}\n\t        \t}\n\t        \t// loop through bookmarkList\n\t        \ttry {\n\t\t\t\t\tit = sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, root).iterator();\n\t\t        \twhile (it.hasNext()) {\n\t\t        \t\tfinal String urlHash = it.next();\n\t\t        \t\tbmk_row = sb.tables.select(YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user), urlHash.getBytes());\n\t\t\t        \tif(bmk_row != null) {\n\t\t\t        \t\tfinal String url = UTF8.String(bmk_row.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t\t        \t\tfinal String title = bmk_row.get(YMarkTables.BOOKMARK.TITLE.key(), YMarkTables.BOOKMARK.TITLE.deflt());\n\t\t\t        \t\t\t\n\t\t\t        \t\t// TODO: get_treeview - get rid of bmtype\n\t\t\t        \t\tif (post.containsKey(\"bmtype\")) {    \t\t\t \n\t\t\t        \t\t\tif (post.get(\"bmtype\").equals(\"title\")) {\n\t\t\t        \t\t\t\tprop.put(\"folders_\"+count+\"_foldername\", title);\n\t\t\t        \t\t\t} else if (post.get(\"bmtype\").equals(\"href\")) {\n\t\t\t        \t\t\t\tprop.put(\"folders_\"+count+\"_foldername\", \n\t\t\t        \t\t\t\t\t\t\"<a href='\"+url+\" 'target='_blank'>\"+title+\"<\/a>\");\n\t\t\t        \t\t\t} \n\t\t\t        \t\t} else {\n\t\t\t        \t\t\t\tprop.put(\"folders_\"+count+\"_foldername\", url);\n\t\t        \t\t\t}\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_expanded\", \"false\");\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_url\", url);\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_type\", \"file\");\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_hash\", \"b:\"+urlHash);\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t        \t\tprop.put(\"folders_\"+count+\"_comma\", \",\");\n\t\t\t        \t\tcount++;   \n\t\t\t        \t}\n\t\t        \t} \n\t\t        \tcount--;\n\t\t        \tprop.put(\"folders_\"+count+\"_comma\", \"\");\n\t\t        \tcount++;\n\t\t        \tprop.put(\"folders\", count);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } else if(isBookmark) {\n\t        \ttry {\n\t\t\t\t\tfinal String urlHash = post.get(ROOT).substring(2);\n\t        \t\tString url = \"\";\n\t\t\t\t\tbmk_row = sb.tables.select(YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user), urlHash.getBytes());\n\t\t\t\t\tif(bmk_row != null) {\n\t\t\t            it = bmk_row.keySet().iterator();\n\t\t\t            while(it.hasNext()) {\n\t\t\t            \tfinal String key = it.next();\n\t\t\t            \tif(key.startsWith(\"date\")) {\n\t\t\t\t            \tfinal String d = UTF8.String(bmk_row.get(key));\n\t\t\t\t            \tif(!d.isEmpty()) {\n\t\t\t\t            \t\tfinal String date = ISO8601Formatter.FORMATTER.format(new Date(Long.parseLong(d)));\n\t\t\t\t\t            \tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key+\":<\/b> \" + date + \"<\/small>\");\n\t\t\t    \t\t\t\t\tputProp(count, \"date\");\n\t\t\t    \t\t\t\t\tcount++;\n\t\t\t\t            \t}\n\t\t\t            \t} else {\n\t\t\t\t\t\t\t\tfinal String value = UTF8.String(bmk_row.get(key));\n\t\t\t\t\t\t\t\tif (key.equals(\"url\"))\n\t\t\t\t\t\t\t\t\turl = value;\n\t\t\t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key+\":<\/b> \" + value + \"<\/small>\");\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tif(YMarkTables.BOOKMARK.contains(key))\n\t\t\t\t\t\t\t\t\tputProp(count, YMarkTables.BOOKMARK.get(key).type());\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tputProp(count, \"meta\");\n\t\t\t\t\t\t\t\tcount++;\t\n\t\t\t            \t}\n\t\t\t            }\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>MetaData<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"m:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t            count++;\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>WordCounts<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"w:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t\t\t\tprop.put(\"folders_\"+count+\"_comma\", \"\");\n\t\t\t    \t\tcount++;\t\n\t\t        \t\tprop.put(\"folders\", count);\n\t\t\t\t\t}\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } else if (isWordCount || isMetadata) {\n\t        \ttry {\n\t                final DigestURI u = new DigestURI(post.get(ROOT).substring(2));\n\t                Response response = null;\n        \t\t\tresponse = sb.loader.load(sb.loader.request(u, true, false), CrawlProfile.CacheStrategy.IFEXIST, Long.MAX_VALUE, true);\n        \t\t\tfinal Document document = Document.mergeDocuments(response.url(), response.getMimeType(), response.parse());\n        \t\t\tif(document != null) {\n    \t        \t\tif(isWordCount)  {\n            \t\t\t\tfinal TreeMap<String,Word> words = YMarkTables.getWordCounts(document);\n        \t\t\t\t\tfinal ArrayList<String> topwords = new ArrayList<String>(words.descendingKeySet());\n        \t\t\t\t\tfor(int i = 0; i < 20 && i < topwords.size(); i++) {\n        \t\t\t\t\t\tString word = topwords.get(i);\n        \t\t\t\t\t\tint occur = words.get(word).occurrences();\n        \t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+word+\":<\/b> [\" + occur + \"]<\/small>\");\n            \t\t\t\t\tputProp(count, \"meta\");\n            \t\t\t\t\tcount++;\n        \t\t\t\t\t}\n        \t\t\t\t\tcount--;\n        \t\t\t\t\tprop.put(\"folders_\"+count+\"_comma\", \"\");\n        \t\t\t\t\tcount++;\n        \t        \t\tprop.put(\"folders\", count);\n    \t        \t\t} else if(isMetadata) {\n    \t\t\t\t\t\tEnumMap<METADATA, String> metadata;\n    \t\t\t\t\t\tmetadata = YMarkTables.getMetadata(YMarkTables.getBookmarkId(post.get(ROOT).substring(2)), sb.indexSegments.segment(Segments.Process.PUBLIC));\n    \t\t\t\t\t\tif (metadata.isEmpty())\n    \t\t\t\t\t\t\tmetadata = YMarkTables.getMetadata(document);\n    \t\t\t\t\t\tfinal Iterator<METADATA> iter = metadata.keySet().iterator();\n    \t\t\t\t\t\twhile (iter.hasNext()) {\n    \t\t\t\t\t\t\tfinal METADATA key = iter.next();\n    \t\t\t\t\t\t\tfinal String value = metadata.get(key);\n    \t\t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key.toString().toLowerCase()+\":<\/b> \" + value + \"<\/small>\");\n    \t\t\t\t\t\t\tputProp(count, \"meta\");\n    \t\t\t\t\t\t\tcount++;\n    \t\t\t\t\t\t}\n    \t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>autotag:<\/b> \" + sb.tables.bookmarks.autoTag(document, bmk_user, 5) + \"<\/small>\");\n    \t\t\t\t\t\tputProp(count, \"meta\");\n    \t\t\t\t\t\tcount++;\n    \t\t        \t\tprop.put(\"folders\", count);\n    \t        \t\t}\n        \t\t\t}\n\t\t\t\t} catch (MalformedURLException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (Failure e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } \n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }  \n        // return rewrite properties\n        return prop;\n\t}","id":14576,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n\t\tprop = new serverObjects();        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n            \n        \tString root = YMarkTables.FOLDERS_ROOT;  \t\n        \tString[] foldername = null;\n        \tboolean isFolder = true;\n        \tboolean isBookmark = false;\n        \tboolean isMetadata = false;\n        \tboolean isURLdb = false;\n        \tboolean isCrawlStart = false;\n        \tboolean isWordCount = false;\n\n        \tif (post != null){\n        \t\tif (post.containsKey(ROOT)) {\n            \t\tif (post.get(ROOT).equals(SOURCE) || post.get(ROOT).equals(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = \"\";\n            \t\t} else if (post.get(ROOT).startsWith(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = post.get(ROOT);\n            \t\t} else if (post.get(ROOT).startsWith(\"b:\")) {\n            \t\t\tisBookmark = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"m:\")) {\n            \t\t\tisMetadata = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"u:\")) {\n            \t\t\tisURLdb = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"w:\")) {\n            \t\t\tisWordCount = true;\n            \t\t\tisFolder = false;\n            \t\t} else if (post.get(ROOT).startsWith(\"c:\")) {\n            \t\t\tisCrawlStart = true;\n            \t\t\tisFolder = false;\n            \t\t}\n        \t\t}\n        \t}\n        \t\n        \tIterator<String> it = null;\n        \tIterator<Tables.Row> bit = null;\n        \tTables.Row bmk_row = null;\n        \tint count = 0;\n        \t\n        \tif(isFolder) {\n\t        \t// loop through folderList  \t\n\t        \ttry {\t\t\t\t\t\n\t        \t\t// it = sb.tables.bookmarks.folders.getFolders(bmk_user, root);\n\t        \t\tit = sb.tables.bookmarks.getFolders(bmk_user, root).iterator();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        \tint n = root.split(YMarkUtil.FOLDERS_SEPARATOR).length;\n\t        \tif (n == 0) n = 1;\n\t        \twhile (it.hasNext()) {    \t\t   \t\t\n\t        \t\tString folder = it.next();\n\t        \t\tfoldername = folder.split(YMarkUtil.FOLDERS_SEPARATOR);\n\t        \t\tif (foldername.length == n+1) {\n\t        \t\t\tprop.put(\"folders_\"+count+\"_foldername\", foldername[n]);\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_expanded\", \"false\");\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_type\", \"folder\");\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_hash\", folder);\t\t\t\t//TODO: switch from pathString to folderHash\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_url\", \"\");\t\t\t\t\t//TODO: insert folder url\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\t\t//TODO: determine if folder has children\n\t    \t    \t\tprop.put(\"folders_\"+count+\"_comma\", \",\");\n\t    \t    \t\tcount++;\n\t        \t\t}\n\t        \t}\n\t        \t// loop through bookmarkList\n\t        \ttry {\n\t        \t\tif(!root.isEmpty()) {\n\t        \t\t\tbit = sb.tables.bookmarks.getBookmarksByFolder(bmk_user, root);\n\t\t\t        \twhile (bit.hasNext()) {\n\t\t\t        \t\tbmk_row = bit.next();\n\t\t\t        \t\tif(bmk_row != null) {\t\t\t        \t\t\n\t\t\t        \t\t\tfinal String url = UTF8.String(bmk_row.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t\t        \t\t\tfinal String title = bmk_row.get(YMarkTables.BOOKMARK.TITLE.key(), YMarkTables.BOOKMARK.TITLE.deflt());\n\t\t\t\t        \t\t\t\n\t\t\t\t        \t\t// TODO: get_treeview - get rid of bmtype\n\t\t\t\t        \t\tif (post.containsKey(\"bmtype\")) {    \t\t\t \n\t\t\t\t        \t\t\tif (post.get(\"bmtype\").equals(\"title\")) {\n\t\t\t\t        \t\t\t\tprop.putJSON(\"folders_\"+count+\"_foldername\", title);\n\t\t\t\t        \t\t\t} else if (post.get(\"bmtype\").equals(\"href\")) {\n\t\t\t\t        \t\t\t\tprop.putJSON(\"folders_\"+count+\"_foldername\", \"<a href='\"+url+\"' target='_blank'>\"+title+\"<\/a>\");\n\t\t\t\t        \t\t\t} \n\t\t\t\t        \t\t} else {\n\t\t\t\t        \t\t\t\tprop.putJSON(\"folders_\"+count+\"_foldername\", url);\n\t\t\t        \t\t\t}\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_expanded\", \"false\");\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_url\", url);\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_type\", \"file\");\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_hash\", \"b:\"+new String(bmk_row.getPK()));\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t\t        \t\tprop.put(\"folders_\"+count+\"_comma\", \",\");\n\t\t\t\t        \t\tcount++;   \n\t\t\t\t        \t}\n\t\t\t        \t} \n\t        \t\t}\n\t\t        \tcount--;\n\t\t        \tprop.put(\"folders_\"+count+\"_comma\", \"\");\n\t\t        \tcount++;\n\t\t        \tprop.put(\"folders\", count);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } else if(isBookmark) {\n\t        \ttry {\n\t\t\t\t\tfinal String urlHash = post.get(ROOT).substring(2);\n\t        \t\tString url = \"\";\n\t\t\t\t\tbmk_row = sb.tables.select(YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user), urlHash.getBytes());\n\t\t\t\t\tif(bmk_row != null) {\n\t\t\t            it = bmk_row.keySet().iterator();\n\t\t\t            while(it.hasNext()) {\n\t\t\t            \tfinal String key = it.next();\n\t\t\t            \tif(key.startsWith(\"date\")) {\n\t\t\t\t            \tfinal String d = UTF8.String(bmk_row.get(key));\n\t\t\t\t            \tif(!d.isEmpty()) {\n\t\t\t\t            \t\tfinal String date = ISO8601Formatter.FORMATTER.format(new Date(Long.parseLong(d)));\n\t\t\t\t\t            \tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key+\":<\/b> \" + date + \"<\/small>\");\n\t\t\t    \t\t\t\t\tputProp(count, \"date\");\n\t\t\t    \t\t\t\t\tcount++;\n\t\t\t\t            \t}\n\t\t\t            \t} else {\n\t\t\t\t\t\t\t\tfinal String value = UTF8.String(bmk_row.get(key));\n\t\t\t\t\t\t\t\tif (key.equals(\"url\"))\n\t\t\t\t\t\t\t\t\turl = value;\n\t\t\t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key+\":<\/b> \" + value + \"<\/small>\");\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tif(YMarkTables.BOOKMARK.contains(key))\n\t\t\t\t\t\t\t\t\tputProp(count, YMarkTables.BOOKMARK.get(key).type());\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tputProp(count, \"meta\");\n\t\t\t\t\t\t\t\tcount++;\t\n\t\t\t            \t}\n\t\t\t            }\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>MetaData<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"m:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t            count++;\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>URLdb<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"u:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t            count++;\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>CrawlStart<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"c:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t            count++;\n\t\t\t            prop.put(\"folders_\"+count+\"_foldername\",\"<small><b>WordCounts<\/b><\/small>\");\n\t\t\t            putProp(count, \"meta\");\n\t\t\t            prop.put(\"folders_\"+count+\"_hash\", \"w:\"+url);\n\t\t\t    \t\tprop.put(\"folders_\"+count+\"_hasChildren\", \"true\");\n\t\t\t\t\t\tprop.put(\"folders_\"+count+\"_comma\", \"\");\n\t\t\t    \t\tcount++;\t\n\t\t        \t\tprop.put(\"folders\", count);\n\t\t\t\t\t}\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } else if (isWordCount || isMetadata || isURLdb || isCrawlStart) {\n\t        \ttry {\n\t                final YMarkMetadata meta = new YMarkMetadata(new DigestURI(post.get(ROOT).substring(2)), sb.indexSegments);\n        \t\t\tmeta.loadDocument(sb.loader);\n\t        \t\tif(isWordCount)  {\n        \t\t\t\tfinal TreeMap<String,Word> words = meta.getWordCounts();\n    \t\t\t\t\tfinal ArrayList<String> topwords = new ArrayList<String>(words.descendingKeySet());\n    \t\t\t\t\tfor(int i = 0; i < 20 && i < topwords.size(); i++) {\n    \t\t\t\t\t\tString word = topwords.get(i);\n    \t\t\t\t\t\tint occur = words.get(word).occurrences();\n    \t\t\t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+word+\":<\/b> [\" + occur + \"]<\/small>\");\n        \t\t\t\t\tputProp(count, \"meta\");\n        \t\t\t\t\tcount++;\n    \t\t\t\t\t}\n    \t\t\t\t\tcount--;\n    \t\t\t\t\tprop.put(\"folders_\"+count+\"_comma\", \"\");\n    \t\t\t\t\tcount++;\n    \t        \t\tprop.put(\"folders\", count);\n\t        \t\t} else if(isMetadata) {\n\t        \t\t\tcount = putMeta(count, meta.loadMetadata());\n\t        \t\t} else if(isURLdb) {\n\t\t\t\t\t\tcount = putMeta(count, meta.getMetadata());\n\t        \t\t} else if(isCrawlStart) {\n\t        \t\t\tLog.logInfo(\"YMark\", \"I am looking for CrawlStart: \"+post.get(ROOT).substring(2));\n\t        \t\t\tfinal YMarkCrawlStart crawlStart = new YMarkCrawlStart(sb.tables, post.get(ROOT).substring(2));\n\t        \t\t\tfinal Iterator<String> iter = crawlStart.keySet().iterator();\n\t        \t\t\tString key;\n\t        \t\t\twhile(iter.hasNext()) {\n\t        \t\t\t\tkey = iter.next();\n\t        \t\t\t\tprop.put(\"folders_\"+count+\"_foldername\",\"<small><b>\"+key.toLowerCase()+\":<\/b> \" + crawlStart.get(key) + \"<\/small>\");\n\t        \t\t\t\tputProp(count, \"meta\");\n\t        \t\t\t\tcount++;\n\t        \t\t\t}\n\t        \t\t\tprop.put(\"folders\", count);\n\t        \t\t}\n\n\t\t\t\t} catch (MalformedURLException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (Failure e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t        } \n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }  \n        // return rewrite properties\n        return prop;\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n\t\tfinal serverObjects prop = new serverObjects();        \n\t\tfinal HashSet<String> alias = new HashSet<String>();\n\t\tfinal StringBuilder buffer = new StringBuilder(250);\n\t\tfinal UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n\t\tfinal String bmk_user;\n        \n        if(isAdmin || isAuthUser) {\n        \tbmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n        \t\n        \tString root = YMarkTables.FOLDERS_ROOT;  \t\n        \tString[] foldername = null;\n        \t\n        \t// TODO: better handling of query\n        \tif (post != null){\n        \t\tif (post.containsKey(ROOT)) {\n            \t\tif (post.get(ROOT).equals(SOURCE) || post.get(ROOT).equals(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = \"\";\n            \t\t} else if (post.get(ROOT).startsWith(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = post.get(ROOT);\n            \t\t} else {\n            \t\t\troot = \"\";            \t\t\t\n            \t\t}\n        \t\t}\n        \t} else {\n        \t\troot = \"\";\n        \t}\n        \t\n        \tfinal int root_depth = root.split(YMarkTables.FOLDERS_SEPARATOR).length;\n    \t\tIterator<String> fit = null;\n        \tIterator<String> bit = null;\n        \tint count = 0;    \t\t\n        \tint n = root_depth;\n        \t\n        \ttry {\n\t\t\t\tfit = sb.tables.bookmarks.folders.getFolders(bmk_user, root);\n\t\t\t} catch (IOException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t}\n\n\t\t\tLog.logInfo(YMarkTables.BOOKMARKS_LOG, \"root: \"+root+\" root_deph: \"+root_depth);\n\t\t\t\n\t\t\twhile (fit.hasNext()) {    \t\t   \t\t\n        \t\tString folder = fit.next();\n        \t\tfoldername = folder.split(YMarkTables.FOLDERS_SEPARATOR); \n        \t\tif (n != root_depth && foldername.length <= n) {\n\t\t\t\t\tprop.put(\"xbel_\"+count+\"_elements\", \"<\/folder>\");\n            \t\tcount++;\n        \t\t}\n        \t\tif (foldername.length >= n) {\n        \t\t\tn = foldername.length;\n        \t\t\tif(n != root_depth) {\n                \t\tprop.put(\"xbel_\"+count+\"_elements\", \"<folder id=\\\"f:\"+UTF8.String(YMarkTables.getKeyId(foldername[n-1]))+\"\\\">\");\n                \t\tcount++;\n                \t\tprop.put(\"xbel_\"+count+\"_elements\", \"<title>\" + CharacterCoding.unicode2xml(foldername[n-1], true) + \"<\/title>\");   \t\t\n                \t\tcount++;\t\n        \t\t\t}\n            \t\ttry {\n            \t\t\tbit = sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folder).iterator();\n            \t    \tTables.Row bmk_row = null;\n            \t    \tString urlHash;\n            \t\t\twhile(bit.hasNext()){ \n            \t\t\t\turlHash = bit.next();\n            \t    \t\tif(alias.contains(urlHash)) {\n            \t    \t\t\tbuffer.setLength(0);\n            \t    \t\t\tbuffer.append(YMarksXBELImporter.XBEL.ALIAS.startTag(true));\n            \t    \t\t\tbuffer.append(\" ref=\\\"b:\");\n            \t    \t\t\tbuffer.append(urlHash);\n            \t    \t\t\tbuffer.append(\"\\\"/>\");            \t    \t\t\t\n            \t    \t\t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString()); \t\t\n            \t\t    \t\tcount++;  \t\n            \t    \t\t} else {\n            \t\t\t\t\talias.add(urlHash);\n            \t    \t\t\tbmk_row = sb.tables.select(YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user), urlHash.getBytes());\n            \t\t        \tif(bmk_row != null) {\n            \t\t        \t\tbuffer.setLength(0);\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarksXBELImporter.XBEL.BOOKMARK.startTag(true));\n            \t\t        \t\tbuffer.append(\" id=\\\"b:\");\n            \t\t        \t\tbuffer.append(urlHash);\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.URL.xbel());\n            \t\t        \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.URL.key(), YMarkTables.BOOKMARK.URL.deflt()), true));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_ADDED.xbel());\n            \t\t        \t\tbuffer.append(CharacterCoding.unicode2xml(YMarkTables.getISO8601(bmk_row.get(YMarkTables.BOOKMARK.DATE_ADDED.key())), true));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_MODIFIED.xbel());\n            \t\t        \t\tbuffer.append(CharacterCoding.unicode2xml(YMarkTables.getISO8601(bmk_row.get(YMarkTables.BOOKMARK.DATE_MODIFIED.key())), true));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_VISITED.xbel());\n            \t\t        \t\tbuffer.append(CharacterCoding.unicode2xml(YMarkTables.getISO8601(bmk_row.get(YMarkTables.BOOKMARK.DATE_VISITED.key())), true));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.TAGS.xbel());\n            \t\t        \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.TAGS.key(), YMarkTables.BOOKMARK.TAGS.deflt()));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.PUBLIC.xbel());\n            \t\t        \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.PUBLIC.key(), YMarkTables.BOOKMARK.PUBLIC.deflt()));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(YMarkTables.BOOKMARK.VISITS.xbel());\n            \t\t        \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.VISITS.key(), YMarkTables.BOOKMARK.VISITS.deflt()));\n            \t\t        \t\t\n            \t\t        \t\tbuffer.append(\"\\\"\\n>\");\n            \t\t        \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n            \t\t\t    \t\tcount++; \n            \t\t\t    \t\t\n            \t\t        \t\tbuffer.setLength(0);\n            \t\t        \t\tbuffer.append(YMarksXBELImporter.XBEL.TITLE.startTag(false));\n            \t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.TITLE.key(), YMarkTables.BOOKMARK.TITLE.deflt()), true));\n            \t\t\t    \t\tbuffer.append(YMarksXBELImporter.XBEL.TITLE.endTag(false));\n            \t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n            \t\t\t    \t\tcount++;\n\n            \t\t\t    \t\tbuffer.setLength(0);\n            \t\t        \t\tbuffer.append(YMarksXBELImporter.XBEL.DESC.startTag(false));\n            \t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.DESC.key(), YMarkTables.BOOKMARK.DESC.deflt()), true));\n            \t\t\t    \t\tbuffer.append(YMarksXBELImporter.XBEL.DESC.endTag(false));\n            \t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n            \t\t\t    \t\tcount++;\n            \t\t\t    \t\t\n            \t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", YMarksXBELImporter.XBEL.BOOKMARK.endTag(false));   \t\t\n            \t\t\t    \t\tcount++;    \n            \t\t        \t}\n            \t\t\t\t}\n            \t\t\t}\n\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\tLog.logException(e);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\t\tLog.logException(e);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n        \t\t}\n        \t}\n\t\t\twhile(n > root_depth) {\n\t\t\t\tprop.put(\"xbel_\"+count+\"_elements\", YMarksXBELImporter.XBEL.FOLDER.endTag(false));\n\t    \t\tcount++;\n\t    \t\tn--;\n\t\t\t}\n    \t\tprop.put(\"user\", bmk_user.substring(0,1).toUpperCase() + bmk_user.substring(1));\n    \t\tprop.put(\"xbel\", count);\n    \t\t\n        }  else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }  \n        // return rewrite properties\n        return prop;\n\t}","id":14577,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n\t\tfinal Switchboard sb = (Switchboard) env;\n\t\tfinal serverObjects prop = new serverObjects();        \n\t\tfinal HashSet<String> alias = new HashSet<String>();\n\t\tfinal StringBuilder buffer = new StringBuilder(250);\n\t\tfinal UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n\t\tfinal String bmk_user;\n        \n        if(isAdmin || isAuthUser) {\n        \tbmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n        \t\n        \tString root = YMarkTables.FOLDERS_ROOT;  \t\n        \tString[] foldername = null;\n        \t\n        \t// TODO: better handling of query\n        \tif (post != null){\n        \t\tif (post.containsKey(ROOT)) {\n            \t\tif (post.get(ROOT).equals(SOURCE) || post.get(ROOT).equals(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = \"\";\n            \t\t} else if (post.get(ROOT).startsWith(YMarkTables.FOLDERS_ROOT)) {\n            \t\t\troot = post.get(ROOT);\n            \t\t} else {\n            \t\t\troot = \"\";            \t\t\t\n            \t\t}\n        \t\t}\n        \t} else {\n        \t\troot = \"\";\n        \t}\n        \t\n        \tfinal int root_depth = root.split(YMarkUtil.FOLDERS_SEPARATOR).length;\n    \t\tIterator<String> fit = null;\n        \tIterator<Tables.Row> bit = null;\n        \tint count = 0;    \t\t\n        \tint n = root_depth;\n        \t\n        \ttry {\n\t\t\t\t// fit = sb.tables.bookmarks.folders.getFolders(bmk_user, root);\n        \t\tfit = sb.tables.bookmarks.getFolders(bmk_user, root).iterator();\n\t\t\t} catch (IOException e) {\n\t\t\t\tLog.logException(e);\n\t\t\t}\n\n\t\t\tLog.logInfo(YMarkTables.BOOKMARKS_LOG, \"root: \"+root+\" root_deph: \"+root_depth);\n\t\t\t\n\t\t\twhile (fit.hasNext()) {    \t\t   \t\t\n        \t\tString folder = fit.next();\n        \t\tfoldername = folder.split(YMarkUtil.FOLDERS_SEPARATOR); \n        \t\tif (n != root_depth && foldername.length <= n) {\n\t\t\t\t\tprop.put(\"xbel_\"+count+\"_elements\", \"<\/folder>\");\n            \t\tcount++;\n        \t\t}\n        \t\tif (foldername.length >= n) {\n        \t\t\tn = foldername.length;\n        \t\t\tif(n != root_depth) {\n                \t\tprop.put(\"xbel_\"+count+\"_elements\", \"<folder id=\\\"f:\"+UTF8.String(YMarkUtil.getKeyId(foldername[n-1]))+\"\\\">\");\n                \t\tcount++;\n                \t\tprop.put(\"xbel_\"+count+\"_elements\", \"<title>\" + CharacterCoding.unicode2xml(foldername[n-1], true) + \"<\/title>\");   \t\t\n                \t\tcount++;\t\n        \t\t\t}\n            \t\t// bit = sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folder).iterator();\n\t\t\t\t\ttry {\n\t\t\t\t\t\tbit = sb.tables.bookmarks.getBookmarksByFolder(bmk_user, folder);\n\t\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t\t// TODO: better error handling (avoid NPE)\n\t\t\t\t\t\tbit = null;\n\t\t\t\t\t}\n\t\t\t\t\tTables.Row bmk_row = null;\n\t\t\t\t\tString urlHash;\n\t\t\t\t\tfinal YMarkDate date = new YMarkDate();\n\t\t\t\t\twhile(bit.hasNext()){\t\t\t\n\t\t\t\t\t\t// urlHash = bit.next();\n\t\t\t\t\t\tbmk_row = bit.next();\n\t\t\t\t\t\turlHash = new String(bmk_row.getPK());\n\t\t\t\t\t\t\n\t\t\t\t\t\tif(alias.contains(urlHash)) {\n\t\t\t\t\t\t\tbuffer.setLength(0);\n\t\t\t\t\t\t\tbuffer.append(YMarkXBELImporter.XBEL.ALIAS.startTag(true));\n\t\t\t\t\t\t\tbuffer.append(\" ref=\\\"b:\");\n\t\t\t\t\t\t\tbuffer.append(urlHash);\n\t\t\t\t\t\t\tbuffer.append(\"\\\"/>\");            \t    \t\t\t\n\t\t\t\t\t\t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString()); \t\t\n\t\t\t\t\t\t\tcount++;  \t\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\talias.add(urlHash);\n\t\t\t\t\t\t\t// bmk_row = sb.tables.select(YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user), urlHash.getBytes());\n\t\t\t\t\t    \tif(bmk_row != null) {\n\t\t\t\t\t    \t\tbuffer.setLength(0);\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkXBELImporter.XBEL.BOOKMARK.startTag(true));\n\t\t\t\t\t    \t\tbuffer.append(\" id=\\\"b:\");\n\t\t\t\t\t    \t\tbuffer.append(urlHash);\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.URL.xbel());\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.URL.key(), YMarkTables.BOOKMARK.URL.deflt()), true));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_ADDED.xbel());\n\t\t\t\t\t    \t\tdate.set(bmk_row.get(YMarkTables.BOOKMARK.DATE_ADDED.key()));\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(date.toISO8601(), true));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_MODIFIED.xbel());\n\t\t\t\t\t    \t\tdate.set(bmk_row.get(YMarkTables.BOOKMARK.DATE_MODIFIED.key()));\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(date.toISO8601(), true));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.DATE_VISITED.xbel());\n\t\t\t\t\t    \t\tdate.set(bmk_row.get(YMarkTables.BOOKMARK.DATE_VISITED.key()));\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(date.toISO8601(), true));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.TAGS.xbel());\n\t\t\t\t\t    \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.TAGS.key(), YMarkTables.BOOKMARK.TAGS.deflt()));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.PUBLIC.xbel());\n\t\t\t\t\t    \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.PUBLIC.key(), YMarkTables.BOOKMARK.PUBLIC.deflt()));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(YMarkTables.BOOKMARK.VISITS.xbel());\n\t\t\t\t\t    \t\tbuffer.append(bmk_row.get(YMarkTables.BOOKMARK.VISITS.key(), YMarkTables.BOOKMARK.VISITS.deflt()));\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.append(\"\\\"\\n>\");\n\t\t\t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n\t\t\t\t\t    \t\tcount++; \n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tbuffer.setLength(0);\n\t\t\t\t\t    \t\tbuffer.append(YMarkXBELImporter.XBEL.TITLE.startTag(false));\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.TITLE.key(), YMarkTables.BOOKMARK.TITLE.deflt()), true));\n\t\t\t\t\t    \t\tbuffer.append(YMarkXBELImporter.XBEL.TITLE.endTag(false));\n\t\t\t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n\t\t\t\t\t    \t\tcount++;\n\n\t\t\t\t\t    \t\tbuffer.setLength(0);\n\t\t\t\t\t    \t\tbuffer.append(YMarkXBELImporter.XBEL.DESC.startTag(false));\n\t\t\t\t\t    \t\tbuffer.append(CharacterCoding.unicode2xml(bmk_row.get(YMarkTables.BOOKMARK.DESC.key(), YMarkTables.BOOKMARK.DESC.deflt()), true));\n\t\t\t\t\t    \t\tbuffer.append(YMarkXBELImporter.XBEL.DESC.endTag(false));\n\t\t\t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", buffer.toString());\n\t\t\t\t\t    \t\tcount++;\n\t\t\t\t\t    \t\t\n\t\t\t\t\t    \t\tprop.put(\"xbel_\"+count+\"_elements\", YMarkXBELImporter.XBEL.BOOKMARK.endTag(false));   \t\t\n\t\t\t\t\t    \t\tcount++;    \n\t\t\t\t\t    \t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n        \t\t}\n        \t}\n\t\t\twhile(n > root_depth) {\n\t\t\t\tprop.put(\"xbel_\"+count+\"_elements\", YMarkXBELImporter.XBEL.FOLDER.endTag(false));\n\t    \t\tcount++;\n\t    \t\tn--;\n\t\t\t}\n    \t\tprop.put(\"user\", bmk_user.substring(0,1).toUpperCase() + bmk_user.substring(1));\n    \t\tprop.put(\"xbel\", count);\n    \t\t\n        }  else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }  \n        // return rewrite properties\n        return prop;\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        sb = (Switchboard) env;\n        prop = new serverObjects();\n        \n        boolean tags = false;\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n    \tfinal TreeSet<String> bookmarks = new TreeSet<String>();\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n        \t\n\t    \tif(post.containsKey(YMarkTables.BOOKMARK.TAGS.key())) {\n\t    \t\ttags = true;\n\t    \t\tfinal String[] tagArray = YMarkTables.cleanTagsString(post.get(YMarkTables.BOOKMARK.TAGS.key())).split(YMarkTables.TAGS_SEPARATOR);\n\t    \t\ttry {\n\t\t\t\t\tbookmarks.addAll(sb.tables.bookmarks.tags.getBookmarkIds(bmk_user, tagArray));\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t    \t}\n\t    \tif(post.containsKey(YMarkTables.BOOKMARK.FOLDERS.key())) {\n\t    \t\tfinal String[] folderArray = YMarkTables.cleanFoldersString(post.get(YMarkTables.BOOKMARK.FOLDERS.key())).split(YMarkTables.TAGS_SEPARATOR);\n                try {                \t\n\t\t\t\t\tif(tags)\n\t\t\t\t\t\tbookmarks.retainAll(sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folderArray));\n\t\t\t\t\telse\n\t\t\t\t\t\tbookmarks.addAll(sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folderArray));\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t    \t}\n\t    \tputBookmarks(bookmarks, YMarkTables.TABLES.BOOKMARKS.tablename(bmk_user));\n\t    \t\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n        // return rewrite properties\n        return prop;\n\t}","id":14578,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        sb = (Switchboard) env;\n        prop = new serverObjects();\n        \n        boolean tags = false;\n        \n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n    \tIterator<Tables.Row> bookmarks = null;\n        \n        if(isAdmin || isAuthUser) {\n        \tfinal String bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);\n        \t\n\t    \tif(post.containsKey(YMarkTables.BOOKMARK.TAGS.key())) {\n\t    \t\ttags = true;\n\t    \t\tfinal String[] tagArray = YMarkUtil.cleanTagsString(post.get(YMarkTables.BOOKMARK.TAGS.key())).split(YMarkUtil.TAGS_SEPARATOR);\n\t    \t\ttry {\n\t    \t\t\tbookmarks = sb.tables.bookmarks.getBookmarksByTag(bmk_user, tagArray);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t    \t}\n\t    \t/*\n\t    \tif(post.containsKey(YMarkTables.BOOKMARK.FOLDERS.key())) {\n\t    \t\tfinal String[] folderArray = YMarkTables.cleanFoldersString(post.get(YMarkTables.BOOKMARK.FOLDERS.key())).split(YMarkTables.TAGS_SEPARATOR);\n                try {                \t\n\t\t\t\t\tif(tags)\n\t\t\t\t\t\tbookmarks.retainAll(sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folderArray));\n\t\t\t\t\telse\n\t\t\t\t\t\tbookmarks.addAll(sb.tables.bookmarks.folders.getBookmarkIds(bmk_user, folderArray));\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t} catch (RowSpaceExceededException e) {\n\t\t\t\t\tLog.logException(e);\n\t\t\t\t}\n\t    \t}\n\t    \t*/\n\t    \tputBookmarks(bookmarks);\n\t    \t\n        } else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n        // return rewrite properties\n        return prop;\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        Thread t;\n        HashMap<String,String> bmk;\n\t\tByteArrayInputStream byteIn = null;\n        \n        if(isAdmin || isAuthUser) {\n        \tString bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);        \t\n        \tif(isAdmin && post.containsKey(\"table\") && post.get(\"table\").length() > 0) {\n        \t\tbmk_user = post.get(\"table\").substring(0, post.get(\"table\").indexOf('_'));\n        \t}\n        \t\n        \tif(post.containsKey(\"bmkfile\") && post.containsKey(\"importer\")){\n        \t\tbyteIn = new ByteArrayInputStream(UTF8.getBytes(post.get(\"bmkfile$file\")));\n        \t\tif(post.get(\"importer\").equals(\"html\") && byteIn != null) {\n\t\t\t\t\tfinal YMarksHTMLImporter htmlImporter = new YMarksHTMLImporter(byteIn, 100);\n\t\t            t = new Thread(htmlImporter, \"YMarks - HTML Importer\");\n\t\t            t.start();\n\t\t            while ((bmk = htmlImporter.take()) != YMarkTables.POISON) {\n\t\t\t\t\t\tputBookmark(sb, bmk_user, bmk);\n\t\t            }\n            \t\tprop.put(\"result\", \"1\");        \t\t\t\n        \t\t} else if(post.get(\"importer\").equals(\"xbel\") && byteIn != null) {\n        \t\t\tfinal YMarksXBELImporter xbelImporter;\t\n    \t\t\t\ttry {\n\t\t\t\t\t\t//TODO: make RootFold \n    \t\t\t\t\txbelImporter = new YMarksXBELImporter(byteIn, 100, YMarkTables.FOLDERS_IMPORTED);\n\t\t\t\t\t} catch (SAXException e) {\n\t\t\t\t\t\t//TODO: display an error message\n\t\t\t\t\t\tLog.logException(e);\n\t\t\t\t\t\tprop.put(\"result\", \"0\");\n\t\t\t\t\t\treturn prop;\n\t\t\t\t\t}\n\t\t            t = new Thread(xbelImporter, \"YMarks - XBEL Importer\");\n\t\t            t.start();\n\t\t            while ((bmk = xbelImporter.take()) != YMarkTables.POISON) {\n\t\t\t\t\t\tputBookmark(sb, bmk_user, bmk);\n\t\t            }\n    \t\t\t\tprop.put(\"result\", \"1\");\n            \t}\n        \t}\n        }  else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n\t\tif(post.containsKey(\"redirect\") && post.get(\"redirect\").length() > 0) {\n\t\t\tprop.put(\"redirect_url\", post.get(\"redirect\"));\n\t\t\tprop.put(\"redirect\", \"1\");\n\t\t}\n        // return rewrite properties\n        return prop;\n\t}","id":14579,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        final UserDB.Entry user = sb.userDB.getUser(header);\n        final boolean isAdmin = (sb.verifyAuthentication(header, true));\n        final boolean isAuthUser = user!= null && user.hasRight(UserDB.AccessRight.BOOKMARK_RIGHT);\n        Thread t;\n        HashMap<String,String> bmk;\n\t\tByteArrayInputStream byteIn = null;\n        \n        if(isAdmin || isAuthUser) {\n        \tString bmk_user = (isAuthUser ? user.getUserName() : YMarkTables.USER_ADMIN);        \t\n        \tif(isAdmin && post.containsKey(\"table\") && post.get(\"table\").length() > 0) {\n        \t\tbmk_user = post.get(\"table\").substring(0, post.get(\"table\").indexOf('_'));\n        \t}\n        \t\n        \tif(post.containsKey(\"bmkfile\") && post.containsKey(\"importer\")){\n        \t\tbyteIn = new ByteArrayInputStream(UTF8.getBytes(post.get(\"bmkfile$file\")));\n        \t\tif(post.get(\"importer\").equals(\"html\") && byteIn != null) {\n\t\t\t\t\tfinal YMarkHTMLImporter htmlImporter = new YMarkHTMLImporter(byteIn, 10);\n\t\t            t = new Thread(htmlImporter, \"YMarks - HTML Importer\");\n\t\t            t.start();\n\t\t            while ((bmk = htmlImporter.take()) != YMarkTables.POISON) {\n\t\t\t\t\t\tputBookmark(sb, bmk_user, bmk);\n\t\t            }\n            \t\tprop.put(\"result\", \"1\");        \t\t\t\n        \t\t} else if(post.get(\"importer\").equals(\"xbel\") && byteIn != null) {\n        \t\t\tfinal YMarkXBELImporter xbelImporter;\t\n    \t\t\t\ttry {\n\t\t\t\t\t\t//TODO: make RootFold \n    \t\t\t\t\txbelImporter = new YMarkXBELImporter(byteIn, 100, YMarkTables.FOLDERS_IMPORTED);\n\t\t\t\t\t} catch (SAXException e) {\n\t\t\t\t\t\t//TODO: display an error message\n\t\t\t\t\t\tLog.logException(e);\n\t\t\t\t\t\tprop.put(\"result\", \"0\");\n\t\t\t\t\t\treturn prop;\n\t\t\t\t\t}\n\t\t            t = new Thread(xbelImporter, \"YMarks - XBEL Importer\");\n\t\t            t.start();\n\t\t            while ((bmk = xbelImporter.take()) != YMarkTables.POISON) {\n\t\t\t\t\t\tputBookmark(sb, bmk_user, bmk);\n\t\t            }\n    \t\t\t\tprop.put(\"result\", \"1\");\n            \t}\n        \t}\n        }  else {\n        \tprop.put(YMarkTables.USER_AUTHENTICATE,YMarkTables.USER_AUTHENTICATE_MSG);\n        }\n\t\tif(post.containsKey(\"redirect\") && post.get(\"redirect\").length() > 0) {\n\t\t\tprop.put(\"redirect_url\", post.get(\"redirect\"));\n\t\t\tprop.put(\"redirect\", \"1\");\n\t\t}\n        // return rewrite properties\n        return prop;\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static void putBookmark(final Switchboard sb, final String bmk_user, final HashMap<String, String> bmk) {\n\t\ttry {\n\t\t\tif(!bmk.containsKey(YMarkTables.BOOKMARK.TAGS.key()) || bmk.get(YMarkTables.BOOKMARK.TAGS.key()).equals(YMarkTables.BOOKMARK.TAGS.deflt())) {\n\t            final DigestURI u = new DigestURI(bmk.get(YMarkTables.BOOKMARK.URL.key()));\n\t            Response response = sb.loader.load(sb.loader.request(u, true, false), CrawlProfile.CacheStrategy.IFEXIST, Long.MAX_VALUE, true);\n\t\t\t\tfinal Document document = Document.mergeDocuments(response.url(), response.getMimeType(), response.parse());\n\t\t\t\tif(document != null) {\n\t\t\t\t\tbmk.put(YMarkTables.BOOKMARK.TAGS.key(), sb.tables.bookmarks.autoTag(document, bmk_user, 3));\n\t\t\t\t}\n\t\t\t}\n\t\t\tsb.tables.bookmarks.addBookmark(bmk_user, bmk, true);\n\t\t} catch (IOException e) {\n\t\t\tLog.logWarning(YMarkTables.BOOKMARKS_LOG.toString(), \"Importer - IOException for URL: \"+bmk.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t} catch (RowSpaceExceededException e) {\n\t\t\tLog.logException(e);\n\t\t} catch (Failure e) {\n\t\t\tLog.logWarning(YMarkTables.BOOKMARKS_LOG.toString(), \"Importer - Failure for URL: \"+bmk.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t}\n\t}","id":14580,"modified_method":"public static void putBookmark(final Switchboard sb, final String bmk_user, final HashMap<String, String> bmk) {\n\t\ttry {\n\t\t\tif(!bmk.containsKey(YMarkTables.BOOKMARK.TAGS.key()) || bmk.get(YMarkTables.BOOKMARK.TAGS.key()).equals(YMarkTables.BOOKMARK.TAGS.deflt())) {\n\t            final YMarkMetadata meta = new YMarkMetadata(new DigestURI(bmk.get(YMarkTables.BOOKMARK.URL.key())));\n\t            meta.loadDocument(sb.loader);\n\t\t\t\tbmk.put(YMarkTables.BOOKMARK.TAGS.key(), meta.autoTag(3));\n\t\t\t}\n\t\t\tsb.tables.bookmarks.addBookmark(bmk_user, bmk, true);\n\t\t} catch (IOException e) {\n\t\t\tLog.logWarning(YMarkTables.BOOKMARKS_LOG.toString(), \"Importer - IOException for URL: \"+bmk.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t} catch (RowSpaceExceededException e) {\n\t\t\tLog.logException(e);\n\t\t} catch (Failure e) {\n\t\t\tLog.logWarning(YMarkTables.BOOKMARKS_LOG.toString(), \"Importer - Failure for URL: \"+bmk.get(YMarkTables.BOOKMARK.URL.key()));\n\t\t}\n\t}","commit_id":"78d6d6ca0640149bb10645ac142f05dd3bb90794","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"/**\n     * Tests sending 1, 2 (OOB) and 3, where they are received in the order 1, 3, 2. Message 3 should not get delivered\n     * until message 4 is received (http://jira.jboss.com/jira/browse/JGRP-780)\n     */\n    public void testRegularAndOOBUnicasts() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        c1.send(m3);\n\n        sendStableMessages(c1,c2);\n        Util.sleep(1000); // time for potential retransmission\n        Collection<Integer> list=receiver.getMsgs();\n        assert list.size() == 3 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3);\n    }","id":14581,"modified_method":"/**\n     * Tests sending 1, 2 (OOB) and 3, where they are received in the order 1, 3, 2. Message 3 should not get delivered\n     * until message 4 is received (http://jira.jboss.com/jira/browse/JGRP-780)\n     */\n    public void testRegularAndOOBUnicasts() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class, UNICAST2.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        c1.send(m3);\n\n        sendStableMessages(c1,c2);\n        Util.sleep(1000); // time for potential retransmission\n        Collection<Integer> list=receiver.getMsgs();\n        assert list.size() == 3 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3);\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"public void testRegularAndOOBUnicasts2() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n        m3.setFlag(Message.OOB);\n        Message m4=new Message(dest, null, 4);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m3);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        \n        c1.send(m4);\n        Util.sleep(1000); // sleep some time to receive all messages\n\n        Collection<Integer> list=receiver.getMsgs();\n        int count=10;\n        while(list.size() < 4 && --count > 0) {\n            Util.sleep(500); // time for potential retransmission\n            sendStableMessages(c1,c2);\n        }\n        log.info(\"list = \" + list);\n        assert list.size() == 4 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3) && list.contains(4);\n    }","id":14582,"modified_method":"public void testRegularAndOOBUnicasts2() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class, UNICAST2.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n        m3.setFlag(Message.OOB);\n        Message m4=new Message(dest, null, 4);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m3);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        \n        c1.send(m4);\n        Util.sleep(1000); // sleep some time to receive all messages\n\n        Collection<Integer> list=receiver.getMsgs();\n        int count=10;\n        while(list.size() < 4 && --count > 0) {\n            Util.sleep(500); // time for potential retransmission\n            sendStableMessages(c1,c2);\n        }\n        log.info(\"list = \" + list);\n        assert list.size() == 4 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3) && list.contains(4);\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"public Adder(UNICAST2 unicast, CountDownLatch latch, AtomicInteger num_msgs, AtomicLong current_seqno,\n                     boolean oob, final Address dest, final Address sender) {\n            this.unicast=unicast;\n            this.latch=latch;\n            this.num_msgs=num_msgs;\n            this.current_seqno=current_seqno;\n            this.oob=oob;\n            this.dest=dest;\n            this.sender=sender;\n        }","id":14583,"modified_method":"public Adder(UNICAST2 unicast, CountDownLatch latch, AtomicInteger num_msgs, AtomicLong current_seqno,\n                     boolean oob, final Address dest, final Address sender) {\n            this.unicast=unicast;\n            this.latch=latch;\n            this.num_msgs=num_msgs;\n            this.current_seqno=current_seqno;\n            this.oob=oob;\n            this.dest=dest;\n            this.sender=sender;\n            setName(\"Adder\");\n        }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"private static void start(final int num_threads, final int num_msgs, boolean oob, int max_msg_batch_size) {\n        final UNICAST2 unicast=new UNICAST2();\n        final AtomicInteger counter=new AtomicInteger(num_msgs);\n        final AtomicLong seqno=new AtomicLong(1);\n        final AtomicInteger delivered_msgs=new AtomicInteger(0);\n        final Lock lock=new ReentrantLock();\n        final Condition all_msgs_delivered=lock.newCondition();\n        final ConcurrentLinkedQueue<Long> delivered_msg_list=new ConcurrentLinkedQueue<Long>();\n        final Address local_addr=Util.createRandomAddress();\n        final Address sender=Util.createRandomAddress();\n\n//        Runtime.getRuntime().addShutdownHook(new Thread() {\n//            public void run() {\n//                System.out.println(\"\\ndelivered_msgs=\" + delivered_msgs);\n//                System.out.println(\"stats:\\n\" + unicast.dumpStats());\n//            }\n//        });\n\n        unicast.setTimer(new TimeScheduler(5));\n\n        unicast.setDownProtocol(new Protocol() {\n            public Object down(Event evt) {\n                return null;\n            }\n        });\n\n        unicast.setUpProtocol(new Protocol() {\n            public Object up(Event evt) {\n                if(evt.getType() == Event.MSG) {\n                    delivered_msgs.incrementAndGet();\n                    UNICAST2.Unicast2Header hdr=(UNICAST2.Unicast2Header)((Message)evt.getArg()).getHeader(UNICAST_ID);\n                    if(hdr != null)\n                        delivered_msg_list.add(hdr.getSeqno());\n\n                    if(delivered_msgs.get() >= num_msgs) {\n                        lock.lock();\n                        try {\n                            all_msgs_delivered.signalAll();\n                        }\n                        finally {\n                            lock.unlock();\n                        }\n                    }\n                }\n                return null;\n            }\n        });\n\n        unicast.down(new Event(Event.SET_LOCAL_ADDRESS, local_addr));\n\n        unicast.setMaxMessageBatchSize(max_msg_batch_size);\n\n        // send the first message manually, to initialize the AckReceiverWindow tables\n        Message msg=createMessage(local_addr, sender, 1L, oob, true);\n        unicast.up(new Event(Event.MSG, msg));\n        Util.sleep(500);\n\n\n        final CountDownLatch latch=new CountDownLatch(1);\n        Adder[] adders=new Adder[num_threads];\n        for(int i=0; i < adders.length; i++) {\n            adders[i]=new Adder(unicast, latch, counter, seqno, oob, local_addr, sender);\n            adders[i].start();\n        }\n\n        long start=System.currentTimeMillis();\n        latch.countDown(); // starts all adders\n\n        lock.lock();\n        try {\n            while(delivered_msgs.get() < num_msgs) {\n                try {\n                    all_msgs_delivered.await(1000, TimeUnit.MILLISECONDS);\n                    System.out.println(\"received \" + delivered_msgs.get() + \" msgs\");\n\n                    // send a spurious message to trigger removal of pending messages in AckReceiverWindow\n                    msg=createMessage(local_addr, sender, 1L, oob, false);\n                    unicast.up(new Event(Event.MSG, msg));\n                }\n                catch(InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        finally {\n            lock.unlock();\n        }\n\n        long time=System.currentTimeMillis() - start;\n        double requests_sec=num_msgs / (time / 1000.0);\n        System.out.println(\"\\nTime: \" + time + \" ms, \" + Util.format(requests_sec) + \" requests / sec\\n\");\n        System.out.println(\"Delivered messages: \" + delivered_msg_list.size());\n        if(delivered_msg_list.size() < 100)\n            System.out.println(\"Elements: \" + delivered_msg_list);\n\n        List<Long> results=new ArrayList<Long>(delivered_msg_list);\n\n        if(oob)\n            Collections.sort(results);\n\n        assert results.size() == num_msgs : \"expected \" + num_msgs + \", but got \" + results.size();\n\n        System.out.println(\"Checking results consistency\");\n        int i=1;\n        for(Long num: results) {\n            if(num.longValue() != i) {\n                assert i == num : \"expected \" + i + \" but got \" + num;\n                return;\n            }\n            i++;\n        }\n        System.out.println(\"OK\");\n    }","id":14584,"modified_method":"private static void start(final int num_threads, final int num_msgs, boolean oob, int max_msg_batch_size) {\n        final UNICAST2 unicast=new UNICAST2();\n        final AtomicInteger counter=new AtomicInteger(num_msgs);\n        final AtomicLong seqno=new AtomicLong(1);\n        final AtomicInteger delivered_msgs=new AtomicInteger(0);\n        final Lock lock=new ReentrantLock();\n        final Condition all_msgs_delivered=lock.newCondition();\n        final ConcurrentLinkedQueue<Long> delivered_msg_list=new ConcurrentLinkedQueue<Long>();\n        final Address local_addr=Util.createRandomAddress();\n        final Address sender=Util.createRandomAddress();\n\n//        Runtime.getRuntime().addShutdownHook(new Thread() {\n//            public void run() {\n//                System.out.println(\"\\ndelivered_msgs=\" + delivered_msgs);\n//                System.out.println(\"stats:\\n\" + unicast.dumpStats());\n//            }\n//        });\n\n        TimeScheduler timer=new TimeScheduler(10);\n        unicast.setTimer(timer);\n\n        unicast.setDownProtocol(new Protocol() {\n            public Object down(Event evt) {\n                return null;\n            }\n        });\n\n        unicast.setUpProtocol(new Protocol() {\n            public Object up(Event evt) {\n                if(evt.getType() == Event.MSG) {\n                    delivered_msgs.incrementAndGet();\n                    UNICAST2.Unicast2Header hdr=(UNICAST2.Unicast2Header)((Message)evt.getArg()).getHeader(UNICAST_ID);\n                    if(hdr != null)\n                        delivered_msg_list.add(hdr.getSeqno());\n\n                    if(delivered_msgs.get() >= num_msgs) {\n                        lock.lock();\n                        try {\n                            all_msgs_delivered.signalAll();\n                        }\n                        finally {\n                            lock.unlock();\n                        }\n                    }\n                }\n                return null;\n            }\n        });\n\n        unicast.down(new Event(Event.SET_LOCAL_ADDRESS, local_addr));\n\n        unicast.setMaxMessageBatchSize(max_msg_batch_size);\n\n        // send the first message manually, to initialize the AckReceiverWindow tables\n        Message msg=createMessage(local_addr, sender, 1L, oob, true);\n        unicast.up(new Event(Event.MSG, msg));\n        Util.sleep(500);\n\n\n        final CountDownLatch latch=new CountDownLatch(1);\n        Adder[] adders=new Adder[num_threads];\n        for(int i=0; i < adders.length; i++) {\n            adders[i]=new Adder(unicast, latch, counter, seqno, oob, local_addr, sender);\n            adders[i].start();\n        }\n\n        long start=System.currentTimeMillis();\n        latch.countDown(); // starts all adders\n\n        lock.lock();\n        try {\n            while(delivered_msgs.get() < num_msgs) {\n                try {\n                    all_msgs_delivered.await(1000, TimeUnit.MILLISECONDS);\n                    System.out.println(\"received \" + delivered_msgs.get() + \" msgs\");\n\n                    // send a spurious message to trigger removal of pending messages in AckReceiverWindow\n                    msg=createMessage(local_addr, sender, 1L, oob, false);\n                    unicast.up(new Event(Event.MSG, msg));\n                }\n                catch(InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        finally {\n            lock.unlock();\n        }\n\n        long time=System.currentTimeMillis() - start;\n        double requests_sec=num_msgs / (time / 1000.0);\n        System.out.println(\"\\nTime: \" + time + \" ms, \" + Util.format(requests_sec) + \" requests / sec\\n\");\n        System.out.println(\"Delivered messages: \" + delivered_msg_list.size());\n        if(delivered_msg_list.size() < 100)\n            System.out.println(\"Elements: \" + delivered_msg_list);\n\n        unicast.stop();\n        try {\n            timer.stop();\n        }\n        catch(InterruptedException e) {\n        }\n\n        List<Long> results=new ArrayList<Long>(delivered_msg_list);\n\n        if(oob)\n            Collections.sort(results);\n\n        assert results.size() == num_msgs : \"expected \" + num_msgs + \", but got \" + results.size();\n\n        System.out.println(\"Checking results consistency\");\n        int i=1;\n        for(Long num: results) {\n            if(num.longValue() != i) {\n                assert i == num : \"expected \" + i + \" but got \" + num;\n                return;\n            }\n            i++;\n        }\n        System.out.println(\"OK\");\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"void invokeRpcs() throws Throwable {\n        if(num_threads > 1 && num_msgs % num_threads != 0) {\n            System.err.println(\"num_msgs (\" + num_msgs + \" ) has to be divisible by num_threads (\" + num_threads + \")\");\n            return;\n        }\n\n        if(anycasting) {\n            populateAnycastList(channel.getView());\n        }\n        else {\n            if((destination=getReceiver()) == null) {\n                System.err.println(\"UnicastTest.invokeRpcs(): receiver is null, cannot send messages\");\n                return;\n            }\n        }\n\n        System.out.println(\"invoking \" + num_msgs + \" RPCs of \" + Util.printBytes(msg_size) + \" on \" +\n                (anycasting? anycast_mbrs : destination) + \", sync=\" + sync + \", oob=\" + oob + \", anycasting=\" + anycasting);\n        \n        // The first call needs to be synchronous with OOB !\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0, anycasting, null);\n        if(sync) options.setFlags(Message.DONT_BUNDLE);\n        if(oob) options.setFlags(Message.OOB);\n\n        if(anycasting)\n            disp.callRemoteMethods(anycast_mbrs, new MethodCall((short)0, new Object[]{num_msgs}), options);\n        else\n            disp.callRemoteMethod(destination, new MethodCall((short)0, new Object[]{num_msgs}), options);\n        options.setMode(sync? Request.GET_ALL : Request.GET_NONE);\n\n        Invoker[] invokers=new Invoker[num_threads];\n        for(int i=0; i < invokers.length; i++) {\n            if(anycasting)\n                invokers[i]=new Invoker(anycast_mbrs, options, num_msgs / num_threads);\n            else\n                invokers[i]=new Invoker(destination, options, num_msgs / num_threads);\n        }\n        for(Invoker invoker: invokers)\n            invoker.start();\n        for(Invoker invoker: invokers)\n            invoker.join();\n\n        System.out.println(\"done invoking \" + num_msgs + \" in \" + destination);\n    }","id":14585,"modified_method":"void invokeRpcs() throws Throwable {\n        if(num_threads > 1 && num_msgs % num_threads != 0) {\n            System.err.println(\"num_msgs (\" + num_msgs + \" ) has to be divisible by num_threads (\" + num_threads + \")\");\n            return;\n        }\n\n        if(anycasting) {\n            populateAnycastList(channel.getView());\n        }\n        else {\n            if((destination=getReceiver()) == null) {\n                System.err.println(\"UnicastTest.invokeRpcs(): receiver is null, cannot send messages\");\n                return;\n            }\n        }\n\n        System.out.println(\"invoking \" + num_msgs + \" RPCs of \" + Util.printBytes(msg_size) + \" on \" +\n                (anycasting? anycast_mbrs : destination) + \", sync=\" + sync + \", oob=\" + oob + \", anycasting=\" + anycasting);\n        \n        // The first call needs to be synchronous with OOB !\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0, anycasting, null);\n        if(sync) options.setFlags(Message.DONT_BUNDLE);\n        if(oob) options.setFlags(Message.OOB);\n\n        if(anycasting)\n            disp.callRemoteMethods(anycast_mbrs, new MethodCall((short)0, num_msgs), options);\n        else\n            disp.callRemoteMethod(destination, new MethodCall((short)0, num_msgs), options);\n        options.setMode(sync? Request.GET_ALL : Request.GET_NONE);\n\n        Invoker[] invokers=new Invoker[num_threads];\n        for(int i=0; i < invokers.length; i++) {\n            if(anycasting)\n                invokers[i]=new Invoker(anycast_mbrs, options, num_msgs / num_threads);\n            else\n                invokers[i]=new Invoker(destination, options, num_msgs / num_threads);\n        }\n        for(Invoker invoker: invokers)\n            invoker.start();\n        for(Invoker invoker: invokers)\n            invoker.join();\n\n        System.out.println(\"done invoking \" + num_msgs + \" in \" + destination);\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeAllConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        unicast.removeAllConnections();\n    }","id":14586,"modified_method":"private void removeAllConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            ((UNICAST)prot).removeAllConnections();\n        else if(prot instanceof UNICAST2)\n            ((UNICAST2)prot).removeAllConnections();\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"public Object objectFromByteBuffer(byte[] buffer) throws Exception {\n            ByteBuffer buf=ByteBuffer.wrap(buffer);\n\n            byte type=buf.get();\n            switch(type) {\n                case 0:\n                    int arg=buf.getInt();\n                    return new MethodCall((short)0, new Object[]{arg});\n                case 1:\n                    Long longarg=buf.getLong();\n                    int len=buf.getInt();\n                    byte[] arg2=new byte[len];\n                    buf.get(arg2, 0, arg2.length);\n                    return new MethodCall((short)1, new Object[]{longarg, arg2});\n                default:\n                    throw new IllegalStateException(\"type \" + type + \" not known\");\n            }\n        }","id":14587,"modified_method":"public Object objectFromByteBuffer(byte[] buffer) throws Exception {\n            ByteBuffer buf=ByteBuffer.wrap(buffer);\n\n            byte type=buf.get();\n            switch(type) {\n                case 0:\n                    int arg=buf.getInt();\n                    return new MethodCall((short)0, arg);\n                case 1:\n                    Long longarg=buf.getLong();\n                    int len=buf.getInt();\n                    byte[] arg2=new byte[len];\n                    buf.get(arg2, 0, arg2.length);\n                    return new MethodCall((short)1, longarg, arg2);\n                default:\n                    throw new IllegalStateException(\"type \" + type + \" not known\");\n            }\n        }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"private void printConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        System.out.println(\"connections:\\n\" + unicast.printConnections());\n    }","id":14588,"modified_method":"private void printConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            System.out.println(\"connections:\\n\" + ((UNICAST)prot).printConnections());\n        else if(prot instanceof UNICAST2)\n            System.out.println(\"connections:\\n\" + ((UNICAST2)prot).printConnections());\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n            unicast.removeConnection(member);\n        }\n    }","id":14589,"modified_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n            if(prot instanceof UNICAST)\n                ((UNICAST)prot).removeConnection(member);\n            else if(prot instanceof UNICAST2)\n                ((UNICAST2)prot).removeConnection(member);\n        }\n    }","commit_id":"9808fab87305db664271b2ec0503a9fb104c7ef8","url":"https://github.com/belaban/JGroups"},{"original_method":"/** Kicks off the benchmark on all cluster nodes */\n    void startBenchmark() throws Throwable {\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0);\n        options.setFlags(Message.OOB);\n        options.setFlags(Message.DONT_BUNDLE);\n        options.setFlags(Message.NO_FC);\n        RspList responses=disp.callRemoteMethods(null, new MethodCall(START), options);\n\n        long total_reqs=0;\n        long total_time=0;\n\n        System.out.println(\"\\n======================= Results: ===========================\");\n        for(Map.Entry<Address,Rsp> entry: responses.entrySet()) {\n            Address mbr=entry.getKey();\n            Rsp rsp=entry.getValue();\n            Results result=(Results)rsp.getValue();\n            total_reqs+=result.num_gets + result.num_puts;\n            total_time+=result.time;\n            System.out.println(mbr + \": \" + result);\n        }\n        double total_reqs_sec=total_reqs / ( total_time/ 1000.0);\n        double throughput=total_reqs_sec * msg_size;\n        double ms_per_req=total_time / (double)total_reqs;\n        System.out.println(\"\\nAverage of \" + f.format(total_reqs_sec) + \" requests / sec (\" +\n                Util.printBytes(throughput) + \" / sec), \" + f.format(ms_per_req) + \" ms /request\");\n        System.out.println(\"\\n\\n\");\n    }","id":14590,"modified_method":"/** Kicks off the benchmark on all cluster nodes */\n    void startBenchmark() throws Throwable {\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0);\n        options.setFlags(Message.OOB);\n        options.setFlags(Message.DONT_BUNDLE);\n        options.setFlags(Message.NO_FC);\n        RspList responses=disp.callRemoteMethods(null, new MethodCall(START), options);\n\n        long total_reqs=0;\n        long total_time=0;\n\n        System.out.println(\"\\n======================= Results: ===========================\");\n        for(Map.Entry<Address,Rsp> entry: responses.entrySet()) {\n            Address mbr=entry.getKey();\n            Rsp rsp=entry.getValue();\n            Results result=(Results)rsp.getValue();\n            total_reqs+=result.num_gets + result.num_puts;\n            total_time+=result.time;\n            System.out.println(mbr + \": \" + result);\n        }\n        double total_reqs_sec=total_reqs / ( total_time/ 1000.0);\n        double throughput=total_reqs_sec * msg_size;\n        double ms_per_req=total_time / (double)total_reqs;\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        System.out.println(\"\\nAverage of \" + f.format(total_reqs_sec) + \" requests / sec (\" +\n                Util.printBytes(throughput) + \" / sec), \" + f.format(ms_per_req) + \" ms /request (prot=\" + prot.getName() + \")\");\n        System.out.println(\"\\n\\n\");\n    }","commit_id":"10e279c2a75e0ea2a919edf7aef53dd56be5cd1c","url":"https://github.com/belaban/JGroups"},{"original_method":"private void printConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        System.out.println(\"connections:\\n\" + unicast.printConnections());\n    }","id":14591,"modified_method":"private void printConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            System.out.println(\"connections:\\n\" + ((UNICAST)prot).printConnections());\n        else if(prot instanceof UNICAST2)\n            System.out.println(\"connections:\\n\" + ((UNICAST2)prot).printConnections());\n    }","commit_id":"10e279c2a75e0ea2a919edf7aef53dd56be5cd1c","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n            unicast.removeConnection(member);\n        }\n    }","id":14592,"modified_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n            if(prot instanceof UNICAST)\n                ((UNICAST)prot).removeConnection(member);\n            else if(prot instanceof UNICAST2)\n                ((UNICAST2)prot).removeConnection(member);\n        }\n    }","commit_id":"10e279c2a75e0ea2a919edf7aef53dd56be5cd1c","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeAllConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        unicast.removeAllConnections();\n    }","id":14593,"modified_method":"private void removeAllConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            ((UNICAST)prot).removeAllConnections();\n        else if(prot instanceof UNICAST2)\n            ((UNICAST2)prot).removeAllConnections();\n    }","commit_id":"10e279c2a75e0ea2a919edf7aef53dd56be5cd1c","url":"https://github.com/belaban/JGroups"},{"original_method":"public void testRegularAndOOBUnicasts2() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n        m3.setFlag(Message.OOB);\n        Message m4=new Message(dest, null, 4);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m3);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        \n        c1.send(m4);\n        Util.sleep(1000); // sleep some time to receive all messages\n\n        Collection<Integer> list=receiver.getMsgs();\n        int count=10;\n        while(list.size() < 4 && --count > 0) {\n            Util.sleep(500); // time for potential retransmission\n            sendStableMessages(c1,c2);\n        }\n        log.info(\"list = \" + list);\n        assert list.size() == 4 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3) && list.contains(4);\n    }","id":14594,"modified_method":"public void testRegularAndOOBUnicasts2() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class, UNICAST2.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n        m3.setFlag(Message.OOB);\n        Message m4=new Message(dest, null, 4);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m3);\n\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        \n        c1.send(m4);\n        Util.sleep(1000); // sleep some time to receive all messages\n\n        Collection<Integer> list=receiver.getMsgs();\n        int count=10;\n        while(list.size() < 4 && --count > 0) {\n            Util.sleep(500); // time for potential retransmission\n            sendStableMessages(c1,c2);\n        }\n        log.info(\"list = \" + list);\n        assert list.size() == 4 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3) && list.contains(4);\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"/**\n     * Tests sending 1, 2 (OOB) and 3, where they are received in the order 1, 3, 2. Message 3 should not get delivered\n     * until message 4 is received (http://jira.jboss.com/jira/browse/JGRP-780)\n     */\n    public void testRegularAndOOBUnicasts() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        c1.send(m3);\n\n        sendStableMessages(c1,c2);\n        Util.sleep(1000); // time for potential retransmission\n        Collection<Integer> list=receiver.getMsgs();\n        assert list.size() == 3 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3);\n    }","id":14595,"modified_method":"/**\n     * Tests sending 1, 2 (OOB) and 3, where they are received in the order 1, 3, 2. Message 3 should not get delivered\n     * until message 4 is received (http://jira.jboss.com/jira/browse/JGRP-780)\n     */\n    public void testRegularAndOOBUnicasts() throws Exception {\n        DISCARD discard=new DISCARD();\n        ProtocolStack stack=c1.getProtocolStack();\n        stack.insertProtocol(discard, ProtocolStack.BELOW, UNICAST.class, UNICAST2.class);\n\n        Address dest=c2.getAddress();\n        Message m1=new Message(dest, null, 1);\n        Message m2=new Message(dest, null, 2);\n        m2.setFlag(Message.OOB);\n        Message m3=new Message(dest, null, 3);\n\n        MyReceiver receiver=new MyReceiver(\"C2\");\n        c2.setReceiver(receiver);\n        c1.send(m1);\n        discard.setDropDownUnicasts(1);\n        c1.send(m2);\n        c1.send(m3);\n\n        sendStableMessages(c1,c2);\n        Util.sleep(1000); // time for potential retransmission\n        Collection<Integer> list=receiver.getMsgs();\n        assert list.size() == 3 : \"list is \" + list;\n        assert list.contains(1) && list.contains(2) && list.contains(3);\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"public Adder(UNICAST2 unicast, CountDownLatch latch, AtomicInteger num_msgs, AtomicLong current_seqno,\n                     boolean oob, final Address dest, final Address sender) {\n            this.unicast=unicast;\n            this.latch=latch;\n            this.num_msgs=num_msgs;\n            this.current_seqno=current_seqno;\n            this.oob=oob;\n            this.dest=dest;\n            this.sender=sender;\n        }","id":14596,"modified_method":"public Adder(UNICAST2 unicast, CountDownLatch latch, AtomicInteger num_msgs, AtomicLong current_seqno,\n                     boolean oob, final Address dest, final Address sender) {\n            this.unicast=unicast;\n            this.latch=latch;\n            this.num_msgs=num_msgs;\n            this.current_seqno=current_seqno;\n            this.oob=oob;\n            this.dest=dest;\n            this.sender=sender;\n            setName(\"Adder\");\n        }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"private static void start(final int num_threads, final int num_msgs, boolean oob, int max_msg_batch_size) {\n        final UNICAST2 unicast=new UNICAST2();\n        final AtomicInteger counter=new AtomicInteger(num_msgs);\n        final AtomicLong seqno=new AtomicLong(1);\n        final AtomicInteger delivered_msgs=new AtomicInteger(0);\n        final Lock lock=new ReentrantLock();\n        final Condition all_msgs_delivered=lock.newCondition();\n        final ConcurrentLinkedQueue<Long> delivered_msg_list=new ConcurrentLinkedQueue<Long>();\n        final Address local_addr=Util.createRandomAddress();\n        final Address sender=Util.createRandomAddress();\n\n//        Runtime.getRuntime().addShutdownHook(new Thread() {\n//            public void run() {\n//                System.out.println(\"\\ndelivered_msgs=\" + delivered_msgs);\n//                System.out.println(\"stats:\\n\" + unicast.dumpStats());\n//            }\n//        });\n\n        unicast.setTimer(new TimeScheduler(5));\n\n        unicast.setDownProtocol(new Protocol() {\n            public Object down(Event evt) {\n                return null;\n            }\n        });\n\n        unicast.setUpProtocol(new Protocol() {\n            public Object up(Event evt) {\n                if(evt.getType() == Event.MSG) {\n                    delivered_msgs.incrementAndGet();\n                    UNICAST2.Unicast2Header hdr=(UNICAST2.Unicast2Header)((Message)evt.getArg()).getHeader(UNICAST_ID);\n                    if(hdr != null)\n                        delivered_msg_list.add(hdr.getSeqno());\n\n                    if(delivered_msgs.get() >= num_msgs) {\n                        lock.lock();\n                        try {\n                            all_msgs_delivered.signalAll();\n                        }\n                        finally {\n                            lock.unlock();\n                        }\n                    }\n                }\n                return null;\n            }\n        });\n\n        unicast.down(new Event(Event.SET_LOCAL_ADDRESS, local_addr));\n\n        unicast.setMaxMessageBatchSize(max_msg_batch_size);\n\n        // send the first message manually, to initialize the AckReceiverWindow tables\n        Message msg=createMessage(local_addr, sender, 1L, oob, true);\n        unicast.up(new Event(Event.MSG, msg));\n        Util.sleep(500);\n\n\n        final CountDownLatch latch=new CountDownLatch(1);\n        Adder[] adders=new Adder[num_threads];\n        for(int i=0; i < adders.length; i++) {\n            adders[i]=new Adder(unicast, latch, counter, seqno, oob, local_addr, sender);\n            adders[i].start();\n        }\n\n        long start=System.currentTimeMillis();\n        latch.countDown(); // starts all adders\n\n        lock.lock();\n        try {\n            while(delivered_msgs.get() < num_msgs) {\n                try {\n                    all_msgs_delivered.await(1000, TimeUnit.MILLISECONDS);\n                    System.out.println(\"received \" + delivered_msgs.get() + \" msgs\");\n\n                    // send a spurious message to trigger removal of pending messages in AckReceiverWindow\n                    msg=createMessage(local_addr, sender, 1L, oob, false);\n                    unicast.up(new Event(Event.MSG, msg));\n                }\n                catch(InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        finally {\n            lock.unlock();\n        }\n\n        long time=System.currentTimeMillis() - start;\n        double requests_sec=num_msgs / (time / 1000.0);\n        System.out.println(\"\\nTime: \" + time + \" ms, \" + Util.format(requests_sec) + \" requests / sec\\n\");\n        System.out.println(\"Delivered messages: \" + delivered_msg_list.size());\n        if(delivered_msg_list.size() < 100)\n            System.out.println(\"Elements: \" + delivered_msg_list);\n\n        List<Long> results=new ArrayList<Long>(delivered_msg_list);\n\n        if(oob)\n            Collections.sort(results);\n\n        assert results.size() == num_msgs : \"expected \" + num_msgs + \", but got \" + results.size();\n\n        System.out.println(\"Checking results consistency\");\n        int i=1;\n        for(Long num: results) {\n            if(num.longValue() != i) {\n                assert i == num : \"expected \" + i + \" but got \" + num;\n                return;\n            }\n            i++;\n        }\n        System.out.println(\"OK\");\n    }","id":14597,"modified_method":"private static void start(final int num_threads, final int num_msgs, boolean oob, int max_msg_batch_size) {\n        final UNICAST2 unicast=new UNICAST2();\n        final AtomicInteger counter=new AtomicInteger(num_msgs);\n        final AtomicLong seqno=new AtomicLong(1);\n        final AtomicInteger delivered_msgs=new AtomicInteger(0);\n        final Lock lock=new ReentrantLock();\n        final Condition all_msgs_delivered=lock.newCondition();\n        final ConcurrentLinkedQueue<Long> delivered_msg_list=new ConcurrentLinkedQueue<Long>();\n        final Address local_addr=Util.createRandomAddress();\n        final Address sender=Util.createRandomAddress();\n\n//        Runtime.getRuntime().addShutdownHook(new Thread() {\n//            public void run() {\n//                System.out.println(\"\\ndelivered_msgs=\" + delivered_msgs);\n//                System.out.println(\"stats:\\n\" + unicast.dumpStats());\n//            }\n//        });\n\n        TimeScheduler timer=new TimeScheduler(10);\n        unicast.setTimer(timer);\n\n        unicast.setDownProtocol(new Protocol() {\n            public Object down(Event evt) {\n                return null;\n            }\n        });\n\n        unicast.setUpProtocol(new Protocol() {\n            public Object up(Event evt) {\n                if(evt.getType() == Event.MSG) {\n                    delivered_msgs.incrementAndGet();\n                    UNICAST2.Unicast2Header hdr=(UNICAST2.Unicast2Header)((Message)evt.getArg()).getHeader(UNICAST_ID);\n                    if(hdr != null)\n                        delivered_msg_list.add(hdr.getSeqno());\n\n                    if(delivered_msgs.get() >= num_msgs) {\n                        lock.lock();\n                        try {\n                            all_msgs_delivered.signalAll();\n                        }\n                        finally {\n                            lock.unlock();\n                        }\n                    }\n                }\n                return null;\n            }\n        });\n\n        unicast.down(new Event(Event.SET_LOCAL_ADDRESS, local_addr));\n\n        unicast.setMaxMessageBatchSize(max_msg_batch_size);\n\n        // send the first message manually, to initialize the AckReceiverWindow tables\n        Message msg=createMessage(local_addr, sender, 1L, oob, true);\n        unicast.up(new Event(Event.MSG, msg));\n        Util.sleep(500);\n\n\n        final CountDownLatch latch=new CountDownLatch(1);\n        Adder[] adders=new Adder[num_threads];\n        for(int i=0; i < adders.length; i++) {\n            adders[i]=new Adder(unicast, latch, counter, seqno, oob, local_addr, sender);\n            adders[i].start();\n        }\n\n        long start=System.currentTimeMillis();\n        latch.countDown(); // starts all adders\n\n        lock.lock();\n        try {\n            while(delivered_msgs.get() < num_msgs) {\n                try {\n                    all_msgs_delivered.await(1000, TimeUnit.MILLISECONDS);\n                    System.out.println(\"received \" + delivered_msgs.get() + \" msgs\");\n\n                    // send a spurious message to trigger removal of pending messages in AckReceiverWindow\n                    msg=createMessage(local_addr, sender, 1L, oob, false);\n                    unicast.up(new Event(Event.MSG, msg));\n                }\n                catch(InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        finally {\n            lock.unlock();\n        }\n\n        long time=System.currentTimeMillis() - start;\n        double requests_sec=num_msgs / (time / 1000.0);\n        System.out.println(\"\\nTime: \" + time + \" ms, \" + Util.format(requests_sec) + \" requests / sec\\n\");\n        System.out.println(\"Delivered messages: \" + delivered_msg_list.size());\n        if(delivered_msg_list.size() < 100)\n            System.out.println(\"Elements: \" + delivered_msg_list);\n\n        unicast.stop();\n        try {\n            timer.stop();\n        }\n        catch(InterruptedException e) {\n        }\n\n        List<Long> results=new ArrayList<Long>(delivered_msg_list);\n\n        if(oob)\n            Collections.sort(results);\n\n        assert results.size() == num_msgs : \"expected \" + num_msgs + \", but got \" + results.size();\n\n        System.out.println(\"Checking results consistency\");\n        int i=1;\n        for(Long num: results) {\n            if(num.longValue() != i) {\n                assert i == num : \"expected \" + i + \" but got \" + num;\n                return;\n            }\n            i++;\n        }\n        System.out.println(\"OK\");\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"public Object objectFromByteBuffer(byte[] buffer) throws Exception {\n            ByteBuffer buf=ByteBuffer.wrap(buffer);\n\n            byte type=buf.get();\n            switch(type) {\n                case 0:\n                    int arg=buf.getInt();\n                    return new MethodCall((short)0, new Object[]{arg});\n                case 1:\n                    Long longarg=buf.getLong();\n                    int len=buf.getInt();\n                    byte[] arg2=new byte[len];\n                    buf.get(arg2, 0, arg2.length);\n                    return new MethodCall((short)1, new Object[]{longarg, arg2});\n                default:\n                    throw new IllegalStateException(\"type \" + type + \" not known\");\n            }\n        }","id":14598,"modified_method":"public Object objectFromByteBuffer(byte[] buffer) throws Exception {\n            ByteBuffer buf=ByteBuffer.wrap(buffer);\n\n            byte type=buf.get();\n            switch(type) {\n                case 0:\n                    int arg=buf.getInt();\n                    return new MethodCall((short)0, arg);\n                case 1:\n                    Long longarg=buf.getLong();\n                    int len=buf.getInt();\n                    byte[] arg2=new byte[len];\n                    buf.get(arg2, 0, arg2.length);\n                    return new MethodCall((short)1, longarg, arg2);\n                default:\n                    throw new IllegalStateException(\"type \" + type + \" not known\");\n            }\n        }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeAllConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        unicast.removeAllConnections();\n    }","id":14599,"modified_method":"private void removeAllConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            ((UNICAST)prot).removeAllConnections();\n        else if(prot instanceof UNICAST2)\n            ((UNICAST2)prot).removeAllConnections();\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"private void printConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        System.out.println(\"connections:\\n\" + unicast.printConnections());\n    }","id":14600,"modified_method":"private void printConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            System.out.println(\"connections:\\n\" + ((UNICAST)prot).printConnections());\n        else if(prot instanceof UNICAST2)\n            System.out.println(\"connections:\\n\" + ((UNICAST2)prot).printConnections());\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n            unicast.removeConnection(member);\n        }\n    }","id":14601,"modified_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n            if(prot instanceof UNICAST)\n                ((UNICAST)prot).removeConnection(member);\n            else if(prot instanceof UNICAST2)\n                ((UNICAST2)prot).removeConnection(member);\n        }\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"void invokeRpcs() throws Throwable {\n        if(num_threads > 1 && num_msgs % num_threads != 0) {\n            System.err.println(\"num_msgs (\" + num_msgs + \" ) has to be divisible by num_threads (\" + num_threads + \")\");\n            return;\n        }\n\n        if(anycasting) {\n            populateAnycastList(channel.getView());\n        }\n        else {\n            if((destination=getReceiver()) == null) {\n                System.err.println(\"UnicastTest.invokeRpcs(): receiver is null, cannot send messages\");\n                return;\n            }\n        }\n\n        System.out.println(\"invoking \" + num_msgs + \" RPCs of \" + Util.printBytes(msg_size) + \" on \" +\n                (anycasting? anycast_mbrs : destination) + \", sync=\" + sync + \", oob=\" + oob + \", anycasting=\" + anycasting);\n        \n        // The first call needs to be synchronous with OOB !\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0, anycasting, null);\n        if(sync) options.setFlags(Message.DONT_BUNDLE);\n        if(oob) options.setFlags(Message.OOB);\n\n        if(anycasting)\n            disp.callRemoteMethods(anycast_mbrs, new MethodCall((short)0, new Object[]{num_msgs}), options);\n        else\n            disp.callRemoteMethod(destination, new MethodCall((short)0, new Object[]{num_msgs}), options);\n        options.setMode(sync? Request.GET_ALL : Request.GET_NONE);\n\n        Invoker[] invokers=new Invoker[num_threads];\n        for(int i=0; i < invokers.length; i++) {\n            if(anycasting)\n                invokers[i]=new Invoker(anycast_mbrs, options, num_msgs / num_threads);\n            else\n                invokers[i]=new Invoker(destination, options, num_msgs / num_threads);\n        }\n        for(Invoker invoker: invokers)\n            invoker.start();\n        for(Invoker invoker: invokers)\n            invoker.join();\n\n        System.out.println(\"done invoking \" + num_msgs + \" in \" + destination);\n    }","id":14602,"modified_method":"void invokeRpcs() throws Throwable {\n        if(num_threads > 1 && num_msgs % num_threads != 0) {\n            System.err.println(\"num_msgs (\" + num_msgs + \" ) has to be divisible by num_threads (\" + num_threads + \")\");\n            return;\n        }\n\n        if(anycasting) {\n            populateAnycastList(channel.getView());\n        }\n        else {\n            if((destination=getReceiver()) == null) {\n                System.err.println(\"UnicastTest.invokeRpcs(): receiver is null, cannot send messages\");\n                return;\n            }\n        }\n\n        System.out.println(\"invoking \" + num_msgs + \" RPCs of \" + Util.printBytes(msg_size) + \" on \" +\n                (anycasting? anycast_mbrs : destination) + \", sync=\" + sync + \", oob=\" + oob + \", anycasting=\" + anycasting);\n        \n        // The first call needs to be synchronous with OOB !\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0, anycasting, null);\n        if(sync) options.setFlags(Message.DONT_BUNDLE);\n        if(oob) options.setFlags(Message.OOB);\n\n        if(anycasting)\n            disp.callRemoteMethods(anycast_mbrs, new MethodCall((short)0, num_msgs), options);\n        else\n            disp.callRemoteMethod(destination, new MethodCall((short)0, num_msgs), options);\n        options.setMode(sync? Request.GET_ALL : Request.GET_NONE);\n\n        Invoker[] invokers=new Invoker[num_threads];\n        for(int i=0; i < invokers.length; i++) {\n            if(anycasting)\n                invokers[i]=new Invoker(anycast_mbrs, options, num_msgs / num_threads);\n            else\n                invokers[i]=new Invoker(destination, options, num_msgs / num_threads);\n        }\n        for(Invoker invoker: invokers)\n            invoker.start();\n        for(Invoker invoker: invokers)\n            invoker.join();\n\n        System.out.println(\"done invoking \" + num_msgs + \" in \" + destination);\n    }","commit_id":"69eb5c872534ff579e9a245204f55eaaa527cf7b","url":"https://github.com/belaban/JGroups"},{"original_method":"/** Kicks off the benchmark on all cluster nodes */\n    void startBenchmark() throws Throwable {\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0);\n        options.setFlags(Message.OOB);\n        options.setFlags(Message.DONT_BUNDLE);\n        options.setFlags(Message.NO_FC);\n        RspList responses=disp.callRemoteMethods(null, new MethodCall(START), options);\n\n        long total_reqs=0;\n        long total_time=0;\n\n        System.out.println(\"\\n======================= Results: ===========================\");\n        for(Map.Entry<Address,Rsp> entry: responses.entrySet()) {\n            Address mbr=entry.getKey();\n            Rsp rsp=entry.getValue();\n            Results result=(Results)rsp.getValue();\n            total_reqs+=result.num_gets + result.num_puts;\n            total_time+=result.time;\n            System.out.println(mbr + \": \" + result);\n        }\n        double total_reqs_sec=total_reqs / ( total_time/ 1000.0);\n        double throughput=total_reqs_sec * msg_size;\n        double ms_per_req=total_time / (double)total_reqs;\n        System.out.println(\"\\nAverage of \" + f.format(total_reqs_sec) + \" requests / sec (\" +\n                Util.printBytes(throughput) + \" / sec), \" + f.format(ms_per_req) + \" ms /request\");\n        System.out.println(\"\\n\\n\");\n    }","id":14603,"modified_method":"/** Kicks off the benchmark on all cluster nodes */\n    void startBenchmark() throws Throwable {\n        RequestOptions options=new RequestOptions(Request.GET_ALL, 0);\n        options.setFlags(Message.OOB);\n        options.setFlags(Message.DONT_BUNDLE);\n        options.setFlags(Message.NO_FC);\n        RspList responses=disp.callRemoteMethods(null, new MethodCall(START), options);\n\n        long total_reqs=0;\n        long total_time=0;\n\n        System.out.println(\"\\n======================= Results: ===========================\");\n        for(Map.Entry<Address,Rsp> entry: responses.entrySet()) {\n            Address mbr=entry.getKey();\n            Rsp rsp=entry.getValue();\n            Results result=(Results)rsp.getValue();\n            total_reqs+=result.num_gets + result.num_puts;\n            total_time+=result.time;\n            System.out.println(mbr + \": \" + result);\n        }\n        double total_reqs_sec=total_reqs / ( total_time/ 1000.0);\n        double throughput=total_reqs_sec * msg_size;\n        double ms_per_req=total_time / (double)total_reqs;\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        System.out.println(\"\\nAverage of \" + f.format(total_reqs_sec) + \" requests / sec (\" +\n                Util.printBytes(throughput) + \" / sec), \" + f.format(ms_per_req) + \" ms /request (prot=\" + prot.getName() + \")\");\n        System.out.println(\"\\n\\n\");\n    }","commit_id":"ee91cf802a6305d171f8d0ef308e77929b5a5152","url":"https://github.com/belaban/JGroups"},{"original_method":"private void printConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        System.out.println(\"connections:\\n\" + unicast.printConnections());\n    }","id":14604,"modified_method":"private void printConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            System.out.println(\"connections:\\n\" + ((UNICAST)prot).printConnections());\n        else if(prot instanceof UNICAST2)\n            System.out.println(\"connections:\\n\" + ((UNICAST2)prot).printConnections());\n    }","commit_id":"ee91cf802a6305d171f8d0ef308e77929b5a5152","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeAllConnections() {\n        UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n        unicast.removeAllConnections();\n    }","id":14605,"modified_method":"private void removeAllConnections() {\n        Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n        if(prot instanceof UNICAST)\n            ((UNICAST)prot).removeAllConnections();\n        else if(prot instanceof UNICAST2)\n            ((UNICAST2)prot).removeAllConnections();\n    }","commit_id":"ee91cf802a6305d171f8d0ef308e77929b5a5152","url":"https://github.com/belaban/JGroups"},{"original_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            UNICAST unicast=(UNICAST)channel.getProtocolStack().findProtocol(UNICAST.class);\n            unicast.removeConnection(member);\n        }\n    }","id":14606,"modified_method":"private void removeConnection() {\n        Address member=getReceiver();\n        if(member != null) {\n            Protocol prot=channel.getProtocolStack().findProtocol(unicast_protocols);\n            if(prot instanceof UNICAST)\n                ((UNICAST)prot).removeConnection(member);\n            else if(prot instanceof UNICAST2)\n                ((UNICAST2)prot).removeConnection(member);\n        }\n    }","commit_id":"ee91cf802a6305d171f8d0ef308e77929b5a5152","url":"https://github.com/belaban/JGroups"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","id":14607,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        String group = request.getParameter(\"group\");\n        Map<String, Object> model;\n        if (group != null) {\n            model   = m_inventoryService.getRancidNodeWithCLoginForGroup(nodeid,WebSecurityUtils.sanitizeString(group),request.isUserInRole(Authentication.ADMIN_ROLE));\n        } else {\n            model   = m_inventoryService.getRancidNodeWithCLogin(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));            \n        }\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"0082acc0e8bd23fb332e20084fd32d75faac7030","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public Map<String, Object> getRancidNode(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNode start\");\n        Map<String, Object> nodeModel = new TreeMap<String, Object>();\n\n        \n        OnmsNode node = m_nodeDao.get(nodeid);\n        String rancidName = node.getLabel();\n        \n        String foreignSource = node.getForeignSource();\n        if (foreignSource != null ) {\n            nodeModel.put(\"permitModifyClogin\", false);\n            nodeModel.put(\"foreignSource\", foreignSource);\n        } else {\n            nodeModel.put(\"permitModifyClogin\", true);            \n        }\n\n        log().debug(\"getRancidNode: \" + rancidName);\n\n\n        nodeModel.put(\"id\", rancidName);\n        nodeModel.put(\"db_id\", nodeid);\n        nodeModel.put(\"status_general\", ElementUtil.getNodeStatusString(node.getType().charAt(0)));\n        \n        List<RancidNodeWrapper> ranlist = new ArrayList<RancidNodeWrapper>();\n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        Iterator<String> iter1 = grouplist.iterator();\n        \n      \n        String groupname;\n        boolean first = true;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNode \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                if (first){\n                    RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                    nodeModel.put(\"devicename\", rn.getDeviceName());\n                    nodeModel.put(\"status\", rn.getState());\n                    nodeModel.put(\"devicetype\", rn.getDeviceType());\n                    nodeModel.put(\"comment\", rn.getComment());\n                    nodeModel.put(\"groupname\", groupname);\n                    first = false;\n                } \n                RancidNode rn = RWSClientApi.getRWSRancidNodeInventory(m_cp ,groupname, rancidName);\n                String vs = rn.getHeadRevision();\n                InventoryNode in = (InventoryNode)rn.getNodeVersions().get(vs);\n\n                RancidNodeWrapper rnw = new RancidNodeWrapper(rn.getDeviceName(), groupname, rn.getDeviceType(), rn.getComment(), rn.getHeadRevision(),\n                  rn.getTotalRevisions(), in.getCreationDate(), rn.getRootConfigurationUrl());\n\n                ranlist.add(rnw); \n                \n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n            \n        //Groups invariant            \n        nodeModel.put(\"grouptable\", ranlist);\n        nodeModel.put(\"url\", m_cp.getUrl());\n        \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","id":14608,"modified_method":"public Map<String, Object> getRancidNodeWithCLogin(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNodeWithClogin start\");\n        Map<String, Object> nodeModel = getRancidNodeBase(nodeid);\n        String rancidName = (String)nodeModel.get(\"id\"); \n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        nodeModel.put(\"grouplist\",grouplist);\n        Iterator<String> iter1 = grouplist.iterator();        \n      \n        String groupname;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNodeWithClogin \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                nodeModel.put(\"devicename\", rn.getDeviceName());\n                nodeModel.put(\"status\", rn.getState());\n                nodeModel.put(\"devicetype\", rn.getDeviceType());\n                nodeModel.put(\"comment\", rn.getComment());\n                nodeModel.put(\"groupname\", groupname);\n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n                    \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","commit_id":"0082acc0e8bd23fb332e20084fd32d75faac7030","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","id":14609,"modified_method":"public InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","commit_id":"0082acc0e8bd23fb332e20084fd32d75faac7030","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","id":14610,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"0082acc0e8bd23fb332e20084fd32d75faac7030","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        model.put(\"iframelink\", iframelink);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","id":14611,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        String group = request.getParameter(\"group\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNodeBase(nodeid);\n        model.put(\"iframelink\", iframelink);\n        model.put(\"group\", group);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"0082acc0e8bd23fb332e20084fd32d75faac7030","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","id":14612,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        String group = request.getParameter(\"group\");\n        Map<String, Object> model;\n        if (group != null) {\n            model   = m_inventoryService.getRancidNodeWithCLoginForGroup(nodeid,WebSecurityUtils.sanitizeString(group),request.isUserInRole(Authentication.ADMIN_ROLE));\n        } else {\n            model   = m_inventoryService.getRancidNodeWithCLogin(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));            \n        }\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"a4833cef59e830e60b4ec6a648f9d753c69edd3d","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public Map<String, Object> getRancidNode(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNode start\");\n        Map<String, Object> nodeModel = new TreeMap<String, Object>();\n\n        \n        OnmsNode node = m_nodeDao.get(nodeid);\n        String rancidName = node.getLabel();\n        \n        String foreignSource = node.getForeignSource();\n        if (foreignSource != null ) {\n            nodeModel.put(\"permitModifyClogin\", false);\n            nodeModel.put(\"foreignSource\", foreignSource);\n        } else {\n            nodeModel.put(\"permitModifyClogin\", true);            \n        }\n\n        log().debug(\"getRancidNode: \" + rancidName);\n\n\n        nodeModel.put(\"id\", rancidName);\n        nodeModel.put(\"db_id\", nodeid);\n        nodeModel.put(\"status_general\", ElementUtil.getNodeStatusString(node.getType().charAt(0)));\n        \n        List<RancidNodeWrapper> ranlist = new ArrayList<RancidNodeWrapper>();\n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        Iterator<String> iter1 = grouplist.iterator();\n        \n      \n        String groupname;\n        boolean first = true;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNode \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                if (first){\n                    RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                    nodeModel.put(\"devicename\", rn.getDeviceName());\n                    nodeModel.put(\"status\", rn.getState());\n                    nodeModel.put(\"devicetype\", rn.getDeviceType());\n                    nodeModel.put(\"comment\", rn.getComment());\n                    nodeModel.put(\"groupname\", groupname);\n                    first = false;\n                } \n                RancidNode rn = RWSClientApi.getRWSRancidNodeInventory(m_cp ,groupname, rancidName);\n                String vs = rn.getHeadRevision();\n                InventoryNode in = (InventoryNode)rn.getNodeVersions().get(vs);\n\n                RancidNodeWrapper rnw = new RancidNodeWrapper(rn.getDeviceName(), groupname, rn.getDeviceType(), rn.getComment(), rn.getHeadRevision(),\n                  rn.getTotalRevisions(), in.getCreationDate(), rn.getRootConfigurationUrl());\n\n                ranlist.add(rnw); \n                \n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n            \n        //Groups invariant            \n        nodeModel.put(\"grouptable\", ranlist);\n        nodeModel.put(\"url\", m_cp.getUrl());\n        \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","id":14613,"modified_method":"public Map<String, Object> getRancidNodeWithCLogin(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNodeWithClogin start\");\n        Map<String, Object> nodeModel = getRancidNodeBase(nodeid);\n        String rancidName = (String)nodeModel.get(\"id\"); \n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        nodeModel.put(\"grouplist\",grouplist);\n        Iterator<String> iter1 = grouplist.iterator();        \n      \n        String groupname;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNodeWithClogin \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                nodeModel.put(\"devicename\", rn.getDeviceName());\n                nodeModel.put(\"status\", rn.getState());\n                nodeModel.put(\"devicetype\", rn.getDeviceType());\n                nodeModel.put(\"comment\", rn.getComment());\n                nodeModel.put(\"groupname\", groupname);\n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n                    \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","commit_id":"a4833cef59e830e60b4ec6a648f9d753c69edd3d","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","id":14614,"modified_method":"public InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","commit_id":"a4833cef59e830e60b4ec6a648f9d753c69edd3d","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","id":14615,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"a4833cef59e830e60b4ec6a648f9d753c69edd3d","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        model.put(\"iframelink\", iframelink);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","id":14616,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        String group = request.getParameter(\"group\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNodeBase(nodeid);\n        model.put(\"iframelink\", iframelink);\n        model.put(\"group\", group);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"a4833cef59e830e60b4ec6a648f9d753c69edd3d","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","id":14617,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n            \n        \n\n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        String group = request.getParameter(\"group\");\n        Map<String, Object> model;\n        if (group != null) {\n            model   = m_inventoryService.getRancidNodeWithCLoginForGroup(nodeid,WebSecurityUtils.sanitizeString(group),request.isUserInRole(Authentication.ADMIN_ROLE));\n        } else {\n            model   = m_inventoryService.getRancidNodeWithCLogin(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));            \n        }\n        ModelAndView modelAndView = new ModelAndView(\"admin/rancid/rancidAdmin\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"dc7bb071676fcd456852637c830f68dcb0f7dfe9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public Map<String, Object> getRancidNode(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNode start\");\n        Map<String, Object> nodeModel = new TreeMap<String, Object>();\n\n        \n        OnmsNode node = m_nodeDao.get(nodeid);\n        String rancidName = node.getLabel();\n        \n        String foreignSource = node.getForeignSource();\n        if (foreignSource != null ) {\n            nodeModel.put(\"permitModifyClogin\", false);\n            nodeModel.put(\"foreignSource\", foreignSource);\n        } else {\n            nodeModel.put(\"permitModifyClogin\", true);            \n        }\n\n        log().debug(\"getRancidNode: \" + rancidName);\n\n\n        nodeModel.put(\"id\", rancidName);\n        nodeModel.put(\"db_id\", nodeid);\n        nodeModel.put(\"status_general\", ElementUtil.getNodeStatusString(node.getType().charAt(0)));\n        \n        List<RancidNodeWrapper> ranlist = new ArrayList<RancidNodeWrapper>();\n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        Iterator<String> iter1 = grouplist.iterator();\n        \n      \n        String groupname;\n        boolean first = true;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNode \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                if (first){\n                    RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                    nodeModel.put(\"devicename\", rn.getDeviceName());\n                    nodeModel.put(\"status\", rn.getState());\n                    nodeModel.put(\"devicetype\", rn.getDeviceType());\n                    nodeModel.put(\"comment\", rn.getComment());\n                    nodeModel.put(\"groupname\", groupname);\n                    first = false;\n                } \n                RancidNode rn = RWSClientApi.getRWSRancidNodeInventory(m_cp ,groupname, rancidName);\n                String vs = rn.getHeadRevision();\n                InventoryNode in = (InventoryNode)rn.getNodeVersions().get(vs);\n\n                RancidNodeWrapper rnw = new RancidNodeWrapper(rn.getDeviceName(), groupname, rn.getDeviceType(), rn.getComment(), rn.getHeadRevision(),\n                  rn.getTotalRevisions(), in.getCreationDate(), rn.getRootConfigurationUrl());\n\n                ranlist.add(rnw); \n                \n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n            \n        //Groups invariant            \n        nodeModel.put(\"grouptable\", ranlist);\n        nodeModel.put(\"url\", m_cp.getUrl());\n        \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","id":14618,"modified_method":"public Map<String, Object> getRancidNodeWithCLogin(int nodeid, boolean adminRole) {\n        \n        log().debug(\"getRancidNodeWithClogin start\");\n        Map<String, Object> nodeModel = getRancidNodeBase(nodeid);\n        String rancidName = (String)nodeModel.get(\"id\"); \n        \n        // Group list \n        RWSResourceList groups;\n        try {\n            groups = RWSClientApi.getRWSResourceGroupsList(m_cp);\n        } catch (RancidApiException e1) {\n            log().error(e1.getLocalizedMessage());\n            return nodeModel;\n        }\n            \n        List<String> grouplist = groups.getResource();\n        nodeModel.put(\"grouplist\",grouplist);\n        Iterator<String> iter1 = grouplist.iterator();        \n      \n        String groupname;\n        while (iter1.hasNext()){\n            groupname = iter1.next();\n            log().debug(\"getRancidNodeWithClogin \" + rancidName + \" group \" + groupname);        \n            \n            try {\n                RancidNode rn = RWSClientApi.getRWSRancidNodeTLO(m_cp, groupname, rancidName);\n                nodeModel.put(\"devicename\", rn.getDeviceName());\n                nodeModel.put(\"status\", rn.getState());\n                nodeModel.put(\"devicetype\", rn.getDeviceType());\n                nodeModel.put(\"comment\", rn.getComment());\n                nodeModel.put(\"groupname\", groupname);\n            }\n            catch (RancidApiException e){\n                log().debug(\"No device found in router.db for:\" + rancidName + \"on Group: \" + groupname);\n            }\n        }\n                    \n        //CLOGIN\n        if (adminRole) {\n            log().debug(\"getRancidNode: getting clogin info for: \" + rancidName);        \n            RancidNodeAuthentication rn5;\n            try {\n                rn5 = RWSClientApi.getRWSAuthNode(m_cp,rancidName);\n                nodeModel.put(\"isadmin\", \"true\");\n                nodeModel.put(\"cloginuser\", rn5.getUser());\n                nodeModel.put(\"cloginpassword\", rn5.getPassword());\n                nodeModel.put(\"cloginconnmethod\", rn5.getConnectionMethodString());\n                nodeModel.put(\"cloginenablepass\", rn5.getEnablePass());\n                String autoen = \"0\";\n                if (rn5.isAutoEnable()){\n                    autoen = \"1\";\n                }\n                nodeModel.put(\"cloginautoenable\", autoen);\n            }catch (RancidApiException e){\n                log().error(\"getRancidNode: clogin get failed with reason: \" + e.getLocalizedMessage());\n            }\n        }\n        return nodeModel;\n    }","commit_id":"dc7bb071676fcd456852637c830f68dcb0f7dfe9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","id":14619,"modified_method":"public InventoryWrapper(String version, Date date, String group, String urlViewVC){\n        this.version = version;\n        this.date = date;\n        this.group = group;\n        this.urlViewVC = urlViewVC;\n    }","commit_id":"dc7bb071676fcd456852637c830f68dcb0f7dfe9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","id":14620,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancid\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"dc7bb071676fcd456852637c830f68dcb0f7dfe9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNode(nodeid,request.isUserInRole(Authentication.ADMIN_ROLE));\n        model.put(\"iframelink\", iframelink);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","id":14621,"modified_method":"public ModelAndView handleRequest(HttpServletRequest request,\n            HttpServletResponse arg1) throws Exception {\n       \n        String node = request.getParameter(\"node\");\n        String iframelink = request.getParameter(\"viewvc\");\n        String group = request.getParameter(\"group\");\n        int nodeid = WebSecurityUtils.safeParseInt(node);\n        Map<String, Object> model = m_inventoryService.getRancidNodeBase(nodeid);\n        model.put(\"iframelink\", iframelink);\n        model.put(\"group\", group);\n        ModelAndView modelAndView = new ModelAndView(\"inventory/rancidViewVc\",\"model\",model);\n        return modelAndView;\n    }","commit_id":"dc7bb071676fcd456852637c830f68dcb0f7dfe9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public Object extractBodyFromIrc(IrcExchange exchange, IrcMessage message) {\n        String type = message.getMessageType();\n        String text = message.getMessage();\n        if (text != null) {\n            return text;\n        } else {\n            return type;\n        }\n    }","id":14622,"modified_method":"public Object extractBodyFromIrc(Exchange exchange, IrcMessage message) {\n        String type = message.getMessageType();\n        String text = message.getMessage();\n        if (text != null) {\n            return text;\n        } else {\n            return type;\n        }\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onQuit(IRCUser user, String msg) {\n            if (configuration.isOnQuit()) {\n                IrcExchange exchange = endpoint.createOnQuitExchange(user, msg);\n                try {\n                    getProcessor().process(exchange);\n                } catch (Exception e) {\n                    handleException(e);\n                }\n            }\n        }","id":14623,"modified_method":"@Override\n        public void onQuit(IRCUser user, String msg) {\n            if (configuration.isOnQuit()) {\n                Exchange exchange = endpoint.createOnQuitExchange(user, msg);\n                try {\n                    getProcessor().process(exchange);\n                } catch (Exception e) {\n                    handleException(e);\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onPrivmsg(String target, IRCUser user, String msg) {\n            if (configuration.isOnPrivmsg()) {\n                if (target.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnPrivmsgExchange(target, user, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14624,"modified_method":"@Override\n        public void onPrivmsg(String target, IRCUser user, String msg) {\n            if (configuration.isOnPrivmsg()) {\n                if (target.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnPrivmsgExchange(target, user, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onNick(IRCUser user, String newNick) {\n            if (configuration.isOnNick()) {\n                IrcExchange exchange = endpoint.createOnNickExchange(user, newNick);\n                try {\n                    getProcessor().process(exchange);\n                } catch (Exception e) {\n                    handleException(e);\n                }\n            }\n        }","id":14625,"modified_method":"@Override\n        public void onNick(IRCUser user, String newNick) {\n            if (configuration.isOnNick()) {\n                Exchange exchange = endpoint.createOnNickExchange(user, newNick);\n                try {\n                    getProcessor().process(exchange);\n                } catch (Exception e) {\n                    handleException(e);\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onPart(String channel, IRCUser user, String msg) {\n            if (configuration.isOnPart()) {\n                if (channel.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnPartExchange(channel, user, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14626,"modified_method":"@Override\n        public void onPart(String channel, IRCUser user, String msg) {\n            if (configuration.isOnPart()) {\n                if (channel.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnPartExchange(channel, user, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onTopic(String channel, IRCUser user, String topic) {\n            if (configuration.isOnTopic()) {\n                if (channel.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnTopicExchange(channel, user, topic);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14627,"modified_method":"@Override\n        public void onTopic(String channel, IRCUser user, String topic) {\n            if (configuration.isOnTopic()) {\n                if (channel.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnTopicExchange(channel, user, topic);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onJoin(String channel, IRCUser user) {\n            if (configuration.isOnJoin()) {\n                if (channel.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnJoinExchange(channel, user);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14628,"modified_method":"@Override\n        public void onJoin(String channel, IRCUser user) {\n            if (configuration.isOnJoin()) {\n                if (channel.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnJoinExchange(channel, user);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onKick(String channel, IRCUser user, String passiveNick, String msg) {\n            if (configuration.isOnKick()) {\n                if (channel.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnKickExchange(channel, user, passiveNick, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14629,"modified_method":"@Override\n        public void onKick(String channel, IRCUser user, String passiveNick, String msg) {\n            if (configuration.isOnKick()) {\n                if (channel.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnKickExchange(channel, user, passiveNick, msg);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n        public void onMode(String channel, IRCUser user, IRCModeParser modeParser) {\n            if (configuration.isOnMode()) {\n                if (channel.equals(configuration.getTarget())) {\n                    IrcExchange exchange = endpoint.createOnModeExchange(channel, user, modeParser);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","id":14630,"modified_method":"@Override\n        public void onMode(String channel, IRCUser user, IRCModeParser modeParser) {\n            if (configuration.isOnMode()) {\n                if (channel.equals(configuration.getTarget())) {\n                    Exchange exchange = endpoint.createOnModeExchange(channel, user, modeParser);\n                    try {\n                        getProcessor().process(exchange);\n                    } catch (Exception e) {\n                        handleException(e);\n                    }\n                }\n            }\n        }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnKickExchange(String channel, IRCUser user, String whoWasKickedNick, String msg) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"KICK\", channel, user, whoWasKickedNick, msg));\n    }","id":14631,"modified_method":"public Exchange createOnKickExchange(String channel, IRCUser user, String whoWasKickedNick, String msg) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"KICK\", channel, user, whoWasKickedNick, msg));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnNickExchange(IRCUser user, String newNick) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"NICK\", user, newNick));\n    }","id":14632,"modified_method":"public Exchange createOnNickExchange(IRCUser user, String newNick) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"NICK\", user, newNick));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnJoinExchange(String channel, IRCUser user) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"JOIN\", channel, user));\n    }","id":14633,"modified_method":"public Exchange createOnJoinExchange(String channel, IRCUser user) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"JOIN\", channel, user));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnPrivmsgExchange(String target, IRCUser user, String msg) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"PRIVMSG\", target, user, msg));\n    }","id":14634,"modified_method":"public Exchange createOnPrivmsgExchange(String target, IRCUser user, String msg) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"PRIVMSG\", target, user, msg));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnPartExchange(String channel, IRCUser user, String msg) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"PART\", channel, user, msg));\n    }","id":14635,"modified_method":"public Exchange createOnPartExchange(String channel, IRCUser user, String msg) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"PART\", channel, user, msg));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnModeExchange(String channel, IRCUser user, IRCModeParser modeParser) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"MODE\", channel, user, modeParser.getLine()));\n    }","id":14636,"modified_method":"public Exchange createOnModeExchange(String channel, IRCUser user, IRCModeParser modeParser) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"MODE\", channel, user, modeParser.getLine()));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnQuitExchange(IRCUser user, String msg) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"QUIT\", user, msg));\n    }","id":14637,"modified_method":"public Exchange createOnQuitExchange(IRCUser user, String msg) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"QUIT\", user, msg));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public Exchange createExchange(ExchangePattern pattern) {\n        return new IrcExchange(this, pattern, getBinding());\n    }","id":14638,"modified_method":"public Exchange createExchange(ExchangePattern pattern) {\n        DefaultExchange exchange = new DefaultExchange(this, pattern);\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange createOnTopicExchange(String channel, IRCUser user, String topic) {\n        return new IrcExchange(this, getExchangePattern(), getBinding(), new IrcMessage(\"TOPIC\", channel, user, topic));\n    }","id":14639,"modified_method":"public Exchange createOnTopicExchange(String channel, IRCUser user, String topic) {\n        DefaultExchange exchange = new DefaultExchange(this, getExchangePattern());\n        exchange.setProperty(Exchange.BINDING, getBinding());\n        exchange.setIn(new IrcMessage(\"TOPIC\", channel, user, topic));\n        return exchange;\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public void setBinding(IrcBinding binding) {\n        this.binding = binding;\n    }","id":14640,"modified_method":"public void setBinding(IrcBinding binding) {\n        setProperty(Exchange.BINDING, binding);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange(IrcEndpoint endpoint, ExchangePattern pattern, IrcBinding binding) {\n        super(endpoint, pattern);\n        this.binding = binding;\n    }","id":14641,"modified_method":"public IrcExchange(IrcEndpoint endpoint, ExchangePattern pattern, IrcBinding binding) {\n        super(endpoint, pattern);\n        setProperty(Exchange.BINDING, binding);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange(DefaultExchange parent, IrcBinding binding) {\n        super(parent);\n        this.binding = binding;\n    }","id":14642,"modified_method":"public IrcExchange(DefaultExchange parent, IrcBinding binding) {\n        super(parent);\n        setProperty(Exchange.BINDING, binding);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcBinding getBinding() {\n        return binding;\n    }","id":14643,"modified_method":"public IrcBinding getBinding() {\n        return (IrcBinding)getProperty(Exchange.BINDING);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"public IrcExchange(IrcEndpoint endpoint, ExchangePattern pattern, IrcBinding binding, IrcMessage inMessage) {\n        this(endpoint, pattern, binding);\n        setIn(inMessage);\n    }","id":14644,"modified_method":"public IrcExchange(IrcEndpoint endpoint, ExchangePattern pattern, IrcBinding binding, IrcMessage inMessage) {\n        this(endpoint, pattern, binding);\n        setProperty(Exchange.BINDING, binding);\n        setIn(inMessage);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n    protected Object createBody() {\n        IrcExchange ircExchange = getExchange();\n        IrcBinding binding = ircExchange.getBinding();\n        return binding.extractBodyFromIrc(ircExchange, this);\n    }","id":14645,"modified_method":"@Override\n    protected Object createBody() {\n        Exchange exchange = getExchange();\n        IrcBinding binding = (IrcBinding)exchange.getProperty(Exchange.BINDING);\n        return binding.extractBodyFromIrc(exchange, this);\n    }","commit_id":"eb2cf9b92804ff6e4dff91f68f8807a54c71964c","url":"https://github.com/apache/camel"},{"original_method":"@Override\n  public void moveBlock(long userId, long blockId, BlockStoreLocation newLocation)\n      throws NotFoundException, AlreadyExistsException, InvalidStateException, OutOfSpaceException,\n      IOException {\n    int numRetries = 0;\n    while (numRetries < MAX_RETRIES) {\n      MoveBlockResult moveResult = moveBlockInternal(userId, blockId, newLocation);\n      if (moveResult.done()) {\n        synchronized (mBlockStoreEventListeners) {\n          for (BlockStoreEventListener listener : mBlockStoreEventListeners) {\n            listener.onMoveBlockByClient(userId, blockId, moveResult.srcLocation(),\n                moveResult.dstLocation());\n          }\n        }\n        return;\n      }\n      freeSpaceInternal(userId, moveResult.blockSize(), newLocation);\n      numRetries ++;\n    }\n    throw new OutOfSpaceException(\"Failed to moveBlock: blockId \" + blockId\n        + \" failed to find space in \" + newLocation + \" after \" + MAX_RETRIES + \" retries\");\n  }","id":14646,"modified_method":"@Override\n  public void moveBlock(long userId, long blockId, BlockStoreLocation newLocation)\n      throws NotFoundException, AlreadyExistsException, InvalidStateException, OutOfSpaceException,\n      IOException {\n    for (int i = 0; i < MAX_RETRIES + 1; i ++) {\n      MoveBlockResult moveResult = moveBlockInternal(userId, blockId, newLocation);\n      if (moveResult.done()) {\n        synchronized (mBlockStoreEventListeners) {\n          for (BlockStoreEventListener listener : mBlockStoreEventListeners) {\n            listener.onMoveBlockByClient(userId, blockId, moveResult.srcLocation(),\n                moveResult.dstLocation());\n          }\n        }\n        return;\n      }\n      if (i < MAX_RETRIES) {\n        freeSpaceInternal(userId, moveResult.blockSize(), newLocation);\n      }\n    }\n    throw new OutOfSpaceException(\"Failed to moveBlock: blockId \" + blockId\n        + \" failed to find space in \" + newLocation + \" after \" + MAX_RETRIES + \" retries\");\n  }","commit_id":"7c81b32fdc4c5bca2d8aa0cb653f4f8e36aa4d1d","url":"https://github.com/amplab/tachyon"},{"original_method":"@Override\n  public void requestSpace(long userId, long blockId, long additionalBytes)\n      throws NotFoundException, OutOfSpaceException, IOException {\n    int numRetries = 0;\n    while (numRetries < MAX_RETRIES) {\n      Pair<Boolean, BlockStoreLocation> requestResult =\n          requestSpaceInternal(blockId, additionalBytes);\n      if (requestResult.getFirst()) {\n        return;\n      }\n      freeSpaceInternal(userId, additionalBytes, requestResult.getSecond());\n      numRetries ++;\n    }\n    throw new OutOfSpaceException(\"Failed to requestSpace: blockId \" + blockId\n        + \" failed to allocate \" + additionalBytes + \" extra bytes after \" + MAX_RETRIES\n        + \" retries\");\n  }","id":14647,"modified_method":"@Override\n  public void requestSpace(long userId, long blockId, long additionalBytes)\n      throws NotFoundException, OutOfSpaceException, IOException {\n    for (int i = 0; i < MAX_RETRIES + 1; i ++) {\n      Pair<Boolean, BlockStoreLocation> requestResult =\n          requestSpaceInternal(blockId, additionalBytes);\n      if (requestResult.getFirst()) {\n        return;\n      }\n      if (i < MAX_RETRIES) {\n        freeSpaceInternal(userId, additionalBytes, requestResult.getSecond());\n      }\n    }\n    throw new OutOfSpaceException(\"Failed to requestSpace: blockId \" + blockId\n        + \" failed to allocate \" + additionalBytes + \" extra bytes after \" + MAX_RETRIES\n        + \" retries\");\n  }","commit_id":"7c81b32fdc4c5bca2d8aa0cb653f4f8e36aa4d1d","url":"https://github.com/amplab/tachyon"},{"original_method":"@Override\n  public TempBlockMeta createBlockMeta(long userId, long blockId, BlockStoreLocation location,\n      long initialBlockSize) throws AlreadyExistsException, OutOfSpaceException, NotFoundException,\n      IOException {\n    int numRetries = 0;\n    while (numRetries < MAX_RETRIES) {\n      TempBlockMeta tempBlockMeta =\n          createBlockMetaInternal(userId, blockId, location, initialBlockSize, true);\n      if (tempBlockMeta != null) {\n        return tempBlockMeta;\n      }\n      // Failed to allocate a temp block, so trigger Evictor to make some space.\n      // NOTE: Successful {@link freeSpaceInternal} here does not ensure the next try of allocation\n      // also successful, because these two operations are not atomic.\n      freeSpaceInternal(userId, initialBlockSize, location);\n      numRetries ++;\n    }\n    // TODO: we are probably seeing a rare transient failure, maybe define and throw some other\n    // types of exception to indicate this case.\n    throw new OutOfSpaceException(\"Failed to create blockMeta: blockId \" + blockId + \" \"\n        + \"failed to allocate \" + initialBlockSize + \" bytes after \" + MAX_RETRIES + \" retries\");\n  }","id":14648,"modified_method":"@Override\n  public TempBlockMeta createBlockMeta(long userId, long blockId, BlockStoreLocation location,\n      long initialBlockSize) throws AlreadyExistsException, OutOfSpaceException, NotFoundException,\n      IOException {\n    for (int i = 0; i < MAX_RETRIES + 1; i ++) {\n      TempBlockMeta tempBlockMeta =\n          createBlockMetaInternal(userId, blockId, location, initialBlockSize, true);\n      if (tempBlockMeta != null) {\n        return tempBlockMeta;\n      }\n      if (i < MAX_RETRIES) {\n        // Failed to create a temp block, so trigger Evictor to make some space.\n        // NOTE: a successful {@link freeSpaceInternal} here does not ensure the subsequent\n        // allocation also successful, because these two operations are not atomic.\n        freeSpaceInternal(userId, initialBlockSize, location);\n      }\n    }\n    // TODO: we are probably seeing a rare transient failure, maybe define and throw some other\n    // types of exception to indicate this case.\n    throw new OutOfSpaceException(\"Failed to create blockMeta: blockId \" + blockId + \" \"\n        + \"failed to allocate \" + initialBlockSize + \" bytes after \" + MAX_RETRIES + \" retries\");\n  }","commit_id":"7c81b32fdc4c5bca2d8aa0cb653f4f8e36aa4d1d","url":"https://github.com/amplab/tachyon"},{"original_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","id":14649,"modified_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = MapperParsingException.class)\n    public void testMultipleDocsEncryptedNotIgnoringErrors() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"),\n                ImmutableSettings.builder().put(\"index.mapping.attachment.ignore_errors\", false).build(),\n                new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                .field(\"_id\", 1)\n                .field(\"file1\", pdf)\n                .field(\"file2\", html)\n                .endObject().bytes();\n\n        Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()), nullValue());\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n    }","id":14650,"modified_method":"@Test(expected = MapperParsingException.class)\n    public void testMultipleDocsEncryptedNotIgnoringErrors() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"),\n                ImmutableSettings.builder().put(\"index.mapping.attachment.ignore_errors\", false).build(),\n                new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                .field(\"_id\", 1)\n                .field(\"file1\", pdf)\n                .field(\"file2\", html)\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()), nullValue());\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testMultipleDocsEncryptedFirst() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                .field(\"_id\", 1)\n                .field(\"file1\", pdf)\n                .field(\"file2\", html)\n                .endObject().bytes();\n\n        Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()), nullValue());\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n    }","id":14651,"modified_method":"@Test\n    public void testMultipleDocsEncryptedFirst() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                .field(\"_id\", 1)\n                .field(\"file1\", pdf)\n                .field(\"file2\", html)\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()), nullValue());\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testMultipleDocsEncryptedLast() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .field(\"_id\", 1)\n                    .field(\"file1\", html)\n                    .field(\"file2\", pdf)\n                .endObject().bytes();\n\n        Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()), nullValue());\n    }","id":14652,"modified_method":"@Test\n    public void testMultipleDocsEncryptedLast() throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .field(\"_id\", 1)\n                    .field(\"file1\", html)\n                    .field(\"file2\", pdf)\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file1.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file1.content_length\").mapper().names().indexName()).numericValue().longValue(), is(344L));\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.title\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.author\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.keywords\").mapper().names().indexName()), nullValue());\n        assertThat(doc.get(docMapper.mappers().smartName(\"file2.content_type\").mapper().names().indexName()), nullValue());\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file2.content_length\").mapper().names().indexName()), nullValue());\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected void checkMeta(String filename, Settings settings, Long expectedDate, Long expectedLength) throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), settings, new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/\" + filename);\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .field(\"_id\", 1)\n                    .startObject(\"file\")\n                        .field(\"_name\", filename)\n                        .field(\"content\", html)\n                    .endObject()\n                .endObject().bytes();\n\n        Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.name\").mapper().names().indexName()), equalTo(filename));\n        if (expectedDate == null) {\n            assertThat(doc.getField(docMapper.mappers().smartName(\"file.date\").mapper().names().indexName()), nullValue());\n        } else {\n            assertThat(doc.getField(docMapper.mappers().smartName(\"file.date\").mapper().names().indexName()).numericValue().longValue(), is(expectedDate));\n        }\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file.content_length\").mapper().names().indexName()).numericValue().longValue(), is(expectedLength));\n    }","id":14653,"modified_method":"protected void checkMeta(String filename, Settings settings, Long expectedDate, Long expectedLength) throws IOException {\n        DocumentMapperParser mapperParser = new DocumentMapperParser(new Index(\"test\"), settings, new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/\" + filename);\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .field(\"_id\", 1)\n                    .startObject(\"file\")\n                        .field(\"_name\", filename)\n                        .field(\"content\", html)\n                    .endObject()\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(json).rootDoc();\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"World\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.name\").mapper().names().indexName()), equalTo(filename));\n        if (expectedDate == null) {\n            assertThat(doc.getField(docMapper.mappers().smartName(\"file.date\").mapper().names().indexName()), nullValue());\n        } else {\n            assertThat(doc.getField(docMapper.mappers().smartName(\"file.date\").mapper().names().indexName()).numericValue().longValue(), is(expectedDate));\n        }\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"Hello\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.author\").mapper().names().indexName()), equalTo(\"kimchy\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.keywords\").mapper().names().indexName()), equalTo(\"elasticsearch,cool,bonsai\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"text/html; charset=ISO-8859-1\"));\n        assertThat(doc.getField(docMapper.mappers().smartName(\"file.content_length\").mapper().names().indexName()).numericValue().longValue(), is(expectedLength));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","id":14654,"modified_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * When we want to ignore errors (default)\n     */\n    @Test\n    public void testMultipleAttachmentsWithEncryptedDoc() throws Exception {\n        ignore_errors = true;\n        logger.info(\"creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file1\", html).field(\"file2\", pdf).field(\"hello\",\"world\").endObject());\n        refresh();\n\n        CountResponse countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file1\", \"World\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"hello\", \"World\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","id":14655,"modified_method":"/**\n     * When we want to ignore errors (default)\n     */\n    @Test\n    public void testMultipleAttachmentsWithEncryptedDoc() throws Exception {\n        ignore_errors = true;\n        logger.info(\"creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/multipledocs/test-mapping.json\");\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/htmlWithValidDateMeta.html\");\n        byte[] pdf = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/encrypted.pdf\");\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file1\", html).field(\"file2\", pdf).field(\"hello\",\"world\").endObject());\n        refresh();\n\n\n        CountResponse countResponse = client().prepareCount(\"test\").setQuery(queryString(\"World\").defaultField(\"file1\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().prepareCount(\"test\").setQuery(queryString(\"World\").defaultField(\"hello\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleAttachment() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testXHTML.html\");\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\", html).endObject());\n        refresh();\n\n        CountResponse countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file.title\", \"test document\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file\", \"tests the ability\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","id":14656,"modified_method":"@Test\n    public void testSimpleAttachment() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testXHTML.html\");\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\", html).endObject());\n        refresh();\n\n        CountResponse countResponse = client().prepareCount(\"test\").setQuery(queryString(\"test document\").defaultField(\"file.title\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().prepareCount(\"test\").setQuery(queryString(\"tests the ability\").defaultField(\"file\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleAttachmentContentLengthLimit() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] txt = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testContentLength.txt\");\n        final int CONTENT_LENGTH_LIMIT = 20;\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\").startObject().field(\"content\", txt).field(\"_indexed_chars\", CONTENT_LENGTH_LIMIT).endObject());\n        refresh();\n\n        CountResponse countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file\", \"BeforeLimit\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file\", \"AfterLimit\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(0l));\n    }","id":14657,"modified_method":"@Test\n    public void testSimpleAttachmentContentLengthLimit() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] txt = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testContentLength.txt\");\n        final int CONTENT_LENGTH_LIMIT = 20;\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\").startObject().field(\"content\", txt).field(\"_indexed_chars\", CONTENT_LENGTH_LIMIT).endObject());\n        refresh();\n\n        CountResponse countResponse = client().prepareCount(\"test\").setQuery(queryString(\"BeforeLimit\").defaultField(\"file\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().prepareCount(\"test\").setQuery(queryString(\"AfterLimit\").defaultField(\"file\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(0l));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleAttachmentNoContentLengthLimit() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] txt = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testContentLength.txt\");\n        final int CONTENT_LENGTH_LIMIT = -1;\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\").startObject().field(\"content\", txt).field(\"_indexed_chars\", CONTENT_LENGTH_LIMIT).endObject());\n        refresh();\n\n        CountResponse countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file\", \"Begin\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().count(countRequest(\"test\").query(fieldQuery(\"file\", \"End\"))).actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","id":14658,"modified_method":"@Test\n    public void testSimpleAttachmentNoContentLengthLimit() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        byte[] txt = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testContentLength.txt\");\n        final int CONTENT_LENGTH_LIMIT = -1;\n\n        client().admin().indices().putMapping(putMappingRequest(\"test\").type(\"person\").source(mapping)).actionGet();\n\n        index(\"test\", \"person\", jsonBuilder().startObject().field(\"file\").startObject().field(\"content\", txt).field(\"_indexed_chars\", CONTENT_LENGTH_LIMIT).endObject());\n        refresh();\n\n        CountResponse countResponse = client().prepareCount(\"test\").setQuery(queryString(\"Begin\").defaultField(\"file\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n        countResponse = client().prepareCount(\"test\").setQuery(queryString(\"End\").defaultField(\"file\")).execute().get();\n        assertThat(countResponse.getCount(), equalTo(1l));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleMappings() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testXHTML.html\");\n\n        BytesReference json = jsonBuilder().startObject().field(\"_id\", 1).field(\"file\", html).endObject().bytes();\n\n        Document doc = docMapper.parse(json).rootDoc();\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n\n        // re-parse it\n        String builtMapping = docMapper.mappingSource().string();\n        docMapper = mapperParser.parse(builtMapping);\n\n        json = jsonBuilder().startObject().field(\"_id\", 1).field(\"file\", html).endObject().bytes();\n\n        doc = docMapper.parse(json).rootDoc();\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n    }","id":14659,"modified_method":"@Test\n    public void testSimpleMappings() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/test-mapping.json\");\n        DocumentMapper docMapper = mapperParser.parse(mapping);\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/testXHTML.html\");\n\n        BytesReference json = jsonBuilder().startObject().field(\"_id\", 1).field(\"file\", html).endObject().bytes();\n\n        ParseContext.Document doc = docMapper.parse(json).rootDoc();\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n\n        // re-parse it\n        String builtMapping = docMapper.mappingSource().string();\n        docMapper = mapperParser.parse(builtMapping);\n\n        json = jsonBuilder().startObject().field(\"_id\", 1).field(\"file\", html).endObject().bytes();\n\n        doc = docMapper.parse(json).rootDoc();\n\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n        assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","id":14660,"modified_method":"@Before\n    public void setupMapperParser() {\n        mapperParser = new DocumentMapperParser(new Index(\"test\"), new AnalysisService(new Index(\"test\")), null, null, null);\n        mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n    }","commit_id":"b877f1bd4f67fbbfcd46837bbaa5abb7c14460b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        this(from, verb);\n        details_ = details;\n    }","id":14661,"modified_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n        details_ = ImmutableMap.copyOf(details);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n    }","id":14662,"modified_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        this(from, verb, Collections.<String, byte[]>emptyMap());\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"void setDetail(String key, byte[] value)\n    {\n        details_.put(key, value);\n    }","id":14663,"modified_method":"Header withDetailsAdded(String key, byte[] value)\n    {\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.put(key, value);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"void removeDetail(String key)\n    {\n        details_.remove(key);\n    }","id":14664,"modified_method":"Header withDetailsRemoved(String key)\n    {\n        if (!details_.containsKey(key))\n            return this;\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.remove(key);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"public void setHeader(String key, byte[] value)\n    {\n        header_.setDetail(key, value);\n    }","id":14665,"modified_method":"public Message withHeaderAdded(String key, byte[] value)\n    {\n        return new Message(header_.withDetailsAdded(key, value), body_, version);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"public void removeHeader(String key)\n    {\n        header_.removeDetail(key);\n    }","id":14666,"modified_method":"public Message withHeaderRemoved(String key)\n    {\n        return new Message(header_.withDetailsRemoved(key), body_, version);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        message.removeHeader(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getLocalAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(message, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","id":14667,"modified_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        Message messageCopy = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getLocalAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(messageCopy, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message.removeHeader(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        // group all nodes in this DC as forward headers on the primary message\n                        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n                        DataOutputStream dos = new DataOutputStream(bos);\n\n                        // append to older addresses\n                        byte[] previousHints = message.getHeader(RowMutation.FORWARD_HEADER);\n                        if (previousHints != null)\n                            dos.write(previousHints);\n\n                        dos.write(destination.getAddress());\n                        message.setHeader(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    }\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","id":14668,"modified_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n                    DataOutputStream dos = new DataOutputStream(bos);\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        dos.write(destination.getAddress());\n                    }\n                    message = message.withHeaderAdded(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"public static void sendToHintedEndpoints(final RowMutation rm, Multimap<InetAddress, InetAddress> hintedEndpoints, IWriteResponseHandler responseHandler, String localDataCenter, ConsistencyLevel consistency_level)\n    throws IOException\n    {\n        // Multimap that holds onto all the messages and addresses meant for a specific datacenter\n        Map<String, Multimap<Message, InetAddress>> dcMessages = new HashMap<String, Multimap<Message, InetAddress>>(hintedEndpoints.size());\n        MessageProducer producer = new CachingMessageProducer(rm);\n\n        for (Map.Entry<InetAddress, Collection<InetAddress>> entry : hintedEndpoints.asMap().entrySet())\n        {\n            InetAddress destination = entry.getKey();\n            Collection<InetAddress> targets = entry.getValue();\n\n            String dc = DatabaseDescriptor.getEndpointSnitch().getDatacenter(destination);\n\n            if (targets.size() == 1 && targets.iterator().next().equals(destination))\n            {\n                // unhinted writes\n                if (destination.equals(FBUtilities.getLocalAddress()))\n                {\n                    insertLocal(rm, responseHandler);\n                }\n                else\n                {\n                    // belongs on a different server\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"insert writing key \" + ByteBufferUtil.bytesToHex(rm.key()) + \" to \" + destination);\n\n                    Multimap<Message, InetAddress> messages = dcMessages.get(dc);\n                    if (messages == null)\n                    {\n                       messages = HashMultimap.create();\n                       dcMessages.put(dc, messages);\n                    }\n\n                    messages.put(producer.getMessage(Gossiper.instance.getVersion(destination)), destination);\n                }\n            }\n            else\n            {\n                // hinted messages are unique, so there is no point to adding a hop by forwarding via another node.\n                // thus, we use sendRR/sendOneWay directly here.\n                Message hintedMessage = rm.getMessage(Gossiper.instance.getVersion(destination));\n                for (InetAddress target : targets)\n                {\n                    if (!target.equals(destination))\n                    {\n                        addHintHeader(hintedMessage, target);\n                        if (logger.isDebugEnabled())\n                            logger.debug(\"insert writing key \" + ByteBufferUtil.bytesToHex(rm.key()) + \" to \" + destination + \" for \" + target);\n                    }\n                }\n                // non-destination hints are part of the callback and count towards consistency only under CL.ANY\n                if (targets.contains(destination) || consistency_level == ConsistencyLevel.ANY)\n                    MessagingService.instance().sendRR(hintedMessage, destination, responseHandler);\n                else\n                    MessagingService.instance().sendOneWay(hintedMessage, destination);\n            }\n        }\n        sendMessages(localDataCenter, dcMessages, responseHandler);\n    }","id":14669,"modified_method":"public static void sendToHintedEndpoints(final RowMutation rm, Multimap<InetAddress, InetAddress> hintedEndpoints, IWriteResponseHandler responseHandler, String localDataCenter, ConsistencyLevel consistency_level)\n    throws IOException\n    {\n        // Multimap that holds onto all the messages and addresses meant for a specific datacenter\n        Map<String, Multimap<Message, InetAddress>> dcMessages = new HashMap<String, Multimap<Message, InetAddress>>(hintedEndpoints.size());\n        MessageProducer producer = new CachingMessageProducer(rm);\n\n        for (Map.Entry<InetAddress, Collection<InetAddress>> entry : hintedEndpoints.asMap().entrySet())\n        {\n            InetAddress destination = entry.getKey();\n            Collection<InetAddress> targets = entry.getValue();\n\n            String dc = DatabaseDescriptor.getEndpointSnitch().getDatacenter(destination);\n\n            if (targets.size() == 1 && targets.iterator().next().equals(destination))\n            {\n                // unhinted writes\n                if (destination.equals(FBUtilities.getLocalAddress()))\n                {\n                    insertLocal(rm, responseHandler);\n                }\n                else\n                {\n                    // belongs on a different server\n                    if (logger.isDebugEnabled())\n                        logger.debug(\"insert writing key \" + ByteBufferUtil.bytesToHex(rm.key()) + \" to \" + destination);\n\n                    Multimap<Message, InetAddress> messages = dcMessages.get(dc);\n                    if (messages == null)\n                    {\n                       messages = HashMultimap.create();\n                       dcMessages.put(dc, messages);\n                    }\n\n                    messages.put(producer.getMessage(Gossiper.instance.getVersion(destination)), destination);\n                }\n            }\n            else\n            {\n                // hinted messages are unique, so there is no point to adding a hop by forwarding via another node.\n                // thus, we use sendRR/sendOneWay directly here.\n                Message hintedMessage = rm.getMessage(Gossiper.instance.getVersion(destination));\n                for (InetAddress target : targets)\n                {\n                    if (!target.equals(destination))\n                    {\n                        hintedMessage = addHintHeader(hintedMessage, target);\n                        if (logger.isDebugEnabled())\n                            logger.debug(\"insert writing key \" + ByteBufferUtil.bytesToHex(rm.key()) + \" to \" + destination + \" for \" + target);\n                    }\n                }\n                // non-destination hints are part of the callback and count towards consistency only under CL.ANY\n                if (targets.contains(destination) || consistency_level == ConsistencyLevel.ANY)\n                    MessagingService.instance().sendRR(hintedMessage, destination, responseHandler);\n                else\n                    MessagingService.instance().sendOneWay(hintedMessage, destination);\n            }\n        }\n        sendMessages(localDataCenter, dcMessages, responseHandler);\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"private static void addHintHeader(Message message, InetAddress target) throws IOException\n    {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        DataOutputStream dos = new DataOutputStream(bos);\n        byte[] previousHints = message.getHeader(RowMutation.HINT);\n        if (previousHints != null)\n        {\n            dos.write(previousHints);\n        }\n        ByteBufferUtil.writeWithShortLength(ByteBufferUtil.bytes(target.getHostAddress()), dos);\n        message.setHeader(RowMutation.HINT, bos.toByteArray());\n    }","id":14670,"modified_method":"private static Message addHintHeader(Message message, InetAddress target) throws IOException\n    {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        DataOutputStream dos = new DataOutputStream(bos);\n        byte[] previousHints = message.getHeader(RowMutation.HINT);\n        if (previousHints != null)\n        {\n            dos.write(previousHints);\n        }\n        ByteBufferUtil.writeWithShortLength(ByteBufferUtil.bytes(target.getHostAddress()), dos);\n        return message.withHeaderAdded(RowMutation.HINT, bos.toByteArray());\n    }","commit_id":"d655e7868f8521d726cf6a854c13a41a61341a1a","url":"https://github.com/apache/cassandra"},{"original_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n    }","id":14671,"modified_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        this(from, verb, Collections.<String, byte[]>emptyMap());\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"void removeDetail(String key)\n    {\n        details_.remove(key);\n    }","id":14672,"modified_method":"Header withDetailsRemoved(String key)\n    {\n        if (!details_.containsKey(key))\n            return this;\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.remove(key);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"void setDetail(String key, byte[] value)\n    {\n        details_.put(key, value);\n    }","id":14673,"modified_method":"Header withDetailsAdded(String key, byte[] value)\n    {\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.put(key, value);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        this(from, verb);\n        details_ = details;\n    }","id":14674,"modified_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n        details_ = ImmutableMap.copyOf(details);\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"public void removeHeader(String key)\n    {\n        header_.removeDetail(key);\n    }","id":14675,"modified_method":"public Message withHeaderRemoved(String key)\n    {\n        return new Message(header_.withDetailsRemoved(key), body_, version);\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"public void setHeader(String key, byte[] value)\n    {\n        header_.setDetail(key, value);\n    }","id":14676,"modified_method":"public Message withHeaderAdded(String key, byte[] value)\n    {\n        return new Message(header_.withDetailsAdded(key, value), body_, version);\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"private void writeConnected(Message message, String id)\n    {\n        try\n        {\n            write(message, id, out);\n            if (queue.peek() == null)\n            {\n                out.flush();\n            }\n        }\n        catch (IOException e)\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"error writing to \" + poolReference.endPoint(), e);\n            disconnect();\n        }\n    }","id":14677,"modified_method":"private void writeConnected(Message message, String id)\n    {\n        try\n        {\n            write(message, id, out);\n            if (queue.peek() == null)\n            {\n                out.flush();\n            }\n        }\n        catch (Exception e)\n        {\n            // Non IO exceptions is likely a programming error so let's not silence it\n            if (!(e instanceof IOException))\n                logger.error(\"error writing to \" + poolReference.endPoint(), e);\n            else if (logger.isDebugEnabled())\n                logger.debug(\"error writing to \" + poolReference.endPoint(), e);\n            disconnect();\n        }\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        message.removeHeader(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getBroadcastAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(message, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","id":14678,"modified_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        Message messageCopy = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getBroadcastAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(messageCopy, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message.removeHeader(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        // group all nodes in this DC as forward headers on the primary message\n                        FastByteArrayOutputStream bos = new FastByteArrayOutputStream();\n                        DataOutputStream dos = new DataOutputStream(bos);\n\n                        // append to older addresses\n                        byte[] previousHints = message.getHeader(RowMutation.FORWARD_HEADER);\n                        if (previousHints != null)\n                            dos.write(previousHints);\n\n                        dos.write(destination.getAddress());\n                        message.setHeader(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    }\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","id":14679,"modified_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    FastByteArrayOutputStream bos = new FastByteArrayOutputStream();\n                    DataOutputStream dos = new DataOutputStream(bos);\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        dos.write(destination.getAddress());\n                    }\n                    message = message.withHeaderAdded(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","commit_id":"789aa15fc1990643a1162e0ac93f1487446328db","url":"https://github.com/apache/cassandra"},{"original_method":"void setDetail(String key, byte[] value)\n    {\n        details_.put(key, value);\n    }","id":14680,"modified_method":"Header withDetailsAdded(String key, byte[] value)\n    {\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.put(key, value);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n    }","id":14681,"modified_method":"Header(InetAddress from, StorageService.Verb verb)\n    {\n        this(from, verb, Collections.<String, byte[]>emptyMap());\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"void removeDetail(String key)\n    {\n        details_.remove(key);\n    }","id":14682,"modified_method":"Header withDetailsRemoved(String key)\n    {\n        if (!details_.containsKey(key))\n            return this;\n        Map<String, byte[]> detailsCopy = Maps.newHashMap(details_);\n        detailsCopy.remove(key);\n        return new Header(from_, verb_, detailsCopy);\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        this(from, verb);\n        details_ = details;\n    }","id":14683,"modified_method":"Header(InetAddress from, StorageService.Verb verb, Map<String, byte[]> details)\n    {\n        assert from != null;\n        assert verb != null;\n\n        from_ = from;\n        verb_ = verb;\n        details_ = ImmutableMap.copyOf(details);\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"public void setHeader(String key, byte[] value)\n    {\n        header_.setDetail(key, value);\n    }","id":14684,"modified_method":"public Message withHeaderAdded(String key, byte[] value)\n    {\n        return new Message(header_.withDetailsAdded(key, value), body_, version);\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"public void removeHeader(String key)\n    {\n        header_.removeDetail(key);\n    }","id":14685,"modified_method":"public Message withHeaderRemoved(String key)\n    {\n        return new Message(header_.withDetailsRemoved(key), body_, version);\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"private void writeConnected(Message message, String id)\n    {\n        try\n        {\n            write(message, id, out);\n            completed++;\n            if (active.peek() == null)\n            {\n                out.flush();\n            }\n        }\n        catch (IOException e)\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"error writing to \" + poolReference.endPoint(), e);\n            disconnect();\n        }\n    }","id":14686,"modified_method":"private void writeConnected(Message message, String id)\n    {\n        try\n        {\n            write(message, id, out);\n            completed++;\n            if (active.peek() == null)\n            {\n                out.flush();\n            }\n        }\n        catch (Exception e)\n        {\n            // Non IO exceptions is likely a programming error so let's not silence it\n            if (!(e instanceof IOException))\n                logger.error(\"error writing to \" + poolReference.endPoint(), e);\n            else if (logger.isDebugEnabled())\n                logger.debug(\"error writing to \" + poolReference.endPoint(), e);\n            disconnect();\n        }\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        message.removeHeader(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getBroadcastAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(message, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","id":14687,"modified_method":"private void forwardToLocalNodes(Message message, byte[] forwardBytes) throws UnknownHostException\n    {\n        // remove fwds from message to avoid infinite loop\n        Message messageCopy = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n        int bytesPerInetAddress = FBUtilities.getBroadcastAddress().getAddress().length;\n        assert forwardBytes.length >= bytesPerInetAddress;\n        assert forwardBytes.length % bytesPerInetAddress == 0;\n\n        int offset = 0;\n        byte[] addressBytes = new byte[bytesPerInetAddress];\n\n        // Send a message to each of the addresses on our Forward List\n        while (offset < forwardBytes.length)\n        {\n            System.arraycopy(forwardBytes, offset, addressBytes, 0, bytesPerInetAddress);\n            InetAddress address = InetAddress.getByAddress(addressBytes);\n\n            if (logger_.isDebugEnabled())\n                logger_.debug(\"Forwarding message to \" + address);\n\n            // Send the original message to the address specified by the FORWARD_HINT\n            // Let the response go back to the coordinator\n            MessagingService.instance().sendOneWay(messageCopy, address);\n\n            offset += bytesPerInetAddress;\n        }\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message.removeHeader(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        // group all nodes in this DC as forward headers on the primary message\n                        FastByteArrayOutputStream bos = new FastByteArrayOutputStream();\n                        DataOutputStream dos = new DataOutputStream(bos);\n\n                        // append to older addresses\n                        byte[] previousHints = message.getHeader(RowMutation.FORWARD_HEADER);\n                        if (previousHints != null)\n                            dos.write(previousHints);\n\n                        dos.write(destination.getAddress());\n                        message.setHeader(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    }\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","id":14688,"modified_method":"/**\n     * for each datacenter, send a message to one node to relay the write to other replicas\n     */\n    private static void sendMessages(String localDataCenter, Map<String, Multimap<Message, InetAddress>> dcMessages, IWriteResponseHandler handler)\n    throws IOException\n    {\n        for (Map.Entry<String, Multimap<Message, InetAddress>> entry: dcMessages.entrySet())\n        {\n            String dataCenter = entry.getKey();\n\n            // send the messages corresponding to this datacenter\n            for (Map.Entry<Message, Collection<InetAddress>> messages: entry.getValue().asMap().entrySet())\n            {\n                Message message = messages.getKey();\n                // a single message object is used for unhinted writes, so clean out any forwards\n                // from previous loop iterations\n                message = message.withHeaderRemoved(RowMutation.FORWARD_HEADER);\n\n                if (dataCenter.equals(localDataCenter))\n                {\n                    // direct writes to local DC or old Cassadra versions\n                    for (InetAddress destination : messages.getValue())\n                        MessagingService.instance().sendRR(message, destination, handler);\n                }\n                else\n                {\n                    // Non-local DC. First endpoint in list is the destination for this group\n                    Iterator<InetAddress> iter = messages.getValue().iterator();\n                    InetAddress target = iter.next();\n                    // Add all the other destinations of the same message as a header in the primary message.\n                    FastByteArrayOutputStream bos = new FastByteArrayOutputStream();\n                    DataOutputStream dos = new DataOutputStream(bos);\n                    while (iter.hasNext())\n                    {\n                        InetAddress destination = iter.next();\n                        dos.write(destination.getAddress());\n                    }\n                    message = message.withHeaderAdded(RowMutation.FORWARD_HEADER, bos.toByteArray());\n                    // send the combined message + forward headers\n                    MessagingService.instance().sendRR(message, target, handler);\n                }\n            }\n        }\n    }","commit_id":"b1e6799d3b8bf3d8047e913924451628eaad74dd","url":"https://github.com/apache/cassandra"},{"original_method":"public void updateExternalAssessmentScore(final String gradebookUid, final String externalId, final String studentUid, final String points) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException\n\t{\n\t\tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n\t\tif(asn == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\n\t\tif (logData.isDebugEnabled()) logData.debug(\"BEGIN: Update 1 score for gradebookUid=\" + gradebookUid + \", external assessment=\" + externalId + \" from \" + asn.getExternalAppName());\n\n\t\tHibernateCallback hc = new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tDate now = new Date();\n\n\t\t\t\tAssignmentGradeRecord agr = getAssignmentGradeRecord(asn, studentUid, session);\n\n\t\t\t\t// Try to reduce data contention by only updating when the\n\t\t\t\t// score has actually changed or property has been set forcing a db update every time.\n                boolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n                \n\t\t\t\t//TODO: for ungraded items, needs to set ungraded-grades later...\n\t\t\t\tDouble oldPointsEarned = (agr == null) ? null : agr.getPointsEarned();\n\t\t\t\tDouble newPointsEarned = (points == null) ? null : convertStringToDouble(points); \n\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) ||\n\t\t\t\t\t\t(newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\tif (agr == null) {\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr = new AssignmentGradeRecord(asn, studentUid, Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr = new AssignmentGradeRecord(asn, studentUid, null);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr.setPointsEarned(Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr.setPointsEarned(null);\n\t\t\t\t\t}\n\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(getUserUid());\n\t\t\t\t\tif (log.isDebugEnabled()) log.debug(\"About to save AssignmentGradeRecord id=\" + agr.getId() + \", version=\" + agr.getVersion() + \", studenttId=\" + agr.getStudentId() + \", pointsEarned=\" + agr.getPointsEarned());\n\t\t\t\t\tsession.saveOrUpdate(agr);\n\n\t\t\t\t\t// Sync database.\n\t\t\t\t\tsession.flush();\n\t\t\t\t\tsession.clear();\n            \t\tpostUpdateGradeEvent(gradebookUid, asn.getName(), studentUid, newPointsEarned);\n\t\t\t\t} else {\n\t\t\t\t\tif(log.isDebugEnabled()) log.debug(\"Ignoring updateExternalAssessmentScore, since the new points value is the same as the old\");\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t};\n\t\tgetHibernateTemplate().execute(hc);\n\t\tif (logData.isDebugEnabled()) logData.debug(\"END: Update 1 score for gradebookUid=\" + gradebookUid + \", external assessment=\" + externalId + \" from \" + asn.getExternalAppName());\n\t\tif (log.isDebugEnabled()) log.debug(\"External assessment score updated in gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid() + \", new score=\" + points);\n\t}","id":14689,"modified_method":"public void updateExternalAssessmentScore(final String gradebookUid, final String externalId, final String studentUid, final String points) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException\n\t{\n\t\tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n\t\tif(asn == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\n\t\tlog.debug(\"BEGIN: Update 1 score for gradebookUid={}, external assessment={} from {}\", gradebookUid, externalId, asn.getExternalAppName());\n\n\t\tHibernateCallback hc = new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tDate now = new Date();\n\n\t\t\t\tAssignmentGradeRecord agr = getAssignmentGradeRecord(asn, studentUid, session);\n\n\t\t\t\t// Try to reduce data contention by only updating when the\n\t\t\t\t// score has actually changed or property has been set forcing a db update every time.\n                boolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n                \n\t\t\t\t//TODO: for ungraded items, needs to set ungraded-grades later...\n\t\t\t\tDouble oldPointsEarned = (agr == null) ? null : agr.getPointsEarned();\n\t\t\t\tDouble newPointsEarned = (points == null) ? null : convertStringToDouble(points); \n\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) ||\n\t\t\t\t\t\t(newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\tif (agr == null) {\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr = new AssignmentGradeRecord(asn, studentUid, Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr = new AssignmentGradeRecord(asn, studentUid, null);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr.setPointsEarned(Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr.setPointsEarned(null);\n\t\t\t\t\t}\n\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(getUserUid());\n\t\t\t\t\tlog.debug(\"About to save AssignmentGradeRecord id={}, version={}, studenttId={}, pointsEarned={}\", agr.getId(), agr.getVersion(), agr.getStudentId(), agr.getPointsEarned());\n\t\t\t\t\tsession.saveOrUpdate(agr);\n\n\t\t\t\t\t// Sync database.\n\t\t\t\t\tsession.flush();\n\t\t\t\t\tsession.clear();\n            \t\tpostUpdateGradeEvent(gradebookUid, asn.getName(), studentUid, newPointsEarned);\n\t\t\t\t} else {\n\t\t\t\t\tlog.debug(\"Ignoring updateExternalAssessmentScore, since the new points value is the same as the old\");\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t};\n\t\tgetHibernateTemplate().execute(hc);\n\t\tlog.debug(\"END: Update 1 score for gradebookUid={}, external assessment={} from {}\", gradebookUid, externalId, asn.getExternalAppName());\n\t\tlog.debug(\"External assessment score updated in gradebookUid={}, externalId={} by userUid={}, new score={}\", gradebookUid, externalId, getUserUid(), points);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void updateExternalAssessmentScores(final String gradebookUid, final String externalId, final Map<String, Double> studentUidsToScores)\n\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\n      final Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n      if (assignment == null) {\n          throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n      }\n\tfinal Set studentIds = studentUidsToScores.keySet();\n\tif (studentIds.isEmpty()) {\n\t\treturn;\n\t}\n\tfinal Date now = new Date();\n\tfinal String graderId = getUserUid();\n\n\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\tList existingScores;\n\t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n\t\t\t\texistingScores = q.list();\n\t\t\t} else {\n\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n\t\t\t}\n\n\t\t\tSet previouslyUnscoredStudents = new HashSet(studentIds);\n\t\t\tSet changedStudents = new HashSet();\n\t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n\t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n\t\t\t\tString studentUid = agr.getStudentId();\n\t\t\t\tpreviouslyUnscoredStudents.remove(studentUid);\n\n\t\t\t\t// Try to reduce data contention by only updating when a score\n\t\t\t\t// has changed or property has been set forcing a db update every time.\n\t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\t\t\t\t\n\t\t\t\tDouble oldPointsEarned = agr.getPointsEarned();\n\t\t\t\tDouble newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) || (newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\tagr.setPointsEarned(newPointsEarned);\n\t\t\t\t\tsession.update(agr);\n\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (Iterator iter = previouslyUnscoredStudents.iterator(); iter.hasNext(); ) {\n\t\t\t\tString studentUid = (String)iter.next();\n\n\t\t\t\t// Don't save unnecessary null scores.\n\t\t\t\tDouble newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\tif (newPointsEarned != null) {\n\t\t\t\t\tAssignmentGradeRecord agr = new AssignmentGradeRecord(assignment, studentUid, newPointsEarned);\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\tsession.save(agr);\n\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (log.isDebugEnabled()) log.debug(\"updateExternalAssessmentScores sent \" + studentIds.size() + \" records, actually changed \" + changedStudents.size());\n\n\t\t\t// Sync database.\n\t\t\tsession.flush();\n\t\t\tsession.clear();\n              return null;\n          }\n      });\n\t}","id":14690,"modified_method":"public void updateExternalAssessmentScores(final String gradebookUid, final String externalId, final Map<String, Double> studentUidsToScores)\n\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\n      final Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n      if (assignment == null) {\n          throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n      }\n\tfinal Set studentIds = studentUidsToScores.keySet();\n\tif (studentIds.isEmpty()) {\n\t\treturn;\n\t}\n\tfinal Date now = new Date();\n\tfinal String graderId = getUserUid();\n\n\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\tList existingScores;\n\t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n\t\t\t\texistingScores = q.list();\n\t\t\t} else {\n\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n\t\t\t}\n\n\t\t\tSet previouslyUnscoredStudents = new HashSet(studentIds);\n\t\t\tSet changedStudents = new HashSet();\n\t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n\t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n\t\t\t\tString studentUid = agr.getStudentId();\n\t\t\t\tpreviouslyUnscoredStudents.remove(studentUid);\n\n\t\t\t\t// Try to reduce data contention by only updating when a score\n\t\t\t\t// has changed or property has been set forcing a db update every time.\n\t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\t\t\t\t\n\t\t\t\tDouble oldPointsEarned = agr.getPointsEarned();\n\t\t\t\tDouble newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) || (newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\tagr.setPointsEarned(newPointsEarned);\n\t\t\t\t\tsession.update(agr);\n\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (Iterator iter = previouslyUnscoredStudents.iterator(); iter.hasNext(); ) {\n\t\t\t\tString studentUid = (String)iter.next();\n\n\t\t\t\t// Don't save unnecessary null scores.\n\t\t\t\tDouble newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\tif (newPointsEarned != null) {\n\t\t\t\t\tAssignmentGradeRecord agr = new AssignmentGradeRecord(assignment, studentUid, newPointsEarned);\n\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\tsession.save(agr);\n\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlog.debug(\"updateExternalAssessmentScores sent {} records, actually changed {}\", studentIds.size() ,changedStudents.size());\n\n\t\t\t// Sync database.\n\t\t\tsession.flush();\n\t\t\tsession.clear();\n              return null;\n          }\n      });\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void updateExternalAssessmentScoresString(final String gradebookUid, final String externalId, final Map<String, String> studentUidsToScores)\n\t\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\n\t\tfinal Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n\t\tif (assignment == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\t\tfinal Set studentIds = studentUidsToScores.keySet();\n\t\tif (studentIds.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\tfinal Date now = new Date();\n\t\tfinal String graderId = getUserUid();\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tList existingScores;\n\t\t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n\t\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n\t\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n\t\t\t\t\texistingScores = q.list();\n\t\t\t\t} else {\n\t\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n\t\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n\t\t\t\t}\n\n\t\t\t\tSet previouslyUnscoredStudents = new HashSet(studentIds);\n\t\t\t\tSet changedStudents = new HashSet();\n\t\t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n\t\t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n\t\t\t\t\tString studentUid = agr.getStudentId();\n\t\t\t\t\tpreviouslyUnscoredStudents.remove(studentUid);\n\n\t\t\t\t\t// Try to reduce data contention by only updating when a score\n\t\t\t\t\t// has changed or property has been set forcing a db update every time.\n\t                boolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\t\t\t\t\t\n\t                //TODO: for ungraded items, needs to set ungraded-grades later...\n\t\t\t\t\tDouble oldPointsEarned = agr.getPointsEarned();\n\t\t\t\t\t//Double newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\t\tString newPointsEarnedString = (String)studentUidsToScores.get(studentUid);\n\t\t\t\t\tDouble newPointsEarned = (newPointsEarnedString == null) ? null : convertStringToDouble(newPointsEarnedString); \n\t\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) || (newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr.setPointsEarned(Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr.setPointsEarned(null);\n\t\t\t\t\t\tsession.update(agr);\n\t\t\t\t\t\tchangedStudents.add(studentUid);\n                \t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfor (Iterator iter = previouslyUnscoredStudents.iterator(); iter.hasNext(); ) {\n\t\t\t\t\tString studentUid = (String)iter.next();\n\n\t\t\t\t\t// Don't save unnecessary null scores.\n\t\t\t\t\tString newPointsEarned = (String)studentUidsToScores.get(studentUid);\n\t\t\t\t\tif (newPointsEarned != null) {\n\t\t\t\t\t\tAssignmentGradeRecord agr = new AssignmentGradeRecord(assignment, studentUid, convertStringToDouble(newPointsEarned));\n\t\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\t\tsession.save(agr);\n\t\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, convertStringToDouble(newPointsEarned));\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (log.isDebugEnabled()) log.debug(\"updateExternalAssessmentScores sent \" + studentIds.size() + \" records, actually changed \" + changedStudents.size());\n\n\t\t\t\t// Sync database.\n\t\t\t\tsession.flush();\n\t\t\t\tsession.clear();\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n\t}","id":14691,"modified_method":"public void updateExternalAssessmentScoresString(final String gradebookUid, final String externalId, final Map<String, String> studentUidsToScores)\n\t\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\n\t\tfinal Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n\t\tif (assignment == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\t\tfinal Set studentIds = studentUidsToScores.keySet();\n\t\tif (studentIds.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\tfinal Date now = new Date();\n\t\tfinal String graderId = getUserUid();\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tList existingScores;\n\t\t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n\t\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n\t\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n\t\t\t\t\texistingScores = q.list();\n\t\t\t\t} else {\n\t\t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n\t\t\t\t\tq.setParameter(\"go\", assignment);\n\t\t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n\t\t\t\t}\n\n\t\t\t\tSet previouslyUnscoredStudents = new HashSet(studentIds);\n\t\t\t\tSet changedStudents = new HashSet();\n\t\t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n\t\t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n\t\t\t\t\tString studentUid = agr.getStudentId();\n\t\t\t\t\tpreviouslyUnscoredStudents.remove(studentUid);\n\n\t\t\t\t\t// Try to reduce data contention by only updating when a score\n\t\t\t\t\t// has changed or property has been set forcing a db update every time.\n\t                boolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\t\t\t\t\t\n\t                //TODO: for ungraded items, needs to set ungraded-grades later...\n\t\t\t\t\tDouble oldPointsEarned = agr.getPointsEarned();\n\t\t\t\t\t//Double newPointsEarned = (Double)studentUidsToScores.get(studentUid);\n\t\t\t\t\tString newPointsEarnedString = (String)studentUidsToScores.get(studentUid);\n\t\t\t\t\tDouble newPointsEarned = (newPointsEarnedString == null) ? null : convertStringToDouble(newPointsEarnedString); \n\t\t\t\t\tif ( alwaysUpdate || (newPointsEarned != null && !newPointsEarned.equals(oldPointsEarned)) || (newPointsEarned == null && oldPointsEarned != null) ) {\n\t\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\t\tif(newPointsEarned != null)\n\t\t\t\t\t\t\tagr.setPointsEarned(Double.valueOf(newPointsEarned));\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tagr.setPointsEarned(null);\n\t\t\t\t\t\tsession.update(agr);\n\t\t\t\t\t\tchangedStudents.add(studentUid);\n                \t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, newPointsEarned);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfor (Iterator iter = previouslyUnscoredStudents.iterator(); iter.hasNext(); ) {\n\t\t\t\t\tString studentUid = (String)iter.next();\n\n\t\t\t\t\t// Don't save unnecessary null scores.\n\t\t\t\t\tString newPointsEarned = (String)studentUidsToScores.get(studentUid);\n\t\t\t\t\tif (newPointsEarned != null) {\n\t\t\t\t\t\tAssignmentGradeRecord agr = new AssignmentGradeRecord(assignment, studentUid, convertStringToDouble(newPointsEarned));\n\t\t\t\t\t\tagr.setDateRecorded(now);\n\t\t\t\t\t\tagr.setGraderId(graderId);\n\t\t\t\t\t\tsession.save(agr);\n\t\t\t\t\t\tchangedStudents.add(studentUid);\n\t\t\t\t\t\tpostUpdateGradeEvent(gradebookUid, assignment.getName(), studentUid, convertStringToDouble(newPointsEarned));\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tlog.debug(\"updateExternalAssessmentScores sent {} records, actually changed {}\", studentIds.size(), changedStudents.size());\n\n\t\t\t\t// Sync database.\n\t\t\t\tsession.flush();\n\t\t\t\tsession.clear();\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void updateExternalAssessmentComment(final String gradebookUid, final String externalId, final String studentUid, final String comment) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\t\tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n\t\tif(asn == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\n\t\tif (logData.isDebugEnabled()) logData.debug(\"BEGIN: Update 1 score for gradebookUid=\" + gradebookUid + \", external assessment=\" + externalId + \" from \" + asn.getExternalAppName());\n\n\t\tHibernateCallback hc = new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tDate now = new Date();\n\n\t\t\t\t// Try to reduce data contention by only updating when the\n\t\t\t\t// score has actually changed or property has been set forcing a db update every time.\n\t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\n\t\t\t\tCommentDefinition gradeComment = getAssignmentScoreComment(gradebookUid, asn.getId(), studentUid);\n\t\t\t\tString oldComment = gradeComment != null ? gradeComment.getCommentText() : null;\n\n\t\t\t\tif ( alwaysUpdate || (comment != null && !comment.equals(oldComment)) ||\n\t\t\t\t\t\t(comment == null && oldComment != null) ) {\n\t\t\t\t\tif(comment != null)\n\t\t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, comment);\n\t\t\t\t\telse\n\t\t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, null);\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t};\n\t\tgetHibernateTemplate().execute(hc);\n\t\tif (logData.isDebugEnabled()) logData.debug(\"END: Update 1 score for gradebookUid=\" + gradebookUid + \", external assessment=\" + externalId + \" from \" + asn.getExternalAppName());\n\t\tif (log.isDebugEnabled()) log.debug(\"External assessment comment updated in gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid() + \", new score=\" + comment);\n\t}","id":14692,"modified_method":"public void updateExternalAssessmentComment(final String gradebookUid, final String externalId, final String studentUid, final String comment) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n\t\tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n\t\tif(asn == null) {\n\t\t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n\t\t}\n\n\t\tlog.debug(\"BEGIN: Update 1 score for gradebookUid={}, external assessment={} from {}\", gradebookUid, externalId, asn.getExternalAppName());\n\n\t\tHibernateCallback hc = new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\tDate now = new Date();\n\n\t\t\t\t// Try to reduce data contention by only updating when the\n\t\t\t\t// score has actually changed or property has been set forcing a db update every time.\n\t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\n\t\t\t\tCommentDefinition gradeComment = getAssignmentScoreComment(gradebookUid, asn.getId(), studentUid);\n\t\t\t\tString oldComment = gradeComment != null ? gradeComment.getCommentText() : null;\n\n\t\t\t\tif ( alwaysUpdate || (comment != null && !comment.equals(oldComment)) ||\n\t\t\t\t\t\t(comment == null && oldComment != null) ) {\n\t\t\t\t\tif(comment != null)\n\t\t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, comment);\n\t\t\t\t\telse\n\t\t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, null);\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\t\t};\n\t\tgetHibernateTemplate().execute(hc);\n\t\tlog.debug(\"END: Update 1 score for gradebookUid={}, external assessment={} from {}\", gradebookUid, externalId, asn.getExternalAppName());\n\t\tlog.debug(\"External assessment comment updated in gradebookUid={}, externalId={} by userUid={}, new score={}\", gradebookUid, externalId, getUserUid(), comment);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void addExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl, final String title, final Double points, \n\t\tfinal Date dueDate, final String externalServiceDescription, final Boolean ungraded, final Long categoryId) \n\t\tthrows GradebookNotFoundException, ConflictingAssignmentNameException, ConflictingExternalIdException, AssignmentHasIllegalPointsException\n\t{\n\t\t// Ensure that the required strings are not empty\n\t\tif(StringUtils.trimToNull(externalServiceDescription) == null ||\n\t\t\t\tStringUtils.trimToNull(externalId) == null ||\n\t\t\t\tStringUtils.trimToNull(title) == null) {\n\t\t\tthrow new RuntimeException(\"External service description, externalId, and title must not be empty\");\n\t\t}\n\n\t\t// Ensure that points is > zero\n\t\tif((ungraded != null && !ungraded.booleanValue() && (points == null ||  points.doubleValue() <= 0))\n\t\t\t\t|| (ungraded == null && (points == null ||  points.doubleValue() <= 0))) {\n\t\t\tthrow new AssignmentHasIllegalPointsException(\"Points can't be null or Points must be > 0\");\n\t\t}\n\n\t\t// Ensure that the assessment name is unique within this gradebook\n\t\tif (isAssignmentDefined(gradebookUid, title)) {\n\t\t\tthrow new ConflictingAssignmentNameException(\"An assignment with that name already exists in gradebook uid=\" + gradebookUid);\n\t\t}\n\t\t\n\t\t// name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\t// Ensure that the externalId is unique within this gradebook\n\t\t\t\tList conflictList = (List)session.createQuery(\n\t\t\t\t\"select asn from Assignment as asn where asn.externalId=? and asn.gradebook.uid=?\").\n\t\t\t\tsetString(0, externalId).\n\t\t\t\tsetString(1, gradebookUid).list();\n\t\t\t\tInteger externalIdConflicts = conflictList.size();\n\t\t\t\tif (externalIdConflicts.intValue() > 0) {\n\t\t\t\t\tthrow new ConflictingExternalIdException(\"An external assessment with that ID already exists in gradebook uid=\" + gradebookUid);\n\t\t\t\t}\n\n\t\t\t\t// Get the gradebook\n\t\t\t\tGradebook gradebook = getGradebook(gradebookUid);\n\t\t\t\t\n\t\t\t\t// if a category was indicated, double check that it is valid\n\t\t\t\tCategory persistedCategory = null;\n\t\t\t\tif (categoryId != null) {\n\t\t\t\t    persistedCategory = getCategory(categoryId);\n\t\t\t\t    if (persistedCategory == null || persistedCategory.isRemoved() ||\n\t\t\t\t            !persistedCategory.getGradebook().getId().equals(gradebook.getId())) {\n\t\t\t\t        throw new InvalidCategoryException(\"The category with id \" + categoryId + \n\t\t\t\t                \" is not valid for gradebook \" + gradebook.getUid());\n\t\t\t\t    }\n\t\t\t\t}\n\n\t\t\t\t// Create the external assignment\n\t\t\t\tAssignment asn = new Assignment(gradebook, title, points, dueDate);\n\t\t\t\tasn.setExternallyMaintained(true);\n\t\t\t\tasn.setExternalId(externalId);\n\t\t\t\tasn.setExternalInstructorLink(externalUrl);\n\t\t\t\tasn.setExternalStudentLink(externalUrl);\n\t\t\t\tasn.setExternalAppName(externalServiceDescription);\n\t\t\t\tif (persistedCategory != null) { \n\t\t\t\t\tasn.setCategory(persistedCategory);\n\t\t\t\t}\n\t\t\t\t//set released to be true to support selective release\n\t\t\t\tasn.setReleased(true);\n\t\t\t\tif(ungraded != null)\n\t\t\t\t\tasn.setUngraded(ungraded.booleanValue());\n\t\t\t\telse\n\t\t\t\t\tasn.setUngraded(false);\n\n\t\t\t\tsession.save(asn);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n\t\tif (log.isInfoEnabled()) log.info(\"External assessment added to gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid() + \" from externalApp=\" + externalServiceDescription);\n\t}","id":14693,"modified_method":"public void addExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl, final String title, final Double points, \n\t\tfinal Date dueDate, final String externalServiceDescription, final Boolean ungraded, final Long categoryId) \n\t\tthrows GradebookNotFoundException, ConflictingAssignmentNameException, ConflictingExternalIdException, AssignmentHasIllegalPointsException\n\t{\n\t\t// Ensure that the required strings are not empty\n\t\tif(StringUtils.trimToNull(externalServiceDescription) == null ||\n\t\t\t\tStringUtils.trimToNull(externalId) == null ||\n\t\t\t\tStringUtils.trimToNull(title) == null) {\n\t\t\tthrow new RuntimeException(\"External service description, externalId, and title must not be empty\");\n\t\t}\n\n\t\t// Ensure that points is > zero\n\t\tif((ungraded != null && !ungraded.booleanValue() && (points == null ||  points.doubleValue() <= 0))\n\t\t\t\t|| (ungraded == null && (points == null ||  points.doubleValue() <= 0))) {\n\t\t\tthrow new AssignmentHasIllegalPointsException(\"Points can't be null or Points must be > 0\");\n\t\t}\n\n\t\t// Ensure that the assessment name is unique within this gradebook\n\t\tif (isAssignmentDefined(gradebookUid, title)) {\n\t\t\tthrow new ConflictingAssignmentNameException(\"An assignment with that name already exists in gradebook uid=\" + gradebookUid);\n\t\t}\n\t\t\n\t\t// name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\t// Ensure that the externalId is unique within this gradebook\n\t\t\t\tList conflictList = (List)session.createQuery(\n\t\t\t\t\"select asn from Assignment as asn where asn.externalId=? and asn.gradebook.uid=?\").\n\t\t\t\tsetString(0, externalId).\n\t\t\t\tsetString(1, gradebookUid).list();\n\t\t\t\tInteger externalIdConflicts = conflictList.size();\n\t\t\t\tif (externalIdConflicts.intValue() > 0) {\n\t\t\t\t\tthrow new ConflictingExternalIdException(\"An external assessment with that ID already exists in gradebook uid=\" + gradebookUid);\n\t\t\t\t}\n\n\t\t\t\t// Get the gradebook\n\t\t\t\tGradebook gradebook = getGradebook(gradebookUid);\n\t\t\t\t\n\t\t\t\t// if a category was indicated, double check that it is valid\n\t\t\t\tCategory persistedCategory = null;\n\t\t\t\tif (categoryId != null) {\n\t\t\t\t    persistedCategory = getCategory(categoryId);\n\t\t\t\t    if (persistedCategory == null || persistedCategory.isRemoved() ||\n\t\t\t\t            !persistedCategory.getGradebook().getId().equals(gradebook.getId())) {\n\t\t\t\t        throw new InvalidCategoryException(\"The category with id \" + categoryId + \n\t\t\t\t                \" is not valid for gradebook \" + gradebook.getUid());\n\t\t\t\t    }\n\t\t\t\t}\n\n\t\t\t\t// Create the external assignment\n\t\t\t\tAssignment asn = new Assignment(gradebook, title, points, dueDate);\n\t\t\t\tasn.setExternallyMaintained(true);\n\t\t\t\tasn.setExternalId(externalId);\n\t\t\t\tasn.setExternalInstructorLink(externalUrl);\n\t\t\t\tasn.setExternalStudentLink(externalUrl);\n\t\t\t\tasn.setExternalAppName(externalServiceDescription);\n\t\t\t\tif (persistedCategory != null) { \n\t\t\t\t\tasn.setCategory(persistedCategory);\n\t\t\t\t}\n\t\t\t\t//set released to be true to support selective release\n\t\t\t\tasn.setReleased(true);\n\t\t\t\tif(ungraded != null)\n\t\t\t\t\tasn.setUngraded(ungraded.booleanValue());\n\t\t\t\telse\n\t\t\t\t\tasn.setUngraded(false);\n\n\t\t\t\tsession.save(asn);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n\t\tlog.info(\"External assessment added to gradebookUid={}, externalId={} by userUid={} from externalApp={}\", gradebookUid, externalId, getUserUid(), externalServiceDescription);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void addExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl,\n\t\t\tfinal String title, final double points, final Date dueDate, final String externalServiceDescription)\n            throws ConflictingAssignmentNameException, ConflictingExternalIdException, GradebookNotFoundException {\n\n        // Ensure that the required strings are not empty\n        if(StringUtils.trimToNull(externalServiceDescription) == null ||\n                StringUtils.trimToNull(externalId) == null ||\n                StringUtils.trimToNull(title) == null) {\n            throw new RuntimeException(\"External service description, externalId, and title must not be empty\");\n        }\n\n        // Ensure that points is > zero\n        if(points <= 0) {\n            throw new AssignmentHasIllegalPointsException(\"Points must be > 0\");\n        }\n\n        // Ensure that the assessment name is unique within this gradebook\n\t\tif (isAssignmentDefined(gradebookUid, title)) {\n            throw new ConflictingAssignmentNameException(\"An assignment with that name already exists in gradebook uid=\" + gradebookUid);\n        }\n\t\t\n\t\t// name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\t// Ensure that the externalId is unique within this gradebook\n\t\t\t\tList conflictList = (List)session.createQuery(\n\t\t\t\t\t\"select asn from Assignment as asn where asn.externalId=? and asn.gradebook.uid=?\").\n\t\t\t\t\tsetString(0, externalId).\n\t\t\t\t\tsetString(1, gradebookUid).list();\n\t\t\t\tInteger externalIdConflicts = conflictList.size();\n\t\t\t\tif (externalIdConflicts.intValue() > 0) {\n\t\t\t\t\tthrow new ConflictingExternalIdException(\"An external assessment with that ID already exists in gradebook uid=\" + gradebookUid);\n\t\t\t\t}\n\n\t\t\t\t// Get the gradebook\n\t\t\t\tGradebook gradebook = getGradebook(gradebookUid);\n\n\t\t\t\t// Create the external assignment\n\t\t\t\tAssignment asn = new Assignment(gradebook, title, Double.valueOf(points), dueDate);\n\t\t\t\tasn.setExternallyMaintained(true);\n\t\t\t\tasn.setExternalId(externalId);\n\t\t\t\tasn.setExternalInstructorLink(externalUrl);\n\t\t\t\tasn.setExternalStudentLink(externalUrl);\n\t\t\t\tasn.setExternalAppName(externalServiceDescription);\n                //set released to be true to support selective release\n                asn.setReleased(true);\n        asn.setUngraded(false);\n\n                session.save(asn);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n        if (log.isInfoEnabled()) log.info(\"External assessment added to gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid() + \" from externalApp=\" + externalServiceDescription);\n\t}","id":14694,"modified_method":"public void addExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl,\n\t\t\tfinal String title, final double points, final Date dueDate, final String externalServiceDescription)\n            throws ConflictingAssignmentNameException, ConflictingExternalIdException, GradebookNotFoundException {\n\n        // Ensure that the required strings are not empty\n        if(StringUtils.trimToNull(externalServiceDescription) == null ||\n                StringUtils.trimToNull(externalId) == null ||\n                StringUtils.trimToNull(title) == null) {\n            throw new RuntimeException(\"External service description, externalId, and title must not be empty\");\n        }\n\n        // Ensure that points is > zero\n        if(points <= 0) {\n            throw new AssignmentHasIllegalPointsException(\"Points must be > 0\");\n        }\n\n        // Ensure that the assessment name is unique within this gradebook\n\t\tif (isAssignmentDefined(gradebookUid, title)) {\n            throw new ConflictingAssignmentNameException(\"An assignment with that name already exists in gradebook uid=\" + gradebookUid);\n        }\n\t\t\n\t\t// name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n\t\tgetHibernateTemplate().execute(new HibernateCallback() {\n\t\t\tpublic Object doInHibernate(Session session) throws HibernateException {\n\t\t\t\t// Ensure that the externalId is unique within this gradebook\n\t\t\t\tList conflictList = (List)session.createQuery(\n\t\t\t\t\t\"select asn from Assignment as asn where asn.externalId=? and asn.gradebook.uid=?\").\n\t\t\t\t\tsetString(0, externalId).\n\t\t\t\t\tsetString(1, gradebookUid).list();\n\t\t\t\tInteger externalIdConflicts = conflictList.size();\n\t\t\t\tif (externalIdConflicts.intValue() > 0) {\n\t\t\t\t\tthrow new ConflictingExternalIdException(\"An external assessment with that ID already exists in gradebook uid=\" + gradebookUid);\n\t\t\t\t}\n\n\t\t\t\t// Get the gradebook\n\t\t\t\tGradebook gradebook = getGradebook(gradebookUid);\n\n\t\t\t\t// Create the external assignment\n\t\t\t\tAssignment asn = new Assignment(gradebook, title, Double.valueOf(points), dueDate);\n\t\t\t\tasn.setExternallyMaintained(true);\n\t\t\t\tasn.setExternalId(externalId);\n\t\t\t\tasn.setExternalInstructorLink(externalUrl);\n\t\t\t\tasn.setExternalStudentLink(externalUrl);\n\t\t\t\tasn.setExternalAppName(externalServiceDescription);\n                //set released to be true to support selective release\n                asn.setReleased(true);\n        asn.setUngraded(false);\n\n                session.save(asn);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t});\n        log.info(\"External assessment added to gradebookUid={}, externalId={} by userUid={} from externalApp={}\", gradebookUid, externalId, getUserUid(), externalServiceDescription);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public Map<String, String> getExternalAssignmentsForCurrentUser(String gradebookUid)\n\t\tthrows GradebookNotFoundException\n\t{\n\t\tfinal Gradebook gradebook = getGradebook(gradebookUid);\n\n\t\tMap<String, String> visibleAssignments = new HashMap<String, String>();\n\t\tSet<String> providedAssignments = getProvidedExternalAssignments(gradebookUid);\n\n\t\tfor (ExternalAssignmentProvider provider : getExternalAssignmentProviders().values()) {\n\t\t\tString appKey = provider.getAppKey();\n\t\t\tList<String> assignments = provider.getExternalAssignmentsForCurrentUser(gradebookUid);\n\t\t\tfor (String externalId : assignments) {\n\t\t\t\tvisibleAssignments.put(externalId, appKey);\n\t\t\t}\n\t\t}\n\n\t\t// We include those items that the gradebook has marked as externally maintained, but no provider has\n\t\t// identified as items under its authority. This maintains the behavior prior to the grouping support\n\t\t// introduced for the 2.9 release (SAK-11485 and SAK-19688), where a tool that does not have a provider\n\t\t// implemented does not have its items filtered for student views and grading.\n\t\tList<org.sakaiproject.service.gradebook.shared.Assignment> gbAssignments = getGradebookService().getViewableAssignmentsForCurrentUser(gradebookUid);\n\t\tfor (org.sakaiproject.service.gradebook.shared.Assignment assignment : gbAssignments) {\n\t\t\tString id = assignment.getExternalId();\n\t\t\tif (assignment.isExternallyMaintained() && !providedAssignments.contains(id) && !visibleAssignments.containsKey(id)) {\n\t\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\t\tlog.debug(String.format(\"External assignment in gradebook [%s] is not handled by a provider; ID: %s\", gradebookUid, id));\n\t\t\t\t}\n\t\t\t\tvisibleAssignments.put(id, null);\n\t\t\t}\n\t\t}\n\n\t\treturn visibleAssignments;\n\t}","id":14695,"modified_method":"public Map<String, String> getExternalAssignmentsForCurrentUser(String gradebookUid)\n\t\tthrows GradebookNotFoundException\n\t{\n\t\tfinal Gradebook gradebook = getGradebook(gradebookUid);\n\n\t\tMap<String, String> visibleAssignments = new HashMap<String, String>();\n\t\tSet<String> providedAssignments = getProvidedExternalAssignments(gradebookUid);\n\n\t\tfor (ExternalAssignmentProvider provider : getExternalAssignmentProviders().values()) {\n\t\t\tString appKey = provider.getAppKey();\n\t\t\tList<String> assignments = provider.getExternalAssignmentsForCurrentUser(gradebookUid);\n\t\t\tfor (String externalId : assignments) {\n\t\t\t\tvisibleAssignments.put(externalId, appKey);\n\t\t\t}\n\t\t}\n\n\t\t// We include those items that the gradebook has marked as externally maintained, but no provider has\n\t\t// identified as items under its authority. This maintains the behavior prior to the grouping support\n\t\t// introduced for the 2.9 release (SAK-11485 and SAK-19688), where a tool that does not have a provider\n\t\t// implemented does not have its items filtered for student views and grading.\n\t\tList<org.sakaiproject.service.gradebook.shared.Assignment> gbAssignments = getGradebookService().getViewableAssignmentsForCurrentUser(gradebookUid);\n\t\tfor (org.sakaiproject.service.gradebook.shared.Assignment assignment : gbAssignments) {\n\t\t\tString id = assignment.getExternalId();\n\t\t\tif (assignment.isExternallyMaintained() && !providedAssignments.contains(id) && !visibleAssignments.containsKey(id)) {\n\t\t\t\tlog.debug(\"External assignment in gradebook [{}] is not handled by a provider; ID: {}\", gradebookUid, id);\n\t\t\t\tvisibleAssignments.put(id, null);\n\t\t\t}\n\t\t}\n\n\t\treturn visibleAssignments;\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void updateExternalAssessmentComments(final String gradebookUid, final String externalId, final Map<String, String> studentUidsToComments)\n    \t\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n    \t//TODO DO\t\n    \tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n    \tif (asn == null) {\n    \t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n    \t}\n    \tfinal Set studentIds = studentUidsToComments.keySet();\n    \tif (studentIds.isEmpty()) {\n    \t\treturn;\n    \t}\n    \tfinal Date now = new Date();\n    \tfinal String graderId = getUserUid();\n\n    \tgetHibernateTemplate().execute(new HibernateCallback() {\n    \t\tpublic Object doInHibernate(Session session) throws HibernateException {\n    \t\t\tList existingScores;\n    \t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n    \t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n    \t\t\t\tq.setParameter(\"go\", asn);\n    \t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n    \t\t\t\texistingScores = q.list();\n    \t\t\t} else {\n    \t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n    \t\t\t\tq.setParameter(\"go\", asn);\n    \t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n    \t\t\t}\n\n    \t\t\tSet changedStudents = new HashSet();\n    \t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n    \t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n    \t\t\t\tString studentUid = agr.getStudentId();\n\n    \t\t\t\t// Try to reduce data contention by only updating when a score\n    \t\t\t\t// has changed or property has been set forcing a db update every time.\n    \t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\n    \t\t\t\tCommentDefinition gradeComment = getAssignmentScoreComment(gradebookUid, asn.getId(), studentUid);\n    \t\t\t\tString oldComment = gradeComment != null ? gradeComment.getCommentText() : null;\n    \t\t\t\tString newComment = (String) studentUidsToComments.get(studentUid);\n\n    \t\t\t\tif ( alwaysUpdate || (newComment != null && !newComment.equals(oldComment)) || (newComment == null && oldComment != null) ) {\n    \t\t\t\t\tchangedStudents.add(studentUid);\n    \t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, newComment);\n    \t\t\t\t}\n    \t\t\t}\n\n    \t\t\tif (log.isDebugEnabled()) log.debug(\"updateExternalAssessmentScores sent \" + studentIds.size() + \" records, actually changed \" + changedStudents.size());\n\n    \t\t\t// Sync database.\n    \t\t\tsession.flush();\n    \t\t\tsession.clear();\n    \t\t\treturn null;\n    \t\t}\n    \t});\n    }","id":14696,"modified_method":"public void updateExternalAssessmentComments(final String gradebookUid, final String externalId, final Map<String, String> studentUidsToComments)\n    \t\tthrows GradebookNotFoundException, AssessmentNotFoundException {\n    \t//TODO DO\t\n    \tfinal Assignment asn = getExternalAssignment(gradebookUid, externalId);\n    \tif (asn == null) {\n    \t\tthrow new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n    \t}\n    \tfinal Set studentIds = studentUidsToComments.keySet();\n    \tif (studentIds.isEmpty()) {\n    \t\treturn;\n    \t}\n    \tfinal Date now = new Date();\n    \tfinal String graderId = getUserUid();\n\n    \tgetHibernateTemplate().execute(new HibernateCallback() {\n    \t\tpublic Object doInHibernate(Session session) throws HibernateException {\n    \t\t\tList existingScores;\n    \t\t\tif (studentIds.size() <= MAX_NUMBER_OF_SQL_PARAMETERS_IN_LIST) {\n    \t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go and gr.studentId in (:studentIds)\");\n    \t\t\t\tq.setParameter(\"go\", asn);\n    \t\t\t\tq.setParameterList(\"studentIds\", studentIds);\n    \t\t\t\texistingScores = q.list();\n    \t\t\t} else {\n    \t\t\t\tQuery q = session.createQuery(\"from AssignmentGradeRecord as gr where gr.gradableObject=:go\");\n    \t\t\t\tq.setParameter(\"go\", asn);\n    \t\t\t\texistingScores = filterGradeRecordsByStudents(q.list(), studentIds);\n    \t\t\t}\n\n    \t\t\tSet changedStudents = new HashSet();\n    \t\t\tfor (Iterator iter = existingScores.iterator(); iter.hasNext(); ) {\n    \t\t\t\tAssignmentGradeRecord agr = (AssignmentGradeRecord)iter.next();\n    \t\t\t\tString studentUid = agr.getStudentId();\n\n    \t\t\t\t// Try to reduce data contention by only updating when a score\n    \t\t\t\t// has changed or property has been set forcing a db update every time.\n    \t\t\t\tboolean alwaysUpdate = ServerConfigurationService.getBoolean(UPDATE_SAME_SCORE_PROP, false);\n\n    \t\t\t\tCommentDefinition gradeComment = getAssignmentScoreComment(gradebookUid, asn.getId(), studentUid);\n    \t\t\t\tString oldComment = gradeComment != null ? gradeComment.getCommentText() : null;\n    \t\t\t\tString newComment = (String) studentUidsToComments.get(studentUid);\n\n    \t\t\t\tif ( alwaysUpdate || (newComment != null && !newComment.equals(oldComment)) || (newComment == null && oldComment != null) ) {\n    \t\t\t\t\tchangedStudents.add(studentUid);\n    \t\t\t\t\tsetAssignmentScoreComment(gradebookUid, asn.getId(), studentUid, newComment);\n    \t\t\t\t}\n    \t\t\t}\n\n    \t\t\tlog.debug(\"updateExternalAssessmentScores sent {} records, actually changed {}\", studentIds.size(), changedStudents.size());\n\n    \t\t\t// Sync database.\n    \t\t\tsession.flush();\n    \t\t\tsession.clear();\n    \t\t\treturn null;\n    \t\t}\n    \t});\n    }","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void setExternalAssessmentToGradebookAssignment(final String gradebookUid, final String externalId) {\n        final Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n        if (assignment == null) {\n            throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n        assignment.setExternalAppName(null);\n        assignment.setExternalId(null);\n        assignment.setExternalInstructorLink(null);\n        assignment.setExternalStudentLink(null);\n        assignment.setExternallyMaintained(false);\n        getHibernateTemplate().execute(new HibernateCallback() {\n        \tpublic Object doInHibernate(Session session) throws HibernateException {\n                session.update(assignment);\n                if (log.isInfoEnabled()) log.info(\"Externally-managed assignment \" + externalId + \" moved to Gradebook management in gradebookUid=\" + gradebookUid + \" by userUid=\" + getUserUid());\n                return null;\n        \t}\n        });\n\t}","id":14697,"modified_method":"public void setExternalAssessmentToGradebookAssignment(final String gradebookUid, final String externalId) {\n        final Assignment assignment = getExternalAssignment(gradebookUid, externalId);\n        if (assignment == null) {\n            throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n        assignment.setExternalAppName(null);\n        assignment.setExternalId(null);\n        assignment.setExternalInstructorLink(null);\n        assignment.setExternalStudentLink(null);\n        assignment.setExternallyMaintained(false);\n        getHibernateTemplate().execute(new HibernateCallback() {\n        \tpublic Object doInHibernate(Session session) throws HibernateException {\n                session.update(assignment);\n                log.info(\"Externally-managed assignment {} moved to Gradebook management in gradebookUid={} by userUid={}\", externalId, gradebookUid, getUserUid());\n                return null;\n        \t}\n        });\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"public void updateExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl, final String title, final Double points, final Date dueDate, final Boolean ungraded) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException, ConflictingAssignmentNameException, AssignmentHasIllegalPointsException\n\t{\n    final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n    if(asn == null) {\n        throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n    }\n\n    // Ensure that points is > zero\n\t\tif((ungraded != null && !ungraded.booleanValue() && (points == null ||  points.doubleValue() <= 0))\n\t\t\t\t|| (ungraded == null && (points == null ||  points.doubleValue() <= 0))) {\n\t\t\tthrow new AssignmentHasIllegalPointsException(\"Points can't be null or Points must be > 0\");\n\t\t}\n\n    // Ensure that the required strings are not empty\n    if( StringUtils.trimToNull(externalId) == null ||\n            StringUtils.trimToNull(title) == null) {\n        throw new RuntimeException(\"ExternalId, and title must not be empty\");\n    }\n    \n    // name cannot start with * or # as they are reserved for special columns in import/export\n    if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n        // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n    \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n    }\n\n    HibernateCallback hc = new HibernateCallback() {\n        public Object doInHibernate(Session session) throws HibernateException {\n            asn.setExternalInstructorLink(externalUrl);\n            asn.setExternalStudentLink(externalUrl);\n            asn.setName(title);\n            asn.setDueDate(dueDate);\n            //support selective release\n            asn.setReleased(true);\n            asn.setPointsPossible(points);\n    \t\t\t\tif(ungraded != null)\n    \t\t\t\t\tasn.setUngraded(ungraded.booleanValue());\n    \t\t\t\telse\n    \t\t\t\t\tasn.setUngraded(false);\n            session.update(asn);\n            if (log.isInfoEnabled()) log.info(\"External assessment updated in gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid());\n            return null;\n\n        }\n    };\n    getHibernateTemplate().execute(hc);\n\t}","id":14698,"modified_method":"public void updateExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl, final String title, final Double points, final Date dueDate, final Boolean ungraded) \n\tthrows GradebookNotFoundException, AssessmentNotFoundException, ConflictingAssignmentNameException, AssignmentHasIllegalPointsException\n\t{\n    final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n    if(asn == null) {\n        throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n    }\n\n    // Ensure that points is > zero\n\t\tif((ungraded != null && !ungraded.booleanValue() && (points == null ||  points.doubleValue() <= 0))\n\t\t\t\t|| (ungraded == null && (points == null ||  points.doubleValue() <= 0))) {\n\t\t\tthrow new AssignmentHasIllegalPointsException(\"Points can't be null or Points must be > 0\");\n\t\t}\n\n    // Ensure that the required strings are not empty\n    if( StringUtils.trimToNull(externalId) == null ||\n            StringUtils.trimToNull(title) == null) {\n        throw new RuntimeException(\"ExternalId, and title must not be empty\");\n    }\n    \n    // name cannot start with * or # as they are reserved for special columns in import/export\n    if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n        // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n    \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n    }\n\n    HibernateCallback hc = new HibernateCallback() {\n        public Object doInHibernate(Session session) throws HibernateException {\n            asn.setExternalInstructorLink(externalUrl);\n            asn.setExternalStudentLink(externalUrl);\n            asn.setName(title);\n            asn.setDueDate(dueDate);\n            //support selective release\n            asn.setReleased(true);\n            asn.setPointsPossible(points);\n    \t\t\t\tif(ungraded != null)\n    \t\t\t\t\tasn.setUngraded(ungraded.booleanValue());\n    \t\t\t\telse\n    \t\t\t\t\tasn.setUngraded(false);\n            session.update(asn);\n            log.info(\"External assessment updated in gradebookUid={}, externalId={} by userUid={}\", gradebookUid, externalId, getUserUid());\n            return null;\n\n        }\n    };\n    getHibernateTemplate().execute(hc);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"/**\n\t * @see org.sakaiproject.service.gradebook.shared.GradebookService#updateExternalAssessment(java.lang.String, java.lang.String, java.lang.String, java.lang.String, long, java.util.Date)\n     */\n    public void updateExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl,\n                                         final String title, final double points, final Date dueDate) throws GradebookNotFoundException, AssessmentNotFoundException,AssignmentHasIllegalPointsException {\n        final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n        if(asn == null) {\n            throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n\n        // Ensure that points is > zero\n        if(points <= 0) {\n            throw new AssignmentHasIllegalPointsException(\"Points must be > 0\");\n        }\n\n        // Ensure that the required strings are not empty\n        if( StringUtils.trimToNull(externalId) == null ||\n                StringUtils.trimToNull(title) == null) {\n            throw new RuntimeException(\"ExternalId, and title must not be empty\");\n        }\n        \n        // name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n        HibernateCallback hc = new HibernateCallback() {\n            public Object doInHibernate(Session session) throws HibernateException {\n                asn.setExternalInstructorLink(externalUrl);\n                asn.setExternalStudentLink(externalUrl);\n                asn.setName(title);\n                asn.setDueDate(dueDate);\n                //support selective release\n                asn.setReleased(true);\n                asn.setPointsPossible(Double.valueOf(points));\n                session.update(asn);\n                if (log.isInfoEnabled()) log.info(\"External assessment updated in gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid());\n                return null;\n\n            }\n        };\n        getHibernateTemplate().execute(hc);\n\t}","id":14699,"modified_method":"/**\n\t * @see org.sakaiproject.service.gradebook.shared.GradebookService#updateExternalAssessment(java.lang.String, java.lang.String, java.lang.String, java.lang.String, long, java.util.Date)\n     */\n    public void updateExternalAssessment(final String gradebookUid, final String externalId, final String externalUrl,\n                                         final String title, final double points, final Date dueDate) throws GradebookNotFoundException, AssessmentNotFoundException,AssignmentHasIllegalPointsException {\n        final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n\n        if(asn == null) {\n            throw new AssessmentNotFoundException(\"There is no assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n\n        // Ensure that points is > zero\n        if(points <= 0) {\n            throw new AssignmentHasIllegalPointsException(\"Points must be > 0\");\n        }\n\n        // Ensure that the required strings are not empty\n        if( StringUtils.trimToNull(externalId) == null ||\n                StringUtils.trimToNull(title) == null) {\n            throw new RuntimeException(\"ExternalId, and title must not be empty\");\n        }\n        \n        // name cannot start with * or # as they are reserved for special columns in import/export\n        if(StringUtils.startsWithAny(title, new String[]{\"*\", \"#\"})) {\n            // TODO InvalidAssignmentNameException plus move all exceptions to their own package\n        \tthrow new ConflictingAssignmentNameException(\"Assignment names cannot start with * or # as they are reserved\");\n        }\n\n        HibernateCallback hc = new HibernateCallback() {\n            public Object doInHibernate(Session session) throws HibernateException {\n                asn.setExternalInstructorLink(externalUrl);\n                asn.setExternalStudentLink(externalUrl);\n                asn.setName(title);\n                asn.setDueDate(dueDate);\n                //support selective release\n                asn.setReleased(true);\n                asn.setPointsPossible(Double.valueOf(points));\n                session.update(asn);\n                log.info(\"External assessment updated in gradebookUid={}, externalId={} by userUid={}\", gradebookUid, externalId, getUserUid());\n                return null;\n\n            }\n        };\n        getHibernateTemplate().execute(hc);\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"/**\n\t * @see org.sakaiproject.service.gradebook.shared.GradebookService#removeExternalAssessment(java.lang.String, java.lang.String)\n\t */\n\tpublic void removeExternalAssessment(final String gradebookUid,\n            final String externalId) throws GradebookNotFoundException, AssessmentNotFoundException {\n        // Get the external assignment\n        final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n        if(asn == null) {\n            throw new AssessmentNotFoundException(\"There is no external assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n\n        // We need to go through Spring's HibernateTemplate to do\n        // any deletions at present. See the comments to deleteGradebook\n        // for the details.\n        HibernateTemplate hibTempl = getHibernateTemplate();\n        \n        List toBeDeletedEvents = hibTempl.find(\"from GradingEvent as ge where ge.gradableObject=?\", asn);\n        int numberDeletedEvents = toBeDeletedEvents.size();\n        hibTempl.deleteAll(toBeDeletedEvents);\n        if (logData.isDebugEnabled()) logData.debug(\"Deleted \" + numberDeletedEvents + \"records from gb_grading_event_t\");\n\n        List toBeDeleted = hibTempl.find(\"from AssignmentGradeRecord as agr where agr.gradableObject=?\", asn);\n        int numberDeleted = toBeDeleted.size();\n        hibTempl.deleteAll(toBeDeleted);\n        if (log.isInfoEnabled()) log.info(\"Deleted \" + numberDeleted + \" externally defined scores\");\n\n        toBeDeleted = hibTempl.find( \"from Comment as c where c.gradableObject = ?\", asn );\n        hibTempl.deleteAll( toBeDeleted );\n        if( log.isInfoEnabled() )\n        {\n            log.info( \"Deleted \" + toBeDeleted.size() + \" externally defined score comments\" );\n        }\n\n        // Delete the assessment.\n\t\thibTempl.flush();\n\t\thibTempl.clear();\n\t\thibTempl.delete(asn);\n\n        if (log.isInfoEnabled()) log.info(\"External assessment removed from gradebookUid=\" + gradebookUid + \", externalId=\" + externalId + \" by userUid=\" + getUserUid());\n\t}","id":14700,"modified_method":"/**\n\t * @see org.sakaiproject.service.gradebook.shared.GradebookService#removeExternalAssessment(java.lang.String, java.lang.String)\n\t */\n\tpublic void removeExternalAssessment(final String gradebookUid,\n            final String externalId) throws GradebookNotFoundException, AssessmentNotFoundException {\n        // Get the external assignment\n        final Assignment asn = getExternalAssignment(gradebookUid, externalId);\n        if(asn == null) {\n            throw new AssessmentNotFoundException(\"There is no external assessment id=\" + externalId + \" in gradebook uid=\" + gradebookUid);\n        }\n\n        // We need to go through Spring's HibernateTemplate to do\n        // any deletions at present. See the comments to deleteGradebook\n        // for the details.\n        HibernateTemplate hibTempl = getHibernateTemplate();\n\n        hibTempl.execute(new HibernateCallback() {\n            public Object doInHibernate(Session session) {\n                int numDeleted = session.createQuery(\"delete GradingEvent where gradableObject=:go\").setParameter(\"go\", asn).executeUpdate();\n                log.debug(\"Deleted \" + numDeleted + \" records from gb_grading_event_t\");\n\n                numDeleted = session.createQuery(\"delete AssignmentGradeRecord where gradableObject=:go\").setParameter(\"go\", asn).executeUpdate();\n                log.info(\"Deleted \" + numDeleted + \" externally defined scores\");\n                \n                numDeleted = session.createQuery(\"delete Comment where gradableObject=:go\").setParameter(\"go\", asn).executeUpdate();\n                log.info(\"Deleted \" + numDeleted + \" externally defined comments\");\n                return null;\n            }\n        });\n\n        // Delete the assessment.\n\t\thibTempl.flush();\n\t\thibTempl.clear();\n\t\thibTempl.delete(asn);\n\n        log.info(\"External assessment removed from gradebookUid={}, externalId={} by userUid={}\", gradebookUid, externalId, getUserUid());\n\t}","commit_id":"472b174603c2e25521b624eba439e8e2f8bd14fc","url":"https://github.com/sakaiproject/sakai"},{"original_method":"@Test\n  public void delete_documents_indexes() throws Exception {\n    insertNewProjectInIndexes(1);\n    insertNewProjectInIndexes(2);\n    insertNewProjectInIndexes(3);\n    insertNewProjectInIndexes(4);\n\n    ws.newPostRequest(\"api/projects\", ACTION)\n      .setParam(PARAM_KEYS, \"project-key-1, project-key-3, project-key-4\").execute();\n\n    String remainingProjectUuid = \"project-uuid-2\";\n    assertThat(es.getDocumentFieldValues(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_ISSUE, IssueIndexDefinition.FIELD_ISSUE_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n    assertThat(es.getDocumentFieldValues(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_AUTHORIZATION, IssueIndexDefinition.FIELD_AUTHORIZATION_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n    assertThat(es.getDocumentFieldValues(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, TestIndexDefinition.FIELD_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n  }","id":14701,"modified_method":"@Test\n  public void delete_documents_indexes() throws Exception {\n    insertNewProjectInIndexes(1);\n    insertNewProjectInIndexes(2);\n    insertNewProjectInIndexes(3);\n    insertNewProjectInIndexes(4);\n\n    ws.newPostRequest(\"api/projects\", ACTION)\n      .setParam(PARAM_KEYS, \"project-key-1, project-key-3, project-key-4\").execute();\n\n    String remainingProjectUuid = \"project-uuid-2\";\n    assertThat(es.getDocumentFieldValues(IssueIndexDefinition.INDEX, TYPE_ISSUE, IssueIndexDefinition.FIELD_ISSUE_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n    assertThat(es.getDocumentFieldValues(IssueIndexDefinition.INDEX, TYPE_AUTHORIZATION, FIELD_AUTHORIZATION_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n    assertThat(es.getDocumentFieldValues(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, TestIndexDefinition.FIELD_PROJECT_UUID))\n      .containsOnly(remainingProjectUuid);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void insertNewProjectInIndexes(int id) throws Exception {\n    String suffix = String.valueOf(id);\n    ComponentDto project = ComponentTesting\n      .newProjectDto(\"project-uuid-\" + suffix)\n      .setKey(\"project-key-\" + suffix);\n    dbClient.componentDao().insert(dbSession, project);\n    dbSession.commit();\n\n    es.putDocuments(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_ISSUE, IssueTesting.newDoc(\"issue-key-\" + suffix, project));\n    es.putDocuments(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_AUTHORIZATION,\n      ImmutableMap.<String, Object>of(IssueIndexDefinition.FIELD_AUTHORIZATION_PROJECT_UUID, project.uuid()));\n\n    TestDoc testDoc = new TestDoc().setUuid(\"test-uuid-\" + suffix).setProjectUuid(project.uuid()).setFileUuid(project.uuid());\n    es.putDocuments(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, testDoc);\n  }","id":14702,"modified_method":"private void insertNewProjectInIndexes(int id) throws Exception {\n    String suffix = String.valueOf(id);\n    ComponentDto project = ComponentTesting\n      .newProjectDto(\"project-uuid-\" + suffix)\n      .setKey(\"project-key-\" + suffix);\n    dbClient.componentDao().insert(dbSession, project);\n    dbSession.commit();\n\n    es.putDocuments(IssueIndexDefinition.INDEX, TYPE_ISSUE, IssueTesting.newDoc(\"issue-key-\" + suffix, project));\n    es.index(IssueIndexDefinition.INDEX, TYPE_AUTHORIZATION, project.uuid(), ImmutableMap.<String, Object>of(FIELD_AUTHORIZATION_PROJECT_UUID, project.uuid()));\n\n    TestDoc testDoc = new TestDoc().setUuid(\"test-uuid-\" + suffix).setProjectUuid(project.uuid()).setFileUuid(project.uuid());\n    es.putDocuments(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, testDoc);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void bulk_delete() throws Exception {\n    int max = 500;\n    int removeFrom = 200;\n    Map[] docs = new Map[max];\n    for (int i = 0; i < max; i++) {\n      docs[i] = ImmutableMap.of(FakeIndexDefinition.INT_FIELD, i);\n    }\n    esTester.putDocuments(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, docs);\n    assertThat(count()).isEqualTo(max);\n\n    SearchRequestBuilder req = esTester.client().prepareSearch(FakeIndexDefinition.INDEX)\n      .setTypes(FakeIndexDefinition.TYPE)\n      .setQuery(QueryBuilders.filteredQuery(\n        QueryBuilders.matchAllQuery(),\n        FilterBuilders.rangeFilter(FakeIndexDefinition.INT_FIELD).gte(removeFrom)));\n    BulkIndexer.delete(esTester.client(), FakeIndexDefinition.INDEX, req);\n\n    assertThat(count()).isEqualTo(removeFrom);\n  }","id":14703,"modified_method":"@Test\n  public void bulk_delete() throws Exception {\n    int max = 500;\n    int removeFrom = 200;\n    FakeDoc[] docs = new FakeDoc[max];\n    for (int i = 0; i < max; i++) {\n      docs[i] = FakeIndexDefinition.newDoc(i);\n    }\n    esTester.putDocuments(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, docs);\n    assertThat(count()).isEqualTo(max);\n\n    SearchRequestBuilder req = esTester.client().prepareSearch(FakeIndexDefinition.INDEX)\n      .setTypes(FakeIndexDefinition.TYPE)\n      .setQuery(QueryBuilders.filteredQuery(\n        QueryBuilders.matchAllQuery(),\n        FilterBuilders.rangeFilter(FakeIndexDefinition.INT_FIELD).gte(removeFrom)));\n    BulkIndexer.delete(esTester.client(), FakeIndexDefinition.INDEX, req);\n\n    assertThat(count()).isEqualTo(removeFrom);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void insertNewProjectInIndexes(int id) throws Exception {\n    String suffix = String.valueOf(id);\n    ComponentDto project = ComponentTesting\n      .newProjectDto(\"project-uuid-\" + suffix)\n      .setKey(\"project-key-\" + suffix);\n    dbClient.componentDao().insert(dbSession, project);\n    dbSession.commit();\n\n    es.putDocuments(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_ISSUE, IssueTesting.newDoc(\"issue-key-\" + suffix, project));\n    es.putDocuments(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_AUTHORIZATION,\n      ImmutableMap.<String, Object>of(IssueIndexDefinition.FIELD_AUTHORIZATION_PROJECT_UUID, project.uuid()));\n\n    TestDoc testDoc = new TestDoc().setUuid(\"test-uuid-\" + suffix).setProjectUuid(project.uuid()).setFileUuid(project.uuid());\n    es.putDocuments(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, testDoc);\n  }","id":14704,"modified_method":"private void insertNewProjectInIndexes(int id) throws Exception {\n    String suffix = String.valueOf(id);\n    ComponentDto project = ComponentTesting\n      .newProjectDto(\"project-uuid-\" + suffix)\n      .setKey(\"project-key-\" + suffix);\n    dbClient.componentDao().insert(dbSession, project);\n    dbSession.commit();\n\n    es.putDocuments(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_ISSUE, IssueTesting.newDoc(\"issue-key-\" + suffix, project));\n    es.index(IssueIndexDefinition.INDEX, IssueIndexDefinition.TYPE_AUTHORIZATION, project.uuid(), ImmutableMap.<String, Object>of(IssueIndexDefinition.FIELD_AUTHORIZATION_PROJECT_UUID, project.uuid()));\n\n    TestDoc testDoc = new TestDoc().setUuid(\"test-uuid-\" + suffix).setProjectUuid(project.uuid()).setFileUuid(project.uuid());\n    es.putDocuments(TestIndexDefinition.INDEX, TestIndexDefinition.TYPE, testDoc);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_process_result_with_date_histogram() throws Exception {\n    esTester.putDocuments(INDEX, TYPE,\n      newTagsDocument(\"first\"), newTagsDocument(\"second\"), newTagsDocument(\"third\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(\n        AggregationBuilders.dateHistogram(FIELD_CREATED_AT)\n          .minDocCount(0L)\n          .field(FIELD_CREATED_AT)\n          .interval(Interval.MINUTE)\n          .format(DateUtils.DATETIME_FORMAT));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).isEmpty();\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).hasSize(1);\n    FacetValue value = facets.getFacetValues(FIELD_CREATED_AT).iterator().next();\n    assertThat(DateUtils.parseDateTime(value.getKey()).before(new Date())).isTrue();\n    assertThat(value.getValue()).isEqualTo(3L);\n  }","id":14705,"modified_method":"@Test\n  public void should_process_result_with_date_histogram() throws Exception {\n    esTester.index(INDEX, TYPE, \"first\", newTagsDocument(\"first\"));\n    esTester.index(INDEX, TYPE, \"second\", newTagsDocument(\"second\"));\n    esTester.index(INDEX, TYPE, \"third\", newTagsDocument(\"third\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(\n        AggregationBuilders.dateHistogram(FIELD_CREATED_AT)\n          .minDocCount(0L)\n          .field(FIELD_CREATED_AT)\n          .interval(Interval.MINUTE)\n          .format(DateUtils.DATETIME_FORMAT));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).isEmpty();\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).hasSize(1);\n    FacetValue value = facets.getFacetValues(FIELD_CREATED_AT).iterator().next();\n    assertThat(DateUtils.parseDateTime(value.getKey()).before(new Date())).isTrue();\n    assertThat(value.getValue()).isEqualTo(3L);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_process_result_with_nested_missing_and_terms_aggregations() throws Exception {\n    esTester.putDocuments(INDEX, TYPE,\n      newTagsDocument(\"noTags\"),\n      newTagsDocument(\"oneTag\", \"tag1\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.global(\"tags__global\")\n        .subAggregation(AggregationBuilders.missing(\"tags_missing\").field(FIELD_TAGS))\n        .subAggregation(AggregationBuilders.terms(\"tags\").field(FIELD_TAGS).size(2))\n        .subAggregation(AggregationBuilders.terms(\"tags__selected\").field(FIELD_TAGS).include(\"tag4\"))\n        .subAggregation(AggregationBuilders.terms(\"__ignored\").field(FIELD_TAGS).include(\"tag3\")));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).containsOnly(\"\", \"tag1\", \"tag2\", \"tag4\");\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).isEmpty();\n    // ES internals use HashMap, so can't test the exact string for compatibility with both java 7 and java 8\n    assertThat(facets.toString()).startsWith(\"{tags=[{\")\n      .contains(\"__ignored=[{tag3=1}]\")\n      .contains(\"{tag4=1}\")\n      .contains(\"{=1}\")\n      .contains(\"{tag1=2}\")\n      .contains(\"{tag2=1}\");\n  }","id":14706,"modified_method":"@Test\n  public void should_process_result_with_nested_missing_and_terms_aggregations() throws Exception {\n    esTester.index(INDEX, TYPE, \"noTags\", newTagsDocument(\"noTags\"));\n    esTester.index(INDEX, TYPE, \"oneTag\", newTagsDocument(\"oneTag\", \"tag1\"));\n    esTester.index(INDEX, TYPE, \"fourTags\", newTagsDocument(\"fourTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.global(\"tags__global\")\n        .subAggregation(AggregationBuilders.missing(\"tags_missing\").field(FIELD_TAGS))\n        .subAggregation(AggregationBuilders.terms(\"tags\").field(FIELD_TAGS).size(2))\n        .subAggregation(AggregationBuilders.terms(\"tags__selected\").field(FIELD_TAGS).include(\"tag4\"))\n        .subAggregation(AggregationBuilders.terms(\"__ignored\").field(FIELD_TAGS).include(\"tag3\")));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).containsOnly(\"\", \"tag1\", \"tag2\", \"tag4\");\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).isEmpty();\n    // ES internals use HashMap, so can't test the exact string for compatibility with both java 7 and java 8\n    assertThat(facets.toString()).startsWith(\"{tags=[{\")\n      .contains(\"__ignored=[{tag3=1}]\")\n      .contains(\"{tag4=1}\")\n      .contains(\"{=1}\")\n      .contains(\"{tag1=2}\")\n      .contains(\"{tag2=1}\");\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_ignore_unknown_aggregation_type() throws Exception {\n    esTester.putDocuments(INDEX, TYPE,\n      newTagsDocument(\"noTags\"),\n      newTagsDocument(\"oneTag\", \"tag1\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.cardinality(FIELD_TAGS).field(FIELD_TAGS));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).isEmpty();\n  }","id":14707,"modified_method":"@Test\n  public void should_ignore_unknown_aggregation_type() throws Exception {\n    esTester.index(INDEX, TYPE, \"noTags\", newTagsDocument(\"noTags\"));\n    esTester.index(INDEX, TYPE, \"oneTag\", newTagsDocument(\"oneTag\", \"tag1\"));\n    esTester.index(INDEX, TYPE, \"twoTags\", newTagsDocument(\"twoTags\", \"tag1\", \"tag2\"));\n    esTester.index(INDEX, TYPE, \"threeTags\", newTagsDocument(\"threeTags\", \"tag1\", \"tag2\", \"tag3\"));\n    esTester.index(INDEX, TYPE, \"fourTags\", newTagsDocument(\"fourTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.cardinality(FIELD_TAGS).field(FIELD_TAGS));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).isEmpty();\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n    public void define(IndexDefinitionContext context) {\n      NewIndexType newType = context.create(INDEX).createType(TYPE);\n      newType.setAttribute(\"_id\", ImmutableMap.of(\"path\", FIELD_KEY));\n      newType.stringFieldBuilder(FIELD_KEY).build();\n      newType.stringFieldBuilder(FIELD_TAGS).build();\n      newType.createDateTimeField(FIELD_CREATED_AT);\n    }","id":14708,"modified_method":"@Override\n    public void define(IndexDefinitionContext context) {\n      NewIndexType newType = context.create(INDEX).createType(TYPE);\n      newType.stringFieldBuilder(FIELD_KEY).build();\n      newType.stringFieldBuilder(FIELD_TAGS).build();\n      newType.createDateTimeField(FIELD_CREATED_AT);\n    }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_ignore_empty_missing_aggregation() throws Exception {\n    esTester.putDocuments(INDEX, TYPE,\n      newTagsDocument(\"oneTag\", \"tag1\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\"),\n      newTagsDocument(\"twoTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.global(\"tags__global\")\n        .subAggregation(AggregationBuilders.missing(\"tags_missing\").field(FIELD_TAGS))\n        .subAggregation(AggregationBuilders.terms(\"tags\").field(FIELD_TAGS).size(2))\n        .subAggregation(AggregationBuilders.terms(\"tags__selected\").field(FIELD_TAGS).include(\"tag4\"))\n        .subAggregation(AggregationBuilders.terms(\"__ignored\").field(FIELD_TAGS).include(\"tag3\")));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).containsOnly(\"tag1\", \"tag2\", \"tag4\");\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).isEmpty();\n  }","id":14709,"modified_method":"@Test\n  public void should_ignore_empty_missing_aggregation() throws Exception {\n    esTester.index(INDEX, TYPE, \"oneTag\", newTagsDocument(\"oneTag\", \"tag1\"));\n    esTester.index(INDEX, TYPE, \"twoTags\", newTagsDocument(\"twoTags\", \"tag1\", \"tag2\"));\n    esTester.index(INDEX, TYPE, \"threeTags\", newTagsDocument(\"threeTags\", \"tag1\", \"tag2\", \"tag3\"));\n    esTester.index(INDEX, TYPE, \"fourTags\", newTagsDocument(\"fourTags\", \"tag1\", \"tag2\", \"tag3\", \"tag4\"));\n\n    SearchRequestBuilder search = esTester.client().prepareSearch(INDEX).setTypes(TYPE)\n      .addAggregation(AggregationBuilders.global(\"tags__global\")\n        .subAggregation(AggregationBuilders.missing(\"tags_missing\").field(FIELD_TAGS))\n        .subAggregation(AggregationBuilders.terms(\"tags\").field(FIELD_TAGS).size(2))\n        .subAggregation(AggregationBuilders.terms(\"tags__selected\").field(FIELD_TAGS).include(\"tag4\"))\n        .subAggregation(AggregationBuilders.terms(\"__ignored\").field(FIELD_TAGS).include(\"tag3\")));\n\n    Facets facets = new Facets(search.get());\n    assertThat(facets.getFacets()).isNotEmpty();\n    assertThat(facets.getFacetKeys(FIELD_TAGS)).containsOnly(\"tag1\", \"tag2\", \"tag4\");\n    assertThat(facets.getFacetKeys(FIELD_CREATED_AT)).isEmpty();\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public static Map<String,Object> newDoc(int value) {\n    return ImmutableMap.<String,Object>of(INT_FIELD, value);\n  }","id":14710,"modified_method":"public static FakeDoc newDoc(int value) {\n    return new FakeDoc().setInt(value);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void testBulk() {\n    BulkRequestBuilder req = esTester.client().prepareBulk();\n    req.add(new UpdateRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key1\")\n      .doc(FakeIndexDefinition.newDoc(1)));\n    req.add(new DeleteRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key2\"));\n    req.add(new IndexRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key3\")\n      .source(FakeIndexDefinition.newDoc(3)));\n\n    assertThat(req.toString()).isEqualTo(\n      \"Bulk[1 update request(s) on index fakes and type fake, 1 delete request(s) on index fakes and type fake, 1 index request(s) on index fakes and type fake]\");\n\n    BulkResponse response = req.get();\n    assertThat(response.getItems()).hasSize(3);\n  }","id":14711,"modified_method":"private void testBulk() {\n    BulkRequestBuilder req = esTester.client().prepareBulk();\n    req.add(new UpdateRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key1\")\n      .doc(FakeIndexDefinition.newDoc(1).getFields()));\n    req.add(new DeleteRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key2\"));\n    req.add(new IndexRequest(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE, \"key3\")\n      .source(FakeIndexDefinition.newDoc(3).getFields()));\n\n    assertThat(req.toString()).isEqualTo(\n      \"Bulk[1 update request(s) on index fakes and type fake, 1 delete request(s) on index fakes and type fake, 1 index request(s) on index fakes and type fake]\");\n\n    BulkResponse response = req.get();\n    assertThat(response.getItems()).hasSize(3);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void trace_logs() {\n    logTester.setLevel(LoggerLevel.TRACE);\n    IndexResponse response = esTester.client().prepareIndex(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE)\n      .setSource(FakeIndexDefinition.newDoc(42))\n      .get();\n    assertThat(response.isCreated()).isTrue();\n    assertThat(logTester.logs()).hasSize(1);\n  }","id":14712,"modified_method":"@Test\n  public void trace_logs() {\n    logTester.setLevel(LoggerLevel.TRACE);\n    IndexResponse response = esTester.client().prepareIndex(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE)\n      .setSource(FakeIndexDefinition.newDoc(42).getFields())\n      .get();\n    assertThat(response.isCreated()).isTrue();\n    assertThat(logTester.logs()).hasSize(1);\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void index_with_index_type_and_id() {\n    IndexResponse response = esTester.client().prepareIndex(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE)\n      .setSource(FakeIndexDefinition.newDoc(42))\n      .get();\n    assertThat(response.isCreated()).isTrue();\n  }","id":14713,"modified_method":"@Test\n  public void index_with_index_type_and_id() {\n    IndexResponse response = esTester.client().prepareIndex(FakeIndexDefinition.INDEX, FakeIndexDefinition.TYPE)\n      .setSource(FakeIndexDefinition.newDoc(42).getFields())\n      .get();\n    assertThat(response.isCreated()).isTrue();\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void support_long_html_description() throws Exception {\n    String longText = StringUtils.repeat(\"hello  \", 10_000);\n    // the following method fails if PUT fails\n    tester.putDocuments(INDEX, RuleIndexDefinition.TYPE_RULE, ImmutableMap.<String, Object>of(\n      FIELD_RULE_HTML_DESCRIPTION, longText,\n      FIELD_RULE_REPOSITORY, \"squid\",\n      FIELD_RULE_KEY, \"S001\"));\n    assertThat(tester.countDocuments(INDEX, RuleIndexDefinition.TYPE_RULE)).isEqualTo(1);\n\n    List<AnalyzeResponse.AnalyzeToken> tokens = analyzeIndexedTokens(longText);\n    for (AnalyzeResponse.AnalyzeToken token : tokens) {\n      assertThat(token.getTerm().length()).isEqualTo(\"hello\".length());\n    }\n  }","id":14714,"modified_method":"@Test\n  public void support_long_html_description() throws Exception {\n    String longText = StringUtils.repeat(\"hello  \", 10_000);\n    // the following method fails if PUT fails\n    tester.putDocuments(INDEX, RuleIndexDefinition.TYPE_RULE, new RuleDoc(ImmutableMap.<String, Object>of(\n      FIELD_RULE_HTML_DESCRIPTION, longText,\n      FIELD_RULE_REPOSITORY, \"squid\",\n      FIELD_RULE_KEY, \"S001\")));\n    assertThat(tester.countDocuments(INDEX, RuleIndexDefinition.TYPE_RULE)).isEqualTo(1);\n\n    List<AnalyzeResponse.AnalyzeToken> tokens = analyzeIndexedTokens(longText);\n    for (AnalyzeResponse.AnalyzeToken token : tokens) {\n      assertThat(token.getTerm().length()).isEqualTo(\"hello\".length());\n    }\n  }","commit_id":"0e57b7c0a8fa2775e3a48d904f44ac6f7e8bed27","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n    public void testMethodImpl() throws Exception {\n      initEditor(\"2278461409093572745\", \"2278461409093572838\");\n      this.getEditorComponent().getOperationContext().getProject().getModelAccess().executeCommandInEDT(new Runnable() {\n        public void run() {\n          SNodeFactoryOperations.addNewChild(SNodeOperations.cast(TestBody.this.getNodeById(\"2278461409093572746\"), MetaAdapterFactory.getConcept(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f71d1L, \"jetbrains.mps.lang.editor.diagram.testLanguage.structure.NodeWithPorts\")), MetaAdapterFactory.getContainmentLink(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f71d1L, 0x4ce40ecaf41f7252L, \"outputs\"), SNodeFactoryOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f722aL, \"jetbrains.mps.lang.editor.diagram.testLanguage.structure.OutputPort\")));\n        }\n      });\n      ModelAccess.instance().flushEventQueue();\n      {\n        int x_rszpwe_c0 = 87;\n        int y_rszpwe_c0 = 42;\n        Component eventTargetComponent_rszpwe_c0 = this.processMouseEvent(x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_PRESSED);\n        this.processSecondaryMouseEvent(eventTargetComponent_rszpwe_c0, x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_RELEASED);\n        this.processSecondaryMouseEvent(eventTargetComponent_rszpwe_c0, x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_CLICKED);\n      }\n\n    }","id":14715,"modified_method":"@Override\n    public void testMethodImpl() throws Exception {\n      initEditor(\"2278461409093572745\", \"2278461409093572838\");\n      this.getEditorComponent().getEditorContext().getRepository().getModelAccess().executeCommandInEDT(new Runnable() {\n        public void run() {\n          SNodeFactoryOperations.addNewChild(SNodeOperations.cast(TestBody.this.getNodeById(\"2278461409093572746\"), MetaAdapterFactory.getConcept(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f71d1L, \"jetbrains.mps.lang.editor.diagram.testLanguage.structure.NodeWithPorts\")), MetaAdapterFactory.getContainmentLink(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f71d1L, 0x4ce40ecaf41f7252L, \"outputs\"), SNodeFactoryOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0x50560c9658e49c5L, 0xb8e79e4db4c7e97fL, 0x4ce40ecaf41f722aL, \"jetbrains.mps.lang.editor.diagram.testLanguage.structure.OutputPort\")));\n        }\n      });\n      ModelAccess.instance().flushEventQueue();\n      {\n        int x_rszpwe_c0 = 87;\n        int y_rszpwe_c0 = 42;\n        Component eventTargetComponent_rszpwe_c0 = this.processMouseEvent(x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_PRESSED);\n        this.processSecondaryMouseEvent(eventTargetComponent_rszpwe_c0, x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_RELEASED);\n        this.processSecondaryMouseEvent(eventTargetComponent_rszpwe_c0, x_rszpwe_c0, y_rszpwe_c0, MouseEvent.MOUSE_CLICKED);\n      }\n\n    }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"public JavaHighlighters(Project project, MPSCoreComponents coreComponents) {\n    myProject = project;\n  }","id":14716,"modified_method":"public JavaHighlighters(MPSProject project, MPSCoreComponents coreComponents) {\n    myProject = project;\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public void initComponent() {\n    Highlighter highlighter = getHighlighter();\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new OverrideMethodsChecker()));\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new ToDoHighlighter()));\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new MethodDeclarationsFixer()));\n  }","id":14717,"modified_method":"@Override\n  public void initComponent() {\n    Highlighter highlighter = getHighlighter();\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new OverrideMethodsChecker(myProject)));\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new ToDoHighlighter()));\n    highlighter.addChecker(DequeSequence.fromDequeNew(myCheckers).pushElement(new MethodDeclarationsFixer()));\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public boolean hasDramaticalEvent(List<SModelEvent> events) {\n    if (this.myIndexWasNotReady) {\n      return true;\n    }\n    for (SModelEvent event : ListSequence.fromList(events)) {\n      if (event instanceof SModelRootEvent || event instanceof SModelFileChangedEvent) {\n        return true;\n      }\n      if (event instanceof SModelChildEvent) {\n        SModelChildEvent childEvent = (SModelChildEvent) event;\n        SNode child = childEvent.getChild();\n        SNode parent = childEvent.getParent();\n        String childRole = childEvent.getChildRole();\n        // Class or Interface was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, \"jetbrains.mps.baseLanguage.structure.Interface\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, \"jetbrains.mps.baseLanguage.structure.ClassConcept\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, \"jetbrains.mps.baseLanguage.structure.AnonymousClass\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1133e3b449aL, \"jetbrains.mps.baseLanguage.structure.AnonymousClassCreator\"))) {\n          return true;\n        }\n        // method was added/removed from containing Classifier \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b21dL, \"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\")) && SNodeOperations.isInstanceOf(parent, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\"))) {\n          return true;\n        }\n        // one of extendedInterface/superclass/implementedInterface child elements was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\")) && (SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, 0x101eddadad7L, \"extendedInterface\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(childRole) || SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, 0x10f6353296dL, \"superclass\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(childRole) || SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, 0xff2ac0b419L, \"implementedInterface\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(childRole))) {\n          return true;\n        }\n        // parameter was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\")) && SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(childRole)) {\n          return true;\n        }\n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506dL, \"jetbrains.mps.baseLanguage.structure.Type\")) && isParameterType(child)) {\n          return true;\n        }\n      }\n      if (event instanceof SModelReferenceEvent) {\n        SModelReferenceEvent referenceEvent = (SModelReferenceEvent) event;\n        SReference reference = referenceEvent.getReference();\n        SNode sourceNode = reference.getSourceNode();\n        String referenceRole = reference.getRole();\n        if (SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(referenceRole) && SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\")) && (SNodeOperations.isInstanceOf(SNodeOperations.getParent(sourceNode), MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\")))) {\n          return true;\n        }\n        if (SPropertyOperations.getString(SLinkOperations.findLinkDeclaration(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, 0x1107e0fd2a0L, \"classifier\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\")).equals(referenceRole) && SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, \"jetbrains.mps.baseLanguage.structure.AnonymousClass\"))) {\n          return true;\n        }\n        if (SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506dL, \"jetbrains.mps.baseLanguage.structure.Type\")) && isParameterType(sourceNode)) {\n          return true;\n        }\n      }\n      if (event instanceof SModelPropertyEvent) {\n        SModelPropertyEvent propertyEvent = (SModelPropertyEvent) event;\n        SNode node = propertyEvent.getNode();\n        if (SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, \"jetbrains.mps.baseLanguage.structure.BaseMethodDeclaration\"))) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }","id":14718,"modified_method":"@Override\n  public boolean hasDramaticalEvent(List<SModelEvent> events) {\n    if (this.myIndexWasNotReady) {\n      return true;\n    }\n    for (SModelEvent event : ListSequence.fromList(events)) {\n      if (event instanceof SModelRootEvent || event instanceof SModelFileChangedEvent) {\n        return true;\n      }\n      if (event instanceof SModelChildEvent) {\n        SModelChildEvent childEvent = (SModelChildEvent) event;\n        SNode child = childEvent.getChild();\n        SNode parent = childEvent.getParent();\n        String childRole = childEvent.getChildRole();\n        // Class or Interface was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, \"jetbrains.mps.baseLanguage.structure.Interface\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, \"jetbrains.mps.baseLanguage.structure.ClassConcept\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, \"jetbrains.mps.baseLanguage.structure.AnonymousClass\")) || SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1133e3b449aL, \"jetbrains.mps.baseLanguage.structure.AnonymousClassCreator\"))) {\n          return true;\n        }\n        // method was added/removed from containing Classifier \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b21dL, \"jetbrains.mps.baseLanguage.structure.InstanceMethodDeclaration\")) && SNodeOperations.isInstanceOf(parent, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\"))) {\n          return true;\n        }\n        // one of extendedInterface/superclass/implementedInterface child elements was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\")) && (MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, 0x101eddadad7L, \"extendedInterface\").getName().equals(childRole) || MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, 0x10f6353296dL, \"superclass\").getName().equals(childRole) || MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, 0xff2ac0b419L, \"implementedInterface\").getName().equals(childRole))) {\n          return true;\n        }\n        // parameter was added/removed \n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\")) && MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\").getName().equals(childRole)) {\n          return true;\n        }\n        if (SNodeOperations.isInstanceOf(child, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506dL, \"jetbrains.mps.baseLanguage.structure.Type\")) && isParameterType(child)) {\n          return true;\n        }\n      }\n      if (event instanceof SModelReferenceEvent) {\n        SModelReferenceEvent referenceEvent = (SModelReferenceEvent) event;\n        SReference reference = referenceEvent.getReference();\n        SNode sourceNode = reference.getSourceNode();\n        SReferenceLink referenceRole = reference.getLink();\n        if (MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\").equals(referenceRole) && SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\")) && (SNodeOperations.isInstanceOf(SNodeOperations.getParent(sourceNode), MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\")))) {\n          return true;\n        }\n        if (MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, 0x1107e0fd2a0L, \"classifier\").equals(referenceRole) && SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x1107e0cb103L, \"jetbrains.mps.baseLanguage.structure.AnonymousClass\"))) {\n          return true;\n        }\n        if (SNodeOperations.isInstanceOf(sourceNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506dL, \"jetbrains.mps.baseLanguage.structure.Type\")) && isParameterType(sourceNode)) {\n          return true;\n        }\n      }\n      if (event instanceof SModelPropertyEvent) {\n        SModelPropertyEvent propertyEvent = (SModelPropertyEvent) event;\n        SNode node = propertyEvent.getNode();\n        if (SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, \"jetbrains.mps.baseLanguage.structure.BaseMethodDeclaration\"))) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public Set<EditorMessage> createMessages(SNode rootNode, List<SModelEvent> events, boolean wasCheckedOnce, EditorContext editorContext) {\n    Iterable<SNode> classifiers = ListSequence.fromList(SNodeOperations.getNodeDescendants(rootNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\"), true, new SAbstractConcept[]{})).where(new IWhereFilter<SNode>() {\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, \"jetbrains.mps.baseLanguage.structure.ClassConcept\")) || SNodeOperations.isInstanceOf(it, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, \"jetbrains.mps.baseLanguage.structure.Interface\"));\n      }\n    });\n    this.myIndexWasNotReady = !(ClassifierSuccessors.getInstance().isIndexReady(editorContext.getOperationContext().getProject()));\n    if (Sequence.fromIterable(classifiers).isEmpty() || this.myIndexWasNotReady) {\n      return Collections.<EditorMessage>emptySet();\n    }\n    Set<EditorMessage> result = SetSequence.fromSet(new HashSet<EditorMessage>());\n    for (SNode containedClassifier : Sequence.fromIterable(classifiers)) {\n      // each classifier here is instance of ClassConcept or Interface \n      try {\n        collectOverridenMethods(containedClassifier, result);\n      } catch (IndexNotReadyException indexNotReady) {\n        // Catching IndexNotReadyException for now. In general suggestion of IDEA developers was to start using \n        // DaemonCodeAnalyzer for background highlighting processes execution \n        myIndexWasNotReady = true;\n      }\n      collectOverridingMethods(containedClassifier, result);\n    }\n    return result;\n  }","id":14719,"modified_method":"@Override\n  public Set<EditorMessage> createMessages(SNode rootNode, List<SModelEvent> events, boolean wasCheckedOnce, EditorContext editorContext) {\n    Iterable<SNode> classifiers = ListSequence.fromList(SNodeOperations.getNodeDescendants(rootNode, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, \"jetbrains.mps.baseLanguage.structure.Classifier\"), true, new SAbstractConcept[]{})).where(new IWhereFilter<SNode>() {\n      public boolean accept(SNode it) {\n        return SNodeOperations.isInstanceOf(it, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c108ca66L, \"jetbrains.mps.baseLanguage.structure.ClassConcept\")) || SNodeOperations.isInstanceOf(it, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101edd46144L, \"jetbrains.mps.baseLanguage.structure.Interface\"));\n      }\n    });\n    this.myIndexWasNotReady = !(ClassifierSuccessors.getInstance().isIndexReady(myProject));\n    if (Sequence.fromIterable(classifiers).isEmpty() || this.myIndexWasNotReady) {\n      return Collections.<EditorMessage>emptySet();\n    }\n    Set<EditorMessage> result = SetSequence.fromSet(new HashSet<EditorMessage>());\n    for (SNode containedClassifier : Sequence.fromIterable(classifiers)) {\n      // each classifier here is instance of ClassConcept or Interface \n      try {\n        collectOverridenMethods(containedClassifier, result);\n      } catch (IndexNotReadyException indexNotReady) {\n        // Catching IndexNotReadyException for now. In general suggestion of IDEA developers was to start using \n        // DaemonCodeAnalyzer for background highlighting processes execution \n        myIndexWasNotReady = true;\n      }\n      collectOverridingMethods(containedClassifier, result);\n    }\n    return result;\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static JComponent _QueryFunction_JComponent_7uomxw_a1a(final SNode node, final EditorContext editorContext) {\n    final JCheckBox box = new JCheckBox(\"vertical align\");\n    box.setSelected(SPropertyOperations.getBoolean(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\")));\n    Project project = editorContext.getOperationContext().getProject();\n    SRepository repository = project.getRepository();\n    final ModelAccess modelAccess = repository.getModelAccess();\n    box.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent p0) {\n        try {\n          modelAccess.executeCommand(new Runnable() {\n            public void run() {\n              if (box.isSelected()) {\n                SPropertyOperations.set(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\"), \"\" + (true));\n              } else {\n                SPropertyOperations.set(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\"), \"\" + (false));\n              }\n            }\n          });\n        } catch (Exception e) {\n          System.out.println(\"AAAAAAA \" + e);\n        }\n      }\n    });\n    return box;\n  }","id":14720,"modified_method":"private static JComponent _QueryFunction_JComponent_7uomxw_a1a(final SNode node, final EditorContext editorContext) {\n    final JCheckBox box = new JCheckBox(\"vertical align\");\n    box.setSelected(SPropertyOperations.getBoolean(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\")));\n    SRepository repository = editorContext.getRepository();\n    final ModelAccess modelAccess = repository.getModelAccess();\n    box.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent p0) {\n        try {\n          modelAccess.executeCommand(new Runnable() {\n            public void run() {\n              if (box.isSelected()) {\n                SPropertyOperations.set(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\"), \"\" + (true));\n              } else {\n                SPropertyOperations.set(node, MetaAdapterFactory.getProperty(0xb4dbff0c8c314a79L, 0xa45a98e5fd0530e7L, 0x4a1cc65caa543033L, 0x3752e6616e34d13dL, \"vertical\"), \"\" + (false));\n              }\n            }\n          });\n        } catch (Exception e) {\n          System.out.println(\"AAAAAAA \" + e);\n        }\n      }\n    });\n    return box;\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n    public Editor open(IOperationContext context, final SNode node) {\n      Set<RelationDescriptor> tabs = new HashSet<RelationDescriptor>();\n\n      for (RelationDescriptor d : getTabDescriptors()) {\n        if (d.isApplicable(node)) {\n          tabs.add(d);\n        }\n      }\n\n      // could use myMpsProject here, but generally project should come through EditorOpenHandler\n      return new TabbedEditor(new jetbrains.mps.smodel.SNodePointer(node), tabs, context.getProject());\n    }","id":14721,"modified_method":"@Override\n    public Editor open(IOperationContext context, final SNode node) {\n      Set<RelationDescriptor> tabs = new HashSet<RelationDescriptor>();\n\n      for (RelationDescriptor d : getTabDescriptors()) {\n        if (d.isApplicable(node)) {\n          tabs.add(d);\n        }\n      }\n\n      // could use myMpsProject here, but generally project should come through EditorOpenHandler\n      return new TabbedEditor(node.getReference(), tabs, myMpsProject);\n    }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"public PropertyMapperCell(EditorContext editorContext, SNode node) {\n    super(editorContext, node);\n    myModelProperty = new WritableModelProperty<T>(getCellId() + \"_\" + node.getNodeId().toString(), getContext().getOperationContext().getProject()) {\n      protected T getModelPropertyValue() {\n        return getModelPropertyValueImpl();\n      }\n      protected void setModelPropertyValue(T value) {\n        setModelPropertyValueImpl(value);\n      }\n    };\n    addModelProperty(myModelProperty);\n  }","id":14722,"modified_method":"public PropertyMapperCell(EditorContext editorContext, SNode node) {\n    super(editorContext, node);\n    myModelProperty = new WritableModelProperty<T>(getCellId() + \"_\" + node.getNodeId().toString(), getContext().getRepository()) {\n      protected T getModelPropertyValue() {\n        return getModelPropertyValueImpl();\n      }\n      protected void setModelPropertyValue(T value) {\n        setModelPropertyValueImpl(value);\n      }\n    };\n    addModelProperty(myModelProperty);\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected void safeSetModelPropertyValue(final T t) {\n    myProject.getModelAccess().executeCommand(new UndoRunnable.Base(null, myCommandId) {\n      public void run() {\n        setModelPropertyValue(t);\n      }\n    });\n  }","id":14723,"modified_method":"protected void safeSetModelPropertyValue(final T t) {\n    myRepo.getModelAccess().executeCommand(new UndoRunnable.Base(null, myCommandId) {\n      public void run() {\n        setModelPropertyValue(t);\n      }\n    });\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"public WritableModelProperty(String commandId, Project project) {\n    myCommandId = commandId;\n    myProject = project;\n    addHandler(new EventHandler<PropertyChangeEvent<T>>() {\n      public void onEvent(PropertyChangeEvent<T> event) {\n        safeSetModelPropertyValue(event.getNewValue());\n      }\n    });\n  }","id":14724,"modified_method":"public WritableModelProperty(String commandId, SRepository repository) {\n    myCommandId = commandId;\n    myRepo = repository;\n    addHandler(new EventHandler<PropertyChangeEvent<T>>() {\n      public void onEvent(PropertyChangeEvent<T> event) {\n        safeSetModelPropertyValue(event.getNewValue());\n      }\n    });\n  }","commit_id":"322eb59ac6652a798a9535505fa4e1df1489edc2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@SuppressWarnings({ \"unchecked\" })\n  public Counter<SurfacePattern> getPatterns(String label, Set<SurfacePattern> alreadyIdentifiedPatterns, SurfacePattern p0, Counter<String> p0Set,\n      Set<SurfacePattern> ignorePatterns) throws InterruptedException, ExecutionException, IOException, ClassNotFoundException,\n      InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchMethodException, SecurityException {\n\n    TwoDimensionalCounter<SurfacePattern, String> patternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> posnegPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> unLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negandUnLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> allPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n\n    if (!constVars.batchProcessSents) {\n      // if not batch processing\n      if (this.patternsForEachToken == null) {\n        // if patterns for each token null\n        if (constVars.computeAllPatterns) {\n          Redwood.log(Redwood.DBG, \"Computing all patterns\");\n          this.patternsForEachToken = createPats.getAllPatterns(label, Data.sents);\n        } else {\n          // read from the saved file\n          this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n          Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n        }\n      }\n      this.calculateSufficientStats(Data.sents, patternsForEachToken, label, patternsandWords4Label, posnegPatternsandWords4Label,\n          allPatternsandWords4Label, negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n    }\n    // batch processing sentences\n    else {\n\n      for (File f : Data.sentsFiles) {\n\n        Redwood.log(Redwood.DBG, (constVars.computeAllPatterns ? \"Creating patterns and \" : \"\") + \"calculating sufficient statistics from \" + f);\n\n        Map<String, List<CoreLabel>> sents = IOUtils.readObjectFromFile(f);\n\n        Map<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>> pats4File = null;\n\n        if (constVars.computeAllPatterns) {\n          if (this.patternsForEachToken == null)\n            this.patternsForEachToken = new HashMap<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>>();\n          pats4File = createPats.getAllPatterns(label, sents);\n          this.patternsForEachToken.putAll(pats4File);\n        } else {\n          if (this.patternsForEachToken == null) {\n            // read only for the first time\n            this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n            Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n          }\n          pats4File = this.patternsForEachToken;\n        }\n\n        this.calculateSufficientStats(sents, pats4File, label, patternsandWords4Label, posnegPatternsandWords4Label, allPatternsandWords4Label,\n            negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n      }\n    }\n    if (constVars.computeAllPatterns && constVars.allPatternsFile != null) {\n      IOUtils.writeObjectToFile(this.patternsForEachToken, constVars.allPatternsFile);\n    }\n\n    if (patternsandWords == null)\n      patternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (allPatternsandWords == null)\n      allPatternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (currentPatternWeights == null)\n      currentPatternWeights = new HashMap<String, Counter<SurfacePattern>>();\n\n    Counter<SurfacePattern> currentPatternWeights4Label = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePats = enforceMinSupportRequirements(patternsandWords4Label, unLabeledPatternsandWords4Label);\n    Counters.removeKeys(patternsandWords4Label, removePats);\n    Counters.removeKeys(unLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(negandUnLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(allPatternsandWords4Label, removePats);\n    Counters.removeKeys(posnegPatternsandWords4Label, removePats);\n    Counters.removeKeys(negPatternsandWords4Label, removePats);\n\n    // Redwood.log(ConstantsAndVariables.extremedebug,\n    // \"Patterns around positive words in the label \" + label + \" are \" +\n    // patternsandWords4Label);\n    ScorePatterns scorePatterns;\n\n    Class<?> patternscoringclass = getPatternScoringClass(constVars.patternScoring);\n    // One of the baseline measures\n\n    if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsF1.class)) {\n      scorePatterns = new ScorePatternsF1(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props, p0Set, p0);\n      Counter<SurfacePattern> finalPat = scorePatterns.score();\n      Counters.removeKeys(finalPat, alreadyIdentifiedPatterns);\n      Counters.retainNonZeros(finalPat);\n      Counters.retainTop(finalPat, 1);\n      if (Double.isNaN(Counters.max(finalPat)))\n        throw new RuntimeException(\"how is the value NaN\");\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Selected Pattern: \" + finalPat);\n      return finalPat;\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsRatioModifiedFreq.class)) {\n      scorePatterns = new ScorePatternsRatioModifiedFreq(constVars, constVars.patternScoring, label, patternsandWords4Label,\n          negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label,\n          phInPatScores, scorePhrases, props);\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsFreqBased.class)) {\n      scorePatterns = new ScorePatternsFreqBased(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n    } else if (constVars.patternScoring.equals(PatternScoring.kNN)) {\n      try {\n        Class<? extends ScorePatterns> clazz = (Class<? extends ScorePatterns>) Class.forName(\"edu.stanford.nlp.patterns.surface.ScorePatternsKNN\");\n        Constructor<? extends ScorePatterns> ctor = clazz.getConstructor(ConstantsAndVariables.class, PatternScoring.class, String.class,\n            TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class,\n            TwoDimensionalCounter.class, Properties.class);\n        scorePatterns = ctor.newInstance(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n            unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n      } catch (ClassNotFoundException e) {\n        throw new RuntimeException(\"kNN pattern scoring is not released yet. Stay tuned.\");\n      } catch (NoSuchMethodException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InvocationTargetException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (IllegalAccessException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InstantiationException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      }\n    } else {\n      throw new RuntimeException(constVars.patternScoring + \" is not implemented (check spelling?). \");\n    }\n\n    scorePatterns.setUp(props);\n    currentPatternWeights4Label = scorePatterns.score();\n\n    Redwood.log(ConstantsAndVariables.extremedebug, \"patterns counter size is \" + currentPatternWeights4Label.size());\n\n    if (ignorePatterns != null && !ignorePatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, ignorePatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing patterns from ignorePatterns of size  \" + ignorePatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    if (alreadyIdentifiedPatterns != null && !alreadyIdentifiedPatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, alreadyIdentifiedPatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns of size  \" + alreadyIdentifiedPatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    PriorityQueue<SurfacePattern> q = Counters.toPriorityQueue(currentPatternWeights4Label);\n    int num = 0;\n\n    Counter<SurfacePattern> chosenPat = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePatterns = new HashSet<SurfacePattern>();\n    \n    Set<SurfacePattern> removeIdentifiedPatterns = null;\n    \n    while (num < constVars.numPatterns && !q.isEmpty()) {\n      SurfacePattern pat = q.removeFirst();\n      if (currentPatternWeights4Label.getCount(pat) < constVars.thresholdSelectPattern) {\n        Redwood.log(Redwood.DBG, \"The max weight of candidate patterns is \" + df.format(currentPatternWeights4Label.getCount(pat))\n            + \" so not adding anymore patterns\");\n        break;\n      }\n      boolean notchoose = false;\n      if (!unLabeledPatternsandWords4Label.containsFirstKey(pat) || unLabeledPatternsandWords4Label.getCounter(pat).isEmpty()) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing pattern \" + pat + \" because it has no unlab support; pos words: \"\n            + patternsandWords4Label.getCounter(pat) + \" and all words \" + allPatternsandWords4Label.getCounter(pat));\n        notchoose = true;\n        continue;\n      }\n\n      Set<SurfacePattern> removeChosenPats = null;\n\n      if (!notchoose) {\n        if (alreadyIdentifiedPatterns != null) {\n          for (SurfacePattern p : alreadyIdentifiedPatterns) {\n            if (SurfacePattern.subsumes(pat, p)) {\n              // if (pat.getNextContextStr().contains(p.getNextContextStr()) &&\n              // pat.getPrevContextStr().contains(p.getPrevContextStr())) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              break;\n            }\n\n            int rest = pat.equalContext(p);\n            // the contexts dont match\n            if (rest == Integer.MAX_VALUE)\n              continue;\n            // if pat is less restrictive, remove p and add pat!\n            if (rest < 0) {\n              if(removeIdentifiedPatterns == null)\n                removeIdentifiedPatterns = new HashSet<SurfacePattern>();\n              \n              removeIdentifiedPatterns.add(p);\n            } else {\n              notchoose = true;\n              break;\n            }\n          }\n        }\n      }\n\n      // In this iteration:\n      if (!notchoose) {\n        for (SurfacePattern p : chosenPat.keySet()) {\n          boolean removeChosenPatFlag = false;\n          if (SurfacePattern.sameGenre(pat, p)) {\n            boolean sub = SurfacePattern.subsumes(pat, p);\n            boolean sub2 = SurfacePattern.subsumes(pat, p);\n            System.out.println(\"subsume is \" + sub + \" and subsume2 is \" + sub2  + \" for comparing \" + pat + \" and \" + p);\n            //if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n              System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                  + SurfacePattern.subsumes(pat, p) + \" sub was \" + sub + \" and sub2 was \" + sub2);\n              \n            //}\n            if (sub) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              \n              if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n                System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                    + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose);\n                \n              }\n              \n              break;\n            } \n//            else if (SurfacePattern.subsumes(p, pat)) {\n//              //subsume is true even if equal context\n//              //check if equal context\n//              int rest = pat.equalContext(p);\n//\n//              // the contexts dont match\n//              if (rest == Integer.MAX_VALUE)\n//              {\n//                Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + p\n//                    + \" because it is contained in or contains another chosen pattern in this iteration \" + pat);  \n//                removeChosenPatFlag = true;\n//              }\n//              // if pat is less restrictive, remove p from chosen patterns and\n//              // add pat!\n//              else if (rest < 0) {\n//                removeChosenPatFlag = true;\n//              } else {\n//                notchoose = true;\n//                break;\n//              }\n//            } \n            \n            if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n              System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                  + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose + \" sub was \" + sub + \" and sub2 was \" + sub2);\n              \n            }\n            \n            if (removeChosenPatFlag) {\n              if(removeChosenPats == null)\n                removeChosenPats = new HashSet<SurfacePattern>();\n              removeChosenPats.add(p);\n              num--;\n            }\n\n          }\n        }\n      }\n      \n      if (notchoose) {\n        Redwood.log(Redwood.DBG, \"Not choosing \" + pat + \" for whatever reason!\");\n        continue;\n      }\n\n      if (removeChosenPats != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already chosen patterns in this iteration \" + removeChosenPats + \" in favor of \"\n            + pat);\n        Counters.removeKeys(chosenPat, removeChosenPats);\n      }\n      \n      if (removeIdentifiedPatterns != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns \" + removeIdentifiedPatterns + \" in favor of \" + pat);\n        removePatterns.addAll(removeIdentifiedPatterns);\n\n      }\n      \n      chosenPat.setCount(pat, currentPatternWeights4Label.getCount(pat));\n      num++;\n      \n    }\n\n    this.removeLearnedPatterns(label, removePatterns);\n\n    Redwood.log(Redwood.DBG, \"final size of the patterns is \" + chosenPat.size());\n    Redwood.log(ConstantsAndVariables.minimaldebug, \"## Selected Patterns ## \\n\");\n    List<Pair<SurfacePattern, Double>> chosenPatSorted = Counters.toSortedListWithCounts(chosenPat);\n    for (Pair<SurfacePattern, Double> en : chosenPatSorted)\n      Redwood.log(ConstantsAndVariables.minimaldebug, en.first().toStringToWrite() + \":\" + df.format(en.second) + \"\\n\");\n\n    if (constVars.outDir != null && !constVars.outDir.isEmpty()) {\n      CollectionValuedMap<SurfacePattern, String> posWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : patternsandWords4Label.entrySet()) {\n        posWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n\n      CollectionValuedMap<SurfacePattern, String> negWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : negPatternsandWords4Label.entrySet()) {\n        negWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      CollectionValuedMap<SurfacePattern, String> unlabWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : unLabeledPatternsandWords4Label.entrySet()) {\n        unlabWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      String outputdir = constVars.outDir + \"/\" + constVars.identifier + \"/\" + label;\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Saving output in \" + outputdir);\n\n      IOUtils.ensureDir(new File(outputdir));\n\n      String filename = outputdir + \"/patterns\" + \".json\";\n\n      JsonArrayBuilder obj = Json.createArrayBuilder();\n      if (writtenPatInJustification.containsKey(label) && writtenPatInJustification.get(label)) {\n        JsonReader jsonReader = Json.createReader(new BufferedInputStream(new FileInputStream(filename)));\n        JsonArray objarr = jsonReader.readArray();\n        jsonReader.close();\n        for (JsonValue o : objarr)\n          obj.add(o);\n      } else\n        obj = Json.createArrayBuilder();\n\n      JsonObjectBuilder objThisIter = Json.createObjectBuilder();\n      for (Pair<SurfacePattern, Double> pat : chosenPatSorted) {\n        JsonObjectBuilder o = Json.createObjectBuilder();\n        JsonArrayBuilder pos = Json.createArrayBuilder();\n        JsonArrayBuilder neg = Json.createArrayBuilder();\n        JsonArrayBuilder unlab = Json.createArrayBuilder();\n\n        for (String w : posWords.get(pat.first()))\n          pos.add(w);\n        for (String w : negWords.get(pat.first()))\n          neg.add(w);\n        for (String w : unlabWords.get(pat.first()))\n          unlab.add(w);\n\n        o.add(\"Positive\", pos);\n        o.add(\"Negative\", neg);\n        o.add(\"Unlabeled\", unlab);\n        o.add(\"Score\", pat.second());\n\n        objThisIter.add(pat.first().toStringSimple(), o);\n      }\n      obj.add(objThisIter.build());\n\n      IOUtils.ensureDir(new File(filename).getParentFile());\n      IOUtils.writeStringToFile(obj.build().toString(), filename, \"utf8\");\n      writtenPatInJustification.put(label, true);\n    }\n\n    if (constVars.justify) {\n      Redwood.log(Redwood.DBG, \"Justification for Patterns:\");\n      for (SurfacePattern key : chosenPat.keySet()) {\n        Redwood.log(Redwood.DBG, \"\\nPattern: \" + key.toStringToWrite());\n        Redwood.log(\n            Redwood.DBG,\n            \"Positive Words:\"\n                + Counters.toSortedString(patternsandWords4Label.getCounter(key), patternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\", \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Negative Words:\"\n                + Counters.toSortedString(negPatternsandWords4Label.getCounter(key), negPatternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\",\n                    \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Unlabeled Words:\"\n                + Counters.toSortedString(unLabeledPatternsandWords4Label.getCounter(key), unLabeledPatternsandWords4Label.getCounter(key).size(),\n                    \"%1$s:%2$f\", \";\"));\n      }\n    }\n    allPatternsandWords.put(label, allPatternsandWords4Label);\n    patternsandWords.put(label, patternsandWords4Label);\n    currentPatternWeights.put(label, currentPatternWeights4Label);\n\n    return chosenPat;\n\n  }","id":14725,"modified_method":"@SuppressWarnings({ \"unchecked\" })\n  public Counter<SurfacePattern> getPatterns(String label, Set<SurfacePattern> alreadyIdentifiedPatterns, SurfacePattern p0, Counter<String> p0Set,\n      Set<SurfacePattern> ignorePatterns) throws InterruptedException, ExecutionException, IOException, ClassNotFoundException,\n      InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchMethodException, SecurityException {\n\n    TwoDimensionalCounter<SurfacePattern, String> patternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> posnegPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> unLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negandUnLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> allPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n\n    if (!constVars.batchProcessSents) {\n      // if not batch processing\n      if (this.patternsForEachToken == null) {\n        // if patterns for each token null\n        if (constVars.computeAllPatterns) {\n          Redwood.log(Redwood.DBG, \"Computing all patterns\");\n          this.patternsForEachToken = createPats.getAllPatterns(label, Data.sents);\n        } else {\n          // read from the saved file\n          this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n          Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n        }\n      }\n      this.calculateSufficientStats(Data.sents, patternsForEachToken, label, patternsandWords4Label, posnegPatternsandWords4Label,\n          allPatternsandWords4Label, negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n    }\n    // batch processing sentences\n    else {\n\n      for (File f : Data.sentsFiles) {\n\n        Redwood.log(Redwood.DBG, (constVars.computeAllPatterns ? \"Creating patterns and \" : \"\") + \"calculating sufficient statistics from \" + f);\n\n        Map<String, List<CoreLabel>> sents = IOUtils.readObjectFromFile(f);\n\n        Map<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>> pats4File = null;\n\n        if (constVars.computeAllPatterns) {\n          if (this.patternsForEachToken == null)\n            this.patternsForEachToken = new HashMap<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>>();\n          pats4File = createPats.getAllPatterns(label, sents);\n          this.patternsForEachToken.putAll(pats4File);\n        } else {\n          if (this.patternsForEachToken == null) {\n            // read only for the first time\n            this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n            Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n          }\n          pats4File = this.patternsForEachToken;\n        }\n\n        this.calculateSufficientStats(sents, pats4File, label, patternsandWords4Label, posnegPatternsandWords4Label, allPatternsandWords4Label,\n            negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n      }\n    }\n    if (constVars.computeAllPatterns && constVars.allPatternsFile != null) {\n      IOUtils.writeObjectToFile(this.patternsForEachToken, constVars.allPatternsFile);\n    }\n\n    if (patternsandWords == null)\n      patternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (allPatternsandWords == null)\n      allPatternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (currentPatternWeights == null)\n      currentPatternWeights = new HashMap<String, Counter<SurfacePattern>>();\n\n    Counter<SurfacePattern> currentPatternWeights4Label = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePats = enforceMinSupportRequirements(patternsandWords4Label, unLabeledPatternsandWords4Label);\n    Counters.removeKeys(patternsandWords4Label, removePats);\n    Counters.removeKeys(unLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(negandUnLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(allPatternsandWords4Label, removePats);\n    Counters.removeKeys(posnegPatternsandWords4Label, removePats);\n    Counters.removeKeys(negPatternsandWords4Label, removePats);\n\n    // Redwood.log(ConstantsAndVariables.extremedebug,\n    // \"Patterns around positive words in the label \" + label + \" are \" +\n    // patternsandWords4Label);\n    ScorePatterns scorePatterns;\n\n    Class<?> patternscoringclass = getPatternScoringClass(constVars.patternScoring);\n    // One of the baseline measures\n\n    if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsF1.class)) {\n      scorePatterns = new ScorePatternsF1(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props, p0Set, p0);\n      Counter<SurfacePattern> finalPat = scorePatterns.score();\n      Counters.removeKeys(finalPat, alreadyIdentifiedPatterns);\n      Counters.retainNonZeros(finalPat);\n      Counters.retainTop(finalPat, 1);\n      if (Double.isNaN(Counters.max(finalPat)))\n        throw new RuntimeException(\"how is the value NaN\");\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Selected Pattern: \" + finalPat);\n      return finalPat;\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsRatioModifiedFreq.class)) {\n      scorePatterns = new ScorePatternsRatioModifiedFreq(constVars, constVars.patternScoring, label, patternsandWords4Label,\n          negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label,\n          phInPatScores, scorePhrases, props);\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsFreqBased.class)) {\n      scorePatterns = new ScorePatternsFreqBased(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n    } else if (constVars.patternScoring.equals(PatternScoring.kNN)) {\n      try {\n        Class<? extends ScorePatterns> clazz = (Class<? extends ScorePatterns>) Class.forName(\"edu.stanford.nlp.patterns.surface.ScorePatternsKNN\");\n        Constructor<? extends ScorePatterns> ctor = clazz.getConstructor(ConstantsAndVariables.class, PatternScoring.class, String.class,\n            TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class,\n            TwoDimensionalCounter.class, Properties.class);\n        scorePatterns = ctor.newInstance(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n            unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n      } catch (ClassNotFoundException e) {\n        throw new RuntimeException(\"kNN pattern scoring is not released yet. Stay tuned.\");\n      } catch (NoSuchMethodException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InvocationTargetException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (IllegalAccessException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InstantiationException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      }\n    } else {\n      throw new RuntimeException(constVars.patternScoring + \" is not implemented (check spelling?). \");\n    }\n\n    scorePatterns.setUp(props);\n    currentPatternWeights4Label = scorePatterns.score();\n\n    Redwood.log(ConstantsAndVariables.extremedebug, \"patterns counter size is \" + currentPatternWeights4Label.size());\n\n    if (ignorePatterns != null && !ignorePatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, ignorePatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing patterns from ignorePatterns of size  \" + ignorePatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    if (alreadyIdentifiedPatterns != null && !alreadyIdentifiedPatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, alreadyIdentifiedPatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns of size  \" + alreadyIdentifiedPatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    PriorityQueue<SurfacePattern> q = Counters.toPriorityQueue(currentPatternWeights4Label);\n    int num = 0;\n\n    Counter<SurfacePattern> chosenPat = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePatterns = new HashSet<SurfacePattern>();\n    \n    Set<SurfacePattern> removeIdentifiedPatterns = null;\n    \n    while (num < constVars.numPatterns && !q.isEmpty()) {\n      SurfacePattern pat = q.removeFirst();\n      if (currentPatternWeights4Label.getCount(pat) < constVars.thresholdSelectPattern) {\n        Redwood.log(Redwood.DBG, \"The max weight of candidate patterns is \" + df.format(currentPatternWeights4Label.getCount(pat))\n            + \" so not adding anymore patterns\");\n        break;\n      }\n      boolean notchoose = false;\n      if (!unLabeledPatternsandWords4Label.containsFirstKey(pat) || unLabeledPatternsandWords4Label.getCounter(pat).isEmpty()) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing pattern \" + pat + \" because it has no unlab support; pos words: \"\n            + patternsandWords4Label.getCounter(pat) + \" and all words \" + allPatternsandWords4Label.getCounter(pat));\n        notchoose = true;\n        continue;\n      }\n\n      Set<SurfacePattern> removeChosenPats = null;\n\n      if (!notchoose) {\n        if (alreadyIdentifiedPatterns != null) {\n          for (SurfacePattern p : alreadyIdentifiedPatterns) {\n            if (SurfacePattern.subsumes(pat, p)) {\n              // if (pat.getNextContextStr().contains(p.getNextContextStr()) &&\n              // pat.getPrevContextStr().contains(p.getPrevContextStr())) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              break;\n            }\n\n            int rest = pat.equalContext(p);\n            // the contexts dont match\n            if (rest == Integer.MAX_VALUE)\n              continue;\n            // if pat is less restrictive, remove p and add pat!\n            if (rest < 0) {\n              if(removeIdentifiedPatterns == null)\n                removeIdentifiedPatterns = new HashSet<SurfacePattern>();\n              \n              removeIdentifiedPatterns.add(p);\n            } else {\n              notchoose = true;\n              break;\n            }\n          }\n        }\n      }\n\n      // In this iteration:\n      if (!notchoose) {\n        for (SurfacePattern p : chosenPat.keySet()) {\n          boolean removeChosenPatFlag = false;\n          if (SurfacePattern.sameGenre(pat, p)) {\n            \n            if(SurfacePattern.subsumes(pat, p)){\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              \n              if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n                System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                    + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose);\n                \n              }\n              \n              break;\n            } \n            else if (SurfacePattern.subsumes(p, pat)) {\n              //subsume is true even if equal context\n              \n              //check if equal context\n              int rest = pat.equalContext(p);\n\n              // the contexts do not match\n              if (rest == Integer.MAX_VALUE)\n              {\n                Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + p\n                    + \" because it is contained in or contains another chosen pattern in this iteration \" + pat);  \n                removeChosenPatFlag = true;\n              }\n              // if pat is less restrictive, remove p from chosen patterns and\n              // add pat!\n              else if (rest < 0) {\n                removeChosenPatFlag = true;\n              } else {\n                notchoose = true;\n                break;\n              }\n            } \n\n            \n            if (removeChosenPatFlag) {\n              if(removeChosenPats == null)\n                removeChosenPats = new HashSet<SurfacePattern>();\n              removeChosenPats.add(p);\n              num--;\n            }\n\n          }\n        }\n      }\n      \n      if (notchoose) {\n        Redwood.log(Redwood.DBG, \"Not choosing \" + pat + \" for whatever reason!\");\n        continue;\n      }\n\n      if (removeChosenPats != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already chosen patterns in this iteration \" + removeChosenPats + \" in favor of \"\n            + pat);\n        Counters.removeKeys(chosenPat, removeChosenPats);\n      }\n      \n      if (removeIdentifiedPatterns != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns \" + removeIdentifiedPatterns + \" in favor of \" + pat);\n        removePatterns.addAll(removeIdentifiedPatterns);\n\n      }\n      \n      chosenPat.setCount(pat, currentPatternWeights4Label.getCount(pat));\n      num++;\n      \n    }\n\n    this.removeLearnedPatterns(label, removePatterns);\n\n    Redwood.log(Redwood.DBG, \"final size of the patterns is \" + chosenPat.size());\n    Redwood.log(ConstantsAndVariables.minimaldebug, \"## Selected Patterns ## \\n\");\n    List<Pair<SurfacePattern, Double>> chosenPatSorted = Counters.toSortedListWithCounts(chosenPat);\n    for (Pair<SurfacePattern, Double> en : chosenPatSorted)\n      Redwood.log(ConstantsAndVariables.minimaldebug, en.first().toStringToWrite() + \":\" + df.format(en.second) + \"\\n\");\n\n    if (constVars.outDir != null && !constVars.outDir.isEmpty()) {\n      CollectionValuedMap<SurfacePattern, String> posWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : patternsandWords4Label.entrySet()) {\n        posWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n\n      CollectionValuedMap<SurfacePattern, String> negWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : negPatternsandWords4Label.entrySet()) {\n        negWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      CollectionValuedMap<SurfacePattern, String> unlabWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : unLabeledPatternsandWords4Label.entrySet()) {\n        unlabWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      String outputdir = constVars.outDir + \"/\" + constVars.identifier + \"/\" + label;\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Saving output in \" + outputdir);\n\n      IOUtils.ensureDir(new File(outputdir));\n\n      String filename = outputdir + \"/patterns\" + \".json\";\n\n      JsonArrayBuilder obj = Json.createArrayBuilder();\n      if (writtenPatInJustification.containsKey(label) && writtenPatInJustification.get(label)) {\n        JsonReader jsonReader = Json.createReader(new BufferedInputStream(new FileInputStream(filename)));\n        JsonArray objarr = jsonReader.readArray();\n        jsonReader.close();\n        for (JsonValue o : objarr)\n          obj.add(o);\n      } else\n        obj = Json.createArrayBuilder();\n\n      JsonObjectBuilder objThisIter = Json.createObjectBuilder();\n      for (Pair<SurfacePattern, Double> pat : chosenPatSorted) {\n        JsonObjectBuilder o = Json.createObjectBuilder();\n        JsonArrayBuilder pos = Json.createArrayBuilder();\n        JsonArrayBuilder neg = Json.createArrayBuilder();\n        JsonArrayBuilder unlab = Json.createArrayBuilder();\n\n        for (String w : posWords.get(pat.first()))\n          pos.add(w);\n        for (String w : negWords.get(pat.first()))\n          neg.add(w);\n        for (String w : unlabWords.get(pat.first()))\n          unlab.add(w);\n\n        o.add(\"Positive\", pos);\n        o.add(\"Negative\", neg);\n        o.add(\"Unlabeled\", unlab);\n        o.add(\"Score\", pat.second());\n\n        objThisIter.add(pat.first().toStringSimple(), o);\n      }\n      obj.add(objThisIter.build());\n\n      IOUtils.ensureDir(new File(filename).getParentFile());\n      IOUtils.writeStringToFile(obj.build().toString(), filename, \"utf8\");\n      writtenPatInJustification.put(label, true);\n    }\n\n    if (constVars.justify) {\n      Redwood.log(Redwood.DBG, \"Justification for Patterns:\");\n      for (SurfacePattern key : chosenPat.keySet()) {\n        Redwood.log(Redwood.DBG, \"\\nPattern: \" + key.toStringToWrite());\n        Redwood.log(\n            Redwood.DBG,\n            \"Positive Words:\"\n                + Counters.toSortedString(patternsandWords4Label.getCounter(key), patternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\", \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Negative Words:\"\n                + Counters.toSortedString(negPatternsandWords4Label.getCounter(key), negPatternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\",\n                    \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Unlabeled Words:\"\n                + Counters.toSortedString(unLabeledPatternsandWords4Label.getCounter(key), unLabeledPatternsandWords4Label.getCounter(key).size(),\n                    \"%1$s:%2$f\", \";\"));\n      }\n    }\n    allPatternsandWords.put(label, allPatternsandWords4Label);\n    patternsandWords.put(label, patternsandWords4Label);\n    currentPatternWeights.put(label, currentPatternWeights4Label);\n\n    return chosenPat;\n\n  }","commit_id":"dc0200d902c2e99405aaaa240c33da982dc685e2","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"@SuppressWarnings({ \"unchecked\" })\n  public Counter<SurfacePattern> getPatterns(String label, Set<SurfacePattern> alreadyIdentifiedPatterns, SurfacePattern p0, Counter<String> p0Set,\n      Set<SurfacePattern> ignorePatterns) throws InterruptedException, ExecutionException, IOException, ClassNotFoundException,\n      InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchMethodException, SecurityException {\n\n    TwoDimensionalCounter<SurfacePattern, String> patternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> posnegPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> unLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negandUnLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> allPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n\n    if (!constVars.batchProcessSents) {\n      // if not batch processing\n      if (this.patternsForEachToken == null) {\n        // if patterns for each token null\n        if (constVars.computeAllPatterns) {\n          Redwood.log(Redwood.DBG, \"Computing all patterns\");\n          this.patternsForEachToken = createPats.getAllPatterns(label, Data.sents);\n        } else {\n          // read from the saved file\n          this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n          Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n        }\n      }\n      this.calculateSufficientStats(Data.sents, patternsForEachToken, label, patternsandWords4Label, posnegPatternsandWords4Label,\n          allPatternsandWords4Label, negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n    }\n    // batch processing sentences\n    else {\n\n      for (File f : Data.sentsFiles) {\n\n        Redwood.log(Redwood.DBG, (constVars.computeAllPatterns ? \"Creating patterns and \" : \"\") + \"calculating sufficient statistics from \" + f);\n\n        Map<String, List<CoreLabel>> sents = IOUtils.readObjectFromFile(f);\n\n        Map<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>> pats4File = null;\n\n        if (constVars.computeAllPatterns) {\n          if (this.patternsForEachToken == null)\n            this.patternsForEachToken = new HashMap<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>>();\n          pats4File = createPats.getAllPatterns(label, sents);\n          this.patternsForEachToken.putAll(pats4File);\n        } else {\n          if (this.patternsForEachToken == null) {\n            // read only for the first time\n            this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n            Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n          }\n          pats4File = this.patternsForEachToken;\n        }\n\n        this.calculateSufficientStats(sents, pats4File, label, patternsandWords4Label, posnegPatternsandWords4Label, allPatternsandWords4Label,\n            negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n      }\n    }\n    if (constVars.computeAllPatterns && constVars.allPatternsFile != null) {\n      IOUtils.writeObjectToFile(this.patternsForEachToken, constVars.allPatternsFile);\n    }\n\n    if (patternsandWords == null)\n      patternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (allPatternsandWords == null)\n      allPatternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (currentPatternWeights == null)\n      currentPatternWeights = new HashMap<String, Counter<SurfacePattern>>();\n\n    Counter<SurfacePattern> currentPatternWeights4Label = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePats = enforceMinSupportRequirements(patternsandWords4Label, unLabeledPatternsandWords4Label);\n    Counters.removeKeys(patternsandWords4Label, removePats);\n    Counters.removeKeys(unLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(negandUnLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(allPatternsandWords4Label, removePats);\n    Counters.removeKeys(posnegPatternsandWords4Label, removePats);\n    Counters.removeKeys(negPatternsandWords4Label, removePats);\n\n    // Redwood.log(ConstantsAndVariables.extremedebug,\n    // \"Patterns around positive words in the label \" + label + \" are \" +\n    // patternsandWords4Label);\n    ScorePatterns scorePatterns;\n\n    Class<?> patternscoringclass = getPatternScoringClass(constVars.patternScoring);\n    // One of the baseline measures\n\n    if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsF1.class)) {\n      scorePatterns = new ScorePatternsF1(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props, p0Set, p0);\n      Counter<SurfacePattern> finalPat = scorePatterns.score();\n      Counters.removeKeys(finalPat, alreadyIdentifiedPatterns);\n      Counters.retainNonZeros(finalPat);\n      Counters.retainTop(finalPat, 1);\n      if (Double.isNaN(Counters.max(finalPat)))\n        throw new RuntimeException(\"how is the value NaN\");\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Selected Pattern: \" + finalPat);\n      return finalPat;\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsRatioModifiedFreq.class)) {\n      scorePatterns = new ScorePatternsRatioModifiedFreq(constVars, constVars.patternScoring, label, patternsandWords4Label,\n          negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label,\n          phInPatScores, scorePhrases, props);\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsFreqBased.class)) {\n      scorePatterns = new ScorePatternsFreqBased(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n    } else if (constVars.patternScoring.equals(PatternScoring.kNN)) {\n      try {\n        Class<? extends ScorePatterns> clazz = (Class<? extends ScorePatterns>) Class.forName(\"edu.stanford.nlp.patterns.surface.ScorePatternsKNN\");\n        Constructor<? extends ScorePatterns> ctor = clazz.getConstructor(ConstantsAndVariables.class, PatternScoring.class, String.class,\n            TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class,\n            TwoDimensionalCounter.class, Properties.class);\n        scorePatterns = ctor.newInstance(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n            unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n      } catch (ClassNotFoundException e) {\n        throw new RuntimeException(\"kNN pattern scoring is not released yet. Stay tuned.\");\n      } catch (NoSuchMethodException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InvocationTargetException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (IllegalAccessException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InstantiationException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      }\n    } else {\n      throw new RuntimeException(constVars.patternScoring + \" is not implemented (check spelling?). \");\n    }\n\n    scorePatterns.setUp(props);\n    currentPatternWeights4Label = scorePatterns.score();\n\n    Redwood.log(ConstantsAndVariables.extremedebug, \"patterns counter size is \" + currentPatternWeights4Label.size());\n\n    if (ignorePatterns != null && !ignorePatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, ignorePatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing patterns from ignorePatterns of size  \" + ignorePatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    if (alreadyIdentifiedPatterns != null && !alreadyIdentifiedPatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, alreadyIdentifiedPatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns of size  \" + alreadyIdentifiedPatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    PriorityQueue<SurfacePattern> q = Counters.toPriorityQueue(currentPatternWeights4Label);\n    int num = 0;\n\n    Counter<SurfacePattern> chosenPat = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePatterns = new HashSet<SurfacePattern>();\n    \n    Set<SurfacePattern> removeIdentifiedPatterns = null;\n    \n    while (num < constVars.numPatterns && !q.isEmpty()) {\n      SurfacePattern pat = q.removeFirst();\n      if (currentPatternWeights4Label.getCount(pat) < constVars.thresholdSelectPattern) {\n        Redwood.log(Redwood.DBG, \"The max weight of candidate patterns is \" + df.format(currentPatternWeights4Label.getCount(pat))\n            + \" so not adding anymore patterns\");\n        break;\n      }\n      boolean notchoose = false;\n      if (!unLabeledPatternsandWords4Label.containsFirstKey(pat) || unLabeledPatternsandWords4Label.getCounter(pat).isEmpty()) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing pattern \" + pat + \" because it has no unlab support; pos words: \"\n            + patternsandWords4Label.getCounter(pat) + \" and all words \" + allPatternsandWords4Label.getCounter(pat));\n        notchoose = true;\n        continue;\n      }\n\n      Set<SurfacePattern> removeChosenPats = null;\n\n      if (!notchoose) {\n        if (alreadyIdentifiedPatterns != null) {\n          for (SurfacePattern p : alreadyIdentifiedPatterns) {\n            if (SurfacePattern.subsumes(pat, p)) {\n              // if (pat.getNextContextStr().contains(p.getNextContextStr()) &&\n              // pat.getPrevContextStr().contains(p.getPrevContextStr())) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              break;\n            }\n\n            int rest = pat.equalContext(p);\n            // the contexts dont match\n            if (rest == Integer.MAX_VALUE)\n              continue;\n            // if pat is less restrictive, remove p and add pat!\n            if (rest < 0) {\n              if(removeIdentifiedPatterns == null)\n                removeIdentifiedPatterns = new HashSet<SurfacePattern>();\n              \n              removeIdentifiedPatterns.add(p);\n            } else {\n              notchoose = true;\n              break;\n            }\n          }\n        }\n      }\n\n      // In this iteration:\n      if (!notchoose) {\n        for (SurfacePattern p : chosenPat.keySet()) {\n          boolean removeChosenPatFlag = false;\n          if (SurfacePattern.sameGenre(pat, p)) {\n            boolean sub = SurfacePattern.subsumes(pat, p);\n            boolean sub2 = SurfacePattern.subsumes(pat, p);\n            System.out.println(\"subsume is \" + sub + \" and subsume2 is \" + sub2  + \" for comparing \" + pat + \" and \" + p);\n            //if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n              System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                  + SurfacePattern.subsumes(pat, p) + \" sub was \" + sub + \" and sub2 was \" + sub2);\n              \n            //}\n            if (sub) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              \n              if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n                System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                    + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose);\n                \n              }\n              \n              break;\n            } \n//            else if (SurfacePattern.subsumes(p, pat)) {\n//              //subsume is true even if equal context\n//              //check if equal context\n//              int rest = pat.equalContext(p);\n//\n//              // the contexts dont match\n//              if (rest == Integer.MAX_VALUE)\n//              {\n//                Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + p\n//                    + \" because it is contained in or contains another chosen pattern in this iteration \" + pat);  \n//                removeChosenPatFlag = true;\n//              }\n//              // if pat is less restrictive, remove p from chosen patterns and\n//              // add pat!\n//              else if (rest < 0) {\n//                removeChosenPatFlag = true;\n//              } else {\n//                notchoose = true;\n//                break;\n//              }\n//            } \n            \n            if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n              System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                  + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose + \" sub was \" + sub + \" and sub2 was \" + sub2);\n              \n            }\n            \n            if (removeChosenPatFlag) {\n              if(removeChosenPats == null)\n                removeChosenPats = new HashSet<SurfacePattern>();\n              removeChosenPats.add(p);\n              num--;\n            }\n\n          }\n        }\n      }\n      \n      if (notchoose) {\n        Redwood.log(Redwood.DBG, \"Not choosing \" + pat + \" for whatever reason!\");\n        continue;\n      }\n\n      if (removeChosenPats != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already chosen patterns in this iteration \" + removeChosenPats + \" in favor of \"\n            + pat);\n        Counters.removeKeys(chosenPat, removeChosenPats);\n      }\n      \n      if (removeIdentifiedPatterns != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns \" + removeIdentifiedPatterns + \" in favor of \" + pat);\n        removePatterns.addAll(removeIdentifiedPatterns);\n\n      }\n      \n      chosenPat.setCount(pat, currentPatternWeights4Label.getCount(pat));\n      num++;\n      \n    }\n\n    this.removeLearnedPatterns(label, removePatterns);\n\n    Redwood.log(Redwood.DBG, \"final size of the patterns is \" + chosenPat.size());\n    Redwood.log(ConstantsAndVariables.minimaldebug, \"## Selected Patterns ## \\n\");\n    List<Pair<SurfacePattern, Double>> chosenPatSorted = Counters.toSortedListWithCounts(chosenPat);\n    for (Pair<SurfacePattern, Double> en : chosenPatSorted)\n      Redwood.log(ConstantsAndVariables.minimaldebug, en.first().toStringToWrite() + \":\" + df.format(en.second) + \"\\n\");\n\n    if (constVars.outDir != null && !constVars.outDir.isEmpty()) {\n      CollectionValuedMap<SurfacePattern, String> posWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : patternsandWords4Label.entrySet()) {\n        posWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n\n      CollectionValuedMap<SurfacePattern, String> negWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : negPatternsandWords4Label.entrySet()) {\n        negWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      CollectionValuedMap<SurfacePattern, String> unlabWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : unLabeledPatternsandWords4Label.entrySet()) {\n        unlabWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      String outputdir = constVars.outDir + \"/\" + constVars.identifier + \"/\" + label;\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Saving output in \" + outputdir);\n\n      IOUtils.ensureDir(new File(outputdir));\n\n      String filename = outputdir + \"/patterns\" + \".json\";\n\n      JsonArrayBuilder obj = Json.createArrayBuilder();\n      if (writtenPatInJustification.containsKey(label) && writtenPatInJustification.get(label)) {\n        JsonReader jsonReader = Json.createReader(new BufferedInputStream(new FileInputStream(filename)));\n        JsonArray objarr = jsonReader.readArray();\n        jsonReader.close();\n        for (JsonValue o : objarr)\n          obj.add(o);\n      } else\n        obj = Json.createArrayBuilder();\n\n      JsonObjectBuilder objThisIter = Json.createObjectBuilder();\n      for (Pair<SurfacePattern, Double> pat : chosenPatSorted) {\n        JsonObjectBuilder o = Json.createObjectBuilder();\n        JsonArrayBuilder pos = Json.createArrayBuilder();\n        JsonArrayBuilder neg = Json.createArrayBuilder();\n        JsonArrayBuilder unlab = Json.createArrayBuilder();\n\n        for (String w : posWords.get(pat.first()))\n          pos.add(w);\n        for (String w : negWords.get(pat.first()))\n          neg.add(w);\n        for (String w : unlabWords.get(pat.first()))\n          unlab.add(w);\n\n        o.add(\"Positive\", pos);\n        o.add(\"Negative\", neg);\n        o.add(\"Unlabeled\", unlab);\n        o.add(\"Score\", pat.second());\n\n        objThisIter.add(pat.first().toStringSimple(), o);\n      }\n      obj.add(objThisIter.build());\n\n      IOUtils.ensureDir(new File(filename).getParentFile());\n      IOUtils.writeStringToFile(obj.build().toString(), filename, \"utf8\");\n      writtenPatInJustification.put(label, true);\n    }\n\n    if (constVars.justify) {\n      Redwood.log(Redwood.DBG, \"Justification for Patterns:\");\n      for (SurfacePattern key : chosenPat.keySet()) {\n        Redwood.log(Redwood.DBG, \"\\nPattern: \" + key.toStringToWrite());\n        Redwood.log(\n            Redwood.DBG,\n            \"Positive Words:\"\n                + Counters.toSortedString(patternsandWords4Label.getCounter(key), patternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\", \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Negative Words:\"\n                + Counters.toSortedString(negPatternsandWords4Label.getCounter(key), negPatternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\",\n                    \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Unlabeled Words:\"\n                + Counters.toSortedString(unLabeledPatternsandWords4Label.getCounter(key), unLabeledPatternsandWords4Label.getCounter(key).size(),\n                    \"%1$s:%2$f\", \";\"));\n      }\n    }\n    allPatternsandWords.put(label, allPatternsandWords4Label);\n    patternsandWords.put(label, patternsandWords4Label);\n    currentPatternWeights.put(label, currentPatternWeights4Label);\n\n    return chosenPat;\n\n  }","id":14726,"modified_method":"@SuppressWarnings({ \"unchecked\" })\n  public Counter<SurfacePattern> getPatterns(String label, Set<SurfacePattern> alreadyIdentifiedPatterns, SurfacePattern p0, Counter<String> p0Set,\n      Set<SurfacePattern> ignorePatterns) throws InterruptedException, ExecutionException, IOException, ClassNotFoundException,\n      InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchMethodException, SecurityException {\n\n    TwoDimensionalCounter<SurfacePattern, String> patternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> posnegPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> unLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> negandUnLabeledPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n    TwoDimensionalCounter<SurfacePattern, String> allPatternsandWords4Label = new TwoDimensionalCounter<SurfacePattern, String>();\n\n    if (!constVars.batchProcessSents) {\n      // if not batch processing\n      if (this.patternsForEachToken == null) {\n        // if patterns for each token null\n        if (constVars.computeAllPatterns) {\n          Redwood.log(Redwood.DBG, \"Computing all patterns\");\n          this.patternsForEachToken = createPats.getAllPatterns(label, Data.sents);\n        } else {\n          // read from the saved file\n          this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n          Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n        }\n      }\n      this.calculateSufficientStats(Data.sents, patternsForEachToken, label, patternsandWords4Label, posnegPatternsandWords4Label,\n          allPatternsandWords4Label, negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n    }\n    // batch processing sentences\n    else {\n\n      for (File f : Data.sentsFiles) {\n\n        Redwood.log(Redwood.DBG, (constVars.computeAllPatterns ? \"Creating patterns and \" : \"\") + \"calculating sufficient statistics from \" + f);\n\n        Map<String, List<CoreLabel>> sents = IOUtils.readObjectFromFile(f);\n\n        Map<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>> pats4File = null;\n\n        if (constVars.computeAllPatterns) {\n          if (this.patternsForEachToken == null)\n            this.patternsForEachToken = new HashMap<String, Map<Integer, Triple<Set<SurfacePattern>, Set<SurfacePattern>, Set<SurfacePattern>>>>();\n          pats4File = createPats.getAllPatterns(label, sents);\n          this.patternsForEachToken.putAll(pats4File);\n        } else {\n          if (this.patternsForEachToken == null) {\n            // read only for the first time\n            this.patternsForEachToken = IOUtils.readObjectFromFile(constVars.allPatternsFile);\n            Redwood.log(ConstantsAndVariables.minimaldebug, \"Read all patterns from \" + constVars.allPatternsFile);\n          }\n          pats4File = this.patternsForEachToken;\n        }\n\n        this.calculateSufficientStats(sents, pats4File, label, patternsandWords4Label, posnegPatternsandWords4Label, allPatternsandWords4Label,\n            negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label);\n      }\n    }\n    if (constVars.computeAllPatterns && constVars.allPatternsFile != null) {\n      IOUtils.writeObjectToFile(this.patternsForEachToken, constVars.allPatternsFile);\n    }\n\n    if (patternsandWords == null)\n      patternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (allPatternsandWords == null)\n      allPatternsandWords = new HashMap<String, TwoDimensionalCounter<SurfacePattern, String>>();\n    if (currentPatternWeights == null)\n      currentPatternWeights = new HashMap<String, Counter<SurfacePattern>>();\n\n    Counter<SurfacePattern> currentPatternWeights4Label = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePats = enforceMinSupportRequirements(patternsandWords4Label, unLabeledPatternsandWords4Label);\n    Counters.removeKeys(patternsandWords4Label, removePats);\n    Counters.removeKeys(unLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(negandUnLabeledPatternsandWords4Label, removePats);\n    Counters.removeKeys(allPatternsandWords4Label, removePats);\n    Counters.removeKeys(posnegPatternsandWords4Label, removePats);\n    Counters.removeKeys(negPatternsandWords4Label, removePats);\n\n    // Redwood.log(ConstantsAndVariables.extremedebug,\n    // \"Patterns around positive words in the label \" + label + \" are \" +\n    // patternsandWords4Label);\n    ScorePatterns scorePatterns;\n\n    Class<?> patternscoringclass = getPatternScoringClass(constVars.patternScoring);\n    // One of the baseline measures\n\n    if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsF1.class)) {\n      scorePatterns = new ScorePatternsF1(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props, p0Set, p0);\n      Counter<SurfacePattern> finalPat = scorePatterns.score();\n      Counters.removeKeys(finalPat, alreadyIdentifiedPatterns);\n      Counters.retainNonZeros(finalPat);\n      Counters.retainTop(finalPat, 1);\n      if (Double.isNaN(Counters.max(finalPat)))\n        throw new RuntimeException(\"how is the value NaN\");\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Selected Pattern: \" + finalPat);\n      return finalPat;\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsRatioModifiedFreq.class)) {\n      scorePatterns = new ScorePatternsRatioModifiedFreq(constVars, constVars.patternScoring, label, patternsandWords4Label,\n          negPatternsandWords4Label, unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label,\n          phInPatScores, scorePhrases, props);\n\n    } else if (patternscoringclass != null && patternscoringclass.equals(ScorePatternsFreqBased.class)) {\n      scorePatterns = new ScorePatternsFreqBased(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n          unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n    } else if (constVars.patternScoring.equals(PatternScoring.kNN)) {\n      try {\n        Class<? extends ScorePatterns> clazz = (Class<? extends ScorePatterns>) Class.forName(\"edu.stanford.nlp.patterns.surface.ScorePatternsKNN\");\n        Constructor<? extends ScorePatterns> ctor = clazz.getConstructor(ConstantsAndVariables.class, PatternScoring.class, String.class,\n            TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class, TwoDimensionalCounter.class,\n            TwoDimensionalCounter.class, Properties.class);\n        scorePatterns = ctor.newInstance(constVars, constVars.patternScoring, label, patternsandWords4Label, negPatternsandWords4Label,\n            unLabeledPatternsandWords4Label, negandUnLabeledPatternsandWords4Label, allPatternsandWords4Label, props);\n\n      } catch (ClassNotFoundException e) {\n        throw new RuntimeException(\"kNN pattern scoring is not released yet. Stay tuned.\");\n      } catch (NoSuchMethodException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InvocationTargetException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (IllegalAccessException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      } catch (InstantiationException e) {\n        throw new RuntimeException(\"newinstance of kNN not created\", e);\n      }\n    } else {\n      throw new RuntimeException(constVars.patternScoring + \" is not implemented (check spelling?). \");\n    }\n\n    scorePatterns.setUp(props);\n    currentPatternWeights4Label = scorePatterns.score();\n\n    Redwood.log(ConstantsAndVariables.extremedebug, \"patterns counter size is \" + currentPatternWeights4Label.size());\n\n    if (ignorePatterns != null && !ignorePatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, ignorePatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing patterns from ignorePatterns of size  \" + ignorePatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    if (alreadyIdentifiedPatterns != null && !alreadyIdentifiedPatterns.isEmpty()) {\n      Counters.removeKeys(currentPatternWeights4Label, alreadyIdentifiedPatterns);\n      Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns of size  \" + alreadyIdentifiedPatterns.size()\n          + \". New patterns size \" + currentPatternWeights4Label.size());\n    }\n\n    PriorityQueue<SurfacePattern> q = Counters.toPriorityQueue(currentPatternWeights4Label);\n    int num = 0;\n\n    Counter<SurfacePattern> chosenPat = new ClassicCounter<SurfacePattern>();\n\n    Set<SurfacePattern> removePatterns = new HashSet<SurfacePattern>();\n    \n    Set<SurfacePattern> removeIdentifiedPatterns = null;\n    \n    while (num < constVars.numPatterns && !q.isEmpty()) {\n      SurfacePattern pat = q.removeFirst();\n      if (currentPatternWeights4Label.getCount(pat) < constVars.thresholdSelectPattern) {\n        Redwood.log(Redwood.DBG, \"The max weight of candidate patterns is \" + df.format(currentPatternWeights4Label.getCount(pat))\n            + \" so not adding anymore patterns\");\n        break;\n      }\n      boolean notchoose = false;\n      if (!unLabeledPatternsandWords4Label.containsFirstKey(pat) || unLabeledPatternsandWords4Label.getCounter(pat).isEmpty()) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing pattern \" + pat + \" because it has no unlab support; pos words: \"\n            + patternsandWords4Label.getCounter(pat) + \" and all words \" + allPatternsandWords4Label.getCounter(pat));\n        notchoose = true;\n        continue;\n      }\n\n      Set<SurfacePattern> removeChosenPats = null;\n\n      if (!notchoose) {\n        if (alreadyIdentifiedPatterns != null) {\n          for (SurfacePattern p : alreadyIdentifiedPatterns) {\n            if (SurfacePattern.subsumes(pat, p)) {\n              // if (pat.getNextContextStr().contains(p.getNextContextStr()) &&\n              // pat.getPrevContextStr().contains(p.getPrevContextStr())) {\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              break;\n            }\n\n            int rest = pat.equalContext(p);\n            // the contexts dont match\n            if (rest == Integer.MAX_VALUE)\n              continue;\n            // if pat is less restrictive, remove p and add pat!\n            if (rest < 0) {\n              if(removeIdentifiedPatterns == null)\n                removeIdentifiedPatterns = new HashSet<SurfacePattern>();\n              \n              removeIdentifiedPatterns.add(p);\n            } else {\n              notchoose = true;\n              break;\n            }\n          }\n        }\n      }\n\n      // In this iteration:\n      if (!notchoose) {\n        for (SurfacePattern p : chosenPat.keySet()) {\n          boolean removeChosenPatFlag = false;\n          if (SurfacePattern.sameGenre(pat, p)) {\n            \n            if(SurfacePattern.subsumes(pat, p)){\n              Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + pat\n                  + \" because it is contained in or contains the already chosen pattern \" + p);\n              notchoose = true;\n              \n              if (pat.toStringSimple().contains(\"upon\") && p.toStringSimple().contains(\"upon\")) {\n                System.out.println(\"For \" + pat + \" and \" + p + \": samegenre is \" + SurfacePattern.sameGenre(pat, p) + \" and subsumes answer is \"\n                    + SurfacePattern.subsumes(pat, p) + \" and notchoose varaible is \" + notchoose);\n                \n              }\n              \n              break;\n            } \n            else if (SurfacePattern.subsumes(p, pat)) {\n              //subsume is true even if equal context\n              \n              //check if equal context\n              int rest = pat.equalContext(p);\n\n              // the contexts do not match\n              if (rest == Integer.MAX_VALUE)\n              {\n                Redwood.log(ConstantsAndVariables.extremedebug, \"Not choosing pattern \" + p\n                    + \" because it is contained in or contains another chosen pattern in this iteration \" + pat);  \n                removeChosenPatFlag = true;\n              }\n              // if pat is less restrictive, remove p from chosen patterns and\n              // add pat!\n              else if (rest < 0) {\n                removeChosenPatFlag = true;\n              } else {\n                notchoose = true;\n                break;\n              }\n            } \n\n            \n            if (removeChosenPatFlag) {\n              if(removeChosenPats == null)\n                removeChosenPats = new HashSet<SurfacePattern>();\n              removeChosenPats.add(p);\n              num--;\n            }\n\n          }\n        }\n      }\n      \n      if (notchoose) {\n        Redwood.log(Redwood.DBG, \"Not choosing \" + pat + \" for whatever reason!\");\n        continue;\n      }\n\n      if (removeChosenPats != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already chosen patterns in this iteration \" + removeChosenPats + \" in favor of \"\n            + pat);\n        Counters.removeKeys(chosenPat, removeChosenPats);\n      }\n      \n      if (removeIdentifiedPatterns != null) {\n        Redwood.log(ConstantsAndVariables.extremedebug, \"Removing already identified patterns \" + removeIdentifiedPatterns + \" in favor of \" + pat);\n        removePatterns.addAll(removeIdentifiedPatterns);\n\n      }\n      \n      chosenPat.setCount(pat, currentPatternWeights4Label.getCount(pat));\n      num++;\n      \n    }\n\n    this.removeLearnedPatterns(label, removePatterns);\n\n    Redwood.log(Redwood.DBG, \"final size of the patterns is \" + chosenPat.size());\n    Redwood.log(ConstantsAndVariables.minimaldebug, \"## Selected Patterns ## \\n\");\n    List<Pair<SurfacePattern, Double>> chosenPatSorted = Counters.toSortedListWithCounts(chosenPat);\n    for (Pair<SurfacePattern, Double> en : chosenPatSorted)\n      Redwood.log(ConstantsAndVariables.minimaldebug, en.first().toStringToWrite() + \":\" + df.format(en.second) + \"\\n\");\n\n    if (constVars.outDir != null && !constVars.outDir.isEmpty()) {\n      CollectionValuedMap<SurfacePattern, String> posWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : patternsandWords4Label.entrySet()) {\n        posWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n\n      CollectionValuedMap<SurfacePattern, String> negWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : negPatternsandWords4Label.entrySet()) {\n        negWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      CollectionValuedMap<SurfacePattern, String> unlabWords = new CollectionValuedMap<SurfacePattern, String>();\n      for (Entry<SurfacePattern, ClassicCounter<String>> en : unLabeledPatternsandWords4Label.entrySet()) {\n        unlabWords.addAll(en.getKey(), en.getValue().keySet());\n      }\n      String outputdir = constVars.outDir + \"/\" + constVars.identifier + \"/\" + label;\n      Redwood.log(ConstantsAndVariables.minimaldebug, \"Saving output in \" + outputdir);\n\n      IOUtils.ensureDir(new File(outputdir));\n\n      String filename = outputdir + \"/patterns\" + \".json\";\n\n      JsonArrayBuilder obj = Json.createArrayBuilder();\n      if (writtenPatInJustification.containsKey(label) && writtenPatInJustification.get(label)) {\n        JsonReader jsonReader = Json.createReader(new BufferedInputStream(new FileInputStream(filename)));\n        JsonArray objarr = jsonReader.readArray();\n        jsonReader.close();\n        for (JsonValue o : objarr)\n          obj.add(o);\n      } else\n        obj = Json.createArrayBuilder();\n\n      JsonObjectBuilder objThisIter = Json.createObjectBuilder();\n      for (Pair<SurfacePattern, Double> pat : chosenPatSorted) {\n        JsonObjectBuilder o = Json.createObjectBuilder();\n        JsonArrayBuilder pos = Json.createArrayBuilder();\n        JsonArrayBuilder neg = Json.createArrayBuilder();\n        JsonArrayBuilder unlab = Json.createArrayBuilder();\n\n        for (String w : posWords.get(pat.first()))\n          pos.add(w);\n        for (String w : negWords.get(pat.first()))\n          neg.add(w);\n        for (String w : unlabWords.get(pat.first()))\n          unlab.add(w);\n\n        o.add(\"Positive\", pos);\n        o.add(\"Negative\", neg);\n        o.add(\"Unlabeled\", unlab);\n        o.add(\"Score\", pat.second());\n\n        objThisIter.add(pat.first().toStringSimple(), o);\n      }\n      obj.add(objThisIter.build());\n\n      IOUtils.ensureDir(new File(filename).getParentFile());\n      IOUtils.writeStringToFile(obj.build().toString(), filename, \"utf8\");\n      writtenPatInJustification.put(label, true);\n    }\n\n    if (constVars.justify) {\n      Redwood.log(Redwood.DBG, \"Justification for Patterns:\");\n      for (SurfacePattern key : chosenPat.keySet()) {\n        Redwood.log(Redwood.DBG, \"\\nPattern: \" + key.toStringToWrite());\n        Redwood.log(\n            Redwood.DBG,\n            \"Positive Words:\"\n                + Counters.toSortedString(patternsandWords4Label.getCounter(key), patternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\", \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Negative Words:\"\n                + Counters.toSortedString(negPatternsandWords4Label.getCounter(key), negPatternsandWords4Label.getCounter(key).size(), \"%1$s:%2$f\",\n                    \";\"));\n\n        Redwood.log(\n            Redwood.DBG,\n            \"Unlabeled Words:\"\n                + Counters.toSortedString(unLabeledPatternsandWords4Label.getCounter(key), unLabeledPatternsandWords4Label.getCounter(key).size(),\n                    \"%1$s:%2$f\", \";\"));\n      }\n    }\n    allPatternsandWords.put(label, allPatternsandWords4Label);\n    patternsandWords.put(label, patternsandWords4Label);\n    currentPatternWeights.put(label, currentPatternWeights4Label);\n\n    return chosenPat;\n\n  }","commit_id":"929f74067f4c2854c23a8dc8913e76c49c0c9765","url":"https://github.com/stanfordnlp/CoreNLP"},{"original_method":"public boolean isAverageRatingStored()\n    {\n        int result = (int) getXWiki().ParamAsLong(\"xwiki.ratings.averagerating.stored\", 1);\n        return (getXWiki().getXWikiPreferenceAsInt(\"ratings_averagerating_stored\", result, getXWikiContext()) == 1);\n    }","id":14727,"modified_method":"public boolean isAverageRatingStored()\n    {\n        String result = getXWiki().Param(\"xwiki.ratings.averagerating.stored\", \"1\");\n        result = getXWiki().getXWikiPreference(\"ratings_averagerating_stored\", result, getXWikiContext());\n        return (getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_STORE_AVERAGE_RATING, result) == \"1\");\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"public boolean isReputationStored()\n    {\n        int result = (int) getXWiki().ParamAsLong(\"xwiki.ratings.reputation.stored\", 0);\n        return (getXWiki().getXWikiPreferenceAsInt(\"ratings_reputation_stored\", result, getXWikiContext()) == 1);\n    }","id":14728,"modified_method":"public boolean isReputationStored()\n    {\n        String result = getXWiki().Param(\"xwiki.ratings.reputation.stored\", \"0\");\n        result = getXWiki().getXWikiPreference(\"ratings_reputation_stored\", result, getXWikiContext());\n        return (getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_REPUTATION_STORED, result) == \"1\");\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"public boolean hasReputation()\n    {\n        int result = (int) getXWiki().ParamAsLong(\"xwiki.ratings.reputation\", 0);\n        return (getXWiki().getXWikiPreferenceAsInt(\"ratings_reputation\", result, getXWikiContext()) == 1);\n    }","id":14729,"modified_method":"public boolean hasReputation()\n    {\n        String result = getXWiki().Param(\"xwiki.ratings.reputation\", \"0\");\n        result = getXWiki().getXWikiPreference(\"ratings_reputation\", result, getXWikiContext());\n        return (getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_REPUTATION, result) == \"1\");\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"public String[] getDefaultReputationMethods()\n    {\n        String method =\n            getXWiki().Param(\"xwiki.ratings.reputation.defaultmethod\", RATING_REPUTATION_METHOD_DEFAULT);\n        method = getXWiki().getXWikiPreference(\"ratings_reputation_defaultmethod\", method, getXWikiContext());\n        return method.split(\",\");\n    }","id":14730,"modified_method":"public String[] getDefaultReputationMethods()\n    {\n        String method =\n            getXWiki().Param(\"xwiki.ratings.reputation.defaultmethod\", RATING_REPUTATION_METHOD_DEFAULT);\n        method = getXWiki().getXWikiPreference(\"ratings_reputation_defaultmethod\", method, getXWikiContext());\n        method = getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_REPUTATION_METHOD, method);\n        return method.split(\",\");\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public RatingsManager get() \n    {\n        // TODO implement\n        String ratingsHint = getXWiki().Param(RatingsManager.RATINGS_CONFIG_PARAM_PREFIX + RatingsManager.RATINGS_CONFIG_FIELDNAME_MANAGER_HINT, \"default\");\n        \n        try {\n            XWikiDocument configDoc = getXWiki().getDocument(RatingsManager.RATINGS_CONFIG_PAGE, getXWikiContext());\n            if (!configDoc.isNew() && configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME)!=null) {\n                BaseProperty prop = (BaseProperty) configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME).get(RatingsManager.RATINGS_CONFIG_FIELDNAME_MANAGER_HINT);\n                String hint = (prop==null) ? null : (String) prop.getValue();\n                ratingsHint = (hint==null) ? ratingsHint : hint;\n            }\n        } catch(Exception e) {\n            logger.error(\"Cannot read ratings config\", e);\n        }\n\n        try {\n            return componentManager.getInstance(RatingsManager.class, ratingsHint);\n        } catch (ComponentLookupException e) {\n            // TODO Auto-generated catch block\n            logger.error(\"Error loading ratings manager component for hint \" + ratingsHint, e);\n            try {\n                return componentManager.getInstance(RatingsManager.class, \"default\");\n            } catch (ComponentLookupException e1) {\n                return null;\n            }\n        }\n    }","id":14731,"modified_method":"@Override\n    public RatingsManager get() \n    {\n        // TODO implement\n        String ratingsHint = getXWiki().Param(RatingsManager.RATINGS_CONFIG_PARAM_PREFIX + RatingsManager.RATINGS_CONFIG_FIELDNAME_MANAGER_HINT, \"default\");\n        \n        try {\n            String space = getXWikiContext().getDoc().getSpace();\n            XWikiDocument spaceConfigDoc = getXWiki().getDocument(space + \".\" + RatingsManager.RATINGS_CONFIG_SPACE_PAGE, getXWikiContext());\n            XWikiDocument globalConfigDoc = getXWiki().getDocument(RatingsManager.RATINGS_CONFIG_GLOBAL_PAGE, getXWikiContext());\n            XWikiDocument configDoc = (spaceConfigDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME) == null) ? globalConfigDoc : spaceConfigDoc;\n\n            if (!configDoc.isNew() && configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME)!=null) {\n                BaseProperty prop = (BaseProperty) configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME).get(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_MANAGER_HINT);\n                String hint = (prop==null) ? null : (String) prop.getValue();\n                ratingsHint = (hint==null) ? ratingsHint : hint;\n            }\n        } catch(Exception e) {\n            logger.error(\"Cannot read ratings config\", e);\n        }\n\n        try {\n            return componentManager.getInstance(RatingsManager.class, ratingsHint);\n        } catch (ComponentLookupException e) {\n            // TODO Auto-generated catch block\n            logger.error(\"Error loading ratings manager component for hint \" + ratingsHint, e);\n            try {\n                return componentManager.getInstance(RatingsManager.class, \"default\");\n            } catch (ComponentLookupException e1) {\n                return null;\n            }\n        }\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Override\n    public ReputationAlgorithm get() \n    {\n        // TODO implement\n        String reputationAlgorithmHint = getXWiki().Param(RatingsManager.RATINGS_CONFIG_PARAM_PREFIX + RatingsManager.RATINGS_CONFIG_FIELDNAME_REPUTATIONALGORITHM_HINT, \"default\");\n        \n        try {\n            XWikiDocument configDoc = getXWiki().getDocument(RatingsManager.RATINGS_CONFIG_PAGE, getXWikiContext());\n            if (configDoc!=null && !configDoc.isNew() && configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME)!=null) {\n                BaseProperty prop = (BaseProperty) configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME).get(RatingsManager.RATINGS_CONFIG_FIELDNAME_REPUTATIONALGORITHM_HINT);\n                String hint = (prop==null) ? null : (String) prop.getValue();\n                reputationAlgorithmHint = (hint==null) ? reputationAlgorithmHint : hint;\n            }\n        } catch(Exception e) {\n            logger.error(\"Cannot read reputation algorithm config\", e);\n        }\n        \n        // if the reputation algorithm hint is a page let's try to get the instance from groovy\n        if (reputationAlgorithmHint.contains(\".\")) { \n            try {\n             ReputationAlgorithmGroovy reputationInstance = (ReputationAlgorithmGroovy) getXWiki().parseGroovyFromPage(reputationAlgorithmHint, getXWikiContext());\n             \n             if (reputationInstance!=null) {            \n                 reputationInstance.setComponentManager(componentManager);\n                 reputationInstance.setExecution(execution);\n                 reputationInstance.setXWikiContext(getXWikiContext());\n                 reputationInstance.setRatingsManager(ratingsManagerProvider.get());\n                 return reputationInstance;\n             }\n            } catch (Throwable e) {\n                logger.error(\"Cannot instanciate Reputation algorithm from page \" + reputationAlgorithmHint, e);                \n            }\n        } \n         \n        try {\n            return componentManager.getInstance(ReputationAlgorithm.class, reputationAlgorithmHint);\n        } catch (ComponentLookupException e) {\n            // TODO Auto-generated catch block\n            logger.error(\"Error loading ratings manager component for hint \" + reputationAlgorithmHint, e);\n            try {\n                return componentManager.getInstance(ReputationAlgorithm.class, \"default\");\n            } catch (ComponentLookupException e1) {\n                return null;\n            }\n        }\n    }","id":14732,"modified_method":"@Override\n    public ReputationAlgorithm get() \n    {\n        // TODO implement\n        String reputationAlgorithmHint = getXWiki().Param(RatingsManager.RATINGS_CONFIG_PARAM_PREFIX + RatingsManager.RATINGS_CONFIG_FIELDNAME_REPUTATIONALGORITHM_HINT, \"default\");\n        \n        try {\n            String space = getXWikiContext().getDoc().getSpace();\n            XWikiDocument spaceConfigDoc = getXWiki().getDocument(space + \".\" + RatingsManager.RATINGS_CONFIG_SPACE_PAGE, getXWikiContext());\n            XWikiDocument globalConfigDoc = getXWiki().getDocument(RatingsManager.RATINGS_CONFIG_GLOBAL_PAGE, getXWikiContext());\n            XWikiDocument configDoc = (spaceConfigDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME) == null) ? globalConfigDoc : spaceConfigDoc;\n\n            if (configDoc!=null && !configDoc.isNew() && configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME)!=null) {\n                BaseProperty prop = (BaseProperty) configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME).get(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_REPUTATION_ALGORITHM_HINT);\n                String hint = (prop==null) ? null : (String) prop.getValue();\n                if (hint == \"custom\")\n                {\n                    prop = (BaseProperty) configDoc.getObject(RatingsManager.RATINGS_CONFIG_CLASSNAME).get(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_REPUTATION_CUSTOM_ALGORITHM);\n                    hint = (prop==null) ? null : (String) prop.getValue();\n                }\n                reputationAlgorithmHint = (hint==null) ? reputationAlgorithmHint : hint;\n            }\n        } catch(Exception e) {\n            logger.error(\"Cannot read reputation algorithm config\", e);\n        }\n        \n        // if the reputation algorithm hint is a page let's try to get the instance from groovy\n        if (reputationAlgorithmHint.contains(\".\")) { \n            try {\n             ReputationAlgorithmGroovy reputationInstance = (ReputationAlgorithmGroovy) getXWiki().parseGroovyFromPage(reputationAlgorithmHint, getXWikiContext());\n             \n             if (reputationInstance!=null) {            \n                 reputationInstance.setComponentManager(componentManager);\n                 reputationInstance.setExecution(execution);\n                 reputationInstance.setXWikiContext(getXWikiContext());\n                 reputationInstance.setRatingsManager(ratingsManagerProvider.get());\n                 return reputationInstance;\n             }\n            } catch (Throwable e) {\n                logger.error(\"Cannot instanciate Reputation algorithm from page \" + reputationAlgorithmHint, e);                \n            }\n        } \n         \n        try {\n            return componentManager.getInstance(ReputationAlgorithm.class, reputationAlgorithmHint);\n        } catch (ComponentLookupException e) {\n            // TODO Auto-generated catch block\n            logger.error(\"Error loading ratings manager component for hint \" + reputationAlgorithmHint, e);\n            try {\n                return componentManager.getInstance(ReputationAlgorithm.class, \"default\");\n            } catch (ComponentLookupException e1) {\n                return null;\n            }\n        }\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"public String getRatingsSpaceName()\n    {\n        String ratingsSpaceName = getXWiki().Param(\"xwiki.ratings.separatepagemanager.spacename\", \"\");\n        ratingsSpaceName =\n            getXWiki().getXWikiPreference(\"ratings_separatepagemanager_spacename\", ratingsSpaceName, getXWikiContext());\n        return ratingsSpaceName;\n    }","id":14733,"modified_method":"public String getRatingsSpaceName()\n    {\n        String ratingsSpaceName = getXWiki().Param(\"xwiki.ratings.separatepagemanager.spacename\", \"\");\n        ratingsSpaceName =\n            getXWiki().getXWikiPreference(\"ratings_separatepagemanager_spacename\", ratingsSpaceName, getXWikiContext());\n        return getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_STORAGE_SPACE, ratingsSpaceName);\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"public boolean hasRatingsSpaceForeachSpace()\n    {\n        int result = (int) getXWiki().ParamAsLong(\"xwiki.ratings.separatepagemanager.ratingsspaceforeachspace\", 0);\n        return (getXWiki().getXWikiPreferenceAsInt(\"ratings_separatepagemanager_ratingsspaceforeachspace\", result, getXWikiContext()) == 1);\n    }","id":14734,"modified_method":"public boolean hasRatingsSpaceForeachSpace()\n    {\n        String result = getXWiki().Param(\"xwiki.ratings.separatepagemanager.ratingsspaceforeachspace\", \"0\");\n        result = getXWiki().getXWikiPreference(\"ratings_separatepagemanager_ratingsspaceforeachspace\", result, getXWikiContext());\n        return (getConfigParameter(RatingsManager.RATINGS_CONFIG_CLASS_FIELDNAME_STORAGE_SEPARATE_SPACES, result) == \"1\");\n    }","commit_id":"fa01e8dedc9611cdbc9d2abaf323a9893d1ffda7","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"private void registerTransformers_1_0_0(final SubsystemRegistration subsystemRegistration) {\n        final ModelVersion version = ModelVersion.create(1, 0, 0);\n        final TransformersSubRegistration subsystemTransformers = subsystemRegistration.registerModelTransformers(version, ResourceTransformer.DEFAULT);\n        final TransformersSubRegistration configurationTransformers = subsystemTransformers.registerSubResource(PathElement.pathElement(ModelConstants.CONFIGURATION));\n        configurationTransformers.registerOperationTransformer(ModelConstants.UPDATE, new OperationTransformer() {\n\n            @Override\n            public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation)\n                    throws OperationFailedException {\n\n                ModelNode remove = operation.clone();\n                remove.get(OP).set(REMOVE);\n                remove.remove(ModelConstants.ENTRIES);\n\n                ModelNode add = operation.clone();\n                add.get(OP).set(ADD);\n\n                ModelNode composite = new ModelNode();\n                composite.get(OP).set(COMPOSITE);\n                composite.get(OP_ADDR).setEmptyList();\n                composite.get(STEPS).add(remove);\n                composite.get(STEPS).add(add);\n\n                return new TransformedOperation(composite, OperationResultTransformer.ORIGINAL_RESULT);\n            }\n        });\n    }","id":14735,"modified_method":"private void registerTransformers_1_0_0(final SubsystemRegistration subsystemRegistration) {\n        final ModelVersion version = ModelVersion.create(1, 0, 0);\n        final TransformersSubRegistration subsystemTransformers = subsystemRegistration.registerModelTransformers(version, ResourceTransformer.DEFAULT);\n        RejectExpressionValuesTransformer rejectTransformer = new RejectExpressionValuesTransformer(ConfigurationResource.ENTRIES);\n        final TransformersSubRegistration configurationTransformers =\n                subsystemTransformers.registerSubResource(PathElement.pathElement(ModelConstants.CONFIGURATION),\n                        (ResourceTransformer) rejectTransformer);\n        configurationTransformers.registerOperationTransformer(ADD, rejectTransformer);\n        configurationTransformers.registerOperationTransformer(WRITE_ATTRIBUTE_OPERATION, rejectTransformer.getWriteAttributeTransformer());\n        configurationTransformers.registerOperationTransformer(ModelConstants.UPDATE, new OperationTransformer() {\n\n            @Override\n            public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation)\n                    throws OperationFailedException {\n\n                ModelNode remove = operation.clone();\n                remove.get(OP).set(REMOVE);\n                remove.remove(ModelConstants.ENTRIES);\n\n                ModelNode add = operation.clone();\n                add.get(OP).set(ADD);\n\n                ModelNode composite = new ModelNode();\n                composite.get(OP).set(COMPOSITE);\n                composite.get(OP_ADDR).setEmptyList();\n                composite.get(STEPS).add(remove);\n                composite.get(STEPS).add(add);\n\n                return new TransformedOperation(composite, OperationResultTransformer.ORIGINAL_RESULT);\n            }\n        });\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"public ConfigAdminRootResource() {\n        super(PathElement.pathElement(SUBSYSTEM, ConfigAdminExtension.SUBSYSTEM_NAME), ConfigAdminExtension.getResourceDescriptionResolver(SUBSYSTEM), ConfigAdminAdd.INSTANCE, new ReloadRequiredRemoveStepHandler());\n    }","id":14736,"modified_method":"public ConfigAdminRootResource() {\n        super(SUBSYSTEM_PATH, ConfigAdminExtension.getResourceDescriptionResolver(SUBSYSTEM), ConfigAdminAdd.INSTANCE, new ReloadRequiredRemoveStepHandler());\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n        context.startSubsystemElement(Namespace.CURRENT.getUriString(), false);\n        ModelNode node = context.getModelNode();\n\n        if (has(node, ModelConstants.CONFIGURATION)) {\n            ModelNode configuration = node.get(ModelConstants.CONFIGURATION);\n            for (String pid : new TreeSet<String>(configuration.keys())) {\n                writer.writeStartElement(Element.CONFIGURATION.getLocalName());\n                writer.writeAttribute(Attribute.PID.getLocalName(), pid);\n\n                ModelNode entries = configuration.get(pid).get(ModelConstants.ENTRIES);\n                if (entries.isDefined()) {\n                    for (String propKey : entries.keys()) {\n                        String propValue = entries.get(propKey).asString();\n                        writer.writeStartElement(Element.PROPERTY.getLocalName());\n                        writer.writeAttribute(Attribute.NAME.getLocalName(), propKey);\n                        writer.writeAttribute(Attribute.VALUE.getLocalName(), propValue);\n                        writer.writeEndElement();\n                    }\n                }\n                writer.writeEndElement();\n            }\n        }\n\n        writer.writeEndElement();\n    }","id":14737,"modified_method":"@Override\n    public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n        context.startSubsystemElement(Namespace.CURRENT.getUriString(), false);\n        ModelNode node = context.getModelNode();\n\n        if (has(node, ModelConstants.CONFIGURATION)) {\n            ModelNode configuration = node.get(ModelConstants.CONFIGURATION);\n            for (String pid : new TreeSet<String>(configuration.keys())) {\n                writer.writeStartElement(Element.CONFIGURATION.getLocalName());\n                writer.writeAttribute(Attribute.PID.getLocalName(), pid);\n\n                ConfigurationResource.ENTRIES.marshallAsElement(configuration.get(pid), writer);\n                writer.writeEndElement();\n            }\n        }\n\n        writer.writeEndElement();\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected void populateModel(ModelNode operation, ModelNode model) throws OperationFailedException {\n        model.get(ModelConstants.ENTRIES).set(operation.get(ModelConstants.ENTRIES));\n    }","id":14738,"modified_method":"@Override\n    protected void populateModel(ModelNode operation, ModelNode model) throws OperationFailedException {\n        ConfigurationResource.ENTRIES.validateAndSet(operation, model);\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected void performRuntime(OperationContext context, ModelNode operation, ModelNode model, ServiceVerificationHandler verificationHandler,\n            List<ServiceController<?>> newControllers) throws OperationFailedException {\n\n        ModelNode entries = operation.get(ModelConstants.ENTRIES);\n        String pid = operation.get(ModelDescriptionConstants.OP_ADDR).asObject().get(ModelConstants.CONFIGURATION).asString();\n        Dictionary<String, String> dictionary = new Hashtable<String, String>();\n        if (entries.isDefined()) {\n            for (String key : entries.keys()) {\n                dictionary.put(key, entries.get(key).asString());\n            }\n        }\n\n        ConfigAdminInternal configAdmin = ConfigAdminExtension.getConfigAdminService(context);\n        if (configAdmin != null) {\n            configAdmin.putConfigurationInternal(pid, dictionary);\n        } else {\n            synchronized (this) {\n                if (initializationService == null) {\n                    initializationService = new InitializeConfigAdminService();\n                    ServiceBuilder<Object> builder = context.getServiceTarget().addService(ServiceName.JBOSS.append(\"configadmin\", \"data_initialization\"), initializationService);\n                    builder.addDependency(ConfigAdmin.SERVICE_NAME, ConfigAdmin.class, initializationService.injectedConfigAdminService);\n                    builder.install();\n                }\n            }\n            initializationService.putConfiguration(pid, dictionary);\n        }\n    }","id":14739,"modified_method":"@Override\n    protected void performRuntime(OperationContext context, ModelNode operation, ModelNode model, ServiceVerificationHandler verificationHandler,\n            List<ServiceController<?>> newControllers) throws OperationFailedException {\n\n        String pid = operation.get(ModelDescriptionConstants.OP_ADDR).asObject().get(ModelConstants.CONFIGURATION).asString();\n        Dictionary<String, String> dictionary = new Hashtable<String, String>(ConfigurationResource.ENTRIES.unwrap(context, model));\n\n        ConfigAdminInternal configAdmin = ConfigAdminExtension.getConfigAdminService(context);\n        if (configAdmin != null) {\n            configAdmin.putConfigurationInternal(pid, dictionary);\n        } else {\n            synchronized (this) {\n                if (initializationService == null) {\n                    initializationService = new InitializeConfigAdminService();\n                    ServiceBuilder<Object> builder = context.getServiceTarget().addService(ServiceName.JBOSS.append(\"configadmin\", \"data_initialization\"), initializationService);\n                    builder.addDependency(ConfigAdmin.SERVICE_NAME, ConfigAdmin.class, initializationService.injectedConfigAdminService);\n                    builder.install();\n                }\n            }\n            initializationService.putConfiguration(pid, dictionary);\n        }\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n    public void testConfigAdminPresent() throws Exception {\n        // Set up some mock objects\n        ConfigAdminServiceImpl mockCAS = Mockito.mock(ConfigAdminServiceImpl.class);\n\n        ServiceController mockCASServiceController = Mockito.mock(ServiceController.class);\n        Mockito.when(mockCASServiceController.getValue()).thenReturn(mockCAS);\n\n        ServiceRegistry mockServiceRegistry = Mockito.mock(ServiceRegistry.class);\n        Mockito.when(mockServiceRegistry.getService(ConfigAdmin.SERVICE_NAME)).thenReturn(mockCASServiceController);\n\n        OperationContext mockOperationContext = Mockito.mock(OperationContext.class);\n        Mockito.when(mockOperationContext.getServiceRegistry(true)).thenReturn(mockServiceRegistry);\n\n        // Create the operation model node\n        Hashtable<String, String> dict = new Hashtable<String, String>();\n        dict.put(\"x.y\", \"a b\");\n        ModelNode operation = getOperationModelNode(\"some.config\", dict);\n\n        // Invoke the Add operation\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, operation, null, null, null);\n\n        // Verify the results\n        Mockito.verify(mockCAS).putConfigurationInternal(\"some.config\", dict);\n        assertNull(getInitializationService());\n    }","id":14740,"modified_method":"@Test\n    @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n    public void testConfigAdminPresent() throws Exception {\n\n        // Create the operation model node\n        Hashtable<String, String> dict = new Hashtable<String, String>();\n        dict.put(\"x.y\", \"a b\");\n        ModelNode operation = getOperationModelNode(\"some.config\", dict);\n        ModelNode model = new ModelNode();\n        ConfigurationAdd.INSTANCE.populateModel(operation, model);\n\n        ModelNode propValue = model.get(ConfigurationResource.ENTRIES.getName(), \"x.y\");\n        Assert.assertEquals(dict.get(\"x.y\"), propValue.asString());\n\n        // Set up some mock objects\n        ConfigAdminServiceImpl mockCAS = Mockito.mock(ConfigAdminServiceImpl.class);\n\n        ServiceController mockCASServiceController = Mockito.mock(ServiceController.class);\n        Mockito.when(mockCASServiceController.getValue()).thenReturn(mockCAS);\n\n        ServiceRegistry mockServiceRegistry = Mockito.mock(ServiceRegistry.class);\n        Mockito.when(mockServiceRegistry.getService(ConfigAdmin.SERVICE_NAME)).thenReturn(mockCASServiceController);\n\n        OperationContext mockOperationContext = Mockito.mock(OperationContext.class);\n        Mockito.when(mockOperationContext.resolveExpressions(propValue)).thenReturn(propValue);\n        Mockito.when(mockOperationContext.getServiceRegistry(true)).thenReturn(mockServiceRegistry);\n\n        // Invoke the Add operation\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, operation, model, null, null);\n\n        // Verify the results\n        Mockito.verify(mockCAS).putConfigurationInternal(\"some.config\", dict);\n        assertNull(getInitializationService());\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n    public void testConfigAdminArrivesLater() throws Exception {\n        // Set up some mock objects\n        ServiceRegistry mockServiceRegistry = Mockito.mock(ServiceRegistry.class);\n\n        ServiceBuilder mockBuilder = Mockito.mock(ServiceBuilder.class);\n\n        ServiceTarget mockServiceTarget = Mockito.mock(ServiceTarget.class);\n        Mockito.when(mockServiceTarget.addService(\n                Mockito.eq(ServiceName.JBOSS.append(\"configadmin\", \"data_initialization\")),\n                Mockito.any(Service.class))).\n            thenReturn(mockBuilder);\n\n        OperationContext mockOperationContext = Mockito.mock(OperationContext.class);\n        Mockito.when(mockOperationContext.getServiceRegistry(true)).thenReturn(mockServiceRegistry);\n        Mockito.when(mockOperationContext.getServiceTarget()).thenReturn(mockServiceTarget);\n\n        // Create the operation model node\n        Hashtable<String, String> values = new Hashtable<String, String>();\n        values.put(\"a\", \"aa\");\n        values.put(\"b\", \"bb\");\n        ModelNode operation = getOperationModelNode(\"a.b.c\", values);\n\n        // Invoke the Add operation\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, operation, null, null, null);\n\n        // Check that the service that depends on the Config Admin Service has been created\n        Mockito.verify(mockBuilder).addDependency(\n                Mockito.eq(ConfigAdmin.SERVICE_NAME),\n                Mockito.eq(ConfigAdmin.class),\n                Mockito.any(Injector.class));\n        Mockito.verify(mockBuilder).install();\n\n        // Set up the mock Config Admin Service\n        ConfigAdminServiceImpl mockCAS = Mockito.mock(ConfigAdminServiceImpl.class);\n        ConfigurationAdd.InitializeConfigAdminService initSvc = getInitializationService();\n        Field injectedCASField = initSvc.getClass().getDeclaredField(\"injectedConfigAdminService\");\n        injectedCASField.setAccessible(true);\n        InjectedValue<ConfigAdmin> injectedCAS = (InjectedValue<ConfigAdmin>) injectedCASField.get(initSvc);\n        injectedCAS.setValue(new ImmediateValue<ConfigAdmin>(mockCAS));\n\n        // Invoke the operation again\n        Hashtable<String, String> values2 = new Hashtable<String, String>();\n        values2.put(\"x\", \"x\");\n        ModelNode op2 = getOperationModelNode(\"xx\", values2);\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, op2, null, null, null);\n\n        initSvc.start(null);\n\n        Mockito.verify(mockCAS).putConfigurationInternal(\"a.b.c\", values);\n        Mockito.verify(mockCAS).putConfigurationInternal(\"xx\", values2);\n    }","id":14741,"modified_method":"@Test\n    @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n    public void testConfigAdminArrivesLater() throws Exception {\n\n        // Create the operation model node\n        Hashtable<String, String> values = new Hashtable<String, String>();\n        values.put(\"a\", \"aa\");\n        values.put(\"b\", \"bb\");\n        ModelNode operation = getOperationModelNode(\"a.b.c\", values);\n        ModelNode model = new ModelNode();\n        ConfigurationAdd.INSTANCE.populateModel(operation, model);\n\n        ModelNode aValue = model.get(ConfigurationResource.ENTRIES.getName(), \"a\");\n        Assert.assertEquals(values.get(\"a\"), aValue.asString());\n        ModelNode bValue = model.get(ConfigurationResource.ENTRIES.getName(), \"b\");\n        Assert.assertEquals(values.get(\"b\"), bValue.asString());\n\n        // Set up some mock objects\n        ServiceRegistry mockServiceRegistry = Mockito.mock(ServiceRegistry.class);\n\n        ServiceBuilder mockBuilder = Mockito.mock(ServiceBuilder.class);\n\n        ServiceTarget mockServiceTarget = Mockito.mock(ServiceTarget.class);\n        Mockito.when(mockServiceTarget.addService(\n                Mockito.eq(ServiceName.JBOSS.append(\"configadmin\", \"data_initialization\")),\n                Mockito.any(Service.class))).\n            thenReturn(mockBuilder);\n\n        OperationContext mockOperationContext = Mockito.mock(OperationContext.class);\n        Mockito.when(mockOperationContext.resolveExpressions(aValue)).thenReturn(aValue);\n        Mockito.when(mockOperationContext.resolveExpressions(bValue)).thenReturn(bValue);\n        Mockito.when(mockOperationContext.getServiceRegistry(true)).thenReturn(mockServiceRegistry);\n        Mockito.when(mockOperationContext.getServiceTarget()).thenReturn(mockServiceTarget);\n\n        // Invoke the Add operation\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, operation, model, null, null);\n\n        // Check that the service that depends on the Config Admin Service has been created\n        Mockito.verify(mockBuilder).addDependency(\n                Mockito.eq(ConfigAdmin.SERVICE_NAME),\n                Mockito.eq(ConfigAdmin.class),\n                Mockito.any(Injector.class));\n        Mockito.verify(mockBuilder).install();\n\n        // Set up the mock Config Admin Service\n        ConfigAdminServiceImpl mockCAS = Mockito.mock(ConfigAdminServiceImpl.class);\n        ConfigurationAdd.InitializeConfigAdminService initSvc = getInitializationService();\n        Field injectedCASField = initSvc.getClass().getDeclaredField(\"injectedConfigAdminService\");\n        injectedCASField.setAccessible(true);\n        InjectedValue<ConfigAdmin> injectedCAS = (InjectedValue<ConfigAdmin>) injectedCASField.get(initSvc);\n        injectedCAS.setValue(new ImmediateValue<ConfigAdmin>(mockCAS));\n\n        // Invoke the operation again\n        Hashtable<String, String> values2 = new Hashtable<String, String>();\n        values2.put(\"x\", \"x\");\n        ModelNode op2 = getOperationModelNode(\"xx\", values2);\n        ModelNode mod2 = new ModelNode();\n        ConfigurationAdd.INSTANCE.populateModel(op2, mod2);\n\n        ModelNode xValue = mod2.get(ConfigurationResource.ENTRIES.getName(), \"x\");\n        Assert.assertEquals(values2.get(\"x\"), xValue.asString());\n\n        Mockito.when(mockOperationContext.resolveExpressions(xValue)).thenReturn(xValue);\n\n        ConfigurationAdd.INSTANCE.performRuntime(mockOperationContext, op2, mod2, null, null);\n\n        initSvc.start(null);\n\n        Mockito.verify(mockCAS).putConfigurationInternal(\"a.b.c\", values);\n        Mockito.verify(mockCAS).putConfigurationInternal(\"xx\", values2);\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"public ConfigurationResource() {\n        super(PathElement.pathElement(ModelConstants.CONFIGURATION), ConfigAdminExtension.getResourceDescriptionResolver(ModelConstants.CONFIGURATION), ConfigurationAdd.INSTANCE, ConfigurationRemove.INSTANCE);\n    }","id":14742,"modified_method":"public ConfigurationResource() {\n        super(PATH_ELEMENT, ConfigAdminExtension.getResourceDescriptionResolver(ModelConstants.CONFIGURATION), ConfigurationAdd.INSTANCE, ConfigurationRemove.INSTANCE);\n    }","commit_id":"4bd0045a7f6949a2bbd518830fb09b4c9f059213","url":"https://github.com/wildfly/wildfly"},{"original_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null) {\n      ListSequence.fromList(rv).insertElement(0, ((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n      return rv;\n    } else if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    return rv;\n  }","id":14743,"modified_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null && !(ListSequence.fromList(rv).contains(((SModel) MapSequence.fromMap(_params).get(\"cmodel\"))))) {\n      ListSequence.fromList(rv).addElement(((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (cmd != null) {\n      ListSequence.fromList(rv).insertElement(0, cmd);\n    } else if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    return rv;\n  }","id":14744,"modified_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    if (cmd != null && !(ListSequence.fromList(rv).contains(cmd))) {\n      ListSequence.fromList(rv).addElement(cmd);\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (cmd != null) {\n      ListSequence.fromList(rv).insertElement(0, cmd);\n    } else if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    return rv;\n  }","id":14745,"modified_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    if (cmd != null && !(ListSequence.fromList(rv).contains(cmd))) {\n      ListSequence.fromList(rv).addElement(cmd);\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null) {\n      ListSequence.fromList(rv).insertElement(0, ((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n      return rv;\n    } else if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    return rv;\n  }","id":14746,"modified_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null && !(ListSequence.fromList(rv).contains(((SModel) MapSequence.fromMap(_params).get(\"cmodel\"))))) {\n      ListSequence.fromList(rv).addElement(((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null) {\n      ListSequence.fromList(rv).insertElement(0, ((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n      return rv;\n    } else if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    return rv;\n  }","id":14747,"modified_method":"private List<SModel> getModels(final Map<String, Object> _params) {\n    List<SModel> rv = ListSequence.fromList(new ArrayList<SModel>());\n    if (((List<SModel>) MapSequence.fromMap(_params).get(\"models\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModel>) MapSequence.fromMap(_params).get(\"models\"))));\n    }\n    if (((SModel) MapSequence.fromMap(_params).get(\"cmodel\")) != null && !(ListSequence.fromList(rv).contains(((SModel) MapSequence.fromMap(_params).get(\"cmodel\"))))) {\n      ListSequence.fromList(rv).addElement(((SModel) MapSequence.fromMap(_params).get(\"cmodel\")));\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (cmd != null) {\n      ListSequence.fromList(rv).insertElement(0, cmd);\n    } else if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    return rv;\n  }","id":14748,"modified_method":"private List<SModule> getModules(final Map<String, Object> _params) {\n    SModule cmd = ((SModule) MapSequence.fromMap(_params).get(\"cmodule\"));\n    if (cmd instanceof Generator) {\n      cmd = ((Generator) cmd).getSourceLanguage();\n    }\n    List<SModule> rv = ListSequence.fromList(new ArrayList<SModule>());\n    if (((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")) != null) {\n      ListSequence.fromList(rv).addSequence(ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\"))));\n    }\n    if (cmd != null && !(ListSequence.fromList(rv).contains(cmd))) {\n      ListSequence.fromList(rv).addElement(cmd);\n    }\n    return rv;\n  }","commit_id":"3672f44877ee29c7efc1f52e7b31c10717638944","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static void exportNode(\n\t\t\tPortletDataContext portletDataContext, Element nodesElement,\n\t\t\tElement pagesElement, WikiNode node)\n\t\tthrows Exception {\n\n\t\tif (portletDataContext.isWithinDateRange(node.getModifiedDate())) {\n\t\t\tString path = getNodePath(portletDataContext, node);\n\n\t\t\tif (portletDataContext.isPathNotProcessed(path)) {\n\t\t\t\tElement nodeElement = nodesElement.addElement(\"node\");\n\n\t\t\t\tportletDataContext.addClassedModel(\n\t\t\t\t\tnodeElement, path, node, NAMESPACE);\n\t\t\t}\n\t\t}\n\n\t\tElement dlFileEntryTypesElement = pagesElement.addElement(\n\t\t\t\"dl-file-entry-types\");\n\t\tElement dlFoldersElement = pagesElement.addElement(\"dl-folders\");\n\t\tElement dlFileEntriesElement = pagesElement.addElement(\n\t\t\t\"dl-file-entries\");\n\t\tElement dlFileRanksElement = pagesElement.addElement(\"dl-file-ranks\");\n\t\tElement dlRepositoriesElement = pagesElement.addElement(\n\t\t\t\"dl-repositories\");\n\t\tElement dlRepositoryEntriesElement = pagesElement.addElement(\n\t\t\t\"dl-repository-entries\");\n\n\t\tList<WikiPage> pages = WikiPageUtil.findByN_S(\n\t\t\tnode.getNodeId(), WorkflowConstants.STATUS_APPROVED,\n\t\t\tQueryUtil.ALL_POS, QueryUtil.ALL_POS,\n\t\t\tnew PageVersionComparator(true));\n\n\t\tfor (WikiPage page : pages) {\n\t\t\texportPage(\n\t\t\t\tportletDataContext, nodesElement, pagesElement,\n\t\t\t\tdlFileEntryTypesElement, dlFoldersElement, dlFileEntriesElement,\n\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, page, true);\n\t\t}\n\t}","id":14749,"modified_method":"public static void exportNode(\n\t\t\tPortletDataContext portletDataContext, Element nodesElement,\n\t\t\tElement pagesElement, WikiNode node)\n\t\tthrows Exception {\n\n\t\tif (portletDataContext.isWithinDateRange(node.getModifiedDate())) {\n\t\t\tString path = getNodePath(portletDataContext, node);\n\n\t\t\tif (portletDataContext.isPathNotProcessed(path)) {\n\t\t\t\tElement nodeElement = nodesElement.addElement(\"node\");\n\n\t\t\t\tportletDataContext.addClassedModel(\n\t\t\t\t\tnodeElement, path, node, NAMESPACE);\n\t\t\t}\n\t\t}\n\n\t\tElement dlFileEntryTypesElement = pagesElement.element(\n\t\t\t\"dl-file-entry-types\");\n\t\tif (dlFileEntryTypesElement == null) {\n\t\t\tpagesElement.addElement(\"dl-file-entry-types\");\n\t\t}\n\t\tElement dlFoldersElement = pagesElement.element(\"dl-folders\");\n\t\tif (dlFoldersElement == null) {\n\t\t\tpagesElement.addElement(\"dl-folders\");\n\t\t}\n\t\tElement dlFileEntriesElement = pagesElement.element(\"dl-file-entries\");\n\t\tif (dlFileEntriesElement == null) {\n\t\t\tpagesElement.addElement(\"dl-file-entries\");\n\t\t}\n\t\tElement dlFileRanksElement = pagesElement.element(\"dl-file-ranks\");\n\t\tif (dlFileRanksElement == null) {\n\t\t\tpagesElement.addElement(\"dl-file-ranks\");\n\t\t}\n\t\tElement dlRepositoriesElement = pagesElement.element(\"dl-repositories\");\n\t\tif (dlRepositoriesElement == null) {\n\t\t\tpagesElement.addElement(\"dl-repositories\");\n\t\t}\n\t\tElement dlRepositoryEntriesElement = pagesElement.element(\n\t\t\t\"dl-repository-entries\");\n\t\tif (dlRepositoryEntriesElement == null) {\n\t\t\tpagesElement.addElement(\"dl-repository-entries\");\n\t\t}\n\n\t\tList<WikiPage> pages = WikiPageUtil.findByN_S(\n\t\t\tnode.getNodeId(), WorkflowConstants.STATUS_APPROVED,\n\t\t\tQueryUtil.ALL_POS, QueryUtil.ALL_POS,\n\t\t\tnew PageVersionComparator(true));\n\n\t\tfor (WikiPage page : pages) {\n\t\t\texportPage(\n\t\t\t\tportletDataContext, nodesElement, pagesElement,\n\t\t\t\tdlFileEntryTypesElement, dlFoldersElement, dlFileEntriesElement,\n\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, page, true);\n\t\t}\n\t}","commit_id":"6afbc0079349cb26f4d4bc8a333597f894efa3d8","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void exportAssetCategories(\n\t\t\tPortletDataContext portletDataContext, Element rootElement)\n\t\tthrows Exception {\n\n\t\tElement assetVocabulariesElement = rootElement.element(\"vocabularies\");\n\n\t\tif (assetVocabulariesElement == null) {\n\t\t\tassetVocabulariesElement = rootElement.addElement(\"vocabularies\");\n\t\t}\n\n\t\tElement assetsElement = rootElement.addElement(\"assets\");\n\n\t\tElement assetCategoriesElement = rootElement.addElement(\"categories\");\n\n\t\tMap<String, String[]> assetCategoryUuidsMap =\n\t\t\tportletDataContext.getAssetCategoryUuidsMap();\n\n\t\tfor (Map.Entry<String, String[]> entry :\n\t\t\t\tassetCategoryUuidsMap.entrySet()) {\n\n\t\t\tString[] assetCategoryEntryParts = StringUtil.split(\n\t\t\t\tentry.getKey(), CharPool.POUND);\n\n\t\t\tString className = assetCategoryEntryParts[0];\n\t\t\tlong classPK = GetterUtil.getLong(assetCategoryEntryParts[1]);\n\n\t\t\tElement assetElement = assetsElement.addElement(\"asset\");\n\n\t\t\tassetElement.addAttribute(\"class-name\", className);\n\t\t\tassetElement.addAttribute(\"class-pk\", String.valueOf(classPK));\n\t\t\tassetElement.addAttribute(\n\t\t\t\t\"category-uuids\", StringUtil.merge(entry.getValue()));\n\n\t\t\tList<AssetCategory> assetCategories =\n\t\t\t\tAssetCategoryServiceUtil.getCategories(className, classPK);\n\n\t\t\tfor (AssetCategory assestCategory : assetCategories) {\n\t\t\t\texportAssetCategory(\n\t\t\t\t\tportletDataContext, assetVocabulariesElement,\n\t\t\t\t\tassetCategoriesElement, assestCategory);\n\t\t\t}\n\t\t}\n\t}","id":14750,"modified_method":"protected void exportAssetCategories(\n\t\t\tPortletDataContext portletDataContext, Element rootElement)\n\t\tthrows Exception {\n\n\t\tElement assetsElement = rootElement.element(\"assets\");\n\t\tElement assetCategoriesElement = rootElement.element(\"categories\");\n\t\tElement assetVocabulariesElement = rootElement.element(\"vocabularies\");\n\n\t\tif (assetsElement == null) {\n\t\t\tassetsElement = rootElement.addElement(\"assets\");\n\t\t}\n\n\t\tif (assetCategoriesElement == null) {\n\t\t\tassetCategoriesElement = rootElement.addElement(\"categories\");\n\t\t}\n\n\t\tif (assetVocabulariesElement == null) {\n\t\t\tassetVocabulariesElement = rootElement.addElement(\"vocabularies\");\n\t\t}\n\n\t\tMap<String, String[]> assetCategoryUuidsMap =\n\t\t\tportletDataContext.getAssetCategoryUuidsMap();\n\n\t\tfor (Map.Entry<String, String[]> entry :\n\t\t\t\tassetCategoryUuidsMap.entrySet()) {\n\n\t\t\tString[] assetCategoryEntryParts = StringUtil.split(\n\t\t\t\tentry.getKey(), CharPool.POUND);\n\n\t\t\tString className = assetCategoryEntryParts[0];\n\t\t\tlong classPK = GetterUtil.getLong(assetCategoryEntryParts[1]);\n\n\t\t\tElement assetElement = assetsElement.addElement(\"asset\");\n\n\t\t\tassetElement.addAttribute(\"class-name\", className);\n\t\t\tassetElement.addAttribute(\"class-pk\", String.valueOf(classPK));\n\t\t\tassetElement.addAttribute(\n\t\t\t\t\"category-uuids\", StringUtil.merge(entry.getValue()));\n\n\t\t\tList<AssetCategory> assetCategories =\n\t\t\t\tAssetCategoryServiceUtil.getCategories(className, classPK);\n\n\t\t\tfor (AssetCategory assestCategory : assetCategories) {\n\t\t\t\texportAssetCategory(\n\t\t\t\t\tportletDataContext, assetVocabulariesElement,\n\t\t\t\t\tassetCategoriesElement, assestCategory);\n\t\t\t}\n\t\t}\n\t}","commit_id":"0f6d851d15349291b0a6849212c2af46294f4769","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testFailedPortletImport() throws Exception {\n\t\tPortletImporter portletImporter = PortletImporter.getInstance();\n\n\t\ttry {\n\t\t\tportletImporter.importPortletInfo(\n\t\t\t\tTestPropsValues.getUserId(), 0, 0, StringPool.BLANK,\n\t\t\t\t_parameterMap, null);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchLayoutException nsle) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Layout exists with the primary key 0\", nsle.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_PORTLET_IMPORT_FAILED));\n\t}","id":14751,"modified_method":"@Test\n\tpublic void testFailedPortletImport() throws Exception {\n\t\tPortletImporter portletImporter = PortletImporter.getInstance();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildImportSettingsMap(\n\t\t\t\tTestPropsValues.getUserId(), 0, _group.getGroupId(),\n\t\t\t\tStringPool.BLANK, _parameterMap, StringPool.BLANK, Locale.US,\n\t\t\t\tTimeZoneUtil.GMT, StringPool.BLANK);\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tTestPropsValues.getUserId(), 0,\n\t\t\t\t\tRandomTestUtil.randomString(), StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_IMPORT_PORTLET,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tServiceContextTestUtil.getServiceContext());\n\n\t\ttry {\n\t\t\tportletImporter.importPortletInfo(exportImportConfiguration, null);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchLayoutException nsle) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Layout exists with the primary key 0\", nsle.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_PORTLET_IMPORT_FAILED));\n\t}","commit_id":"97dc3342d807108df876fca2e006795d3d57b22a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testFailedPortletExport() throws Exception {\n\t\tPortletExporter portletExporter = PortletExporter.getInstance();\n\n\t\tlong plid = RandomTestUtil.nextLong();\n\n\t\ttry {\n\t\t\tportletExporter.exportPortletInfoAsFile(\n\t\t\t\tplid, _group.getGroupId(), StringPool.BLANK, _parameterMap,\n\t\t\t\tnew Date(), new Date());\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchLayoutException nsle) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Layout exists with the primary key \" + plid,\n\t\t\t\tnsle.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_PORTLET_EXPORT_FAILED));\n\t}","id":14752,"modified_method":"@Test\n\tpublic void testFailedPortletExport() throws Exception {\n\t\tPortletExporter portletExporter = PortletExporter.getInstance();\n\n\t\tlong plid = RandomTestUtil.nextLong();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildExportSettingsMap(\n\t\t\t\tTestPropsValues.getUserId(), plid, _group.getGroupId(),\n\t\t\t\tStringPool.BLANK, _parameterMap, StringPool.BLANK, Locale.US,\n\t\t\t\tTimeZoneUtil.GMT, StringPool.BLANK);\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tTestPropsValues.getUserId(), 0,\n\t\t\t\t\tRandomTestUtil.randomString(), StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_PORTLET,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tServiceContextTestUtil.getServiceContext());\n\n\t\ttry {\n\t\t\tportletExporter.exportPortletInfoAsFile(exportImportConfiguration);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchLayoutException nsle) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Layout exists with the primary key \" + plid,\n\t\t\t\tnsle.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_PORTLET_EXPORT_FAILED));\n\t}","commit_id":"97dc3342d807108df876fca2e006795d3d57b22a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testFailedLayoutImport() throws Exception {\n\t\tLayoutImporter layoutImporter = LayoutImporter.getInstance();\n\n\t\ttry {\n\t\t\tlayoutImporter.importLayouts(\n\t\t\t\tTestPropsValues.getUserId(), 0, false, _parameterMap, null);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Group exists with the primary key 0\", nsge.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_LAYOUT_IMPORT_FAILED));\n\t}","id":14753,"modified_method":"@Test\n\tpublic void testFailedLayoutImport() throws Exception {\n\t\tLayoutImporter layoutImporter = LayoutImporter.getInstance();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tTestPropsValues.getUserId(), 0, false, new long[0],\n\t\t\t\t_parameterMap, Locale.US, TimeZoneUtil.GMT);\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tTestPropsValues.getUserId(), 0,\n\t\t\t\t\tRandomTestUtil.randomString(), StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_IMPORT_LAYOUT,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tServiceContextTestUtil.getServiceContext());\n\n\t\ttry {\n\t\t\tlayoutImporter.importLayouts(exportImportConfiguration, null);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Group exists with the primary key 0\", nsge.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_LAYOUT_IMPORT_FAILED));\n\t}","commit_id":"97dc3342d807108df876fca2e006795d3d57b22a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testFailedLayoutExport() throws Exception {\n\t\tLayoutExporter layoutExporter = LayoutExporter.getInstance();\n\n\t\ttry {\n\t\t\tlayoutExporter.exportLayoutsAsFile(\n\t\t\t\t0, false, new long[0], _parameterMap, new Date(), new Date());\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Group exists with the primary key 0\", nsge.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_LAYOUT_EXPORT_FAILED));\n\t}","id":14754,"modified_method":"@Test\n\tpublic void testFailedLayoutExport() throws Exception {\n\t\tLayoutExporter layoutExporter = LayoutExporter.getInstance();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tTestPropsValues.getUserId(), 0, false, new long[0],\n\t\t\t\t_parameterMap, Locale.US, TimeZoneUtil.GMT);\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tTestPropsValues.getUserId(), 0,\n\t\t\t\t\tRandomTestUtil.randomString(), StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_LAYOUT,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tServiceContextTestUtil.getServiceContext());\n\n\t\ttry {\n\t\t\tlayoutExporter.exportLayoutsAsFile(exportImportConfiguration);\n\n\t\t\tAssert.fail();\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tAssert.assertEquals(\n\t\t\t\t\"No Group exists with the primary key 0\", nsge.getMessage());\n\t\t}\n\n\t\tAssert.assertTrue(\n\t\t\t_firedExportImportLifecycleEventsMap.containsKey(\n\t\t\t\tExportImportLifecycleConstants.EVENT_LAYOUT_EXPORT_FAILED));\n\t}","commit_id":"97dc3342d807108df876fca2e006795d3d57b22a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tprotected void exportImportPortlet(String portletId) throws Exception {\n\t\tList<Layout> layouts = LayoutLocalServiceUtil.getLayouts(\n\t\t\tlayout.getGroupId(), layout.isPrivateLayout());\n\n\t\tlarFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\tlayout.getGroupId(), layout.isPrivateLayout(),\n\t\t\tExportImportHelperUtil.getLayoutIds(layouts),\n\t\t\tgetExportParameterMap(), null, null);\n\n\t\t// Import site LAR\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), importedGroup.getGroupId(),\n\t\t\tlayout.isPrivateLayout(), getImportParameterMap(), larFile);\n\n\t\timportedLayout = LayoutLocalServiceUtil.fetchLayoutByUuidAndGroupId(\n\t\t\tlayout.getUuid(), importedGroup.getGroupId(),\n\t\t\tlayout.isPrivateLayout());\n\n\t\tAssert.assertNotNull(importedLayout);\n\t}","id":14755,"modified_method":"@Override\n\tprotected void exportImportPortlet(String portletId) throws Exception {\n\t\tList<Layout> layouts = LayoutLocalServiceUtil.getLayouts(\n\t\t\tlayout.getGroupId(), layout.isPrivateLayout());\n\n\t\tUser user = TestPropsValues.getUser();\n\n\t\tMap<String, Serializable> exportSettingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tuser.getUserId(), layout.getGroupId(), layout.isPrivateLayout(),\n\t\t\t\tExportImportHelperUtil.getLayoutIds(layouts),\n\t\t\t\tgetExportParameterMap(), user.getLocale(), user.getTimeZone());\n\n\t\tExportImportConfiguration exportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tuser.getUserId(), layout.getGroupId(), StringPool.BLANK,\n\t\t\t\t\tStringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_LAYOUT,\n\t\t\t\t\texportSettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tnew ServiceContext());\n\n\t\tlarFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\texportConfiguration);\n\n\t\t// Import site LAR\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), importedGroup.getGroupId(),\n\t\t\tlayout.isPrivateLayout(), getImportParameterMap(), larFile);\n\n\t\timportedLayout = LayoutLocalServiceUtil.fetchLayoutByUuidAndGroupId(\n\t\t\tlayout.getUuid(), importedGroup.getGroupId(),\n\t\t\tlayout.isPrivateLayout());\n\n\t\tAssert.assertNotNull(importedLayout);\n\t}","commit_id":"38955b9650b1a0ef23a50054b2fa02b28f2c0cbe","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void exportImportLayouts(boolean privateLayout) throws Exception {\n\t\tList<Layout> layouts = LayoutLocalServiceUtil.getLayouts(\n\t\t\t_stagingGroup.getGroupId(), privateLayout);\n\n\t\tFile larFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\t_stagingGroup.getGroupId(), privateLayout,\n\t\t\tExportImportHelperUtil.getLayoutIds(layouts),\n\t\t\tnew HashMap<String, String[]>(), null, null);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), _liveGroup.getGroupId(), privateLayout,\n\t\t\tnew HashMap<String, String[]>(), larFile);\n\t}","id":14756,"modified_method":"protected void exportImportLayouts(boolean privateLayout) throws Exception {\n\t\tList<Layout> layouts = LayoutLocalServiceUtil.getLayouts(\n\t\t\t_stagingGroup.getGroupId(), privateLayout);\n\n\t\tUser user = TestPropsValues.getUser();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tuser.getUserId(), _stagingGroup.getGroupId(), privateLayout,\n\t\t\t\tExportImportHelperUtil.getLayoutIds(layouts),\n\t\t\t\tnew HashMap<String, String[]>(), user.getLocale(),\n\t\t\t\tuser.getTimeZone());\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tuser.getUserId(), _stagingGroup.getGroupId(),\n\t\t\t\t\tStringPool.BLANK, StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_LAYOUT,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tnew ServiceContext());\n\n\t\tFile larFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\texportImportConfiguration);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), _liveGroup.getGroupId(), privateLayout,\n\t\t\tnew HashMap<String, String[]>(), larFile);\n\t}","commit_id":"38955b9650b1a0ef23a50054b2fa02b28f2c0cbe","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void exportImportLayouts(\n\t\t\tlong[] layoutIds, Map<String, String[]> parameterMap)\n\t\tthrows Exception {\n\n\t\tlarFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\tgroup.getGroupId(), false, layoutIds, getExportParameterMap(), null,\n\t\t\tnull);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), importedGroup.getGroupId(), false,\n\t\t\tparameterMap, larFile);\n\t}","id":14757,"modified_method":"protected void exportImportLayouts(\n\t\t\tlong[] layoutIds, Map<String, String[]> parameterMap)\n\t\tthrows Exception {\n\n\t\tUser user = TestPropsValues.getUser();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tuser.getUserId(), group.getGroupId(), false, layoutIds,\n\t\t\t\tgetExportParameterMap(), user.getLocale(), user.getTimeZone());\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tuser.getUserId(), group.getGroupId(), StringPool.BLANK,\n\t\t\t\t\tStringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_LAYOUT,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tnew ServiceContext());\n\n\t\tlarFile = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\texportImportConfiguration);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), importedGroup.getGroupId(), false,\n\t\t\tparameterMap, larFile);\n\t}","commit_id":"38955b9650b1a0ef23a50054b2fa02b28f2c0cbe","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void testUpdateLocales(\n\t\t\tString defaultLanguageId, String languageIds,\n\t\t\tString defaultContentLanguageId)\n\t\tthrows Exception {\n\n\t\tGroupTestUtil.enableLocalStaging(_sourceGroup);\n\n\t\tJournalArticle article = JournalTestUtil.addArticle(\n\t\t\t_sourceGroup.getGroupId(), \"Title\", \"content\",\n\t\t\tLocaleUtil.fromLanguageId(defaultContentLanguageId));\n\n\t\tMap<String, String[]> parameterMap =\n\t\t\tExportImportConfigurationParameterMapFactory.buildParameterMap();\n\n\t\tFile file = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\t_sourceGroup.getGroupId(), false, null, parameterMap,\n\t\t\tnew Date(System.currentTimeMillis() - Time.MINUTE), new Date());\n\n\t\tCompanyTestUtil.resetCompanyLocales(\n\t\t\tTestPropsValues.getCompanyId(), languageIds, defaultLanguageId);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), _targetGroup.getGroupId(), false,\n\t\t\tparameterMap, file);\n\n\t\tJournalArticleResource articleResource =\n\t\t\tJournalArticleResourceLocalServiceUtil.\n\t\t\t\tfetchJournalArticleResourceByUuidAndGroupId(\n\t\t\t\t\tarticle.getArticleResourceUuid(),\n\t\t\t\t\t_targetGroup.getGroupId());\n\n\t\tAssert.assertNotNull(articleResource);\n\n\t\tJournalArticle stagingArticle =\n\t\t\tJournalArticleLocalServiceUtil.getLatestArticle(\n\t\t\t\tarticleResource.getResourcePrimKey(),\n\t\t\t\tWorkflowConstants.STATUS_ANY, false);\n\n\t\tif (languageIds.contains(defaultContentLanguageId)) {\n\t\t\tAssert.assertEquals(\n\t\t\t\tarticle.getDefaultLanguageId(),\n\t\t\t\tstagingArticle.getDefaultLanguageId());\n\t\t}\n\t\telse {\n\t\t\tAssert.assertEquals(\n\t\t\t\tdefaultLanguageId, stagingArticle.getDefaultLanguageId());\n\t\t}\n\n\t\tfor (Locale locale : _locales) {\n\t\t\tif (languageIds.contains(LocaleUtil.toLanguageId(locale)) ||\n\t\t\t\tlanguageIds.contains(defaultContentLanguageId)) {\n\n\t\t\t\tAssert.assertEquals(\n\t\t\t\t\tarticle.getTitle(locale), stagingArticle.getTitle(locale));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tAssert.assertEquals(\n\t\t\t\t\tarticle.getTitle(defaultLanguageId),\n\t\t\t\t\tstagingArticle.getTitle(locale));\n\t\t\t}\n\t\t}\n\t}","id":14758,"modified_method":"protected void testUpdateLocales(\n\t\t\tString defaultLanguageId, String languageIds,\n\t\t\tString defaultContentLanguageId)\n\t\tthrows Exception {\n\n\t\tGroupTestUtil.enableLocalStaging(_sourceGroup);\n\n\t\tJournalArticle article = JournalTestUtil.addArticle(\n\t\t\t_sourceGroup.getGroupId(), \"Title\", \"content\",\n\t\t\tLocaleUtil.fromLanguageId(defaultContentLanguageId));\n\n\t\tMap<String, String[]> parameterMap =\n\t\t\tExportImportConfigurationParameterMapFactory.buildParameterMap();\n\n\t\tUser user = TestPropsValues.getUser();\n\n\t\tMap<String, Serializable> settingsMap =\n\t\t\tExportImportConfigurationSettingsMapFactory.buildSettingsMap(\n\t\t\t\tuser.getUserId(), _sourceGroup.getGroupId(), false, null,\n\t\t\t\tparameterMap, user.getLocale(), user.getTimeZone());\n\n\t\tExportImportConfiguration exportImportConfiguration =\n\t\t\tExportImportConfigurationLocalServiceUtil.\n\t\t\t\taddExportImportConfiguration(\n\t\t\t\t\tuser.getUserId(), _sourceGroup.getGroupId(),\n\t\t\t\t\tStringPool.BLANK, StringPool.BLANK,\n\t\t\t\t\tExportImportConfigurationConstants.TYPE_EXPORT_LAYOUT,\n\t\t\t\t\tsettingsMap, WorkflowConstants.STATUS_DRAFT,\n\t\t\t\t\tnew ServiceContext());\n\n\t\tFile file = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\texportImportConfiguration);\n\n\t\tCompanyTestUtil.resetCompanyLocales(\n\t\t\tTestPropsValues.getCompanyId(), languageIds, defaultLanguageId);\n\n\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\tTestPropsValues.getUserId(), _targetGroup.getGroupId(), false,\n\t\t\tparameterMap, file);\n\n\t\tJournalArticleResource articleResource =\n\t\t\tJournalArticleResourceLocalServiceUtil.\n\t\t\t\tfetchJournalArticleResourceByUuidAndGroupId(\n\t\t\t\t\tarticle.getArticleResourceUuid(),\n\t\t\t\t\t_targetGroup.getGroupId());\n\n\t\tAssert.assertNotNull(articleResource);\n\n\t\tJournalArticle stagingArticle =\n\t\t\tJournalArticleLocalServiceUtil.getLatestArticle(\n\t\t\t\tarticleResource.getResourcePrimKey(),\n\t\t\t\tWorkflowConstants.STATUS_ANY, false);\n\n\t\tif (languageIds.contains(defaultContentLanguageId)) {\n\t\t\tAssert.assertEquals(\n\t\t\t\tarticle.getDefaultLanguageId(),\n\t\t\t\tstagingArticle.getDefaultLanguageId());\n\t\t}\n\t\telse {\n\t\t\tAssert.assertEquals(\n\t\t\t\tdefaultLanguageId, stagingArticle.getDefaultLanguageId());\n\t\t}\n\n\t\tfor (Locale locale : _locales) {\n\t\t\tif (languageIds.contains(LocaleUtil.toLanguageId(locale)) ||\n\t\t\t\tlanguageIds.contains(defaultContentLanguageId)) {\n\n\t\t\t\tAssert.assertEquals(\n\t\t\t\t\tarticle.getTitle(locale), stagingArticle.getTitle(locale));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tAssert.assertEquals(\n\t\t\t\t\tarticle.getTitle(defaultLanguageId),\n\t\t\t\t\tstagingArticle.getTitle(locale));\n\t\t\t}\n\t\t}\n\t}","commit_id":"38955b9650b1a0ef23a50054b2fa02b28f2c0cbe","url":"https://github.com/liferay/liferay-portal"},{"original_method":"static final TokenStore getTokenStore(Message message) {\n        TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n        if (tokenStore == null) {\n            tokenStore = new MemoryTokenStore();\n            message.getExchange().get(Endpoint.class).getEndpointInfo()\n                .setProperty(TokenStore.class.getName(), tokenStore);\n        }\n        return tokenStore;\n    }","id":14759,"modified_method":"static final TokenStore getTokenStore(Message message) {\n        EndpointInfo info = message.getExchange().get(Endpoint.class).getEndpointInfo();\n        synchronized (info) {\n            TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n            if (tokenStore == null) {\n                tokenStore = (TokenStore)info.getProperty(TokenStore.class.getName());\n            }\n            if (tokenStore == null) {\n                tokenStore = new MemoryTokenStore();\n                info.setProperty(TokenStore.class.getName(), tokenStore);\n            }\n            return tokenStore;\n        }\n    }","commit_id":"98c47b5a5293979148cdb666f43ce96fb09b08a3","url":"https://github.com/apache/cxf"},{"original_method":"static final TokenStore getTokenStore(Message message) {\n        TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n        if (tokenStore == null) {\n            tokenStore = new MemoryTokenStore();\n            message.getExchange().get(Endpoint.class).getEndpointInfo()\n                .setProperty(TokenStore.class.getName(), tokenStore);\n        }\n        return tokenStore;\n    }","id":14760,"modified_method":"static final TokenStore getTokenStore(Message message) {\n        EndpointInfo info = message.getExchange().get(Endpoint.class).getEndpointInfo();\n        synchronized (info) {\n            TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n            if (tokenStore == null) {\n                tokenStore = (TokenStore)info.getProperty(TokenStore.class.getName());\n            }\n            if (tokenStore == null) {\n                tokenStore = new MemoryTokenStore();\n                info.setProperty(TokenStore.class.getName(), tokenStore);\n            }\n            return tokenStore;\n        }\n    }","commit_id":"98c47b5a5293979148cdb666f43ce96fb09b08a3","url":"https://github.com/apache/cxf"},{"original_method":"static final TokenStore getTokenStore(Message message) {\n        TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n        if (tokenStore == null) {\n            tokenStore = new MemoryTokenStore();\n            message.getExchange().get(Endpoint.class).getEndpointInfo()\n                .setProperty(TokenStore.class.getName(), tokenStore);\n        }\n        return tokenStore;\n    }","id":14761,"modified_method":"static final TokenStore getTokenStore(Message message) {\n        EndpointInfo info = message.getExchange().get(Endpoint.class).getEndpointInfo();\n        synchronized (info) {\n            TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n            if (tokenStore == null) {\n                tokenStore = (TokenStore)info.getProperty(TokenStore.class.getName());\n            }\n            if (tokenStore == null) {\n                tokenStore = new MemoryTokenStore();\n                info.setProperty(TokenStore.class.getName(), tokenStore);\n            }\n            return tokenStore;\n        }\n    }","commit_id":"98c47b5a5293979148cdb666f43ce96fb09b08a3","url":"https://github.com/apache/cxf"},{"original_method":"static final TokenStore getTokenStore(Message message) {\n        TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n        if (tokenStore == null) {\n            tokenStore = new MemoryTokenStore();\n            message.getExchange().get(Endpoint.class).getEndpointInfo()\n                .setProperty(TokenStore.class.getName(), tokenStore);\n            message.getExchange().put(TokenStore.class.getName(), tokenStore);\n        }\n        return tokenStore;\n    }","id":14762,"modified_method":"static final TokenStore getTokenStore(Message message) {\n        EndpointInfo info = message.getExchange().get(Endpoint.class).getEndpointInfo();\n        synchronized (info) {\n            TokenStore tokenStore = (TokenStore)message.getContextualProperty(TokenStore.class.getName());\n            if (tokenStore == null) {\n                tokenStore = (TokenStore)info.getProperty(TokenStore.class.getName());\n            }\n            if (tokenStore == null) {\n                tokenStore = new MemoryTokenStore();\n                info.setProperty(TokenStore.class.getName(), tokenStore);\n            }\n            return tokenStore;\n        }\n    }","commit_id":"98c47b5a5293979148cdb666f43ce96fb09b08a3","url":"https://github.com/apache/cxf"},{"original_method":"@Configuration\n    public Option[] config() {\n        return options(\n            bootDelegationPackage(\"sun.*\"),\n            cleanCaches(),\n            CoreOptions.systemProperty(\"logback.configurationFile\").value(\"file:src/test/resources/logback.xml\"),\n//            CoreOptions.vmOption(\"-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8787\"),\n\n            mavenBundle(\"org.slf4j\", \"slf4j-api\").version(\"1.6.5\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"ch.qos.logback\", \"logback-core\").version(\"1.0.6\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"ch.qos.logback\", \"logback-classic\").version(\"1.0.6\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.exam.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.exam.inject.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.extender.service.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.base.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.swissbox.core.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.swissbox.extender.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.swissbox.lifecycle.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.ops4j.pax.swissbox.framework.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            url(\"link:classpath:META-INF/links/org.apache.geronimo.specs.atinject.link\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n\n            mavenBundle(\"org.osgi\", \"org.osgi.core\").version(\"4.2.0\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.osgi\", \"org.osgi.compendium\").version(\"4.2.0\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.dependencymanager\").version(\"3.0.0\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.deploymentadmin\").version(\"0.9.1-SNAPSHOT\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.eventadmin\").version(\"1.2.14\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.configadmin\").version(\"1.2.8\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.log\").version(\"1.0.1\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n//            mavenBundle(\"org.apache.felix\", \"org.apache.felix.shell\").version(\"1.4.3\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n//            mavenBundle(\"org.apache.felix\", \"org.apache.felix.shell.tui\").version(\"1.4.1\").startLevel(START_LEVEL_SYSTEM_BUNDLES),\n            \n            junitBundles(),\n            frameworkStartLevel(START_LEVEL_TEST_BUNDLE),\n            felix());\n    }","id":14763,"modified_method":"@Configuration\n    public Option[] config() throws Exception {\n        File f = new File(\"src/test/resources/logback.xml\");\n        if (!f.exists()) {\n            throw new RuntimeException(\"No log configuration...!\");\n        }\n        return options(\n            bootDelegationPackage(\"sun.*\"),\n            cleanCaches(),\n            systemProperty(\"org.ops4j.pax.logging.DefaultServiceLog.level\").value(\"WARN\"),\n            \n            mavenBundle(\"org.slf4j\", \"slf4j-api\").version(\"1.7.5\"),\n            mavenBundle(\"ch.qos.logback\", \"logback-core\").version(\"1.0.13\"),\n            mavenBundle(\"ch.qos.logback\", \"logback-classic\").version(\"1.0.13\"),\n            systemProperty(\"logback.configurationFile\").value(f.toURI().toASCIIString()),\n\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.metatype\").versionAsInProject(),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.dependencymanager\").versionAsInProject(),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.deploymentadmin\").versionAsInProject(),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.eventadmin\").versionAsInProject(),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.configadmin\").versionAsInProject(),\n            mavenBundle(\"org.apache.felix\", \"org.apache.felix.log\").versionAsInProject(),\n            \n            junitBundles()\n        );\n    }","commit_id":"25376b319e72edad927ac97e35dcfd3b4a3d33b0","url":"https://github.com/apache/felix"},{"original_method":"/**\n     * @param baseName\n     * @return\n     * @throws MalformedURLException\n     */\n    protected URL getTestBundle(String baseName) throws MalformedURLException {\n        File f = new File(m_testBundleBasePath, String.format(\"%1$s/target/org.apache.felix.deploymentadmin.test.%1$s-1.0.0.jar\", baseName));\n        assertTrue(\"No such bundle: \" + f, f.exists() && f.isFile());\n        return f.toURI().toURL();\n    }","id":14764,"modified_method":"protected URL getTestBundle(String baseName) throws MalformedURLException {\n        File f = new File(m_testBundleBasePath, String.format(\"%1$s/target/org.apache.felix.deploymentadmin.test.%1$s-1.0.0.jar\", baseName));\n        assertTrue(\"No such bundle: \" + f, f.exists() && f.isFile());\n        return f.toURI().toURL();\n    }","commit_id":"25376b319e72edad927ac97e35dcfd3b4a3d33b0","url":"https://github.com/apache/felix"},{"original_method":"public final InputStream createInputStream(URL url) throws IOException {\n            byte[] buffer = new byte[BUFFER_SIZE];\n\n            JarInputStream jis = new JarInputStream(url.openStream());\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n            JarOutputStream jos = new JarOutputStream(baos, filterManifest(jis.getManifest()));\n\n            JarEntry input;\n            while ((input = jis.getNextJarEntry()) != null) {\n                jos.putNextEntry(input);\n                int read;\n                while ((read = jis.read(buffer)) > 0) {\n                    jos.write(buffer, 0, read);\n                }\n                jos.closeEntry();\n            }\n            jos.close();\n\n            return new ByteArrayInputStream(baos.toByteArray());\n        }","id":14765,"modified_method":"public final InputStream createInputStream(URL url) throws IOException {\n            byte[] buffer = new byte[BUFFER_SIZE];\n\n            JarInputStream jis = new JarInputStream(url.openStream());\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n            JarOutputStream jos = new JarOutputStream(baos, filterManifest(jis.getManifest()));\n\n            JarEntry input;\n            while ((input = jis.getNextJarEntry()) != null) {\n                jos.putNextEntry(input);\n                int read;\n                while ((read = jis.read(buffer)) > 0) {\n                    jos.write(buffer, 0, read);\n                }\n                jos.closeEntry();\n            }\n            jos.close();\n            jis.close();\n\n            return new ByteArrayInputStream(baos.toByteArray());\n        }","commit_id":"25376b319e72edad927ac97e35dcfd3b4a3d33b0","url":"https://github.com/apache/felix"},{"original_method":"/**\n     * Tests that installing a bundle with a dependency installed by another deployment package is not started, but is resolved.\n     */\n    @Test\n    public void testInstallBundleWithDependencyInSeparatePackageOk() throws Exception {\n        DeploymentPackageBuilder dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle2\")));\n\n        DeploymentPackage dp1 = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp1);\n\n        awaitRefreshPackagesEvent();\n\n        assertBundleExists(getSymbolicName(\"bundle2\"), \"1.0.0\");\n\n        // We shouldn't be able to resolve the deps for bundle2...\n        assertFalse(m_packageAdmin.resolveBundles(new Bundle[] { dp1.getBundle(getSymbolicName(\"bundle2\")) }));\n\n        assertTrue(isBundleInstalled(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n\n        dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        // as missing bundle1...\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle1\")));\n\n        DeploymentPackage dp2 = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp2);\n\n        awaitRefreshPackagesEvent();\n\n        assertBundleExists(getSymbolicName(\"bundle1\"), \"1.0.0\");\n        assertBundleExists(getSymbolicName(\"bundle2\"), \"1.0.0\");\n\n        // Now we should be able to resolve the dependencies for bundle2...\n        assertTrue(m_packageAdmin.resolveBundles(new Bundle[] { dp1.getBundle(getSymbolicName(\"bundle2\")) }));\n\n        assertTrue(isBundleActive(dp2.getBundle(getSymbolicName(\"bundle1\"))));\n        assertTrue(isBundleResolved(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n    }","id":14766,"modified_method":"/**\n     * Tests that installing a bundle with a dependency installed by another deployment package is not started, but is resolved.\n     */\n    @Test\n    public void testInstallBundleWithDependencyInSeparatePackageOk() throws Exception {\n        DeploymentPackageBuilder dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle2\")));\n\n        DeploymentPackage dp1 = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp1);\n\n        awaitRefreshPackagesEvent();\n\n        assertBundleExists(getSymbolicName(\"bundle2\"), \"1.0.0\");\n\n        // We shouldn't be able to resolve the deps for bundle2...\n        assertFalse(resolveBundles(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n\n        assertTrue(isBundleInstalled(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n\n        dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        // as missing bundle1...\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle1\")));\n\n        DeploymentPackage dp2 = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp2);\n\n        awaitRefreshPackagesEvent();\n\n        assertBundleExists(getSymbolicName(\"bundle1\"), \"1.0.0\");\n        assertBundleExists(getSymbolicName(\"bundle2\"), \"1.0.0\");\n\n        // Now we should be able to resolve the dependencies for bundle2...\n        assertTrue(resolveBundles(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n\n        assertTrue(isBundleActive(dp2.getBundle(getSymbolicName(\"bundle1\"))));\n        assertTrue(isBundleResolved(dp1.getBundle(getSymbolicName(\"bundle2\"))));\n    }","commit_id":"25376b319e72edad927ac97e35dcfd3b4a3d33b0","url":"https://github.com/apache/felix"},{"original_method":"/**\n     * Tests that if a resource processor is missing (uninstalled) during the uninstallation of a deployment package, this is regarded an error and a rollback is performed.\n     */\n    @Test\n    public void testUninstallDeploymentPackageWithMissingResourceProcessorCausesRollback() throws Exception {\n        DeploymentPackageBuilder dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle1\")))\n            .add(dpBuilder.createResourceProcessorResource().setUrl(getTestBundle(\"rp1\")))\n            .add(dpBuilder.createResource().setResourceProcessorPID(TEST_FAILING_BUNDLE_RP1).setUrl(getTestResource(\"test-config1.xml\")));\n\n        DeploymentPackage dp = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp);\n\n        awaitRefreshPackagesEvent();\n\n        assertTrue(\"Two bundles should be started!\", getCurrentBundles().size() == 2);\n\n        Bundle rpBundle = dp.getBundle(getSymbolicName(\"rp1\"));\n        rpBundle.uninstall();\n\n        assertTrue(\"One bundle should be started!\", getCurrentBundles().size() == 1);\n\n        assertEquals(\"Expected no deployment package?!\", 1, m_deploymentAdmin.listDeploymentPackages().length);\n\n        try {\n            dp.uninstall();\n            fail(\"Expected uninstall to fail and rollback!\");\n        }\n        catch (DeploymentException exception) {\n            // Ok; expected\n            assertDeploymentException(CODE_PROCESSOR_NOT_FOUND, exception);\n        }\n        \n        assertTrue(\"One bundle should be started!\", getCurrentBundles().size() == 1);\n\n        assertEquals(\"Expected no deployment package?!\", 1, m_deploymentAdmin.listDeploymentPackages().length);\n    }","id":14767,"modified_method":"/**\n     * Tests that if a resource processor is missing (uninstalled) during the uninstallation of a deployment package, this is regarded an error and a rollback is performed.\n     */\n    @Test\n    public void testUninstallDeploymentPackageWithMissingResourceProcessorCausesRollback() throws Exception {\n        DeploymentPackageBuilder dpBuilder = createNewDeploymentPackageBuilder(\"1.0.0\");\n        dpBuilder\n            .add(dpBuilder.createBundleResource().setUrl(getTestBundle(\"bundle1\")))\n            .add(dpBuilder.createResourceProcessorResource().setUrl(getTestBundle(\"rp1\")))\n            .add(dpBuilder.createResource().setResourceProcessorPID(TEST_FAILING_BUNDLE_RP1).setUrl(getTestResource(\"test-config1.xml\")));\n\n        DeploymentPackage dp = m_deploymentAdmin.installDeploymentPackage(dpBuilder.generate());\n        assertNotNull(\"No deployment package returned?!\", dp);\n\n        awaitRefreshPackagesEvent();\n\n        assertTrue(\"Two bundles should be started!\", getCurrentBundles().size() == 2);\n\n        Bundle rpBundle = dp.getBundle(getSymbolicName(\"rp1\"));\n        rpBundle.uninstall();\n\n        assertTrue(\"One bundle should be started!\", getCurrentBundles().size() == 1);\n\n        assertEquals(\"Expected no deployment package?!\", 1, m_deploymentAdmin.listDeploymentPackages().length);\n\n        try {\n            dp.uninstall();\n            fail(\"Expected uninstall to fail and rollback!\");\n        }\n        catch (DeploymentException exception) {\n            // Ok; expected\n            assertDeploymentException(CODE_PROCESSOR_NOT_FOUND, exception);\n        }\n        \n        assertTrue(\"One bundle should be started!\", getCurrentBundles().size() == 1);\n\n        assertEquals(\"Expected one deployment package?!\", 1, m_deploymentAdmin.listDeploymentPackages().length);\n    }","commit_id":"25376b319e72edad927ac97e35dcfd3b4a3d33b0","url":"https://github.com/apache/felix"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tint retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\t\n\t\t\trtt = pinger.ping(host, timeout, retries);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","id":14768,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n        InetAddress host = (InetAddress) iface.getAddress();\n\n        try {\n            \n            // get parameters\n            //\n            int retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n            long timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n            \n            rtt = Pinger.ping(host, timeout, retries);\n        } catch (Exception e) {\n            log.debug(\"failed to ping \" + host, e);\n        }\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tPinger pinger;\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tpinger = new Pinger();\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","id":14769,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = Pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n    \tPinger pinger;\n\t\ttry {\n\t\t\tpinger = new Pinger();\n\t    \tLong retval = pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","id":14770,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n\t\ttry {\n\t    \tLong retval = Pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","id":14771,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(Pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"short getSequenceId() {\n        return m_sequenceId;\n    }","id":14772,"modified_method":"public short getSequenceId() {\n        return m_id.getSequenceId();\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n        this(addr, timeout, retries, s_nextTid++, sequenceId, cb);\n    }","id":14773,"modified_method":"PingRequest(InetAddress addr, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, s_nextTid++, sequenceId, timeout, retries, cb);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        m_callback.handleResponse(packet);\n    }","id":14774,"modified_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        log().info(System.currentTimeMillis()+\": Ping Response Received \"+this);\n        m_callback.handleResponse(packet);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() > getExpiration());\n    }","id":14775,"modified_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() >= getExpiration());\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public long getTid() {\n        return m_tid;\n    }","id":14776,"modified_method":"public long getTid() {\n        return m_id.getTid();\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InetAddress getAddress() {\n    \treturn m_addr;\n    }","id":14777,"modified_method":"public InetAddress getAddress() {\n        return m_id.getAddress();\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            m_expiration = System.currentTimeMillis() + m_timeout;\n            ICMPEchoPacket iPkt = new ICMPEchoPacket(getTid());\n            iPkt.setIdentity(FILTER_ID);\n            iPkt.setSequenceId(getSequenceId());\n            iPkt.computeChecksum();\n            m_request = iPkt;\n\n            byte[] data = iPkt.toBytes();\n            DatagramPacket packet = new DatagramPacket(data, data.length, getAddress(), 0);\n            ThreadCategory.getInstance(this.getClass()).info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(packet);\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","id":14778,"modified_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            createRequestPacket();\n\n            log().info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(createDatagram());\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (m_addr.equals(addr) && getSequenceId() == sequenceId);\n    }","id":14779,"modified_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (getAddress().equals(addr) && getSequenceId() == sequenceId);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, timeout, retries, DEFAULT_SEQUENCE_ID, cb);\n    }","id":14780,"modified_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, DEFAULT_SEQUENCE_ID, timeout, retries, cb);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, long tid, short sequenceId, PingResponseCallback cb) {\n        m_addr       = addr;\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n        m_tid        = tid;\n        m_sequenceId = sequenceId;\n    }","id":14781,"modified_method":"PingRequest(InetAddress addr, long tid, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        m_id = new RequestId(addr, tid, sequenceId);\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public String toString() {\n        StringBuffer sb = new StringBuffer();\n        sb.append(this.getAddress()).append(\" [\");\n        sb.append(\"TID=\").append(this.getTid()).append(\",\");\n        sb.append(\"Sequence ID=\").append(this.getSequenceId()).append(\",\");\n        // sb.append(\"Callback=\").append(m_callback.getClass().getName()).append(\",\");\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration());\n        sb.append(\"]\");\n        return sb.toString();\n    }","id":14782,"modified_method":"public String toString() {\n        StringBuilder sb = new StringBuilder();\n        sb.append('[');\n        sb.append(\"ID=\").append(getId()).append(',');\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration()).append(',');\n        sb.append(\"Callback=\").append(m_callback);\n        sb.append(\"]\");\n        return sb.toString();\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTimeout(), getRetries() - 1, getTid(), getSequenceId(), m_callback);\n            } else {\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","id":14783,"modified_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTid(), getSequenceId(), getTimeout(), getRetries() - 1, m_callback);\n                log().info(System.currentTimeMillis()+\": Retrying Ping Request \"+returnval);\n            } else {\n                log().info(System.currentTimeMillis()+\": Ping Request Timed out \"+this);\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(m_pinger.ping(m_badHost));\n    }","id":14784,"modified_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(Pinger.ping(m_badHost));\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePing() throws Exception {\n        assertTrue(m_pinger.ping(m_goodHost) > 0);\n    }","id":14785,"modified_method":"public void testSinglePing() throws Exception {\n        assertTrue(Pinger.ping(m_goodHost) > 0);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPing() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","id":14786,"modified_method":"public void testParallelPing() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_pinger = new Pinger();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","id":14787,"modified_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","id":14788,"modified_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tstartReplyProcessor();\n\t}","id":14789,"modified_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tinitialize();\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private Category log() {\n        return ThreadCategory.getInstance(this.getClass());\n    }","id":14790,"modified_method":"private static Category log() {\n        return ThreadCategory.getInstance(Pinger.class);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return this.ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","id":14791,"modified_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic static Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     */\n    public Long ping(InetAddress host, long timeout, int retries) throws InterruptedException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","id":14792,"modified_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     * @throws IOException \n     */\n    public static Long ping(InetAddress host, long timeout, int retries) throws InterruptedException, IOException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(PingRequest request, PingResponseCallback cb) {\n        synchronized(requestTracker.getTrackerLock()) {\n            requestTracker.registerRequest(request);\n            request.sendRequest(icmpSocket);\n        }\n    }","id":14793,"modified_method":"private static void ping(PingRequest request) throws IOException {\n        initialize();\n        synchronized(s_pendingRequests) {\n            s_pendingRequests.put(request.getId(), request);\n            request.sendRequest(s_icmpSocket);\n        }\n        debugf(\"Scheding timeout for request to %s in %d ms\", request, request.getDelay(TimeUnit.MILLISECONDS));\n        s_timeoutQueue.offer(request);\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, DEFAULT_TIMEOUT, 0, (short) i, cb);\n\t        ping(request, cb);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","id":14794,"modified_method":"public static List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, (short) i, DEFAULT_TIMEOUT, 0, cb);\n\t        ping(request);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processTimeouts() {\n        synchronized(requestTracker.getTrackerLock()) {\n            for (Iterator<Entry<Long, PingRequest>> it = requestTracker.getPendingRequestMap().entrySet().iterator(); it.hasNext(); ) {\n                PingRequest request = it.next().getValue();\n                log().debug(\"checking request \" + request);\n                if (request.isExpired()) {\n                    it.remove();\n                    PingRequest retry = request.processTimeout();\n                    if (retry != null) {\n                        requestTracker.registerRequest(retry);\n                        retry.sendRequest(icmpSocket);\n                    }\n                }\n            }\n        }\n    }","id":14795,"modified_method":"private static void processTimeouts() throws InterruptedException {  \n\t    while (true) {\n\t        PingRequest request = s_timeoutQueue.take();\n            debugf(\"Found a possibly timedout request: %s\", request);\n\t        if (s_pendingRequests.remove(request.getId()) == request) {\n\t            // then this request is still pending so we must time it out\n\t            debugf(\"Processing timeout for: %s\", request);\n\t            PingRequest retry = request.processTimeout();\n\t            if (retry != null) {\n\t                try {\n                        ping(retry);\n                    } catch (IOException e) {\n                        retry.processError(e);\n                    }\n\t            }\n\t        }\n\t        \n\t    }\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processReply(Reply pong) {\n        ICMPEchoPacket pongPacket = pong.getPacket();\n        Long key = new Long(pongPacket.getTID());\n        short sid = pongPacket.getSequenceId();\n        PingRequest ping = null;\n        synchronized(requestTracker.getTrackerLock()) {\n            if (requestTracker.getPendingRequestMap().containsKey(key)) {\n                PingRequest p = requestTracker.getPendingRequestMap().get(key);\n                if (p != null && p.isTarget(pong.getAddress(), sid)) {\n                    ping = p;\n                    requestTracker.getPendingRequestMap().remove(key);\n                }\n            }\n        }\n\n        if (ping != null) {\n            ping.processResponse(pong.getPacket());\n        }\n    }","id":14796,"modified_method":"private static void processReplies() throws InterruptedException {\n\t    while (true) {\n\t        Reply reply = s_pendingReplyQueue.take();\n            debugf(\"Found a reply to process: %s\", reply);\n\t        RequestId id = new RequestId(reply);\n\t        debugf(\"Looking for request with Id: %s in map %s\", id, s_pendingRequests);\n\t        PingRequest request = s_pendingRequests.remove(id);\n\t        if (request != null) {\n\t            debugf(\"Processing reply %s for request %s\", reply, request);\n\t            request.processResponse(reply.getPacket());\n\t        } else {\n\t            debugf(\"No request found for reply %s\", reply);\n\t        }\n\t    }\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n    \tPingRequest request = new PingRequest(host, timeout, retries, sequenceId, cb);\n    \tsynchronized(requestTracker.getTrackerLock()) {\n    \t    requestTracker.registerRequest(request);\n    \t    request.sendRequest(icmpSocket);\n    \t}\n\t}","id":14797,"modified_method":"public static void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) throws IOException {\n    \tping(new PingRequest(host, sequenceId, timeout, retries, cb));\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    private Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","id":14798,"modified_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    public Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","id":14799,"modified_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId() + \" with a responseTime \"+packet.getPingRTT());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","commit_id":"b2fa367993c8a8622bb85ab4cae4927cfd8e8fb6","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tint retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\t\n\t\t\trtt = pinger.ping(host, timeout, retries);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","id":14800,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n        InetAddress host = (InetAddress) iface.getAddress();\n\n        try {\n            \n            // get parameters\n            //\n            int retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n            long timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n            \n            rtt = Pinger.ping(host, timeout, retries);\n        } catch (Exception e) {\n            log.debug(\"failed to ping \" + host, e);\n        }\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tPinger pinger;\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tpinger = new Pinger();\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","id":14801,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = Pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n    \tPinger pinger;\n\t\ttry {\n\t\t\tpinger = new Pinger();\n\t    \tLong retval = pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","id":14802,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n\t\ttry {\n\t    \tLong retval = Pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","id":14803,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(Pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n        this(addr, timeout, retries, s_nextTid++, sequenceId, cb);\n    }","id":14804,"modified_method":"PingRequest(InetAddress addr, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, s_nextTid++, sequenceId, timeout, retries, cb);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() > getExpiration());\n    }","id":14805,"modified_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() >= getExpiration());\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InetAddress getAddress() {\n    \treturn m_addr;\n    }","id":14806,"modified_method":"public InetAddress getAddress() {\n        return m_id.getAddress();\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public String toString() {\n        StringBuffer sb = new StringBuffer();\n        sb.append(this.getAddress()).append(\" [\");\n        sb.append(\"TID=\").append(this.getTid()).append(\",\");\n        sb.append(\"Sequence ID=\").append(this.getSequenceId()).append(\",\");\n        // sb.append(\"Callback=\").append(m_callback.getClass().getName()).append(\",\");\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration());\n        sb.append(\"]\");\n        return sb.toString();\n    }","id":14807,"modified_method":"public String toString() {\n        StringBuilder sb = new StringBuilder();\n        sb.append('[');\n        sb.append(\"ID=\").append(getId()).append(',');\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration()).append(',');\n        sb.append(\"Callback=\").append(m_callback);\n        sb.append(\"]\");\n        return sb.toString();\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (m_addr.equals(addr) && getSequenceId() == sequenceId);\n    }","id":14808,"modified_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (getAddress().equals(addr) && getSequenceId() == sequenceId);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            m_expiration = System.currentTimeMillis() + m_timeout;\n            ICMPEchoPacket iPkt = new ICMPEchoPacket(getTid());\n            iPkt.setIdentity(FILTER_ID);\n            iPkt.setSequenceId(getSequenceId());\n            iPkt.computeChecksum();\n            m_request = iPkt;\n\n            byte[] data = iPkt.toBytes();\n            DatagramPacket packet = new DatagramPacket(data, data.length, getAddress(), 0);\n            ThreadCategory.getInstance(this.getClass()).info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(packet);\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","id":14809,"modified_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            createRequestPacket();\n\n            log().info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(createDatagram());\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTimeout(), getRetries() - 1, getTid(), getSequenceId(), m_callback);\n            } else {\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","id":14810,"modified_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTid(), getSequenceId(), getTimeout(), getRetries() - 1, m_callback);\n                log().info(System.currentTimeMillis()+\": Retrying Ping Request \"+returnval);\n            } else {\n                log().info(System.currentTimeMillis()+\": Ping Request Timed out \"+this);\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public long getTid() {\n        return m_tid;\n    }","id":14811,"modified_method":"public long getTid() {\n        return m_id.getTid();\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, timeout, retries, DEFAULT_SEQUENCE_ID, cb);\n    }","id":14812,"modified_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, DEFAULT_SEQUENCE_ID, timeout, retries, cb);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, long tid, short sequenceId, PingResponseCallback cb) {\n        m_addr       = addr;\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n        m_tid        = tid;\n        m_sequenceId = sequenceId;\n    }","id":14813,"modified_method":"PingRequest(InetAddress addr, long tid, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        m_id = new RequestId(addr, tid, sequenceId);\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"short getSequenceId() {\n        return m_sequenceId;\n    }","id":14814,"modified_method":"public short getSequenceId() {\n        return m_id.getSequenceId();\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        m_callback.handleResponse(packet);\n    }","id":14815,"modified_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        log().info(System.currentTimeMillis()+\": Ping Response Received \"+this);\n        m_callback.handleResponse(packet);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_pinger = new Pinger();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","id":14816,"modified_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","id":14817,"modified_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPing() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","id":14818,"modified_method":"public void testParallelPing() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePing() throws Exception {\n        assertTrue(m_pinger.ping(m_goodHost) > 0);\n    }","id":14819,"modified_method":"public void testSinglePing() throws Exception {\n        assertTrue(Pinger.ping(m_goodHost) > 0);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(m_pinger.ping(m_badHost));\n    }","id":14820,"modified_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(Pinger.ping(m_badHost));\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processTimeouts() {\n        synchronized(requestTracker.getTrackerLock()) {\n            for (Iterator<Entry<Long, PingRequest>> it = requestTracker.getPendingRequestMap().entrySet().iterator(); it.hasNext(); ) {\n                PingRequest request = it.next().getValue();\n                log().debug(\"checking request \" + request);\n                if (request.isExpired()) {\n                    it.remove();\n                    PingRequest retry = request.processTimeout();\n                    if (retry != null) {\n                        requestTracker.registerRequest(retry);\n                        retry.sendRequest(icmpSocket);\n                    }\n                }\n            }\n        }\n    }","id":14821,"modified_method":"private static void processTimeouts() throws InterruptedException {  \n\t    while (true) {\n\t        PingRequest request = s_timeoutQueue.take();\n            debugf(\"Found a possibly timedout request: %s\", request);\n\t        if (s_pendingRequests.remove(request.getId()) == request) {\n\t            // then this request is still pending so we must time it out\n\t            debugf(\"Processing timeout for: %s\", request);\n\t            PingRequest retry = request.processTimeout();\n\t            if (retry != null) {\n\t                try {\n                        ping(retry);\n                    } catch (IOException e) {\n                        retry.processError(e);\n                    }\n\t            }\n\t        }\n\t        \n\t    }\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, DEFAULT_TIMEOUT, 0, (short) i, cb);\n\t        ping(request, cb);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","id":14822,"modified_method":"public static List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, (short) i, DEFAULT_TIMEOUT, 0, cb);\n\t        ping(request);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n    \tPingRequest request = new PingRequest(host, timeout, retries, sequenceId, cb);\n    \tsynchronized(requestTracker.getTrackerLock()) {\n    \t    requestTracker.registerRequest(request);\n    \t    request.sendRequest(icmpSocket);\n    \t}\n\t}","id":14823,"modified_method":"public static void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) throws IOException {\n    \tping(new PingRequest(host, sequenceId, timeout, retries, cb));\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     */\n    public Long ping(InetAddress host, long timeout, int retries) throws InterruptedException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","id":14824,"modified_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     * @throws IOException \n     */\n    public static Long ping(InetAddress host, long timeout, int retries) throws InterruptedException, IOException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processReply(Reply pong) {\n        ICMPEchoPacket pongPacket = pong.getPacket();\n        Long key = new Long(pongPacket.getTID());\n        short sid = pongPacket.getSequenceId();\n        PingRequest ping = null;\n        synchronized(requestTracker.getTrackerLock()) {\n            if (requestTracker.getPendingRequestMap().containsKey(key)) {\n                PingRequest p = requestTracker.getPendingRequestMap().get(key);\n                if (p != null && p.isTarget(pong.getAddress(), sid)) {\n                    ping = p;\n                    requestTracker.getPendingRequestMap().remove(key);\n                }\n            }\n        }\n\n        if (ping != null) {\n            ping.processResponse(pong.getPacket());\n        }\n    }","id":14825,"modified_method":"private static void processReplies() throws InterruptedException {\n\t    while (true) {\n\t        Reply reply = s_pendingReplyQueue.take();\n            debugf(\"Found a reply to process: %s\", reply);\n\t        RequestId id = new RequestId(reply);\n\t        debugf(\"Looking for request with Id: %s in map %s\", id, s_pendingRequests);\n\t        PingRequest request = s_pendingRequests.remove(id);\n\t        if (request != null) {\n\t            debugf(\"Processing reply %s for request %s\", reply, request);\n\t            request.processResponse(reply.getPacket());\n\t        } else {\n\t            debugf(\"No request found for reply %s\", reply);\n\t        }\n\t    }\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(PingRequest request, PingResponseCallback cb) {\n        synchronized(requestTracker.getTrackerLock()) {\n            requestTracker.registerRequest(request);\n            request.sendRequest(icmpSocket);\n        }\n    }","id":14826,"modified_method":"private static void ping(PingRequest request) throws IOException {\n        initialize();\n        synchronized(s_pendingRequests) {\n            s_pendingRequests.put(request.getId(), request);\n            request.sendRequest(s_icmpSocket);\n        }\n        debugf(\"Scheding timeout for request to %s in %d ms\", request, request.getDelay(TimeUnit.MILLISECONDS));\n        s_timeoutQueue.offer(request);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tstartReplyProcessor();\n\t}","id":14827,"modified_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tinitialize();\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return this.ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","id":14828,"modified_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic static Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private Category log() {\n        return ThreadCategory.getInstance(this.getClass());\n    }","id":14829,"modified_method":"private static Category log() {\n        return ThreadCategory.getInstance(Pinger.class);\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    private Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","id":14830,"modified_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    public Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","id":14831,"modified_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId() + \" with a responseTime \"+packet.getPingRTT());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","commit_id":"ca5b62cc69ccfbe1cd398baafa5c8bc1ab30d37f","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tint retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\t\n\t\t\trtt = pinger.ping(host, timeout, retries);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","id":14832,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/recv) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availibility of the interface and if a transition event\n     *         should be supressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n        Long rtt = null;\n        InetAddress host = (InetAddress) iface.getAddress();\n\n        try {\n            \n            // get parameters\n            //\n            int retries = ParameterMap.getKeyedInteger(parameters, \"retry\", Pinger.DEFAULT_RETRIES);\n            long timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n            \n            rtt = Pinger.ping(host, timeout, retries);\n        } catch (Exception e) {\n            log.debug(\"failed to ping \" + host, e);\n        }\n        \n        if (rtt != null) {\n        \tserviceStatus = PollStatus.available();\n        \tserviceStatus.setResponseTime(rtt);\n        }\n        \n        return serviceStatus;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tPinger pinger;\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tpinger = new Pinger();\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","id":14833,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * The qualifier map passed to the method is used by the plugin to return\n     * additional information by key-name. These key-value pairs can be added to\n     * service events if needed.\n     * \n     * @param address\n     *            The address to check for support.\n     * @param qualifiers\n     *            The map where qualification are set by the plugin.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address, Map qualifiers) {\n    \tint retries;\n    \tlong timeout;\n\n    \ttry {\n    \t\tif (qualifiers != null) {\n    \t\t\tretries = ParameterMap.getKeyedInteger(qualifiers, \"retry\", Pinger.DEFAULT_RETRIES);\n    \t\t\ttimeout = ParameterMap.getKeyedLong(qualifiers, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n    \t\t} else {\n    \t\t\tretries = Pinger.DEFAULT_RETRIES;\n    \t\t\ttimeout = Pinger.DEFAULT_TIMEOUT;\n    \t\t}\n    \t\tLong retval = Pinger.ping(address, timeout, retries);\n    \t\tif (retval != null) {\n    \t\t\treturn true;\n    \t\t}\n    \t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n        }\n    \t\n    \treturn false;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n    \tPinger pinger;\n\t\ttry {\n\t\t\tpinger = new Pinger();\n\t    \tLong retval = pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","id":14834,"modified_method":"/**\n     * Returns true if the protocol defined by this plugin is supported. If the\n     * protocol is not supported then a false value is returned to the caller.\n     * \n     * @param address\n     *            The address to check for support.\n     * \n     * @return True if the protocol is supported by the address.\n     */\n    public boolean isProtocolSupported(InetAddress address) {\n\t\ttry {\n\t    \tLong retval = Pinger.ping(address);\n\t    \tif (retval != null) {\n\t    \t\treturn true;\n\t    \t}\n\t\t} catch (Exception e) {\n\t        Category log = ThreadCategory.getInstance(this.getClass());\n\t\t\tlog.warn(\"Pinger failed to ping \" + address, e);\n\t\t}\n\t\treturn false;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\tPinger pinger = new Pinger();\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","id":14835,"modified_method":"/**\n     * <P>\n     * Poll the specified address for ICMP service availability.\n     * <\/P>\n     * \n     * <P>\n     * The ICMP service monitor relies on Discovery for the actual generation of\n     * IMCP 'ping' requests. A JSDT session with two channels (send/receive) is\n     * utilized for passing poll requests and receiving poll replies from\n     * discovery. All exchanges are SOAP/XML compliant.\n     * <\/P>\n     * @param parameters\n     *            The package parameters (timeout, retry, etc...) to be used for\n     *            this poll.\n     * @param iface\n     *            The network interface to test the service on.\n     * @return The availability of the interface and if a transition event\n     *         should be suppressed.\n     * \n     */\n    public PollStatus poll(MonitoredService svc, Map parameters) {\n        NetworkInterface iface = svc.getNetInterface();\n\n        // Get interface address from NetworkInterface\n        //\n        if (iface.getType() != NetworkInterface.TYPE_IPV4)\n            throw new NetworkInterfaceNotSupportedException(\"Unsupported interface type, only TYPE_IPV4 currently supported\");\n\n        Category log = ThreadCategory.getInstance(this.getClass());\n        PollStatus serviceStatus = PollStatus.unavailable();\n\t\tInetAddress host = (InetAddress) iface.getAddress();\n\t\tList<Number> responseTimes = null;\n\t\t\n\t\ttry {\n\t\t\t\n\t\t\t// get parameters\n\t\t\t//\n\t\t\tlong timeout = ParameterMap.getKeyedLong(parameters, \"timeout\", Pinger.DEFAULT_TIMEOUT);\n\t\t\tint count = ParameterMap.getKeyedInteger(parameters, \"pings\", DEFAULT_MULTI_PING_COUNT);\n\t\t\tlong pingInterval = ParameterMap.getKeyedLong(parameters, \"interval\", DEFAULT_PING_INTERVAL);\n\t\t\t\n\t\t\tresponseTimes = new ArrayList<Number>(Pinger.parallelPing(host, count, timeout, pingInterval));\n\n\t\t\tserviceStatus = PollStatus.available();\n\t\t\tCollections.sort(responseTimes, new Comparator<Number>() {\n\n                public int compare(Number arg0, Number arg1) {\n                    if (arg0 == null) {\n                        return -1;\n                    } else if (arg1 == null) {\n                        return 1;\n                    } else if (arg0.doubleValue() == arg1.doubleValue()) {\n                        return 0;\n                    } else {\n                        return arg1.doubleValue() > arg0.doubleValue()? 1 : -1;\n                    }\n                }\n\t\t\t    \n\t\t\t});\n\t\t\t\n\t\t\tMap<String, Number> returnval = new LinkedHashMap<String,Number>();\n\t\t\tfor (int i = 0; i < responseTimes.size(); i++) {\n\t\t\t    returnval.put(\"ping\" + (i+1), responseTimes.get(i));\n\t\t\t}\n\t\t\treturnval.put(\"loss\", CollectionMath.countNull(responseTimes));\n\t\t\treturnval.put(\"median\", CollectionMath.median(responseTimes));\n\t\t\treturnval.put(\"response-time\", CollectionMath.average(responseTimes));\n\t\t\t\n\t\t\tserviceStatus.setProperties(returnval);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"failed to ping \" + host, e);\n\t\t}\n        \n        return serviceStatus;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"short getSequenceId() {\n        return m_sequenceId;\n    }","id":14836,"modified_method":"public short getSequenceId() {\n        return m_id.getSequenceId();\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, timeout, retries, DEFAULT_SEQUENCE_ID, cb);\n    }","id":14837,"modified_method":"PingRequest(InetAddress addr, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, DEFAULT_SEQUENCE_ID, timeout, retries, cb);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public long getTid() {\n        return m_tid;\n    }","id":14838,"modified_method":"public long getTid() {\n        return m_id.getTid();\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (m_addr.equals(addr) && getSequenceId() == sequenceId);\n    }","id":14839,"modified_method":"/**\n     * Returns true if the passed address and sequence ID is the target of the ping.\n     */\n    boolean isTarget(InetAddress addr, short sequenceId) {\n        return (getAddress().equals(addr) && getSequenceId() == sequenceId);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, long tid, short sequenceId, PingResponseCallback cb) {\n        m_addr       = addr;\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n        m_tid        = tid;\n        m_sequenceId = sequenceId;\n    }","id":14840,"modified_method":"PingRequest(InetAddress addr, long tid, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        m_id = new RequestId(addr, tid, sequenceId);\n        m_retries    = retries;\n        m_timeout    = timeout;\n        m_callback   = cb;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() > getExpiration());\n    }","id":14841,"modified_method":"public boolean isExpired() {\n        return (System.currentTimeMillis() >= getExpiration());\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            m_expiration = System.currentTimeMillis() + m_timeout;\n            ICMPEchoPacket iPkt = new ICMPEchoPacket(getTid());\n            iPkt.setIdentity(FILTER_ID);\n            iPkt.setSequenceId(getSequenceId());\n            iPkt.computeChecksum();\n            m_request = iPkt;\n\n            byte[] data = iPkt.toBytes();\n            DatagramPacket packet = new DatagramPacket(data, data.length, getAddress(), 0);\n            ThreadCategory.getInstance(this.getClass()).info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(packet);\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","id":14842,"modified_method":"/**\n     * Send this PingRequest through the given icmpSocket\n     * @param icmpSocket\n     */\n    public void sendRequest(IcmpSocket icmpSocket) {\n        try {\n            createRequestPacket();\n\n            log().info(System.currentTimeMillis()+\": Sending Ping Request: \"+this);\n            icmpSocket.send(createDatagram());\n        } catch (Throwable t) {\n            m_callback.handleError(this, t);\n        }\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public String toString() {\n        StringBuffer sb = new StringBuffer();\n        sb.append(this.getAddress()).append(\" [\");\n        sb.append(\"TID=\").append(this.getTid()).append(\",\");\n        sb.append(\"Sequence ID=\").append(this.getSequenceId()).append(\",\");\n        // sb.append(\"Callback=\").append(m_callback.getClass().getName()).append(\",\");\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration());\n        sb.append(\"]\");\n        return sb.toString();\n    }","id":14843,"modified_method":"public String toString() {\n        StringBuilder sb = new StringBuilder();\n        sb.append('[');\n        sb.append(\"ID=\").append(getId()).append(',');\n        sb.append(\"Retries=\").append(getRetries()).append(\",\");\n        sb.append(\"Timeout=\").append(getTimeout()).append(\",\");\n        sb.append(\"Expiration=\").append(getExpiration()).append(',');\n        sb.append(\"Callback=\").append(m_callback);\n        sb.append(\"]\");\n        return sb.toString();\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"PingRequest(InetAddress addr, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n        this(addr, timeout, retries, s_nextTid++, sequenceId, cb);\n    }","id":14844,"modified_method":"PingRequest(InetAddress addr, short sequenceId, long timeout, int retries, PingResponseCallback cb) {\n        this(addr, s_nextTid++, sequenceId, timeout, retries, cb);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        m_callback.handleResponse(packet);\n    }","id":14845,"modified_method":"public void processResponse(ICMPEchoPacket packet) {\n        m_response = packet;\n        log().info(System.currentTimeMillis()+\": Ping Response Received \"+this);\n        m_callback.handleResponse(packet);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTimeout(), getRetries() - 1, getTid(), getSequenceId(), m_callback);\n            } else {\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","id":14846,"modified_method":"public PingRequest processTimeout() {\n        PingRequest returnval = null;\n        if (this.isExpired()) {\n            if (this.getRetries() > 0) {\n                returnval = new PingRequest(getAddress(), getTid(), getSequenceId(), getTimeout(), getRetries() - 1, m_callback);\n                log().info(System.currentTimeMillis()+\": Retrying Ping Request \"+returnval);\n            } else {\n                log().info(System.currentTimeMillis()+\": Ping Request Timed out \"+this);\n                m_callback.handleTimeout(getRequest());\n            }\n        }\n        return returnval;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"InetAddress getAddress() {\n    \treturn m_addr;\n    }","id":14847,"modified_method":"public InetAddress getAddress() {\n        return m_id.getAddress();\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","id":14848,"modified_method":"public void testParallelPingFailure() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_badHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) == 0);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_pinger = new Pinger();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","id":14849,"modified_method":"@Override\n    protected void setUp() throws Exception {\n        if (!isRunTest()) {\n            return;\n        }\n\n        super.setUp();\n        m_goodHost = InetAddress.getByName(\"www.google.com\");\n        m_badHost  = InetAddress.getByName(\"1.1.1.1\");\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(m_pinger.ping(m_badHost));\n    }","id":14850,"modified_method":"public void testSinglePingFailure() throws Exception {\n        assertNull(Pinger.ping(m_badHost));\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testParallelPing() throws Exception {\n        List<Number> items = m_pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","id":14851,"modified_method":"public void testParallelPing() throws Exception {\n        List<Number> items = Pinger.parallelPing(m_goodHost, 20, Pinger.DEFAULT_TIMEOUT, 50);\n        Thread.sleep(1000);\n        printResponse(items);\n        assertTrue(CollectionMath.countNotNull(items) > 0);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void testSinglePing() throws Exception {\n        assertTrue(m_pinger.ping(m_goodHost) > 0);\n    }","id":14852,"modified_method":"public void testSinglePing() throws Exception {\n        assertTrue(Pinger.ping(m_goodHost) > 0);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tstartReplyProcessor();\n\t}","id":14853,"modified_method":"/**\n     * Initialize a Pinger object, specifying the timeout and retries.\n     * @param defaultTimeout the timeout, in milliseconds, to wait for returned packets.\n     * @param defaultRetries the number of times to retry a given ping packet\n     * @throws IOException\n     */\n\tpublic Pinger() throws IOException {\n\t\tinitialize();\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(PingRequest request, PingResponseCallback cb) {\n        synchronized(requestTracker.getTrackerLock()) {\n            requestTracker.registerRequest(request);\n            request.sendRequest(icmpSocket);\n        }\n    }","id":14854,"modified_method":"private static void ping(PingRequest request) throws IOException {\n        initialize();\n        synchronized(s_pendingRequests) {\n            s_pendingRequests.put(request.getId(), request);\n            request.sendRequest(s_icmpSocket);\n        }\n        debugf(\"Scheding timeout for request to %s in %d ms\", request, request.getDelay(TimeUnit.MILLISECONDS));\n        s_timeoutQueue.offer(request);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processReply(Reply pong) {\n        ICMPEchoPacket pongPacket = pong.getPacket();\n        Long key = new Long(pongPacket.getTID());\n        short sid = pongPacket.getSequenceId();\n        PingRequest ping = null;\n        synchronized(requestTracker.getTrackerLock()) {\n            if (requestTracker.getPendingRequestMap().containsKey(key)) {\n                PingRequest p = requestTracker.getPendingRequestMap().get(key);\n                if (p != null && p.isTarget(pong.getAddress(), sid)) {\n                    ping = p;\n                    requestTracker.getPendingRequestMap().remove(key);\n                }\n            }\n        }\n\n        if (ping != null) {\n            ping.processResponse(pong.getPacket());\n        }\n    }","id":14855,"modified_method":"private static void processReplies() throws InterruptedException {\n\t    while (true) {\n\t        Reply reply = s_pendingReplyQueue.take();\n            debugf(\"Found a reply to process: %s\", reply);\n\t        RequestId id = new RequestId(reply);\n\t        debugf(\"Looking for request with Id: %s in map %s\", id, s_pendingRequests);\n\t        PingRequest request = s_pendingRequests.remove(id);\n\t        if (request != null) {\n\t            debugf(\"Processing reply %s for request %s\", reply, request);\n\t            request.processResponse(reply.getPacket());\n\t        } else {\n\t            debugf(\"No request found for reply %s\", reply);\n\t        }\n\t    }\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, DEFAULT_TIMEOUT, 0, (short) i, cb);\n\t        ping(request, cb);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","id":14856,"modified_method":"public static List<Number> parallelPing(InetAddress host, int count, long timeout, long pingInterval) throws IOException, InterruptedException {\n\t    ParallelPingResponseCallback cb = new ParallelPingResponseCallback(count);\n\t    \n\t    for (int i = 0; i < count; i++) {\n\t        PingRequest request = new PingRequest(host, (short) i, DEFAULT_TIMEOUT, 0, cb);\n\t        ping(request);\n\t        Thread.sleep(pingInterval);\n\t    }\n\t    \n\t    cb.waitFor();\n\t    return cb.getResponseTimes();\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private Category log() {\n        return ThreadCategory.getInstance(this.getClass());\n    }","id":14857,"modified_method":"private static Category log() {\n        return ThreadCategory.getInstance(Pinger.class);\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return this.ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","id":14858,"modified_method":"/**\n\t * Ping a remote host, using the default number of retries and timeouts.\n\t * @param host the host to ping\n\t * @return the round-trip time of the packet\n\t * @throws IOException\n\t * @throws InterruptedException \n\t */\n\tpublic static Long ping(InetAddress host) throws IOException, InterruptedException {\n\t    return ping(host, DEFAULT_TIMEOUT, DEFAULT_RETRIES);\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) {\n    \tPingRequest request = new PingRequest(host, timeout, retries, sequenceId, cb);\n    \tsynchronized(requestTracker.getTrackerLock()) {\n    \t    requestTracker.registerRequest(request);\n    \t    request.sendRequest(icmpSocket);\n    \t}\n\t}","id":14859,"modified_method":"public static void ping(InetAddress host, long timeout, int retries, short sequenceId, PingResponseCallback cb) throws IOException {\n    \tping(new PingRequest(host, sequenceId, timeout, retries, cb));\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void processTimeouts() {\n        synchronized(requestTracker.getTrackerLock()) {\n            for (Iterator<Entry<Long, PingRequest>> it = requestTracker.getPendingRequestMap().entrySet().iterator(); it.hasNext(); ) {\n                PingRequest request = it.next().getValue();\n                log().debug(\"checking request \" + request);\n                if (request.isExpired()) {\n                    it.remove();\n                    PingRequest retry = request.processTimeout();\n                    if (retry != null) {\n                        requestTracker.registerRequest(retry);\n                        retry.sendRequest(icmpSocket);\n                    }\n                }\n            }\n        }\n    }","id":14860,"modified_method":"private static void processTimeouts() throws InterruptedException {  \n\t    while (true) {\n\t        PingRequest request = s_timeoutQueue.take();\n            debugf(\"Found a possibly timedout request: %s\", request);\n\t        if (s_pendingRequests.remove(request.getId()) == request) {\n\t            // then this request is still pending so we must time it out\n\t            debugf(\"Processing timeout for: %s\", request);\n\t            PingRequest retry = request.processTimeout();\n\t            if (retry != null) {\n\t                try {\n                        ping(retry);\n                    } catch (IOException e) {\n                        retry.processError(e);\n                    }\n\t            }\n\t        }\n\t        \n\t    }\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     */\n    public Long ping(InetAddress host, long timeout, int retries) throws InterruptedException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","id":14861,"modified_method":"/**\n     * This method is used to ping a remote host to test for ICMP support. If\n     * the remote host responds within the specified period, defined by retries\n     * and timeouts, then the response time is returned.\n     * \n     * @param host\n     *            The address to poll.\n     * @param timeout\n     *            The time to wait between each retry.\n     * @param retries\n     *            The number of times to retry\n     * \n     * @return The response time in microseconds if the host is reachable and has responded with an echo reply, otherwise a null value.\n     * @throws InterruptedException \n     * @throws IOException \n     */\n    public static Long ping(InetAddress host, long timeout, int retries) throws InterruptedException, IOException {\n        SinglePingResponseCallback cb = new SinglePingResponseCallback();\n        ping(host, timeout, retries, (short) 1, cb);\n        cb.waitFor();\n        return cb.getResponseTime();\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    private Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","id":14862,"modified_method":"/**\n     * Constructs a new reply with the passed address and packet as the contents\n     * of the reply.\n     * \n     * @param addr\n     *            The address of the ICMP sender.\n     * @param pkt\n     *            The received packet.\n     * \n     */\n    public Reply(InetAddress addr, ICMPEchoPacket pkt) {\n        m_packet = pkt;\n        m_address = addr;\n    }","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","id":14863,"modified_method":"public void handleResponse(ICMPEchoPacket packet) {\n\t    info(\"got response for \" + packet.getTID() + \"/\" + packet.getSequenceId() + \" with a responseTime \"+packet.getPingRTT());\n\t    responseTime = packet.getPingRTT();\n\t    bs.signalAll();\n\t}","commit_id":"1ef6b1b6a483b40060f6e78cb0374b8b763cba40","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Reads whole text file into String.\n     *\n     * @param fileName Name of the file to read.\n     * @return Content of the file as String value.\n     * @throws java.io.IOException If could not read the file.\n     */\n    protected String readAndSortFile(String fileName) throws IOException {\n        BufferedReader reader = new BufferedReader(new FileReader(fileName));\n\n        List<String> list = new ArrayList<>();\n\n        String line;\n\n        while ((line = reader.readLine()) != null)\n            list.add(line);\n\n        Collections.sort(list);\n\n        return Joiner.on('\\n').join(list) + \"\\n\";\n    }","id":14864,"modified_method":"/**\n     * Reads whole text file into String.\n     *\n     * @param fileName Name of the file to read.\n     * @return Content of the file as String value.\n     * @throws Exception If could not read the file.\n     */\n    protected String readAndSortFile(String fileName) throws Exception {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(ggfs.open(new GridGgfsPath(fileName))));\n\n        List<String> list = new ArrayList<>();\n\n        String line;\n\n        while ((line = reader.readLine()) != null)\n            list.add(line);\n\n        Collections.sort(list);\n\n        return Joiner.on('\\n').join(list) + \"\\n\";\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Determine the best node for this split.\n     *\n     * @param split Split.\n     * @param topIds Topology node IDs.\n     * @param nodes Nodes.\n     * @param nodeLoads Node load tracker.\n     * @return Node ID.\n     */\n    @SuppressWarnings(\"unchecked\")\n    private UUID nodeForSplit(GridHadoopInputSplit split, Collection<UUID> topIds, Map<String, Collection<UUID>> nodes,\n        Map<UUID, Integer> nodeLoads) throws GridException {\n        if (split instanceof GridHadoopFileBlock) {\n            GridHadoopFileBlock split0 = (GridHadoopFileBlock)split;\n\n            if (GGFS_SCHEME.equalsIgnoreCase(split0.file().getScheme())) {\n                // TODO GG-8300: Get GGFS by name based on URI.\n                GridGgfsEx ggfs = (GridGgfsEx)grid.ggfs(\"ggfs\");\n\n                if (ggfs != null && !ggfs.isProxy(split0.file())) {\n                    Collection<GridGgfsBlockLocation> blocks = ggfs.affinity(new GridGgfsPath(split0.file()),\n                        split0.start(), split0.length());\n\n                    assert blocks != null;\n\n                    if (blocks.size() == 1)\n                        // Fast-path, split consists of one GGFS block (as in most cases).\n                        return bestNode(blocks.iterator().next().nodeIds(), topIds, nodeLoads, false);\n                    else {\n                        // Slow-path, file consists of multiple GGFS blocks. First, find the most co-located nodes.\n                        Map<UUID, Long> nodeMap = new HashMap<>();\n\n                        List<UUID> bestNodeIds = null;\n                        long bestLen = -1L;\n\n                        for (GridGgfsBlockLocation block : blocks) {\n                            for (UUID blockNodeId : block.nodeIds()) {\n                                if (topIds.contains(blockNodeId)) {\n                                    Long oldLen = nodeMap.get(blockNodeId);\n                                    long newLen = oldLen == null ? block.length() : oldLen + block.length();\n\n                                    nodeMap.put(blockNodeId, newLen);\n\n                                    if (bestNodeIds == null || bestLen < newLen) {\n                                        bestNodeIds = new ArrayList<>(1);\n\n                                        bestNodeIds.add(blockNodeId);\n\n                                        bestLen = newLen;\n                                    }\n                                    else if (bestLen == newLen) {\n                                        assert !F.isEmpty(bestNodeIds);\n\n                                        bestNodeIds.add(blockNodeId);\n                                    }\n                                }\n                            }\n                        }\n\n                        if (bestNodeIds != null && bestNodeIds.size() == 1)\n                            // Optimization: if there is only one node with maximum length, return it.\n                            return bestNodeIds.get(0);\n                        else {\n                            // Several nodes have maximum length, decide which one to use.\n                            assert bestNodeIds != null;\n\n                            return bestNode(bestNodeIds, topIds, nodeLoads, true);\n                        }\n                    }\n                }\n            }\n        }\n\n        // Cannot use local GGFS for some reason, try selecting the node by host.\n        Collection<UUID> blockNodes = null;\n\n        for (String host : split.hosts()) {\n            Collection<UUID> hostNodes = nodes.get(host);\n\n            if (!F.isEmpty(hostNodes)) {\n                if (blockNodes == null)\n                    blockNodes = new ArrayList<>(hostNodes);\n                else\n                    blockNodes.addAll(hostNodes);\n            }\n        }\n\n        return bestNode(blockNodes, topIds, nodeLoads, false);\n    }","id":14865,"modified_method":"/**\n     * Determine the best node for this split.\n     *\n     * @param split Split.\n     * @param topIds Topology node IDs.\n     * @param nodes Nodes.\n     * @param nodeLoads Node load tracker.\n     * @return Node ID.\n     */\n    @SuppressWarnings(\"unchecked\")\n    private UUID nodeForSplit(GridHadoopInputSplit split, Collection<UUID> topIds, Map<String, Collection<UUID>> nodes,\n        Map<UUID, Integer> nodeLoads) throws GridException {\n        if (split instanceof GridHadoopFileBlock) {\n            GridHadoopFileBlock split0 = (GridHadoopFileBlock)split;\n\n            if (GGFS_SCHEME.equalsIgnoreCase(split0.file().getScheme())) {\n                // TODO GG-8300: Get GGFS by name based on URI.\n                GridGgfsEx ggfs = (GridGgfsEx)grid.ggfs(\"ggfs\");\n\n                if (ggfs != null && !ggfs.isProxy(split0.file())) {\n                    Collection<GridGgfsBlockLocation> blocks = ggfs.affinity(new GridGgfsPath(split0.file()),\n                        split0.start(), split0.length());\n\n                    assert blocks != null;\n\n                    if (blocks.size() == 1)\n                        // Fast-path, split consists of one GGFS block (as in most cases).\n                        return bestNode(blocks.iterator().next().nodeIds(), topIds, nodeLoads, false);\n                    else {\n                        // Slow-path, file consists of multiple GGFS blocks. First, find the most co-located nodes.\n                        Map<UUID, Long> nodeMap = new HashMap<>();\n\n                        List<UUID> bestNodeIds = null;\n                        long bestLen = -1L;\n\n                        for (GridGgfsBlockLocation block : blocks) {\n                            for (UUID blockNodeId : block.nodeIds()) {\n                                if (topIds.contains(blockNodeId)) {\n                                    Long oldLen = nodeMap.get(blockNodeId);\n                                    long newLen = oldLen == null ? block.length() : oldLen + block.length();\n\n                                    nodeMap.put(blockNodeId, newLen);\n\n                                    if (bestNodeIds == null || bestLen < newLen) {\n                                        bestNodeIds = new ArrayList<>(1);\n\n                                        bestNodeIds.add(blockNodeId);\n\n                                        bestLen = newLen;\n                                    }\n                                    else if (bestLen == newLen) {\n                                        assert !F.isEmpty(bestNodeIds);\n\n                                        bestNodeIds.add(blockNodeId);\n                                    }\n                                }\n                            }\n                        }\n\n                        if (bestNodeIds != null) {\n                            return bestNodeIds.size() == 1 ? bestNodeIds.get(0) :\n                                bestNode(bestNodeIds, topIds, nodeLoads, true);\n                        }\n                    }\n                }\n            }\n        }\n\n        // Cannot use local GGFS for some reason, try selecting the node by host.\n        Collection<UUID> blockNodes = null;\n\n        for (String host : split.hosts()) {\n            Collection<UUID> hostNodes = nodes.get(host);\n\n            if (!F.isEmpty(hostNodes)) {\n                if (blockNodes == null)\n                    blockNodes = new ArrayList<>(hostNodes);\n                else\n                    blockNodes.addAll(hostNodes);\n            }\n        }\n\n        return bestNode(blockNodes, topIds, nodeLoads, false);\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Tests whole job execution with all phases in all combination of new and old versions of API.\n     * @throws Exception If fails.\n     */\n    public void testWholeMapReduceExecution() throws Exception {\n        File testInputFile = File.createTempFile(GridHadoopWordCount2.class.getSimpleName(), \"-input\");\n\n        testInputFile.deleteOnExit();\n\n        generateTestFile(testInputFile, \"red\", 100000, \"blue\", 200000, \"green\", 150000, \"yellow\", 70000);\n\n        File testOutputDir = Files.createTempDirectory(\"job-output\").toFile();\n\n        for (int i = 0; i < 16; i++) {\n            boolean useNewMapper = (i & 1) == 0;\n            boolean useNewCombiner = (i & 2) == 0;\n            boolean useNewReducer = (i & 4) == 0;\n            boolean useCustomSerializer = (i & 8) == 0;\n\n            JobConf jobConf = new JobConf();\n\n            if (useCustomSerializer)\n                jobConf.set(CommonConfigurationKeys.IO_SERIALIZATIONS_KEY, CustomSerialization.class.getName());\n\n            //To split into about 40 items for v2\n            jobConf.setInt(FileInputFormat.SPLIT_MAXSIZE, 65000);\n\n            //For v1\n            jobConf.setInt(\"fs.local.block.size\", 65000);\n\n            GridHadoopWordCount1.setTasksClasses(jobConf, !useNewMapper, !useNewCombiner, !useNewReducer);\n\n            Job job = Job.getInstance(jobConf);\n\n            GridHadoopWordCount2.setTasksClasses(job, useNewMapper, useNewCombiner, useNewReducer);\n\n            job.setOutputKeyClass(Text.class);\n            job.setOutputValueClass(IntWritable.class);\n\n            FileInputFormat.setInputPaths(job, new Path(testInputFile.getAbsolutePath()));\n            FileOutputFormat.setOutputPath(job, new Path(testOutputDir.getAbsolutePath()));\n\n            job.setJarByClass(GridHadoopWordCount2.class);\n\n            try {\n                GridHadoopProcessorAdapter hadoop = ((GridKernal) grid(0)).context().hadoop();\n\n                GridFuture<?> fut = hadoop.submit(new GridHadoopJobId(UUID.randomUUID(), 1),\n                        new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n                fut.get();\n\n                assertEquals(\"Use new mapper = \" + useNewMapper + \", combiner = \" + useNewCombiner + \"reducer = \" + useNewReducer,\n                    \"blue\\t200000\\n\" +\n                    \"green\\t150000\\n\" +\n                    \"red\\t100000\\n\" +\n                    \"yellow\\t70000\\n\",\n                    readAndSortFile(testOutputDir.getAbsolutePath() + \"/\" + (useNewReducer ? \"part-r-\" : \"part-\") + \"00000\")\n                );\n            }\n            finally {\n                FileUtils.deleteDirectory(testOutputDir);\n            }\n        }\n    }","id":14866,"modified_method":"/**\n     * Tests whole job execution with all phases in all combination of new and old versions of API.\n     * @throws Exception If fails.\n     */\n    public void testWholeMapReduceExecution() throws Exception {\n        GridGgfsPath inDir = new GridGgfsPath(PATH_INPUT);\n\n        ggfs.mkdirs(inDir);\n\n        GridGgfsPath inFile = new GridGgfsPath(inDir, GridHadoopWordCount2.class.getSimpleName() + \"-input\");\n\n        generateTestFile(inFile.toString(), \"red\", 100000, \"blue\", 200000, \"green\", 150000, \"yellow\", 70000 );\n\n        for (int i = 0; i < 16; i++) {\n            ggfs.delete(new GridGgfsPath(PATH_OUTPUT), true);\n\n            boolean useNewMapper = (i & 1) == 0;\n            boolean useNewCombiner = (i & 2) == 0;\n            boolean useNewReducer = (i & 4) == 0;\n            boolean useCustomSerializer = (i & 8) == 0;\n\n            JobConf jobConf = new JobConf();\n\n            if (useCustomSerializer)\n                jobConf.set(CommonConfigurationKeys.IO_SERIALIZATIONS_KEY, CustomSerialization.class.getName());\n\n            //To split into about 40 items for v2\n            jobConf.setInt(FileInputFormat.SPLIT_MAXSIZE, 65000);\n\n            //For v1\n            jobConf.setInt(\"fs.local.block.size\", 65000);\n\n            // File system coordinates.\n            jobConf.set(\"fs.default.name\", GGFS_SCHEME);\n            jobConf.set(\"fs.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v1.GridGgfsHadoopFileSystem\");\n            jobConf.set(\"fs.AbstractFileSystem.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v2.GridGgfsHadoopFileSystem\");\n\n            GridHadoopWordCount1.setTasksClasses(jobConf, !useNewMapper, !useNewCombiner, !useNewReducer);\n\n            Job job = Job.getInstance(jobConf);\n\n            GridHadoopWordCount2.setTasksClasses(job, useNewMapper, useNewCombiner, useNewReducer);\n\n            job.setOutputKeyClass(Text.class);\n            job.setOutputValueClass(IntWritable.class);\n\n            FileInputFormat.setInputPaths(job, new Path(GGFS_SCHEME + inFile.toString()));\n            FileOutputFormat.setOutputPath(job, new Path(GGFS_SCHEME + PATH_OUTPUT));\n\n            job.setJarByClass(GridHadoopWordCount2.class);\n\n            GridHadoopProcessorAdapter hadoop = ((GridKernal) grid(0)).context().hadoop();\n\n            GridFuture<?> fut = hadoop.submit(new GridHadoopJobId(UUID.randomUUID(), 1),\n                    new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n            fut.get();\n\n            assertEquals(\"Use new mapper = \" + useNewMapper + \", combiner = \" + useNewCombiner + \"reducer = \" +\n                    useNewReducer,\n                \"blue\\t200000\\n\" +\n                \"green\\t150000\\n\" +\n                \"red\\t100000\\n\" +\n                \"yellow\\t70000\\n\",\n                readAndSortFile(PATH_OUTPUT + \"/\" + (useNewReducer ? \"part-r-\" : \"part-\") +\n                    \"00000\")\n            );\n        }\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @throws Exception If failed.\n     */\n    public void testTaskCancelling() throws Exception {\n        int lineCnt = 10000;\n        String fileName = \"/testFile\";\n\n        prepareFile(fileName, lineCnt);\n\n        executedTasks.set(0);\n        cancelledTasks.set(0);\n        failMapperId = 0;\n\n        Configuration cfg = new Configuration();\n\n        cfg.setStrings(\"fs.ggfs.impl\", GridGgfsHadoopFileSystem.class.getName());\n\n        Job job = Job.getInstance(cfg);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        job.setMapperClass(CancellingTestMapper.class);\n\n        job.setNumReduceTasks(0);\n\n        job.setInputFormatClass(TextInputFormat.class);\n\n        FileInputFormat.setInputPaths(job, new Path(\"ggfs://ipc/\"));\n        FileOutputFormat.setOutputPath(job, new Path(\"ggfs://ipc/out/\"));\n\n        job.setJarByClass(getClass());\n\n        GridHadoopProcessorAdapter hadoop = ((GridKernal) grid(0)).context().hadoop();\n\n        GridHadoopJobId jobId = new GridHadoopJobId(UUID.randomUUID(), 1);\n\n        final GridFuture<?> fut = hadoop.submit(jobId, new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n        while (executedTasks.get() != 32) {\n            Thread.sleep(100);\n        }\n\n        // Fail mapper with id \"1\", cancels others\n        failMapperId = 1;\n\n        GridTestUtils.assertThrows(log, new Callable<Object>() {\n            @Override public Object call() throws Exception {\n                fut.get();\n\n                return null;\n            }\n        }, GridException.class, null);\n\n\n        assertEquals(executedTasks.get(), cancelledTasks.get() + 1);\n    }","id":14867,"modified_method":"/**\n     * @throws Exception If failed.\n     */\n    // TODO: Hangs.\n    public void testTaskCancelling() throws Exception {\n        int lineCnt = 10000;\n        String fileName = \"/testFile\";\n\n        prepareFile(fileName, lineCnt);\n\n        executedTasks.set(0);\n        cancelledTasks.set(0);\n        failMapperId = 0;\n\n        Configuration cfg = new Configuration();\n\n        cfg.set(\"fs.ggfs.impl\", GridGgfsHadoopFileSystem.class.getName());\n\n        Job job = Job.getInstance(cfg);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        job.setMapperClass(CancellingTestMapper.class);\n\n        job.setNumReduceTasks(0);\n\n        job.setInputFormatClass(TextInputFormat.class);\n\n        FileInputFormat.setInputPaths(job, new Path(\"ggfs://ipc/\"));\n        FileOutputFormat.setOutputPath(job, new Path(\"ggfs://ipc/out/\"));\n\n        job.setJarByClass(getClass());\n\n        GridHadoopProcessorAdapter hadoop = ((GridKernal) grid(0)).context().hadoop();\n\n        GridHadoopJobId jobId = new GridHadoopJobId(UUID.randomUUID(), 1);\n\n        final GridFuture<?> fut = hadoop.submit(jobId, new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n        while (executedTasks.get() != 32) {\n            Thread.sleep(100);\n        }\n\n        // Fail mapper with id \"1\", cancels others\n        failMapperId = 1;\n\n        GridTestUtils.assertThrows(log, new Callable<Object>() {\n            @Override public Object call() throws Exception {\n                fut.get();\n\n                return null;\n            }\n        }, GridException.class, null);\n\n\n        assertEquals(executedTasks.get(), cancelledTasks.get() + 1);\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @throws Exception If failed.\n     */\n    public void testMapRun() throws Exception {\n        int lineCnt = 10000;\n        String fileName = \"/testFile\";\n\n        prepareFile(fileName, lineCnt);\n\n        totalLineCnt.set(0);\n\n        Configuration cfg = new Configuration();\n\n        cfg.setStrings(\"fs.ggfs.impl\", GridGgfsHadoopFileSystem.class.getName());\n\n        Job job = Job.getInstance(cfg);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        job.setMapperClass(TestMapper.class);\n\n        job.setNumReduceTasks(0);\n\n        job.setInputFormatClass(TextInputFormat.class);\n\n        FileInputFormat.setInputPaths(job, new Path(\"ggfs://ipc/\"));\n\n        job.setJarByClass(getClass());\n\n        GridHadoopProcessorAdapter hadoop = ((GridKernal)grid(0)).context().hadoop();\n\n        GridFuture<?> fut = hadoop.submit(new GridHadoopJobId(UUID.randomUUID(), 1),\n            new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n        fut.get();\n\n        assertEquals(lineCnt, totalLineCnt.get());\n    }","id":14868,"modified_method":"/**\n     * @throws Exception If failed.\n     */\n    public void testMapRun() throws Exception {\n        int lineCnt = 10000;\n        String fileName = \"/testFile\";\n\n        prepareFile(fileName, lineCnt);\n\n        totalLineCnt.set(0);\n\n        Configuration cfg = new Configuration();\n\n        cfg.setStrings(\"fs.ggfs.impl\", GridGgfsHadoopFileSystem.class.getName());\n\n        Job job = Job.getInstance(cfg);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        job.setMapperClass(TestMapper.class);\n\n        job.setNumReduceTasks(0);\n\n        job.setInputFormatClass(TextInputFormat.class);\n\n        FileInputFormat.setInputPaths(job, new Path(\"ggfs://ipc/\"));\n        FileOutputFormat.setOutputPath(job, new Path(\"ggfs://ipc/\"));\n\n        job.setJarByClass(getClass());\n\n        GridHadoopProcessorAdapter hadoop = ((GridKernal)grid(0)).context().hadoop();\n\n        GridFuture<?> fut = hadoop.submit(new GridHadoopJobId(UUID.randomUUID(), 1),\n            new GridHadoopDefaultJobInfo(job.getConfiguration()));\n\n        fut.get();\n\n        assertEquals(lineCnt, totalLineCnt.get());\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Tests reduce task execution.\n     *\n     * @throws Exception If fails.\n     */\n    public void testReduceTask() throws Exception {\n        Path outputDir = Files.createTempDirectory(GridHadoopWordCount2.class.getSimpleName() + \"-output\");\n\n        try {\n            URI testOutputDirURI = outputDir.toUri();\n\n            GridHadoopJob gridJob = getHadoopJob(\"/\", testOutputDirURI.toString());\n\n            runTaskWithInput(gridJob, GridHadoopTaskType.REDUCE, 0, \"word1\", \"5\", \"word2\", \"10\");\n            runTaskWithInput(gridJob, GridHadoopTaskType.REDUCE, 1, \"word3\", \"7\", \"word4\", \"15\");\n\n            assertEquals(\n                \"word1\\t5\\n\" +\n                \"word2\\t10\\n\",\n                readAndSortFile(outputDir + \"/_temporary/0/task_00000000-0000-0000-0000-000000000000_0000_r_000000/\" +\n                        getOutputFileNamePrefix() + \"00000\")\n            );\n\n            assertEquals(\n                \"word3\\t7\\n\" +\n                \"word4\\t15\\n\",\n                readAndSortFile(outputDir + \"/_temporary/0/task_00000000-0000-0000-0000-000000000000_0000_r_000001/\" +\n                        getOutputFileNamePrefix() + \"00001\")\n            );\n        }\n        finally {\n            FileUtils.deleteDirectory(outputDir.toFile());\n        }\n    }","id":14869,"modified_method":"/**\n     * Tests reduce task execution.\n     *\n     * @throws Exception If fails.\n     */\n    public void testReduceTask() throws Exception {\n        GridHadoopJob gridJob = getHadoopJob(GGFS_SCHEME + PATH_INPUT, GGFS_SCHEME + PATH_OUTPUT);\n\n        runTaskWithInput(gridJob, GridHadoopTaskType.REDUCE, 0, \"word1\", \"5\", \"word2\", \"10\");\n        runTaskWithInput(gridJob, GridHadoopTaskType.REDUCE, 1, \"word3\", \"7\", \"word4\", \"15\");\n\n        assertEquals(\n            \"word1\\t5\\n\" +\n            \"word2\\t10\\n\",\n            readAndSortFile(PATH_OUTPUT + \"/_temporary/0/task_00000000-0000-0000-0000-000000000000_0000_r_000000/\" +\n                    getOutputFileNamePrefix() + \"00000\")\n        );\n\n        assertEquals(\n            \"word3\\t7\\n\" +\n            \"word4\\t15\\n\",\n            readAndSortFile(PATH_OUTPUT + \"/_temporary/0/task_00000000-0000-0000-0000-000000000000_0000_r_000001/\" +\n                    getOutputFileNamePrefix() + \"00001\")\n        );\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Tests all job in complex.\n     * Runs 2 chains of map-combine tasks and sends result into one reduce task.\n     *\n     * @throws Exception If fails.\n     */\n    public void testAllTasks() throws Exception {\n        Path outputDir = Files.createTempDirectory(GridHadoopWordCount2.class.getSimpleName() + \"-output\");\n\n        try {\n            URI testOutputDirURI = URI.create(outputDir.toString());\n\n            File testInputFile = File.createTempFile(GridHadoopWordCount2.class.getSimpleName(), \"-input\");\n            testInputFile.deleteOnExit();\n\n            URI testInputFileURI = URI.create(testInputFile.getAbsolutePath());\n\n            generateTestFile(testInputFile, \"red\", 100, \"blue\", 200, \"green\", 150, \"yellow\", 70);\n\n            //Split file into two blocks\n            Long l = testInputFile.length() / 2;\n            GridHadoopFileBlock fileBlock1 = new GridHadoopFileBlock(HOSTS, testInputFileURI, 0, l);\n            GridHadoopFileBlock fileBlock2 = new GridHadoopFileBlock(HOSTS, testInputFileURI, l, testInputFile.length() - l);\n\n            GridHadoopJob gridJob = getHadoopJob(testInputFileURI.toString(), testOutputDirURI.toString());\n\n            GridHadoopTestTaskContext combine1Ctx = runMapCombineTask(fileBlock1, gridJob);\n\n            GridHadoopTestTaskContext combine2Ctx = runMapCombineTask(fileBlock2, gridJob);\n\n            //Prepare input for combine\n            GridHadoopTestTaskContext reduceCtx = new GridHadoopTestTaskContext(gridJob);\n            reduceCtx.makeTreeOfWritables(combine1Ctx.mockOutput());\n            reduceCtx.makeTreeOfWritables(combine2Ctx.mockOutput());\n\n            GridHadoopTaskInfo taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.REDUCE, gridJob.id(), 0, 0, null);\n            GridHadoopTask task = gridJob.createTask(taskInfo);\n\n            task.run(reduceCtx);\n\n            taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.COMMIT, gridJob.id(), 0, 0, null);\n            task = gridJob.createTask(taskInfo);\n\n            task.run(reduceCtx);\n\n            assertEquals(\n                \"blue\\t200\\n\" +\n                \"green\\t150\\n\" +\n                \"red\\t100\\n\" +\n                \"yellow\\t70\\n\",\n                readAndSortFile(outputDir + \"/\" + getOutputFileNamePrefix() + \"00000\")\n            );\n        }\n        finally {\n            FileUtils.deleteDirectory(outputDir.toFile());\n        }\n    }","id":14870,"modified_method":"/**\n     * Tests all job in complex.\n     * Runs 2 chains of map-combine tasks and sends result into one reduce task.\n     *\n     * @throws Exception If fails.\n     */\n    @SuppressWarnings(\"ConstantConditions\")\n    public void testAllTasks() throws Exception {\n        GridGgfsPath inDir = new GridGgfsPath(PATH_INPUT);\n\n        ggfs.mkdirs(inDir);\n\n        GridGgfsPath inFile = new GridGgfsPath(inDir, GridHadoopWordCount2.class.getSimpleName() + \"-input\");\n\n        URI inFileUri = URI.create(GGFS_SCHEME + inFile.toString());\n\n        generateTestFile(inFile.toString(), \"red\", 100, \"blue\", 200, \"green\", 150, \"yellow\", 70);\n\n        //Split file into two blocks\n        long fileLen = ggfs.info(inFile).length();\n\n        Long l = fileLen / 2;\n\n        GridHadoopFileBlock fileBlock1 = new GridHadoopFileBlock(HOSTS, inFileUri, 0, l);\n        GridHadoopFileBlock fileBlock2 = new GridHadoopFileBlock(HOSTS, inFileUri, l, fileLen - l);\n\n        GridHadoopJob gridJob = getHadoopJob(GGFS_SCHEME + inFileUri.toString(), GGFS_SCHEME + PATH_OUTPUT);\n\n        GridHadoopTestTaskContext combine1Ctx = runMapCombineTask(fileBlock1, gridJob);\n\n        GridHadoopTestTaskContext combine2Ctx = runMapCombineTask(fileBlock2, gridJob);\n\n        //Prepare input for combine\n        GridHadoopTestTaskContext reduceCtx = new GridHadoopTestTaskContext(gridJob);\n\n        reduceCtx.makeTreeOfWritables(combine1Ctx.mockOutput());\n        reduceCtx.makeTreeOfWritables(combine2Ctx.mockOutput());\n\n        GridHadoopTaskInfo taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.REDUCE, gridJob.id(), 0, 0, null);\n\n        GridHadoopTask task = gridJob.createTask(taskInfo);\n\n        task.run(reduceCtx);\n\n        taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.COMMIT, gridJob.id(), 0, 0, null);\n\n        task = gridJob.createTask(taskInfo);\n\n        task.run(reduceCtx);\n\n        assertEquals(\n            \"blue\\t200\\n\" +\n                \"green\\t150\\n\" +\n                \"red\\t100\\n\" +\n                \"yellow\\t70\\n\",\n            readAndSortFile(PATH_OUTPUT + \"/\" + getOutputFileNamePrefix() + \"00000\")\n        );\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Tests map task execution.\n     *\n     * @throws Exception If fails.\n     */\n    public void testMapTask() throws Exception {\n        File testInputFile = File.createTempFile(GridHadoopWordCount2.class.getSimpleName(), \"-input\");\n\n        testInputFile.deleteOnExit();\n\n        URI testInputFileURI = URI.create(testInputFile.getAbsolutePath());\n\n        PrintWriter testInputFileWriter = new PrintWriter(testInputFile);\n\n        testInputFileWriter.println(\"hello0 world0\");\n        testInputFileWriter.println(\"world1 hello1\");\n        testInputFileWriter.flush();\n\n        GridHadoopFileBlock fileBlock1 = new GridHadoopFileBlock(HOSTS, testInputFileURI, 0, testInputFile.length() - 1);\n\n        testInputFileWriter.println(\"hello2 world2\");\n        testInputFileWriter.println(\"world3 hello3\");\n        testInputFileWriter.close();\n\n        GridHadoopFileBlock fileBlock2 =\n                new GridHadoopFileBlock(HOSTS, testInputFileURI, fileBlock1.length(), testInputFile.length() - fileBlock1.length());\n\n        GridHadoopJob gridJob = getHadoopJob(testInputFileURI.toString(), \"/\");\n\n        GridHadoopTestTaskContext ctx = new GridHadoopTestTaskContext(gridJob);\n\n        ctx.mockOutput().clear();\n        GridHadoopTaskInfo taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.MAP, gridJob.id(), 0, 0, fileBlock1);\n        GridHadoopTask task = gridJob.createTask(taskInfo);\n        task.run(ctx);\n\n        assertEquals(\"hello0,1; world0,1; world1,1; hello1,1\", Joiner.on(\"; \").join(ctx.mockOutput()));\n\n        ctx.mockOutput().clear();\n        taskInfo = new GridHadoopTaskInfo (null, GridHadoopTaskType.MAP, gridJob.id(), 0, 0, fileBlock2);\n        task = gridJob.createTask(taskInfo);\n        task.run(ctx);\n\n        assertEquals(\"hello2,1; world2,1; world3,1; hello3,1\", Joiner.on(\"; \").join(ctx.mockOutput()));\n    }","id":14871,"modified_method":"/**\n     * Tests map task execution.\n     *\n     * @throws Exception If fails.\n     */\n    @SuppressWarnings(\"ConstantConditions\")\n    public void testMapTask() throws Exception {\n        GridGgfsPath inDir = new GridGgfsPath(PATH_INPUT);\n\n        ggfs.mkdirs(inDir);\n\n        GridGgfsPath inFile = new GridGgfsPath(inDir, GridHadoopWordCount2.class.getSimpleName() + \"-input\");\n\n        URI inFileUri = URI.create(GGFS_SCHEME + inFile.toString());\n\n        try (PrintWriter pw = new PrintWriter(ggfs.create(inFile, true))) {\n            pw.println(\"hello0 world0\");\n            pw.println(\"world1 hello1\");\n        }\n\n        GridHadoopFileBlock fileBlock1 = new GridHadoopFileBlock(HOSTS, inFileUri, 0, ggfs.info(inFile).length() - 1);\n\n        try (PrintWriter pw = new PrintWriter(ggfs.append(inFile, false))) {\n            pw.println(\"hello2 world2\");\n            pw.println(\"world3 hello3\");\n        }\n        GridHadoopFileBlock fileBlock2 = new GridHadoopFileBlock(HOSTS, inFileUri, fileBlock1.length(),\n                ggfs.info(inFile).length() - fileBlock1.length());\n\n        GridHadoopJob gridJob = getHadoopJob(GGFS_SCHEME + inFile.toString(), GGFS_SCHEME + PATH_OUTPUT);\n\n        GridHadoopTestTaskContext ctx = new GridHadoopTestTaskContext(gridJob);\n\n        ctx.mockOutput().clear();\n\n        GridHadoopTaskInfo taskInfo = new GridHadoopTaskInfo(null, GridHadoopTaskType.MAP, gridJob.id(), 0, 0,\n            fileBlock1);\n\n        GridHadoopTask task = gridJob.createTask(taskInfo);\n\n        task.run(ctx);\n\n        assertEquals(\"hello0,1; world0,1; world1,1; hello1,1\", Joiner.on(\"; \").join(ctx.mockOutput()));\n\n        ctx.mockOutput().clear();\n\n        taskInfo = new GridHadoopTaskInfo (null, GridHadoopTaskType.MAP, gridJob.id(), 0, 0, fileBlock2);\n\n        task = gridJob.createTask(taskInfo);\n\n        task.run(ctx);\n\n        assertEquals(\"hello2,1; world2,1; world3,1; hello3,1\", Joiner.on(\"; \").join(ctx.mockOutput()));\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Creates WordCount hadoop job for API v1.\n     *\n     * @param inFile Input file name for the job.\n     * @param outFile Output file name for the job.\n     * @return Hadoop job.\n     * @throws IOException If fails.\n     */\n    @Override public GridHadoopJob getHadoopJob(String inFile, String outFile) throws Exception {\n        JobConf hadoopJob = GridHadoopWordCount1.getJob(inFile, outFile);\n\n        GridHadoopDefaultJobInfo jobInfo = new GridHadoopDefaultJobInfo(hadoopJob);\n\n        GridHadoopJobId jobId = new GridHadoopJobId(new UUID(0, 0), 0);\n\n        GridHadoopV2Job gridHadoopJob = new GridHadoopV2Job(jobId, jobInfo);\n\n        return gridHadoopJob;\n    }","id":14872,"modified_method":"/**\n     * Creates WordCount hadoop job for API v1.\n     *\n     * @param inFile Input file name for the job.\n     * @param outFile Output file name for the job.\n     * @return Hadoop job.\n     * @throws IOException If fails.\n     */\n    @Override public GridHadoopJob getHadoopJob(String inFile, String outFile) throws Exception {\n        JobConf hadoopJob = GridHadoopWordCount1.getJob(inFile, outFile);\n\n        hadoopJob.set(\"fs.default.name\", GGFS_SCHEME);\n        hadoopJob.set(\"fs.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v1.GridGgfsHadoopFileSystem\");\n        hadoopJob.set(\"fs.AbstractFileSystem.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v2.GridGgfsHadoopFileSystem\");\n\n        GridHadoopDefaultJobInfo jobInfo = new GridHadoopDefaultJobInfo(hadoopJob);\n\n        GridHadoopJobId jobId = new GridHadoopJobId(new UUID(0, 0), 0);\n\n        GridHadoopV2Job gridHadoopJob = new GridHadoopV2Job(jobId, jobInfo);\n\n        return gridHadoopJob;\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Creates WordCount hadoop job for API v2.\n     *\n     * @param inFile Input file name for the job.\n     * @param outFile Output file name for the job.\n     * @return Hadoop job.\n     * @throws Exception if fails.\n     */\n    @Override public GridHadoopJob getHadoopJob(String inFile, String outFile) throws Exception {\n        Job hadoopJob = GridHadoopWordCount2.getJob(inFile, outFile);\n\n        GridHadoopDefaultJobInfo jobInfo = new GridHadoopDefaultJobInfo(hadoopJob.getConfiguration());\n\n        GridHadoopJobId jobId = new GridHadoopJobId(new UUID(0, 0), 0);\n\n        GridHadoopV2Job gridHadoopJob = new GridHadoopV2Job(jobId, jobInfo);\n\n        hadoopJob.setJobID(gridHadoopJob.hadoopJobContext().getJobID());\n\n        return gridHadoopJob;\n    }","id":14873,"modified_method":"/**\n     * Creates WordCount hadoop job for API v2.\n     *\n     * @param inFile Input file name for the job.\n     * @param outFile Output file name for the job.\n     * @return Hadoop job.\n     * @throws Exception if fails.\n     */\n    @Override public GridHadoopJob getHadoopJob(String inFile, String outFile) throws Exception {\n        Job job = Job.getInstance();\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        GridHadoopWordCount2.setTasksClasses(job, true, true, true);\n\n        Configuration conf = job.getConfiguration();\n\n        conf.set(\"fs.default.name\", GGFS_SCHEME);\n        conf.set(\"fs.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v1.GridGgfsHadoopFileSystem\");\n        conf.set(\"fs.AbstractFileSystem.ggfs.impl\", \"org.gridgain.grid.ggfs.hadoop.v2.GridGgfsHadoopFileSystem\");\n\n        FileInputFormat.setInputPaths(job, new Path(inFile));\n        FileOutputFormat.setOutputPath(job, new Path(outFile));\n\n        job.setJarByClass(GridHadoopWordCount2.class);\n\n        Job hadoopJob = GridHadoopWordCount2.getJob(inFile, outFile);\n\n        GridHadoopDefaultJobInfo jobInfo = new GridHadoopDefaultJobInfo(hadoopJob.getConfiguration());\n\n        GridHadoopJobId jobId = new GridHadoopJobId(new UUID(0, 0), 0);\n\n        GridHadoopV2Job gridHadoopJob = new GridHadoopV2Job(jobId, jobInfo);\n\n        hadoopJob.setJobID(gridHadoopJob.hadoopJobContext().getJobID());\n\n        return gridHadoopJob;\n    }","commit_id":"9ea00614e257bfad64d6befd890772c1ca1b2394","url":"https://github.com/apache/ignite"},{"original_method":"@Override\n  public Optional<EvictionPlan> freeSpace(long bytes, BlockStoreLocation location) {\n    List<Pair<Long, BlockStoreLocation>> toMove = new ArrayList<Pair<Long, BlockStoreLocation>>();\n    List<Long> toEvict = new ArrayList<Long>();\n\n    long spaceFreed = 0;\n    if (location.equals(BlockStoreLocation.anyTier())) {\n      for (StorageTier tier : mMetaManager.getTiers()) {\n        for (StorageDir dir : tier.getStorageDirs()) {\n          for (BlockMeta block : dir.getBlocks()) {\n            toEvict.add(block.getBlockId());\n            spaceFreed += block.getBlockSize();\n            if (spaceFreed >= bytes) {\n              return Optional.of(new EvictionPlan(toMove, toEvict));\n            }\n          }\n        }\n      }\n      return Optional.absent();\n    }\n\n    int tierAlias = location.tierAlias();\n    StorageTier tier = mMetaManager.getTier(tierAlias);\n    if (location.equals(BlockStoreLocation.anyDirInTier(tierAlias))) {\n      // Loop over all dirs in the given tier\n      for (StorageDir dir : tier.getStorageDirs()) {\n        for (BlockMeta block : dir.getBlocks()) {\n          toEvict.add(block.getBlockId());\n          spaceFreed += block.getBlockSize();\n          if (spaceFreed >= bytes) {\n            return Optional.of(new EvictionPlan(toMove, toEvict));\n          }\n        }\n      }\n      return Optional.absent();\n    }\n\n    int dirIndex = location.dir();\n    StorageDir dir = tier.getDir(dirIndex);\n    for (BlockMeta block : dir.getBlocks()) {\n      toEvict.add(block.getBlockId());\n      spaceFreed += block.getBlockSize();\n      if (spaceFreed >= bytes) {\n        return Optional.of(new EvictionPlan(toMove, toEvict));\n      }\n    }\n    return Optional.absent();\n  }","id":14874,"modified_method":"@Override\n  public Optional<EvictionPlan> freeSpace(long availableBytes, BlockStoreLocation location) {\n    List<Pair<Long, BlockStoreLocation>> toMove = new ArrayList<Pair<Long, BlockStoreLocation>>();\n    List<Long> toEvict = new ArrayList<Long>();\n\n    long freed = 0;\n    long available = mMetaManager.getAvailableBytes(location);\n    if (available >= availableBytes) {\n      // The current space is sufficient, no need for eviction\n      return Optional.of(new EvictionPlan(toMove, toEvict));\n    }\n\n    if (location.equals(BlockStoreLocation.anyTier())) {\n      for (StorageTier tier : mMetaManager.getTiers()) {\n        for (StorageDir dir : tier.getStorageDirs()) {\n          for (BlockMeta block : dir.getBlocks()) {\n            toEvict.add(block.getBlockId());\n            freed += block.getBlockSize();\n            if (available + freed >= availableBytes) {\n              return Optional.of(new EvictionPlan(toMove, toEvict));\n            }\n          }\n        }\n      }\n      return Optional.absent();\n    }\n\n    int tierAlias = location.tierAlias();\n    StorageTier tier = mMetaManager.getTier(tierAlias);\n    if (location.equals(BlockStoreLocation.anyDirInTier(tierAlias))) {\n      // Loop over all dirs in the given tier\n      for (StorageDir dir : tier.getStorageDirs()) {\n        for (BlockMeta block : dir.getBlocks()) {\n          toEvict.add(block.getBlockId());\n          freed += block.getBlockSize();\n          if (available + freed >= availableBytes) {\n            return Optional.of(new EvictionPlan(toMove, toEvict));\n          }\n        }\n      }\n      return Optional.absent();\n    }\n\n    int dirIndex = location.dir();\n    StorageDir dir = tier.getDir(dirIndex);\n    for (BlockMeta block : dir.getBlocks()) {\n      toEvict.add(block.getBlockId());\n      freed += block.getBlockSize();\n      if (available + freed >= availableBytes) {\n        return Optional.of(new EvictionPlan(toMove, toEvict));\n      }\n    }\n    return Optional.absent();\n  }","commit_id":"b542a18f4500469f70141f00ec14bf5a4768b448","url":"https://github.com/amplab/tachyon"},{"original_method":"/**\n     * Create the MBeans for the specified UserDatabase and its contents.\n     *\n     * @param name Complete resource name of this UserDatabase\n     * @param database The UserDatabase to be processed\n     *\n     * @exception Exception if an exception occurs while creating MBeans\n     */\n    protected void createMBeans(String name, UserDatabase database)\n        throws Exception {\n\n        // Create the MBean for the UserDatabase itself\n        if (log.isDebugEnabled()) {\n            log.debug(\"Creating UserDatabase MBeans for resource \" + name);\n            log.debug(\"Database=\" + database);\n        }\n        if (MBeanUtils.createMBean(database) == null) {\n            throw new IllegalArgumentException\n                (\"Cannot create UserDatabase MBean for resource \" + name);\n        }\n\n        // Create the MBeans for each defined Role\n        Iterator<Role> roles = database.getRoles();\n        while (roles.hasNext()) {\n            Role role = roles.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating Role MBean for role \" + role);\n            }\n            if (MBeanUtils.createMBean(role) == null) {\n                throw new IllegalArgumentException\n                    (\"Cannot create Role MBean for role \" + role);\n            }\n        }\n\n        // Create the MBeans for each defined Group\n        Iterator<Group> groups = database.getGroups();\n        while (groups.hasNext()) {\n            Group group = groups.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating Group MBean for group \" + group);\n            }\n            if (MBeanUtils.createMBean(group) == null) {\n                throw new IllegalArgumentException\n                    (\"Cannot create Group MBean for group \" + group);\n            }\n        }\n\n        // Create the MBeans for each defined User\n        Iterator<User> users = database.getUsers();\n        while (users.hasNext()) {\n            User user = users.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating User MBean for user \" + user);\n            }\n            if (MBeanUtils.createMBean(user) == null) {\n                throw new IllegalArgumentException\n                    (\"Cannot create User MBean for user \" + user);\n            }\n        }\n\n    }","id":14875,"modified_method":"/**\n     * Create the MBeans for the specified UserDatabase and its contents.\n     *\n     * @param name Complete resource name of this UserDatabase\n     * @param database The UserDatabase to be processed\n     *\n     * @exception Exception if an exception occurs while creating MBeans\n     */\n    protected void createMBeans(String name, UserDatabase database)\n        throws Exception {\n\n        // Create the MBean for the UserDatabase itself\n        if (log.isDebugEnabled()) {\n            log.debug(\"Creating UserDatabase MBeans for resource \" + name);\n            log.debug(\"Database=\" + database);\n        }\n        try {\n            MBeanUtils.createMBean(database);\n        } catch(Exception e) {\n            IllegalArgumentException iae = new IllegalArgumentException\n                (\"Cannot create UserDatabase MBean for resource \" + name);\n            iae.initCause(e);\n            throw iae;\n        }\n\n        // Create the MBeans for each defined Role\n        Iterator<Role> roles = database.getRoles();\n        while (roles.hasNext()) {\n            Role role = roles.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating Role MBean for role \" + role);\n            }\n            try {\n                MBeanUtils.createMBean(role);\n            } catch (Exception e) {\n                IllegalArgumentException iae = new IllegalArgumentException\n                    (\"Cannot create Role MBean for role \" + role);\n                iae.initCause(e);\n                throw iae;\n            }\n        }\n\n        // Create the MBeans for each defined Group\n        Iterator<Group> groups = database.getGroups();\n        while (groups.hasNext()) {\n            Group group = groups.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating Group MBean for group \" + group);\n            }\n            try {\n                MBeanUtils.createMBean(group);\n            } catch (Exception e) {\n                IllegalArgumentException iae = new IllegalArgumentException\n                    (\"Cannot create Group MBean for group \" + group);\n                iae.initCause(e);\n                throw iae;\n            }\n        }\n\n        // Create the MBeans for each defined User\n        Iterator<User> users = database.getUsers();\n        while (users.hasNext()) {\n            User user = users.next();\n            if (log.isDebugEnabled()) {\n                log.debug(\"  Creating User MBean for user \" + user);\n            }\n            try {\n                MBeanUtils.createMBean(user);\n            } catch (Exception e) {\n                IllegalArgumentException iae = new IllegalArgumentException\n                    (\"Cannot create User MBean for user \" + user);\n                iae.initCause(e);\n                throw iae;\n            }\n        }\n\n    }","commit_id":"1c1fbb50477c2d522185ba035bb404aacbcb6597","url":"https://github.com/apache/tomcat"},{"original_method":"protected Object delegate(final String iElementName, final OComposableProcessor iManager, final Object iContent,\r\n      final OCommandContext iContext, ODocument iOutput, final boolean iReadOnly) {\r\n    try {\r\n      return iManager.process(iContent, iContext, iOutput, iReadOnly);\r\n    } catch (Exception e) {\r\n      throw new OProcessException(\"Error on processing '\" + iElementName + \"' field of '\" + getName() + \"' block\", e);\r\n    }\r\n  }","id":14876,"modified_method":"protected Object delegate(final String iElementName, final OComposableProcessor iManager, final Object iContent,\r\n      final OCommandContext iContext, ODocument iOutput, final boolean iReadOnly) {\r\n    try {\r\n      return iManager.process(this, iContent, iContext, iOutput, iReadOnly);\r\n    } catch (Exception e) {\r\n      throw new OProcessException(\"Error on processing '\" + iElementName + \"' field of '\" + getName() + \"' block\", e);\r\n    }\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public Object process(OComposableProcessor iManager, OCommandContext iContext, ODocument iConfig, ODocument iOutput,\r\n      boolean iReadOnly) {\r\n    if (!checkForCondition(iContext, iConfig))\r\n      return null;\r\n\r\n    Boolean enabled = getFieldOfClass(iContext, iConfig, \"enabled\", Boolean.class);\r\n    if (enabled != null && !enabled)\r\n      return null;\r\n\r\n    returnVariable = getFieldOfClass(iContext, iConfig, \"return\", String.class);\r\n\r\n    debug(iContext, \"Executing {%s} block...\", iConfig.field(\"type\"));\r\n\r\n    final Object result = processBlock(iManager, iContext, iConfig, iOutput, iReadOnly);\r\n\r\n    printReturn(iContext, result);\r\n\r\n    if (returnVariable != null)\r\n      assignVariable(iContext, returnVariable, result);\r\n\r\n    return result;\r\n  }","id":14877,"modified_method":"@Override\r\n  public Object process(OComposableProcessor iManager, OCommandContext iContext, ODocument iConfig, ODocument iOutput,\r\n      boolean iReadOnly) {\r\n    if (!checkForCondition(iContext, iConfig))\r\n      return null;\r\n\r\n    Boolean enabled = getFieldOfClass(iContext, iConfig, \"enabled\", Boolean.class);\r\n    if (enabled != null && !enabled)\r\n      return null;\r\n\r\n    String returnVariable = getFieldOfClass(iContext, iConfig, \"return\", String.class);\r\n\r\n    debug(iContext, \"Executing {%s} block...\", iConfig.field(\"type\"));\r\n\r\n    final Object result = processBlock(iManager, iContext, iConfig, iOutput, iReadOnly);\r\n\r\n    printReturn(iContext, result);\r\n\r\n    if (returnVariable != null)\r\n      assignVariable(iContext, returnVariable, result);\r\n\r\n    return result;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"protected Object delegate(final String iElementName, final OComposableProcessor iManager, final String iType,\r\n      final ODocument iContent, final OCommandContext iContext, ODocument iOutput, final boolean iReadOnly) {\r\n    try {\r\n      return iManager.process(iType, iContent, iContext, iOutput, iReadOnly);\r\n    } catch (Exception e) {\r\n      throw new OProcessException(\"Error on processing '\" + iElementName + \"' field of '\" + getName() + \"' block\", e);\r\n    }\r\n  }","id":14878,"modified_method":"protected Object delegate(final String iElementName, final OComposableProcessor iManager, final String iType,\r\n      final ODocument iContent, final OCommandContext iContext, ODocument iOutput, final boolean iReadOnly) {\r\n    try {\r\n      return iManager.process(this, iType, iContent, iContext, iOutput, iReadOnly);\r\n    } catch (Exception e) {\r\n      throw new OProcessException(\"Error on processing '\" + iElementName + \"' field of '\" + getName() + \"' block\", e);\r\n    }\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Object execute(final Map<Object, Object> iArgs) {\r\n    return executeInContext(null, iArgs);\r\n  }","id":14879,"modified_method":"public Object execute(final Map<Object, Object> iArgs) {\r\n    return executeInContext(context, iArgs);\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Object process(final Object iContent, final OCommandContext iContext, final ODocument iOutput, final boolean iReadOnly) {\r\n    if (!(iContent instanceof ODocument))\r\n      throw new OProcessException(\"Composable processor needs a document\");\r\n\r\n    final ODocument document = (ODocument) iContent;\r\n\r\n    final String type = document.field(\"type\");\r\n    if (type == null)\r\n      throw new OProcessException(\"Composable processor needs 'type' field\");\r\n\r\n    return process(type, document, iContext, iOutput, iReadOnly);\r\n  }","id":14880,"modified_method":"public Object process(final OProcessorBlock iParent, final Object iContent, final OCommandContext iContext, final ODocument iOutput, final boolean iReadOnly) {\r\n    if (!(iContent instanceof ODocument))\r\n      throw new OProcessException(\"Composable processor needs a document\");\r\n\r\n    final ODocument document = (ODocument) iContent;\r\n\r\n    final String type = document.field(\"type\");\r\n    if (type == null)\r\n      throw new OProcessException(\"Composable processor needs 'type' field\");\r\n\r\n    return process(iParent, type, document, iContext, iOutput, iReadOnly);\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public OComposableProcessor() {\r\n    register(new OFunctionBlock());\r\n    register(new OIfBlock());\r\n    register(new OIterateBlock());\r\n    register(new OLetBlock());\r\n    register(new OExecuteBlock());\r\n    register(new OOutputBlock());\r\n    register(new OQueryBlock());\r\n    register(new OScriptBlock());\r\n    register(new OTableBlock());\r\n  }","id":14881,"modified_method":"public OComposableProcessor() {\r\n    register(OFunctionBlock.NAME, OFunctionBlock.class);\r\n    register(OIfBlock.NAME, OIfBlock.class);\r\n    register(OIterateBlock.NAME, OIterateBlock.class);\r\n    register(OLetBlock.NAME, OLetBlock.class);\r\n    register(OExecuteBlock.NAME, OExecuteBlock.class);\r\n    register(OOutputBlock.NAME, OOutputBlock.class);\r\n    register(OQueryBlock.NAME, OQueryBlock.class);\r\n    register(OScriptBlock.NAME, OScriptBlock.class);\r\n    register(OTableBlock.NAME, OTableBlock.class);\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Object process(final String iType, final ODocument iContent, final OCommandContext iContext, final ODocument iOutput,\r\n      final boolean iReadOnly) {\r\n    if (iContent == null)\r\n      throw new OProcessException(\"Cannot find block type '\" + iType + \"'\");\r\n\r\n    final OProcessorBlock block = registry.get(iType);\r\n    if (block == null)\r\n      throw new OProcessException(\"Cannot find block type '\" + iType + \"'\");\r\n\r\n    final Integer depthLevel = (Integer) iContext.getVariable(\"depthLevel\");\r\n    iContext.setVariable(\"depthLevel\", depthLevel == null ? 0 : depthLevel + 1);\r\n\r\n    if (depthLevel == null)\r\n      OLogManager.instance().info(this, \"Start processing...\");\r\n\r\n    final long start = System.currentTimeMillis();\r\n    try {\r\n      return block.process(this, iContext, (ODocument) iContent, iOutput, iReadOnly);\r\n    } finally {\r\n      iContext.setVariable(\"depthLevel\", depthLevel == null ? 0 : depthLevel);\r\n\r\n      if (depthLevel == null)\r\n        OLogManager.instance().info(this, \"End of processing. Elapsed %dms\", (System.currentTimeMillis() - start));\r\n    }\r\n  }","id":14882,"modified_method":"public Object process(final OProcessorBlock iParent, final String iType, final ODocument iContent,\r\n      final OCommandContext iContext, final ODocument iOutput, final boolean iReadOnly) {\r\n    if (iContent == null)\r\n      throw new OProcessException(\"Cannot find block type '\" + iType + \"'\");\r\n\r\n    final Class<? extends OProcessorBlock> blockClass = registry.get(iType);\r\n    if (blockClass == null)\r\n      throw new OProcessException(\"Cannot find block type '\" + iType + \"'\");\r\n\r\n    OProcessorBlock block;\r\n    try {\r\n      block = blockClass.newInstance();\r\n    } catch (Exception e) {\r\n      throw new OProcessException(\"Cannot create block of class '\" + iType + \"'\", e);\r\n    }\r\n\r\n    block.setParentBlock(iParent);\r\n\r\n    final Integer depthLevel = (Integer) iContext.getVariable(\"depthLevel\");\r\n    iContext.setVariable(\"depthLevel\", depthLevel == null ? 0 : depthLevel + 1);\r\n\r\n    if (depthLevel == null)\r\n      OLogManager.instance().info(this, \"Start processing...\");\r\n\r\n    final long start = System.currentTimeMillis();\r\n    try {\r\n      return block.process(this, iContext, (ODocument) iContent, iOutput, iReadOnly);\r\n    } finally {\r\n      iContext.setVariable(\"depthLevel\", depthLevel == null ? 0 : depthLevel);\r\n\r\n      if (depthLevel == null)\r\n        OLogManager.instance().info(this, \"End of processing. Elapsed %dms\", (System.currentTimeMillis() - start));\r\n    }\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Object processFromFile(final String iFileName, final OCommandContext iContext, final boolean iReadOnly) throws IOException {\r\n    final ODocument template = new ODocument().fromJSON(loadTemplate(iFileName), \"noMap\");\r\n\r\n    return process(template, iContext, new ODocument().setOrdered(true), iReadOnly);\r\n  }","id":14883,"modified_method":"public Object processFromFile(final String iFileName, final OCommandContext iContext, final boolean iReadOnly) throws IOException {\r\n    final ODocument template = new ODocument().fromJSON(loadTemplate(iFileName), \"noMap\");\r\n\r\n    return process(null, template, iContext, new ODocument().setOrdered(true), iReadOnly);\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"execute\";\r\n  }","id":14884,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n\r\n    final Object foreach = getField(iContext, iConfig, \"foreach\");\r\n    String returnType = (String) getFieldOfClass(iContext, iConfig, \"returnType\", String.class);\r\n\r\n    Object returnValue = null;\r\n    if (returnType == null)\r\n      returnType = \"last\";\r\n    else if (\"list\".equalsIgnoreCase(returnType))\r\n      returnValue = new ArrayList<Object>();\r\n    else if (\"set\".equalsIgnoreCase(returnType))\r\n      returnValue = new HashSet<Object>();\r\n\r\n    int iterated = 0;\r\n\r\n    if (foreach != null) {\r\n      Object result;\r\n      if (foreach instanceof ODocument)\r\n        result = delegate(\"foreach\", iManager, (ODocument) foreach, iContext, iOutput, iReadOnly);\r\n      else if (foreach instanceof Map)\r\n        result = ((Map<?, ?>) foreach).values();\r\n      else\r\n        result = foreach;\r\n\r\n      if (!OMultiValue.isIterable(result))\r\n        throw new OProcessException(\"Result of 'foreach' block (\" + foreach + \") must be iterable but found \" + result.getClass());\r\n\r\n      for (Object current : OMultiValue.getMultiValueIterable(result)) {\r\n        if (current instanceof Map.Entry)\r\n          current = ((Entry<?, ?>) current).getValue();\r\n\r\n        assignVariable(iContext, \"current\", current);\r\n\r\n        debug(iContext, \"Executing...\");\r\n        final Object doClause = getRequiredField(iContext, iConfig, \"do\");\r\n\r\n        returnValue = executeDo(iManager, iContext, doClause, returnType, returnValue, iOutput, iReadOnly);\r\n\r\n        debug(iContext, \"Done\");\r\n\r\n        iterated++;\r\n      }\r\n\r\n    } else {\r\n      debug(iContext, \"Executing...\");\r\n      final Object doClause = getRequiredField(iContext, iConfig, \"do\");\r\n      returnValue = executeDo(iManager, iContext, doClause, returnType, returnValue, iOutput, iReadOnly);\r\n      debug(iContext, \"Done\");\r\n    }\r\n\r\n    debug(iContext, \"Executed %d iteration and returned type %s\", iterated, returnType);\r\n    return returnValue;\r\n  }","id":14885,"modified_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n\r\n    final Object foreach = getField(iContext, iConfig, \"foreach\");\r\n    String returnType = (String) getFieldOfClass(iContext, iConfig, \"returnType\", String.class);\r\n\r\n    returnValue = null;\r\n    if (returnType == null)\r\n      returnType = \"last\";\r\n    else if (\"list\".equalsIgnoreCase(returnType))\r\n      returnValue = new ArrayList<Object>();\r\n    else if (\"set\".equalsIgnoreCase(returnType))\r\n      returnValue = new HashSet<Object>();\r\n\r\n    int iterated = 0;\r\n\r\n    final Object beginClause = getField(iContext, iConfig, \"begin\");\r\n    if (beginClause != null)\r\n      executeBlock(iManager, iContext, \"begin\", beginClause, iOutput, iReadOnly, returnType, returnValue);\r\n\r\n    if (foreach != null) {\r\n      Object result;\r\n      if (foreach instanceof ODocument)\r\n        result = delegate(\"foreach\", iManager, (ODocument) foreach, iContext, iOutput, iReadOnly);\r\n      else if (foreach instanceof Map)\r\n        result = ((Map<?, ?>) foreach).values();\r\n      else\r\n        result = foreach;\r\n\r\n      if (!OMultiValue.isIterable(result))\r\n        throw new OProcessException(\"Result of 'foreach' block (\" + foreach + \") must be iterable but found \" + result.getClass());\r\n\r\n      for (Object current : OMultiValue.getMultiValueIterable(result)) {\r\n        if (current instanceof Map.Entry)\r\n          current = ((Entry<?, ?>) current).getValue();\r\n\r\n        assignVariable(iContext, \"current\", current);\r\n\r\n        debug(iContext, \"Executing...\");\r\n        final Object doClause = getRequiredField(iContext, iConfig, \"do\");\r\n\r\n        returnValue = executeDo(iManager, iContext, doClause, returnType, returnValue, iOutput, iReadOnly);\r\n\r\n        debug(iContext, \"Done\");\r\n\r\n        iterated++;\r\n      }\r\n\r\n    } else {\r\n      debug(iContext, \"Executing...\");\r\n      final Object doClause = getRequiredField(iContext, iConfig, \"do\");\r\n      returnValue = executeDo(iManager, iContext, doClause, returnType, returnValue, iOutput, iReadOnly);\r\n      debug(iContext, \"Done\");\r\n    }\r\n\r\n    final Object endClause = getField(iContext, iConfig, \"end\");\r\n    if (endClause != null)\r\n      executeBlock(iManager, iContext, \"end\", endClause, iOutput, iReadOnly, returnType, returnValue);\r\n\r\n    debug(iContext, \"Executed %d iteration and returned type %s\", iterated, returnType);\r\n    return returnValue;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"function\";\r\n  }","id":14886,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@SuppressWarnings(\"unchecked\")\r\n  @Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    final String function = getRequiredFieldOfClass(iContext, iConfig, \"function\", String.class);\r\n\r\n    final Object[] args;\r\n    final Collection<Object> configuredArgs = getFieldOfClass(iContext, iConfig, \"args\", Collection.class);\r\n    if (configuredArgs != null) {\r\n      args = new Object[configuredArgs.size()];\r\n      int argIdx = 0;\r\n      for (Object arg : configuredArgs) {\r\n        Object value = resolveValue(iContext, arg, true);\r\n\r\n        if (value instanceof List<?>)\r\n          // RHINO DOESN'T TREAT LIST AS ARRAY: CONVERT IT\r\n          value = ((List<?>) value).toArray();\r\n\r\n        args[argIdx++] = value;\r\n      }\r\n    } else\r\n      args = null;\r\n\r\n    final OFunction f = ODatabaseRecordThreadLocal.INSTANCE.get().getMetadata().getFunctionLibrary().getFunction(function);\r\n    if (f != null) {\r\n      debug(iContext, \"Calling database function: \" + function + \"(\" + Arrays.toString(args) + \")...\");\r\n      return f.executeInContext(iContext, args);\r\n    }\r\n\r\n    int lastDot = function.lastIndexOf('.');\r\n    if (lastDot > -1) {\r\n      final String clsName = function.substring(0, lastDot);\r\n      final String methodName = function.substring(lastDot + 1);\r\n      Class<?> cls = null;\r\n      try {\r\n        cls = Class.forName(clsName);\r\n\r\n        Class<?>[] argTypes = new Class<?>[args.length];\r\n        for (int i = 0; i < args.length; ++i)\r\n          argTypes[i] = args[i] == null ? null : args[i].getClass();\r\n\r\n        Method m = cls.getMethod(methodName, argTypes);\r\n\r\n        debug(iContext, \"Calling Java function: \" + m + \"(\" + Arrays.toString(args).replace(\"%\", \"%%\") + \")...\");\r\n        return m.invoke(null, args);\r\n\r\n      } catch (NoSuchMethodException e) {\r\n\r\n        for (Method m : cls.getMethods()) {\r\n          if (m.getName().equals(methodName) && m.getParameterTypes().length == args.length) {\r\n            try {\r\n              debug(iContext, \"Calling Java function: \" + m + \"(\" + Arrays.toString(args) + \")...\");\r\n              return m.invoke(null, args);\r\n            } catch (IllegalArgumentException e1) {\r\n              // DO NOTHING, LOOK FOR ANOTHER METHOD\r\n            } catch (Exception e1) {\r\n              e1.printStackTrace();\r\n              throw new OProcessException(\"Error on call function '\" + function + \"'\", e);\r\n            }\r\n          }\r\n        }\r\n\r\n        // METHOD NOT FOUND!\r\n        debug(iContext, \"Method not found: \" + clsName + \".\" + methodName + \"(\" + Arrays.toString(args) + \")\");\r\n\r\n        for (Method m : cls.getMethods()) {\r\n          final StringBuilder candidates = new StringBuilder();\r\n          if (m.getName().equals(methodName)) {\r\n            candidates.append(\"-\" + m + \"\\n\");\r\n          }\r\n          if (candidates.length() > 0)\r\n            debug(iContext, \"Candidate methods were: \\n\" + candidates);\r\n          else\r\n            debug(iContext, \"No candidate methods were found\");\r\n        }\r\n\r\n      } catch (ClassNotFoundException e) {\r\n        throw new OProcessException(\"Function '\" + function + \"' was not found because the class '\" + clsName + \"' was not found\");\r\n      } catch (Exception e) {\r\n        e.printStackTrace();\r\n      }\r\n    }\r\n\r\n    throw new OProcessException(\"Function '\" + function + \"' was not found\");\r\n  }","id":14887,"modified_method":"@SuppressWarnings(\"unchecked\")\r\n  @Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    final String function = getRequiredFieldOfClass(iContext, iConfig, NAME, String.class);\r\n\r\n    final Object[] args;\r\n    final Collection<Object> configuredArgs = getFieldOfClass(iContext, iConfig, \"args\", Collection.class);\r\n    if (configuredArgs != null) {\r\n      args = new Object[configuredArgs.size()];\r\n      int argIdx = 0;\r\n      for (Object arg : configuredArgs) {\r\n        Object value = resolveValue(iContext, arg, true);\r\n\r\n        if (value instanceof List<?>)\r\n          // RHINO DOESN'T TREAT LIST AS ARRAY: CONVERT IT\r\n          value = ((List<?>) value).toArray();\r\n\r\n        args[argIdx++] = value;\r\n      }\r\n    } else\r\n      args = null;\r\n\r\n    final OFunction f = ODatabaseRecordThreadLocal.INSTANCE.get().getMetadata().getFunctionLibrary().getFunction(function);\r\n    if (f != null) {\r\n      debug(iContext, \"Calling database function: \" + function + \"(\" + Arrays.toString(args) + \")...\");\r\n      return f.executeInContext(iContext, args);\r\n    }\r\n\r\n    int lastDot = function.lastIndexOf('.');\r\n    if (lastDot > -1) {\r\n      final String clsName = function.substring(0, lastDot);\r\n      final String methodName = function.substring(lastDot + 1);\r\n      Class<?> cls = null;\r\n      try {\r\n        cls = Class.forName(clsName);\r\n\r\n        Class<?>[] argTypes = new Class<?>[args.length];\r\n        for (int i = 0; i < args.length; ++i)\r\n          argTypes[i] = args[i] == null ? null : args[i].getClass();\r\n\r\n        Method m = cls.getMethod(methodName, argTypes);\r\n\r\n        debug(iContext, \"Calling Java function: \" + m + \"(\" + Arrays.toString(args).replace(\"%\", \"%%\") + \")...\");\r\n        return m.invoke(null, args);\r\n\r\n      } catch (NoSuchMethodException e) {\r\n\r\n        for (Method m : cls.getMethods()) {\r\n          if (m.getName().equals(methodName) && m.getParameterTypes().length == args.length) {\r\n            try {\r\n              debug(iContext, \"Calling Java function: \" + m + \"(\" + Arrays.toString(args) + \")...\");\r\n              return m.invoke(null, args);\r\n            } catch (IllegalArgumentException e1) {\r\n              // DO NOTHING, LOOK FOR ANOTHER METHOD\r\n            } catch (Exception e1) {\r\n              e1.printStackTrace();\r\n              throw new OProcessException(\"Error on call function '\" + function + \"'\", e);\r\n            }\r\n          }\r\n        }\r\n\r\n        // METHOD NOT FOUND!\r\n        debug(iContext, \"Method not found: \" + clsName + \".\" + methodName + \"(\" + Arrays.toString(args) + \")\");\r\n\r\n        for (Method m : cls.getMethods()) {\r\n          final StringBuilder candidates = new StringBuilder();\r\n          if (m.getName().equals(methodName)) {\r\n            candidates.append(\"-\" + m + \"\\n\");\r\n          }\r\n          if (candidates.length() > 0)\r\n            debug(iContext, \"Candidate methods were: \\n\" + candidates);\r\n          else\r\n            debug(iContext, \"No candidate methods were found\");\r\n        }\r\n\r\n      } catch (ClassNotFoundException e) {\r\n        throw new OProcessException(\"Function '\" + function + \"' was not found because the class '\" + clsName + \"' was not found\");\r\n      } catch (Exception e) {\r\n        e.printStackTrace();\r\n      }\r\n    }\r\n\r\n    throw new OProcessException(\"Function '\" + function + \"' was not found\");\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"if\";\r\n  }","id":14888,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"iterate\";\r\n  }","id":14889,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"let\";\r\n  }","id":14890,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"output\";\r\n  }","id":14891,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@SuppressWarnings(\"unchecked\")\r\n  @Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n\r\n    final Object value = getRequiredField(iContext, iConfig, \"value\");\r\n    final Boolean flatMultivalues = getFieldOfClass(iContext, iConfig, \"flatMultivalues\", Boolean.class);\r\n\r\n    Object result;\r\n    if (isBlock(value))\r\n      result = delegate(\"value\", iManager, value, iContext, iOutput, iReadOnly);\r\n    else\r\n      result = value;\r\n\r\n    final Object source = getField(iContext, iConfig, \"source\");\r\n    if (source instanceof ODocument && result instanceof List<?>) {\r\n      final List<Object> list = new ArrayList<Object>();\r\n      for (Object o : (List<Object>) result) {\r\n        if (o != null)\r\n          list.add(((ODocument) source).field(o.toString()));\r\n      }\r\n      result = list;\r\n    } else if (OMultiValue.isMultiValue(result) && flatMultivalues != null && flatMultivalues) {\r\n      result = flatMultivalues(iContext, false, flatMultivalues, result);\r\n    }\r\n\r\n    final String field = getFieldOfClass(iContext, iConfig, \"field\", String.class);\r\n    if (field != null) {\r\n      // WRITE TO THE OUTPUT\r\n      iOutput.field(field, result);\r\n      return iOutput;\r\n    }\r\n\r\n    // NO FIELD: RETURN THE VALUE\r\n    return result;\r\n  }","id":14892,"modified_method":"@SuppressWarnings(\"unchecked\")\r\n  @Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n\r\n    final Object value = getRequiredField(iContext, iConfig, \"value\");\r\n    final Boolean flatMultivalues = getFieldOfClass(iContext, iConfig, \"flatMultivalues\", Boolean.class);\r\n\r\n    Object result;\r\n    if (isBlock(value))\r\n      result = delegate(\"value\", iManager, value, iContext, iOutput, iReadOnly);\r\n    else\r\n      result = value;\r\n\r\n    final Object source = getField(iContext, iConfig, \"source\");\r\n    if (source instanceof ODocument && result instanceof List<?>) {\r\n      result = addDocumentFields((ODocument) source, (List<Object>) result);\r\n    } else if (OMultiValue.isMultiValue(result) && flatMultivalues != null && flatMultivalues) {\r\n      result = flatMultivalues(iContext, false, flatMultivalues, result);\r\n    }\r\n\r\n    final String field = getFieldOfClass(iContext, iConfig, \"field\", String.class);\r\n    if (field != null) {\r\n      // WRITE TO THE OUTPUT\r\n      iOutput.field(field, result);\r\n      return iOutput;\r\n    }\r\n\r\n    // NO FIELD: RETURN THE VALUE\r\n    return result;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Object process(final String iType, final Object iContent, final OCommandContext iContext, ODocument iOutput,\r\n      final boolean iReadOnly) {\r\n    final OProcessor t = registry.get(iType);\r\n    if (t == null)\r\n      throw new OProcessException(\"Cannot find processor type '\" + iType + \"'\");\r\n\r\n    return t.process(iContent, iContext, iOutput, iReadOnly);\r\n  }","id":14893,"modified_method":"public Object process(final String iType, final Object iContent, final OCommandContext iContext, ODocument iOutput,\r\n      final boolean iReadOnly) {\r\n    final OProcessor t = registry.get(iType);\r\n    if (t == null)\r\n      throw new OProcessException(\"Cannot find processor type '\" + iType + \"'\");\r\n\r\n    return t.process(null, iContent, iContext, iOutput, iReadOnly);\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"query\";\r\n  }","id":14894,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"script\";\r\n  }","id":14895,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    final String language = getFieldOrDefault(iContext, iConfig, \"language\", \"javascript\");\r\n\r\n    Object code = getRequiredField(iContext, iConfig, \"code\");\r\n\r\n    if (OMultiValue.isMultiValue(code)) {\r\n      // CONCATS THE SNIPPET IN A BIG ONE\r\n      final StringBuilder buffer = new StringBuilder();\r\n      for (Object o : OMultiValue.getMultiValueIterable(code)) {\r\n        if (buffer.length() > 0)\r\n          buffer.append(\";\");\r\n        buffer.append(o.toString());\r\n      }\r\n      code = buffer.toString();\r\n    }\r\n\r\n    final OCommandScript script = new OCommandScript(language, code.toString());\r\n    script.getContext().setParent(iContext);\r\n    return script.execute();\r\n  }","id":14896,"modified_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    final String language = getFieldOrDefault(iContext, iConfig, \"language\", \"javascript\");\r\n\r\n    Object code = getRequiredField(iContext, iConfig, \"code\");\r\n\r\n    if (OMultiValue.isMultiValue(code)) {\r\n      // CONCATS THE SNIPPET IN A BIG ONE\r\n      final StringBuilder buffer = new StringBuilder();\r\n      for (Object o : OMultiValue.getMultiValueIterable(code)) {\r\n        if (buffer.length() > 0)\r\n          buffer.append(\";\");\r\n        buffer.append(o.toString());\r\n      }\r\n      code = buffer.toString();\r\n    }\r\n\r\n    final OCommandScript script = new OCommandScript(language, code.toString());\r\n    script.getContext().setParent(iContext);\r\n\r\n    iContext.setVariable(\"block\", this);\r\n\r\n    return script.execute();\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public Bindings bind(final Bindings binding, final ODatabaseRecordTx db, final OCommandContext iContext,\r\n      final Map<Object, Object> iArgs) {\r\n    for (OScriptInjection i : injections)\r\n      i.bind(binding);\r\n\r\n    if (db != null) {\r\n      // BIND FIXED VARIABLES\r\n      binding.put(\"db\", new OScriptDocumentDatabaseWrapper(db));\r\n      binding.put(\"gdb\", new OScriptGraphDatabaseWrapper(db));\r\n    }\r\n    binding.put(\"util\", new OFunctionUtilWrapper(null));\r\n\r\n    // BIND CONTEXT VARIABLE INTO THE SCRIPT\r\n    if (iContext != null) {\r\n      for (Entry<String, Object> a : iContext.getVariables().entrySet())\r\n        binding.put(a.getKey(), a.getValue());\r\n    }\r\n\r\n    // BIND PARAMETERS INTO THE SCRIPT\r\n    if (iArgs != null) {\r\n      for (Entry<Object, Object> a : iArgs.entrySet())\r\n        binding.put(a.getKey().toString(), a.getValue());\r\n\r\n      binding.put(\"params\", iArgs.values().toArray());\r\n    } else\r\n      binding.put(\"params\", EMPTY_PARAMS);\r\n\r\n    return binding;\r\n  }","id":14897,"modified_method":"public Bindings bind(final Bindings binding, final ODatabaseRecordTx db, final OCommandContext iContext,\r\n      final Map<Object, Object> iArgs) {\r\n    for (OScriptInjection i : injections)\r\n      i.bind(binding);\r\n\r\n    if (db != null) {\r\n      // BIND FIXED VARIABLES\r\n      binding.put(\"db\", new OScriptDocumentDatabaseWrapper(db));\r\n      binding.put(\"gdb\", new OScriptGraphDatabaseWrapper(db));\r\n    }\r\n    binding.put(\"util\", new OFunctionUtilWrapper(null));\r\n\r\n    // BIND CONTEXT VARIABLE INTO THE SCRIPT\r\n    if (iContext != null) {\r\n      binding.put(\"ctx\", iContext);\r\n      for (Entry<String, Object> a : iContext.getVariables().entrySet())\r\n        binding.put(a.getKey(), a.getValue());\r\n    }\r\n\r\n    // BIND PARAMETERS INTO THE SCRIPT\r\n    if (iArgs != null) {\r\n      for (Entry<Object, Object> a : iArgs.entrySet())\r\n        binding.put(a.getKey().toString(), a.getValue());\r\n\r\n      binding.put(\"params\", iArgs.values().toArray());\r\n    } else\r\n      binding.put(\"params\", EMPTY_PARAMS);\r\n\r\n    return binding;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public String getName() {\r\n    return \"table\";\r\n  }","id":14898,"modified_method":"@Override\r\n  public String getName() {\r\n    return NAME;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    if (!(iConfig instanceof ODocument))\r\n      throw new OProcessException(\"Content in not a JSON\");\r\n\r\n    final Object header = getRequiredField(iContext, iConfig, \"header\");\r\n    final Object body = getRequiredField(iContext, iConfig, \"body\");\r\n    final Object footer = getRequiredField(iContext, iConfig, \"footer\");\r\n\r\n    final ODocument table = new ODocument();\r\n\r\n    table.field(\"header\", isBlock(header) ? delegate(\"header\", iManager, header, iContext, iOutput, iReadOnly) : header);\r\n    table.field(\"body\", isBlock(body) ? delegate(\"body\", iManager, body, iContext, iOutput, iReadOnly) : body);\r\n    table.field(\"footer\", isBlock(footer) ? delegate(\"footer\", iManager, footer, iContext, iOutput, iReadOnly) : footer);\r\n\r\n    return table;\r\n  }","id":14899,"modified_method":"@Override\r\n  public Object processBlock(OComposableProcessor iManager, final OCommandContext iContext, final ODocument iConfig,\r\n      ODocument iOutput, final boolean iReadOnly) {\r\n    if (!(iConfig instanceof ODocument))\r\n      throw new OProcessException(\"Content in not a JSON\");\r\n\r\n    final ODocument table = new ODocument();\r\n\r\n    // HEADER\r\n    header = getRequiredField(iContext, iConfig, \"header\");\r\n    if (isBlock(header))\r\n      header = delegate(\"header\", iManager, header, iContext, iOutput, iReadOnly);\r\n    table.field(\"header\", header);\r\n\r\n    // BODY\r\n    body = getRequiredField(iContext, iConfig, \"body\");\r\n    if (isBlock(body))\r\n      body = delegate(\"body\", iManager, body, iContext, iOutput, iReadOnly);\r\n    table.field(\"body\", body);\r\n\r\n    // FOOTER\r\n    footer = getRequiredField(iContext, iConfig, \"footer\");\r\n    if (isBlock(footer))\r\n      footer = delegate(\"footer\", iManager, footer, iContext, iOutput, iReadOnly);\r\n    table.field(\"footer\", footer);\r\n\r\n    return table;\r\n  }","commit_id":"ea0e9b1bbe636b59babbc6f6df9bf1f1dca6cce2","url":"https://github.com/orientechnologies/orientdb"},{"original_method":"public PortableFactory createFactory() {\n        return new PortableFactory() {\n            public Portable create(int classId) {\n                switch (classId){\n                    case ADD_AND_GET:\n                        return new AddAndGetRequest();\n                    case COMPARE_AND_SET:\n                        return new CompareAndSetRequest();\n                    case GET_AND_ADD:\n                        return new GetAndAddRequest();\n                    case GET_AND_SET:\n                        return new GetAndSetRequest();\n                    case SET:\n                        return new SetRequest();\n                }\n                return null;\n            }\n        };\n    }","id":14900,"modified_method":"public PortableFactory createFactory() {\n        return new PortableFactory() {\n            public Portable create(int classId) {\n                switch (classId){\n                    case ADD_AND_GET:\n                        return new AddAndGetRequest();\n                    case COMPARE_AND_SET:\n                        return new CompareAndSetRequest();\n                    case GET_AND_ADD:\n                        return new GetAndAddRequest();\n                    case GET_AND_SET:\n                        return new GetAndSetRequest();\n                    case SET:\n                        return new SetRequest();\n                    case APPLY:\n                        return new ApplyRequest();\n                    case ALTER:\n                        return new AlterRequest();\n                    case ALTER_AND_GET:\n                        return new AlterAndGetRequest();\n                    case GET_AND_ALTER:\n                        return new GetAndAlterRequest();\n                }\n                return null;\n            }\n        };\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public long getAndAdd(long delta) {\n        try {\n            GetAndAddOperation operation = new GetAndAddOperation(name, delta);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            Future f = inv.invoke();\n            return (Long) f.get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14901,"modified_method":"@Override\n    public long getAndAdd(long delta) {\n        Operation operation = new GetAndAddOperation(name, delta);\n        return (Long)invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public long get() {\n        try {\n            GetOperation operation = new GetOperation(name);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            Future f = inv.invoke();\n            return (Long) f.get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14902,"modified_method":"@Override\n    public long get() {\n        GetOperation operation = new GetOperation(name);\n        return (Long)invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public long addAndGet(long delta) {\n        try {\n            AddAndGetOperation operation = new AddAndGetOperation(name, delta);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            Future f = inv.invoke();\n            return (Long) f.get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14903,"modified_method":"@Override\n    public long addAndGet(long delta) {\n        Operation operation = new AddAndGetOperation(name, delta);\n        return (Long)invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public void set(long newValue) {\n        try {\n            SetOperation operation = new SetOperation(name, newValue);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            inv.invoke().get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14904,"modified_method":"@Override\n    public void set(long newValue) {\n        Operation operation = new SetOperation(name, newValue);\n        invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public long getAndSet(long newValue) {\n        try {\n            GetAndSetOperation operation = new GetAndSetOperation(name, newValue);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            Future f = inv.invoke();\n            return (Long) f.get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14905,"modified_method":"@Override\n    public long getAndSet(long newValue) {\n        Operation operation = new GetAndSetOperation(name, newValue);\n        return (Long) invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean compareAndSet(long expect, long update) {\n        try {\n            CompareAndSetOperation operation = new CompareAndSetOperation(name, expect, update);\n            Invocation inv = getNodeEngine().getOperationService().createInvocationBuilder(AtomicLongService.SERVICE_NAME, operation, partitionId).build();\n            Future f = inv.invoke();\n            return (Boolean) f.get();\n        } catch (Throwable throwable) {\n            throw ExceptionUtil.rethrow(throwable);\n        }\n    }","id":14906,"modified_method":"@Override\n    public boolean compareAndSet(long expect, long update) {\n        Operation operation = new CompareAndSetOperation(name, expect, update);\n        return (Boolean)invoke(operation,getNodeEngine());\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private Data getKey(){\n        if (key == null){\n            key = getContext().getSerializationService().toData(name);\n        }\n        return key;\n    }","id":14907,"modified_method":"private Data getKey(){\n        if (key == null){\n            key = toData(name);\n        }\n        return key;\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@AfterClass\n    public static void destroy() {\n        hz.getLifecycleService().shutdown();\n        Hazelcast.shutdownAll();\n    }","id":14908,"modified_method":"@AfterClass\n    public static void destroy() {\n        client.getLifecycleService().shutdown();\n        Hazelcast.shutdownAll();\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@BeforeClass\n    public static void init(){\n        server = Hazelcast.newHazelcastInstance();\n        hz = HazelcastClient.newHazelcastClient(null);\n        l = hz.getAtomicLong(name);\n    }","id":14909,"modified_method":"@BeforeClass\n    public static void init(){\n        server = Hazelcast.newHazelcastInstance();\n        client = HazelcastClient.newHazelcastClient(null);\n        l = client.getAtomicLong(name);\n    }","commit_id":"2227017361b03b4f0356e2fb28706e1dfe81199b","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"MapRecord getChildNodeMap() {\n        return getTemplate().getChildNodeMap(getSegment(), getRecordId());\n    }","id":14910,"modified_method":"MapRecord getChildNodeMap() {\n        Segment segment = getSegment();\n        return segment.readMap(segment.readRecordId(getOffset(0, 1)));\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    public long getChildNodeCount(long max) {\n        return getTemplate().getChildNodeCount(getSegment(), getRecordId());\n    }","id":14911,"modified_method":"@Override\n    public long getChildNodeCount(long max) {\n        String childName = getTemplate().getChildName();\n        if (childName == Template.ZERO_CHILD_NODES) {\n            return 0;\n        } else if (childName == Template.MANY_CHILD_NODES) {\n            return getChildNodeMap().size();\n        } else {\n            return 1;\n        }\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override @Nonnull\n    public Iterable<? extends ChildNodeEntry> getChildNodeEntries() {\n        return getTemplate().getChildNodeEntries(getSegment(), getRecordId());\n    }","id":14912,"modified_method":"@Override @Nonnull\n    public Iterable<? extends ChildNodeEntry> getChildNodeEntries() {\n        String childName = getTemplate().getChildName();\n        if (childName == Template.ZERO_CHILD_NODES) {\n            return Collections.emptyList();\n        } else if (childName == Template.MANY_CHILD_NODES) {\n            return getChildNodeMap().getEntries();\n        } else {\n            Segment segment = getSegment();\n            RecordId childNodeId = segment.readRecordId(getOffset(0, 1));\n            return Collections.singletonList(new MemoryChildNodeEntry(\n                    childName, new SegmentNodeState(segment, childNodeId)));\n        }\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    public Iterable<String> getChildNodeNames() {\n        return getTemplate().getChildNodeNames(getSegment(), getRecordId());\n    }","id":14913,"modified_method":"@Override @Nonnull\n    public Iterable<String> getChildNodeNames() {\n        String childName = getTemplate().getChildName();\n        if (childName == Template.ZERO_CHILD_NODES) {\n            return Collections.emptyList();\n        } else if (childName == Template.MANY_CHILD_NODES) {\n            return getChildNodeMap().getKeys();\n        } else {\n            return Collections.singletonList(childName);\n        }\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override @CheckForNull\n    public NodeState getChildNode(String name) {\n        // checkArgument(!checkNotNull(name).isEmpty()); // TODO\n        return getTemplate().getChildNode(name, getSegment(), getRecordId());\n    }","id":14914,"modified_method":"@Override @Nonnull\n    public NodeState getChildNode(String name) {\n        // checkArgument(!checkNotNull(name).isEmpty()); // TODO\n        String childName = getTemplate().getChildName();\n        if (childName == Template.ZERO_CHILD_NODES) {\n            return MISSING_NODE;\n        } else if (childName == Template.MANY_CHILD_NODES) {\n            RecordId childNodeId = getChildNodeMap().getEntry(name);\n            if (childNodeId != null) {\n                return new SegmentNodeState(getSegment(), childNodeId);\n            } else {\n                return MISSING_NODE;\n            }\n        } else {\n            if (childName.equals(name)) {\n                Segment segment = getSegment();\n                RecordId childNodeId = segment.readRecordId(getOffset(0, 1));\n                return new SegmentNodeState(segment, childNodeId);\n            } else {\n                return MISSING_NODE;\n            }\n        }\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n    public boolean hasChildNode(String name) {\n        checkArgument(!checkNotNull(name).isEmpty());\n        return getTemplate().hasChildNode(name, getSegment(), getRecordId());\n    }","id":14915,"modified_method":"@Override\n    public boolean hasChildNode(String name) {\n        checkArgument(!checkNotNull(name).isEmpty());\n        String childName = getTemplate().getChildName();\n        if (childName == Template.ZERO_CHILD_NODES) {\n            return false;\n        } else if (childName == Template.MANY_CHILD_NODES) {\n            return getChildNodeMap().getEntry(name) != null;\n        } else {\n            return childName.equals(name);\n        }\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"public String getChildName() {\n        if (hasOneChildNode()) {\n            return childName;\n        } else {\n            return null;\n        }\n    }","id":14916,"modified_method":"String getChildName() {\n        return childName;\n    }","commit_id":"9787de3a63be25391b504c4cc88a5d192d9218b8","url":"https://github.com/apache/jackrabbit-oak"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile syncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tsyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\tsyncFile.getParentFolderId());\n\n\t\tString filePathName = null;\n\n\t\tif (parentSyncFile != null) {\n\t\t\tfilePathName = FilePathNameUtil.getFilePathName(\n\t\t\t\tparentSyncFile.getFilePathName(), syncFile.getName());\n\t\t}\n\n\t\tsyncFile.setFileKey(FileUtil.getFileKey(filePathName));\n\t\tsyncFile.setFilePathName(filePathName);\n\n\t\tsyncFile.setSyncAccountId(getSyncAccountId());\n\n\t\tSyncFileService.update(syncFile);\n\t}","id":14917,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setCompanyId(remoteSyncFile.getCompanyId());\n\t\tlocalSyncFile.setCreateTime(remoteSyncFile.getCreateTime());\n\t\tlocalSyncFile.setExtension(remoteSyncFile.getExtension());\n\t\tlocalSyncFile.setExtraSettings(remoteSyncFile.getExtraSettings());\n\t\tlocalSyncFile.setLockExpirationDate(\n\t\t\tremoteSyncFile.getLockExpirationDate());\n\t\tlocalSyncFile.setLockExpirationDate(\n\t\t\tremoteSyncFile.getLockExpirationDate());\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\t\tlocalSyncFile.setParentFolderId(remoteSyncFile.getParentFolderId());\n\t\tlocalSyncFile.setSize(remoteSyncFile.getSize());\n\t\tlocalSyncFile.setSyncAccountId(getSyncAccountId());\n\t\tlocalSyncFile.setTypePK(remoteSyncFile.getTypePK());\n\t\tlocalSyncFile.setTypeUuid(remoteSyncFile.getTypeUuid());\n\t\tlocalSyncFile.setVersion(remoteSyncFile.getVersion());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile syncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tsyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\tsyncFile.getParentFolderId());\n\n\t\tString filePathName = null;\n\n\t\tif (parentSyncFile != null) {\n\t\t\tfilePathName = FilePathNameUtil.getFilePathName(\n\t\t\t\tparentSyncFile.getFilePathName(), syncFile.getName());\n\t\t}\n\n\t\tsyncFile.setFileKey(FileUtil.getFileKey(filePathName));\n\t\tsyncFile.setFilePathName(filePathName);\n\n\t\tsyncFile.setSyncAccountId(getSyncAccountId());\n\n\t\tSyncFileService.update(syncFile);\n\t}","id":14918,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setCompanyId(remoteSyncFile.getCompanyId());\n\t\tlocalSyncFile.setCreateTime(remoteSyncFile.getCreateTime());\n\t\tlocalSyncFile.setExtension(remoteSyncFile.getExtension());\n\t\tlocalSyncFile.setExtraSettings(remoteSyncFile.getExtraSettings());\n\t\tlocalSyncFile.setLockExpirationDate(\n\t\t\tremoteSyncFile.getLockExpirationDate());\n\t\tlocalSyncFile.setLockUserId(remoteSyncFile.getLockUserId());\n\t\tlocalSyncFile.setLockUserName(remoteSyncFile.getLockUserName());\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\t\tlocalSyncFile.setParentFolderId(remoteSyncFile.getParentFolderId());\n\t\tlocalSyncFile.setSize(remoteSyncFile.getSize());\n\t\tlocalSyncFile.setSyncAccountId(getSyncAccountId());\n\t\tlocalSyncFile.setTypePK(remoteSyncFile.getTypePK());\n\t\tlocalSyncFile.setTypeUuid(remoteSyncFile.getTypeUuid());\n\t\tlocalSyncFile.setVersion(remoteSyncFile.getVersion());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Before\n\t@Override\n\tpublic void setUp() throws Exception {\n\t\tsuper.setUp();\n\n\t\t_testFolderSyncFile = SyncFileService.addSyncFile(\n\t\t\tsyncAccount.getFilePathName(), \"test\", 0, 0,\n\t\t\tsyncAccount.getSyncAccountId(), SyncFile.TYPE_FOLDER);\n\t}","id":14919,"modified_method":"@Before\n\t@Override\n\tpublic void setUp() throws Exception {\n\t\tsuper.setUp();\n\n\t\t_testFolderSyncFile = SyncFileService.addSyncFile(\n\t\t\tnull, null, null,\n\t\t\tFileUtil.getFileKey(syncAccount.getFilePathName()),\n\t\t\tsyncAccount.getFilePathName(), null, \"test\", 0, 0,\n\t\t\tsyncAccount.getSyncAccountId(), SyncFile.TYPE_FOLDER);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile parentLocalSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tremoteSyncFile.getParentFolderId(),\n\t\t\tremoteSyncFile.getRepositoryId(), getSyncAccountId());\n\n\t\tString filePathName = null;\n\n\t\tif (parentLocalSyncFile != null) {\n\t\t\tfilePathName = FilePathNameUtil.getFilePathName(\n\t\t\t\tparentLocalSyncFile.getFilePathName(),\n\t\t\t\tremoteSyncFile.getName());\n\t\t}\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setFilePathName(filePathName);\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","id":14920,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tSyncFile syncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tSyncFileService.deleteSyncFile(syncFile.getSyncFileId());\n\t}","id":14921,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tSyncFile syncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tSyncFileService.deleteSyncFile(syncFile.getSyncFileId());\n\t}","id":14922,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"public static SyncAccount addSyncAccount(\n\t\t\tString filePathName, String login, String password, String url)\n\t\tthrows Exception {\n\n\t\tSyncAccount syncAccount = new SyncAccount();\n\n\t\tsyncAccount.setFilePathName(filePathName);\n\t\tsyncAccount.setLogin(login);\n\t\tsyncAccount.setPassword(Encryptor.encrypt(password));\n\t\tsyncAccount.setUrl(url);\n\n\t\t_syncAccountPersistence.create(syncAccount);\n\n\t\tSyncFileService.addSyncFile(\n\t\t\tfilePathName, filePathName, 0, 0, syncAccount.getSyncAccountId(),\n\t\t\tSyncFile.TYPE_FOLDER);\n\n\t\treturn syncAccount;\n\t}","id":14923,"modified_method":"public static SyncAccount addSyncAccount(\n\t\t\tString filePathName, String login, String password, String url)\n\t\tthrows Exception {\n\n\t\t// Sync account\n\n\t\tSyncAccount syncAccount = new SyncAccount();\n\n\t\tsyncAccount.setFilePathName(filePathName);\n\t\tsyncAccount.setLogin(login);\n\t\tsyncAccount.setPassword(Encryptor.encrypt(password));\n\t\tsyncAccount.setUrl(url);\n\n\t\t_syncAccountPersistence.create(syncAccount);\n\n\t\t// Sync file\n\n\t\tif (Files.notExists(Paths.get(filePathName))) {\n\t\t\tFiles.createDirectory(Paths.get(filePathName));\n\t\t}\n\n\t\tSyncFileService.addSyncFile(\n\t\t\tnull, null, filePathName, FileUtil.getFileKey(filePathName),\n\t\t\tfilePathName, null, filePathName, 0, 0,\n\t\t\tsyncAccount.getSyncAccountId(), SyncFile.TYPE_FOLDER);\n\n\t\treturn syncAccount;\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"public static SyncFile addSyncFile(\n\t\t\tString filePathName, String name, long parentFolderId,\n\t\t\tlong repositoryId, long syncAccountId, String type)\n\t\tthrows Exception {\n\n\t\tSyncFile syncFile = new SyncFile();\n\n\t\tsyncFile.setFilePathName(filePathName);\n\t\tsyncFile.setName(name);\n\t\tsyncFile.setRepositoryId(repositoryId);\n\t\tsyncFile.setParentFolderId(parentFolderId);\n\t\tsyncFile.setSyncAccountId(syncAccountId);\n\t\tsyncFile.setType(type);\n\n\t\t_syncFilePersistence.create(syncFile);\n\n\t\tif (type.equals(SyncFile.TYPE_FOLDER)) {\n\t\t\tPath filePath = Paths.get(filePathName);\n\n\t\t\tFiles.createDirectories(filePath);\n\t\t}\n\n\t\treturn syncFile;\n\t}","id":14924,"modified_method":"public static SyncFile addSyncFile(\n\t\t\tString changeLog, String checksum, String description,\n\t\t\tString fileKey, String filePathName, String mimeType, String name,\n\t\t\tlong parentFolderId, long repositoryId, long syncAccountId,\n\t\t\tString type)\n\t\tthrows Exception {\n\n\t\tSyncFile syncFile = new SyncFile();\n\n\t\tsyncFile.setChangeLog(changeLog);\n\t\tsyncFile.setChecksum(checksum);\n\t\tsyncFile.setDescription(description);\n\t\tsyncFile.setFileKey(fileKey);\n\t\tsyncFile.setFilePathName(filePathName);\n\t\tsyncFile.setMimeType(mimeType);\n\t\tsyncFile.setName(name);\n\t\tsyncFile.setParentFolderId(parentFolderId);\n\t\tsyncFile.setRepositoryId(repositoryId);\n\t\tsyncFile.setSyncAccountId(syncAccountId);\n\t\tsyncFile.setType(type);\n\n\t\t_syncFilePersistence.create(syncFile);\n\n\t\treturn syncFile;\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"public static SyncSite addSyncSite(\n\t\t\tString filePathName, long groupId, long syncAccountId)\n\t\tthrows Exception {\n\n\t\tSyncSite syncSite = new SyncSite();\n\n\t\tsyncSite.setFilePathName(filePathName);\n\t\tsyncSite.setGroupId(groupId);\n\t\tsyncSite.setSyncAccountId(syncAccountId);\n\n\t\t_syncSitePersistence.create(syncSite);\n\n\t\tSyncFileService.addSyncFile(\n\t\t\tfilePathName, filePathName, 0, groupId, syncAccountId,\n\t\t\tSyncFile.TYPE_FOLDER);\n\n\t\treturn syncSite;\n\t}","id":14925,"modified_method":"public static SyncSite addSyncSite(\n\t\t\tString filePathName, long groupId, long syncAccountId)\n\t\tthrows Exception {\n\n\t\t// Sync site\n\n\t\tSyncSite syncSite = new SyncSite();\n\n\t\tsyncSite.setFilePathName(filePathName);\n\t\tsyncSite.setGroupId(groupId);\n\t\tsyncSite.setSyncAccountId(syncAccountId);\n\n\t\t_syncSitePersistence.create(syncSite);\n\n\t\t// Sync file\n\n\t\tif (Files.notExists(Paths.get(filePathName))) {\n\t\t\tFiles.createDirectory(Paths.get(filePathName));\n\t\t}\n\n\t\tSyncFileService.addSyncFile(\n\t\t\tnull, null, filePathName, FileUtil.getFileKey(filePathName),\n\t\t\tfilePathName, null, filePathName, 0, groupId,\n\t\t\tsyncSite.getSyncAccountId(), SyncFile.TYPE_FOLDER);\n\n\t\treturn syncSite;\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void deleteFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(filePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\tparameters.put(\"fileEntryId\", syncFile.getTypePK());\n\t\tparameters.put(\"syncFile\", syncFile);\n\n\t\tMoveFileEntryToTrashEvent moveFileEntryToTrashEvent =\n\t\t\tnew MoveFileEntryToTrashEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\tmoveFileEntryToTrashEvent.run();\n\t}","id":14926,"modified_method":"protected void deleteFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(filePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFileService.deleteFileSyncFile(\n\t\t\tsyncWatchEvent.getSyncAccountId(), syncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void addFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tPath parentFilePath = filePath.getParent();\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(parentFilePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFileByFileKey(\n\t\t\tFileUtil.getFileKey(filePath), syncWatchEvent.getSyncAccountId());\n\n\t\tif (syncFile == null) {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"changeLog\", \"1.0\");\n\t\t\tparameters.put(\"checksum\", FileUtil.getChecksum(filePath));\n\t\t\tparameters.put(\"description\", null);\n\t\t\tparameters.put(\"filePath\", filePath);\n\t\t\tparameters.put(\"folderId\", parentSyncFile.getTypePK());\n\t\t\tparameters.put(\"mimeType\", Files.probeContentType(filePath));\n\t\t\tparameters.put(\"repositoryId\", parentSyncFile.getRepositoryId());\n\t\t\tparameters.put(\"sourceFileName\", filePath.getFileName());\n\t\t\tparameters.put(\"title\", String.valueOf(filePath.getFileName()));\n\n\t\t\tAddFileEntryEvent addFileEntryEvent = new AddFileEntryEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\taddFileEntryEvent.run();\n\n\t\t\treturn;\n\t\t}\n\n\t\tSyncWatchEvent relatedSyncWatchEvent =\n\t\t\tSyncWatchEventService.fetchSyncWatchEvent(\n\t\t\t\tsyncFile.getFilePathName(), SyncWatchEvent.ENTRY_DELETE,\n\t\t\t\tsyncWatchEvent.getTimestamp());\n\n\t\tif (relatedSyncWatchEvent == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tPath srcFilePath = Paths.get(relatedSyncWatchEvent.getFilePathName());\n\n\t\tif (parentFilePath.equals(srcFilePath.getParent())) {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"changeLog\", syncFile.getVersion() + .1);\n\t\t\tparameters.put(\"checksum\", FileUtil.getChecksum(filePath));\n\t\t\tparameters.put(\"description\", syncFile.getDescription());\n\t\t\tparameters.put(\"fileEntryId\", syncFile.getTypePK());\n\t\t\tparameters.put(\"filePath\", filePath);\n\t\t\tparameters.put(\"majorVersion\", false);\n\t\t\tparameters.put(\"mimeType\", syncFile.getMimeType());\n\t\t\tparameters.put(\"sourceFileName\", filePath.getFileName());\n\t\t\tparameters.put(\"syncFile\", syncFile);\n\t\t\tparameters.put(\"title\", String.valueOf(filePath.getFileName()));\n\n\t\t\tUpdateFileEntryEvent updateFileEntryEvent =\n\t\t\t\tnew UpdateFileEntryEvent(\n\t\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\tupdateFileEntryEvent.run();\n\t\t}\n\t\telse {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"fileEntryId\", syncFile.getTypePK());\n\t\t\tparameters.put(\"newFolderId\", parentSyncFile.getTypePK());\n\t\t\tparameters.put(\n\t\t\t\t\"serviceContext.scopeGroupId\", syncFile.getRepositoryId());\n\n\t\t\tMoveFileEntryEvent moveFileEntryEvent = new MoveFileEntryEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\tmoveFileEntryEvent.run();\n\t\t}\n\n\t\t_processedSyncWatchEvents.add(relatedSyncWatchEvent);\n\t}","id":14927,"modified_method":"protected void addFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tPath parentFilePath = filePath.getParent();\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(parentFilePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFileByFileKey(\n\t\t\tFileUtil.getFileKey(filePath), syncWatchEvent.getSyncAccountId());\n\n\t\tif (syncFile == null) {\n\t\t\tSyncFileService.addFileSyncFile(\n\t\t\t\tfilePath, parentSyncFile.getTypePK(),\n\t\t\t\tparentSyncFile.getRepositoryId(),\n\t\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\t\treturn;\n\t\t}\n\n\t\tSyncWatchEvent relatedSyncWatchEvent =\n\t\t\tSyncWatchEventService.fetchSyncWatchEvent(\n\t\t\t\tsyncFile.getFilePathName(), SyncWatchEvent.ENTRY_DELETE,\n\t\t\t\tsyncWatchEvent.getTimestamp());\n\n\t\tif (relatedSyncWatchEvent == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tPath srcFilePath = Paths.get(relatedSyncWatchEvent.getFilePathName());\n\n\t\tif (parentFilePath.equals(srcFilePath.getParent())) {\n\t\t\tSyncFileService.updateFileSyncFile(\n\t\t\t\tfilePath, syncWatchEvent.getSyncAccountId(), syncFile);\n\t\t}\n\t\telse {\n\t\t\tSyncFileService.moveFileSyncFile(\n\t\t\t\tfilePath, parentSyncFile.getTypePK(),\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), syncFile);\n\t\t}\n\n\t\t_processedSyncWatchEventIds.add(\n\t\t\trelatedSyncWatchEvent.getSyncWatchEventId());\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void addFolder(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tString filePathName = FilePathNameUtil.getFilePathName(filePath);\n\n\t\tSyncAccount syncAccount = SyncAccountService.fetchSyncAccount(\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tif (filePathName.equals(syncAccount.getFilePathName()) ||\n\t\t\t(SyncSiteService.fetchSyncSite(\n\t\t\t\tfilePathName, syncWatchEvent.getSyncAccountId()) != null)) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tPath parentFilePath = filePath.getParent();\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(parentFilePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFileByFileKey(\n\t\t\tFileUtil.getFileKey(filePath), syncWatchEvent.getSyncAccountId());\n\n\t\tif (syncFile == null) {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"repositoryId\", parentSyncFile.getRepositoryId());\n\t\t\tparameters.put(\"parentFolderId\", parentSyncFile.getTypePK());\n\t\t\tparameters.put(\"name\", filePath.getFileName());\n\t\t\tparameters.put(\"description\", filePath);\n\n\t\t\tAddFolderEvent addFolderEvent = new AddFolderEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\taddFolderEvent.run();\n\n\t\t\treturn;\n\t\t}\n\n\t\tSyncWatchEvent relatedSyncWatchEvent =\n\t\t\tSyncWatchEventService.fetchSyncWatchEvent(\n\t\t\t\tsyncFile.getFilePathName(), SyncWatchEvent.ENTRY_DELETE,\n\t\t\t\tsyncWatchEvent.getTimestamp());\n\n\t\tif (relatedSyncWatchEvent == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tPath srcFilePath = Paths.get(relatedSyncWatchEvent.getFilePathName());\n\n\t\tif (parentFilePath.equals(srcFilePath.getParent())) {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"description\", syncFile.getDescription());\n\t\t\tparameters.put(\"folderId\", syncFile.getTypePK());\n\t\t\tparameters.put(\"name\", filePath.getFileName());\n\n\t\t\tUpdateFolderEvent updateFolderEvent =\n\t\t\t\tnew UpdateFolderEvent(\n\t\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\tupdateFolderEvent.run();\n\t\t}\n\t\telse {\n\t\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\t\tparameters.put(\"folderId\", syncFile.getTypePK());\n\t\t\tparameters.put(\"parentFolderId\", parentSyncFile.getTypePK());\n\t\t\tparameters.put(\n\t\t\t\t\"serviceContext.scopeGroupId\", syncFile.getRepositoryId());\n\n\t\t\tMoveFolderEvent moveFolderEvent = new MoveFolderEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\t\tmoveFolderEvent.run();\n\t\t}\n\n\t\t_processedSyncWatchEvents.add(relatedSyncWatchEvent);\n\t}","id":14928,"modified_method":"protected void addFolder(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tString filePathName = FilePathNameUtil.getFilePathName(filePath);\n\n\t\tSyncAccount syncAccount = SyncAccountService.fetchSyncAccount(\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tif (filePathName.equals(syncAccount.getFilePathName()) ||\n\t\t\t(SyncSiteService.fetchSyncSite(\n\t\t\t\tfilePathName, syncWatchEvent.getSyncAccountId()) != null)) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tPath parentFilePath = filePath.getParent();\n\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(parentFilePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFileByFileKey(\n\t\t\tFileUtil.getFileKey(filePath), syncWatchEvent.getSyncAccountId());\n\n\t\tif (syncFile == null) {\n\t\t\tSyncFileService.addFolderSyncFile(\n\t\t\t\tfilePath, parentSyncFile.getTypePK(),\n\t\t\t\tparentSyncFile.getRepositoryId(),\n\t\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\t\treturn;\n\t\t}\n\n\t\tSyncWatchEvent relatedSyncWatchEvent =\n\t\t\tSyncWatchEventService.fetchSyncWatchEvent(\n\t\t\t\tsyncFile.getFilePathName(), SyncWatchEvent.ENTRY_DELETE,\n\t\t\t\tsyncWatchEvent.getTimestamp());\n\n\t\tif (relatedSyncWatchEvent == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tPath srcFilePath = Paths.get(relatedSyncWatchEvent.getFilePathName());\n\n\t\tif (parentFilePath.equals(srcFilePath.getParent())) {\n\t\t\tSyncFileService.updateFolderSyncFile(\n\t\t\t\tfilePath, syncWatchEvent.getSyncAccountId(), syncFile);\n\t\t}\n\t\telse {\n\t\t\tSyncFileService.moveFolderSyncFile(\n\t\t\t\tfilePath, parentSyncFile.getTypePK(),\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), syncFile);\n\t\t}\n\n\t\t_processedSyncWatchEventIds.add(\n\t\t\trelatedSyncWatchEvent.getSyncWatchEventId());\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tpublic void run() {\n\t\tif (_logger.isTraceEnabled()) {\n\t\t\t_logger.trace(\"Processing sync watch events\");\n\t\t}\n\n\t\tList<SyncWatchEvent> syncWatchEvents = SyncWatchEventService.findAll(\n\t\t\t\"kindName\", true);\n\n\t\tfor (SyncWatchEvent syncWatchEvent : syncWatchEvents) {\n\t\t\tif (_processedSyncWatchEvents.contains(syncWatchEvent)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (_logger.isDebugEnabled()) {\n\t\t\t\t_logger.debug(\n\t\t\t\t\t\"Event file path {} file type {} kind name {} timestamp {}\",\n\t\t\t\t\tsyncWatchEvent.getFilePathName(),\n\t\t\t\t\tsyncWatchEvent.getFileType(), syncWatchEvent.getKindName(),\n\t\t\t\t\tsyncWatchEvent.getTimestamp());\n\t\t\t}\n\n\t\t\tString fileType = syncWatchEvent.getFileType();\n\n\t\t\tString kindName = syncWatchEvent.getKindName();\n\n\t\t\tif (kindName.equals(SyncWatchEvent.ENTRY_CREATE)) {\n\t\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\taddFile(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t_logger.error(e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\ttry {\n\t\t\t\t\t\taddFolder(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t_logger.error(e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (kindName.equals(SyncWatchEvent.ENTRY_DELETE)) {\n\t\t\t\tSystem.out.println(fileType);\n\n\t\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdeleteFile(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t_logger.error(e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdeleteFolder(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t_logger.error(e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\t\t}\n\n\t\t_processedSyncWatchEvents.clear();\n\t}","id":14929,"modified_method":"@Override\n\tpublic void run() {\n\t\tif (_logger.isTraceEnabled()) {\n\t\t\t_logger.trace(\"Processing sync watch events\");\n\t\t}\n\n\t\tList<SyncWatchEvent> syncWatchEvents = SyncWatchEventService.findAll(\n\t\t\t\"kindName\", true);\n\n\t\tfor (SyncWatchEvent syncWatchEvent : syncWatchEvents) {\n\t\t\tif (_processedSyncWatchEventIds.contains(\n\t\t\t\t\tsyncWatchEvent.getSyncWatchEventId())) {\n\n\t\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (_logger.isDebugEnabled()) {\n\t\t\t\t_logger.debug(\n\t\t\t\t\t\"Event file path {} file type {} kind name {} timestamp {}\",\n\t\t\t\t\tsyncWatchEvent.getFilePathName(),\n\t\t\t\t\tsyncWatchEvent.getFileType(), syncWatchEvent.getKindName(),\n\t\t\t\t\tsyncWatchEvent.getTimestamp());\n\t\t\t}\n\n\t\t\tString fileType = syncWatchEvent.getFileType();\n\n\t\t\tString kindName = syncWatchEvent.getKindName();\n\n\t\t\ttry {\n\t\t\t\tif (kindName.equals(SyncWatchEvent.ENTRY_CREATE)) {\n\t\t\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\t\t\taddFile(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\taddFolder(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (kindName.equals(SyncWatchEvent.ENTRY_DELETE)) {\n\t\t\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\t\t\tdeleteFile(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tdeleteFolder(syncWatchEvent);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\t_logger.error(e.getMessage(), e);\n\t\t\t}\n\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\t\t}\n\n\t\t_processedSyncWatchEventIds.clear();\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void deleteFolder(SyncWatchEvent syncWatchEvent)\n\t\tthrows Exception {\n\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(filePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\tparameters.put(\"folderId\", syncFile.getTypePK());\n\t\tparameters.put(\"syncFile\", syncFile);\n\n\t\tMoveFolderToTrashEvent moveFolderToTrashEvent =\n\t\t\tnew MoveFolderToTrashEvent(\n\t\t\t\tsyncWatchEvent.getSyncAccountId(), parameters);\n\n\t\tmoveFolderToTrashEvent.run();\n\t}","id":14930,"modified_method":"protected void deleteFolder(SyncWatchEvent syncWatchEvent)\n\t\tthrows Exception {\n\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(\n\t\t\tFilePathNameUtil.getFilePathName(filePath),\n\t\t\tsyncWatchEvent.getSyncAccountId());\n\n\t\tSyncFileService.deleteFolderSyncFile(\n\t\t\tsyncWatchEvent.getSyncAccountId(), syncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile parentLocalSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tremoteSyncFile.getParentFolderId(),\n\t\t\tremoteSyncFile.getRepositoryId(), getSyncAccountId());\n\n\t\tString filePathName = null;\n\n\t\tif (parentLocalSyncFile != null) {\n\t\t\tfilePathName = FilePathNameUtil.getFilePathName(\n\t\t\t\tparentLocalSyncFile.getFilePathName(),\n\t\t\t\tremoteSyncFile.getName());\n\t\t}\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setDescription(remoteSyncFile.getDescription());\n\t\tlocalSyncFile.setFilePathName(filePathName);\n\t\tlocalSyncFile.setName(remoteSyncFile.getName());\n\t\tlocalSyncFile.setParentFolderId(remoteSyncFile.getParentFolderId());\n\t\tlocalSyncFile.setRepositoryId(remoteSyncFile.getRepositoryId());\n\t\tlocalSyncFile.setSize(remoteSyncFile.getSize());\n\t\tlocalSyncFile.setTypePK(remoteSyncFile.getTypePK());\n\t\tlocalSyncFile.setTypeUuid(remoteSyncFile.getTypeUuid());\n\t\tlocalSyncFile.setVersion(remoteSyncFile.getVersion());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","id":14931,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\t\tlocalSyncFile.setParentFolderId(remoteSyncFile.getParentFolderId());\n\t\tlocalSyncFile.setSize(remoteSyncFile.getSize());\n\t\tlocalSyncFile.setVersion(remoteSyncFile.getVersion());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile parentLocalSyncFile = SyncFileService.fetchSyncFile(\n\t\t\tremoteSyncFile.getParentFolderId(),\n\t\t\tremoteSyncFile.getRepositoryId(), getSyncAccountId());\n\n\t\tString filePathName = null;\n\n\t\tif (parentLocalSyncFile != null) {\n\t\t\tfilePathName = FilePathNameUtil.getFilePathName(\n\t\t\t\tparentLocalSyncFile.getFilePathName(),\n\t\t\t\tremoteSyncFile.getName());\n\t\t}\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\t\tlocalSyncFile.setFilePathName(filePathName);\n\t\tlocalSyncFile.setName(remoteSyncFile.getName());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","id":14932,"modified_method":"@Override\n\tprotected void processResponse(String response) throws Exception {\n\t\tObjectMapper objectMapper = new ObjectMapper();\n\n\t\tSyncFile remoteSyncFile = objectMapper.readValue(\n\t\t\tresponse, new TypeReference<SyncFile>() {});\n\n\t\tSyncFile localSyncFile = (SyncFile)getParameterValue(\"syncFile\");\n\n\t\tlocalSyncFile.setModifiedTime(remoteSyncFile.getModifiedTime());\n\n\t\tSyncFileService.update(localSyncFile);\n\t}","commit_id":"86d3c85f3db4cc4a623ab0ccefbebdab4c66db5f","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void downloadFile(\n\t\tSyncFile syncFile, String sourceVersion, boolean patch) {\n\n\t\tMap<String, Object> parameters = new HashMap<String, Object>();\n\n\t\tparameters.put(\"syncFile\", syncFile);\n\n\t\tString targetVersion = syncFile.getVersion();\n\n\t\tif (patch &&\n\t\t\t(Double.valueOf(targetVersion) > Double.valueOf(sourceVersion))) {\n\n\t\t\tparameters.put(\"patch\", true);\n\t\t\tparameters.put(\"sourceVersion\", sourceVersion);\n\t\t\tparameters.put(\"targetVersion\", targetVersion);\n\t\t}\n\t\telse {\n\t\t\tparameters.put(\"patch\", false);\n\t\t}\n\n\t\tDownloadFileEvent downloadFileEvent = new DownloadFileEvent(\n\t\t\tgetSyncAccountId(), parameters);\n\n\t\tdownloadFileEvent.run();\n\t}","id":14933,"modified_method":"protected void downloadFile(\n\t\tSyncFile syncFile, String sourceVersion, boolean patch) {\n\n\t\tString targetVersion = syncFile.getVersion();\n\n\t\tif (patch &&\n\t\t\t(Double.valueOf(targetVersion) > Double.valueOf(sourceVersion))) {\n\n\t\t\tFileEventUtil.downloadPatch(\n\t\t\t\tsourceVersion, getSyncAccountId(), syncFile, targetVersion);\n\t\t}\n\t\telse {\n\t\t\tFileEventUtil.downloadFile(getSyncAccountId(), syncFile);\n\t\t}\n\t}","commit_id":"4c4bc5758fcea7d7fb5486c08a6c2bde80c6c911","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected static void synchronizeSyncFiles(\n\t\t\tPath filePath, long syncAccountId,\n\t\t\tWatchEventListener watchEventListener)\n\t\tthrows IOException {\n\n\t\tfireDeleteEvents(filePath, watchEventListener);\n\n\t\tretryFileTransfers(syncAccountId);\n\t}","id":14934,"modified_method":"protected static void synchronizeSyncFiles(\n\t\t\tPath filePath, long syncAccountId,\n\t\t\tWatchEventListener watchEventListener)\n\t\tthrows IOException {\n\n\t\tfireDeleteEvents(filePath, watchEventListener);\n\n\t\tFileEventUtil.retryFileTransfers(syncAccountId);\n\t}","commit_id":"4c4bc5758fcea7d7fb5486c08a6c2bde80c6c911","url":"https://github.com/liferay/liferay-portal"},{"original_method":"/**\n   * Invokes grid search based on specified hyper space walk strategy.\n   *\n   * It updates passed grid object in distributed store.\n   *\n   * @param grid grid object to save results; grid already locked\n   */\n  private void gridSearch(Grid<MP> grid) {\n    Model model = null;\n    // Prepare nice model key and override default key by appending model counter\n    //String protoModelKey = _hyperSpaceWalker.getParams()._model_id == null\n    //                       ? grid._key + \"_model_\"\n    //                       : _hyperSpaceWalker.getParams()._model_id.toString() + H2O.calcNextUniqueModelId(\"\") + \"_\";\n    String protoModelKey = grid._key + \"_model_\";\n    try {\n      // Get iterator to traverse hyper space\n      HyperSpaceWalker.HyperSpaceIterator<MP> it = _hyperSpaceWalker.iterator();\n      // Number of traversed model parameters\n      int counter = 0;\n      while (it.hasNext(model)) {\n        if(_job.stop_requested() ) return;  // Handle end-user cancel request\n        MP params;\n        try {\n          // Get parameters for next model\n          params = it.nextModelParameters(model);\n          // Sequential model building, should never propagate\n          // exception up, just mark combination of model parameters as wrong\n          try {\n            model = buildModel(params, grid, counter++, protoModelKey);\n          } catch (RuntimeException e) { // Catch everything\n            StringWriter sw = new StringWriter();\n            PrintWriter pw = new PrintWriter(sw);\n            e.printStackTrace(pw);\n            Log.warn(\"Grid search: model builder for parameters \" + params + \" failed! Exception: \", e, sw.toString());\n            grid.appendFailedModelParameters(params, e);\n          }\n        } catch (IllegalArgumentException e) {\n          Log.warn(\"Grid search: construction of model parameters failed! Exception: \", e);\n          // Model parameters cannot be constructed for some reason\n          Object[] rawParams = it.getCurrentRawParameters();\n          grid.appendFailedModelParameters(rawParams, e);\n        } finally {\n          // Update progress by 1 increment\n          _job.update(1);\n          // Always update grid in DKV after model building attempt\n          grid.update(_job);\n        }\n      }\n    } finally {\n      grid.unlock(_job);\n    }\n  }","id":14935,"modified_method":"/**\n   * Invokes grid search based on specified hyper space walk strategy.\n   *\n   * It updates passed grid object in distributed store.\n   *\n   * @param grid grid object to save results; grid already locked\n   */\n  private void gridSearch(Grid<MP> grid) {\n    Model model = null;\n    // Prepare nice model key and override default key by appending model counter\n    //String protoModelKey = _hyperSpaceWalker.getParams()._model_id == null\n    //                       ? grid._key + \"_model_\"\n    //                       : _hyperSpaceWalker.getParams()._model_id.toString() + H2O.calcNextUniqueModelId(\"\") + \"_\";\n    String protoModelKey = grid._key + \"_model_\";\n    try {\n      // Get iterator to traverse hyper space\n      HyperSpaceWalker.HyperSpaceIterator<MP> it = _hyperSpaceWalker.iterator();\n      // Number of traversed model parameters\n      int counter = 0;\n      while (it.hasNext(model)) {\n        if(_job.stop_requested() ) return;  // Handle end-user cancel request\n        MP params;\n        try {\n          // Get parameters for next model\n          params = it.nextModelParameters(model);\n          // Sequential model building, should never propagate\n          // exception up, just mark combination of model parameters as wrong\n          try {\n            model = buildModel(params, grid, counter++, protoModelKey);\n          } catch (RuntimeException e) { // Catch everything\n            StringWriter sw = new StringWriter();\n            PrintWriter pw = new PrintWriter(sw);\n            e.printStackTrace(pw);\n            Log.warn(\"Grid search: model builder for parameters \" + params + \" failed! Exception: \", e, sw.toString());\n            grid.appendFailedModelParameters(params, e);\n          }\n        } catch (IllegalArgumentException e) {\n          Log.warn(\"Grid search: construction of model parameters failed! Exception: \", e);\n          // Model parameters cannot be constructed for some reason\n          it.modelFailed(model);\n          Object[] rawParams = it.getCurrentRawParameters();\n          grid.appendFailedModelParameters(rawParams, e);\n        } finally {\n          // Update progress by 1 increment\n          _job.update(1);\n          // Always update grid in DKV after model building attempt\n          grid.update(_job);\n        }\n      }\n      Log.info(\"For grid: \" + grid._key + \" built: \" + grid.getModelCount() + \" models.\");\n    } finally {\n      grid.unlock(_job);\n    }\n  }","commit_id":"58b884c43e52f46defe04a484cbec05e515e4049","url":"https://github.com/h2oai/h2o-3"},{"original_method":"@Override S handle(int version, water.api.Route route, Properties parms) throws Exception {\n    // Only here for train or validate-parms\n    if( !route._handler_method.getName().equals(\"train\") )\n      throw water.H2O.unimpl();\n\n    // Peek out the desired algo from the URL\n    String ss[] = route._url_pattern_raw.split(\"/\");\n    String algoURLName = ss[3]; // {}/{99}/{Grid}/{gbm}/\n    String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n    String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n    // Get the latest version of this algo: /99/Grid/gbm  ==> GBMV3\n    String algoSchemaName = Schema.schemaClass(version, algoName).getSimpleName(); // GBMV3\n    int algoVersion = Integer.valueOf(algoSchemaName.substring(algoSchemaName.lastIndexOf(\"V\")+1)); // '3'\n\n    // TODO: this is a horrible hack which is going to cause maintenance problems:\n    String paramSchemaName = schemaDir+algoName+\"V\"+algoVersion+\"$\"+ModelBuilder.paramName(algoURLName)+\"V\"+algoVersion;\n\n    // Build the Grid Search schema, and fill it from the parameters\n    S gss = (S) new GridSearchSchema();\n    gss.init_meta();\n    gss.parameters = (P)TypeMap.newFreezable(paramSchemaName);\n    gss.parameters.init_meta();\n    ModelBuilder builder = ModelBuilder.make(algoURLName,null,null); // Default parameter settings\n    gss.parameters.fillFromImpl(builder._parms); // Defaults for this builder into schema\n    gss.fillFromParms(parms);   // Override defaults from user parms\n\n    if (parms.contains(\"strategy\"))\n      try { gss.strategy = GridSearch.Strategy.valueOf((String)parms.get(\"strategy\")); }\n      catch (IllegalArgumentException iae) { throw new H2OIllegalValueException(\"strategy\", parms.get(\"strategy\")); }\n\n    if (parms.contains(\"max_models\"))\n      try { gss.max_models = Integer.valueOf((String)parms.get(\"max_models\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalValueException(\"max_models\", parms.get(\"max_models\")); }\n\n    if (parms.contains(\"max_time_ms\"))\n      try { gss.max_time_ms = Integer.valueOf((String)parms.get(\"max_time_ms\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalValueException(\"max_time_ms\", parms.get(\"max_time_ms\")); }\n\n    if (parms.contains(\"seed\"))\n      try { gss.seed = Long.valueOf((String)parms.get(\"seed\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalValueException(\"seed\", parms.get(\"seed\")); }\n\n    // TODO: for testing; remove:\n    // gss.max_models = 10000;\n    // gss.strategy = GridSearch.Strategy.Random;\n\n    // Verify list of hyper parameters\n    // Right now only names, no types\n    validateHyperParams((P)gss.parameters, gss.hyper_parameters);\n\n    // Get actual parameters\n    MP params = (MP) gss.parameters.createAndFillImpl();\n\n    // Get/create a grid for given frame\n    // FIXME: Grid ID is not pass to grid search builder!\n    Key<Grid> destKey = gss.grid_id != null ? gss.grid_id.key() : null;\n    // Create target grid search object (keep it private for now)\n    // Start grid search and return the schema back with job key\n    Job<Grid> gsJob = GridSearch.startGridSearch(destKey,\n                                                 params,\n                                                 gss.hyper_parameters,\n                                                 new DefaultModelParametersBuilderFactory<MP, P>(),\n            gss.strategy, gss.max_models, gss.max_time_ms, gss.seed);\n\n    // Fill schema with job parameters\n    // FIXME: right now we have to remove grid parameters which we sent back\n    gss.hyper_parameters = null;\n    gss.total_models = gsJob._result.get().getModelCount();\n    gss.job = (JobV3) Schema.schema(version, Job.class).fillFromImpl(gsJob);\n\n    return gss;\n  }","id":14936,"modified_method":"@Override S handle(int version, water.api.Route route, Properties parms) throws Exception {\n    // Only here for train or validate-parms\n    if( !route._handler_method.getName().equals(\"train\") )\n      throw water.H2O.unimpl();\n\n    // Peek out the desired algo from the URL\n    String ss[] = route._url_pattern_raw.split(\"/\");\n    String algoURLName = ss[3]; // {}/{99}/{Grid}/{gbm}/\n    String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n    String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n    // Get the latest version of this algo: /99/Grid/gbm  ==> GBMV3\n    String algoSchemaName = Schema.schemaClass(version, algoName).getSimpleName(); // GBMV3\n    int algoVersion = Integer.valueOf(algoSchemaName.substring(algoSchemaName.lastIndexOf(\"V\")+1)); // '3'\n\n    // TODO: this is a horrible hack which is going to cause maintenance problems:\n    String paramSchemaName = schemaDir+algoName+\"V\"+algoVersion+\"$\"+ModelBuilder.paramName(algoURLName)+\"V\"+algoVersion;\n\n    // Build the Grid Search schema, and fill it from the parameters\n    S gss = (S) new GridSearchSchema();\n    gss.init_meta();\n    gss.parameters = (P)TypeMap.newFreezable(paramSchemaName);\n    gss.parameters.init_meta();\n    ModelBuilder builder = ModelBuilder.make(algoURLName,null,null); // Default parameter settings\n    gss.parameters.fillFromImpl(builder._parms); // Defaults for this builder into schema\n    gss.fillFromParms(parms);   // Override defaults from user parms\n\n    // Verify list of hyper parameters\n    // Right now only names, no types\n    validateHyperParams((P)gss.parameters, gss.hyper_parameters);\n\n    // Get actual parameters\n    MP params = (MP) gss.parameters.createAndFillImpl();\n\n    // Get/create a grid for given frame\n    // FIXME: Grid ID is not pass to grid search builder!\n    Key<Grid> destKey = gss.grid_id != null ? gss.grid_id.key() : null;\n    // Create target grid search object (keep it private for now)\n    // Start grid search and return the schema back with job key\n    Job<Grid> gsJob = GridSearch.startGridSearch(destKey,\n                                                 params,\n                                                 gss.hyper_parameters,\n                                                 new DefaultModelParametersBuilderFactory<MP, P>(),\n            gss.strategy, gss.max_models, gss.max_time_ms, gss.seed);\n\n    // Fill schema with job parameters\n    // FIXME: right now we have to remove grid parameters which we sent back\n    gss.hyper_parameters = null;\n    gss.total_models = gsJob._result.get().getModelCount(); // TODO: looks like it's currently always 0\n    gss.job = (JobV3) Schema.schema(version, Job.class).fillFromImpl(gsJob);\n\n    return gss;\n  }","commit_id":"58b884c43e52f46defe04a484cbec05e515e4049","url":"https://github.com/h2oai/h2o-3"},{"original_method":"@Override public S fillFromParms(Properties parms) {\n    if( parms.containsKey(\"hyper_parameters\") ) {\n      Map<String,Object> m = water.util.JSONUtils.parse(parms.getProperty(\"hyper_parameters\"));\n      hyper_parameters = new IcedHashMap<>();\n      // Convert lists and singletons into arrays\n      for (Map.Entry<String, Object> e : m.entrySet()) {\n        Object o = e.getValue();\n        Object[] o2 = o instanceof List ? ((List) o).toArray() : new Object[]{o};\n        hyper_parameters.put(e.getKey(),o2);\n      }\n      parms.remove(\"hyper_parameters\");\n    }\n\n    // Ugh:\n    if (parms.containsKey(\"strategy\")) { strategy = Strategy.valueOf(parms.getProperty(\"strategy\")); parms.remove(\"strategy\"); }\n    if (parms.containsKey(\"max_models\")) { max_models = Integer.valueOf(parms.getProperty(\"max_models\")); parms.remove(\"max_models\"); }\n    if (parms.containsKey(\"max_time_ms\")) { max_time_ms = Integer.valueOf(parms.getProperty(\"max_time_ms\")); parms.remove(\"max_time_ms\"); }\n    if (parms.containsKey(\"seed\")) { seed = Long.valueOf(parms.getProperty(\"seed\")); parms.remove(\"seed\"); }\n\n    if (parms.containsKey(\"grid_id\")) { grid_id = new KeyV3.GridKeyV3(Key.<Grid>make(parms.getProperty(\"grid_id\"))); parms.remove(\"grid_id\"); }\n\n    // Do not check validity of parameters, GridSearch is tolerant of bad\n    // parameters (on purpose, many hyper-param points in the grid might be\n    // illegal for whatever reason).\n    this.parameters.fillFromParms(parms, false);\n\n    return (S) this;\n  }","id":14937,"modified_method":"@Override public S fillFromParms(Properties parms) {\n    if( parms.containsKey(\"hyper_parameters\") ) {\n      Map<String,Object> m = water.util.JSONUtils.parse(parms.getProperty(\"hyper_parameters\"));\n      hyper_parameters = new IcedHashMap<>();\n      // Convert lists and singletons into arrays\n      for (Map.Entry<String, Object> e : m.entrySet()) {\n        Object o = e.getValue();\n        Object[] o2 = o instanceof List ? ((List) o).toArray() : new Object[]{o};\n        hyper_parameters.put(e.getKey(),o2);\n      }\n      parms.remove(\"hyper_parameters\");\n    }\n\n    // Ugh:\n    if (parms.containsKey(\"strategy\"))\n      try { strategy = GridSearch.Strategy.valueOf((String)parms.get(\"strategy\")); }\n      catch (IllegalArgumentException iae) { throw new H2OIllegalArgumentException(\"strategy\", (String)parms.get(\"strategy\")); }\n      finally { parms.remove(\"strategy\"); }\n\n    if (parms.containsKey(\"max_models\"))\n      try { max_models = Integer.valueOf((String)parms.get(\"max_models\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalArgumentException(\"max_models\", (String)parms.get(\"max_models\")); }\n      finally { parms.remove(\"max_models\"); }\n\n    if (parms.containsKey(\"max_time_ms\"))\n      try { max_time_ms = Integer.valueOf((String)parms.get(\"max_time_ms\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalArgumentException(\"max_time_ms\", (String)parms.get(\"max_time_ms\")); }\n      finally { parms.remove(\"max_time_ms\"); }\n\n    if (parms.containsKey(\"seed\"))\n      try { seed = Long.valueOf((String)parms.get(\"seed\")); }\n      catch (NumberFormatException nfe) { throw new H2OIllegalArgumentException(\"seed\", (String)parms.get(\"seed\")); }\n      finally { parms.remove(\"seed\"); }\n\n    if (parms.containsKey(\"grid_id\")) { grid_id = new KeyV3.GridKeyV3(Key.<Grid>make(parms.getProperty(\"grid_id\"))); parms.remove(\"grid_id\"); }\n\n    // Do not check validity of parameters, GridSearch is tolerant of bad\n    // parameters (on purpose, many hyper-param points in the grid might be\n    // illegal for whatever reason).\n    this.parameters.fillFromParms(parms, false);\n\n    return (S) this;\n  }","commit_id":"58b884c43e52f46defe04a484cbec05e515e4049","url":"https://github.com/h2oai/h2o-3"},{"original_method":"private EditorCell createRefNode_i2dquw_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectGetter\");\n    provider.setNoTargetText(\"<no objectGetter>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14938,"modified_method":"private EditorCell createRefNode_i2dquw_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectGetter\");\n    provider.setNoTargetText(\"<no objectGetter>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.INDENT_LAYOUT_ON_NEW_LINE, true);\n      style.set(StyleAttributes.INDENT_LAYOUT_INDENT, true);\n    }\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createProperty_i2dquw_a0b0(EditorContext editorContext, SNode node) {\n      CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n      provider.setRole(\"name\");\n      provider.setNoTargetText(\"<no name>\");\n      provider.setReadOnly(true);\n      EditorCell editorCell;\n      editorCell = provider.createEditorCell(editorContext);\n      editorCell.setCellId(\"property_name\");\n      editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n      SNode attributeConcept = provider.getRoleAttribute();\n      Class attributeKind = provider.getRoleAttributeClass();\n      if (attributeConcept != null) {\n        IOperationContext opContext = editorContext.getOperationContext();\n        EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n        return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n      } else\n      return editorCell;\n    }","id":14939,"modified_method":"private EditorCell createProperty_i2dquw_a0b0(EditorContext editorContext, SNode node) {\n      CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n      provider.setRole(\"extensionName\");\n      provider.setNoTargetText(\"<no extensionName>\");\n      provider.setReadOnly(true);\n      EditorCell editorCell;\n      editorCell = provider.createEditorCell(editorContext);\n      editorCell.setCellId(\"property_extensionName\");\n      editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n      SNode attributeConcept = provider.getRoleAttribute();\n      Class attributeKind = provider.getRoleAttributeClass();\n      if (attributeConcept != null) {\n        IOperationContext opContext = editorContext.getOperationContext();\n        EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n        return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n      } else\n      return editorCell;\n    }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_i2dquw_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"Extension\");\n    editorCell.setCellId(\"Constant_i2dquw_a0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14940,"modified_method":"private EditorCell createConstant_i2dquw_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"Extension of\");\n    editorCell.setCellId(\"Constant_i2dquw_a0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static String call_getId_63012922130945363(SNode thisNode) {\n    IModule module = SNodeOperations.getModel(thisNode).getModelDescriptor().getModule();\n    String moduleFqName = module.getModuleFqName();\n    int atIdx = moduleFqName.indexOf(\"@\");\n    if (atIdx >= 0) {\n      moduleFqName = moduleFqName.substring(0, atIdx);\n    }\n    return moduleFqName + \".\" + SPropertyOperations.getString(thisNode, \"name\");\n  }","id":14941,"modified_method":"public static String call_getId_63012922130945363(SNode thisNode) {\n    IModule module = SNodeOperations.getModel(thisNode).getModelDescriptor().getModule();\n    String moduleFqName = module.getModuleFqName();\n    int atIdx = moduleFqName.indexOf(\"@\");\n    if (atIdx >= 0) {\n      moduleFqName = moduleFqName.substring(0, atIdx);\n    }\n    return moduleFqName + \".\" + SPropertyOperations.getString(thisNode, \"extensionName\");\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createProperty_obn5mp_e0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n    provider.setRole(\"name\");\n    provider.setNoTargetText(\"<no name>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setCellId(\"property_name\");\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14942,"modified_method":"private EditorCell createProperty_obn5mp_b0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n    provider.setRole(\"extensionName\");\n    provider.setNoTargetText(\"<no extensionName>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setCellId(\"property_extensionName\");\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createCollection_obn5mp_a(EditorContext editorContext, SNode node) {\n    EditorCell_Collection editorCell = EditorCell_Collection.createIndent2(editorContext, node);\n    editorCell.setCellId(\"Collection_obn5mp_a\");\n    editorCell.addEditorCell(this.createConstant_obn5mp_a0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_b0(editorContext, node));\n    editorCell.addEditorCell(this.createRefNode_obn5mp_c0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_d0(editorContext, node));\n    editorCell.addEditorCell(this.createProperty_obn5mp_e0(editorContext, node));\n    return editorCell;\n  }","id":14943,"modified_method":"private EditorCell createCollection_obn5mp_a(EditorContext editorContext, SNode node) {\n    EditorCell_Collection editorCell = EditorCell_Collection.createIndent2(editorContext, node);\n    editorCell.setCellId(\"Collection_obn5mp_a\");\n    editorCell.addEditorCell(this.createConstant_obn5mp_a0(editorContext, node));\n    editorCell.addEditorCell(this.createProperty_obn5mp_b0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_c0(editorContext, node));\n    editorCell.addEditorCell(this.createRefNode_obn5mp_d0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_e0(editorContext, node));\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_d0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \">\");\n    editorCell.setCellId(\"Constant_obn5mp_d0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14944,"modified_method":"private EditorCell createConstant_obn5mp_c0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"<\");\n    editorCell.setCellId(\"Constant_obn5mp_c0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_RIGHT, true);\n    }\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"ExtensionPoint\");\n    editorCell.setCellId(\"Constant_obn5mp_a0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14945,"modified_method":"private EditorCell createConstant_obn5mp_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"ExtensionPoint\");\n    editorCell.setCellId(\"Constant_obn5mp_a0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_b0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"<\");\n    editorCell.setCellId(\"Constant_obn5mp_b0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14946,"modified_method":"private EditorCell createConstant_obn5mp_e0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \">\");\n    editorCell.setCellId(\"Constant_obn5mp_e0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_LEFT, true);\n    }\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createRefNode_obn5mp_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectType\");\n    provider.setNoTargetText(\"<no objectType>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14947,"modified_method":"private EditorCell createRefNode_obn5mp_d0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectType\");\n    provider.setNoTargetText(\"<no objectType>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_LEFT, true);\n    }\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object propertyMacro_GetPropertyValue_8820339482096486801(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14948,"modified_method":"public static Object propertyMacro_GetPropertyValue_8820339482096486801(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object referenceMacro_GetReferent_63012922130977670(final IOperationContext operationContext, final ReferenceMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14949,"modified_method":"public static Object referenceMacro_GetReferent_63012922130977670(final IOperationContext operationContext, final ReferenceMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object propertyMacro_GetPropertyValue_63012922130977712(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14950,"modified_method":"public static Object propertyMacro_GetPropertyValue_63012922130977712(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"public ConceptDescriptor getDescriptor(String conceptFqName) {\n    switch (Arrays.binarySearch(stringSwitchCases_1htk8d_a0a0a, conceptFqName)) {\n      case 0:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      case 1:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionObjectGetter\", \"jetbrains.mps.baseLanguage.structure.ConceptFunction\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.ConceptFunction\"}, new String[]{}, new String[]{});\n      case 2:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{}, new String[]{});\n      case 3:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointExpression\", \"jetbrains.mps.baseLanguage.structure.Expression\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.Expression\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      default:\n        return StructureAspectInterpreted.getInstance().getDescriptor(conceptFqName);\n    }\n  }","id":14951,"modified_method":"public ConceptDescriptor getDescriptor(String conceptFqName) {\n    switch (Arrays.binarySearch(stringSwitchCases_1htk8d_a0a0a, conceptFqName)) {\n      case 0:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      case 1:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionObjectGetter\", \"jetbrains.mps.baseLanguage.structure.ConceptFunction\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.ConceptFunction\"}, new String[]{}, new String[]{});\n      case 2:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{\"extensionName\"}, new String[]{});\n      case 3:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointExpression\", \"jetbrains.mps.baseLanguage.structure.Expression\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.Expression\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      default:\n        return StructureAspectInterpreted.getInstance().getDescriptor(conceptFqName);\n    }\n  }","commit_id":"e67c0facf6313e701a114460edd8b1fba7f809f9","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_i2dquw_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"Extension\");\n    editorCell.setCellId(\"Constant_i2dquw_a0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14952,"modified_method":"private EditorCell createConstant_i2dquw_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"Extension of\");\n    editorCell.setCellId(\"Constant_i2dquw_a0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createProperty_i2dquw_a0b0(EditorContext editorContext, SNode node) {\n      CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n      provider.setRole(\"name\");\n      provider.setNoTargetText(\"<no name>\");\n      provider.setReadOnly(true);\n      EditorCell editorCell;\n      editorCell = provider.createEditorCell(editorContext);\n      editorCell.setCellId(\"property_name\");\n      editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n      SNode attributeConcept = provider.getRoleAttribute();\n      Class attributeKind = provider.getRoleAttributeClass();\n      if (attributeConcept != null) {\n        IOperationContext opContext = editorContext.getOperationContext();\n        EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n        return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n      } else\n      return editorCell;\n    }","id":14953,"modified_method":"private EditorCell createProperty_i2dquw_a0b0(EditorContext editorContext, SNode node) {\n      CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n      provider.setRole(\"extensionName\");\n      provider.setNoTargetText(\"<no extensionName>\");\n      provider.setReadOnly(true);\n      EditorCell editorCell;\n      editorCell = provider.createEditorCell(editorContext);\n      editorCell.setCellId(\"property_extensionName\");\n      editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n      SNode attributeConcept = provider.getRoleAttribute();\n      Class attributeKind = provider.getRoleAttributeClass();\n      if (attributeConcept != null) {\n        IOperationContext opContext = editorContext.getOperationContext();\n        EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n        return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n      } else\n      return editorCell;\n    }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createRefNode_i2dquw_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectGetter\");\n    provider.setNoTargetText(\"<no objectGetter>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14954,"modified_method":"private EditorCell createRefNode_i2dquw_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectGetter\");\n    provider.setNoTargetText(\"<no objectGetter>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.INDENT_LAYOUT_ON_NEW_LINE, true);\n      style.set(StyleAttributes.INDENT_LAYOUT_INDENT, true);\n    }\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static String call_getId_63012922130945363(SNode thisNode) {\n    IModule module = SNodeOperations.getModel(thisNode).getModelDescriptor().getModule();\n    String moduleFqName = module.getModuleFqName();\n    int atIdx = moduleFqName.indexOf(\"@\");\n    if (atIdx >= 0) {\n      moduleFqName = moduleFqName.substring(0, atIdx);\n    }\n    return moduleFqName + \".\" + SPropertyOperations.getString(thisNode, \"name\");\n  }","id":14955,"modified_method":"public static String call_getId_63012922130945363(SNode thisNode) {\n    IModule module = SNodeOperations.getModel(thisNode).getModelDescriptor().getModule();\n    String moduleFqName = module.getModuleFqName();\n    int atIdx = moduleFqName.indexOf(\"@\");\n    if (atIdx >= 0) {\n      moduleFqName = moduleFqName.substring(0, atIdx);\n    }\n    return moduleFqName + \".\" + SPropertyOperations.getString(thisNode, \"extensionName\");\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createCollection_obn5mp_a(EditorContext editorContext, SNode node) {\n    EditorCell_Collection editorCell = EditorCell_Collection.createIndent2(editorContext, node);\n    editorCell.setCellId(\"Collection_obn5mp_a\");\n    editorCell.addEditorCell(this.createConstant_obn5mp_a0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_b0(editorContext, node));\n    editorCell.addEditorCell(this.createRefNode_obn5mp_c0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_d0(editorContext, node));\n    editorCell.addEditorCell(this.createProperty_obn5mp_e0(editorContext, node));\n    return editorCell;\n  }","id":14956,"modified_method":"private EditorCell createCollection_obn5mp_a(EditorContext editorContext, SNode node) {\n    EditorCell_Collection editorCell = EditorCell_Collection.createIndent2(editorContext, node);\n    editorCell.setCellId(\"Collection_obn5mp_a\");\n    editorCell.addEditorCell(this.createConstant_obn5mp_a0(editorContext, node));\n    editorCell.addEditorCell(this.createProperty_obn5mp_b0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_c0(editorContext, node));\n    editorCell.addEditorCell(this.createRefNode_obn5mp_d0(editorContext, node));\n    editorCell.addEditorCell(this.createConstant_obn5mp_e0(editorContext, node));\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_b0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"<\");\n    editorCell.setCellId(\"Constant_obn5mp_b0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14957,"modified_method":"private EditorCell createConstant_obn5mp_e0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \">\");\n    editorCell.setCellId(\"Constant_obn5mp_e0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_LEFT, true);\n    }\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_d0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \">\");\n    editorCell.setCellId(\"Constant_obn5mp_d0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14958,"modified_method":"private EditorCell createConstant_obn5mp_c0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"<\");\n    editorCell.setCellId(\"Constant_obn5mp_c0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_RIGHT, true);\n    }\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createRefNode_obn5mp_c0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectType\");\n    provider.setNoTargetText(\"<no objectType>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14959,"modified_method":"private EditorCell createRefNode_obn5mp_d0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new RefNodeCellProvider(node, editorContext);\n    provider.setRole(\"objectType\");\n    provider.setNoTargetText(\"<no objectType>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    {\n      Style style = editorCell.getStyle();\n      style.set(StyleAttributes.PUNCTUATION_LEFT, true);\n    }\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createProperty_obn5mp_e0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n    provider.setRole(\"name\");\n    provider.setNoTargetText(\"<no name>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setCellId(\"property_name\");\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","id":14960,"modified_method":"private EditorCell createProperty_obn5mp_b0(EditorContext editorContext, SNode node) {\n    CellProviderWithRole provider = new PropertyCellProvider(node, editorContext);\n    provider.setRole(\"extensionName\");\n    provider.setNoTargetText(\"<no extensionName>\");\n    EditorCell editorCell;\n    editorCell = provider.createEditorCell(editorContext);\n    editorCell.setCellId(\"property_extensionName\");\n    editorCell.setSubstituteInfo(provider.createDefaultSubstituteInfo());\n    SNode attributeConcept = provider.getRoleAttribute();\n    Class attributeKind = provider.getRoleAttributeClass();\n    if (attributeConcept != null) {\n      IOperationContext opContext = editorContext.getOperationContext();\n      EditorManager manager = EditorManager.getInstanceFromContext(opContext);\n      return manager.createRoleAttributeCell(editorContext, attributeConcept, attributeKind, editorCell);\n    } else\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createConstant_obn5mp_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"ExtensionPoint\");\n    editorCell.setCellId(\"Constant_obn5mp_a0\");\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","id":14961,"modified_method":"private EditorCell createConstant_obn5mp_a0(EditorContext editorContext, SNode node) {\n    EditorCell_Constant editorCell = new EditorCell_Constant(editorContext, node, \"ExtensionPoint\");\n    editorCell.setCellId(\"Constant_obn5mp_a0\");\n    BaseLanguageStyle_StyleSheet.getKeyWord(editorCell).apply(editorCell);\n    editorCell.setDefaultText(\"\");\n    return editorCell;\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object propertyMacro_GetPropertyValue_8820339482096486801(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14962,"modified_method":"public static Object propertyMacro_GetPropertyValue_8820339482096486801(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object referenceMacro_GetReferent_63012922130977670(final IOperationContext operationContext, final ReferenceMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14963,"modified_method":"public static Object referenceMacro_GetReferent_63012922130977670(final IOperationContext operationContext, final ReferenceMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Object propertyMacro_GetPropertyValue_63012922130977712(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return \"Extension_\" + NameUtil.toValidIdentifier(SPropertyOperations.getString(SLinkOperations.getTarget(_context.getNode(), \"extensionPoint\", false), \"name\"));\n  }","id":14964,"modified_method":"public static Object propertyMacro_GetPropertyValue_63012922130977712(final IOperationContext operationContext, final PropertyMacroContext _context) {\n    return ExtensionDeclaration_Behavior.call_getJavaName_5234729458457669523(_context.getNode());\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"public ConceptDescriptor getDescriptor(String conceptFqName) {\n    switch (Arrays.binarySearch(stringSwitchCases_1htk8d_a0a0a, conceptFqName)) {\n      case 0:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      case 1:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionObjectGetter\", \"jetbrains.mps.baseLanguage.structure.ConceptFunction\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.ConceptFunction\"}, new String[]{}, new String[]{});\n      case 2:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{}, new String[]{});\n      case 3:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointExpression\", \"jetbrains.mps.baseLanguage.structure.Expression\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.Expression\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      default:\n        return StructureAspectInterpreted.getInstance().getDescriptor(conceptFqName);\n    }\n  }","id":14965,"modified_method":"public ConceptDescriptor getDescriptor(String conceptFqName) {\n    switch (Arrays.binarySearch(stringSwitchCases_1htk8d_a0a0a, conceptFqName)) {\n      case 0:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      case 1:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionObjectGetter\", \"jetbrains.mps.baseLanguage.structure.ConceptFunction\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.ConceptFunction\"}, new String[]{}, new String[]{});\n      case 2:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointDeclaration\", \"jetbrains.mps.lang.core.structure.BaseConcept\", false, new String[]{\"jetbrains.mps.lang.core.structure.BaseConcept\", \"jetbrains.mps.lang.core.structure.INamedConcept\"}, new String[]{\"extensionName\"}, new String[]{});\n      case 3:\n        return new CompiledConceptDescriptor(\"jetbrains.mps.lang.extension.structure.ExtensionPointExpression\", \"jetbrains.mps.baseLanguage.structure.Expression\", false, new String[]{\"jetbrains.mps.baseLanguage.structure.Expression\"}, new String[]{}, new String[]{\"extensionPoint\"});\n      default:\n        return StructureAspectInterpreted.getInstance().getDescriptor(conceptFqName);\n    }\n  }","commit_id":"cb0360db9e0c0089f039b513adf245c137142d39","url":"https://github.com/JetBrains/MPS"},{"original_method":"/**\n         * Create a connected list of a list of coordinates\n         * \n         * @param points\n         *            array of point\n         * @param offset\n         *            index of the first point\n         * @param length\n         *            number of points\n         * @return Array of edges\n         */\n        protected static Edge[] ring(int component, boolean direction, BaseLineStringBuilder<?> shell, Coordinate[] points, int offset, \n                Edge[] edges, int toffset, int length) {\n            // calculate the direction of the points:\n            // find the point a the top of the set and check its\n            // neighbors orientation. So direction is equivalent\n            // to clockwise/counterclockwise\n            final int top = top(points, offset, length);\n            final int prev = (offset + ((top + length - 1) % length));\n            final int next = (offset + ((top + 1) % length));\n            boolean orientation = points[offset + prev].x > points[offset + next].x;\n\n            // OGC requires shell as ccw (Right-Handedness) and holes as cw (Left-Handedness) \n            // since GeoJSON doesn't specify (and doesn't need to) GEO core will assume OGC standards\n            // thus if orientation is computed as cw, the logic will translate points across dateline\n            // and convert to a right handed system\n\n            // compute the bounding box and calculate range\n            Pair<Pair, Pair> range = range(points, offset, length);\n            final double rng = (Double)range.getLeft().getRight() - (Double)range.getLeft().getLeft();\n            // translate the points if the following is true\n            //   1.  shell orientation is cw and range is greater than a hemisphere (180 degrees) but not spanning 2 hemispheres \n            //       (translation would result in a collapsed poly)\n            //   2.  the shell of the candidate hole has been translated (to preserve the coordinate system)\n            if ((rng > DATELINE && rng != 2*DATELINE && orientation && component == 0) || (shell.translated && component != 0)) {\n                translate(points);\n                // flip the translation bit if the shell is being translated\n                if (component == 0 && !shell.translated) {\n                    shell.translated = true;\n                }\n                // correct the orientation post translation (ccw for shell, cw for holes)\n                if ((component == 0 && orientation) || (component != 0 && !orientation)) {\n                    orientation = !orientation;\n                }\n            }\n            return concat(component, direction ^ orientation, points, offset, edges, toffset, length);\n        }","id":14966,"modified_method":"/**\n         * Create a connected list of a list of coordinates\n         * \n         * @param points\n         *            array of point\n         * @param offset\n         *            index of the first point\n         * @param length\n         *            number of points\n         * @return Array of edges\n         */\n        protected static Edge[] ring(int component, boolean direction, BaseLineStringBuilder<?> shell, Coordinate[] points, int offset, \n                Edge[] edges, int toffset, int length) {\n            // calculate the direction of the points:\n            // find the point a the top of the set and check its\n            // neighbors orientation. So direction is equivalent\n            // to clockwise/counterclockwise\n            final int top = top(points, offset, length);\n            final int prev = (offset + ((top + length - 1) % length));\n            final int next = (offset + ((top + 1) % length));\n            boolean orientation = points[offset + prev].x > points[offset + next].x;\n\n            // OGC requires shell as ccw (Right-Handedness) and holes as cw (Left-Handedness) \n            // since GeoJSON doesn't specify (and doesn't need to) GEO core will assume OGC standards\n            // thus if orientation is computed as cw, the logic will translate points across dateline\n            // and convert to a right handed system\n\n            // compute the bounding box and calculate range\n            Pair<Pair, Pair> range = range(points, offset, length);\n            final double rng = (Double)range.getLeft().getRight() - (Double)range.getLeft().getLeft();\n            // translate the points if the following is true\n            //   1.  shell orientation is cw and range is greater than a hemisphere (180 degrees) but not spanning 2 hemispheres \n            //       (translation would result in a collapsed poly)\n            //   2.  the shell of the candidate hole has been translated (to preserve the coordinate system)\n            if (((component == 0 && orientation) && (rng > DATELINE && rng != 2*DATELINE))\n                    || (shell.translated && component != 0)) {\n                translate(points);\n                // flip the translation bit if the shell is being translated\n                if (component == 0) {\n                    shell.translated = true;\n                }\n                // correct the orientation post translation (ccw for shell, cw for holes)\n                if (component == 0 || (component != 0 && !orientation)) {\n                    orientation = !orientation;\n                }\n            }\n            return concat(component, direction ^ orientation, points, offset, edges, toffset, length);\n        }","commit_id":"437afd6f450cbead1fc2bb69e7d8923edd913e7d","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDateline() {\n        // view shape at https://gist.github.com/anonymous/7f1bb6d7e9cd72f5977c\n        // expect 3 polygons, 1 with a hole\n\n        // a giant c shape\n        PolygonBuilder builder = ShapeBuilder.newPolygon()\n            .point(174,0)\n            .point(-176,0)\n            .point(-176,3)\n            .point(177,3)\n            .point(177,5)\n            .point(-176,5)\n            .point(-176,8)\n            .point(174,8)\n            .point(174,0);\n\n        // 3/4 of an embedded 'c', crossing dateline once\n        builder.hole()\n            .point(175, 1)\n            .point(175, 7)\n            .point(-178, 7)\n            .point(-178, 6)\n            .point(176, 6)\n            .point(176, 2)\n            .point(179, 2)\n            .point(179,1)\n            .point(175, 1);\n\n        // embedded hole right of the dateline\n        builder.hole()\n            .point(-179, 1)\n            .point(-179, 2)\n            .point(-177, 2)\n            .point(-177,1)\n            .point(-179,1);\n\n        Shape shape = builder.close().build();\n\n        assertMultiPolygon(shape);\n    }","id":14967,"modified_method":"@Test\n    public void testDateline() {\n        // view shape at https://gist.github.com/anonymous/7f1bb6d7e9cd72f5977c\n        // expect 3 polygons, 1 with a hole\n\n        // a giant c shape\n        PolygonBuilder builder = ShapeBuilder.newPolygon()\n                .point(-186,0)\n                .point(-176,0)\n                .point(-176,3)\n                .point(-183,3)\n                .point(-183,5)\n                .point(-176,5)\n                .point(-176,8)\n                .point(-186,8)\n                .point(-186,0);\n\n        // 3/4 of an embedded 'c', crossing dateline once\n        builder.hole()\n                .point(-185,1)\n                .point(-181,1)\n                .point(-181,2)\n                .point(-184,2)\n                .point(-184,6)\n                .point(-178,6)\n                .point(-178,7)\n                .point(-185,7)\n                .point(-185,1);\n\n        // embedded hole right of the dateline\n        builder.hole()\n                .point(-179,1)\n                .point(-177,1)\n                .point(-177,2)\n                .point(-179,2)\n                .point(-179,1);\n\n        Shape shape = builder.close().build();\n\n        assertMultiPolygon(shape);\n    }","commit_id":"437afd6f450cbead1fc2bb69e7d8923edd913e7d","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private Breakpoint createBreakpoint(String category, Element breakpointNode) throws InvalidDataException {\n    if (category.equals(LineBreakpoint.CATEGORY.toString())) {\n      XLineBreakpoint xBreakpoint = createXLineBreakpoint(JavaLineBreakpointType.class, breakpointNode);\n      return LineBreakpoint.create(myProject, xBreakpoint);\n    }\n    else if (category.equals(MethodBreakpoint.CATEGORY.toString())) {\n      XLineBreakpoint xBreakpoint =  createXLineBreakpoint(JavaMethodBreakpointType.class, breakpointNode);\n      return MethodBreakpoint.create(myProject, xBreakpoint);\n    }\n    else if (category.equals(FieldBreakpoint.CATEGORY.toString())) {\n      XLineBreakpoint xBreakpoint =  createXLineBreakpoint(JavaFieldBreakpointType.class, breakpointNode);\n      return FieldBreakpoint.create(myProject, \"\", xBreakpoint);\n    }\n    else if (category.equals(ExceptionBreakpoint.CATEGORY.toString())) {\n      XBreakpoint xBreakpoint =  createXBreakpoint(JavaExceptionBreakpointType.class, breakpointNode);\n      return new ExceptionBreakpoint(myProject, xBreakpoint);\n    }\n    throw new IllegalStateException(\"Unknown breakpoint category \" + category);\n  }","id":14968,"modified_method":"private Breakpoint createBreakpoint(String category, Element breakpointNode) throws InvalidDataException {\n    XBreakpoint xBreakpoint = null;\n    if (category.equals(LineBreakpoint.CATEGORY.toString())) {\n      xBreakpoint = createXLineBreakpoint(JavaLineBreakpointType.class, breakpointNode);\n    }\n    else if (category.equals(MethodBreakpoint.CATEGORY.toString())) {\n      if (breakpointNode.getAttribute(\"url\") != null) {\n        xBreakpoint = createXLineBreakpoint(JavaMethodBreakpointType.class, breakpointNode);\n      }\n      else {\n        xBreakpoint = createXBreakpoint(JavaWildcardMethodBreakpointType.class, breakpointNode);\n      }\n    }\n    else if (category.equals(FieldBreakpoint.CATEGORY.toString())) {\n      xBreakpoint = createXLineBreakpoint(JavaFieldBreakpointType.class, breakpointNode);\n    }\n    else if (category.equals(ExceptionBreakpoint.CATEGORY.toString())) {\n      xBreakpoint =  createXBreakpoint(JavaExceptionBreakpointType.class, breakpointNode);\n    }\n    if (xBreakpoint == null) {\n      throw new IllegalStateException(\"Unknown breakpoint category \" + category);\n    }\n    return myBreakpoints.get(xBreakpoint);\n  }","commit_id":"c4ee509dec8d3962e3999c22bffdbdc66e93a89b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void doRead(@NotNull final Element parentNode) {\n    ApplicationManager.getApplication().runReadAction(new Runnable() {\n      @Override\n      @SuppressWarnings({\"HardCodedStringLiteral\"})\n      public void run() {\n        final Map<String, Breakpoint> nameToBreakpointMap = new THashMap<String, Breakpoint>();\n        try {\n          final List groups = parentNode.getChildren();\n          for (final Object group1 : groups) {\n            final Element group = (Element)group1;\n            if (group.getName().equals(RULES_GROUP_NAME)) {\n              continue;\n            }\n            // skip already converted\n            if (group.getAttribute(CONVERTED_PARAM) != null) {\n              continue;\n            }\n            final String categoryName = group.getName();\n            final Key<Breakpoint> breakpointCategory = BreakpointCategory.lookup(categoryName);\n            final String defaultPolicy = group.getAttributeValue(DEFAULT_SUSPEND_POLICY_ATTRIBUTE_NAME);\n            final boolean conditionEnabled = Boolean.parseBoolean(group.getAttributeValue(DEFAULT_CONDITION_STATE_ATTRIBUTE_NAME, \"true\"));\n            setBreakpointDefaults(breakpointCategory, new BreakpointDefaults(defaultPolicy, conditionEnabled));\n            Element anyExceptionBreakpointGroup;\n            if (!AnyExceptionBreakpoint.ANY_EXCEPTION_BREAKPOINT.equals(breakpointCategory)) {\n              // for compatibility with previous format\n              anyExceptionBreakpointGroup = group.getChild(AnyExceptionBreakpoint.ANY_EXCEPTION_BREAKPOINT.toString());\n              //final BreakpointFactory factory = BreakpointFactory.getInstance(breakpointCategory);\n              //if (factory != null) {\n                for (Element breakpointNode : group.getChildren(\"breakpoint\")) {\n                  //Breakpoint breakpoint = factory.createBreakpoint(myProject, breakpointNode);\n                  Breakpoint breakpoint = createBreakpoint(categoryName, breakpointNode);\n                  breakpoint.readExternal(breakpointNode);\n                  addBreakpoint(breakpoint);\n                  nameToBreakpointMap.put(breakpoint.getDisplayName(), breakpoint);\n                }\n              //}\n            }\n            else {\n              anyExceptionBreakpointGroup = group;\n            }\n\n            if (anyExceptionBreakpointGroup != null) {\n              final Element breakpointElement = group.getChild(\"breakpoint\");\n              if (breakpointElement != null) {\n                XBreakpointManager manager = XDebuggerManager.getInstance(myProject).getBreakpointManager();\n                JavaExceptionBreakpointType type = (JavaExceptionBreakpointType)XDebuggerUtil.getInstance().findBreakpointType(JavaExceptionBreakpointType.class);\n                XBreakpoint<JavaExceptionBreakpointProperties> xBreakpoint = manager.getDefaultBreakpoint(type);\n                Breakpoint breakpoint = createJavaBreakpoint(xBreakpoint);\n                breakpoint.readExternal(breakpointElement);\n                addBreakpoint(breakpoint);\n              }\n            }\n          }\n        }\n        catch (InvalidDataException ignored) {\n        }\n\n        final Element rulesGroup = parentNode.getChild(RULES_GROUP_NAME);\n        if (rulesGroup != null) {\n          final List<Element> rules = rulesGroup.getChildren(\"rule\");\n          for (Element rule : rules) {\n            // skip already converted\n            if (rule.getAttribute(CONVERTED_PARAM) != null) {\n              continue;\n            }\n            final Element master = rule.getChild(MASTER_BREAKPOINT_TAGNAME);\n            if (master == null) {\n              continue;\n            }\n            final Element slave = rule.getChild(SLAVE_BREAKPOINT_TAGNAME);\n            if (slave == null) {\n              continue;\n            }\n            final Breakpoint masterBreakpoint = nameToBreakpointMap.get(master.getAttributeValue(\"name\"));\n            if (masterBreakpoint == null) {\n              continue;\n            }\n            final Breakpoint slaveBreakpoint = nameToBreakpointMap.get(slave.getAttributeValue(\"name\"));\n            if (slaveBreakpoint == null) {\n              continue;\n            }\n\n            boolean leaveEnabled = \"true\".equalsIgnoreCase(rule.getAttributeValue(\"leaveEnabled\"));\n            XDependentBreakpointManager dependentBreakpointManager = ((XBreakpointManagerImpl)getXBreakpointManager()).getDependentBreakpointManager();\n            dependentBreakpointManager.setMasterBreakpoint(slaveBreakpoint.myXBreakpoint, masterBreakpoint.myXBreakpoint, leaveEnabled);\n            //addBreakpointRule(new EnableBreakpointRule(BreakpointManager.this, masterBreakpoint, slaveBreakpoint, leaveEnabled));\n          }\n        }\n\n        DebuggerInvocationUtil.invokeLater(myProject, new Runnable() {\n          @Override\n          public void run() {\n            updateBreakpointsUI();\n          }\n        });\n      }\n    });\n\n    myUIProperties.clear();\n    final Element props = parentNode.getChild(\"ui_properties\");\n    if (props != null) {\n      final List children = props.getChildren(\"property\");\n      for (Object child : children) {\n        Element property = (Element)child;\n        final String name = property.getAttributeValue(\"name\");\n        final String value = property.getAttributeValue(\"value\");\n        if (name != null && value != null) {\n          myUIProperties.put(name, value);\n        }\n      }\n    }\n  }","id":14969,"modified_method":"private void doRead(@NotNull final Element parentNode) {\n    ApplicationManager.getApplication().runReadAction(new Runnable() {\n      @Override\n      @SuppressWarnings({\"HardCodedStringLiteral\"})\n      public void run() {\n        final Map<String, Breakpoint> nameToBreakpointMap = new THashMap<String, Breakpoint>();\n        try {\n          final List groups = parentNode.getChildren();\n          for (final Object group1 : groups) {\n            final Element group = (Element)group1;\n            if (group.getName().equals(RULES_GROUP_NAME)) {\n              continue;\n            }\n            // skip already converted\n            if (group.getAttribute(CONVERTED_PARAM) != null) {\n              continue;\n            }\n            final String categoryName = group.getName();\n            final Key<Breakpoint> breakpointCategory = BreakpointCategory.lookup(categoryName);\n            final String defaultPolicy = group.getAttributeValue(DEFAULT_SUSPEND_POLICY_ATTRIBUTE_NAME);\n            final boolean conditionEnabled = Boolean.parseBoolean(group.getAttributeValue(DEFAULT_CONDITION_STATE_ATTRIBUTE_NAME, \"true\"));\n            setBreakpointDefaults(breakpointCategory, new BreakpointDefaults(defaultPolicy, conditionEnabled));\n            Element anyExceptionBreakpointGroup;\n            if (!AnyExceptionBreakpoint.ANY_EXCEPTION_BREAKPOINT.equals(breakpointCategory)) {\n              // for compatibility with previous format\n              anyExceptionBreakpointGroup = group.getChild(AnyExceptionBreakpoint.ANY_EXCEPTION_BREAKPOINT.toString());\n              //final BreakpointFactory factory = BreakpointFactory.getInstance(breakpointCategory);\n              //if (factory != null) {\n                for (Element breakpointNode : group.getChildren(\"breakpoint\")) {\n                  //Breakpoint breakpoint = factory.createBreakpoint(myProject, breakpointNode);\n                  Breakpoint breakpoint = createBreakpoint(categoryName, breakpointNode);\n                  breakpoint.readExternal(breakpointNode);\n                  nameToBreakpointMap.put(breakpoint.getDisplayName(), breakpoint);\n                }\n              //}\n            }\n            else {\n              anyExceptionBreakpointGroup = group;\n            }\n\n            if (anyExceptionBreakpointGroup != null) {\n              final Element breakpointElement = group.getChild(\"breakpoint\");\n              if (breakpointElement != null) {\n                XBreakpointManager manager = XDebuggerManager.getInstance(myProject).getBreakpointManager();\n                JavaExceptionBreakpointType type = (JavaExceptionBreakpointType)XDebuggerUtil.getInstance().findBreakpointType(JavaExceptionBreakpointType.class);\n                XBreakpoint<JavaExceptionBreakpointProperties> xBreakpoint = manager.getDefaultBreakpoint(type);\n                Breakpoint breakpoint = createJavaBreakpoint(xBreakpoint);\n                breakpoint.readExternal(breakpointElement);\n                addBreakpoint(breakpoint);\n              }\n            }\n          }\n        }\n        catch (InvalidDataException ignored) {\n        }\n\n        final Element rulesGroup = parentNode.getChild(RULES_GROUP_NAME);\n        if (rulesGroup != null) {\n          final List<Element> rules = rulesGroup.getChildren(\"rule\");\n          for (Element rule : rules) {\n            // skip already converted\n            if (rule.getAttribute(CONVERTED_PARAM) != null) {\n              continue;\n            }\n            final Element master = rule.getChild(MASTER_BREAKPOINT_TAGNAME);\n            if (master == null) {\n              continue;\n            }\n            final Element slave = rule.getChild(SLAVE_BREAKPOINT_TAGNAME);\n            if (slave == null) {\n              continue;\n            }\n            final Breakpoint masterBreakpoint = nameToBreakpointMap.get(master.getAttributeValue(\"name\"));\n            if (masterBreakpoint == null) {\n              continue;\n            }\n            final Breakpoint slaveBreakpoint = nameToBreakpointMap.get(slave.getAttributeValue(\"name\"));\n            if (slaveBreakpoint == null) {\n              continue;\n            }\n\n            boolean leaveEnabled = \"true\".equalsIgnoreCase(rule.getAttributeValue(\"leaveEnabled\"));\n            XDependentBreakpointManager dependentBreakpointManager = ((XBreakpointManagerImpl)getXBreakpointManager()).getDependentBreakpointManager();\n            dependentBreakpointManager.setMasterBreakpoint(slaveBreakpoint.myXBreakpoint, masterBreakpoint.myXBreakpoint, leaveEnabled);\n            //addBreakpointRule(new EnableBreakpointRule(BreakpointManager.this, masterBreakpoint, slaveBreakpoint, leaveEnabled));\n          }\n        }\n\n        DebuggerInvocationUtil.invokeLater(myProject, new Runnable() {\n          @Override\n          public void run() {\n            updateBreakpointsUI();\n          }\n        });\n      }\n    });\n\n    myUIProperties.clear();\n    final Element props = parentNode.getChild(\"ui_properties\");\n    if (props != null) {\n      final List children = props.getChildren(\"property\");\n      for (Object child : children) {\n        Element property = (Element)child;\n        final String name = property.getAttributeValue(\"name\");\n        final String value = property.getAttributeValue(\"value\");\n        if (name != null && value != null) {\n          myUIProperties.put(name, value);\n        }\n      }\n    }\n  }","commit_id":"c4ee509dec8d3962e3999c22bffdbdc66e93a89b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean checkAppliedCorrectly_generic(SNode op) {\n    List<String> applicables = new ArrayList<String>();\n    // ===========\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_model\")) {\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_46().createNode())) {\n        return true;\n      }\n      applicables.add(\"model\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_concept\")) {\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_47().createNode())) {\n        return true;\n      }\n      applicables.add(\"concept\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_node\")) {\n      // todo: get type of left expression and try to 'adapt' to snode\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_48().createNode())) {\n        return true;\n      }\n      applicables.add(\"node\");\n    }\n    // ===========\n    SNode leftExpression = RulesUtil.leftExpression(op);\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_link\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SLinkAccess\")) {\n        return true;\n      }\n      applicables.add(\"link-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_linkList\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SLinkListAccess\")) {\n        return true;\n      }\n      applicables.add(\"link-list-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_simple_property\")) {\n      // ???\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_concept_property\")) {\n      // ???\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_enum_property\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SPropertyAccess\")) {\n        SNode propertyDecl = SLinkOperations.getTarget(leftOp, \"property\", false);\n        if(DataTypeUtil.isEnum(((DataTypeDeclaration)SNodeOperations.getAdapter(SLinkOperations.getTarget(propertyDecl, \"dataType\", false))))) {\n          return true;\n        }\n      }\n      applicables.add(\"enum-property-access\");\n    }\n    // ===========\n    String applicableTo = \"\";\n    Iterator<String> iter = applicables.iterator();\n    while(iter.hasNext()) {\n      applicableTo = applicableTo + iter.next();\n      if(iter.hasNext()) {\n        applicableTo = applicableTo + \",\";\n      }\n    }\n    TypeChecker.getInstance().reportTypeError(op, \"operation is only applicable to \" + applicableTo);\n    return false;\n  }","id":14970,"modified_method":"public static boolean checkAppliedCorrectly_generic(SNode op) {\n    List<String> applicables = new ArrayList<String>();\n    // ===========\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_model\")) {\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_46().createNode())) {\n        return true;\n      }\n      applicables.add(\"model\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_concept\")) {\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_47().createNode())) {\n        return true;\n      }\n      applicables.add(\"concept\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_node\")) {\n      // todo: get type of left expression and try to 'adapt' to snode\n      SNode leftType = RulesUtil.typeOf_leftExpression(op);\n      if(TypeChecker.getInstance().getSubtypingManager().isSubtype(leftType, new QuotationClass_48().createNode())) {\n        return true;\n      }\n      applicables.add(\"node\");\n    }\n    // ===========\n    SNode leftExpression = RulesUtil.leftExpression(op);\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_link\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SLinkAccess\")) {\n        return true;\n      }\n      applicables.add(\"link-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_linkList\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SLinkListAccess\")) {\n        return true;\n      }\n      applicables.add(\"link-list-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_simple_property\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SPropertyAccess\")) {\n        SNode propertyDecl = SLinkOperations.getTarget(leftOp, \"property\", false);\n        if(DataTypeUtil.isSimple(((DataTypeDeclaration)SNodeOperations.getAdapter(SLinkOperations.getTarget(propertyDecl, \"dataType\", false))))) {\n          return true;\n        }\n      }\n      applicables.add(\"simple-property-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_enum_property\")) {\n      SNode leftOp = SLinkOperations.getTarget(leftExpression, \"nodeOperation\", true);\n      if(SConceptOperations.isExactly(SNodeOperations.getConceptDeclaration(leftOp), \"jetbrains.mps.bootstrap.smodelLanguage.structure.SPropertyAccess\")) {\n        SNode propertyDecl = SLinkOperations.getTarget(leftOp, \"property\", false);\n        if(DataTypeUtil.isEnum(((DataTypeDeclaration)SNodeOperations.getAdapter(SLinkOperations.getTarget(propertyDecl, \"dataType\", false))))) {\n          return true;\n        }\n      }\n      applicables.add(\"enum-property-access\");\n    }\n    if(SConceptPropertyOperations.getBoolean(op, \"applicable_to_concept_property\")) {\n      // ???\n    }\n    // ===========\n    String applicableTo = \"\";\n    Iterator<String> iter = applicables.iterator();\n    while(iter.hasNext()) {\n      applicableTo = applicableTo + iter.next();\n      if(iter.hasNext()) {\n        applicableTo = applicableTo + \",\";\n      }\n    }\n    TypeChecker.getInstance().reportTypeError(op, \"operation is only applicable to \" + applicableTo);\n    return false;\n  }","commit_id":"1470f57f71fd44b053871c4314e9cba4a3f315b4","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void applyRule(SNode argument) {\n    if(!((Boolean)Queries.CustomExpression_check_isAppliedTo_SPropertyAccess_simpleProperty(argument))) {\n      TypeChecker.getInstance().reportTypeError(argument, \"\\\"'has value (simple)' is not expected here\\\"\");\n    }\n    if(!((SLinkOperations.getTarget(argument, \"value\", true) == null))) {\n      TypeChecker.getInstance().getRuntimeSupport().check(SLinkOperations.getTarget(argument, \"value\", true));\n      if((Boolean)Queries.CustomExpression_check_isAppliedTo_SPropertyAccess_simpleStringProperty(argument)) {\n        if(!(TypeChecker.getInstance().getSubtypingManager().isSubtype(TypeChecker.getInstance().getRuntimeSupport().typeOf(SLinkOperations.getTarget(argument, \"value\", true)), new QuotationClass_5().createNode()))) {\n          TypeChecker.getInstance().reportTypeError(SLinkOperations.getTarget(argument, \"value\", true), \"java.lang.String is expected\");\n        }\n      }\n      if((Boolean)Queries.CustomExpression_check_isAppliedTo_SPropertyAccess_simpleIntegerProperty(argument)) {\n        if(!(TypeChecker.getInstance().getSubtypingManager().isSubtype(TypeChecker.getInstance().getRuntimeSupport().typeOf(SLinkOperations.getTarget(argument, \"value\", true)), new QuotationClass_6().createNode()))) {\n          TypeChecker.getInstance().reportTypeError(SLinkOperations.getTarget(argument, \"value\", true), \"integer is expected\");\n        }\n      }\n      if((Boolean)Queries.CustomExpression_check_isAppliedTo_SPropertyAccess_simpleBooleanProperty(argument)) {\n        if(!(TypeChecker.getInstance().getSubtypingManager().isSubtype(TypeChecker.getInstance().getRuntimeSupport().typeOf(SLinkOperations.getTarget(argument, \"value\", true)), new QuotationClass_7().createNode()))) {\n          TypeChecker.getInstance().reportTypeError(SLinkOperations.getTarget(argument, \"value\", true), \"boolean is expected\");\n        }\n      }\n    }\n    TypeChecker.getInstance().getRuntimeSupport().givetype(new QuotationClass_8().createNode(), argument);\n  }","id":14971,"modified_method":"public void applyRule(SNode argument) {\n    if(RulesUtil.checkAppliedCorrectly_generic(argument)) {\n      SNode propertyAccessOp = SLinkOperations.getTarget(RulesUtil.leftExpression(argument), \"nodeOperation\", true);\n      SNode dataType = SLinkOperations.getTarget(SLinkOperations.getTarget(propertyAccessOp, \"property\", false), \"dataType\", false);\n      if(!((dataType != null))) {\n        TypeChecker.getInstance().reportTypeError(argument, \"couldn't define accessed property datatype\");\n      }\n      SNode value = SLinkOperations.getTarget(argument, \"value\", true);\n      if((value != null)) {\n        if(DataTypeUtil.isSimpleString(((DataTypeDeclaration)SNodeOperations.getAdapter(dataType)))) {\n          TypeChecker.getInstance().getRuntimeSupport().createLessThanInequation(TypeChecker.getInstance().getRuntimeSupport().typeOf(value), new QuotationClass_5().createNode(), value);\n        } else \n        if(DataTypeUtil.isSimpleInteger(((DataTypeDeclaration)SNodeOperations.getAdapter(dataType)))) {\n          TypeChecker.getInstance().getRuntimeSupport().createLessThanInequation(TypeChecker.getInstance().getRuntimeSupport().typeOf(value), new QuotationClass_6().createNode(), value);\n        } else \n        if(DataTypeUtil.isSimpleBoolean(((DataTypeDeclaration)SNodeOperations.getAdapter(dataType)))) {\n          TypeChecker.getInstance().getRuntimeSupport().createLessThanInequation(TypeChecker.getInstance().getRuntimeSupport().typeOf(value), new QuotationClass_7().createNode(), value);\n        } else \n        {\n          TypeChecker.getInstance().reportTypeError(argument, \"unknown property datatype: \" + dataType);\n        }\n      }\n    }\n    TypeChecker.getInstance().getRuntimeSupport().givetype(new QuotationClass_8().createNode(), argument);\n  }","commit_id":"1470f57f71fd44b053871c4314e9cba4a3f315b4","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Test\n    public void testMapRemove_WithNearCache() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        final int size = 1113;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        for (int i = 0; i < size; i++) {\n            map.remove(i);\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getMisses());\n        assertEquals(0, stats.getOwnedEntryCount());\n    }","id":14972,"modified_method":"@Test\n    public void testMapRemove_WithNearCache() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n\n        final int size = 1113;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        for (int i = 0; i < size; i++) {\n            map.remove(i);\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getMisses());\n        assertEquals(0, stats.getOwnedEntryCount());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testIssue2009() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertNotNull(stats);\n    }","id":14973,"modified_method":"@Test\n    public void testIssue2009() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertNotNull(stats);\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test(expected = NullPointerException.class)\n    public void testNearCacheContainsNullKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        map.containsKey(null);\n    }","id":14974,"modified_method":"@Test(expected = NullPointerException.class)\n    public void testNearCacheContainsNullKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n        map.containsKey(null);\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCacheContainsKey_afterRemove() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        final Object key = \"key\";\n\n        map.put(key, \"value\");\n        map.get(key);\n        map.remove(key);\n\n        assertFalse(map.containsKey(key));\n    }","id":14975,"modified_method":"@Test\n    public void testNearCacheContainsKey_afterRemove() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n        final Object key = \"key\";\n\n        map.put(key, \"value\");\n        map.get(key);\n        map.remove(key);\n\n        assertFalse(map.containsKey(key));\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testGetAllChecksNearCacheFirst() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        final HashSet keys = new HashSet();\n\n        final int size = 1003;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            keys.add(i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        //getAll generates the near cache hits\n        map.getAll(keys);\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","id":14976,"modified_method":"@Test\n    public void testGetAllChecksNearCacheFirst() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_NO_INVALIDATION));\n        final HashSet keys = new HashSet();\n\n        final int size = 1003;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            keys.add(i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        //getAll generates the near cache hits\n        map.getAll(keys);\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testRemovedKeyValueNotInNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        int size = 1247;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n\n        for (int i = 0; i < size; i++) {\n            map.remove(i);\n            assertNull(map.get(i));\n        }\n    }","id":14977,"modified_method":"@Test\n    public void testRemovedKeyValueNotInNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n\n        int size = 1247;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n\n        for (int i = 0; i < size; i++) {\n            map.remove(i);\n            assertNull(map.get(i));\n        }\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testGetAllPopulatesNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        final HashSet keys = new HashSet();\n\n        final int size = 1214;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            keys.add(i);\n        }\n        //getAll populates near cache\n        map.getAll(keys);\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n    }","id":14978,"modified_method":"@Test\n    public void testGetAllPopulatesNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_NO_INVALIDATION));\n        final HashSet keys = new HashSet();\n\n        final int size = 1214;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            keys.add(i);\n        }\n        //getAll populates near cache\n        map.getAll(keys);\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCacheContainsKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n        final Object key = \"key\";\n\n        map.put(key, \"value\");\n        map.get(key);\n\n        assertTrue(map.containsKey(key));\n    }","id":14979,"modified_method":"@Test\n    public void testNearCacheContainsKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n        final Object key = \"key\";\n\n        map.put(key, \"value\");\n        map.get(key);\n\n        assertTrue(map.containsKey(key));\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCacheFasterThanGoingToTheCluster() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        final int size = 2007;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n\n        long begin = System.currentTimeMillis();\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        long readFromClusterTime = System.currentTimeMillis() - begin;\n\n        begin = System.currentTimeMillis();\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        long readFromCacheTime = System.currentTimeMillis() - begin;\n\n        assertTrue(\"readFromCacheTime > readFromClusterTime\", readFromCacheTime < readFromClusterTime);\n    }","id":14980,"modified_method":"@Test\n    public void testNearCacheFasterThanGoingToTheCluster() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n\n        final int size = 2007;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n\n        long begin = System.currentTimeMillis();\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        long readFromClusterTime = System.currentTimeMillis() - begin;\n\n        begin = System.currentTimeMillis();\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        long readFromCacheTime = System.currentTimeMillis() - begin;\n\n        assertTrue(\"readFromCacheTime > readFromClusterTime\", readFromCacheTime < readFromClusterTime);\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCacheContainsKey_whenKeyAbsent() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        assertFalse(map.containsKey(\"NOT_THERE\"));\n    }","id":14981,"modified_method":"@Test\n    public void testNearCacheContainsKey_whenKeyAbsent() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n\n        assertFalse(map.containsKey(\"NOT_THERE\"));\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testGetAsync() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        int size = 1009;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        //generate near cache hits with async call\n        for (int i = 0; i < size; i++) {\n            Future async = map.getAsync(i);\n            async.get();\n        }\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","id":14982,"modified_method":"@Test\n    public void testGetAsync() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_NO_INVALIDATION));\n\n        int size = 1009;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        //generate near cache hits with async call\n        for (int i = 0; i < size; i++) {\n            Future async = map.getAsync(i);\n            async.get();\n        }\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@BeforeClass\n    public static void setup() throws Exception {\n        h1 = Hazelcast.newHazelcastInstance();\n        h2 = Hazelcast.newHazelcastInstance();\n\n        ClientConfig clientConfig = new ClientConfig();\n\n        NearCacheConfig basicConfig = new NearCacheConfig();\n        basicConfig.setInMemoryFormat(InMemoryFormat.OBJECT);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_DEFAULT_CONFIG + \"*\", basicConfig);\n\n        NearCacheConfig basicConfigNoInvalidation = new NearCacheConfig();\n        basicConfig.setInMemoryFormat(InMemoryFormat.OBJECT);\n        basicConfigNoInvalidation.setInvalidateOnChange(false);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_NO_INVALIDATION + \"*\", basicConfigNoInvalidation);\n\n        NearCacheConfig maxSizeConfig = new NearCacheConfig();\n        maxSizeConfig.setMaxSize(MAX_CACHE_SIZE);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_MAX_SIZE + \"*\", maxSizeConfig);\n\n        NearCacheConfig ttlConfig = new NearCacheConfig();\n        ttlConfig.setTimeToLiveSeconds(MAX_TTL_SECONDS);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_TTL + \"*\", ttlConfig);\n\n        NearCacheConfig idleConfig = new NearCacheConfig();\n        idleConfig.setMaxIdleSeconds(MAX_IDLE_SECONDS);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_IDLE + \"*\", idleConfig);\n\n        NearCacheConfig invalidateConfig = new NearCacheConfig();\n        invalidateConfig.setInvalidateOnChange(true);\n        clientConfig.addNearCacheConfig(NEAR_CACHE_WITH_INVALIDATION + \"*\", invalidateConfig);\n\n        client = HazelcastClient.newHazelcastClient(clientConfig);\n    }","id":14983,"modified_method":"@BeforeClass\n    public static void setup() throws Exception {\n        h1 = Hazelcast.newHazelcastInstance();\n        h2 = Hazelcast.newHazelcastInstance();\n\n        ClientConfig clientConfig = new ClientConfig();\n\n        NearCacheConfig basicConfigNoInvalidation = new NearCacheConfig();\n        basicConfigNoInvalidation.setInMemoryFormat(InMemoryFormat.OBJECT);\n        basicConfigNoInvalidation.setName(NEAR_CACHE_WITH_NO_INVALIDATION + \"*\");\n        basicConfigNoInvalidation.setInvalidateOnChange(false);\n        clientConfig.addNearCacheConfig(basicConfigNoInvalidation);\n\n        NearCacheConfig maxSizeConfig = new NearCacheConfig();\n        maxSizeConfig.setMaxSize(MAX_CACHE_SIZE);\n        maxSizeConfig.setInvalidateOnChange(false);\n        maxSizeConfig.setName(NEAR_CACHE_WITH_MAX_SIZE + \"*\");\n        clientConfig.addNearCacheConfig(maxSizeConfig);\n\n        NearCacheConfig ttlConfig = new NearCacheConfig();\n        ttlConfig.setName(NEAR_CACHE_WITH_TTL + \"*\");\n        ttlConfig.setInvalidateOnChange(false);\n        ttlConfig.setTimeToLiveSeconds(MAX_TTL_SECONDS);\n        clientConfig.addNearCacheConfig(ttlConfig);\n\n        NearCacheConfig idleConfig = new NearCacheConfig();\n        idleConfig.setName(NEAR_CACHE_WITH_IDLE + \"*\");\n        idleConfig.setInvalidateOnChange(false);\n        idleConfig.setMaxIdleSeconds(MAX_IDLE_SECONDS);\n        clientConfig.addNearCacheConfig(idleConfig);\n\n        NearCacheConfig invalidateConfig = new NearCacheConfig();\n        invalidateConfig.setName(NEAR_CACHE_WITH_INVALIDATION + \"*\");\n        invalidateConfig.setInvalidateOnChange(true);\n        clientConfig.addNearCacheConfig(invalidateConfig);\n\n        client = HazelcastClient.newHazelcastClient(clientConfig);\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testGetAsyncPopulatesNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        int size = 1239;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            Future async = map.getAsync(i);\n            async.get();\n        }\n        //generate near cache hits with async call\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","id":14984,"modified_method":"@Test\n    public void testGetAsyncPopulatesNearCache() throws Exception {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_NO_INVALIDATION));\n\n        int size = 1239;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n        }\n        //populate near cache\n        for (int i = 0; i < size; i++) {\n            Future async = map.getAsync(i);\n            async.get();\n        }\n        //generate near cache hits with async call\n        for (int i = 0; i < size; i++) {\n            map.get(i);\n        }\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCacheMisses_whenRepeatedOnSameKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_DEFAULT_CONFIG));\n\n        final int size = 17;\n        for (int i = 0; i < size; i++) {\n            map.get(\"NOT_THERE\");\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(1, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getMisses());\n    }","id":14985,"modified_method":"@Test\n    public void testNearCacheMisses_whenRepeatedOnSameKey() {\n        final IMap map = client.getMap(randomMapName(NEAR_CACHE_WITH_INVALIDATION));\n\n        final int size = 17;\n        for (int i = 0; i < size; i++) {\n            map.get(\"NOT_THERE\");\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        assertEquals(1, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getMisses());\n    }","commit_id":"dec0b7d163923910475a209bea5070a383c425d6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Test\n    public void testNearCachePopulatedAndHitsGenerated() throws Exception {\n        final IMap map = client.getMap(mapWithInvalidateCash + randomString());\n\n        final int size = 1278;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            map.get(i);  //populate near cache\n            map.get(i);  //generate near cache hits\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        System.out.println(\"stats = \" + stats);\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","id":14986,"modified_method":"@Test\n    public void testNearCachePopulatedAndHitsGenerated() throws Exception {\n        final IMap map = client.getMap(mapWithBasicCash + randomString());\n\n        final int size = 1278;\n        for (int i = 0; i < size; i++) {\n            map.put(i, i);\n            map.get(i);  //populate near cache\n            map.get(i);  //generate near cache hits\n        }\n\n        NearCacheStats stats = map.getLocalMapStats().getNearCacheStats();\n        System.out.println(\"stats = \" + stats);\n        assertEquals(size, stats.getOwnedEntryCount());\n        assertEquals(size, stats.getHits());\n    }","commit_id":"81a50f3e3ac32a6e7e47da993fef3bd6bc129e35","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@BeforeClass\n    public static void setup() throws Exception {\n        h1 = Hazelcast.newHazelcastInstance();\n        h2 = Hazelcast.newHazelcastInstance();\n\n        ClientConfig clientConfig = new ClientConfig();\n\n        NearCacheConfig basicConfig = new NearCacheConfig();\n        basicConfig.setInMemoryFormat(InMemoryFormat.OBJECT);\n        clientConfig.addNearCacheConfig(mapWithBasicCash + \"*\", basicConfig);\n\n        NearCacheConfig maxSizeConfig = new NearCacheConfig();\n        maxSizeConfig.setMaxSize(MAX_CACHE_SIZE);\n        clientConfig.addNearCacheConfig(mapWithMaxSizeCash + \"*\", maxSizeConfig);\n\n        NearCacheConfig ttlConfig = new NearCacheConfig();\n        ttlConfig.setTimeToLiveSeconds(MAX_TTL_SECONDS);\n        clientConfig.addNearCacheConfig(mapWithTTLCash + \"*\", ttlConfig);\n\n        NearCacheConfig idleConfig = new NearCacheConfig();\n        idleConfig.setMaxIdleSeconds(MAX_IDLE_SECONDS);\n        clientConfig.addNearCacheConfig(mapWithIdleCash + \"*\", idleConfig);\n\n        NearCacheConfig invalidateConfig = new NearCacheConfig();\n        invalidateConfig.setInvalidateOnChange(true);\n        clientConfig.addNearCacheConfig(mapWithInvalidateCash + \"*\", invalidateConfig);\n\n        client = HazelcastClient.newHazelcastClient(clientConfig);\n    }","id":14987,"modified_method":"@BeforeClass\n    public static void setup() throws Exception {\n        h1 = Hazelcast.newHazelcastInstance();\n        h2 = Hazelcast.newHazelcastInstance();\n\n        ClientConfig clientConfig = new ClientConfig();\n\n        NearCacheConfig basicConfig = new NearCacheConfig();\n        basicConfig.setName(mapWithBasicCash + \"*\");\n        basicConfig.setInvalidateOnChange(false);\n        basicConfig.setInMemoryFormat(InMemoryFormat.OBJECT);\n        clientConfig.addNearCacheConfig(basicConfig);\n\n        NearCacheConfig maxSizeConfig = new NearCacheConfig();\n        maxSizeConfig.setName(mapWithMaxSizeCash + \"*\");\n        maxSizeConfig.setInvalidateOnChange(false);\n        maxSizeConfig.setMaxSize(MAX_CACHE_SIZE);\n        clientConfig.addNearCacheConfig(maxSizeConfig);\n\n        NearCacheConfig ttlConfig = new NearCacheConfig();\n        ttlConfig.setName(mapWithTTLCash + \"*\");\n        ttlConfig.setInvalidateOnChange(false);\n        ttlConfig.setTimeToLiveSeconds(MAX_TTL_SECONDS);\n        clientConfig.addNearCacheConfig(ttlConfig);\n\n        NearCacheConfig idleConfig = new NearCacheConfig();\n        idleConfig.setName(mapWithIdleCash + \"*\");\n        idleConfig.setInvalidateOnChange(false);\n        idleConfig.setMaxIdleSeconds(MAX_IDLE_SECONDS);\n        clientConfig.addNearCacheConfig(idleConfig);\n\n        NearCacheConfig invalidateConfig = new NearCacheConfig();\n        invalidateConfig.setName(mapWithInvalidateCash + \"*\");\n        invalidateConfig.setInvalidateOnChange(true);\n        clientConfig.addNearCacheConfig(invalidateConfig);\n\n        client = HazelcastClient.newHazelcastClient(clientConfig);\n    }","commit_id":"81a50f3e3ac32a6e7e47da993fef3bd6bc129e35","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"/**\n     * Closes all the open DB Connections for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC Connections for\n     */\n    private static void closeAllConnections(XQueryContext xqueryContext) {\n        // get the existing Connections map from the context\n        Map<Long, FTPClient> connections = ModuleUtils.retrieveContextMap(xqueryContext, FTPClientModule.CONNECTIONS_CONTEXTVAR);\n\n        if(connections != null) {\n\n            // iterate over each Connection\n            for(Entry<Long, FTPClient> entry : connections.entrySet()) {\n                Long conID = entry.getKey();\n                FTPClient con = entry.getValue();\n                \n                try {\n                    // close the Connection\n                    con.logout();\n                } catch(IOException ioe) {\n                    log.error(ioe.getMessage(), ioe);\n                } finally {\n                    if(con.isConnected()) {\n                        try {\n                            con.disconnect();\n                        } catch(IOException ioe) {\n                            log.error(ioe.getMessage(), ioe);\n                        }\n                    }\n                }\n            }\n\n            //empty the map\n            connections.clear();\n\n            // update the context\n            ModuleUtils.storeContextMap(xqueryContext, FTPClientModule.CONNECTIONS_CONTEXTVAR, connections);\n        }\n    }","id":14988,"modified_method":"/**\n     * Closes all the open DB Connections for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC Connections for\n     */\n    private static void closeAllConnections(XQueryContext xqueryContext) {\n        \n        ModuleUtils.modifyContextMap(xqueryContext, FTPClientModule.CONNECTIONS_CONTEXTVAR, new ContextMapEntryModifier<FTPClient>(){\n            \n            @Override \n            public void modify(Map<Long, FTPClient> map) {\n                super.modify(map);\n                \n                //empty the map\n                map.clear();\n            }\n            \n            @Override\n            public void modify(Entry<Long, FTPClient> entry) {\n            \n                final FTPClient con = entry.getValue();\n                \n                try {\n                    // close the Connection\n                    con.logout();\n                } catch(IOException ioe) {\n                    log.error(ioe.getMessage(), ioe);\n                } finally {\n                    if(con.isConnected()) {\n                        try {\n                            con.disconnect();\n                        } catch(IOException ioe) {\n                            log.error(ioe.getMessage(), ioe);\n                        }\n                    }\n                }\n            }\n        });\n\n        // update the context\n        //ModuleUtils.storeContextMap(xqueryContext, FTPClientModule.CONNECTIONS_CONTEXTVAR, connections);\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"public static <T> Map<Long, T> retrieveContextMap(XQueryContext context, String contextMapName) {\r\n        // get the existing map from the context\r\n        return (HashMap<Long, T>)context.getXQueryContextVar(contextMapName);\r\n    }","id":14989,"modified_method":"public static <T> void modifyContextMap(XQueryContext context, String contextMapName, ContextMapModifier<T> modifier) {\r\n        contextMapLocks.getWriteLock(contextMapName).lock();\r\n        try {\r\n            // get the existing map from the context\r\n            final Map<Long, T> map = (Map<Long, T>)context.getXQueryContextVar(contextMapName);\r\n            if(map == null) {\r\n                return;\r\n            }\r\n            \r\n            modifier.modify(map);\r\n            \r\n        } finally {\r\n            contextMapLocks.getWriteLock(contextMapName).unlock();\r\n        }\r\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\r\n     * Retrieves a previously stored Object from the Context of an XQuery.\r\n     *\r\n     * @param   context         The Context of the XQuery containing the Object\r\n     * @param   contextMapName  DOCUMENT ME!\r\n     * @param   objectUID       The UID of the Object to retrieve from the Context of the XQuery\r\n     *\r\n     * @return  DOCUMENT ME!\r\n     */\r\n    public static <T> T retrieveObjectFromContextMap(XQueryContext context, String contextMapName, long objectUID) {\r\n        \r\n        // get the existing object map from the context\r\n        Map<Long, T> map = (HashMap<Long, T>)context.getXQueryContextVar(contextMapName);\r\n\r\n        if(map == null) {\r\n            return null;\r\n        }\r\n\r\n        // get the connection\r\n        return map.get(objectUID);\r\n    }","id":14990,"modified_method":"/**\r\n     * Retrieves a previously stored Object from the Context of an XQuery.\r\n     *\r\n     * @param   context         The Context of the XQuery containing the Object\r\n     * @param   contextMapName  DOCUMENT ME!\r\n     * @param   objectUID       The UID of the Object to retrieve from the Context of the XQuery\r\n     *\r\n     * @return  DOCUMENT ME!\r\n     */        \r\n    public static <T> T retrieveObjectFromContextMap(XQueryContext context, String contextMapName, long objectUID) {\r\n        \r\n        contextMapLocks.getReadLock(contextMapName).lock();\r\n        try{\r\n            // get the existing object map from the context\r\n            final Map<Long, T> map = (HashMap<Long, T>)context.getXQueryContextVar(contextMapName);\r\n\r\n            if(map == null) {\r\n                return null;\r\n            }\r\n\r\n            // get the connection\r\n            return map.get(objectUID);\r\n        } finally {\r\n            contextMapLocks.getReadLock(contextMapName).unlock();\r\n        }\r\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\r\n     * Stores an Object in the Context of an XQuery.\r\n     *\r\n     * @param   context         The Context of the XQuery to store the Object in\r\n     * @param   contextMapName  The name of the context map\r\n     * @param   o               The Object to store\r\n     *\r\n     * @return  A unique ID representing the Object\r\n     */\r\n    public static synchronized <T> long storeObjectInContextMap(XQueryContext context, String contextMapName, T o) {\r\n        // get the existing map from the context\r\n        Map<Long, T> map = (HashMap<Long, T>)context.getXQueryContextVar(contextMapName);\r\n\r\n        if(map == null) {\r\n            // if there is no map, create a new one\r\n            map = new HashMap<Long, T>();\r\n        }\r\n\r\n        // get an id for the map\r\n        long uid = 0;\r\n        while(uid == 0 || map.keySet().contains(uid)) {\r\n            uid = getUID();\r\n        }\r\n\r\n        // place the object in the map\r\n        map.put(uid, o);\r\n\r\n        // store the map back in the context\r\n        context.setXQueryContextVar(contextMapName, map);\r\n\r\n        return (uid);\r\n    }","id":14991,"modified_method":"/**\r\n     * Stores an Object in the Context of an XQuery.\r\n     *\r\n     * @param   context         The Context of the XQuery to store the Object in\r\n     * @param   contextMapName  The name of the context map\r\n     * @param   o               The Object to store\r\n     *\r\n     * @return  A unique ID representing the Object\r\n     */\r\n    public static <T> long storeObjectInContextMap(XQueryContext context, String contextMapName, T o) {\r\n        \r\n        contextMapLocks.getWriteLock(contextMapName).lock();\r\n        try{\r\n\r\n            // get the existing map from the context\r\n            Map<Long, T> map = (HashMap<Long, T>)context.getXQueryContextVar(contextMapName);\r\n\r\n            if(map == null) {\r\n                // if there is no map, create a new one\r\n                map = new HashMap<Long, T>();\r\n            }\r\n\r\n            // get an id for the map\r\n            long uid = 0;\r\n            while(uid == 0 || map.keySet().contains(uid)) {\r\n                uid = getUID();\r\n            }\r\n\r\n            // place the object in the map\r\n            map.put(uid, o);\r\n\r\n            // store the map back in the context\r\n            context.setXQueryContextVar(contextMapName, map);\r\n\r\n            return (uid);\r\n        } finally {\r\n            contextMapLocks.getWriteLock(contextMapName).unlock();\r\n        }\r\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Closes all the open DB Connections for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC Connections for\n     */\n    private static void closeAllConnections(XQueryContext xqueryContext) {\n        // get the existing Connections map from the context\n        Map<Long, Connection> connections = ModuleUtils.retrieveContextMap(xqueryContext, SQLModule.CONNECTIONS_CONTEXTVAR);\n\n        if(connections != null) {\n\n            // iterate over each Connection\n            for(Entry<Long, Connection> entry : connections.entrySet()) {\n                Long conID = entry.getKey();\n                Connection con = entry.getValue();\n\n                try {\n\n                    // close the Connection\n                    con.close();\n                } catch(SQLException se) {\n                    LOG.debug(\"Unable to close JDBC Connection\", se);\n                }\n            }\n\n            //empty the map\n            connections.clear();\n\n            // update the context\n            ModuleUtils.storeContextMap(xqueryContext, SQLModule.CONNECTIONS_CONTEXTVAR, connections);\n        }\n    }","id":14992,"modified_method":"/**\n     * Closes all the open DB Connections for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC Connections for\n     */\n    private static void closeAllConnections(XQueryContext xqueryContext) {\n        ModuleUtils.modifyContextMap(xqueryContext, SQLModule.CONNECTIONS_CONTEXTVAR, new ContextMapEntryModifier<Connection>(){\n            \n            @Override \n            public void modify(Map<Long, Connection> map) {\n                super.modify(map);\n                \n                //empty the map\n                map.clear();\n            }\n            \n            @Override\n            public void modify(Entry<Long, Connection> entry) {\n                final Connection con = entry.getValue();\n                try {\n                    // close the Connection\n                    con.close();\n                } catch(SQLException se) {\n                    LOG.warn(\"Unable to close JDBC Connection: \" + se.getMessage(), se);\n                }\n            }\n        });\n        \n        // update the context\n        //ModuleUtils.storeContextMap(xqueryContext, SQLModule.CONNECTIONS_CONTEXTVAR, connections);\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Closes all the open DB PreparedStatements for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC PreparedStatements for\n     */\n    private static void closeAllPreparedStatements(XQueryContext xqueryContext) {\n        // get the existing PreparedStatements map from the context\n        Map<Long, PreparedStatementWithSQL> preparedStatements = ModuleUtils.retrieveContextMap(xqueryContext, SQLModule.PREPARED_STATEMENTS_CONTEXTVAR);\n\n        if(preparedStatements != null) {\n\n            // iterate over each PreparedStatement\n            for(Entry<Long, PreparedStatementWithSQL> entry : preparedStatements.entrySet()) {\n                Long conID = entry.getKey();\n                PreparedStatementWithSQL stmt = entry.getValue();\n\n                try {\n\n                    // close the PreparedStatement\n                    stmt.getStmt().close();\n                } catch(SQLException se) {\n                    LOG.debug(\"Unable to close JDBC PreparedStatement\", se);\n                }\n            }\n\n            //empty the map\n            preparedStatements.clear();\n\n            // update the context\n            ModuleUtils.storeContextMap(xqueryContext, SQLModule.PREPARED_STATEMENTS_CONTEXTVAR, preparedStatements);\n        }\n    }","id":14993,"modified_method":"/**\n     * Closes all the open DB PreparedStatements for the specified XQueryContext.\n     *\n     * @param  xqueryContext  The context to close JDBC PreparedStatements for\n     */\n    private static void closeAllPreparedStatements(XQueryContext xqueryContext) {\n        ModuleUtils.modifyContextMap(xqueryContext, SQLModule.PREPARED_STATEMENTS_CONTEXTVAR, new ContextMapEntryModifier<PreparedStatementWithSQL>(){\n            \n            @Override \n            public void modify(Map<Long, PreparedStatementWithSQL> map) {\n                super.modify(map);\n                \n                //empty the map\n                map.clear();\n            }\n            \n            @Override\n            public void modify(Entry<Long, PreparedStatementWithSQL> entry) {\n                final PreparedStatementWithSQL stmt = entry.getValue();\n                try {\n                    // close the PreparedStatement\n                    stmt.getStmt().close();\n                } catch(SQLException se) {\n                    LOG.warn(\"Unable to close JDBC PreparedStatement: \" + se.getMessage(), se);\n                }\n            }\n        });\n        \n        // update the context\n        //ModuleUtils.storeContextMap(xqueryContext, SQLModule.PREPARED_STATEMENTS_CONTEXTVAR, preparedStatements);\n    }","commit_id":"7a610b9e2624375d6765793787a9ba072e0bb706","url":"https://github.com/eXist-db/exist"},{"original_method":"protected void exportEntry(\n\t\t\tPortletDataContext portletDataContext, Element entriesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tBlogsEntry entry)\n\t\tthrows Exception {\n\n\t\tif (!portletDataContext.isWithinDateRange(entry.getModifiedDate())) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!entry.isApproved() && !entry.isInTrash()) {\n\t\t\treturn;\n\t\t}\n\n\t\tString path = getEntryPath(portletDataContext, entry);\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this entry to make sure changes to its content are never\n\t\t// persisted\n\n\t\tentry = (BlogsEntry)entry.clone();\n\n\t\tElement entryElement = (Element)entriesElement.selectSingleNode(\n\t\t\t\"//page[@path='\".concat(path).concat(\"']\"));\n\n\t\tif (entryElement == null) {\n\t\t\tentryElement = entriesElement.addElement(\"entry\");\n\t\t}\n\n\t\tString content = DDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\tdlRepositoryEntriesElement, entryElement, entry.getContent());\n\n\t\tentry.setContent(content);\n\n\t\tString imagePath = getEntryImagePath(portletDataContext, entry);\n\n\t\tentryElement.addAttribute(\"image-path\", imagePath);\n\n\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(entry.getSmallImageId());\n\n\t\tif (entry.isSmallImage() && (smallImage != null)) {\n\t\t\tString smallImagePath = getEntrySmallImagePath(\n\t\t\t\tportletDataContext, entry);\n\n\t\t\tentryElement.addAttribute(\"small-image-path\", smallImagePath);\n\n\t\t\tentry.setSmallImageType(smallImage.getType());\n\n\t\t\tportletDataContext.addZipEntry(\n\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tentryElement, path, entry, _NAMESPACE);\n\t}","id":14994,"modified_method":"protected void exportEntry(\n\t\t\tPortletDataContext portletDataContext, Element entriesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tBlogsEntry entry)\n\t\tthrows Exception {\n\n\t\tif (!portletDataContext.isWithinDateRange(entry.getModifiedDate())) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!entry.isApproved() && !entry.isInTrash()) {\n\t\t\treturn;\n\t\t}\n\n\t\tString path = getEntryPath(portletDataContext, entry);\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this entry to make sure changes to its content are never\n\t\t// persisted\n\n\t\tentry = (BlogsEntry)entry.clone();\n\n\t\tElement entryElement = (Element)entriesElement.selectSingleNode(\n\t\t\t\"//page[@path='\".concat(path).concat(\"']\"));\n\n\t\tif (entryElement == null) {\n\t\t\tentryElement = entriesElement.addElement(\"entry\");\n\t\t}\n\n\t\tString content = DDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\tdlRepositoryEntriesElement, entryElement, entry.getContent());\n\n\t\tentry.setContent(content);\n\n\t\tString imagePath = getEntryImagePath(portletDataContext, entry);\n\n\t\tentryElement.addAttribute(\"image-path\", imagePath);\n\n\t\tif (entry.isSmallImage()) {\n\t\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(\n\t\t\t\tentry.getSmallImageId());\n\n\t\t\tif (Validator.isNotNull(entry.getSmallImageURL())) {\n\t\t\t\tString smallImageURL =\n\t\t\t\t\tDDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\t\t\t\tportletDataContext, dlFileEntryTypesElement,\n\t\t\t\t\t\tdlFoldersElement, dlFileEntriesElement,\n\t\t\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\t\t\tdlRepositoryEntriesElement, entryElement,\n\t\t\t\t\t\tentry.getSmallImageURL().concat(StringPool.SPACE));\n\n\t\t\t\tentry.setSmallImageURL(smallImageURL);\n\t\t\t}\n\t\t\telse if (smallImage != null) {\n\t\t\t\tString smallImagePath = getEntrySmallImagePath(\n\t\t\t\t\tportletDataContext, entry);\n\n\t\t\t\tentryElement.addAttribute(\"small-image-path\", smallImagePath);\n\n\t\t\t\tentry.setSmallImageType(smallImage.getType());\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t\t}\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tentryElement, path, entry, _NAMESPACE);\n\t}","commit_id":"7b0b9c5abdbe298dac937431b6944cb72baa56a9","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void importEntry(\n\t\t\tPortletDataContext portletDataContext, Element entryElement,\n\t\t\tBlogsEntry entry)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(entry.getUserUuid());\n\n\t\tString content = JournalPortletDataHandlerImpl.importReferencedContent(\n\t\t\tportletDataContext, entryElement, entry.getContent());\n\n\t\tentry.setContent(content);\n\n\t\tCalendar displayDateCal = CalendarFactoryUtil.getCalendar();\n\n\t\tdisplayDateCal.setTime(entry.getDisplayDate());\n\n\t\tint displayDateMonth = displayDateCal.get(Calendar.MONTH);\n\t\tint displayDateDay = displayDateCal.get(Calendar.DATE);\n\t\tint displayDateYear = displayDateCal.get(Calendar.YEAR);\n\t\tint displayDateHour = displayDateCal.get(Calendar.HOUR);\n\t\tint displayDateMinute = displayDateCal.get(Calendar.MINUTE);\n\n\t\tif (displayDateCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\tdisplayDateHour += 12;\n\t\t}\n\n\t\tboolean allowPingbacks = entry.isAllowPingbacks();\n\t\tboolean allowTrackbacks = entry.isAllowTrackbacks();\n\t\tString[] trackbacks = StringUtil.split(entry.getTrackbacks());\n\t\tint status = entry.getStatus();\n\n\t\tString smallImageFileName = null;\n\t\tInputStream smallImageInputStream = null;\n\n\t\ttry {\n\t\t\tString smallImagePath = entryElement.attributeValue(\n\t\t\t\t\"small-image-path\");\n\n\t\t\tif (entry.isSmallImage() && Validator.isNotNull(smallImagePath)) {\n\t\t\t\tsmallImageFileName = String.valueOf(\n\t\t\t\t\tentry.getSmallImageId()).concat(\n\t\t\t\t\t\tStringPool.PERIOD).concat(entry.getSmallImageType());\n\t\t\t\tsmallImageInputStream =\n\t\t\t\t\tportletDataContext.getZipEntryAsInputStream(smallImagePath);\n\t\t\t}\n\n\t\t\tServiceContext serviceContext =\n\t\t\t\tportletDataContext.createServiceContext(\n\t\t\t\t\tentryElement, entry, _NAMESPACE);\n\n\t\t\tif ((status != WorkflowConstants.STATUS_APPROVED) &&\n\t\t\t\t(status != WorkflowConstants.STATUS_IN_TRASH)) {\n\n\t\t\t\tserviceContext.setWorkflowAction(\n\t\t\t\t\tWorkflowConstants.ACTION_SAVE_DRAFT);\n\t\t\t}\n\n\t\t\tBlogsEntry importedEntry = null;\n\n\t\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\t\tserviceContext.setAttribute(\"urlTitle\", entry.getUrlTitle());\n\n\t\t\t\tBlogsEntry existingEntry = BlogsEntryUtil.fetchByUUID_G(\n\t\t\t\t\tentry.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\t\tif (existingEntry == null) {\n\t\t\t\t\tserviceContext.setUuid(entry.getUuid());\n\n\t\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.addEntry(\n\t\t\t\t\t\tuserId, entry.getTitle(), entry.getDescription(),\n\t\t\t\t\t\tentry.getContent(), displayDateMonth, displayDateDay,\n\t\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\t\tallowPingbacks, allowTrackbacks, trackbacks,\n\t\t\t\t\t\tentry.isSmallImage(), entry.getSmallImageURL(),\n\t\t\t\t\t\tsmallImageFileName, smallImageInputStream,\n\t\t\t\t\t\tserviceContext);\n\n\t\t\t\t\tif (status == WorkflowConstants.STATUS_IN_TRASH) {\n\t\t\t\t\t\timportedEntry =\n\t\t\t\t\t\t\tBlogsEntryLocalServiceUtil.moveEntryToTrash(\n\t\t\t\t\t\t\t\tuserId, importedEntry);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.updateEntry(\n\t\t\t\t\t\tuserId, existingEntry.getEntryId(), entry.getTitle(),\n\t\t\t\t\t\tentry.getDescription(), entry.getContent(),\n\t\t\t\t\t\tdisplayDateMonth, displayDateDay, displayDateYear,\n\t\t\t\t\t\tdisplayDateHour, displayDateMinute, allowPingbacks,\n\t\t\t\t\t\tallowTrackbacks, trackbacks, entry.getSmallImage(),\n\t\t\t\t\t\tentry.getSmallImageURL(), smallImageFileName,\n\t\t\t\t\t\tsmallImageInputStream, serviceContext);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.addEntry(\n\t\t\t\t\tuserId, entry.getTitle(), entry.getDescription(),\n\t\t\t\t\tentry.getContent(), displayDateMonth, displayDateDay,\n\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\tallowPingbacks, allowTrackbacks, trackbacks,\n\t\t\t\t\tentry.getSmallImage(), entry.getSmallImageURL(),\n\t\t\t\t\tsmallImageFileName, smallImageInputStream, serviceContext);\n\t\t\t}\n\n\t\t\tportletDataContext.importClassedModel(\n\t\t\t\tentry, importedEntry, _NAMESPACE);\n\t\t}\n\t\tfinally {\n\t\t\tStreamUtil.cleanUp(smallImageInputStream);\n\t\t}\n\n\t}","id":14995,"modified_method":"protected void importEntry(\n\t\t\tPortletDataContext portletDataContext, Element entryElement,\n\t\t\tBlogsEntry entry)\n\t\tthrows Exception {\n\n\t\tlong userId = portletDataContext.getUserId(entry.getUserUuid());\n\n\t\tString content = JournalPortletDataHandlerImpl.importReferencedContent(\n\t\t\tportletDataContext, entryElement, entry.getContent());\n\n\t\tentry.setContent(content);\n\n\t\tCalendar displayDateCal = CalendarFactoryUtil.getCalendar();\n\n\t\tdisplayDateCal.setTime(entry.getDisplayDate());\n\n\t\tint displayDateMonth = displayDateCal.get(Calendar.MONTH);\n\t\tint displayDateDay = displayDateCal.get(Calendar.DATE);\n\t\tint displayDateYear = displayDateCal.get(Calendar.YEAR);\n\t\tint displayDateHour = displayDateCal.get(Calendar.HOUR);\n\t\tint displayDateMinute = displayDateCal.get(Calendar.MINUTE);\n\n\t\tif (displayDateCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\tdisplayDateHour += 12;\n\t\t}\n\n\t\tboolean allowPingbacks = entry.isAllowPingbacks();\n\t\tboolean allowTrackbacks = entry.isAllowTrackbacks();\n\t\tString[] trackbacks = StringUtil.split(entry.getTrackbacks());\n\t\tint status = entry.getStatus();\n\n\t\tString smallImageFileName = null;\n\t\tInputStream smallImageInputStream = null;\n\n\t\ttry {\n\n\t\t\tif (entry.isSmallImage()) {\n\t\t\t\tString smallImagePath = entryElement.attributeValue(\n\t\t\t\t\t\"small-image-path\");\n\n\t\t\t\tif (Validator.isNotNull(entry.getSmallImageURL())) {\n\t\t\t\t\tString smallImageURL =\n\t\t\t\t\t\tJournalPortletDataHandlerImpl.importReferencedContent(\n\t\t\t\t\t\t\tportletDataContext, entryElement,\n\t\t\t\t\t\t\tentry.getSmallImageURL());\n\n\t\t\t\t\tentry.setSmallImageURL(smallImageURL);\n\t\t\t\t}\n\t\t\t\telse if (Validator.isNotNull(smallImagePath)) {\n\t\t\t\t\tsmallImageFileName = String.valueOf(\n\t\t\t\t\t\tentry.getSmallImageId()).concat(\n\t\t\t\t\t\t\tStringPool.PERIOD).concat(\n\t\t\t\t\t\t\t\tentry.getSmallImageType());\n\t\t\t\t\tsmallImageInputStream =\n\t\t\t\t\t\tportletDataContext.getZipEntryAsInputStream(\n\t\t\t\t\t\t\tsmallImagePath);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tServiceContext serviceContext =\n\t\t\t\tportletDataContext.createServiceContext(\n\t\t\t\t\tentryElement, entry, _NAMESPACE);\n\n\t\t\tif ((status != WorkflowConstants.STATUS_APPROVED) &&\n\t\t\t\t(status != WorkflowConstants.STATUS_IN_TRASH)) {\n\n\t\t\t\tserviceContext.setWorkflowAction(\n\t\t\t\t\tWorkflowConstants.ACTION_SAVE_DRAFT);\n\t\t\t}\n\n\t\t\tBlogsEntry importedEntry = null;\n\n\t\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\t\tserviceContext.setAttribute(\"urlTitle\", entry.getUrlTitle());\n\n\t\t\t\tBlogsEntry existingEntry = BlogsEntryUtil.fetchByUUID_G(\n\t\t\t\t\tentry.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\t\tif (existingEntry == null) {\n\t\t\t\t\tserviceContext.setUuid(entry.getUuid());\n\n\t\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.addEntry(\n\t\t\t\t\t\tuserId, entry.getTitle(), entry.getDescription(),\n\t\t\t\t\t\tentry.getContent(), displayDateMonth, displayDateDay,\n\t\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\t\tallowPingbacks, allowTrackbacks, trackbacks,\n\t\t\t\t\t\tentry.isSmallImage(), entry.getSmallImageURL(),\n\t\t\t\t\t\tsmallImageFileName, smallImageInputStream,\n\t\t\t\t\t\tserviceContext);\n\n\t\t\t\t\tif (status == WorkflowConstants.STATUS_IN_TRASH) {\n\t\t\t\t\t\timportedEntry =\n\t\t\t\t\t\t\tBlogsEntryLocalServiceUtil.moveEntryToTrash(\n\t\t\t\t\t\t\t\tuserId, importedEntry);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.updateEntry(\n\t\t\t\t\t\tuserId, existingEntry.getEntryId(), entry.getTitle(),\n\t\t\t\t\t\tentry.getDescription(), entry.getContent(),\n\t\t\t\t\t\tdisplayDateMonth, displayDateDay, displayDateYear,\n\t\t\t\t\t\tdisplayDateHour, displayDateMinute, allowPingbacks,\n\t\t\t\t\t\tallowTrackbacks, trackbacks, entry.getSmallImage(),\n\t\t\t\t\t\tentry.getSmallImageURL(), smallImageFileName,\n\t\t\t\t\t\tsmallImageInputStream, serviceContext);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedEntry = BlogsEntryLocalServiceUtil.addEntry(\n\t\t\t\t\tuserId, entry.getTitle(), entry.getDescription(),\n\t\t\t\t\tentry.getContent(), displayDateMonth, displayDateDay,\n\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\tallowPingbacks, allowTrackbacks, trackbacks,\n\t\t\t\t\tentry.getSmallImage(), entry.getSmallImageURL(),\n\t\t\t\t\tsmallImageFileName, smallImageInputStream, serviceContext);\n\t\t\t}\n\n\t\t\tportletDataContext.importClassedModel(\n\t\t\t\tentry, importedEntry, _NAMESPACE);\n\t\t}\n\t\tfinally {\n\t\t\tStreamUtil.cleanUp(smallImageInputStream);\n\t\t}\n\n\t}","commit_id":"7b0b9c5abdbe298dac937431b6944cb72baa56a9","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void importTemplate(\n\t\t\tPortletDataContext portletDataContext, Element templateElement)\n\t\tthrows Exception {\n\n\t\tString path = templateElement.attributeValue(\"path\");\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\tDDMTemplate template =\n\t\t\t(DDMTemplate)portletDataContext.getZipEntryAsObject(\n\t\t\t\ttemplateElement, path);\n\n\t\tlong userId = portletDataContext.getUserId(template.getUserUuid());\n\n\t\tMap<Long, Long> structureIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMStructure.class);\n\n\t\tlong classPK = MapUtil.getLong(\n\t\t\tstructureIds, template.getClassPK(), template.getClassPK());\n\n\t\tFile smallFile = null;\n\n\t\tString smallImagePath = templateElement.attributeValue(\n\t\t\t\"small-image-path\");\n\n\t\tif (template.isSmallImage() && Validator.isNotNull(smallImagePath)) {\n\t\t\tbyte[] bytes = portletDataContext.getZipEntryAsByteArray(\n\t\t\t\tsmallImagePath);\n\n\t\t\tif (bytes != null) {\n\t\t\t\tsmallFile = FileUtil.createTempFile(\n\t\t\t\t\ttemplate.getSmallImageType());\n\n\t\t\t\tFileUtil.write(smallFile, bytes);\n\t\t\t}\n\t\t}\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\ttemplateElement, template, _NAMESPACE);\n\n\t\tDDMTemplate importedTemplate = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tDDMTemplate existingTemplate = DDMTemplateUtil.fetchByUUID_G(\n\t\t\t\ttemplate.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingTemplate == null) {\n\t\t\t\tserviceContext.setUuid(template.getUuid());\n\n\t\t\t\timportedTemplate = addTemplate(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(), template,\n\t\t\t\t\tclassPK, smallFile, serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedTemplate = DDMTemplateLocalServiceUtil.updateTemplate(\n\t\t\t\t\texistingTemplate.getTemplateId(), template.getNameMap(),\n\t\t\t\t\ttemplate.getDescriptionMap(), template.getType(),\n\t\t\t\t\ttemplate.getMode(), template.getLanguage(),\n\t\t\t\t\ttemplate.getScript(), template.isCacheable(),\n\t\t\t\t\ttemplate.isSmallImage(), template.getSmallImageURL(),\n\t\t\t\t\tsmallFile, serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedTemplate = addTemplate(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(), template, classPK,\n\t\t\t\tsmallFile, serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\ttemplate, importedTemplate, _NAMESPACE);\n\t}","id":14996,"modified_method":"public static void importTemplate(\n\t\t\tPortletDataContext portletDataContext, Element templateElement)\n\t\tthrows Exception {\n\n\t\tString path = templateElement.attributeValue(\"path\");\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\tDDMTemplate template =\n\t\t\t(DDMTemplate)portletDataContext.getZipEntryAsObject(\n\t\t\t\ttemplateElement, path);\n\n\t\tlong userId = portletDataContext.getUserId(template.getUserUuid());\n\n\t\tMap<Long, Long> structureIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMStructure.class);\n\n\t\tlong classPK = MapUtil.getLong(\n\t\t\tstructureIds, template.getClassPK(), template.getClassPK());\n\n\t\tFile smallFile = null;\n\n\t\tif (template.isSmallImage()) {\n\t\t\tString smallImagePath = templateElement.attributeValue(\n\t\t\t\t\"small-image-path\");\n\n\t\t\tif (Validator.isNotNull(template.getSmallImageURL())) {\n\t\t\t\tString smallImageURL =\n\t\t\t\t\tJournalPortletDataHandlerImpl.importReferencedContent(\n\t\t\t\t\t\tportletDataContext, templateElement,\n\t\t\t\t\t\ttemplate.getSmallImageURL());\n\n\t\t\t\ttemplate.setSmallImageURL(smallImageURL);\n\t\t\t}\n\t\t\telse if (Validator.isNotNull(smallImagePath)) {\n\t\t\t\tbyte[] bytes = portletDataContext.getZipEntryAsByteArray(\n\t\t\t\t\tsmallImagePath);\n\n\t\t\t\tif (bytes != null) {\n\t\t\t\t\tsmallFile = FileUtil.createTempFile(\n\t\t\t\t\t\ttemplate.getSmallImageType());\n\n\t\t\t\t\tFileUtil.write(smallFile, bytes);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\ttemplateElement, template, _NAMESPACE);\n\n\t\tDDMTemplate importedTemplate = null;\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tDDMTemplate existingTemplate = DDMTemplateUtil.fetchByUUID_G(\n\t\t\t\ttemplate.getUuid(), portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingTemplate == null) {\n\t\t\t\tserviceContext.setUuid(template.getUuid());\n\n\t\t\t\timportedTemplate = addTemplate(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(), template,\n\t\t\t\t\tclassPK, smallFile, serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedTemplate = DDMTemplateLocalServiceUtil.updateTemplate(\n\t\t\t\t\texistingTemplate.getTemplateId(), template.getNameMap(),\n\t\t\t\t\ttemplate.getDescriptionMap(), template.getType(),\n\t\t\t\t\ttemplate.getMode(), template.getLanguage(),\n\t\t\t\t\ttemplate.getScript(), template.isCacheable(),\n\t\t\t\t\ttemplate.isSmallImage(), template.getSmallImageURL(),\n\t\t\t\t\tsmallFile, serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedTemplate = addTemplate(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(), template, classPK,\n\t\t\t\tsmallFile, serviceContext);\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\ttemplate, importedTemplate, _NAMESPACE);\n\t}","commit_id":"47dfe9fabfc5660b00214114005f4beb7460cb1c","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void exportTemplate(\n\t\t\tPortletDataContext portletDataContext, Element templatesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tString path, DDMTemplate template)\n\t\tthrows Exception {\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this template to make sure changes to its content are never\n\t\t// persisted\n\n\t\ttemplate = (DDMTemplate)template.clone();\n\n\t\tElement templateElement = templatesElement.addElement(\"template\");\n\n\t\tif (template.isSmallImage() &&\n\t\t\tValidator.isNull(template.getSmallImageURL())) {\n\n\t\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(\n\t\t\t\ttemplate.getSmallImageId());\n\n\t\t\tif (smallImage != null) {\n\t\t\t\tString smallImagePath = getTemplateSmallImagePath(\n\t\t\t\t\tportletDataContext, template);\n\n\t\t\t\ttemplateElement.addAttribute(\n\t\t\t\t\t\"small-image-path\", smallImagePath);\n\n\t\t\t\ttemplate.setSmallImageType(smallImage.getType());\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t\t}\n\t\t}\n\n\t\tif (portletDataContext.getBooleanParameter(\n\t\t\t\t_NAMESPACE, \"embedded-assets\")) {\n\n\t\t\tString content = exportReferencedContent(\n\t\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, templateElement,\n\t\t\t\ttemplate.getScript());\n\n\t\t\ttemplate.setScript(content);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\ttemplateElement, path, template, _NAMESPACE);\n\t}","id":14997,"modified_method":"public static void exportTemplate(\n\t\t\tPortletDataContext portletDataContext, Element templatesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tString path, DDMTemplate template)\n\t\tthrows Exception {\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this template to make sure changes to its content are never\n\t\t// persisted\n\n\t\ttemplate = (DDMTemplate)template.clone();\n\n\t\tElement templateElement = templatesElement.addElement(\"template\");\n\n\t\tif (template.isSmallImage()) {\n\t\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(\n\t\t\t\t\ttemplate.getSmallImageId());\n\n\t\t\tif (Validator.isNotNull(template.getSmallImageURL())) {\n\t\t\t\tString smallImageURL =\n\t\t\t\t\tDDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\t\t\t\tportletDataContext, dlFileEntryTypesElement,\n\t\t\t\t\t\tdlFoldersElement, dlFileEntriesElement,\n\t\t\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\t\t\tdlRepositoryEntriesElement, templateElement,\n\t\t\t\t\t\ttemplate.getSmallImageURL().concat(StringPool.SPACE));\n\n\t\t\t\ttemplate.setSmallImageURL(smallImageURL);\n\t\t\t}\n\t\t\telse if (smallImage != null) {\n\t\t\t\tString smallImagePath = getTemplateSmallImagePath(\n\t\t\t\t\tportletDataContext, template);\n\n\t\t\t\ttemplateElement.addAttribute(\n\t\t\t\t\t\"small-image-path\", smallImagePath);\n\n\t\t\t\ttemplate.setSmallImageType(smallImage.getType());\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t\t}\n\t\t}\n\n\t\tif (portletDataContext.getBooleanParameter(\n\t\t\t\t_NAMESPACE, \"embedded-assets\")) {\n\n\t\t\tString content = exportReferencedContent(\n\t\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, templateElement,\n\t\t\t\ttemplate.getScript());\n\n\t\t\ttemplate.setScript(content);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\ttemplateElement, path, template, _NAMESPACE);\n\t}","commit_id":"47dfe9fabfc5660b00214114005f4beb7460cb1c","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void importArticle(\n\t\t\tPortletDataContext portletDataContext, Element articleElement)\n\t\tthrows Exception {\n\n\t\tString path = articleElement.attributeValue(\"path\");\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\tJournalArticle article =\n\t\t\t(JournalArticle)portletDataContext.getZipEntryAsObject(\n\t\t\t\tarticleElement, path);\n\n\t\tprepareLanguagesForImport(article);\n\n\t\tlong userId = portletDataContext.getUserId(article.getUserUuid());\n\n\t\tJournalCreationStrategy creationStrategy =\n\t\t\tJournalCreationStrategyFactory.getInstance();\n\n\t\tlong authorId = creationStrategy.getAuthorUserId(\n\t\t\tportletDataContext, article);\n\n\t\tif (authorId != JournalCreationStrategy.USE_DEFAULT_USER_ID_STRATEGY) {\n\t\t\tuserId = authorId;\n\t\t}\n\n\t\tUser user = UserLocalServiceUtil.getUser(userId);\n\n\t\tMap<Long, Long> folderIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tJournalFolder.class);\n\n\t\tlong folderId = MapUtil.getLong(\n\t\t\tfolderIds, article.getFolderId(), article.getFolderId());\n\n\t\tif ((folderId != JournalFolderConstants.DEFAULT_PARENT_FOLDER_ID) &&\n\t\t\t(folderId == article.getFolderId())) {\n\n\t\t\tString folderPath = getImportFolderPath(\n\t\t\t\tportletDataContext, folderId);\n\n\t\t\tJournalFolder folder =\n\t\t\t\t(JournalFolder)portletDataContext.getZipEntryAsObject(\n\t\t\t\t\tfolderPath);\n\n\t\t\timportFolder(portletDataContext, folderPath, folder);\n\n\t\t\tfolderId = MapUtil.getLong(\n\t\t\t\tfolderIds, article.getFolderId(), article.getFolderId());\n\t\t}\n\n\t\tString articleId = article.getArticleId();\n\t\tboolean autoArticleId = false;\n\n\t\tif (Validator.isNumber(articleId) ||\n\t\t\t(JournalArticleUtil.fetchByG_A_V(\n\t\t\t\tportletDataContext.getScopeGroupId(), articleId,\n\t\t\t\tJournalArticleConstants.VERSION_DEFAULT) != null)) {\n\n\t\t\tautoArticleId = true;\n\t\t}\n\n\t\tMap<String, String> articleIds =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tJournalArticle.class + \".articleId\");\n\n\t\tString newArticleId = articleIds.get(articleId);\n\n\t\tif (Validator.isNotNull(newArticleId)) {\n\n\t\t\t// A sibling of a different version was already assigned a new\n\t\t\t// article id\n\n\t\t\tarticleId = newArticleId;\n\t\t\tautoArticleId = false;\n\t\t}\n\n\t\tString content = article.getContent();\n\n\t\tcontent = importReferencedContent(\n\t\t\tportletDataContext, articleElement, content);\n\n\t\tarticle.setContent(content);\n\n\t\tString newContent = creationStrategy.getTransformedContent(\n\t\t\tportletDataContext, article);\n\n\t\tif (newContent != JournalCreationStrategy.ARTICLE_CONTENT_UNCHANGED) {\n\t\t\tarticle.setContent(newContent);\n\t\t}\n\n\t\tMap<String, String> ddmStructureKeys =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMStructure.class);\n\n\t\tString parentDDMStructureKey = MapUtil.getString(\n\t\t\tddmStructureKeys, article.getStructureId(),\n\t\t\tarticle.getStructureId());\n\n\t\tMap<String, String> ddmTemplateKeys =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMTemplate.class);\n\n\t\tString parentDDMTemplateKey = MapUtil.getString(\n\t\t\tddmTemplateKeys, article.getTemplateId(), article.getTemplateId());\n\n\t\tDate displayDate = article.getDisplayDate();\n\n\t\tint displayDateMonth = 0;\n\t\tint displayDateDay = 0;\n\t\tint displayDateYear = 0;\n\t\tint displayDateHour = 0;\n\t\tint displayDateMinute = 0;\n\n\t\tif (displayDate != null) {\n\t\t\tCalendar displayCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\tdisplayCal.setTime(displayDate);\n\n\t\t\tdisplayDateMonth = displayCal.get(Calendar.MONTH);\n\t\t\tdisplayDateDay = displayCal.get(Calendar.DATE);\n\t\t\tdisplayDateYear = displayCal.get(Calendar.YEAR);\n\t\t\tdisplayDateHour = displayCal.get(Calendar.HOUR);\n\t\t\tdisplayDateMinute = displayCal.get(Calendar.MINUTE);\n\n\t\t\tif (displayCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\tdisplayDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tDate expirationDate = article.getExpirationDate();\n\n\t\tint expirationDateMonth = 0;\n\t\tint expirationDateDay = 0;\n\t\tint expirationDateYear = 0;\n\t\tint expirationDateHour = 0;\n\t\tint expirationDateMinute = 0;\n\t\tboolean neverExpire = true;\n\n\t\tif (expirationDate != null) {\n\t\t\tCalendar expirationCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\texpirationCal.setTime(expirationDate);\n\n\t\t\texpirationDateMonth = expirationCal.get(Calendar.MONTH);\n\t\t\texpirationDateDay = expirationCal.get(Calendar.DATE);\n\t\t\texpirationDateYear = expirationCal.get(Calendar.YEAR);\n\t\t\texpirationDateHour = expirationCal.get(Calendar.HOUR);\n\t\t\texpirationDateMinute = expirationCal.get(Calendar.MINUTE);\n\t\t\tneverExpire = false;\n\n\t\t\tif (expirationCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\texpirationDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tDate reviewDate = article.getReviewDate();\n\n\t\tint reviewDateMonth = 0;\n\t\tint reviewDateDay = 0;\n\t\tint reviewDateYear = 0;\n\t\tint reviewDateHour = 0;\n\t\tint reviewDateMinute = 0;\n\t\tboolean neverReview = true;\n\n\t\tif (reviewDate != null) {\n\t\t\tCalendar reviewCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\treviewCal.setTime(reviewDate);\n\n\t\t\treviewDateMonth = reviewCal.get(Calendar.MONTH);\n\t\t\treviewDateDay = reviewCal.get(Calendar.DATE);\n\t\t\treviewDateYear = reviewCal.get(Calendar.YEAR);\n\t\t\treviewDateHour = reviewCal.get(Calendar.HOUR);\n\t\t\treviewDateMinute = reviewCal.get(Calendar.MINUTE);\n\t\t\tneverReview = false;\n\n\t\t\tif (reviewCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\treviewDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tlong ddmStructureId = 0;\n\n\t\tif (Validator.isNotNull(article.getStructureId())) {\n\t\t\tString ddmStructureUuid = articleElement.attributeValue(\n\t\t\t\t\"ddm-structure-uuid\");\n\n\t\t\tDDMStructure existingDDMStructure =\n\t\t\t\tDDMStructureUtil.fetchByUUID_G(\n\t\t\t\t\tddmStructureUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingDDMStructure == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\texistingDDMStructure = DDMStructureUtil.fetchByUUID_G(\n\t\t\t\t\tddmStructureUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tif (existingDDMStructure == null) {\n\t\t\t\tString newStructureId = ddmStructureKeys.get(\n\t\t\t\t\tarticle.getStructureId());\n\n\t\t\t\tif (Validator.isNotNull(newStructureId)) {\n\t\t\t\t\texistingDDMStructure = DDMStructureUtil.fetchByG_S(\n\t\t\t\t\t\tportletDataContext.getScopeGroupId(),\n\t\t\t\t\t\tString.valueOf(newStructureId));\n\t\t\t\t}\n\n\t\t\t\tif (existingDDMStructure == null) {\n\t\t\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t\t\tStringBundler sb = new StringBundler();\n\n\t\t\t\t\t\tsb.append(\"Structure \");\n\t\t\t\t\t\tsb.append(article.getStructureId());\n\t\t\t\t\t\tsb.append(\" is missing for article \");\n\t\t\t\t\t\tsb.append(article.getArticleId());\n\t\t\t\t\t\tsb.append(\", skipping this article.\");\n\n\t\t\t\t\t\t_log.warn(sb.toString());\n\t\t\t\t\t}\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tddmStructureId = existingDDMStructure.getStructureId();\n\n\t\t\tparentDDMStructureKey = existingDDMStructure.getStructureKey();\n\t\t}\n\n\t\tif (Validator.isNotNull(article.getTemplateId())) {\n\t\t\tString ddmTemplateUuid = articleElement.attributeValue(\n\t\t\t\t\"ddm-template-uuid\");\n\n\t\t\tDDMTemplate existingDDMTemplate =\n\t\t\t\tDDMTemplateUtil.fetchByUUID_G(\n\t\t\t\t\tddmTemplateUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\texistingDDMTemplate = DDMTemplateUtil.fetchByUUID_G(\n\t\t\t\t\tddmTemplateUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\tString newTemplateId = ddmTemplateKeys.get(\n\t\t\t\t\tarticle.getTemplateId());\n\n\t\t\t\tif (Validator.isNotNull(newTemplateId)) {\n\t\t\t\t\texistingDDMTemplate = DDMTemplateUtil.fetchByG_T(\n\t\t\t\t\t\tportletDataContext.getScopeGroupId(), newTemplateId);\n\t\t\t\t}\n\n\t\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t\t\tStringBundler sb = new StringBundler();\n\n\t\t\t\t\t\tsb.append(\"Template \");\n\t\t\t\t\t\tsb.append(article.getTemplateId());\n\t\t\t\t\t\tsb.append(\" is missing for article \");\n\t\t\t\t\t\tsb.append(article.getArticleId());\n\t\t\t\t\t\tsb.append(\", skipping this article.\");\n\n\t\t\t\t\t\t_log.warn(sb.toString());\n\t\t\t\t\t}\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tparentDDMTemplateKey = existingDDMTemplate.getTemplateKey();\n\t\t}\n\n\t\tFile smallFile = null;\n\n\t\tString smallImagePath = articleElement.attributeValue(\n\t\t\t\"small-image-path\");\n\n\t\tif (article.isSmallImage() && Validator.isNotNull(smallImagePath)) {\n\t\t\tbyte[] bytes = portletDataContext.getZipEntryAsByteArray(\n\t\t\t\tsmallImagePath);\n\n\t\t\tsmallFile = FileUtil.createTempFile(article.getSmallImageType());\n\n\t\t\tFileUtil.write(smallFile, bytes);\n\t\t}\n\n\t\tMap<String, byte[]> images = new HashMap<String, byte[]>();\n\n\t\tString imagePath = articleElement.attributeValue(\"image-path\");\n\n\t\tif (portletDataContext.getBooleanParameter(_NAMESPACE, \"images\") &&\n\t\t\tValidator.isNotNull(imagePath)) {\n\n\t\t\tList<String> imageFiles = portletDataContext.getZipFolderEntries(\n\t\t\t\timagePath);\n\n\t\t\tfor (String imageFile : imageFiles) {\n\t\t\t\tString fileName = imageFile;\n\n\t\t\t\tif (fileName.contains(StringPool.SLASH)) {\n\t\t\t\t\tfileName = fileName.substring(\n\t\t\t\t\t\tfileName.lastIndexOf(CharPool.SLASH) + 1);\n\t\t\t\t}\n\n\t\t\t\tif (fileName.endsWith(\".xml\")) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint pos = fileName.lastIndexOf(CharPool.PERIOD);\n\n\t\t\t\tif (pos != -1) {\n\t\t\t\t\tfileName = fileName.substring(0, pos);\n\t\t\t\t}\n\n\t\t\t\timages.put(\n\t\t\t\t\tfileName,\n\t\t\t\t\tportletDataContext.getZipEntryAsByteArray(imageFile));\n\t\t\t}\n\t\t}\n\n\t\tString articleURL = null;\n\n\t\tboolean addGroupPermissions = creationStrategy.addGroupPermissions(\n\t\t\tportletDataContext, article);\n\t\tboolean addGuestPermissions = creationStrategy.addGuestPermissions(\n\t\t\tportletDataContext, article);\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tarticleElement, article, _NAMESPACE);\n\n\t\tserviceContext.setAddGroupPermissions(addGroupPermissions);\n\t\tserviceContext.setAddGuestPermissions(addGuestPermissions);\n\n\t\tif (article.getStatus() != WorkflowConstants.STATUS_APPROVED) {\n\t\t\tserviceContext.setWorkflowAction(\n\t\t\t\tWorkflowConstants.ACTION_SAVE_DRAFT);\n\t\t}\n\n\t\tJournalArticle importedArticle = null;\n\n\t\tString articleResourceUuid = articleElement.attributeValue(\n\t\t\t\"article-resource-uuid\");\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tJournalArticleResource articleResource =\n\t\t\t\tJournalArticleResourceUtil.fetchByUUID_G(\n\t\t\t\t\tarticleResourceUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (articleResource == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\tarticleResource = JournalArticleResourceUtil.fetchByUUID_G(\n\t\t\t\t\tarticleResourceUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tserviceContext.setUuid(articleResourceUuid);\n\t\t\tserviceContext.setAttribute(\"urlTitle\", article.getUrlTitle());\n\n\t\t\tJournalArticle existingArticle = null;\n\n\t\t\tif (articleResource != null) {\n\t\t\t\ttry {\n\t\t\t\t\texistingArticle =\n\t\t\t\t\t\tJournalArticleLocalServiceUtil.getLatestArticle(\n\t\t\t\t\t\t\tarticleResource.getResourcePrimKey(),\n\t\t\t\t\t\t\tWorkflowConstants.STATUS_ANY, false);\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchArticleException nsae) {\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (existingArticle == null) {\n\t\t\t\texistingArticle = JournalArticleUtil.fetchByG_A_V(\n\t\t\t\t\tportletDataContext.getScopeGroupId(), newArticleId,\n\t\t\t\t\tarticle.getVersion());\n\t\t\t}\n\n\t\t\tif (existingArticle == null) {\n\t\t\t\timportedArticle = JournalArticleLocalServiceUtil.addArticle(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(), folderId,\n\t\t\t\t\tarticle.getClassNameId(), ddmStructureId, articleId,\n\t\t\t\t\tautoArticleId, article.getVersion(), article.getTitleMap(),\n\t\t\t\t\tarticle.getDescriptionMap(), article.getContent(),\n\t\t\t\t\tarticle.getType(), parentDDMStructureKey,\n\t\t\t\t\tparentDDMTemplateKey, article.getLayoutUuid(),\n\t\t\t\t\tdisplayDateMonth, displayDateDay, displayDateYear,\n\t\t\t\t\tdisplayDateHour, displayDateMinute, expirationDateMonth,\n\t\t\t\t\texpirationDateDay, expirationDateYear, expirationDateHour,\n\t\t\t\t\texpirationDateMinute, neverExpire, reviewDateMonth,\n\t\t\t\t\treviewDateDay, reviewDateYear, reviewDateHour,\n\t\t\t\t\treviewDateMinute, neverReview, article.isIndexable(),\n\t\t\t\t\tarticle.isSmallImage(), article.getSmallImageURL(),\n\t\t\t\t\tsmallFile, images, articleURL, serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedArticle = JournalArticleLocalServiceUtil.updateArticle(\n\t\t\t\t\tuserId, existingArticle.getGroupId(), folderId,\n\t\t\t\t\texistingArticle.getArticleId(), article.getVersion(),\n\t\t\t\t\tarticle.getTitleMap(), article.getDescriptionMap(),\n\t\t\t\t\tarticle.getContent(), article.getType(),\n\t\t\t\t\tparentDDMStructureKey, parentDDMTemplateKey,\n\t\t\t\t\tarticle.getLayoutUuid(), displayDateMonth, displayDateDay,\n\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\texpirationDateMonth, expirationDateDay, expirationDateYear,\n\t\t\t\t\texpirationDateHour, expirationDateMinute, neverExpire,\n\t\t\t\t\treviewDateMonth, reviewDateDay, reviewDateYear,\n\t\t\t\t\treviewDateHour, reviewDateMinute, neverReview,\n\t\t\t\t\tarticle.isIndexable(), article.isSmallImage(),\n\t\t\t\t\tarticle.getSmallImageURL(), smallFile, images, articleURL,\n\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedArticle = JournalArticleLocalServiceUtil.addArticle(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(), folderId,\n\t\t\t\tarticle.getClassNameId(), ddmStructureId, articleId,\n\t\t\t\tautoArticleId, article.getVersion(), article.getTitleMap(),\n\t\t\t\tarticle.getDescriptionMap(), article.getContent(),\n\t\t\t\tarticle.getType(), parentDDMStructureKey, parentDDMTemplateKey,\n\t\t\t\tarticle.getLayoutUuid(), displayDateMonth, displayDateDay,\n\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\texpirationDateMonth, expirationDateDay, expirationDateYear,\n\t\t\t\texpirationDateHour, expirationDateMinute, neverExpire,\n\t\t\t\treviewDateMonth, reviewDateDay, reviewDateYear, reviewDateHour,\n\t\t\t\treviewDateMinute, neverReview, article.isIndexable(),\n\t\t\t\tarticle.isSmallImage(), article.getSmallImageURL(), smallFile,\n\t\t\t\timages, articleURL, serviceContext);\n\t\t}\n\n\t\tif (smallFile != null) {\n\t\t\tsmallFile.delete();\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tarticle, importedArticle, _NAMESPACE);\n\n\t\tif (Validator.isNull(newArticleId)) {\n\t\t\tarticleIds.put(\n\t\t\t\tarticle.getArticleId(), importedArticle.getArticleId());\n\t\t}\n\n\t\tif (!articleId.equals(importedArticle.getArticleId())) {\n\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t_log.warn(\n\t\t\t\t\t\"An article with the ID \" + articleId + \" already \" +\n\t\t\t\t\t\t\"exists. The new generated ID is \" +\n\t\t\t\t\t\t\timportedArticle.getArticleId());\n\t\t\t}\n\t\t}\n\t}","id":14998,"modified_method":"public static void importArticle(\n\t\t\tPortletDataContext portletDataContext, Element articleElement)\n\t\tthrows Exception {\n\n\t\tString path = articleElement.attributeValue(\"path\");\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\tJournalArticle article =\n\t\t\t(JournalArticle)portletDataContext.getZipEntryAsObject(\n\t\t\t\tarticleElement, path);\n\n\t\tprepareLanguagesForImport(article);\n\n\t\tlong userId = portletDataContext.getUserId(article.getUserUuid());\n\n\t\tJournalCreationStrategy creationStrategy =\n\t\t\tJournalCreationStrategyFactory.getInstance();\n\n\t\tlong authorId = creationStrategy.getAuthorUserId(\n\t\t\tportletDataContext, article);\n\n\t\tif (authorId != JournalCreationStrategy.USE_DEFAULT_USER_ID_STRATEGY) {\n\t\t\tuserId = authorId;\n\t\t}\n\n\t\tUser user = UserLocalServiceUtil.getUser(userId);\n\n\t\tMap<Long, Long> folderIds =\n\t\t\t(Map<Long, Long>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tJournalFolder.class);\n\n\t\tlong folderId = MapUtil.getLong(\n\t\t\tfolderIds, article.getFolderId(), article.getFolderId());\n\n\t\tif ((folderId != JournalFolderConstants.DEFAULT_PARENT_FOLDER_ID) &&\n\t\t\t(folderId == article.getFolderId())) {\n\n\t\t\tString folderPath = getImportFolderPath(\n\t\t\t\tportletDataContext, folderId);\n\n\t\t\tJournalFolder folder =\n\t\t\t\t(JournalFolder)portletDataContext.getZipEntryAsObject(\n\t\t\t\t\tfolderPath);\n\n\t\t\timportFolder(portletDataContext, folderPath, folder);\n\n\t\t\tfolderId = MapUtil.getLong(\n\t\t\t\tfolderIds, article.getFolderId(), article.getFolderId());\n\t\t}\n\n\t\tString articleId = article.getArticleId();\n\t\tboolean autoArticleId = false;\n\n\t\tif (Validator.isNumber(articleId) ||\n\t\t\t(JournalArticleUtil.fetchByG_A_V(\n\t\t\t\tportletDataContext.getScopeGroupId(), articleId,\n\t\t\t\tJournalArticleConstants.VERSION_DEFAULT) != null)) {\n\n\t\t\tautoArticleId = true;\n\t\t}\n\n\t\tMap<String, String> articleIds =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tJournalArticle.class + \".articleId\");\n\n\t\tString newArticleId = articleIds.get(articleId);\n\n\t\tif (Validator.isNotNull(newArticleId)) {\n\n\t\t\t// A sibling of a different version was already assigned a new\n\t\t\t// article id\n\n\t\t\tarticleId = newArticleId;\n\t\t\tautoArticleId = false;\n\t\t}\n\n\t\tString content = article.getContent();\n\n\t\tcontent = importReferencedContent(\n\t\t\tportletDataContext, articleElement, content);\n\n\t\tarticle.setContent(content);\n\n\t\tString newContent = creationStrategy.getTransformedContent(\n\t\t\tportletDataContext, article);\n\n\t\tif (newContent != JournalCreationStrategy.ARTICLE_CONTENT_UNCHANGED) {\n\t\t\tarticle.setContent(newContent);\n\t\t}\n\n\t\tMap<String, String> ddmStructureKeys =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMStructure.class);\n\n\t\tString parentDDMStructureKey = MapUtil.getString(\n\t\t\tddmStructureKeys, article.getStructureId(),\n\t\t\tarticle.getStructureId());\n\n\t\tMap<String, String> ddmTemplateKeys =\n\t\t\t(Map<String, String>)portletDataContext.getNewPrimaryKeysMap(\n\t\t\t\tDDMTemplate.class);\n\n\t\tString parentDDMTemplateKey = MapUtil.getString(\n\t\t\tddmTemplateKeys, article.getTemplateId(), article.getTemplateId());\n\n\t\tDate displayDate = article.getDisplayDate();\n\n\t\tint displayDateMonth = 0;\n\t\tint displayDateDay = 0;\n\t\tint displayDateYear = 0;\n\t\tint displayDateHour = 0;\n\t\tint displayDateMinute = 0;\n\n\t\tif (displayDate != null) {\n\t\t\tCalendar displayCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\tdisplayCal.setTime(displayDate);\n\n\t\t\tdisplayDateMonth = displayCal.get(Calendar.MONTH);\n\t\t\tdisplayDateDay = displayCal.get(Calendar.DATE);\n\t\t\tdisplayDateYear = displayCal.get(Calendar.YEAR);\n\t\t\tdisplayDateHour = displayCal.get(Calendar.HOUR);\n\t\t\tdisplayDateMinute = displayCal.get(Calendar.MINUTE);\n\n\t\t\tif (displayCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\tdisplayDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tDate expirationDate = article.getExpirationDate();\n\n\t\tint expirationDateMonth = 0;\n\t\tint expirationDateDay = 0;\n\t\tint expirationDateYear = 0;\n\t\tint expirationDateHour = 0;\n\t\tint expirationDateMinute = 0;\n\t\tboolean neverExpire = true;\n\n\t\tif (expirationDate != null) {\n\t\t\tCalendar expirationCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\texpirationCal.setTime(expirationDate);\n\n\t\t\texpirationDateMonth = expirationCal.get(Calendar.MONTH);\n\t\t\texpirationDateDay = expirationCal.get(Calendar.DATE);\n\t\t\texpirationDateYear = expirationCal.get(Calendar.YEAR);\n\t\t\texpirationDateHour = expirationCal.get(Calendar.HOUR);\n\t\t\texpirationDateMinute = expirationCal.get(Calendar.MINUTE);\n\t\t\tneverExpire = false;\n\n\t\t\tif (expirationCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\texpirationDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tDate reviewDate = article.getReviewDate();\n\n\t\tint reviewDateMonth = 0;\n\t\tint reviewDateDay = 0;\n\t\tint reviewDateYear = 0;\n\t\tint reviewDateHour = 0;\n\t\tint reviewDateMinute = 0;\n\t\tboolean neverReview = true;\n\n\t\tif (reviewDate != null) {\n\t\t\tCalendar reviewCal = CalendarFactoryUtil.getCalendar(\n\t\t\t\tuser.getTimeZone());\n\n\t\t\treviewCal.setTime(reviewDate);\n\n\t\t\treviewDateMonth = reviewCal.get(Calendar.MONTH);\n\t\t\treviewDateDay = reviewCal.get(Calendar.DATE);\n\t\t\treviewDateYear = reviewCal.get(Calendar.YEAR);\n\t\t\treviewDateHour = reviewCal.get(Calendar.HOUR);\n\t\t\treviewDateMinute = reviewCal.get(Calendar.MINUTE);\n\t\t\tneverReview = false;\n\n\t\t\tif (reviewCal.get(Calendar.AM_PM) == Calendar.PM) {\n\t\t\t\treviewDateHour += 12;\n\t\t\t}\n\t\t}\n\n\t\tlong ddmStructureId = 0;\n\n\t\tif (Validator.isNotNull(article.getStructureId())) {\n\t\t\tString ddmStructureUuid = articleElement.attributeValue(\n\t\t\t\t\"ddm-structure-uuid\");\n\n\t\t\tDDMStructure existingDDMStructure =\n\t\t\t\tDDMStructureUtil.fetchByUUID_G(\n\t\t\t\t\tddmStructureUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingDDMStructure == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\texistingDDMStructure = DDMStructureUtil.fetchByUUID_G(\n\t\t\t\t\tddmStructureUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tif (existingDDMStructure == null) {\n\t\t\t\tString newStructureId = ddmStructureKeys.get(\n\t\t\t\t\tarticle.getStructureId());\n\n\t\t\t\tif (Validator.isNotNull(newStructureId)) {\n\t\t\t\t\texistingDDMStructure = DDMStructureUtil.fetchByG_S(\n\t\t\t\t\t\tportletDataContext.getScopeGroupId(),\n\t\t\t\t\t\tString.valueOf(newStructureId));\n\t\t\t\t}\n\n\t\t\t\tif (existingDDMStructure == null) {\n\t\t\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t\t\tStringBundler sb = new StringBundler();\n\n\t\t\t\t\t\tsb.append(\"Structure \");\n\t\t\t\t\t\tsb.append(article.getStructureId());\n\t\t\t\t\t\tsb.append(\" is missing for article \");\n\t\t\t\t\t\tsb.append(article.getArticleId());\n\t\t\t\t\t\tsb.append(\", skipping this article.\");\n\n\t\t\t\t\t\t_log.warn(sb.toString());\n\t\t\t\t\t}\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tddmStructureId = existingDDMStructure.getStructureId();\n\n\t\t\tparentDDMStructureKey = existingDDMStructure.getStructureKey();\n\t\t}\n\n\t\tif (Validator.isNotNull(article.getTemplateId())) {\n\t\t\tString ddmTemplateUuid = articleElement.attributeValue(\n\t\t\t\t\"ddm-template-uuid\");\n\n\t\t\tDDMTemplate existingDDMTemplate =\n\t\t\t\tDDMTemplateUtil.fetchByUUID_G(\n\t\t\t\t\tddmTemplateUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\texistingDDMTemplate = DDMTemplateUtil.fetchByUUID_G(\n\t\t\t\t\tddmTemplateUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\tString newTemplateId = ddmTemplateKeys.get(\n\t\t\t\t\tarticle.getTemplateId());\n\n\t\t\t\tif (Validator.isNotNull(newTemplateId)) {\n\t\t\t\t\texistingDDMTemplate = DDMTemplateUtil.fetchByG_T(\n\t\t\t\t\t\tportletDataContext.getScopeGroupId(), newTemplateId);\n\t\t\t\t}\n\n\t\t\t\tif (existingDDMTemplate == null) {\n\t\t\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t\t\tStringBundler sb = new StringBundler();\n\n\t\t\t\t\t\tsb.append(\"Template \");\n\t\t\t\t\t\tsb.append(article.getTemplateId());\n\t\t\t\t\t\tsb.append(\" is missing for article \");\n\t\t\t\t\t\tsb.append(article.getArticleId());\n\t\t\t\t\t\tsb.append(\", skipping this article.\");\n\n\t\t\t\t\t\t_log.warn(sb.toString());\n\t\t\t\t\t}\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tparentDDMTemplateKey = existingDDMTemplate.getTemplateKey();\n\t\t}\n\n\t\tFile smallFile = null;\n\n\t\tif (article.isSmallImage()) {\n\t\t\tString smallImagePath = articleElement.attributeValue(\n\t\t\t\t\"small-image-path\");\n\n\t\t\tif (Validator.isNotNull(article.getSmallImageURL())) {\n\t\t\t\tString smallImageURL =\n\t\t\t\t\tJournalPortletDataHandlerImpl.importReferencedContent(\n\t\t\t\t\t\tportletDataContext, articleElement,\n\t\t\t\t\t\tarticle.getSmallImageURL());\n\n\t\t\t\tarticle.setSmallImageURL(smallImageURL);\n\t\t\t}\n\t\t\telse if (Validator.isNotNull(smallImagePath)) {\n\t\t\t\tbyte[] bytes = portletDataContext.getZipEntryAsByteArray(\n\t\t\t\t\tsmallImagePath);\n\n\t\t\t\tif (bytes != null) {\n\t\t\t\t\tsmallFile = FileUtil.createTempFile(\n\t\t\t\t\t\tarticle.getSmallImageType());\n\n\t\t\t\t\tFileUtil.write(smallFile, bytes);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMap<String, byte[]> images = new HashMap<String, byte[]>();\n\n\t\tString imagePath = articleElement.attributeValue(\"image-path\");\n\n\t\tif (portletDataContext.getBooleanParameter(_NAMESPACE, \"images\") &&\n\t\t\tValidator.isNotNull(imagePath)) {\n\n\t\t\tList<String> imageFiles = portletDataContext.getZipFolderEntries(\n\t\t\t\timagePath);\n\n\t\t\tfor (String imageFile : imageFiles) {\n\t\t\t\tString fileName = imageFile;\n\n\t\t\t\tif (fileName.contains(StringPool.SLASH)) {\n\t\t\t\t\tfileName = fileName.substring(\n\t\t\t\t\t\tfileName.lastIndexOf(CharPool.SLASH) + 1);\n\t\t\t\t}\n\n\t\t\t\tif (fileName.endsWith(\".xml\")) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint pos = fileName.lastIndexOf(CharPool.PERIOD);\n\n\t\t\t\tif (pos != -1) {\n\t\t\t\t\tfileName = fileName.substring(0, pos);\n\t\t\t\t}\n\n\t\t\t\timages.put(\n\t\t\t\t\tfileName,\n\t\t\t\t\tportletDataContext.getZipEntryAsByteArray(imageFile));\n\t\t\t}\n\t\t}\n\n\t\tString articleURL = null;\n\n\t\tboolean addGroupPermissions = creationStrategy.addGroupPermissions(\n\t\t\tportletDataContext, article);\n\t\tboolean addGuestPermissions = creationStrategy.addGuestPermissions(\n\t\t\tportletDataContext, article);\n\n\t\tServiceContext serviceContext = portletDataContext.createServiceContext(\n\t\t\tarticleElement, article, _NAMESPACE);\n\n\t\tserviceContext.setAddGroupPermissions(addGroupPermissions);\n\t\tserviceContext.setAddGuestPermissions(addGuestPermissions);\n\n\t\tif (article.getStatus() != WorkflowConstants.STATUS_APPROVED) {\n\t\t\tserviceContext.setWorkflowAction(\n\t\t\t\tWorkflowConstants.ACTION_SAVE_DRAFT);\n\t\t}\n\n\t\tJournalArticle importedArticle = null;\n\n\t\tString articleResourceUuid = articleElement.attributeValue(\n\t\t\t\"article-resource-uuid\");\n\n\t\tif (portletDataContext.isDataStrategyMirror()) {\n\t\t\tJournalArticleResource articleResource =\n\t\t\t\tJournalArticleResourceUtil.fetchByUUID_G(\n\t\t\t\t\tarticleResourceUuid, portletDataContext.getScopeGroupId());\n\n\t\t\tif (articleResource == null) {\n\t\t\t\tGroup companyGroup = GroupLocalServiceUtil.getCompanyGroup(\n\t\t\t\t\tportletDataContext.getCompanyId());\n\n\t\t\t\tlong companyGroupId = companyGroup.getGroupId();\n\n\t\t\t\tarticleResource = JournalArticleResourceUtil.fetchByUUID_G(\n\t\t\t\t\tarticleResourceUuid, companyGroupId);\n\t\t\t}\n\n\t\t\tserviceContext.setUuid(articleResourceUuid);\n\t\t\tserviceContext.setAttribute(\"urlTitle\", article.getUrlTitle());\n\n\t\t\tJournalArticle existingArticle = null;\n\n\t\t\tif (articleResource != null) {\n\t\t\t\ttry {\n\t\t\t\t\texistingArticle =\n\t\t\t\t\t\tJournalArticleLocalServiceUtil.getLatestArticle(\n\t\t\t\t\t\t\tarticleResource.getResourcePrimKey(),\n\t\t\t\t\t\t\tWorkflowConstants.STATUS_ANY, false);\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchArticleException nsae) {\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (existingArticle == null) {\n\t\t\t\texistingArticle = JournalArticleUtil.fetchByG_A_V(\n\t\t\t\t\tportletDataContext.getScopeGroupId(), newArticleId,\n\t\t\t\t\tarticle.getVersion());\n\t\t\t}\n\n\t\t\tif (existingArticle == null) {\n\t\t\t\timportedArticle = JournalArticleLocalServiceUtil.addArticle(\n\t\t\t\t\tuserId, portletDataContext.getScopeGroupId(), folderId,\n\t\t\t\t\tarticle.getClassNameId(), ddmStructureId, articleId,\n\t\t\t\t\tautoArticleId, article.getVersion(), article.getTitleMap(),\n\t\t\t\t\tarticle.getDescriptionMap(), article.getContent(),\n\t\t\t\t\tarticle.getType(), parentDDMStructureKey,\n\t\t\t\t\tparentDDMTemplateKey, article.getLayoutUuid(),\n\t\t\t\t\tdisplayDateMonth, displayDateDay, displayDateYear,\n\t\t\t\t\tdisplayDateHour, displayDateMinute, expirationDateMonth,\n\t\t\t\t\texpirationDateDay, expirationDateYear, expirationDateHour,\n\t\t\t\t\texpirationDateMinute, neverExpire, reviewDateMonth,\n\t\t\t\t\treviewDateDay, reviewDateYear, reviewDateHour,\n\t\t\t\t\treviewDateMinute, neverReview, article.isIndexable(),\n\t\t\t\t\tarticle.isSmallImage(), article.getSmallImageURL(),\n\t\t\t\t\tsmallFile, images, articleURL, serviceContext);\n\t\t\t}\n\t\t\telse {\n\t\t\t\timportedArticle = JournalArticleLocalServiceUtil.updateArticle(\n\t\t\t\t\tuserId, existingArticle.getGroupId(), folderId,\n\t\t\t\t\texistingArticle.getArticleId(), article.getVersion(),\n\t\t\t\t\tarticle.getTitleMap(), article.getDescriptionMap(),\n\t\t\t\t\tarticle.getContent(), article.getType(),\n\t\t\t\t\tparentDDMStructureKey, parentDDMTemplateKey,\n\t\t\t\t\tarticle.getLayoutUuid(), displayDateMonth, displayDateDay,\n\t\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\t\texpirationDateMonth, expirationDateDay, expirationDateYear,\n\t\t\t\t\texpirationDateHour, expirationDateMinute, neverExpire,\n\t\t\t\t\treviewDateMonth, reviewDateDay, reviewDateYear,\n\t\t\t\t\treviewDateHour, reviewDateMinute, neverReview,\n\t\t\t\t\tarticle.isIndexable(), article.isSmallImage(),\n\t\t\t\t\tarticle.getSmallImageURL(), smallFile, images, articleURL,\n\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\timportedArticle = JournalArticleLocalServiceUtil.addArticle(\n\t\t\t\tuserId, portletDataContext.getScopeGroupId(), folderId,\n\t\t\t\tarticle.getClassNameId(), ddmStructureId, articleId,\n\t\t\t\tautoArticleId, article.getVersion(), article.getTitleMap(),\n\t\t\t\tarticle.getDescriptionMap(), article.getContent(),\n\t\t\t\tarticle.getType(), parentDDMStructureKey, parentDDMTemplateKey,\n\t\t\t\tarticle.getLayoutUuid(), displayDateMonth, displayDateDay,\n\t\t\t\tdisplayDateYear, displayDateHour, displayDateMinute,\n\t\t\t\texpirationDateMonth, expirationDateDay, expirationDateYear,\n\t\t\t\texpirationDateHour, expirationDateMinute, neverExpire,\n\t\t\t\treviewDateMonth, reviewDateDay, reviewDateYear, reviewDateHour,\n\t\t\t\treviewDateMinute, neverReview, article.isIndexable(),\n\t\t\t\tarticle.isSmallImage(), article.getSmallImageURL(), smallFile,\n\t\t\t\timages, articleURL, serviceContext);\n\t\t}\n\n\t\tif (smallFile != null) {\n\t\t\tsmallFile.delete();\n\t\t}\n\n\t\tportletDataContext.importClassedModel(\n\t\t\tarticle, importedArticle, _NAMESPACE);\n\n\t\tif (Validator.isNull(newArticleId)) {\n\t\t\tarticleIds.put(\n\t\t\t\tarticle.getArticleId(), importedArticle.getArticleId());\n\t\t}\n\n\t\tif (!articleId.equals(importedArticle.getArticleId())) {\n\t\t\tif (_log.isWarnEnabled()) {\n\t\t\t\t_log.warn(\n\t\t\t\t\t\"An article with the ID \" + articleId + \" already \" +\n\t\t\t\t\t\t\"exists. The new generated ID is \" +\n\t\t\t\t\t\t\timportedArticle.getArticleId());\n\t\t\t}\n\t\t}\n\t}","commit_id":"47dfe9fabfc5660b00214114005f4beb7460cb1c","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void exportArticle(\n\t\t\tPortletDataContext portletDataContext, Element articlesElement,\n\t\t\tElement ddmStructuresElement, Element ddmTemplatesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tJournalArticle article, boolean checkDateRange)\n\t\tthrows Exception {\n\n\t\tif (checkDateRange &&\n\t\t\t!portletDataContext.isWithinDateRange(article.getModifiedDate())) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tif ((article.getStatus() != WorkflowConstants.STATUS_APPROVED) &&\n\t\t\t(article.getStatus() != WorkflowConstants.STATUS_EXPIRED)) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tString path = getArticlePath(portletDataContext, article);\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this article to make sure changes to its content are never\n\t\t// persisted\n\n\t\tarticle = (JournalArticle)article.clone();\n\n\t\tElement articleElement = (Element)articlesElement.selectSingleNode(\n\t\t\t\"//article[@path='\".concat(path).concat(\"']\"));\n\n\t\tif (articleElement == null) {\n\t\t\tarticleElement = articlesElement.addElement(\"article\");\n\t\t}\n\n\t\tarticleElement.addAttribute(\n\t\t\t\"article-resource-uuid\", article.getArticleResourceUuid());\n\n\t\tif (Validator.isNotNull(article.getStructureId())) {\n\t\t\tDDMStructure ddmStructure =\n\t\t\t\tDDMStructureLocalServiceUtil.getStructure(\n\t\t\t\t\tarticle.getGroupId(), article.getStructureId(), true);\n\n\t\t\tarticleElement.addAttribute(\n\t\t\t\t\"ddm-structure-uuid\", ddmStructure.getUuid());\n\n\t\t\tString ddmStructurePath = getDDMStructurePath(\n\t\t\t\tportletDataContext, ddmStructure.getUuid());\n\n\t\t\tDDMPortletDataHandlerImpl.exportStructure(\n\t\t\t\tportletDataContext, ddmStructuresElement, ddmStructurePath,\n\t\t\t\tddmStructure);\n\t\t}\n\n\t\tif (Validator.isNotNull(article.getTemplateId())) {\n\t\t\tDDMTemplate ddmTemplate =\n\t\t\t\tDDMTemplateLocalServiceUtil.getTemplate(\n\t\t\t\t\tarticle.getGroupId(), article.getTemplateId(), true);\n\n\t\t\tarticleElement.addAttribute(\n\t\t\t\t\"ddm-template-uuid\", ddmTemplate.getUuid());\n\n\t\t\tString ddmTemplatePath = getDDMTemplatePath(\n\t\t\t\tportletDataContext, ddmTemplate);\n\n\t\t\tDDMPortletDataHandlerImpl.exportTemplate(\n\t\t\t\tportletDataContext, ddmTemplatesElement,\n\t\t\t\tdlFileEntryTypesElement, dlFoldersElement, dlFileEntriesElement,\n\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, ddmTemplatePath, ddmTemplate);\n\t\t}\n\n\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(\n\t\t\tarticle.getSmallImageId());\n\n\t\tif (article.isSmallImage() && (smallImage != null)) {\n\t\t\tString smallImagePath = getArticleSmallImagePath(\n\t\t\t\tportletDataContext, article);\n\n\t\t\tarticleElement.addAttribute(\"small-image-path\", smallImagePath);\n\n\t\t\tarticle.setSmallImageType(smallImage.getType());\n\n\t\t\tportletDataContext.addZipEntry(\n\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t}\n\n\t\tif (portletDataContext.getBooleanParameter(_NAMESPACE, \"images\")) {\n\t\t\tString imagePath = getArticleImagePath(portletDataContext, article);\n\n\t\t\tarticleElement.addAttribute(\"image-path\", imagePath);\n\n\t\t\tList<JournalArticleImage> articleImages =\n\t\t\t\tJournalArticleImageUtil.findByG_A_V(\n\t\t\t\t\tarticle.getGroupId(), article.getArticleId(),\n\t\t\t\t\tarticle.getVersion());\n\n\t\t\tfor (JournalArticleImage articleImage : articleImages) {\n\t\t\t\tImage image = null;\n\n\t\t\t\ttry {\n\t\t\t\t\timage = ImageUtil.findByPrimaryKey(\n\t\t\t\t\t\tarticleImage.getArticleImageId());\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchImageException nsie) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (image.getTextObj() == null) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tString articleImagePath = getArticleImagePath(\n\t\t\t\t\tportletDataContext, article, articleImage, image);\n\n\t\t\t\tif (!portletDataContext.isPathNotProcessed(articleImagePath)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tarticleImagePath, image.getTextObj());\n\t\t\t}\n\t\t}\n\n\t\tarticle.setStatusByUserUuid(article.getStatusByUserUuid());\n\n\t\tif (portletDataContext.getBooleanParameter(\n\t\t\t\t_NAMESPACE, \"embedded-assets\")) {\n\n\t\t\tString content = DDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, articleElement,\n\t\t\t\tarticle.getContent());\n\n\t\t\tarticle.setContent(content);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tarticleElement, path, article, _NAMESPACE);\n\t}","id":14999,"modified_method":"public static void exportArticle(\n\t\t\tPortletDataContext portletDataContext, Element articlesElement,\n\t\t\tElement ddmStructuresElement, Element ddmTemplatesElement,\n\t\t\tElement dlFileEntryTypesElement, Element dlFoldersElement,\n\t\t\tElement dlFileEntriesElement, Element dlFileRanksElement,\n\t\t\tElement dlRepositoriesElement, Element dlRepositoryEntriesElement,\n\t\t\tJournalArticle article, boolean checkDateRange)\n\t\tthrows Exception {\n\n\t\tif (checkDateRange &&\n\t\t\t!portletDataContext.isWithinDateRange(article.getModifiedDate())) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tif ((article.getStatus() != WorkflowConstants.STATUS_APPROVED) &&\n\t\t\t(article.getStatus() != WorkflowConstants.STATUS_EXPIRED)) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tString path = getArticlePath(portletDataContext, article);\n\n\t\tif (!portletDataContext.isPathNotProcessed(path)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Clone this article to make sure changes to its content are never\n\t\t// persisted\n\n\t\tarticle = (JournalArticle)article.clone();\n\n\t\tElement articleElement = (Element)articlesElement.selectSingleNode(\n\t\t\t\"//article[@path='\".concat(path).concat(\"']\"));\n\n\t\tif (articleElement == null) {\n\t\t\tarticleElement = articlesElement.addElement(\"article\");\n\t\t}\n\n\t\tarticleElement.addAttribute(\n\t\t\t\"article-resource-uuid\", article.getArticleResourceUuid());\n\n\t\tif (Validator.isNotNull(article.getStructureId())) {\n\t\t\tDDMStructure ddmStructure =\n\t\t\t\tDDMStructureLocalServiceUtil.getStructure(\n\t\t\t\t\tarticle.getGroupId(), article.getStructureId(), true);\n\n\t\t\tarticleElement.addAttribute(\n\t\t\t\t\"ddm-structure-uuid\", ddmStructure.getUuid());\n\n\t\t\tString ddmStructurePath = getDDMStructurePath(\n\t\t\t\tportletDataContext, ddmStructure.getUuid());\n\n\t\t\tDDMPortletDataHandlerImpl.exportStructure(\n\t\t\t\tportletDataContext, ddmStructuresElement, ddmStructurePath,\n\t\t\t\tddmStructure);\n\t\t}\n\n\t\tif (Validator.isNotNull(article.getTemplateId())) {\n\t\t\tDDMTemplate ddmTemplate =\n\t\t\t\tDDMTemplateLocalServiceUtil.getTemplate(\n\t\t\t\t\tarticle.getGroupId(), article.getTemplateId(), true);\n\n\t\t\tarticleElement.addAttribute(\n\t\t\t\t\"ddm-template-uuid\", ddmTemplate.getUuid());\n\n\t\t\tString ddmTemplatePath = getDDMTemplatePath(\n\t\t\t\tportletDataContext, ddmTemplate);\n\n\t\t\tDDMPortletDataHandlerImpl.exportTemplate(\n\t\t\t\tportletDataContext, ddmTemplatesElement,\n\t\t\t\tdlFileEntryTypesElement, dlFoldersElement, dlFileEntriesElement,\n\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, ddmTemplatePath, ddmTemplate);\n\t\t}\n\n\t\tif (article.isSmallImage()) {\n\t\t\tImage smallImage = ImageUtil.fetchByPrimaryKey(\n\t\t\t\tarticle.getSmallImageId());\n\n\t\t\tif (Validator.isNotNull(article.getSmallImageURL())) {\n\t\t\t\tString smallImageURL =\n\t\t\t\t\tDDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\t\t\t\tportletDataContext, dlFileEntryTypesElement,\n\t\t\t\t\t\tdlFoldersElement, dlFileEntriesElement,\n\t\t\t\t\t\tdlFileRanksElement, dlRepositoriesElement,\n\t\t\t\t\t\tdlRepositoryEntriesElement, articleElement,\n\t\t\t\t\t\tarticle.getSmallImageURL().concat(StringPool.SPACE));\n\n\t\t\t\tarticle.setSmallImageURL(smallImageURL);\n\t\t\t}\n\t\t\telse if (smallImage != null) {\n\t\t\t\tString smallImagePath = getArticleSmallImagePath(\n\t\t\t\t\tportletDataContext, article);\n\n\t\t\t\tarticleElement.addAttribute(\"small-image-path\", smallImagePath);\n\n\t\t\t\tarticle.setSmallImageType(smallImage.getType());\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tsmallImagePath, smallImage.getTextObj());\n\t\t\t}\n\n\t\t}\n\n\t\tif (portletDataContext.getBooleanParameter(_NAMESPACE, \"images\")) {\n\t\t\tString imagePath = getArticleImagePath(portletDataContext, article);\n\n\t\t\tarticleElement.addAttribute(\"image-path\", imagePath);\n\n\t\t\tList<JournalArticleImage> articleImages =\n\t\t\t\tJournalArticleImageUtil.findByG_A_V(\n\t\t\t\t\tarticle.getGroupId(), article.getArticleId(),\n\t\t\t\t\tarticle.getVersion());\n\n\t\t\tfor (JournalArticleImage articleImage : articleImages) {\n\t\t\t\tImage image = null;\n\n\t\t\t\ttry {\n\t\t\t\t\timage = ImageUtil.findByPrimaryKey(\n\t\t\t\t\t\tarticleImage.getArticleImageId());\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchImageException nsie) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (image.getTextObj() == null) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tString articleImagePath = getArticleImagePath(\n\t\t\t\t\tportletDataContext, article, articleImage, image);\n\n\t\t\t\tif (!portletDataContext.isPathNotProcessed(articleImagePath)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tportletDataContext.addZipEntry(\n\t\t\t\t\tarticleImagePath, image.getTextObj());\n\t\t\t}\n\t\t}\n\n\t\tarticle.setStatusByUserUuid(article.getStatusByUserUuid());\n\n\t\tif (portletDataContext.getBooleanParameter(\n\t\t\t\t_NAMESPACE, \"embedded-assets\")) {\n\n\t\t\tString content = DDMPortletDataHandlerImpl.exportReferencedContent(\n\t\t\t\tportletDataContext, dlFileEntryTypesElement, dlFoldersElement,\n\t\t\t\tdlFileEntriesElement, dlFileRanksElement, dlRepositoriesElement,\n\t\t\t\tdlRepositoryEntriesElement, articleElement,\n\t\t\t\tarticle.getContent());\n\n\t\t\tarticle.setContent(content);\n\t\t}\n\n\t\tportletDataContext.addClassedModel(\n\t\t\tarticleElement, path, article, _NAMESPACE);\n\t}","commit_id":"47dfe9fabfc5660b00214114005f4beb7460cb1c","url":"https://github.com/liferay/liferay-portal"}]