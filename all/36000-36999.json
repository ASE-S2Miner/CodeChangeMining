[{"original_method":"private void printMetadataContent(ParseContext.Document doc, String field) {\n        logger.debug(\"- [{}]: [{}]\", field, doc.get(docMapper.mappers().getMapper(\"file.\" + field).names().indexName()));\n    }","id":36000,"modified_method":"private void printMetadataContent(ParseContext.Document doc, String field) {\n        logger.debug(\"- [{}]: [{}]\", field, doc.get(docMapper.mappers().getMapper(\"file.\" + field).fieldType().names().indexName()));\n    }","commit_id":"f743ebb87f3a9685d6358b69c2e9227fa7d45bc9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected void testMapper(String filename, boolean errorExpected) throws IOException {\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/attachment/test/sample-files/\" + filename);\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .startObject(\"file\")\n                        .field(\"_name\", filename)\n                        .field(\"_content\", html)\n                    .endObject()\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(\"person\", \"1\", json).rootDoc();\n        if (!errorExpected) {\n            assertThat(doc.get(docMapper.mappers().getMapper(\"file.content\").names().indexName()), not(isEmptyOrNullString()));\n            logger.debug(\"-> extracted content: {}\", doc.get(docMapper.mappers().getMapper(\"file\").names().indexName()));\n            logger.debug(\"-> extracted metadata:\");\n            printMetadataContent(doc, AUTHOR);\n            printMetadataContent(doc, CONTENT_LENGTH);\n            printMetadataContent(doc, CONTENT_TYPE);\n            printMetadataContent(doc, DATE);\n            printMetadataContent(doc, KEYWORDS);\n            printMetadataContent(doc, LANGUAGE);\n            printMetadataContent(doc, NAME);\n            printMetadataContent(doc, TITLE);\n        }\n    }","id":36001,"modified_method":"protected void testMapper(String filename, boolean errorExpected) throws IOException {\n        byte[] html = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/attachment/test/sample-files/\" + filename);\n\n        BytesReference json = jsonBuilder()\n                .startObject()\n                    .startObject(\"file\")\n                        .field(\"_name\", filename)\n                        .field(\"_content\", html)\n                    .endObject()\n                .endObject().bytes();\n\n        ParseContext.Document doc =  docMapper.parse(\"person\", \"1\", json).rootDoc();\n        if (!errorExpected) {\n            assertThat(doc.get(docMapper.mappers().getMapper(\"file.content\").fieldType().names().indexName()), not(isEmptyOrNullString()));\n            logger.debug(\"-> extracted content: {}\", doc.get(docMapper.mappers().getMapper(\"file\").fieldType().names().indexName()));\n            logger.debug(\"-> extracted metadata:\");\n            printMetadataContent(doc, AUTHOR);\n            printMetadataContent(doc, CONTENT_LENGTH);\n            printMetadataContent(doc, CONTENT_TYPE);\n            printMetadataContent(doc, DATE);\n            printMetadataContent(doc, KEYWORDS);\n            printMetadataContent(doc, LANGUAGE);\n            printMetadataContent(doc, NAME);\n            printMetadataContent(doc, TITLE);\n        }\n    }","commit_id":"f743ebb87f3a9685d6358b69c2e9227fa7d45bc9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@NotNull\n    private TraitImplDelegateInfo getTraitImplDelegateInfo(@NotNull FunctionDescriptor fun) {\n        if (fun instanceof PropertyAccessorDescriptor) {\n            PropertyDescriptor property = ((PropertyAccessorDescriptor) fun).getCorrespondingProperty();\n            PropertyDescriptor original = property.getOriginal();\n            if (fun instanceof PropertyGetterDescriptor) {\n                JvmPropertyAccessorSignature toGenerate = typeMapper.mapGetterSignature(property, OwnerKind.IMPLEMENTATION);\n                JvmPropertyAccessorSignature inTrait = typeMapper.mapGetterSignature(original, OwnerKind.IMPLEMENTATION);\n                return new TraitImplDelegateInfo(\n                        toGenerate.getJvmMethodSignature().getAsmMethod(), inTrait.getJvmMethodSignature().getAsmMethod());\n            }\n            else if (fun instanceof PropertySetterDescriptor) {\n                JvmPropertyAccessorSignature toGenerate = typeMapper.mapSetterSignature(property, OwnerKind.IMPLEMENTATION);\n                JvmPropertyAccessorSignature inTrait = typeMapper.mapSetterSignature(original, OwnerKind.IMPLEMENTATION);\n                return new TraitImplDelegateInfo(\n                        toGenerate.getJvmMethodSignature().getAsmMethod(), inTrait.getJvmMethodSignature().getAsmMethod());\n            }\n            else {\n                throw new IllegalStateException(\"Accessor is neither getter, nor setter, what is it? \" + fun);\n            }\n        }\n        else {\n            Method function = typeMapper.mapSignature(fun).getAsmMethod();\n            Method functionOriginal = typeMapper.mapSignature(fun.getOriginal()).getAsmMethod();\n            return new TraitImplDelegateInfo(function, functionOriginal);\n        }\n    }","id":36002,"modified_method":"@NotNull\n    private TraitImplDelegateInfo getTraitImplDelegateInfo(@NotNull FunctionDescriptor fun) {\n        if (fun instanceof PropertyAccessorDescriptor) {\n            PropertyDescriptor property = ((PropertyAccessorDescriptor) fun).getCorrespondingProperty();\n            PropertyDescriptor original = property.getOriginal();\n            if (fun instanceof PropertyGetterDescriptor) {\n                JvmPropertyAccessorSignature toGenerate = typeMapper.mapGetterSignature(property, OwnerKind.IMPLEMENTATION);\n                JvmPropertyAccessorSignature inTrait = typeMapper.mapGetterSignature(original, OwnerKind.IMPLEMENTATION);\n                return new TraitImplDelegateInfo(\n                        toGenerate.getAsmMethod(), inTrait.getAsmMethod());\n            }\n            else if (fun instanceof PropertySetterDescriptor) {\n                JvmPropertyAccessorSignature toGenerate = typeMapper.mapSetterSignature(property, OwnerKind.IMPLEMENTATION);\n                JvmPropertyAccessorSignature inTrait = typeMapper.mapSetterSignature(original, OwnerKind.IMPLEMENTATION);\n                return new TraitImplDelegateInfo(\n                        toGenerate.getAsmMethod(), inTrait.getAsmMethod());\n            }\n            else {\n                throw new IllegalStateException(\"Accessor is neither getter, nor setter, what is it? \" + fun);\n            }\n        }\n        else {\n            Method function = typeMapper.mapSignature(fun).getAsmMethod();\n            Method functionOriginal = typeMapper.mapSignature(fun.getOriginal()).getAsmMethod();\n            return new TraitImplDelegateInfo(function, functionOriginal);\n        }\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private Type genPropertyOnStack(InstructionAdapter iv, PropertyDescriptor propertyDescriptor, int index) {\n        iv.load(index, classAsmType);\n        Method\n                method = typeMapper.mapGetterSignature(propertyDescriptor, OwnerKind.IMPLEMENTATION).getJvmMethodSignature().getAsmMethod();\n\n        iv.invokevirtual(classAsmType.getInternalName(), method.getName(), method.getDescriptor());\n        return method.getReturnType();\n    }","id":36003,"modified_method":"private Type genPropertyOnStack(InstructionAdapter iv, PropertyDescriptor propertyDescriptor, int index) {\n        iv.load(index, classAsmType);\n        Method\n                method = typeMapper.mapGetterSignature(propertyDescriptor, OwnerKind.IMPLEMENTATION).getAsmMethod();\n\n        iv.invokevirtual(classAsmType.getInternalName(), method.getName(), method.getDescriptor());\n        return method.getReturnType();\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void genAccessor(Map.Entry<DeclarationDescriptor, DeclarationDescriptor> entry) {\n        if (entry.getValue() instanceof FunctionDescriptor) {\n            FunctionDescriptor bridge = (FunctionDescriptor) entry.getValue();\n            FunctionDescriptor original = (FunctionDescriptor) entry.getKey();\n\n            Method method = typeMapper.mapSignature(bridge).getAsmMethod();\n            boolean isConstructor = original instanceof ConstructorDescriptor;\n            Method originalMethod = isConstructor ?\n                                    typeMapper.mapToCallableMethod((ConstructorDescriptor) original).getSignature().getAsmMethod() :\n                                    typeMapper.mapSignature(original).getAsmMethod();\n            Type[] argTypes = method.getArgumentTypes();\n\n            String owner = typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isCallInsideSameModuleAsDeclared(original, context)).getInternalName();\n            MethodVisitor mv = v.newMethod(null, ACC_BRIDGE | ACC_SYNTHETIC | ACC_STATIC, bridge.getName().getName(),\n                                           method.getDescriptor(), null, null);\n            if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                genStubCode(mv);\n            }\n            else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                mv.visitCode();\n\n                InstructionAdapter iv = new InstructionAdapter(mv);\n\n                if (isConstructor) {\n                    iv.anew(method.getReturnType());\n                    iv.dup();\n                }\n                else {\n                    // todo: note that for now we never have access bridges for namespace methods, if at some point we do...\n                    iv.load(0, OBJECT_TYPE);\n                }\n\n                for (int i = isConstructor ? 0 : 1, reg = isConstructor ? 0 : 1; i < argTypes.length; i++) {\n                    Type argType = argTypes[i];\n                    iv.load(reg, argType);\n                    //noinspection AssignmentToForLoopParameter\n                    reg += argType.getSize();\n                }\n                iv.invokespecial(owner, originalMethod.getName(), originalMethod.getDescriptor());\n\n                iv.areturn(method.getReturnType());\n                FunctionCodegen.endVisit(iv, \"accessor\", null);\n            }\n        }\n        else if (entry.getValue() instanceof PropertyDescriptor) {\n            PropertyDescriptor bridge = (PropertyDescriptor) entry.getValue();\n            PropertyDescriptor original = (PropertyDescriptor) entry.getKey();\n\n            {\n                Method method = typeMapper.mapGetterSignature(bridge, OwnerKind.IMPLEMENTATION).getJvmMethodSignature().getAsmMethod();\n                JvmPropertyAccessorSignature originalSignature = typeMapper.mapGetterSignature(original, OwnerKind.IMPLEMENTATION);\n                Method originalMethod = originalSignature.getJvmMethodSignature().getAsmMethod();\n                MethodVisitor mv =\n                        v.newMethod(null, ACC_BRIDGE | ACC_SYNTHETIC | ACC_STATIC, method.getName(), method.getDescriptor(), null, null);\n                PropertyGetterDescriptor getter = bridge.getGetter();\n                assert getter != null;\n                PropertyCodegen.generateJetPropertyAnnotation(mv,\n                                                              originalSignature,\n                                                              original,\n                                                              getter.getVisibility());\n                if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                    genStubCode(mv);\n                }\n                else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                    mv.visitCode();\n\n                    InstructionAdapter iv = new InstructionAdapter(mv);\n\n                    iv.load(0, OBJECT_TYPE);\n                    boolean hasBackingField = Boolean.TRUE.equals(bindingContext.get(BindingContext.BACKING_FIELD_REQUIRED, original));\n                    boolean isInsideModule = isCallInsideSameModuleAsDeclared(original, context);\n                    if (original.getVisibility() == Visibilities.PRIVATE && hasBackingField) {\n                        iv.getfield(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(), original.getName().getName(),\n                                    originalMethod.getReturnType().getDescriptor());\n                    }\n                    else {\n                        iv.invokespecial(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(),\n                                         originalMethod.getName(), originalMethod.getDescriptor());\n                    }\n\n                    iv.areturn(method.getReturnType());\n                    FunctionCodegen.endVisit(iv, \"accessor\", null);\n                }\n            }\n\n            if (bridge.isVar()) {\n                Method method = typeMapper.mapSetterSignature(bridge, OwnerKind.IMPLEMENTATION).getJvmMethodSignature().getAsmMethod();\n                JvmPropertyAccessorSignature originalSignature2 = typeMapper.mapSetterSignature(original, OwnerKind.IMPLEMENTATION);\n                Method originalMethod = originalSignature2.getJvmMethodSignature().getAsmMethod();\n                MethodVisitor mv =\n                        v.newMethod(null, ACC_STATIC | ACC_BRIDGE | ACC_FINAL, method.getName(), method.getDescriptor(), null, null);\n                PropertySetterDescriptor setter = bridge.getSetter();\n                assert setter != null;\n                PropertyCodegen.generateJetPropertyAnnotation(mv,\n                                                              originalSignature2,\n                                                              original,\n                                                              setter.getVisibility());\n                if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                    genStubCode(mv);\n                }\n                else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                    mv.visitCode();\n\n                    InstructionAdapter iv = new InstructionAdapter(mv);\n\n                    iv.load(0, OBJECT_TYPE);\n                    Type[] argTypes = method.getArgumentTypes();\n                    for (int i = 1, reg = 1; i < argTypes.length; i++) {\n                        Type argType = argTypes[i];\n                        iv.load(reg, argType);\n                        //noinspection AssignmentToForLoopParameter\n                        reg += argType.getSize();\n                    }\n                    boolean isInsideModule = isCallInsideSameModuleAsDeclared(original, context);\n                    if (original.getVisibility() == Visibilities.PRIVATE && original.getModality() == Modality.FINAL) {\n                        iv.putfield(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(), original.getName().getName(),\n                                    originalMethod.getArgumentTypes()[0].getDescriptor());\n                    }\n                    else {\n                        iv.invokespecial(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(),\n                                         originalMethod.getName(), originalMethod.getDescriptor());\n                    }\n\n                    iv.areturn(method.getReturnType());\n                    FunctionCodegen.endVisit(iv, \"accessor\", null);\n                }\n            }\n        }\n        else {\n            throw new UnsupportedOperationException();\n        }\n    }","id":36004,"modified_method":"private void genAccessor(Map.Entry<DeclarationDescriptor, DeclarationDescriptor> entry) {\n        if (entry.getValue() instanceof FunctionDescriptor) {\n            FunctionDescriptor bridge = (FunctionDescriptor) entry.getValue();\n            FunctionDescriptor original = (FunctionDescriptor) entry.getKey();\n\n            Method method = typeMapper.mapSignature(bridge).getAsmMethod();\n            boolean isConstructor = original instanceof ConstructorDescriptor;\n            Method originalMethod = isConstructor ?\n                                    typeMapper.mapToCallableMethod((ConstructorDescriptor) original).getSignature().getAsmMethod() :\n                                    typeMapper.mapSignature(original).getAsmMethod();\n            Type[] argTypes = method.getArgumentTypes();\n\n            String owner = typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isCallInsideSameModuleAsDeclared(original, context)).getInternalName();\n            MethodVisitor mv = v.newMethod(null, ACC_BRIDGE | ACC_SYNTHETIC | ACC_STATIC, bridge.getName().getName(),\n                                           method.getDescriptor(), null, null);\n            if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                genStubCode(mv);\n            }\n            else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                mv.visitCode();\n\n                InstructionAdapter iv = new InstructionAdapter(mv);\n\n                if (isConstructor) {\n                    iv.anew(method.getReturnType());\n                    iv.dup();\n                }\n                else {\n                    // todo: note that for now we never have access bridges for namespace methods, if at some point we do...\n                    iv.load(0, OBJECT_TYPE);\n                }\n\n                for (int i = isConstructor ? 0 : 1, reg = isConstructor ? 0 : 1; i < argTypes.length; i++) {\n                    Type argType = argTypes[i];\n                    iv.load(reg, argType);\n                    //noinspection AssignmentToForLoopParameter\n                    reg += argType.getSize();\n                }\n                iv.invokespecial(owner, originalMethod.getName(), originalMethod.getDescriptor());\n\n                iv.areturn(method.getReturnType());\n                FunctionCodegen.endVisit(iv, \"accessor\", null);\n            }\n        }\n        else if (entry.getValue() instanceof PropertyDescriptor) {\n            PropertyDescriptor bridge = (PropertyDescriptor) entry.getValue();\n            PropertyDescriptor original = (PropertyDescriptor) entry.getKey();\n\n            {\n                Method method = typeMapper.mapGetterSignature(bridge, OwnerKind.IMPLEMENTATION).getAsmMethod();\n                JvmPropertyAccessorSignature originalSignature = typeMapper.mapGetterSignature(original, OwnerKind.IMPLEMENTATION);\n                Method originalMethod = originalSignature.getAsmMethod();\n                MethodVisitor mv =\n                        v.newMethod(null, ACC_BRIDGE | ACC_SYNTHETIC | ACC_STATIC, method.getName(), method.getDescriptor(), null, null);\n                PropertyGetterDescriptor getter = bridge.getGetter();\n                assert getter != null;\n                PropertyCodegen.generateJetPropertyAnnotation(mv,\n                                                              originalSignature,\n                                                              original,\n                                                              getter.getVisibility());\n                if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                    genStubCode(mv);\n                }\n                else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                    mv.visitCode();\n\n                    InstructionAdapter iv = new InstructionAdapter(mv);\n\n                    iv.load(0, OBJECT_TYPE);\n                    boolean hasBackingField = Boolean.TRUE.equals(bindingContext.get(BindingContext.BACKING_FIELD_REQUIRED, original));\n                    boolean isInsideModule = isCallInsideSameModuleAsDeclared(original, context);\n                    if (original.getVisibility() == Visibilities.PRIVATE && hasBackingField) {\n                        iv.getfield(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(), original.getName().getName(),\n                                    originalMethod.getReturnType().getDescriptor());\n                    }\n                    else {\n                        iv.invokespecial(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(),\n                                         originalMethod.getName(), originalMethod.getDescriptor());\n                    }\n\n                    iv.areturn(method.getReturnType());\n                    FunctionCodegen.endVisit(iv, \"accessor\", null);\n                }\n            }\n\n            if (bridge.isVar()) {\n                Method method = typeMapper.mapSetterSignature(bridge, OwnerKind.IMPLEMENTATION).getAsmMethod();\n                JvmPropertyAccessorSignature originalSignature2 = typeMapper.mapSetterSignature(original, OwnerKind.IMPLEMENTATION);\n                Method originalMethod = originalSignature2.getAsmMethod();\n                MethodVisitor mv =\n                        v.newMethod(null, ACC_STATIC | ACC_BRIDGE | ACC_FINAL, method.getName(), method.getDescriptor(), null, null);\n                PropertySetterDescriptor setter = bridge.getSetter();\n                assert setter != null;\n                PropertyCodegen.generateJetPropertyAnnotation(mv,\n                                                              originalSignature2,\n                                                              original,\n                                                              setter.getVisibility());\n                if (state.getClassBuilderMode() == ClassBuilderMode.STUBS) {\n                    genStubCode(mv);\n                }\n                else if (state.getClassBuilderMode() == ClassBuilderMode.FULL) {\n                    mv.visitCode();\n\n                    InstructionAdapter iv = new InstructionAdapter(mv);\n\n                    iv.load(0, OBJECT_TYPE);\n                    Type[] argTypes = method.getArgumentTypes();\n                    for (int i = 1, reg = 1; i < argTypes.length; i++) {\n                        Type argType = argTypes[i];\n                        iv.load(reg, argType);\n                        //noinspection AssignmentToForLoopParameter\n                        reg += argType.getSize();\n                    }\n                    boolean isInsideModule = isCallInsideSameModuleAsDeclared(original, context);\n                    if (original.getVisibility() == Visibilities.PRIVATE && original.getModality() == Modality.FINAL) {\n                        iv.putfield(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(), original.getName().getName(),\n                                    originalMethod.getArgumentTypes()[0].getDescriptor());\n                    }\n                    else {\n                        iv.invokespecial(typeMapper.getOwner(original, OwnerKind.IMPLEMENTATION, isInsideModule).getInternalName(),\n                                         originalMethod.getName(), originalMethod.getDescriptor());\n                    }\n\n                    iv.areturn(method.getReturnType());\n                    FunctionCodegen.endVisit(iv, \"accessor\", null);\n                }\n            }\n        }\n        else {\n            throw new UnsupportedOperationException();\n        }\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public void genDelegate(PropertyDescriptor delegate, PropertyDescriptor overridden, StackValue field) {\n        ClassDescriptor toClass = (ClassDescriptor) overridden.getContainingDeclaration();\n\n        functionCodegen.genDelegate(delegate.getGetter(), toClass, field,\n                                    typeMapper.mapGetterSignature(delegate, OwnerKind.IMPLEMENTATION).getJvmMethodSignature(),\n                                    typeMapper.mapGetterSignature(overridden.getOriginal(), OwnerKind.IMPLEMENTATION).getJvmMethodSignature());\n\n        if (delegate.isVar()) {\n            functionCodegen.genDelegate(delegate.getSetter(), toClass, field,\n                                        typeMapper.mapSetterSignature(delegate, OwnerKind.IMPLEMENTATION).getJvmMethodSignature(),\n                                        typeMapper.mapSetterSignature(overridden.getOriginal(), OwnerKind.IMPLEMENTATION).getJvmMethodSignature());\n        }\n    }","id":36005,"modified_method":"public void genDelegate(PropertyDescriptor delegate, PropertyDescriptor overridden, StackValue field) {\n        ClassDescriptor toClass = (ClassDescriptor) overridden.getContainingDeclaration();\n\n        functionCodegen.genDelegate(delegate.getGetter(), toClass, field,\n                                    typeMapper.mapGetterSignature(delegate, OwnerKind.IMPLEMENTATION),\n                                    typeMapper.mapGetterSignature(overridden.getOriginal(), OwnerKind.IMPLEMENTATION));\n\n        if (delegate.isVar()) {\n            functionCodegen.genDelegate(delegate.getSetter(), toClass, field,\n                                        typeMapper.mapSetterSignature(delegate, OwnerKind.IMPLEMENTATION),\n                                        typeMapper.mapSetterSignature(overridden.getOriginal(), OwnerKind.IMPLEMENTATION));\n        }\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void generateGetter(JetNamedDeclaration p, PropertyDescriptor propertyDescriptor, JetPropertyAccessor getter) {\n        boolean defaultGetter = getter == null || getter.getBodyExpression() == null;\n\n        //TODO: Now it's not enough information to properly resolve property from bytecode without generated getter and setter\n        //if (!defaultGetter || isExternallyAccessible(propertyDescriptor)) {\n        JvmPropertyAccessorSignature signature = typeMapper.mapGetterSignature(propertyDescriptor, kind);\n        PropertyGetterDescriptor getterDescriptor = propertyDescriptor.getGetter();\n        getterDescriptor = getterDescriptor != null ? getterDescriptor : DescriptorResolver.createDefaultGetter(propertyDescriptor);\n\n        if (kind != OwnerKind.TRAIT_IMPL || !defaultGetter) {\n            FunctionGenerationStrategy strategy =\n                    defaultGetter\n                    ? new DefaultPropertyAccessorStrategy(getterDescriptor)\n                    : new FunctionGenerationStrategy.FunctionDefault(state, getterDescriptor, getter);\n            functionCodegen.generateMethod(getter != null ? getter : p,\n                                           signature.getJvmMethodSignature(),\n                                           true,\n                                           getterDescriptor,\n                                           strategy);\n        }\n        //}\n    }","id":36006,"modified_method":"private void generateGetter(JetNamedDeclaration p, PropertyDescriptor propertyDescriptor, JetPropertyAccessor getter) {\n        boolean defaultGetter = getter == null || getter.getBodyExpression() == null;\n\n        //TODO: Now it's not enough information to properly resolve property from bytecode without generated getter and setter\n        //if (!defaultGetter || isExternallyAccessible(propertyDescriptor)) {\n        JvmPropertyAccessorSignature signature = typeMapper.mapGetterSignature(propertyDescriptor, kind);\n        PropertyGetterDescriptor getterDescriptor = propertyDescriptor.getGetter();\n        getterDescriptor = getterDescriptor != null ? getterDescriptor : DescriptorResolver.createDefaultGetter(propertyDescriptor);\n\n        if (kind != OwnerKind.TRAIT_IMPL || !defaultGetter) {\n            FunctionGenerationStrategy strategy =\n                    defaultGetter\n                    ? new DefaultPropertyAccessorStrategy(getterDescriptor)\n                    : new FunctionGenerationStrategy.FunctionDefault(state, getterDescriptor, getter);\n            functionCodegen.generateMethod(getter != null ? getter : p,\n                                           signature,\n                                           true,\n                                           getterDescriptor,\n                                           strategy);\n        }\n        //}\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void generateSetter(JetNamedDeclaration p, PropertyDescriptor propertyDescriptor, JetPropertyAccessor setter) {\n        boolean defaultSetter = setter == null || setter.getBodyExpression() == null;\n\n        //TODO: Now it's not enough information to properly resolve property from bytecode without generated getter and setter\n        if (/*!defaultSetter || isExternallyAccessible(propertyDescriptor) &&*/ propertyDescriptor.isVar()) {\n            JvmPropertyAccessorSignature signature = typeMapper.mapSetterSignature(propertyDescriptor, kind);\n            PropertySetterDescriptor setterDescriptor = propertyDescriptor.getSetter();\n            setterDescriptor = setterDescriptor != null ? setterDescriptor : DescriptorResolver.createDefaultSetter(propertyDescriptor);\n\n            if (kind != OwnerKind.TRAIT_IMPL || !defaultSetter) {\n                FunctionGenerationStrategy strategy =\n                        defaultSetter\n                        ? new DefaultPropertyAccessorStrategy(setterDescriptor)\n                        : new FunctionGenerationStrategy.FunctionDefault(state, setterDescriptor, setter);\n                functionCodegen.generateMethod(setter != null ? setter : p,\n                                               signature.getJvmMethodSignature(),\n                                               true,\n                                               setterDescriptor,\n                                               strategy);\n            }\n        }\n    }","id":36007,"modified_method":"private void generateSetter(JetNamedDeclaration p, PropertyDescriptor propertyDescriptor, JetPropertyAccessor setter) {\n        boolean defaultSetter = setter == null || setter.getBodyExpression() == null;\n\n        //TODO: Now it's not enough information to properly resolve property from bytecode without generated getter and setter\n        if (/*!defaultSetter || isExternallyAccessible(propertyDescriptor) &&*/ propertyDescriptor.isVar()) {\n            JvmPropertyAccessorSignature signature = typeMapper.mapSetterSignature(propertyDescriptor, kind);\n            PropertySetterDescriptor setterDescriptor = propertyDescriptor.getSetter();\n            setterDescriptor = setterDescriptor != null ? setterDescriptor : DescriptorResolver.createDefaultSetter(propertyDescriptor);\n\n            if (kind != OwnerKind.TRAIT_IMPL || !defaultSetter) {\n                FunctionGenerationStrategy strategy =\n                        defaultSetter\n                        ? new DefaultPropertyAccessorStrategy(setterDescriptor)\n                        : new FunctionGenerationStrategy.FunctionDefault(state, setterDescriptor, setter);\n                functionCodegen.generateMethod(setter != null ? setter : p,\n                                               signature,\n                                               true,\n                                               setterDescriptor,\n                                               strategy);\n            }\n        }\n    }","commit_id":"b1c2d9035a6d9a8823b5f95e4082024291fe20e8","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public static String processXML(\n\t\t\tString content, RuntimeLogic runtimeLogic)\n\t\tthrows Exception {\n\n\t\tif (Validator.isNull(content)) {\n\t\t\treturn StringPool.BLANK;\n\t\t}\n\n\t\tStringBuffer sb = new StringBuffer();\n\n\t\tint x = 0;\n\t\tint y = content.indexOf(runtimeLogic.getOpenTag());\n\n\t\twhile (y != -1) {\n\t\t\tsb.append(content.substring(x, y));\n\n\t\t\tint close1 = content.indexOf(runtimeLogic.getClose1Tag(), y);\n\t\t\tint close2 = content.indexOf(runtimeLogic.getClose2Tag(), y);\n\n\t\t\tif ((close2 == -1) || ((close1 != -1) && (close1 < close2))) {\n\t\t\t\tx = close1 + runtimeLogic.getClose1Tag().length();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tx = close2 + runtimeLogic.getClose2Tag().length();\n\t\t\t}\n\n\t\t\truntimeLogic.processXML(sb, content.substring(y, x));\n\n\t\t\ty = content.indexOf(runtimeLogic.getOpenTag(), x);\n\t\t}\n\n\t\tif (y == -1) {\n\t\t\tsb.append(content.substring(x, content.length()));\n\t\t}\n\n\t\treturn sb.toString();\n\t}","id":36008,"modified_method":"public static String processXML(\n\t\t\tHttpServletRequest req, String content, RuntimeLogic runtimeLogic)\n\t\tthrows Exception {\n\n\t\tif (Validator.isNull(content)) {\n\t\t\treturn StringPool.BLANK;\n\t\t}\n\n\t\ttry {\n\t\t\treq.setAttribute(WebKeys.RENDER_PORTLET_RESOURCE, Boolean.TRUE);\n\n\t\t\tStringBuffer sb = new StringBuffer();\n\n\t\t\tint x = 0;\n\t\t\tint y = content.indexOf(runtimeLogic.getOpenTag());\n\n\t\t\twhile (y != -1) {\n\t\t\t\tsb.append(content.substring(x, y));\n\n\t\t\t\tint close1 = content.indexOf(runtimeLogic.getClose1Tag(), y);\n\t\t\t\tint close2 = content.indexOf(runtimeLogic.getClose2Tag(), y);\n\n\t\t\t\tif ((close2 == -1) || ((close1 != -1) && (close1 < close2))) {\n\t\t\t\t\tx = close1 + runtimeLogic.getClose1Tag().length();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tx = close2 + runtimeLogic.getClose2Tag().length();\n\t\t\t\t}\n\n\t\t\t\truntimeLogic.processXML(sb, content.substring(y, x));\n\n\t\t\t\ty = content.indexOf(runtimeLogic.getOpenTag(), x);\n\t\t\t}\n\n\t\t\tif (y == -1) {\n\t\t\t\tsb.append(content.substring(x, content.length()));\n\t\t\t}\n\n\t\t\treturn sb.toString();\n\t\t}\n\t\tfinally {\n\t\t\treq.removeAttribute(WebKeys.RENDER_PORTLET_RESOURCE);\n\t\t}\n\t}","commit_id":"9062831bde888aa5b72655a453c1468ddc85783f","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void doTag(\n\t\t\tString portletName, PageContext pageContext, ServletContext ctx,\n\t\t\tHttpServletRequest req, HttpServletResponse res)\n\t\tthrows Exception {\n\n\t\tPortletRequest portletRequest =\n\t\t\t(PortletRequest)req.getAttribute(WebKeys.JAVAX_PORTLET_REQUEST);\n\n\t\tRenderRequest renderRequest = null;\n\n\t\tif ((portletRequest != null) &&\n\t\t\t(portletRequest instanceof RenderRequest)) {\n\n\t\t\trenderRequest = (RenderRequest)portletRequest;\n\t\t}\n\n\t\tPortletResponse portletResponse =\n\t\t\t(PortletResponse)req.getAttribute(WebKeys.JAVAX_PORTLET_RESPONSE);\n\n\t\tRenderResponse renderResponse = null;\n\n\t\tif ((portletResponse != null) &&\n\t\t\t(portletResponse instanceof RenderResponse)) {\n\n\t\t\trenderResponse = (RenderResponse)portletResponse;\n\t\t}\n\n\t\tString rootPortletId = Portlet.getRootPortletId(portletName);\n\t\tString instanceId = Portlet.getInstanceId(portletName);\n\n\t\tStringBuffer renderPortletSB = new StringBuffer();\n\n\t\tRuntimePortletUtil.processPortlet(\n\t\t\trenderPortletSB, ctx, req, res, renderRequest, renderResponse,\n\t\t\trootPortletId, instanceId);\n\n\t\tif (pageContext != null) {\n\t\t\tpageContext.getOut().print(renderPortletSB.toString());\n\t\t}\n\t\telse {\n\t\t\tres.getOutputStream().print(renderPortletSB.toString());\n\t\t}\n\t}","id":36009,"modified_method":"public static void doTag(\n\t\t\tString portletName, PageContext pageContext, ServletContext ctx,\n\t\t\tHttpServletRequest req, HttpServletResponse res)\n\t\tthrows Exception {\n\n\t\tPortletRequest portletRequest =\n\t\t\t(PortletRequest)req.getAttribute(WebKeys.JAVAX_PORTLET_REQUEST);\n\n\t\tRenderRequest renderRequest = null;\n\n\t\tif ((portletRequest != null) &&\n\t\t\t(portletRequest instanceof RenderRequest)) {\n\n\t\t\trenderRequest = (RenderRequest)portletRequest;\n\t\t}\n\n\t\tPortletResponse portletResponse =\n\t\t\t(PortletResponse)req.getAttribute(WebKeys.JAVAX_PORTLET_RESPONSE);\n\n\t\tRenderResponse renderResponse = null;\n\n\t\tif ((portletResponse != null) &&\n\t\t\t(portletResponse instanceof RenderResponse)) {\n\n\t\t\trenderResponse = (RenderResponse)portletResponse;\n\t\t}\n\n\t\tString rootPortletId = Portlet.getRootPortletId(portletName);\n\t\tString instanceId = Portlet.getInstanceId(portletName);\n\n\t\tStringBuffer renderPortletSB = new StringBuffer();\n\n\t\ttry {\n\t\t\treq.setAttribute(WebKeys.RENDER_PORTLET_RESOURCE, Boolean.TRUE);\n\n\t\t\tRuntimePortletUtil.processPortlet(\n\t\t\t\trenderPortletSB, ctx, req, res, renderRequest, renderResponse,\n\t\t\t\trootPortletId, instanceId);\n\t\t}\n\t\tfinally {\n\t\t\treq.removeAttribute(WebKeys.RENDER_PORTLET_RESOURCE);\n\t\t}\n\n\t\tif (pageContext != null) {\n\t\t\tpageContext.getOut().print(renderPortletSB.toString());\n\t\t}\n\t\telse {\n\t\t\tres.getOutputStream().print(renderPortletSB.toString());\n\t\t}\n\t}","commit_id":"9062831bde888aa5b72655a453c1468ddc85783f","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, String portletId, String queryString)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, renderRequest, renderResponse,\n\t\t\tportletId, queryString, null, null, null);\n\t}","id":36010,"modified_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, String portletId, String queryString)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, renderRequest, renderResponse,\n\t\t\tnull, portletId, queryString, null, null, null, null, false);\n\t}","commit_id":"66948acaf4d8a31f59cb5b7e84598a268c9079bf","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, String portletId, String queryString,\n\t\t\tString columnId, Integer columnPos, Integer columnCount)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, renderRequest, renderResponse,\n\t\t\tnull, portletId, queryString, columnId, columnPos, columnCount,\n\t\t\tnull);\n\t}","id":36011,"modified_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, String portletId, String queryString,\n\t\t\tString columnId, Integer columnPos, Integer columnCount)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, renderRequest, renderResponse,\n\t\t\tnull, portletId, queryString, columnId, columnPos, columnCount,\n\t\t\tnull, false);\n\t}","commit_id":"66948acaf4d8a31f59cb5b7e84598a268c9079bf","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, Portlet portlet, String queryString,\n\t\t\tString columnId, Integer columnPos, Integer columnCount,\n\t\t\tString path)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, null, null, portlet,\n\t\t\tportlet.getPortletId(), queryString, columnId, columnPos,\n\t\t\tcolumnCount, path);\n\t}","id":36012,"modified_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, Portlet portlet, String queryString,\n\t\t\tString columnId, Integer columnPos, Integer columnCount,\n\t\t\tString path)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(\n\t\t\tservletContext, request, response, null, null, portlet,\n\t\t\tportlet.getPortletId(), queryString, columnId, columnPos,\n\t\t\tcolumnCount, path, false);\n\t}","commit_id":"66948acaf4d8a31f59cb5b7e84598a268c9079bf","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, Portlet portlet, String portletId,\n\t\t\tString queryString, String columnId, Integer columnPos,\n\t\t\tInteger columnCount, String path)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)request.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tif (portlet == null) {\n\t\t\tportlet = PortletLocalServiceUtil.getPortletById(\n\t\t\t\tthemeDisplay.getCompanyId(), portletId);\n\t\t}\n\n\t\tif ((portlet != null) && (portlet.isInstanceable()) &&\n\t\t\t(!portlet.isAddDefaultResource())) {\n\n\t\t\tString instanceId = portlet.getInstanceId();\n\n\t\t\tif (Validator.isNotNull(instanceId) &&\n\t\t\t\tValidator.isPassword(instanceId) &&\n\t\t\t\t(instanceId.length() == 4)) {\n\n\t\t\t\t/*portletId +=\n\t\t\t\t\tPortletConstants.INSTANCE_SEPARATOR + instanceId;\n\n\t\t\t\tportlet = PortletLocalServiceUtil.getPortletById(\n\t\t\t\t\tthemeDisplay.getCompanyId(), portletId);*/\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (_log.isDebugEnabled()) {\n\t\t\t\t\t_log.debug(\n\t\t\t\t\t\t\"Portlet \" + portlet.getPortletId() +\n\t\t\t\t\t\t\t\" is instanceable but does not have a \" +\n\t\t\t\t\t\t\t\t\"valid instance id\");\n\t\t\t\t}\n\n\t\t\t\tportlet = null;\n\t\t\t}\n\t\t}\n\n\t\tif (portlet == null) {\n\t\t\treturn StringPool.BLANK;\n\t\t}\n\n\t\t// Capture the current portlet's settings to reset them once the child\n\t\t// portlet is rendered\n\n\t\tPortletDisplay portletDisplay = themeDisplay.getPortletDisplay();\n\n\t\tPortletDisplay portletDisplayClone = PortletDisplayFactory.create();\n\n\t\tportletDisplay.copyTo(portletDisplayClone);\n\n\t\tPortletConfig portletConfig = (PortletConfig)request.getAttribute(\n\t\t\tJavaConstants.JAVAX_PORTLET_CONFIG);\n\n\t\ttry {\n\t\t\treturn PortalUtil.renderPortlet(\n\t\t\t\tservletContext, request, response, portlet, queryString,\n\t\t\t\tcolumnId, columnPos, columnCount, path, false);\n\t\t}\n\t\tfinally {\n\t\t\tportletDisplay.copyFrom(portletDisplayClone);\n\n\t\t\tportletDisplayClone.recycle();\n\n\t\t\t_defineObjects(\n\t\t\t\trequest, portletConfig, renderRequest, renderResponse);\n\t\t}\n\t}","id":36013,"modified_method":"public static String processPortlet(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, RenderRequest renderRequest,\n\t\t\tRenderResponse renderResponse, Portlet portlet, String portletId,\n\t\t\tString queryString, String columnId, Integer columnPos,\n\t\t\tInteger columnCount, String path)\n\t\tthrows Exception {\n\n\t\treturn processPortlet(servletContext, request, response, renderRequest,\n\t\t\trenderResponse, portlet, portletId, queryString, columnId,\n\t\t\tcolumnPos, columnCount, path, false);\n\t}","commit_id":"66948acaf4d8a31f59cb5b7e84598a268c9079bf","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void doTag(\n\t\t\tString portletName, String queryString, String defaultPreferences,\n\t\t\tPageContext pageContext, ServletContext servletContext,\n\t\t\tHttpServletRequest request, HttpServletResponse response)\n\t\tthrows Exception {\n\n\t\tPortletRequest portletRequest = (PortletRequest)request.getAttribute(\n\t\t\tJavaConstants.JAVAX_PORTLET_REQUEST);\n\n\t\tRenderRequest renderRequest = null;\n\n\t\tif ((portletRequest != null) &&\n\t\t\t(portletRequest instanceof RenderRequest)) {\n\n\t\t\trenderRequest = (RenderRequest)portletRequest;\n\t\t}\n\n\t\tPortletResponse portletResponse = (PortletResponse)request.getAttribute(\n\t\t\tJavaConstants.JAVAX_PORTLET_RESPONSE);\n\n\t\tRenderResponse renderResponse = null;\n\n\t\tif ((portletResponse != null) &&\n\t\t\t(portletResponse instanceof RenderResponse)) {\n\n\t\t\trenderResponse = (RenderResponse)portletResponse;\n\t\t}\n\n\t\tString portletId = portletName;\n\n\t\tString content = StringPool.BLANK;\n\n\t\ttry {\n\t\t\trequest.setAttribute(WebKeys.RENDER_PORTLET_RESOURCE, Boolean.TRUE);\n\n\t\t\tif (Validator.isNotNull(defaultPreferences)) {\n\t\t\t\tPortletPreferencesFactoryUtil.getPortletSetup(\n\t\t\t\t\trequest, portletId, defaultPreferences);\n\t\t\t}\n\n\t\t\tcontent = RuntimePortletUtil.processPortlet(\n\t\t\t\tservletContext, request, response, renderRequest,\n\t\t\t\trenderResponse, portletId, queryString);\n\t\t}\n\t\tfinally {\n\t\t\trequest.removeAttribute(WebKeys.RENDER_PORTLET_RESOURCE);\n\t\t}\n\n\t\tif (pageContext != null) {\n\t\t\tpageContext.getOut().print(content);\n\t\t}\n\t\telse {\n\n\t\t\t// LEP-1023\n\n\t\t\t//res.getOutputStream().print(renderPortletSM.toString());\n\t\t\tresponse.getWriter().print(content);\n\t\t}\n\t}","id":36014,"modified_method":"public static void doTag(\n\t\t\tString portletName, String queryString, String defaultPreferences,\n\t\t\tPageContext pageContext, ServletContext servletContext,\n\t\t\tHttpServletRequest request, HttpServletResponse response)\n\t\tthrows Exception {\n\n\t\tPortletRequest portletRequest = (PortletRequest)request.getAttribute(\n\t\t\tJavaConstants.JAVAX_PORTLET_REQUEST);\n\n\t\tRenderRequest renderRequest = null;\n\n\t\tif ((portletRequest != null) &&\n\t\t\t(portletRequest instanceof RenderRequest)) {\n\n\t\t\trenderRequest = (RenderRequest)portletRequest;\n\t\t}\n\n\t\tPortletResponse portletResponse = (PortletResponse)request.getAttribute(\n\t\t\tJavaConstants.JAVAX_PORTLET_RESPONSE);\n\n\t\tRenderResponse renderResponse = null;\n\n\t\tif ((portletResponse != null) &&\n\t\t\t(portletResponse instanceof RenderResponse)) {\n\n\t\t\trenderResponse = (RenderResponse)portletResponse;\n\t\t}\n\n\t\tString portletId = portletName;\n\n\t\tHttpServletResponse servletResponse = response;\n\t\tif (pageContext != null) {\n\t\t\tservletResponse = new PipingServletResponse(response,\n\t\t\t\tpageContext.getOut());\n\t\t}\n\t\ttry {\n\t\t\trequest.setAttribute(WebKeys.RENDER_PORTLET_RESOURCE, Boolean.TRUE);\n\n\t\t\tif (Validator.isNotNull(defaultPreferences)) {\n\t\t\t\tPortletPreferencesFactoryUtil.getPortletSetup(\n\t\t\t\t\trequest, portletId, defaultPreferences);\n\t\t\t}\n\n\t\t\tRuntimePortletUtil.processPortlet(\n\t\t\t\tservletContext, request, servletResponse, renderRequest,\n\t\t\t\trenderResponse, portletId, queryString, true);\n\t\t}\n\t\tfinally {\n\t\t\trequest.removeAttribute(WebKeys.RENDER_PORTLET_RESOURCE);\n\t\t}\n\t}","commit_id":"66948acaf4d8a31f59cb5b7e84598a268c9079bf","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void processTemplate(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, PageContext pageContext,\n\t\t\tJspWriter jspWriter, String portletId, String velocityTemplateId,\n\t\t\tString velocityTemplateContent)\n\t\tthrows Exception {\n\n\t\tif (Validator.isNull(velocityTemplateContent)) {\n\t\t\treturn;\n\t\t}\n\n\t\tTemplateProcessor processor = new TemplateProcessor(\n\t\t\tservletContext, request, response, portletId);\n\n\t\tVelocityContext velocityContext =\n\t\t\tVelocityEngineUtil.getWrappedStandardToolsContext();\n\n\t\tvelocityContext.put(\"processor\", processor);\n\n\t\t// Velocity variables\n\n\t\tVelocityVariables.insertVariables(velocityContext, request);\n\n\t\t// liferay:include tag library\n\n\t\tUnsyncStringWriter unsyncStringWriter = new UnsyncStringWriter();\n\n\t\tMethodWrapper methodWrapper = new MethodWrapper(\n\t\t\t\"com.liferay.taglib.util.VelocityTaglib\", \"init\",\n\t\t\tnew Object[] {\n\t\t\t\tservletContext, request,\n\t\t\t\tnew PipingServletResponse(response, unsyncStringWriter),\n\t\t\t\tpageContext\n\t\t\t});\n\n\t\tObject velocityTaglib = MethodInvoker.invoke(methodWrapper);\n\n\t\tvelocityContext.put(\"taglibLiferay\", velocityTaglib);\n\t\tvelocityContext.put(\"theme\", velocityTaglib);\n\n\t\ttry {\n\t\t\tVelocityEngineUtil.mergeTemplate(\n\t\t\t\tvelocityTemplateId, velocityTemplateContent, velocityContext,\n\t\t\t\tunsyncStringWriter);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\n\t\t\tthrow e;\n\t\t}\n\n\t\tString output = unsyncStringWriter.toString();\n\n\t\tMap<Portlet, Object[]> portletsMap = processor.getPortletsMap();\n\n\t\tMap<String, String> contentsMap = new HashMap<String, String>(\n\t\t\tportletsMap.size());\n\n\t\tfor (Map.Entry<Portlet, Object[]> entry : portletsMap.entrySet()) {\n\t\t\tPortlet portlet = entry.getKey();\n\t\t\tObject[] value = entry.getValue();\n\n\t\t\tString queryString = (String)value[0];\n\t\t\tString columnId = (String)value[1];\n\t\t\tInteger columnPos = (Integer)value[2];\n\t\t\tInteger columnCount = (Integer)value[3];\n\n\t\t\tString content = processPortlet(\n\t\t\t\tservletContext, request, response, portlet, queryString,\n\t\t\t\tcolumnId, columnPos, columnCount, null, false);\n\n\t\t\tcontentsMap.put(portlet.getPortletId(), content);\n\t\t}\n\n\t\tStringBundler sb = StringUtil.replaceToStringBundler(\n\t\t\toutput, \"[$TEMPLATE_PORTLET_\", \"$]\", contentsMap);\n\n\t\tsb.writeTo(new UnbufferedJspWriter(jspWriter));\n\t}","id":36015,"modified_method":"public static void processTemplate(\n\t\t\tServletContext servletContext, HttpServletRequest request,\n\t\t\tHttpServletResponse response, PageContext pageContext,\n\t\t\tJspWriter jspWriter, String portletId, String velocityTemplateId,\n\t\t\tString velocityTemplateContent)\n\t\tthrows Exception {\n\n\t\tif (Validator.isNull(velocityTemplateContent)) {\n\t\t\treturn;\n\t\t}\n\n\t\tTemplateProcessor processor = new TemplateProcessor(\n\t\t\tservletContext, request, response, portletId);\n\n\t\tVelocityContext velocityContext =\n\t\t\tVelocityEngineUtil.getWrappedStandardToolsContext();\n\n\t\tvelocityContext.put(\"processor\", processor);\n\n\t\t// Velocity variables\n\n\t\tVelocityVariables.insertVariables(velocityContext, request);\n\n\t\t// liferay:include tag library\n\n\t\tUnsyncStringWriter unsyncStringWriter = new UnsyncStringWriter();\n\n\t\tMethodWrapper methodWrapper = new MethodWrapper(\n\t\t\t\"com.liferay.taglib.util.VelocityTaglib\", \"init\",\n\t\t\tnew Object[] {\n\t\t\t\tservletContext, request,\n\t\t\t\tnew PipingServletResponse(response, unsyncStringWriter),\n\t\t\t\tpageContext\n\t\t\t});\n\n\t\tObject velocityTaglib = MethodInvoker.invoke(methodWrapper);\n\n\t\tvelocityContext.put(\"taglibLiferay\", velocityTaglib);\n\t\tvelocityContext.put(\"theme\", velocityTaglib);\n\n\t\ttry {\n\t\t\tVelocityEngineUtil.mergeTemplate(\n\t\t\t\tvelocityTemplateId, velocityTemplateContent, velocityContext,\n\t\t\t\tunsyncStringWriter);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\n\t\t\tthrow e;\n\t\t}\n\n\t\tString output = unsyncStringWriter.toString();\n\n\t\tMap<Portlet, Object[]> portletsMap = processor.getPortletsMap();\n\n\t\tMap<String, StringBundler> contentsMap =\n\t\t\tnew HashMap<String, StringBundler>(portletsMap.size());\n\n\t\tfor (Map.Entry<Portlet, Object[]> entry : portletsMap.entrySet()) {\n\t\t\tPortlet portlet = entry.getKey();\n\t\t\tObject[] value = entry.getValue();\n\n\t\t\tString queryString = (String)value[0];\n\t\t\tString columnId = (String)value[1];\n\t\t\tInteger columnPos = (Integer)value[2];\n\t\t\tInteger columnCount = (Integer)value[3];\n\n\t\t\tUnsyncStringWriter portletUnsyncStringWriter =\n\t\t\t\tnew UnsyncStringWriter();\n\n\t\t\tPipingServletResponse pipingServletResponse =\n\t\t\t\tnew PipingServletResponse(response, portletUnsyncStringWriter);\n\n\t\t\tprocessPortlet(\n\t\t\t\tservletContext, request, pipingServletResponse, portlet,\n\t\t\t\tqueryString, columnId, columnPos, columnCount, null, true);\n\n\t\t\tcontentsMap.put(\n\t\t\t\tportlet.getPortletId(),\n\t\t\t\tportletUnsyncStringWriter.getStringBundler());\n\t\t}\n\n\t\tStringBundler sb = StringUtil.replaceWithStringBundler(\n\t\t\toutput, \"[$TEMPLATE_PORTLET_\", \"$]\", contentsMap);\n\n\t\tsb.writeTo(jspWriter);\n\t}","commit_id":"5b2b93cc5055838c115213d4c5af4efe8e1a217f","url":"https://github.com/liferay/liferay-portal"},{"original_method":"/**\n     * Generate xml for a Holder (Filter/Servlet)\n     * \n     * @param out\n     * @param md\n     * @param tag\n     * @param holder\n     * @throws IOException\n     */\n    private void outholder(XmlAppendable out, MetaData md, String tag, Holder<?> holder) throws IOException\n    {\n        out.openTag(tag,Collections.singletonMap(\"source\",holder.getSource().toString()));\n        String n = holder.getName();\n        out.tag(tag + \"-name\",n);\n\n        String ot = n + \".\" + tag + \".\";\n        \n        if (holder instanceof FilterHolder)\n            out.tag(tag + \"-class\",origin(md,ot + tag + \"-class\"),holder.getClassName());\n        else if (holder instanceof ServletHolder)\n        {\n            ServletHolder s = (ServletHolder)holder;\n            if (s.getForcedPath() != null && s.getClassName() == null)\n                out.tag(\"jsp-file\",s.getForcedPath());\n            else\n                out.tag(tag + \"-class\",origin(md,ot + tag + \"-class\"),s.getClassName());\n\n        }\n\n        for (String p : holder.getInitParameters().keySet())\n        {\n            if (\"scratchdir\".equalsIgnoreCase(p)) //don't preconfigure the temp dir for jsp output\n                continue;\n            out.openTag(\"init-param\",origin(md,ot + \"init-param.\" + p))\n            .tag(\"param-name\",p)\n            .tag(\"param-value\",holder.getInitParameter(p))\n            .closeTag();\n        }\n\n        if (holder instanceof ServletHolder)\n        {\n            ServletHolder s = (ServletHolder)holder;\n            if (s.getInitOrder() >= 0)\n                out.tag(\"load-on-startup\",Integer.toString(s.getInitOrder()));\n\n            if (s.getRunAsRole() != null)\n                out.openTag(\"run-as\",origin(md,ot + \"run-as\"))\n                .tag(\"role-name\",s.getRunAsRole())\n                .closeTag();\n\n            Map<String,String> roles = s.getRoleRefMap();\n            if (roles!=null)\n            {\n                for (Map.Entry<String, String> e : roles.entrySet())\n                {\n                    out.openTag(\"security-role-ref\",origin(md,ot+\"role-name.\"+e.getKey()))\n                    .tag(\"role-name\",e.getKey())\n                    .tag(\"role-link\",e.getValue())\n                    .closeTag();\n                }\n            }\n            \n            if (!s.isEnabled())\n                out.tag(\"enabled\",origin(md,ot + \"enabled\"),\"false\");\n\n            //multipart-config\n            MultipartConfigElement multipartConfig = ((ServletHolder.Registration)s.getRegistration()).getMultipartConfig();\n            if (multipartConfig != null)\n            {\n                out.openTag(\"multipart-config\", origin(md, s.getName()+\".servlet.multipart-config\"));\n                if (multipartConfig.getLocation() != null)\n                    out.tag(\"location\", multipartConfig.getLocation());\n                out.tag(\"max-file-size\", Long.toString(multipartConfig.getMaxFileSize()));\n                out.tag(\"max-request-size\", Long.toString(multipartConfig.getMaxRequestSize()));\n                out.tag(\"file-size-threshold\", Long.toString(multipartConfig.getFileSizeThreshold()));\n                out.closeTag();\n            }\n        }\n\n        out.tag(\"async-supported\",origin(md,ot + \"async-supported\"),holder.isAsyncSupported()?\"true\":\"false\");\n        out.closeTag();\n    }","id":36016,"modified_method":"private void outholder(XmlAppendable out, MetaData md, ServletHolder holder) throws IOException\n    {\n        \n        if (LOG.isDebugEnabled())\n            out.openTag(\"servlet\",Collections.singletonMap(\"source\",holder.getSource().toString()));\n        else\n            out.openTag(\"servlet\");\n        \n        String n = holder.getName();\n        out.tag(\"servlet-name\",n);\n\n        String ot = n + \".servlet.\";\n\n        ServletHolder s = (ServletHolder)holder;\n        if (s.getForcedPath() != null && s.getClassName() == null)\n            out.tag(\"jsp-file\",s.getForcedPath());\n        else\n            out.tag(\"servlet-class\",origin(md,ot + \"servlet-class\"),s.getClassName());\n\n        for (String p : holder.getInitParameters().keySet())\n        {\n            if (\"jsp\".equalsIgnoreCase(n) && \"scratchdir\".equalsIgnoreCase(p)) //don't preconfigure the temp dir for jsp output\n                continue;\n            out.openTag(\"init-param\",origin(md,ot + \"init-param.\" + p))\n            .tag(\"param-name\",p)\n            .tag(\"param-value\",holder.getInitParameter(p))\n            .closeTag();\n        }\n\n        if (s.getInitOrder() >= 0)\n            out.tag(\"load-on-startup\",Integer.toString(s.getInitOrder()));\n\n        if (!s.isEnabled())\n            out.tag(\"enabled\",origin(md,ot + \"enabled\"),\"false\");\n\n        out.tag(\"async-supported\",origin(md,ot + \"async-supported\"),holder.isAsyncSupported()?\"true\":\"false\");\n\n        if (s.getRunAsRole() != null)\n            out.openTag(\"run-as\",origin(md,ot + \"run-as\"))\n            .tag(\"role-name\",s.getRunAsRole())\n            .closeTag();\n\n        Map<String,String> roles = s.getRoleRefMap();\n        if (roles!=null)\n        {\n            for (Map.Entry<String, String> e : roles.entrySet())\n            {\n                out.openTag(\"security-role-ref\",origin(md,ot+\"role-name.\"+e.getKey()))\n                .tag(\"role-name\",e.getKey())\n                .tag(\"role-link\",e.getValue())\n                .closeTag();\n            }\n        }\n\n        //multipart-config\n        MultipartConfigElement multipartConfig = ((ServletHolder.Registration)s.getRegistration()).getMultipartConfig();\n        if (multipartConfig != null)\n        {\n            out.openTag(\"multipart-config\", origin(md, s.getName()+\".servlet.multipart-config\"));\n            if (multipartConfig.getLocation() != null)\n                out.tag(\"location\", multipartConfig.getLocation());\n            out.tag(\"max-file-size\", Long.toString(multipartConfig.getMaxFileSize()));\n            out.tag(\"max-request-size\", Long.toString(multipartConfig.getMaxRequestSize()));\n            out.tag(\"file-size-threshold\", Long.toString(multipartConfig.getFileSizeThreshold()));\n            out.closeTag();\n        }\n\n        out.closeTag();\n    }","commit_id":"4c8e2a6635d6a13a783a567aa890237a88a62e56","url":"https://github.com/eclipse/jetty.project"},{"original_method":"/**\n     * Perform the generation of the xml file\n     * @throws IOException \n     * @throws FileNotFoundException \n     * @throws Exception\n     */\n    public void generateQuickStartWebXml (OutputStream stream) throws FileNotFoundException, IOException \n    {   \n        if (_webApp == null)\n            throw new IllegalStateException(\"No webapp for quickstart generation\");\n        if (stream == null)\n            throw new IllegalStateException(\"No output for quickstart generation\");\n        \n        _webApp.getMetaData().getOrigins();\n\n        if (_webApp.getBaseResource()==null)\n            throw new IllegalArgumentException(\"No base resource for \"+this);\n\n        LOG.info(\"Quickstart generating\");\n\n        XmlAppendable out = new XmlAppendable(stream,\"UTF-8\");\n\n        MetaData md = _webApp.getMetaData();\n\n        Map<String, String> webappAttr = new HashMap<>();\n        webappAttr.put(\"xmlns\",\"http://xmlns.jcp.org/xml/ns/javaee\");\n        webappAttr.put(\"xmlns:xsi\",\"http://www.w3.org/2001/XMLSchema-instance\");\n        webappAttr.put(\"xsi:schemaLocation\",\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\");\n        webappAttr.put(\"metadata-complete\",\"true\");\n        webappAttr.put(\"version\",\"3.1\");\n\n        out.openTag(\"web-app\",webappAttr);\n        if (_webApp.getDisplayName() != null)\n            out.tag(\"display-name\",_webApp.getDisplayName());\n\n        // Set some special context parameters\n\n        // The location of the war file on disk\n        String resourceBase = _webApp.getBaseResource().getFile().getCanonicalFile().getAbsoluteFile().toURI().toString();\n\n        // The library order\n        addContextParamFromAttribute(out,ServletContext.ORDERED_LIBS);\n        //the servlet container initializers\n        addContextParamFromAttribute(out,AnnotationConfiguration.CONTAINER_INITIALIZERS);\n        //the tlds discovered\n        addContextParamFromAttribute(out,MetaInfConfiguration.METAINF_TLDS,resourceBase);\n        //the META-INF/resources discovered\n        addContextParamFromAttribute(out,MetaInfConfiguration.METAINF_RESOURCES,resourceBase);\n\n\n        // init params\n        for (String p : _webApp.getInitParams().keySet())\n            out.openTag(\"context-param\",origin(md,\"context-param.\" + p))\n            .tag(\"param-name\",p)\n            .tag(\"param-value\",_webApp.getInitParameter(p))\n            .closeTag();\n\n        if (_webApp.getEventListeners() != null)\n            for (EventListener e : _webApp.getEventListeners())\n                out.openTag(\"listener\",origin(md,e.getClass().getCanonicalName() + \".listener\"))\n                .tag(\"listener-class\",e.getClass().getCanonicalName())\n                .closeTag();\n\n        ServletHandler servlets = _webApp.getServletHandler();\n\n        if (servlets.getFilters() != null)\n        {\n            for (FilterHolder holder : servlets.getFilters())\n                outholder(out,md,\"filter\",holder);\n        }\n\n        if (servlets.getFilterMappings() != null)\n        {\n            for (FilterMapping mapping : servlets.getFilterMappings())\n            {\n                out.openTag(\"filter-mapping\");\n                out.tag(\"filter-name\",mapping.getFilterName());\n                if (mapping.getPathSpecs() != null)\n                    for (String s : mapping.getPathSpecs())\n                        out.tag(\"url-pattern\",s);\n                if (mapping.getServletNames() != null)\n                    for (String n : mapping.getServletNames())\n                        out.tag(\"servlet-name\",n);\n\n                if (!mapping.isDefaultDispatches())\n                {\n                    if (mapping.appliesTo(DispatcherType.REQUEST))\n                        out.tag(\"dispatcher\",\"REQUEST\");\n                    if (mapping.appliesTo(DispatcherType.ASYNC))\n                        out.tag(\"dispatcher\",\"ASYNC\");\n                    if (mapping.appliesTo(DispatcherType.ERROR))\n                        out.tag(\"dispatcher\",\"ERROR\");\n                    if (mapping.appliesTo(DispatcherType.FORWARD))\n                        out.tag(\"dispatcher\",\"FORWARD\");\n                    if (mapping.appliesTo(DispatcherType.INCLUDE))\n                        out.tag(\"dispatcher\",\"INCLUDE\");\n                }\n                out.closeTag();\n            }\n        }\n\n        if (servlets.getServlets() != null)\n        {\n            for (ServletHolder holder : servlets.getServlets())\n                outholder(out,md,\"servlet\",holder);\n        }\n\n        if (servlets.getServletMappings() != null)\n        {\n            for (ServletMapping mapping : servlets.getServletMappings())\n            {\n                out.openTag(\"servlet-mapping\",origin(md,mapping.getServletName() + \".servlet.mappings\"));\n                out.tag(\"servlet-name\",mapping.getServletName());\n                if (mapping.getPathSpecs() != null)\n                    for (String s : mapping.getPathSpecs())\n                        out.tag(\"url-pattern\",s);\n                out.closeTag();\n            }\n        }\n\n        // Security elements\n        SecurityHandler security =_webApp. getSecurityHandler();\n\n        if (security!=null && (security.getRealmName()!=null || security.getAuthMethod()!=null))\n        {\n            out.openTag(\"login-config\");\n            if (security.getAuthMethod()!=null)\n                out.tag(\"auth-method\",origin(md,\"auth-method\"),security.getAuthMethod());\n            if (security.getRealmName()!=null)\n                out.tag(\"realm-name\",origin(md,\"realm-name\"),security.getRealmName());\n\n\n            if (Constraint.__FORM_AUTH.equalsIgnoreCase(security.getAuthMethod()))\n            {\n                out.openTag(\"form-login-config\");\n                out.tag(\"form-login-page\",origin(md,\"form-login-page\"),security.getInitParameter(FormAuthenticator.__FORM_LOGIN_PAGE));\n                out.tag(\"form-error-page\",origin(md,\"form-error-page\"),security.getInitParameter(FormAuthenticator.__FORM_ERROR_PAGE));\n                out.closeTag();\n            }\n\n            out.closeTag();\n        }\n\n        if (security instanceof ConstraintAware)\n        {\n            ConstraintAware ca = (ConstraintAware)security;\n            for (String r:ca.getRoles())\n                out.openTag(\"security-role\")\n                .tag(\"role-name\",r)\n                .closeTag();\n\n            for (ConstraintMapping m : ca.getConstraintMappings())\n            {\n                out.openTag(\"security-constraint\");\n\n                if (m.getConstraint().getAuthenticate())\n                {\n                    out.openTag(\"auth-constraint\");\n                    if (m.getConstraint().getRoles()!=null)\n                        for (String r : m.getConstraint().getRoles())\n                            out.tag(\"role-name\",r);\n\n                    out.closeTag();\n                }\n\n                switch (m.getConstraint().getDataConstraint())\n                {\n                    case Constraint.DC_NONE:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"NONE\").closeTag();\n                        break;\n\n                    case Constraint.DC_INTEGRAL:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"INTEGRAL\").closeTag();\n                        break;\n\n                    case Constraint.DC_CONFIDENTIAL:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"CONFIDENTIAL\").closeTag();\n                        break;\n\n                    default:\n                        break;\n\n                }\n\n                out.openTag(\"web-resource-collection\");\n                {\n                    if (m.getConstraint().getName()!=null)\n                        out.tag(\"web-resource-name\",m.getConstraint().getName());\n                    if (m.getPathSpec()!=null)\n                        out.tag(\"url-pattern\",origin(md,\"constraint.url.\"+m.getPathSpec()),m.getPathSpec());\n                    if (m.getMethod()!=null)\n                        out.tag(\"http-method\",m.getMethod());\n\n                    if (m.getMethodOmissions()!=null)\n                        for (String o:m.getMethodOmissions())\n                            out.tag(\"http-method-omission\",o);\n\n                    out.closeTag();\n                }\n\n                out.closeTag();\n\n            }\n        }\n\n        if (_webApp.getWelcomeFiles() != null)\n        {\n            out.openTag(\"welcome-file-list\");\n            for (String welcomeFile:_webApp.getWelcomeFiles())\n            {\n                out.tag(\"welcome-file\", welcomeFile);\n            }\n            out.closeTag();\n        }\n\n        Map<String,String> localeEncodings = _webApp.getLocaleEncodings();\n        if (localeEncodings != null && !localeEncodings.isEmpty())\n        {\n            out.openTag(\"locale-encoding-mapping-list\");\n            for (Map.Entry<String, String> entry:localeEncodings.entrySet())\n            {\n                out.openTag(\"locale-encoding-mapping\", origin(md,\"locale-encoding.\"+entry.getKey()));\n                out.tag(\"locale\", entry.getKey());\n                out.tag(\"encoding\", entry.getValue());\n                out.closeTag();\n            }\n            out.closeTag();\n        }\n\n        //session-config\n        if (_webApp.getSessionHandler().getSessionManager() != null)\n        {\n            out.openTag(\"session-config\");\n            int maxInactiveSec = _webApp.getSessionHandler().getSessionManager().getMaxInactiveInterval();\n            out.tag(\"session-timeout\", (maxInactiveSec==0?\"0\":Integer.toString(maxInactiveSec/60)));\n\n            Set<SessionTrackingMode> modes =_webApp. getSessionHandler().getSessionManager().getEffectiveSessionTrackingModes();\n            if (modes != null)\n            {\n                for (SessionTrackingMode mode:modes)\n                    out.tag(\"tracking-mode\", mode.toString());\n            }\n\n            //cookie-config\n            SessionCookieConfig cookieConfig = _webApp.getSessionHandler().getSessionManager().getSessionCookieConfig();\n            if (cookieConfig != null)\n            {\n                out.openTag(\"cookie-config\");\n                if (cookieConfig.getName() != null)\n                    out.tag(\"name\", origin(md,\"cookie-config.name\"), cookieConfig.getName());\n\n                if (cookieConfig.getDomain() != null)\n                    out.tag(\"domain\", origin(md, \"cookie-config.domain\"), cookieConfig.getDomain());\n\n                if (cookieConfig.getPath() != null)\n                    out.tag(\"path\", origin(md, \"cookie-config.path\"), cookieConfig.getPath());\n\n                if (cookieConfig.getComment() != null)\n                    out.tag(\"comment\", origin(md, \"cookie-config.comment\"), cookieConfig.getComment());\n\n                out.tag(\"http-only\", origin(md, \"cookie-config.http-only\"), Boolean.toString(cookieConfig.isHttpOnly()));\n                out.tag(\"secure\", origin(md, \"cookie-config.secure\"), Boolean.toString(cookieConfig.isSecure()));\n                out.tag(\"max-age\", origin(md, \"cookie-config.max-age\"), Integer.toString(cookieConfig.getMaxAge()));\n                out.closeTag();\n            }\n            out.closeTag();     \n        }\n\n        //error-pages\n        Map<String,String> errorPages = ((ErrorPageErrorHandler)_webApp.getErrorHandler()).getErrorPages();\n        if (errorPages != null)\n        {\n            for (Map.Entry<String, String> entry:errorPages.entrySet())\n            {\n                out.openTag(\"error-page\", origin(md, \"error.\"+entry.getKey()));\n                //a global or default error page has no code or exception               \n                if (!ErrorPageErrorHandler.GLOBAL_ERROR_PAGE.equals(entry.getKey()))\n                {\n                    if (entry.getKey().matches(\"\\\\d{3}\"))\n                        out.tag(\"error-code\", entry.getKey());\n                    else\n                        out.tag(\"exception-type\", entry.getKey());\n                }\n                out.tag(\"location\", entry.getValue());\n                out.closeTag();\n            }\n        }\n\n        //mime-types\n        MimeTypes mimeTypes = _webApp.getMimeTypes();\n        if (mimeTypes != null)\n        {\n            for (Map.Entry<String, String> entry:mimeTypes.getMimeMap().entrySet())\n            {\n                out.openTag(\"mime-mapping\");\n                out.tag(\"extension\", origin(md, \"extension.\"+entry.getKey()), entry.getKey());\n                out.tag(\"mime-type\", entry.getValue());\n                out.closeTag();\n            }\n        }\n\n        //jsp-config\n        JspConfig jspConfig = (JspConfig)_webApp.getServletContext().getJspConfigDescriptor();\n        if (jspConfig != null)\n        {\n            out.openTag(\"jsp-config\");\n            Collection<TaglibDescriptor> tlds = jspConfig.getTaglibs();\n            if (tlds != null && !tlds.isEmpty())\n            {\n                for (TaglibDescriptor tld:tlds)\n                {\n                    out.openTag(\"taglib\");\n                    out.tag(\"taglib-uri\", tld.getTaglibURI());\n                    out.tag(\"taglib-location\", tld.getTaglibLocation());\n                    out.closeTag();\n                }\n            }\n\n            Collection<JspPropertyGroupDescriptor> jspPropertyGroups = jspConfig.getJspPropertyGroups();\n            if (jspPropertyGroups != null && !jspPropertyGroups.isEmpty())\n            {\n                for (JspPropertyGroupDescriptor jspPropertyGroup:jspPropertyGroups)\n                {\n                    out.openTag(\"jsp-property-group\");\n                    Collection<String> strings = jspPropertyGroup.getUrlPatterns();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String urlPattern:strings)\n                            out.tag(\"url-pattern\", urlPattern);\n                    }\n\n                    if (jspPropertyGroup.getElIgnored() != null)\n                        out.tag(\"el-ignored\", jspPropertyGroup.getElIgnored());\n\n                    if (jspPropertyGroup.getPageEncoding() != null)\n                        out.tag(\"page-encoding\", jspPropertyGroup.getPageEncoding());\n\n                    if (jspPropertyGroup.getScriptingInvalid() != null)\n                        out.tag(\"scripting-invalid\", jspPropertyGroup.getScriptingInvalid());\n\n                    if (jspPropertyGroup.getIsXml() != null)\n                        out.tag(\"is-xml\", jspPropertyGroup.getIsXml());\n\n                    if (jspPropertyGroup.getDeferredSyntaxAllowedAsLiteral() != null)\n                        out.tag(\"deferred-syntax-allowed-as-literal\", jspPropertyGroup.getDeferredSyntaxAllowedAsLiteral());\n\n                    if (jspPropertyGroup.getTrimDirectiveWhitespaces() != null)\n                        out.tag(\"trim-directive-whitespaces\", jspPropertyGroup.getTrimDirectiveWhitespaces());\n\n                    if (jspPropertyGroup.getDefaultContentType() != null)\n                        out.tag(\"default-content-type\", jspPropertyGroup.getDefaultContentType());\n\n                    if (jspPropertyGroup.getBuffer() != null)\n                        out.tag(\"buffer\", jspPropertyGroup.getBuffer());\n\n                    if (jspPropertyGroup.getErrorOnUndeclaredNamespace() != null)\n                        out.tag(\"error-on-undeclared-namespace\", jspPropertyGroup.getErrorOnUndeclaredNamespace());\n\n                    strings = jspPropertyGroup.getIncludePreludes();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String prelude:strings)\n                            out.tag(\"include-prelude\", prelude);\n                    }\n\n                    strings = jspPropertyGroup.getIncludeCodas();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String coda:strings)\n                            out.tag(\"include-coda\", coda);\n                    }\n\n                    out.closeTag();\n                }\n            }\n\n            out.closeTag();\n        }\n\n        //lifecycle: post-construct, pre-destroy\n        LifeCycleCallbackCollection lifecycles = ((LifeCycleCallbackCollection)_webApp.getAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION));\n        if (lifecycles != null)\n        {\n            Collection<LifeCycleCallback> tmp = lifecycles.getPostConstructCallbacks();\n\n            for (LifeCycleCallback c:tmp)\n            {\n                out.openTag(\"post-construct\");\n                out.tag(\"lifecycle-callback-class\", c.getTargetClassName());\n                out.tag(\"lifecycle-callback-method\", c.getMethodName());\n                out.closeTag();\n            }\n\n            tmp = lifecycles.getPreDestroyCallbacks();\n            for (LifeCycleCallback c:tmp)\n            {\n                out.openTag(\"pre-destroy\");\n                out.tag(\"lifecycle-callback-class\", c.getTargetClassName());\n                out.tag(\"lifecycle-callback-method\", c.getMethodName());\n                out.closeTag();\n            }\n        }\n\n        out.literal(_extraXML);\n\n        out.closeTag();\n    }","id":36017,"modified_method":"/**\n     * Perform the generation of the xml file\n     * @throws IOException \n     * @throws FileNotFoundException \n     * @throws Exception\n     */\n    public void generateQuickStartWebXml (OutputStream stream) throws FileNotFoundException, IOException \n    {   \n        if (_webApp == null)\n            throw new IllegalStateException(\"No webapp for quickstart generation\");\n        if (stream == null)\n            throw new IllegalStateException(\"No output for quickstart generation\");\n        \n        _webApp.getMetaData().getOrigins();\n\n        if (_webApp.getBaseResource()==null)\n            throw new IllegalArgumentException(\"No base resource for \"+this);\n\n        LOG.info(\"Quickstart generating\");\n\n        XmlAppendable out = new XmlAppendable(stream,\"UTF-8\");\n\n        MetaData md = _webApp.getMetaData();\n\n        Map<String, String> webappAttr = new HashMap<>();\n        webappAttr.put(\"xmlns\",\"http://xmlns.jcp.org/xml/ns/javaee\");\n        webappAttr.put(\"xmlns:xsi\",\"http://www.w3.org/2001/XMLSchema-instance\");\n        webappAttr.put(\"xsi:schemaLocation\",\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\");\n        webappAttr.put(\"metadata-complete\",\"true\");\n        webappAttr.put(\"version\",\"3.1\");\n\n        out.openTag(\"web-app\",webappAttr);\n        if (_webApp.getDisplayName() != null)\n            out.tag(\"display-name\",_webApp.getDisplayName());\n        \n        // Set some special context parameters\n\n        // The location of the war file on disk\n        String resourceBase = _webApp.getBaseResource().getFile().getCanonicalFile().getAbsoluteFile().toURI().toString();\n\n        // The library order\n        addContextParamFromAttribute(out,ServletContext.ORDERED_LIBS);\n        //the servlet container initializers\n        addContextParamFromAttribute(out,AnnotationConfiguration.CONTAINER_INITIALIZERS);\n        //the tlds discovered\n        addContextParamFromAttribute(out,MetaInfConfiguration.METAINF_TLDS,resourceBase);\n        //the META-INF/resources discovered\n        addContextParamFromAttribute(out,MetaInfConfiguration.METAINF_RESOURCES,resourceBase);\n\n\n        // init params\n        for (String p : _webApp.getInitParams().keySet())\n            out.openTag(\"context-param\",origin(md,\"context-param.\" + p))\n            .tag(\"param-name\",p)\n            .tag(\"param-value\",_webApp.getInitParameter(p))\n            .closeTag();\n\n        if (_webApp.getEventListeners() != null)\n            for (EventListener e : _webApp.getEventListeners())\n                out.openTag(\"listener\",origin(md,e.getClass().getCanonicalName() + \".listener\"))\n                .tag(\"listener-class\",e.getClass().getCanonicalName())\n                .closeTag();\n\n        ServletHandler servlets = _webApp.getServletHandler();\n\n        if (servlets.getFilters() != null)\n        {\n            for (FilterHolder holder : servlets.getFilters())\n                outholder(out,md,holder);\n        }\n\n        if (servlets.getFilterMappings() != null)\n        {\n            for (FilterMapping mapping : servlets.getFilterMappings())\n            {\n                out.openTag(\"filter-mapping\");\n                out.tag(\"filter-name\",mapping.getFilterName());\n                if (mapping.getPathSpecs() != null)\n                    for (String s : mapping.getPathSpecs())\n                        out.tag(\"url-pattern\",s);\n                if (mapping.getServletNames() != null)\n                    for (String n : mapping.getServletNames())\n                        out.tag(\"servlet-name\",n);\n\n                if (!mapping.isDefaultDispatches())\n                {\n                    if (mapping.appliesTo(DispatcherType.REQUEST))\n                        out.tag(\"dispatcher\",\"REQUEST\");\n                    if (mapping.appliesTo(DispatcherType.ASYNC))\n                        out.tag(\"dispatcher\",\"ASYNC\");\n                    if (mapping.appliesTo(DispatcherType.ERROR))\n                        out.tag(\"dispatcher\",\"ERROR\");\n                    if (mapping.appliesTo(DispatcherType.FORWARD))\n                        out.tag(\"dispatcher\",\"FORWARD\");\n                    if (mapping.appliesTo(DispatcherType.INCLUDE))\n                        out.tag(\"dispatcher\",\"INCLUDE\");\n                }\n                out.closeTag();\n            }\n        }\n\n        if (servlets.getServlets() != null)\n        {\n            for (ServletHolder holder : servlets.getServlets())\n                outholder(out,md,holder);\n        }\n\n        if (servlets.getServletMappings() != null)\n        {\n            for (ServletMapping mapping : servlets.getServletMappings())\n            {\n                out.openTag(\"servlet-mapping\",origin(md,mapping.getServletName() + \".servlet.mappings\"));\n                out.tag(\"servlet-name\",mapping.getServletName());\n                if (mapping.getPathSpecs() != null)\n                    for (String s : mapping.getPathSpecs())\n                        out.tag(\"url-pattern\",s);\n                out.closeTag();\n            }\n        }\n\n        // Security elements\n        SecurityHandler security =_webApp. getSecurityHandler();\n\n        if (security!=null && (security.getRealmName()!=null || security.getAuthMethod()!=null))\n        {\n            out.openTag(\"login-config\");\n            if (security.getAuthMethod()!=null)\n                out.tag(\"auth-method\",origin(md,\"auth-method\"),security.getAuthMethod());\n            if (security.getRealmName()!=null)\n                out.tag(\"realm-name\",origin(md,\"realm-name\"),security.getRealmName());\n\n\n            if (Constraint.__FORM_AUTH.equalsIgnoreCase(security.getAuthMethod()))\n            {\n                out.openTag(\"form-login-config\");\n                out.tag(\"form-login-page\",origin(md,\"form-login-page\"),security.getInitParameter(FormAuthenticator.__FORM_LOGIN_PAGE));\n                out.tag(\"form-error-page\",origin(md,\"form-error-page\"),security.getInitParameter(FormAuthenticator.__FORM_ERROR_PAGE));\n                out.closeTag();\n            }\n\n            out.closeTag();\n        }\n\n        if (security instanceof ConstraintAware)\n        {\n            ConstraintAware ca = (ConstraintAware)security;\n            for (String r:ca.getRoles())\n                out.openTag(\"security-role\")\n                .tag(\"role-name\",r)\n                .closeTag();\n\n            for (ConstraintMapping m : ca.getConstraintMappings())\n            {\n                out.openTag(\"security-constraint\");\n\n                out.openTag(\"web-resource-collection\");\n                {\n                    if (m.getConstraint().getName()!=null)\n                        out.tag(\"web-resource-name\",m.getConstraint().getName());\n                    if (m.getPathSpec()!=null)\n                        out.tag(\"url-pattern\",origin(md,\"constraint.url.\"+m.getPathSpec()),m.getPathSpec());\n                    if (m.getMethod()!=null)\n                        out.tag(\"http-method\",m.getMethod());\n\n                    if (m.getMethodOmissions()!=null)\n                        for (String o:m.getMethodOmissions())\n                            out.tag(\"http-method-omission\",o);\n\n                    out.closeTag();\n                }\n\n                if (m.getConstraint().getAuthenticate())\n                {\n                    String[] roles = m.getConstraint().getRoles();\n                    if (roles!=null && roles.length>0)\n                    {\n                        out.openTag(\"auth-constraint\");\n                        if (m.getConstraint().getRoles()!=null)\n                            for (String r : m.getConstraint().getRoles())\n                                out.tag(\"role-name\",r);\n                        out.closeTag();\n                    }\n                    else\n                        out.tag(\"auth-constraint\");\n                }\n\n                switch (m.getConstraint().getDataConstraint())\n                {\n                    case Constraint.DC_NONE:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"NONE\").closeTag();\n                        break;\n\n                    case Constraint.DC_INTEGRAL:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"INTEGRAL\").closeTag();\n                        break;\n\n                    case Constraint.DC_CONFIDENTIAL:\n                        out.openTag(\"user-data-constraint\").tag(\"transport-guarantee\",\"CONFIDENTIAL\").closeTag();\n                        break;\n\n                    default:\n                        break;\n\n                }\n\n                out.closeTag();\n\n            }\n        }\n\n        if (_webApp.getWelcomeFiles() != null)\n        {\n            out.openTag(\"welcome-file-list\");\n            for (String welcomeFile:_webApp.getWelcomeFiles())\n            {\n                out.tag(\"welcome-file\", welcomeFile);\n            }\n            out.closeTag();\n        }\n\n        Map<String,String> localeEncodings = _webApp.getLocaleEncodings();\n        if (localeEncodings != null && !localeEncodings.isEmpty())\n        {\n            out.openTag(\"locale-encoding-mapping-list\");\n            for (Map.Entry<String, String> entry:localeEncodings.entrySet())\n            {\n                out.openTag(\"locale-encoding-mapping\", origin(md,\"locale-encoding.\"+entry.getKey()));\n                out.tag(\"locale\", entry.getKey());\n                out.tag(\"encoding\", entry.getValue());\n                out.closeTag();\n            }\n            out.closeTag();\n        }\n\n        //session-config\n        if (_webApp.getSessionHandler().getSessionManager() != null)\n        {\n            out.openTag(\"session-config\");\n            int maxInactiveSec = _webApp.getSessionHandler().getSessionManager().getMaxInactiveInterval();\n            out.tag(\"session-timeout\", (maxInactiveSec==0?\"0\":Integer.toString(maxInactiveSec/60)));\n\n\n            //cookie-config\n            SessionCookieConfig cookieConfig = _webApp.getSessionHandler().getSessionManager().getSessionCookieConfig();\n            if (cookieConfig != null)\n            {\n                out.openTag(\"cookie-config\");\n                if (cookieConfig.getName() != null)\n                    out.tag(\"name\", origin(md,\"cookie-config.name\"), cookieConfig.getName());\n\n                if (cookieConfig.getDomain() != null)\n                    out.tag(\"domain\", origin(md, \"cookie-config.domain\"), cookieConfig.getDomain());\n\n                if (cookieConfig.getPath() != null)\n                    out.tag(\"path\", origin(md, \"cookie-config.path\"), cookieConfig.getPath());\n\n                if (cookieConfig.getComment() != null)\n                    out.tag(\"comment\", origin(md, \"cookie-config.comment\"), cookieConfig.getComment());\n\n                out.tag(\"http-only\", origin(md, \"cookie-config.http-only\"), Boolean.toString(cookieConfig.isHttpOnly()));\n                out.tag(\"secure\", origin(md, \"cookie-config.secure\"), Boolean.toString(cookieConfig.isSecure()));\n                out.tag(\"max-age\", origin(md, \"cookie-config.max-age\"), Integer.toString(cookieConfig.getMaxAge()));\n                out.closeTag();\n            }\n            \n            // tracking-modes\n            Set<SessionTrackingMode> modes =_webApp. getSessionHandler().getSessionManager().getEffectiveSessionTrackingModes();\n            if (modes != null)\n            {\n                for (SessionTrackingMode mode:modes)\n                    out.tag(\"tracking-mode\", mode.toString());\n            }\n            \n            out.closeTag();     \n        }\n\n        //error-pages\n        Map<String,String> errorPages = ((ErrorPageErrorHandler)_webApp.getErrorHandler()).getErrorPages();\n        if (errorPages != null)\n        {\n            for (Map.Entry<String, String> entry:errorPages.entrySet())\n            {\n                out.openTag(\"error-page\", origin(md, \"error.\"+entry.getKey()));\n                //a global or default error page has no code or exception               \n                if (!ErrorPageErrorHandler.GLOBAL_ERROR_PAGE.equals(entry.getKey()))\n                {\n                    if (entry.getKey().matches(\"\\\\d{3}\"))\n                        out.tag(\"error-code\", entry.getKey());\n                    else\n                        out.tag(\"exception-type\", entry.getKey());\n                }\n                out.tag(\"location\", entry.getValue());\n                out.closeTag();\n            }\n        }\n\n        //mime-types\n        MimeTypes mimeTypes = _webApp.getMimeTypes();\n        if (mimeTypes != null)\n        {\n            for (Map.Entry<String, String> entry:mimeTypes.getMimeMap().entrySet())\n            {\n                out.openTag(\"mime-mapping\");\n                out.tag(\"extension\", origin(md, \"extension.\"+entry.getKey()), entry.getKey());\n                out.tag(\"mime-type\", entry.getValue());\n                out.closeTag();\n            }\n        }\n\n        //jsp-config\n        JspConfig jspConfig = (JspConfig)_webApp.getServletContext().getJspConfigDescriptor();\n        if (jspConfig != null)\n        {\n            out.openTag(\"jsp-config\");\n            Collection<TaglibDescriptor> tlds = jspConfig.getTaglibs();\n            if (tlds != null && !tlds.isEmpty())\n            {\n                for (TaglibDescriptor tld:tlds)\n                {\n                    out.openTag(\"taglib\");\n                    out.tag(\"taglib-uri\", tld.getTaglibURI());\n                    out.tag(\"taglib-location\", tld.getTaglibLocation());\n                    out.closeTag();\n                }\n            }\n\n            Collection<JspPropertyGroupDescriptor> jspPropertyGroups = jspConfig.getJspPropertyGroups();\n            if (jspPropertyGroups != null && !jspPropertyGroups.isEmpty())\n            {\n                for (JspPropertyGroupDescriptor jspPropertyGroup:jspPropertyGroups)\n                {\n                    out.openTag(\"jsp-property-group\");\n                    Collection<String> strings = jspPropertyGroup.getUrlPatterns();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String urlPattern:strings)\n                            out.tag(\"url-pattern\", urlPattern);\n                    }\n\n                    if (jspPropertyGroup.getElIgnored() != null)\n                        out.tag(\"el-ignored\", jspPropertyGroup.getElIgnored());\n\n                    if (jspPropertyGroup.getPageEncoding() != null)\n                        out.tag(\"page-encoding\", jspPropertyGroup.getPageEncoding());\n\n                    if (jspPropertyGroup.getScriptingInvalid() != null)\n                        out.tag(\"scripting-invalid\", jspPropertyGroup.getScriptingInvalid());\n\n                    if (jspPropertyGroup.getIsXml() != null)\n                        out.tag(\"is-xml\", jspPropertyGroup.getIsXml());\n\n                    if (jspPropertyGroup.getDeferredSyntaxAllowedAsLiteral() != null)\n                        out.tag(\"deferred-syntax-allowed-as-literal\", jspPropertyGroup.getDeferredSyntaxAllowedAsLiteral());\n\n                    if (jspPropertyGroup.getTrimDirectiveWhitespaces() != null)\n                        out.tag(\"trim-directive-whitespaces\", jspPropertyGroup.getTrimDirectiveWhitespaces());\n\n                    if (jspPropertyGroup.getDefaultContentType() != null)\n                        out.tag(\"default-content-type\", jspPropertyGroup.getDefaultContentType());\n\n                    if (jspPropertyGroup.getBuffer() != null)\n                        out.tag(\"buffer\", jspPropertyGroup.getBuffer());\n\n                    if (jspPropertyGroup.getErrorOnUndeclaredNamespace() != null)\n                        out.tag(\"error-on-undeclared-namespace\", jspPropertyGroup.getErrorOnUndeclaredNamespace());\n\n                    strings = jspPropertyGroup.getIncludePreludes();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String prelude:strings)\n                            out.tag(\"include-prelude\", prelude);\n                    }\n\n                    strings = jspPropertyGroup.getIncludeCodas();\n                    if (strings != null && !strings.isEmpty())\n                    {\n                        for (String coda:strings)\n                            out.tag(\"include-coda\", coda);\n                    }\n\n                    out.closeTag();\n                }\n            }\n\n            out.closeTag();\n        }\n\n        //lifecycle: post-construct, pre-destroy\n        LifeCycleCallbackCollection lifecycles = ((LifeCycleCallbackCollection)_webApp.getAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION));\n        if (lifecycles != null)\n        {\n            Collection<LifeCycleCallback> tmp = lifecycles.getPostConstructCallbacks();\n\n            for (LifeCycleCallback c:tmp)\n            {\n                out.openTag(\"post-construct\");\n                out.tag(\"lifecycle-callback-class\", c.getTargetClassName());\n                out.tag(\"lifecycle-callback-method\", c.getMethodName());\n                out.closeTag();\n            }\n\n            tmp = lifecycles.getPreDestroyCallbacks();\n            for (LifeCycleCallback c:tmp)\n            {\n                out.openTag(\"pre-destroy\");\n                out.tag(\"lifecycle-callback-class\", c.getTargetClassName());\n                out.tag(\"lifecycle-callback-method\", c.getMethodName());\n                out.closeTag();\n            }\n        }\n\n        out.literal(_extraXML);\n\n        out.closeTag();\n    }","commit_id":"4c8e2a6635d6a13a783a567aa890237a88a62e56","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n    public void ensureParser()\n    throws ClassNotFoundException\n    {\n        if (_parserSingleton == null)\n        {\n            _parserSingleton = newParser();\n        }\n        _parser = _parserSingleton;\n    }","id":36018,"modified_method":"@Override\n    public void ensureParser() throws ClassNotFoundException\n    {\n        synchronized (WebDescriptor.class)\n        {\n            if (_parserSingleton == null)\n                _parserSingleton = newParser(isValidating());\n        }\n        \n        if (_parserSingleton.isValidating()==isValidating())\n            _parser = _parserSingleton;\n        else\n            _parser = newParser(isValidating());\n    }","commit_id":"4c8e2a6635d6a13a783a567aa890237a88a62e56","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public XmlParser newParser()\n    throws ClassNotFoundException\n    {\n        XmlParser xmlParser=new XmlParser()\n        {\n            boolean mapped=false;\n            \n            @Override\n            protected InputSource resolveEntity(String pid, String sid)\n            {\n                if (!mapped)\n                {\n                    mapResources();\n                    mapped=true;\n                }\n                InputSource is = super.resolveEntity(pid,sid);\n                return is;\n            }\n            \n            void mapResources()\n            {\n                //set up cache of DTDs and schemas locally\n                URL dtd22=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_2.dtd\");\n                URL dtd23=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_3.dtd\");\n                URL j2ee14xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/j2ee_1_4.xsd\");\n                URL javaee5=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_5.xsd\");\n                URL javaee6=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_6.xsd\");\n                URL javaee7=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_7.xsd\");\n\n                URL webapp24xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_4.xsd\");\n                URL webapp25xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_5.xsd\");\n                URL webapp30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_3_0.xsd\");\n                URL webapp31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_3_1.xsd\");\n                \n                URL webcommon30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-common_3_0.xsd\");\n                URL webcommon31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-common_3_1.xsd\");\n            \n                URL webfragment30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-fragment_3_0.xsd\");\n                URL webfragment31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-fragment_3_1.xsd\");\n                \n                URL schemadtd=Loader.getResource(Servlet.class,\"javax/servlet/resources/XMLSchema.dtd\");\n                URL xmlxsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/xml.xsd\");\n                URL webservice11xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/j2ee_web_services_client_1_1.xsd\");\n                URL webservice12xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_2.xsd\");\n                URL webservice13xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_3.xsd\");\n                URL webservice14xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_4.xsd\");\n                URL datatypesdtd=Loader.getResource(Servlet.class,\"javax/servlet/resources/datatypes.dtd\");\n                \n                URL jsp20xsd = null;\n                URL jsp21xsd = null;\n                URL jsp22xsd = null;\n                URL jsp23xsd = null;\n\n                try\n                {\n                    //try both javax/servlet/resources and javax/servlet/jsp/resources to load \n                    jsp20xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_0.xsd\");\n                    jsp21xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_1.xsd\");\n                    jsp22xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_2.xsd\");\n                    jsp23xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_3.xsd\");\n                }\n                catch (Exception e)\n                {\n                    LOG.ignore(e);\n                }\n                finally\n                {\n                    if (jsp20xsd == null) jsp20xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_0.xsd\");\n                    if (jsp21xsd == null) jsp21xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_1.xsd\");\n                    if (jsp22xsd == null) jsp22xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_2.xsd\");\n                    if (jsp23xsd == null) jsp23xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_3.xsd\");\n                }\n\n                redirect(this,\"web-app_2_2.dtd\",dtd22);\n                redirect(this,\"-//Sun Microsystems, Inc.//DTD Web Application 2.2//EN\",dtd22);\n                redirect(this,\"web.dtd\",dtd23);\n                redirect(this,\"web-app_2_3.dtd\",dtd23);\n                redirect(this,\"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\",dtd23);\n                redirect(this,\"XMLSchema.dtd\",schemadtd);\n                redirect(this,\"http://www.w3.org/2001/XMLSchema.dtd\",schemadtd);\n                redirect(this,\"-//W3C//DTD XMLSCHEMA 200102//EN\",schemadtd);\n                redirect(this,\"jsp_2_0.xsd\",jsp20xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/j2ee/jsp_2_0.xsd\",jsp20xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/jsp_2_1.xsd\",jsp21xsd);\n                redirect(this,\"jsp_2_2.xsd\",jsp22xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/jsp_2_2.xsd\",jsp22xsd);\n                redirect(this,\"jsp_2_3.xsd\",jsp23xsd);\n                redirect(this,\"http://xmlns.jcp.org/xml/ns/javaee/jsp_2_3.xsd\",jsp23xsd);\n                redirect(this,\"j2ee_1_4.xsd\",j2ee14xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/j2ee/j2ee_1_4.xsd\",j2ee14xsd);\n                redirect(this, \"http://java.sun.com/xml/ns/javaee/javaee_5.xsd\",javaee5);\n                redirect(this, \"http://java.sun.com/xml/ns/javaee/javaee_6.xsd\",javaee6);\n                redirect(this, \"http://xmlns.jcp.org/xml/ns/javaee/javaee_7.xsd\",javaee7);\n                redirect(this,\"web-app_2_4.xsd\",webapp24xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\",webapp24xsd);\n                redirect(this,\"web-app_2_5.xsd\",webapp25xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\",webapp25xsd);\n                redirect(this,\"web-app_3_0.xsd\",webapp30xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\",webapp30xsd);\n                redirect(this,\"web-common_3_0.xsd\",webcommon30xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/web-common_3_0.xsd\",webcommon30xsd);\n                redirect(this,\"web-fragment_3_0.xsd\",webfragment30xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/web-fragment_3_0.xsd\",webfragment30xsd);\n                redirect(this,\"web-app_3_1.xsd\",webapp31xsd);\n                redirect(this,\"http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\",webapp31xsd);\n                \n                redirect(this,\"web-common_3_1.xsd\",webcommon30xsd);\n                redirect(this,\"http://xmlns.jcp.org/xml/ns/javaee/web-common_3_1.xsd\",webcommon31xsd);\n                redirect(this,\"web-fragment_3_1.xsd\",webfragment30xsd);\n                redirect(this,\"http://xmlns.jcp.org/xml/ns/javaee/web-fragment_3_1.xsd\",webfragment31xsd);\n                redirect(this,\"xml.xsd\",xmlxsd);\n                redirect(this,\"http://www.w3.org/2001/xml.xsd\",xmlxsd);\n                redirect(this,\"datatypes.dtd\",datatypesdtd);\n                redirect(this,\"http://www.w3.org/2001/datatypes.dtd\",datatypesdtd);\n                redirect(this,\"j2ee_web_services_client_1_1.xsd\",webservice11xsd);\n                redirect(this,\"http://www.ibm.com/webservices/xsd/j2ee_web_services_client_1_1.xsd\",webservice11xsd);\n                redirect(this,\"javaee_web_services_client_1_2.xsd\",webservice12xsd);   \n                redirect(this,\"http://www.ibm.com/webservices/xsd/javaee_web_services_client_1_2.xsd\",webservice12xsd);\n                redirect(this,\"javaee_web_services_client_1_3.xsd\",webservice13xsd);\n                redirect(this,\"http://java.sun.com/xml/ns/javaee/javaee_web_services_client_1_3.xsd\",webservice13xsd);\n                redirect(this,\"javaee_web_services_client_1_4.xsd\",webservice14xsd);\n                redirect(this,\"http://xmlns.jcp.org/xml/ns/javaee/javaee_web_services_client_1_4.xsd\",webservice14xsd);\n            }\n        };\n        \n        return xmlParser;\n    }","id":36019,"modified_method":"public static XmlParser newParser(boolean validating) throws ClassNotFoundException\n    {\n        XmlParser xmlParser=new XmlParser(validating)\n        {\n            boolean mapped=false;\n            \n            @Override\n            protected InputSource resolveEntity(String pid, String sid)\n            {\n                if (!mapped)\n                {\n                    mapResources();\n                    mapped=true;\n                }\n                InputSource is = super.resolveEntity(pid,sid);\n                return is;\n            }\n            \n            void mapResources()\n            {\n                //set up cache of DTDs and schemas locally\n                URL dtd22=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_2.dtd\");\n                URL dtd23=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_3.dtd\");\n                URL j2ee14xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/j2ee_1_4.xsd\");\n                URL javaee5=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_5.xsd\");\n                URL javaee6=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_6.xsd\");\n                URL javaee7=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_7.xsd\");\n\n                URL webapp24xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_4.xsd\");\n                URL webapp25xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_2_5.xsd\");\n                URL webapp30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_3_0.xsd\");\n                URL webapp31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-app_3_1.xsd\");\n                \n                URL webcommon30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-common_3_0.xsd\");\n                URL webcommon31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-common_3_1.xsd\");\n            \n                URL webfragment30xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-fragment_3_0.xsd\");\n                URL webfragment31xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/web-fragment_3_1.xsd\");\n                \n                URL schemadtd=Loader.getResource(Servlet.class,\"javax/servlet/resources/XMLSchema.dtd\");\n                URL xmlxsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/xml.xsd\");\n                URL webservice11xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/j2ee_web_services_client_1_1.xsd\");\n                URL webservice12xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_2.xsd\");\n                URL webservice13xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_3.xsd\");\n                URL webservice14xsd=Loader.getResource(Servlet.class,\"javax/servlet/resources/javaee_web_services_client_1_4.xsd\");\n                URL datatypesdtd=Loader.getResource(Servlet.class,\"javax/servlet/resources/datatypes.dtd\");\n                \n                URL jsp20xsd = null;\n                URL jsp21xsd = null;\n                URL jsp22xsd = null;\n                URL jsp23xsd = null;\n\n                try\n                {\n                    //try both javax/servlet/resources and javax/servlet/jsp/resources to load \n                    jsp20xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_0.xsd\");\n                    jsp21xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_1.xsd\");\n                    jsp22xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_2.xsd\");\n                    jsp23xsd = Loader.getResource(Servlet.class, \"javax/servlet/resources/jsp_2_3.xsd\");\n                }\n                catch (Exception e)\n                {\n                    LOG.ignore(e);\n                }\n                finally\n                {\n                    if (jsp20xsd == null) jsp20xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_0.xsd\");\n                    if (jsp21xsd == null) jsp21xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_1.xsd\");\n                    if (jsp22xsd == null) jsp22xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_2.xsd\");\n                    if (jsp23xsd == null) jsp23xsd = Loader.getResource(Servlet.class, \"javax/servlet/jsp/resources/jsp_2_3.xsd\");\n                }\n                \n                redirectEntity(\"web-app_2_2.dtd\",dtd22);\n                redirectEntity(\"-//Sun Microsystems, Inc.//DTD Web Application 2.2//EN\",dtd22);\n                redirectEntity(\"web.dtd\",dtd23);\n                redirectEntity(\"web-app_2_3.dtd\",dtd23);\n                redirectEntity(\"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\",dtd23);\n                redirectEntity(\"XMLSchema.dtd\",schemadtd);\n                redirectEntity(\"http://www.w3.org/2001/XMLSchema.dtd\",schemadtd);\n                redirectEntity(\"-//W3C//DTD XMLSCHEMA 200102//EN\",schemadtd);\n                redirectEntity(\"jsp_2_0.xsd\",jsp20xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/j2ee/jsp_2_0.xsd\",jsp20xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/jsp_2_1.xsd\",jsp21xsd);\n                redirectEntity(\"jsp_2_2.xsd\",jsp22xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/jsp_2_2.xsd\",jsp22xsd);\n                redirectEntity(\"jsp_2_3.xsd\",jsp23xsd);\n                redirectEntity(\"http://xmlns.jcp.org/xml/ns/javaee/jsp_2_3.xsd\",jsp23xsd);\n                redirectEntity(\"j2ee_1_4.xsd\",j2ee14xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/j2ee/j2ee_1_4.xsd\",j2ee14xsd);\n                redirectEntity( \"http://java.sun.com/xml/ns/javaee/javaee_5.xsd\",javaee5);\n                redirectEntity( \"http://java.sun.com/xml/ns/javaee/javaee_6.xsd\",javaee6);\n                redirectEntity( \"http://xmlns.jcp.org/xml/ns/javaee/javaee_7.xsd\",javaee7);\n                redirectEntity(\"web-app_2_4.xsd\",webapp24xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\",webapp24xsd);\n                redirectEntity(\"web-app_2_5.xsd\",webapp25xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\",webapp25xsd);\n                redirectEntity(\"web-app_3_0.xsd\",webapp30xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\",webapp30xsd);\n                redirectEntity(\"web-common_3_0.xsd\",webcommon30xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/web-common_3_0.xsd\",webcommon30xsd);\n                redirectEntity(\"web-fragment_3_0.xsd\",webfragment30xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/web-fragment_3_0.xsd\",webfragment30xsd);\n                redirectEntity(\"web-app_3_1.xsd\",webapp31xsd);\n                redirectEntity(\"http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\",webapp31xsd);\n                \n                redirectEntity(\"web-common_3_1.xsd\",webcommon30xsd);\n                redirectEntity(\"http://xmlns.jcp.org/xml/ns/javaee/web-common_3_1.xsd\",webcommon31xsd);\n                redirectEntity(\"web-fragment_3_1.xsd\",webfragment30xsd);\n                redirectEntity(\"http://xmlns.jcp.org/xml/ns/javaee/web-fragment_3_1.xsd\",webfragment31xsd);\n                redirectEntity(\"xml.xsd\",xmlxsd);\n                redirectEntity(\"http://www.w3.org/2001/xml.xsd\",xmlxsd);\n                redirectEntity(\"datatypes.dtd\",datatypesdtd);\n                redirectEntity(\"http://www.w3.org/2001/datatypes.dtd\",datatypesdtd);\n                redirectEntity(\"j2ee_web_services_client_1_1.xsd\",webservice11xsd);\n                redirectEntity(\"http://www.ibm.com/webservices/xsd/j2ee_web_services_client_1_1.xsd\",webservice11xsd);\n                redirectEntity(\"javaee_web_services_client_1_2.xsd\",webservice12xsd);   \n                redirectEntity(\"http://www.ibm.com/webservices/xsd/javaee_web_services_client_1_2.xsd\",webservice12xsd);\n                redirectEntity(\"javaee_web_services_client_1_3.xsd\",webservice13xsd);\n                redirectEntity(\"http://java.sun.com/xml/ns/javaee/javaee_web_services_client_1_3.xsd\",webservice13xsd);\n                redirectEntity(\"javaee_web_services_client_1_4.xsd\",webservice14xsd);\n                redirectEntity(\"http://xmlns.jcp.org/xml/ns/javaee/javaee_web_services_client_1_4.xsd\",webservice14xsd);\n            }\n        };\n        \n        return xmlParser;\n    }","commit_id":"4c8e2a6635d6a13a783a567aa890237a88a62e56","url":"https://github.com/eclipse/jetty.project"},{"original_method":"/**\n\t * Constructor.\n\t * \n\t * @param message   message describing the error\n\t * @param exception exception which is the cause of the error\n\t */\n\tpublic AnalysisError(String message, Throwable exception) {\n\t\tthis.message = message;\n\t\tif (exception != null) {\n\t\t\texceptionMessage = exception.toString();\n\t\t\tStackTraceElement[] exceptionStackTrace = exception.getStackTrace();\n\t\t\tArrayList<String> arr = new ArrayList<String>();\n\t\t\tfor (StackTraceElement aExceptionStackTrace : exceptionStackTrace) {\n\t\t\t\tarr.add(aExceptionStackTrace.toString());\n\t\t\t}\n\t\t\tstackTrace = arr.toArray(new String[arr.size()]);\n\t\t}\n\t}","id":36020,"modified_method":"/**\n\t * Constructor.\n\t * \n\t * @param message   message describing the error\n\t * @param exception exception which is the cause of the error\n\t */\n\tpublic AnalysisError(String message, Throwable exception) {\n\t\tthis.message = message;\n\t\tif (exception != null) {\n\t\t\texceptionMessage = exception.toString();\n\t\t\tstackTrace =  getStackTraceAsStringArray(exception);\n\t\t\tThrowable initCause = exception.getCause();\n\t\t\tif (initCause != null) {\n\t\t\t\tnestedExceptionMessage = initCause.toString();\n\t\t\t\tnestedStackTrace = getStackTraceAsStringArray(initCause);\n\t\t\t}\n\t\t\t\n\t\t}\n\t}","commit_id":"95a3a1b9638d7f3ce70885eb54ae54e74ffcf6ce","url":"https://github.com/findbugsproject/findbugs"},{"original_method":"private void emitErrors(XMLOutput xmlOutput) throws IOException {\n\t\t//System.err.println(\"Writing errors to XML output\");\n\n\t\txmlOutput.openTag(ERRORS_ELEMENT_NAME);\n\n\t\t// Emit Error elements describing analysis errors\n\t\tfor (Iterator<AnalysisError> i = errorIterator(); i.hasNext(); ) {\n\t\t\tAnalysisError error = i.next();\n\t\t\txmlOutput.openTag(ERROR_ELEMENT_NAME);\n\n\t\t\txmlOutput.openTag(ERROR_MESSAGE_ELEMENT_NAME);\n\t\t\txmlOutput.writeText(error.getMessage());\n\t\t\txmlOutput.closeTag(ERROR_MESSAGE_ELEMENT_NAME);\n\n\t\t\tif (error.getExceptionMessage() != null) {\n\t\t\t\txmlOutput.openTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\t\t\t\txmlOutput.writeText(error.getExceptionMessage());\n\t\t\t\txmlOutput.closeTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\t\t\t}\n\n\t\t\tString stackTrace[] = error.getStackTrace();\n\t\t\tif (stackTrace != null) {\n\t\t\t\tfor (String aStackTrace : stackTrace) {\n\t\t\t\t\txmlOutput.openTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t\txmlOutput.writeText(aStackTrace);\n\t\t\t\t\txmlOutput.closeTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\txmlOutput.closeTag(ERROR_ELEMENT_NAME);\n\t\t}\n\n\t\t// Emit missing classes\n\t\tXMLOutputUtil.writeElementList(xmlOutput, MISSING_CLASS_ELEMENT_NAME,\n\t\t\tmissingClassIterator());\n\n\t\txmlOutput.closeTag(ERRORS_ELEMENT_NAME);\n\t}","id":36021,"modified_method":"private void emitErrors(XMLOutput xmlOutput) throws IOException {\n\t\t//System.err.println(\"Writing errors to XML output\");\n\n\t\txmlOutput.openTag(ERRORS_ELEMENT_NAME);\n\n\t\t// Emit Error elements describing analysis errors\n\t\tfor (Iterator<AnalysisError> i = errorIterator(); i.hasNext(); ) {\n\t\t\tAnalysisError error = i.next();\n\t\t\txmlOutput.openTag(ERROR_ELEMENT_NAME);\n\n\t\t\txmlOutput.openTag(ERROR_MESSAGE_ELEMENT_NAME);\n\t\t\txmlOutput.writeText(error.getMessage());\n\t\t\txmlOutput.closeTag(ERROR_MESSAGE_ELEMENT_NAME);\n\n\t\t\tif (error.getExceptionMessage() != null) {\n\t\t\t\txmlOutput.openTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\t\t\t\txmlOutput.writeText(error.getExceptionMessage());\n\t\t\t\txmlOutput.closeTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\n\t\t\t\tString stackTrace[] = error.getStackTrace();\n\t\t\t\tif (stackTrace != null) {\n\t\t\t\t\tfor (String aStackTrace : stackTrace) {\n\t\t\t\t\t\txmlOutput.openTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t\t\txmlOutput.writeText(aStackTrace);\n\t\t\t\t\t\txmlOutput.closeTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (error.getNestedExceptionMessage() != null) {\n\t\t\t\t\txmlOutput.openTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\t\t\t\t\txmlOutput.writeText(error.getNestedExceptionMessage());\n\t\t\t\t\txmlOutput.closeTag(ERROR_EXCEPTION_ELEMENT_NAME);\n\n\t\t\t\t\tstackTrace = error.getNestedStackTrace();\n\t\t\t\t\tif (stackTrace != null) {\n\t\t\t\t\t\tfor (String aStackTrace : stackTrace) {\n\t\t\t\t\t\t\txmlOutput.openTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t\t\t\txmlOutput.writeText(aStackTrace);\n\t\t\t\t\t\t\txmlOutput.closeTag(ERROR_STACK_TRACE_ELEMENT_NAME);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\txmlOutput.closeTag(ERROR_ELEMENT_NAME);\n\t\t}\n\n\t\t// Emit missing classes\n\t\tXMLOutputUtil.writeElementList(xmlOutput, MISSING_CLASS_ELEMENT_NAME,\n\t\t\tmissingClassIterator());\n\n\t\txmlOutput.closeTag(ERRORS_ELEMENT_NAME);\n\t}","commit_id":"95a3a1b9638d7f3ce70885eb54ae54e74ffcf6ce","url":"https://github.com/findbugsproject/findbugs"},{"original_method":"void createBinaries(BinaryContainer binaries, LibraryContainer libraries) {\n        for (JvmLibrary jvmLibrary : libraries.withType(JvmLibrary.class)) {\n            BinaryNamingScheme namingScheme = namingSchemeBuilder\n                    .withComponentName(jvmLibrary.getName())\n                    .withTypeString(\"jar\")\n                    .build();\n            binaries.add(new DefaultJvmLibraryBinary(jvmLibrary, namingScheme));\n        }\n    }","id":36022,"modified_method":"void createBinaries(BinaryContainer binaries, SoftwareComponentContainer libraries) {\n        for (JvmLibrary jvmLibrary : libraries.withType(JvmLibrary.class)) {\n            BinaryNamingScheme namingScheme = namingSchemeBuilder\n                    .withComponentName(jvmLibrary.getName())\n                    .withTypeString(\"jar\")\n                    .build();\n            binaries.add(new DefaultJvmLibraryBinary(jvmLibrary, namingScheme));\n        }\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"private Collection<ProjectNativeComponent> allComponents() {\n        ExecutableContainer executables = project.getExtensions().getByType(ExecutableContainer.class);\n        LibraryContainer libraries = project.getExtensions().getByType(LibraryContainer.class);\n\n        List<ProjectNativeComponent> components = new ArrayList<ProjectNativeComponent>();\n        for (NativeLibrary library : libraries.withType(NativeLibrary.class)) {\n            components.add(library);\n        }\n        for (NativeExecutable executable : executables) {\n            components.add(executable);\n        }\n        return components;\n    }","id":36023,"modified_method":"private Collection<ProjectNativeComponent> allComponents() {\n        SoftwareComponentContainer softwareComponents = project.getExtensions().getByType(SoftwareComponentContainer.class);\n\n        List<ProjectNativeComponent> components = new ArrayList<ProjectNativeComponent>();\n        // TODO:DAZ merge\n        for (NativeLibrary library : softwareComponents.withType(NativeLibrary.class)) {\n            components.add(library);\n        }\n        for (NativeExecutable executable : softwareComponents.withType(NativeExecutable.class)) {\n            components.add(executable);\n        }\n        return components;\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final Project project) {\n        project.getPlugins().apply(LifecycleBasePlugin.class);\n        project.getPlugins().apply(LanguageBasePlugin.class);\n\n        LibraryContainer libraries = project.getExtensions().getByType(LibraryContainer.class);\n        libraries.registerFactory(JvmLibrary.class, new NamedDomainObjectFactory<JvmLibrary>() {\n            public JvmLibrary create(String name) {\n                return new DefaultJvmLibrary(name);\n            }\n        });\n\n        modelRules.register(\"libraries\", libraries);\n        modelRules.rule(new CreateJvmBinaries(new DefaultBinaryNamingSchemeBuilder()));\n        modelRules.rule(new CreateTasksForJvmBinaries());\n        modelRules.rule(new AttachBinariesToLifecycle());\n    }","id":36024,"modified_method":"public void apply(final Project project) {\n        project.getPlugins().apply(LifecycleBasePlugin.class);\n        project.getPlugins().apply(LanguageBasePlugin.class);\n\n        // TODO:DAZ Introduce jvmLibraries typed container\n        SoftwareComponentContainer libraries = project.getExtensions().getByType(SoftwareComponentContainer.class);\n        libraries.registerFactory(JvmLibrary.class, new NamedDomainObjectFactory<JvmLibrary>() {\n            public JvmLibrary create(String name) {\n                return new DefaultJvmLibrary(name);\n            }\n        });\n\n        modelRules.register(\"libraries\", libraries);\n        modelRules.rule(new CreateJvmBinaries(new DefaultBinaryNamingSchemeBuilder()));\n        modelRules.rule(new CreateTasksForJvmBinaries());\n        modelRules.rule(new AttachBinariesToLifecycle());\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final Project target) {\n        target.getExtensions().create(\"libraries\", DefaultLibraryContainer.class, instantiator);\n        target.getExtensions().create(\"sources\", DefaultProjectSourceSet.class, instantiator);\n        final BinaryContainer binaries = target.getExtensions().create(\"binaries\", DefaultBinaryContainer.class, instantiator);\n\n        modelRules.register(\"binaries\", BinaryContainer.class, new Factory<BinaryContainer>() {\n            public BinaryContainer create() {\n                return binaries;\n            }\n        });\n\n        binaries.withType(BinaryInternal.class).all(new Action<BinaryInternal>() {\n            public void execute(BinaryInternal binary) {\n                Task binaryLifecycleTask = target.task(binary.getNamingScheme().getLifecycleTaskName());\n                binaryLifecycleTask.setGroup(LifecycleBasePlugin.BUILD_GROUP);\n                binaryLifecycleTask.setDescription(String.format(\"Assembles %s.\", binary));\n                binary.setLifecycleTask(binaryLifecycleTask);\n            }\n        });\n    }","id":36025,"modified_method":"public void apply(final Project target) {\n        // TODO:DAZ Rename to components and introduce 'jvmLibraries'\n        target.getExtensions().create(\"libraries\", DefaultSoftwareComponentContainer.class, instantiator);\n        target.getExtensions().create(\"sources\", DefaultProjectSourceSet.class, instantiator);\n        final BinaryContainer binaries = target.getExtensions().create(\"binaries\", DefaultBinaryContainer.class, instantiator);\n\n        modelRules.register(\"binaries\", BinaryContainer.class, new Factory<BinaryContainer>() {\n            public BinaryContainer create() {\n                return binaries;\n            }\n        });\n\n        binaries.withType(BinaryInternal.class).all(new Action<BinaryInternal>() {\n            public void execute(BinaryInternal binary) {\n                Task binaryLifecycleTask = target.task(binary.getNamingScheme().getLifecycleTaskName());\n                binaryLifecycleTask.setGroup(LifecycleBasePlugin.BUILD_GROUP);\n                binaryLifecycleTask.setDescription(String.format(\"Assembles %s.\", binary));\n                binary.setLifecycleTask(binaryLifecycleTask);\n            }\n        });\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final ProjectInternal project) {\n        project.getPlugins().apply(BasePlugin.class);\n        project.getPlugins().apply(LanguageBasePlugin.class);\n\n        modelRules.register(\"toolChains\", ToolChainRegistryInternal.class, factory(DefaultToolChainRegistry.class));\n        modelRules.register(\"platforms\", PlatformContainer.class, factory(DefaultPlatformContainer.class));\n        modelRules.register(\"buildTypes\", BuildTypeContainer.class, factory(DefaultBuildTypeContainer.class));\n        modelRules.register(\"flavors\", FlavorContainer.class, factory(DefaultFlavorContainer.class));\n\n        project.getModelRegistry().create(\"repositories\", Arrays.asList(\"flavors\", \"platforms\", \"buildTypes\"), new RepositoriesFactory(instantiator, fileResolver));\n\n        modelRules.rule(new CreateDefaultPlatform());\n        modelRules.rule(new CreateDefaultBuildTypes());\n        modelRules.rule(new CreateDefaultFlavors());\n        modelRules.rule(new AddDefaultToolChainsIfRequired());\n        modelRules.rule(new CreateNativeBinaries(instantiator, project, resolver));\n        // TODO:DAZ Push this down to LanguageBasePlugin (but first need to deal with ClassDirectoryBinary)\n        modelRules.rule(new AttachBinariesToLifecycle());\n\n        DefaultLibraryContainer libraries = (DefaultLibraryContainer) project.getExtensions().getByType(LibraryContainer.class);\n        libraries.registerFactory(NativeLibrary.class, new NativeLibraryFactory(instantiator, project));\n\n        NamedDomainObjectContainer<NativeLibrary> nativeLibraries = libraries.containerWithType(NativeLibrary.class);\n        project.getExtensions().add(\"nativeLibraries\", nativeLibraries);\n\n        project.getExtensions().create(\n                \"nativeExecutables\",\n                DefaultExecutableContainer.class,\n                instantiator,\n                project\n        );\n\n        configurationActions.add(Actions.composite(\n                new ConfigureGeneratedSourceSets(),\n                new ApplySourceSetConventions()\n        ));\n    }","id":36026,"modified_method":"public void apply(final ProjectInternal project) {\n        project.getPlugins().apply(BasePlugin.class);\n        project.getPlugins().apply(LanguageBasePlugin.class);\n\n        modelRules.register(\"toolChains\", ToolChainRegistryInternal.class, factory(DefaultToolChainRegistry.class));\n        modelRules.register(\"platforms\", PlatformContainer.class, factory(DefaultPlatformContainer.class));\n        modelRules.register(\"buildTypes\", BuildTypeContainer.class, factory(DefaultBuildTypeContainer.class));\n        modelRules.register(\"flavors\", FlavorContainer.class, factory(DefaultFlavorContainer.class));\n\n        project.getModelRegistry().create(\"repositories\", Arrays.asList(\"flavors\", \"platforms\", \"buildTypes\"), new RepositoriesFactory(instantiator, fileResolver));\n\n        modelRules.rule(new CreateDefaultPlatform());\n        modelRules.rule(new CreateDefaultBuildTypes());\n        modelRules.rule(new CreateDefaultFlavors());\n        modelRules.rule(new AddDefaultToolChainsIfRequired());\n        modelRules.rule(new CreateNativeBinaries(instantiator, project, resolver));\n        // TODO:DAZ Push this down to LanguageBasePlugin (but first need to deal with ClassDirectoryBinary)\n        modelRules.rule(new AttachBinariesToLifecycle());\n\n        SoftwareComponentContainer components = project.getExtensions().getByType(SoftwareComponentContainer.class);\n        components.registerFactory(NativeLibrary.class, new NativeLibraryFactory(instantiator, project));\n        project.getExtensions().add(\"nativeLibraries\", components.containerWithType(NativeLibrary.class));\n\n        components.registerFactory(NativeExecutable.class, new NativeExecutableFactory(instantiator, project));\n        project.getExtensions().add(\"nativeExecutables\", components.containerWithType(NativeExecutable.class));\n\n        configurationActions.add(Actions.composite(\n                new ConfigureGeneratedSourceSets(),\n                new ApplySourceSetConventions()\n        ));\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"public DomainObjectSet<NativeBinary> getBinaries(NativeLibraryRequirement requirement) {\n        Project project = findProject(requirement);\n        LibraryContainer libraryContainer = (LibraryContainer) project.getExtensions().findByName(\"libraries\");\n        if (libraryContainer == null) {\n            throw new LibraryResolveException(String.format(\"Project does not have a libraries container: '%s'\", project.getPath()));\n        }\n        return libraryContainer.withType(NativeLibrary.class).getByName(requirement.getLibraryName()).getBinaries();\n    }","id":36027,"modified_method":"public DomainObjectSet<NativeBinary> getBinaries(NativeLibraryRequirement requirement) {\n        Project project = findProject(requirement);\n        SoftwareComponentContainer softwareComponentContainer = project.getExtensions().findByType(SoftwareComponentContainer.class);\n        if (softwareComponentContainer == null) {\n            throw new LibraryResolveException(String.format(\"Project does not have a libraries container: '%s'\", project.getPath()));\n        }\n        return softwareComponentContainer.withType(NativeLibrary.class).getByName(requirement.getLibraryName()).getBinaries();\n    }","commit_id":"c8380cc80e5fa34030cc6dd188fe922528a7decd","url":"https://github.com/gradle/gradle"},{"original_method":"protected AbstractNamedDomainObjectContainer(Class<? extends T> type, Instantiator instantiator, Namer<? super T> namer) {\n        super(type, instantiator, namer);\n    }","id":36028,"modified_method":"protected AbstractNamedDomainObjectContainer(Class<T> type, Instantiator instantiator, Namer<? super T> namer) {\n        super(type, instantiator, namer);\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"protected AbstractNamedDomainObjectContainer(Class<? extends T> type, Instantiator instantiator) {\n        super(type, instantiator, Named.Namer.forType(type));\n    }","id":36029,"modified_method":"protected AbstractNamedDomainObjectContainer(Class<T> type, Instantiator instantiator) {\n        super(type, instantiator, Named.Namer.forType(type));\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public PublicationRepositoryContainer getRepositories() {\n        return repositories;\n    }","id":36030,"modified_method":"public RepositoryHandler getRepositories() {\n        return repositories;\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public void repositories(Action<? super NamedDomainObjectContainer<ArtifactRepository>> configure) {\n        configure.execute(repositories);\n    }","id":36031,"modified_method":"public void repositories(Action<? super RepositoryHandler> configure) {\n        configure.execute(repositories);\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public DefaultPublishingExtension(PublicationRepositoryContainer repositories, PublicationContainer publications) {\n        this.repositories = repositories;\n        this.publications = publications;\n    }","id":36032,"modified_method":"public DefaultPublishingExtension(RepositoryHandler repositories, PublicationContainer publications) {\n        this.repositories = repositories;\n        this.publications = publications;\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public void monitor(final PublicationContainer publications, final NamedDomainObjectContainer<ArtifactRepository> repositories) {\n        publications.all(new Action<Publication>() {\n            public void execute(Publication publication) {\n                for (ArtifactRepository repository : repositories) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        repositories.whenObjectAdded(new Action<ArtifactRepository>() {\n            public void execute(ArtifactRepository repository) {\n                for (Publication publication : publications) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        // Note: we aren't supporting removal of repositories or publications\n        // Note: we also aren't considering that repos have a setName, so their name can change\n        //       (though this is a violation of the Named contract)\n    }","id":36033,"modified_method":"public void monitor(final PublicationContainer publications, final ArtifactRepositoryContainer repositories) {\n        publications.all(new Action<Publication>() {\n            public void execute(Publication publication) {\n                for (ArtifactRepository repository : repositories) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        repositories.whenObjectAdded(new Action<ArtifactRepository>() {\n            public void execute(ArtifactRepository repository) {\n                for (Publication publication : publications) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        // Note: we aren't supporting removal of repositories or publications\n        // Note: we also aren't considering that repos have a setName, so their name can change\n        //       (though this is a violation of the Named contract)\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"@Inject\n    public IvyPublishPlugin(\n            Instantiator instantiator, DependencyMetaDataProvider dependencyMetaDataProvider, FileResolver fileResolver,\n            DependencyResolutionServices dependencyResolutionServices\n    ) {\n        this.instantiator = instantiator;\n        this.dependencyMetaDataProvider = dependencyMetaDataProvider;\n        this.fileResolver = fileResolver;\n        this.dependencyResolutionServices = dependencyResolutionServices;\n    }","id":36034,"modified_method":"@Inject\n    public IvyPublishPlugin(\n            Instantiator instantiator, DependencyMetaDataProvider dependencyMetaDataProvider, FileResolver fileResolver\n    ) {\n        this.instantiator = instantiator;\n        this.dependencyMetaDataProvider = dependencyMetaDataProvider;\n        this.fileResolver = fileResolver;\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(Project project) {\n        project.getPlugins().apply(PublishingPlugin.class);\n        DefaultPublishingExtension extension = (DefaultPublishingExtension) project.getExtensions().getByType(PublishingExtension.class);\n\n        Set<Configuration> visibleConfigurations = project.getConfigurations().matching(new Spec<Configuration>() {\n            public boolean isSatisfiedBy(Configuration configuration) {\n                return configuration.isVisible();\n            }\n        });\n\n        PublicationContainer publications = extension.getPublications();\n        publications.add(createPublication(\"main\", project, visibleConfigurations));\n\n        final BaseRepositoryFactory baseRepositoryFactory = dependencyResolutionServices.getBaseRepositoryFactory();\n        PublicationRepositoryContainer repositories = extension.getRepositories();\n        repositories.setFactory(new IvyArtifactRepositoryFactory(baseRepositoryFactory));\n\n        // Create publish tasks automatically for any Ivy publication and repository combinations\n        new IvyPublishDynamicTaskCreator(project.getTasks(), new DefaultIvyPublishTaskNamer()).monitor(publications, repositories);\n    }","id":36035,"modified_method":"public void apply(Project project) {\n        project.getPlugins().apply(PublishingPlugin.class);\n        PublishingExtension extension = project.getExtensions().getByType(PublishingExtension.class);\n\n        Set<Configuration> visibleConfigurations = project.getConfigurations().matching(new Spec<Configuration>() {\n            public boolean isSatisfiedBy(Configuration configuration) {\n                return configuration.isVisible();\n            }\n        });\n\n        extension.getPublications().add(createPublication(\"main\", project, visibleConfigurations));\n        extension.getRepositories().ivy(new Action<IvyArtifactRepository>() {\n            public void execute(IvyArtifactRepository ivyArtifactRepository) {\n                ivyArtifactRepository.setName(\"main\");\n            }\n        });\n\n        // Create publish tasks automatically for any Ivy publication and repository combinations\n        new IvyPublishDynamicTaskCreator(project.getTasks(), new DefaultIvyPublishTaskNamer()).monitor(extension.getPublications(), extension.getRepositories());\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"@Inject\n    public PublishingPlugin(Instantiator instantiator) {\n        this.instantiator = instantiator;\n    }","id":36036,"modified_method":"@Inject\n    public PublishingPlugin(Factory<ArtifactPublicationServices> artifactPublicationServicesFactory, Instantiator instantiator) {\n        this.artifactPublicationServicesFactory = artifactPublicationServicesFactory;\n        this.instantiator = instantiator;\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(Project project) {\n        PublicationRepositoryContainer repositories = instantiator.newInstance(PublicationRepositoryContainer.class, instantiator);\n        PublicationContainer publications = instantiator.newInstance(DefaultPublicationContainer.class, instantiator);\n        project.getExtensions().create(PublishingExtension.NAME, DefaultPublishingExtension.class, repositories, publications);\n    }","id":36037,"modified_method":"public void apply(Project project) {\n        RepositoryHandler repositories = artifactPublicationServicesFactory.create().getRepositoryHandler();\n        PublicationContainer publications = instantiator.newInstance(DefaultPublicationContainer.class, instantiator);\n        project.getExtensions().create(PublishingExtension.NAME, DefaultPublishingExtension.class, repositories, publications);\n    }","commit_id":"b5a2e128501a656ba9099270ac71436ce6271495","url":"https://github.com/gradle/gradle"},{"original_method":"public DefaultBinariesContainer(Instantiator instantiator) {\n        super(Named.class, instantiator);\n    }","id":36038,"modified_method":"public DefaultBinariesContainer(Instantiator instantiator) {\n        super(Binary.class, instantiator);\n    }","commit_id":"35af1624f48c56a74ec7031dca3f56769c9fd560","url":"https://github.com/gradle/gradle"},{"original_method":"private void configureSourceSetDefaults(final JavaPluginConvention pluginConvention) {\n        final Project project = pluginConvention.getProject();\n        final ProjectSourceSet projectSourceSet = project.getExtensions().getByType(ProjectSourceSet.class);\n\n        pluginConvention.getSourceSets().all(new Action<SourceSet>() {\n            public void execute(final SourceSet sourceSet) {\n                ConventionMapping outputConventionMapping = ((IConventionAware) sourceSet.getOutput()).getConventionMapping();\n\n                ConfigurationContainer configurations = project.getConfigurations();\n\n                Configuration compileConfiguration = configurations.findByName(sourceSet.getCompileConfigurationName());\n                if (compileConfiguration == null) {\n                    compileConfiguration = configurations.create(sourceSet.getCompileConfigurationName());\n                }\n                compileConfiguration.setVisible(false);\n                compileConfiguration.setDescription(String.format(\"Compile classpath for %s.\", sourceSet));\n\n                Configuration runtimeConfiguration = configurations.findByName(sourceSet.getRuntimeConfigurationName());\n                if (runtimeConfiguration == null) {\n                    runtimeConfiguration = configurations.create(sourceSet.getRuntimeConfigurationName());\n                }\n                runtimeConfiguration.setVisible(false);\n                runtimeConfiguration.extendsFrom(compileConfiguration);\n                runtimeConfiguration.setDescription(String.format(\"Runtime classpath for %s.\", sourceSet));\n\n                sourceSet.setCompileClasspath(compileConfiguration);\n                sourceSet.setRuntimeClasspath(sourceSet.getOutput().plus(runtimeConfiguration));\n\n                outputConventionMapping.map(\"classesDir\", new Callable<Object>() {\n                    public Object call() throws Exception {\n                        String classesDirName = String.format(\"classes/%s\", sourceSet.getName());\n                        return new File(project.getBuildDir(), classesDirName);\n                    }\n                });\n                outputConventionMapping.map(\"resourcesDir\", new Callable<Object>() {\n                    public Object call() throws Exception {\n                        String classesDirName = String.format(\"resources/%s\", sourceSet.getName());\n                        return new File(project.getBuildDir(), classesDirName);\n                    }\n                });\n\n                sourceSet.getJava().srcDir(String.format(\"src/%s/java\", sourceSet.getName()));\n                sourceSet.getResources().srcDir(String.format(\"src/%s/resources\", sourceSet.getName()));\n                sourceSet.compiledBy(sourceSet.getClassesTaskName());\n\n                FunctionalSourceSet functionalSourceSet = projectSourceSet.create(sourceSet.getName());\n                Classpath compileClasspath = new SourceSetCompileClasspath(sourceSet);\n                DefaultJavaSourceSet javaSourceSet = instantiator.newInstance(DefaultJavaSourceSet.class, \"java\", sourceSet.getJava(), compileClasspath, functionalSourceSet);\n                functionalSourceSet.add(javaSourceSet);\n                ResourceSet resourceSet = instantiator.newInstance(DefaultResourceSet.class, \"resources\", sourceSet.getResources(), functionalSourceSet);\n                functionalSourceSet.add(resourceSet);\n\n                JvmBinaryContainer jvmBinaryContainer = (JvmBinaryContainer) project.getExtensions().getByType(BinariesContainer.class).getByName(\"jvm\");\n                ClassDirectoryBinary binary = jvmBinaryContainer.create(sourceSet.getName(), ClassDirectoryBinary.class);\n                ConventionMapping conventionMapping = new DslObject(binary).getConventionMapping();\n                conventionMapping.map(\"classesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return sourceSet.getOutput().getClassesDir();\n                    }\n                });\n                conventionMapping.map(\"resourcesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return sourceSet.getOutput().getResourcesDir();\n                    }\n                });\n\n                binary.getSource().add(javaSourceSet);\n                binary.getSource().add(resourceSet);\n\n                binary.getClassesTask().dependsOn(sourceSet.getOutput().getDirs());\n            }\n        });\n    }","id":36039,"modified_method":"private void configureSourceSetDefaults(final JavaPluginConvention pluginConvention) {\n        final Project project = pluginConvention.getProject();\n        final ProjectSourceSet projectSourceSet = project.getExtensions().getByType(ProjectSourceSet.class);\n\n        pluginConvention.getSourceSets().all(new Action<SourceSet>() {\n            public void execute(final SourceSet sourceSet) {\n                ConventionMapping outputConventionMapping = ((IConventionAware) sourceSet.getOutput()).getConventionMapping();\n\n                ConfigurationContainer configurations = project.getConfigurations();\n\n                Configuration compileConfiguration = configurations.findByName(sourceSet.getCompileConfigurationName());\n                if (compileConfiguration == null) {\n                    compileConfiguration = configurations.create(sourceSet.getCompileConfigurationName());\n                }\n                compileConfiguration.setVisible(false);\n                compileConfiguration.setDescription(String.format(\"Compile classpath for %s.\", sourceSet));\n\n                Configuration runtimeConfiguration = configurations.findByName(sourceSet.getRuntimeConfigurationName());\n                if (runtimeConfiguration == null) {\n                    runtimeConfiguration = configurations.create(sourceSet.getRuntimeConfigurationName());\n                }\n                runtimeConfiguration.setVisible(false);\n                runtimeConfiguration.extendsFrom(compileConfiguration);\n                runtimeConfiguration.setDescription(String.format(\"Runtime classpath for %s.\", sourceSet));\n\n                sourceSet.setCompileClasspath(compileConfiguration);\n                sourceSet.setRuntimeClasspath(sourceSet.getOutput().plus(runtimeConfiguration));\n\n                outputConventionMapping.map(\"classesDir\", new Callable<Object>() {\n                    public Object call() throws Exception {\n                        String classesDirName = String.format(\"classes/%s\", sourceSet.getName());\n                        return new File(project.getBuildDir(), classesDirName);\n                    }\n                });\n                outputConventionMapping.map(\"resourcesDir\", new Callable<Object>() {\n                    public Object call() throws Exception {\n                        String classesDirName = String.format(\"resources/%s\", sourceSet.getName());\n                        return new File(project.getBuildDir(), classesDirName);\n                    }\n                });\n\n                sourceSet.getJava().srcDir(String.format(\"src/%s/java\", sourceSet.getName()));\n                sourceSet.getResources().srcDir(String.format(\"src/%s/resources\", sourceSet.getName()));\n                sourceSet.compiledBy(sourceSet.getClassesTaskName());\n\n                FunctionalSourceSet functionalSourceSet = projectSourceSet.create(sourceSet.getName());\n                Classpath compileClasspath = new SourceSetCompileClasspath(sourceSet);\n                DefaultJavaSourceSet javaSourceSet = instantiator.newInstance(DefaultJavaSourceSet.class, \"java\", sourceSet.getJava(), compileClasspath, functionalSourceSet);\n                functionalSourceSet.add(javaSourceSet);\n                ResourceSet resourceSet = instantiator.newInstance(DefaultResourceSet.class, \"resources\", sourceSet.getResources(), functionalSourceSet);\n                functionalSourceSet.add(resourceSet);\n\n                BinariesContainer binariesContainer = project.getExtensions().getByType(BinariesContainer.class);\n                ClassDirectoryBinary binary = binariesContainer.create(sourceSet.getName(), ClassDirectoryBinary.class);\n                ConventionMapping conventionMapping = new DslObject(binary).getConventionMapping();\n                conventionMapping.map(\"classesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return sourceSet.getOutput().getClassesDir();\n                    }\n                });\n                conventionMapping.map(\"resourcesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return sourceSet.getOutput().getResourcesDir();\n                    }\n                });\n\n                binary.getSource().add(javaSourceSet);\n                binary.getSource().add(resourceSet);\n\n                binary.getClassesTask().dependsOn(sourceSet.getOutput().getDirs());\n            }\n        });\n    }","commit_id":"35af1624f48c56a74ec7031dca3f56769c9fd560","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final Project target) {\n        target.getPlugins().apply(JvmLanguagePlugin.class);\n\n        JvmBinaryContainer jvmBinaryContainer = (JvmBinaryContainer) target.getExtensions().getByType(BinariesContainer.class).getByName(\"jvm\");\n        jvmBinaryContainer.all(new Action<ClassDirectoryBinary>() {\n            public void execute(final ClassDirectoryBinary binary) {\n                binary.getSource().withType(JavaSourceSet.class).all(new Action<JavaSourceSet>() {\n                    public void execute(JavaSourceSet javaSourceSet) {\n                        // TODO: handle case where binary has multiple JavaSourceSet's\n                        JavaCompile compileTask = target.getTasks().create(binary.getTaskName(\"compile\", \"java\"), JavaCompile.class);\n                        configureCompileTask(compileTask, javaSourceSet, binary);\n                        binary.getClassesTask().dependsOn(compileTask);\n                    }\n                });\n            }\n        });\n\n        ProjectSourceSet projectSourceSet = target.getExtensions().getByType(DefaultProjectSourceSet.class);\n        projectSourceSet.all(new Action<FunctionalSourceSet>() {\n            public void execute(final FunctionalSourceSet functionalSourceSet) {\n                functionalSourceSet.registerFactory(JavaSourceSet.class, new NamedDomainObjectFactory<JavaSourceSet>() {\n                    public JavaSourceSet create(String name) {\n                        return instantiator.newInstance(DefaultJavaSourceSet.class, name,\n                                instantiator.newInstance(DefaultSourceDirectorySet.class, name, fileResolver),\n                                instantiator.newInstance(DefaultClasspath.class, fileResolver,\n                                        target.getTasks()), functionalSourceSet);\n                    }\n                });\n            }\n        });\n    }","id":36040,"modified_method":"public void apply(final Project target) {\n        target.getPlugins().apply(JvmLanguagePlugin.class);\n\n        BinariesContainer jvmBinaryContainer = target.getExtensions().getByType(BinariesContainer.class);\n        jvmBinaryContainer.withType(ClassDirectoryBinary.class).all(new Action<ClassDirectoryBinary>() {\n            public void execute(final ClassDirectoryBinary binary) {\n                binary.getSource().withType(JavaSourceSet.class).all(new Action<JavaSourceSet>() {\n                    public void execute(JavaSourceSet javaSourceSet) {\n                        // TODO: handle case where binary has multiple JavaSourceSet's\n                        JavaCompile compileTask = target.getTasks().create(binary.getTaskName(\"compile\", \"java\"), JavaCompile.class);\n                        configureCompileTask(compileTask, javaSourceSet, binary);\n                        binary.getClassesTask().dependsOn(compileTask);\n                    }\n                });\n            }\n        });\n\n        ProjectSourceSet projectSourceSet = target.getExtensions().getByType(DefaultProjectSourceSet.class);\n        projectSourceSet.all(new Action<FunctionalSourceSet>() {\n            public void execute(final FunctionalSourceSet functionalSourceSet) {\n                functionalSourceSet.registerFactory(JavaSourceSet.class, new NamedDomainObjectFactory<JavaSourceSet>() {\n                    public JavaSourceSet create(String name) {\n                        return instantiator.newInstance(DefaultJavaSourceSet.class, name,\n                                instantiator.newInstance(DefaultSourceDirectorySet.class, name, fileResolver),\n                                instantiator.newInstance(DefaultClasspath.class, fileResolver,\n                                        target.getTasks()), functionalSourceSet);\n                    }\n                });\n            }\n        });\n    }","commit_id":"35af1624f48c56a74ec7031dca3f56769c9fd560","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final Project target) {\n        target.getPlugins().apply(LanguageBasePlugin.class);\n\n        ProjectSourceSet projectSourceSet = target.getExtensions().getByType(ProjectSourceSet.class);\n        projectSourceSet.all(new Action<FunctionalSourceSet>() {\n            public void execute(final FunctionalSourceSet functionalSourceSet) {\n                functionalSourceSet.registerFactory(ResourceSet.class, new NamedDomainObjectFactory<ResourceSet>() {\n                    public ResourceSet create(String name) {\n                        return instantiator.newInstance(DefaultResourceSet.class, name,\n                                instantiator.newInstance(DefaultSourceDirectorySet.class, name, fileResolver), functionalSourceSet);\n                    }\n                });\n            }\n        });\n\n        BinariesContainer binariesContainer = target.getExtensions().getByType(BinariesContainer.class);\n        JvmBinaryContainer jvmBinaryContainer = instantiator.newInstance(DefaultJvmBinaryContainer.class, instantiator);\n        binariesContainer.add(jvmBinaryContainer);\n\n        jvmBinaryContainer.registerFactory(ClassDirectoryBinary.class, new NamedDomainObjectFactory<ClassDirectoryBinary>() {\n            public ClassDirectoryBinary create(String name) {\n                return instantiator.newInstance(DefaultClassDirectoryBinary.class, name);\n            };\n        });\n\n        jvmBinaryContainer.all(new Action<ClassDirectoryBinary>() {\n            public void execute(final ClassDirectoryBinary binary) {\n                ConventionMapping conventionMapping = new DslObject(binary).getConventionMapping();\n                conventionMapping.map(\"classesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return new File(new File(target.getBuildDir(), \"classes\"), binary.getName());\n                    }\n                });\n                final Task classesTask = target.getTasks().create(binary.getTaskName(null, \"classes\"));\n                classesTask.setDescription(String.format(\"Assembles %s.\", binary));\n                binary.setClassesTask(classesTask);\n                binary.getSource().withType(ResourceSet.class).all(new Action<ResourceSet>() {\n                    public void execute(ResourceSet resourceSet) {\n                        // TODO: handle case where binary has multiple ResourceSet's\n                        Copy resourcesTask = target.getTasks().create(binary.getTaskName(\"process\", \"resources\"), ProcessResources.class);\n                        resourcesTask.setDescription(String.format(\"Processes %s.\", resourceSet));\n                        new DslObject(resourcesTask).getConventionMapping().map(\"destinationDir\", new Callable<File>() {\n                            public File call() throws Exception {\n                                return binary.getResourcesDir();\n                            }\n                        });\n                        classesTask.dependsOn(resourcesTask);\n                        resourcesTask.from(resourceSet.getSource());\n                    }\n                });\n            }\n        });\n    }","id":36041,"modified_method":"public void apply(final Project target) {\n        target.getPlugins().apply(LanguageBasePlugin.class);\n\n        ProjectSourceSet projectSourceSet = target.getExtensions().getByType(ProjectSourceSet.class);\n        projectSourceSet.all(new Action<FunctionalSourceSet>() {\n            public void execute(final FunctionalSourceSet functionalSourceSet) {\n                functionalSourceSet.registerFactory(ResourceSet.class, new NamedDomainObjectFactory<ResourceSet>() {\n                    public ResourceSet create(String name) {\n                        return instantiator.newInstance(DefaultResourceSet.class, name,\n                                instantiator.newInstance(DefaultSourceDirectorySet.class, name, fileResolver), functionalSourceSet);\n                    }\n                });\n            }\n        });\n\n        BinariesContainer binariesContainer = target.getExtensions().getByType(BinariesContainer.class);\n        binariesContainer.registerFactory(ClassDirectoryBinary.class, new NamedDomainObjectFactory<ClassDirectoryBinary>() {\n            public ClassDirectoryBinary create(String name) {\n                return instantiator.newInstance(DefaultClassDirectoryBinary.class, name);\n            };\n        });\n\n        binariesContainer.withType(ClassDirectoryBinary.class).all(new Action<ClassDirectoryBinary>() {\n            public void execute(final ClassDirectoryBinary binary) {\n                ConventionMapping conventionMapping = new DslObject(binary).getConventionMapping();\n                conventionMapping.map(\"classesDir\", new Callable<File>() {\n                    public File call() throws Exception {\n                        return new File(new File(target.getBuildDir(), \"classes\"), binary.getName());\n                    }\n                });\n                final Task classesTask = target.getTasks().create(binary.getTaskName(null, \"classes\"));\n                classesTask.setDescription(String.format(\"Assembles %s.\", binary));\n                binary.setClassesTask(classesTask);\n                binary.getSource().withType(ResourceSet.class).all(new Action<ResourceSet>() {\n                    public void execute(ResourceSet resourceSet) {\n                        // TODO: handle case where binary has multiple ResourceSet's\n                        Copy resourcesTask = target.getTasks().create(binary.getTaskName(\"process\", \"resources\"), ProcessResources.class);\n                        resourcesTask.setDescription(String.format(\"Processes %s.\", resourceSet));\n                        new DslObject(resourcesTask).getConventionMapping().map(\"destinationDir\", new Callable<File>() {\n                            public File call() throws Exception {\n                                return binary.getResourcesDir();\n                            }\n                        });\n                        classesTask.dependsOn(resourcesTask);\n                        resourcesTask.from(resourceSet.getSource());\n                    }\n                });\n            }\n        });\n    }","commit_id":"35af1624f48c56a74ec7031dca3f56769c9fd560","url":"https://github.com/gradle/gradle"},{"original_method":"protected AbstractNamedDomainObjectContainer(Class<? extends T> type, Instantiator instantiator, Namer<? super T> namer) {\n        super(type, instantiator, namer);\n    }","id":36042,"modified_method":"protected AbstractNamedDomainObjectContainer(Class<T> type, Instantiator instantiator, Namer<? super T> namer) {\n        super(type, instantiator, namer);\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"protected AbstractNamedDomainObjectContainer(Class<? extends T> type, Instantiator instantiator) {\n        super(type, instantiator, Named.Namer.forType(type));\n    }","id":36043,"modified_method":"protected AbstractNamedDomainObjectContainer(Class<T> type, Instantiator instantiator) {\n        super(type, instantiator, Named.Namer.forType(type));\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public PublicationRepositoryContainer getRepositories() {\n        return repositories;\n    }","id":36044,"modified_method":"public RepositoryHandler getRepositories() {\n        return repositories;\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public DefaultPublishingExtension(PublicationRepositoryContainer repositories, PublicationContainer publications) {\n        this.repositories = repositories;\n        this.publications = publications;\n    }","id":36045,"modified_method":"public DefaultPublishingExtension(RepositoryHandler repositories, PublicationContainer publications) {\n        this.repositories = repositories;\n        this.publications = publications;\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public void repositories(Action<? super NamedDomainObjectContainer<ArtifactRepository>> configure) {\n        configure.execute(repositories);\n    }","id":36046,"modified_method":"public void repositories(Action<? super RepositoryHandler> configure) {\n        configure.execute(repositories);\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public void monitor(final PublicationContainer publications, final NamedDomainObjectContainer<ArtifactRepository> repositories) {\n        publications.all(new Action<Publication>() {\n            public void execute(Publication publication) {\n                for (ArtifactRepository repository : repositories) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        repositories.whenObjectAdded(new Action<ArtifactRepository>() {\n            public void execute(ArtifactRepository repository) {\n                for (Publication publication : publications) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        // Note: we aren't supporting removal of repositories or publications\n        // Note: we also aren't considering that repos have a setName, so their name can change\n        //       (though this is a violation of the Named contract)\n    }","id":36047,"modified_method":"public void monitor(final PublicationContainer publications, final ArtifactRepositoryContainer repositories) {\n        publications.all(new Action<Publication>() {\n            public void execute(Publication publication) {\n                for (ArtifactRepository repository : repositories) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        repositories.whenObjectAdded(new Action<ArtifactRepository>() {\n            public void execute(ArtifactRepository repository) {\n                for (Publication publication : publications) {\n                    maybeCreate(publication, repository);\n                }\n            }\n        });\n\n        // Note: we aren't supporting removal of repositories or publications\n        // Note: we also aren't considering that repos have a setName, so their name can change\n        //       (though this is a violation of the Named contract)\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"@Inject\n    public IvyPublishPlugin(\n            Instantiator instantiator, DependencyMetaDataProvider dependencyMetaDataProvider, FileResolver fileResolver,\n            DependencyResolutionServices dependencyResolutionServices\n    ) {\n        this.instantiator = instantiator;\n        this.dependencyMetaDataProvider = dependencyMetaDataProvider;\n        this.fileResolver = fileResolver;\n        this.dependencyResolutionServices = dependencyResolutionServices;\n    }","id":36048,"modified_method":"@Inject\n    public IvyPublishPlugin(\n            Instantiator instantiator, DependencyMetaDataProvider dependencyMetaDataProvider, FileResolver fileResolver\n    ) {\n        this.instantiator = instantiator;\n        this.dependencyMetaDataProvider = dependencyMetaDataProvider;\n        this.fileResolver = fileResolver;\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(Project project) {\n        project.getPlugins().apply(PublishingPlugin.class);\n        DefaultPublishingExtension extension = (DefaultPublishingExtension) project.getExtensions().getByType(PublishingExtension.class);\n\n        Set<Configuration> visibleConfigurations = project.getConfigurations().matching(new Spec<Configuration>() {\n            public boolean isSatisfiedBy(Configuration configuration) {\n                return configuration.isVisible();\n            }\n        });\n\n        PublicationContainer publications = extension.getPublications();\n        publications.add(createPublication(\"main\", project, visibleConfigurations));\n\n        final BaseRepositoryFactory baseRepositoryFactory = dependencyResolutionServices.getBaseRepositoryFactory();\n        PublicationRepositoryContainer repositories = extension.getRepositories();\n        repositories.setFactory(new IvyArtifactRepositoryFactory(baseRepositoryFactory));\n\n        // Create publish tasks automatically for any Ivy publication and repository combinations\n        new IvyPublishDynamicTaskCreator(project.getTasks(), new DefaultIvyPublishTaskNamer()).monitor(publications, repositories);\n    }","id":36049,"modified_method":"public void apply(Project project) {\n        project.getPlugins().apply(PublishingPlugin.class);\n        PublishingExtension extension = project.getExtensions().getByType(PublishingExtension.class);\n\n        Set<Configuration> visibleConfigurations = project.getConfigurations().matching(new Spec<Configuration>() {\n            public boolean isSatisfiedBy(Configuration configuration) {\n                return configuration.isVisible();\n            }\n        });\n\n        extension.getPublications().add(createPublication(\"main\", project, visibleConfigurations));\n        extension.getRepositories().ivy(new Action<IvyArtifactRepository>() {\n            public void execute(IvyArtifactRepository ivyArtifactRepository) {\n                ivyArtifactRepository.setName(\"main\");\n            }\n        });\n\n        // Create publish tasks automatically for any Ivy publication and repository combinations\n        new IvyPublishDynamicTaskCreator(project.getTasks(), new DefaultIvyPublishTaskNamer()).monitor(extension.getPublications(), extension.getRepositories());\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"@Inject\n    public PublishingPlugin(Instantiator instantiator) {\n        this.instantiator = instantiator;\n    }","id":36050,"modified_method":"@Inject\n    public PublishingPlugin(Factory<ArtifactPublicationServices> artifactPublicationServicesFactory, Instantiator instantiator) {\n        this.artifactPublicationServicesFactory = artifactPublicationServicesFactory;\n        this.instantiator = instantiator;\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(Project project) {\n        PublicationRepositoryContainer repositories = instantiator.newInstance(PublicationRepositoryContainer.class, instantiator);\n        PublicationContainer publications = instantiator.newInstance(DefaultPublicationContainer.class, instantiator);\n        project.getExtensions().create(PublishingExtension.NAME, DefaultPublishingExtension.class, repositories, publications);\n    }","id":36051,"modified_method":"public void apply(Project project) {\n        RepositoryHandler repositories = artifactPublicationServicesFactory.create().getRepositoryHandler();\n        PublicationContainer publications = instantiator.newInstance(DefaultPublicationContainer.class, instantiator);\n        project.getExtensions().create(PublishingExtension.NAME, DefaultPublishingExtension.class, repositories, publications);\n    }","commit_id":"17f7b51166c9703c99d21d34af2809bea9ea919d","url":"https://github.com/gradle/gradle"},{"original_method":"/**\n     * This method purges the JSP repository dirs,\n     * ie. it deletes all JSP files that OpenCms has written to the\n     * real FS.\n     * Obviously this method must be used with caution.\n     * Purpose of this method is to allow\n     * a complete purge of all JSP pages on a remote machine after\n     * a major update of JSP templates was made.\n     *\n     * @param cms The CmsObject used for user authorization\n     */\n    private synchronized void purgeJspRepository(CmsObject cms) {\n        if (!isAdmin(cms) && !cms.getRequestContext().isEventControlled()) return;\n        java.io.File d;\n        if (DEBUG > 0) System.err.println(\"FlexCache.purgeJspRepository() purging JSP repositories!\");\n        d = new java.io.File(com.opencms.flex.CmsJspLoader.getJspRepository() + \"online\" + java.io.File.separator);\n        if (DEBUG > 0) System.err.println(\"FlexCache.purgeJspRepository() trying to purge ONLINE repository: \" + d);\n        if (d.canRead() && d.isDirectory()) {\n            java.io.File files[] = d.listFiles();\n            if (DEBUG > 0) System.err.println(\"FlexCache.purgeJspRepository() Files in ONLINE repository = \" + files.length);\n            for (int i = 0; i<files.length; i++) {\n                java.io.File f = files[i];\n                if (f.canWrite()) {\n                    f.delete();\n                } else if (DEBUG > 0) {\n                    System.err.println(\"FlexCache.purgeJspRepository() could not delete file = \" + f);\n                }\n            }\n        } else if (DEBUG > 0) {\n            System.err.println(\"FlexCache.purgeJspRepository() could not access ONLINE repository: \" + d);\n            System.err.println(\"FlexCache.purgeJspRepository() d.isDirectory() = \" + d.canWrite());\n            System.err.println(\"FlexCache.purgeJspRepository() d.canRead() = \" + d.canRead());\n            \n        }\n        d = new java.io.File(com.opencms.flex.CmsJspLoader.getJspRepository() + \"offline\" + java.io.File.separator);\n        if (DEBUG > 1) System.err.println(\"FlexCache.purgeJspRepository() trying to purge OFFLINE repository: \" + d);\n        if (d.canRead() && d.isDirectory()) {\n            java.io.File files[] = d.listFiles();\n            if (DEBUG > 0) System.err.println(\"FlexCache.purgeJspRepository() Files in OFFLINE repository = \" + files.length);\n            for (int i = 0; i<files.length; i++) {\n                java.io.File f = files[i];\n                if (f.canWrite()) {\n                    f.delete();\n                } else if (DEBUG > 0) {\n                    System.err.println(\"FlexCache.purgeJspRepository() could not delete file = \" + f);\n                }\n            }\n        } else if (DEBUG > 0) {\n            System.err.println(\"FlexCache.purgeJspRepository() could not access OFFLINE repository: \" + d);\n            System.err.println(\"FlexCache.purgeJspRepository() d.isDirectory() = \" + d.canWrite());\n            System.err.println(\"FlexCache.purgeJspRepository() d.canRead() = \" + d.canRead());\n            \n        }\n        clear();\n        if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_INFO)) \n            A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_INFO, \"JSP repository purged - purgeJspRepository() called\");\n    }","id":36052,"modified_method":"/**\n     * This method purges the JSP repository dirs,\n     * ie. it deletes all JSP files that OpenCms has written to the\n     * real FS.\n     * Obviously this method must be used with caution.\n     * Purpose of this method is to allow\n     * a complete purge of all JSP pages on a remote machine after\n     * a major update of JSP templates was made.\n     *\n     * @param cms The CmsObject used for user authorization\n     */\n    private synchronized void purgeJspRepository(CmsObject cms) {\n        if (!isAdmin(cms) && !cms.getRequestContext().isEventControlled()) return;\n        if (DEBUG > 0) System.err.println(\"FlexCache.purgeJspRepository() purging JSP repositories!\");\n\n        File d;\n        d = new java.io.File(com.opencms.flex.CmsJspLoader.getJspRepository() + \"online\" + java.io.File.separator);\n        purgeDirectory(d);\n\n        d = new java.io.File(com.opencms.flex.CmsJspLoader.getJspRepository() + \"offline\" + java.io.File.separator);\n        purgeDirectory(d);\n         \n        clear();\n        if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_INFO)) \n            A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_INFO, \"JSP repository purged - purgeJspRepository() called\");\n    }","commit_id":"ee42941aab8aa515993fc546221bcdb5127f2b5d","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Translates the JSP file name for a OpenCms VFS resourcn \n     * to the name used in the \"real\" file system.<p>\n     * \n     * The name given must be a absolute URI in the OpenCms VFS,\n     * e.g. CmsFile.getAbsolutePath()\n     *\n     * @param name The file to calculate the JSP name for\n     * @return The JSP name for the file\n     */    \n    public static String getJspName(String name) {\n        return name.replace('\\\\', 'T').replace('/', 'T') + '.' + name.hashCode() + C_JSP_EXTENSION;\n    }","id":36053,"modified_method":"/**\n     * Translates the JSP file name for a OpenCms VFS resourcn \n     * to the name used in the \"real\" file system.<p>\n     * \n     * The name given must be a absolute URI in the OpenCms VFS,\n     * e.g. CmsFile.getAbsolutePath()\n     *\n     * @param name The file to calculate the JSP name for\n     * @return The JSP name for the file\n     */    \n    public static String getJspName(String name) {\n        return name + C_JSP_EXTENSION;\n    }","commit_id":"ee42941aab8aa515993fc546221bcdb5127f2b5d","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Updates a JSP page in the \"real\" file system in case the VFS resource has changed.<p>\n     * \n     * Also processes the <code>&lt;%@ cms %&gt;<\/code> tags before the JSP is written to the real FS.\n     * Also recursivly updates all files that are referenced by a <code>&lt;%@ cms %&gt;<\/code> tag \n     * on this page to make sure the file actually exists in the real FS. \n     * All <code>&lt;%@ include %&gt;<\/code> tags are parsed and the name in the tag is translated\n     * from the OpenCms VFS path to the path in the real FS. \n     * The same is done for filenames in <code>&lt;%@ page errorPage=... %&gt;<\/code> tags.\n     * \n     * @param cms Used to access the OpenCms VFS\n     * @param file The reqested JSP file resource in the VFS\n     * @param req The current request\n     * @param res The current response\n     * @param updates A Set containing all JSP pages that have been already updated\n     * \n     * @return The file name of the updated JSP in the \"real\" FS\n     * \n     * @throws ServletException might be thrown in the process of including the JSP \n     * @throws IOException might be thrown in the process of including the JSP \n     */\n    private synchronized String updateJsp(CmsObject cms, CmsResource file, CmsFlexRequest req, Set updates) \n    throws IOException, ServletException {\n        \n        String jspTargetName = getJspName(file.getAbsolutePath());\n        String jspPath = getJspPath(jspTargetName, req.isOnline());\n        \n        File d = new File(jspPath).getParentFile();\n        if (! (d != null) && (d.exists() && d.isDirectory() && d.canRead())) {\n            if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_CRITICAL)) \n                A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_CRITICAL, \"Could not access directory for \" + jspPath);\n            throw new ServletException(\"JspLoader: Could not access directory for \" + jspPath);\n        }    \n        \n        if (updates.contains(jspTargetName)) return null;\n        updates.add(jspTargetName);\n        \n        boolean mustUpdate = false;\n        \n        File f = new File(jspPath);        \n        if (!f.exists()) {\n            // File does not exist in FS\n            mustUpdate = true;\n        } else if (f.lastModified() <= file.getDateLastModified()) {\n            // File in FS is older then file in VFS\n            mustUpdate = true;\n        } else if (req.isDoRecompile()) {\n            // Recompile is forced with parameter\n            mustUpdate = true;\n        }\n\n        String jspfilename = getJspUri(file.getAbsolutePath(), req.isOnline());               \n        \n        if (mustUpdate) {\n            if (DEBUG > 2) System.err.println(\"JspLoader writing new file: \" + jspfilename);         \n            byte[] contents = null;\n            String jspEncoding = null;\n            try {\n                contents = req.getCmsObject().readFile(file.getAbsolutePath()).getContents();\n                // Encoding project:\n                // Check the JSP \"content-encoding\" property\n                jspEncoding = cms.readProperty(file.getAbsolutePath(), I_CmsConstants.C_PROPERTY_CONTENT_ENCODING, false);\n                if (jspEncoding == null) jspEncoding = C_DEFAULT_JSP_ENCODING;\n                jspEncoding = jspEncoding.trim().toUpperCase();\n            } catch (CmsException e) {\n                throw new ServletException(\"JspLoader: Could not read contents for file '\" + file.getAbsolutePath() + \"'\", e);\n            }\n            \n            try {\n                FileOutputStream fs = new FileOutputStream(f);                \n                // Encoding project:\n                // We need to use some encoding to convert bytes to String\n                // corectly. Internally a JSP will always be stored in the \n                // system default encoding since they are just a variation of\n                // the \"plain\" resource type.\n                String page = new String(contents, A_OpenCms.getDefaultEncoding());\n                StringBuffer buf = new StringBuffer(contents.length);\n\n                int p0 = 0, i2 = 0, slen = C_DIRECTIVE_START.length(), elen = C_DIRECTIVE_END.length();\n                // Check if any jsp name references occur in the file\n                int i1 = page.indexOf(C_DIRECTIVE_START);\n                while (i1 >= 0) {\n                    // Parse the file and replace jsp name references \n                    i2 = page.indexOf(C_DIRECTIVE_END, i1 + slen);\n                    if (i2 > i1) {\n                        String directive = page.substring(i1 + slen, i2);\n                        if (DEBUG > 2) System.err.println(\"JspLoader: Detected \" + C_DIRECTIVE_START + directive + C_DIRECTIVE_END);\n\n                        int t1=0, t2=0, t3=0, t4=0, t5=0, t6=slen, t7=0;\n                        while (directive.charAt(t1) == ' ') t1++;\n                        String filename = null;                        \n                        if (directive.startsWith(\"include\", t1)) {            \n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'include' directive!\");                            \n                            t2 = directive.indexOf(\"file\", t1 + 7);\n                            t5 = 6;\n                        } else if (directive.startsWith(\"page\", t1)) {\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'page' directive!\");                            \n                            t2 = directive.indexOf(\"errorPage\", t1 + 4);\n                            t5 = 11;\n                        } else if (directive.startsWith(\"cms\", t1)) {\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'cms' directive!\");                            \n                            t2 = directive.indexOf(\"file\", t1 + 3);\n                            t5 = 4; t6 = 0; t7 = elen; \n                        }\n                        \n                        if (t2 > 0) {\n                            String sub = directive.substring(t2 + t5); \n                            char c1 = sub.charAt(t3);\n                            while ((c1 == ' ') || (c1 == '=') || (c1 == '\"')) c1 = sub.charAt(++t3);\n                            t4 = t3;\n                            while (c1 != '\"') c1 = sub.charAt(++t4);\n                            if (t4 > t3) filename=sub.substring(t3,t4);\n                            if (DEBUG > 2) System.err.println(\"JspLoader: File given in directive is: \" + filename);                            \n                        }\n                        \n                        if (filename != null) {\n                            // a file was found, changes have to be made\n                            String pre = ((t7 == 0)?directive.substring(0,t2+t3+t5):\"\");                            ;\n                            String suf = ((t7 == 0)?directive.substring(t2+t3+t5+filename.length()):\"\");\n                            // Now try to update the referenced file \n                            String absolute = req.toAbsolute(filename);\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Absolute location=\" + absolute);\n                            String jspname = null;\n                            try {\n                                // Make sure the jsp referenced file is generated\n                                CmsResource jsp = cms.readFileHeader(absolute);\n                                updateJsp(cms, jsp, req, updates);\n                                jspname = getJspUri(jsp.getAbsolutePath(), req.isOnline());\n                            } catch (Exception e) {\n                                jspname = null;\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Error while creating jsp file \" + absolute + \"\\n\" + e);\n                            }\n                            if (jspname != null) {\n                                // Only change something in case no error had occured\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Name of jsp file is \" + jspname);\n                                directive = pre + jspname + suf;\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Changed directive to \" + C_DIRECTIVE_START + directive + C_DIRECTIVE_END);                                                     \n                            }\n                        }\n                        \n                        buf.append(page.substring(p0, i1 + t6));\n                        buf.append(directive);\n                        p0 = i2 + t7;\n                        i1 = page.indexOf(C_DIRECTIVE_START, p0);\n                    }\n                }                  \n                if (i2 > 0) {\n                    buf.append(page.substring(p0, page.length()));\n                    // Encoding project:\n                    // Now we are ready to store String data in file system.\n                    // To convert String to bytes we also need to provide\n                    // some encoding. The default (by the JSP standard) encoding \n                    // for JSP is ISO-8859-1.\n                    contents = buf.toString().getBytes(jspEncoding);\n                } else {\n                    // Encoding project:\n                    // Contents of original file where not modified,\n                    // just translate to the required JSP encoding (if necessary)\n                    contents = Encoder.changeEncoding(contents, A_OpenCms.getDefaultEncoding(), jspEncoding);   \n                }                                         \n                fs.write(contents);                \n                fs.close();\n                \n                if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_INFO)) \n                    A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_INFO, \"Updated JSP file \\\"\" + jspfilename + \"\\\" for resource \\\"\" + file.getAbsolutePath() + \"\\\"\") ;\n            } catch (FileNotFoundException e) {\n                throw new ServletException(\"JspLauncher: Could not write to file '\" + f.getName() + \"'\\n\" + e, e);\n            }\n        }                      \n        return jspfilename;\n    }","id":36054,"modified_method":"/**\n     * Updates a JSP page in the \"real\" file system in case the VFS resource has changed.<p>\n     * \n     * Also processes the <code>&lt;%@ cms %&gt;<\/code> tags before the JSP is written to the real FS.\n     * Also recursivly updates all files that are referenced by a <code>&lt;%@ cms %&gt;<\/code> tag \n     * on this page to make sure the file actually exists in the real FS. \n     * All <code>&lt;%@ include %&gt;<\/code> tags are parsed and the name in the tag is translated\n     * from the OpenCms VFS path to the path in the real FS. \n     * The same is done for filenames in <code>&lt;%@ page errorPage=... %&gt;<\/code> tags.\n     * \n     * @param cms Used to access the OpenCms VFS\n     * @param file The reqested JSP file resource in the VFS\n     * @param req The current request\n     * @param res The current response\n     * @param updates A Set containing all JSP pages that have been already updated\n     * \n     * @return The file name of the updated JSP in the \"real\" FS\n     * \n     * @throws ServletException might be thrown in the process of including the JSP \n     * @throws IOException might be thrown in the process of including the JSP \n     */\n    private synchronized String updateJsp(CmsObject cms, CmsResource file, CmsFlexRequest req, Set updates) \n    throws IOException, ServletException {\n        \n        String jspTargetName = getJspName(file.getAbsolutePath());\n\n        // check for inclusion loops\n        if (updates.contains(jspTargetName)) return null;\n        updates.add(jspTargetName);\n\n        String jspPath = getJspPath(jspTargetName, req.isOnline());\n        \n        File d = new File(jspPath).getParentFile();   \n        if ((d == null) || (d.exists() && ! (d.isDirectory() && d.canRead()))) {\n            if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_CRITICAL)) \n                A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_CRITICAL, \"Could not access directory for \" + jspPath);\n            throw new ServletException(\"JspLoader: Could not access directory for \" + jspPath);\n        }   \n         \n        if (! d.exists()) {\n            // create directory structure\n            d.mkdirs();    \n        }\n                \n        boolean mustUpdate = false;\n        \n        File f = new File(jspPath);        \n        if (!f.exists()) {\n            // File does not exist in FS\n            mustUpdate = true;            \n        } else if (f.lastModified() <= file.getDateLastModified()) {\n            // File in FS is older then file in VFS\n            mustUpdate = true;\n        } else if (req.isDoRecompile()) {\n            // Recompile is forced with parameter\n            mustUpdate = true;\n        }\n\n        String jspfilename = getJspUri(file.getAbsolutePath(), req.isOnline());               \n        \n        if (mustUpdate) {\n            if (DEBUG > 2) System.err.println(\"JspLoader writing new file: \" + jspfilename);         \n            byte[] contents = null;\n            String jspEncoding = null;\n            try {\n                contents = req.getCmsObject().readFile(file.getAbsolutePath()).getContents();\n                // Encoding project:\n                // Check the JSP \"content-encoding\" property\n                jspEncoding = cms.readProperty(file.getAbsolutePath(), I_CmsConstants.C_PROPERTY_CONTENT_ENCODING, false);\n                if (jspEncoding == null) jspEncoding = C_DEFAULT_JSP_ENCODING;\n                jspEncoding = jspEncoding.trim().toUpperCase();\n            } catch (CmsException e) {\n                throw new ServletException(\"JspLoader: Could not read contents for file '\" + file.getAbsolutePath() + \"'\", e);\n            }\n            \n            try {\n                FileOutputStream fs = new FileOutputStream(f);                \n                // Encoding project:\n                // We need to use some encoding to convert bytes to String\n                // corectly. Internally a JSP will always be stored in the \n                // system default encoding since they are just a variation of\n                // the \"plain\" resource type.\n                String page = new String(contents, A_OpenCms.getDefaultEncoding());\n                StringBuffer buf = new StringBuffer(contents.length);\n\n                int p0 = 0, i2 = 0, slen = C_DIRECTIVE_START.length(), elen = C_DIRECTIVE_END.length();\n                // Check if any jsp name references occur in the file\n                int i1 = page.indexOf(C_DIRECTIVE_START);\n                while (i1 >= 0) {\n                    // Parse the file and replace jsp name references \n                    i2 = page.indexOf(C_DIRECTIVE_END, i1 + slen);\n                    if (i2 > i1) {\n                        String directive = page.substring(i1 + slen, i2);\n                        if (DEBUG > 2) System.err.println(\"JspLoader: Detected \" + C_DIRECTIVE_START + directive + C_DIRECTIVE_END);\n\n                        int t1=0, t2=0, t3=0, t4=0, t5=0, t6=slen, t7=0;\n                        while (directive.charAt(t1) == ' ') t1++;\n                        String filename = null;                        \n                        if (directive.startsWith(\"include\", t1)) {            \n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'include' directive!\");                            \n                            t2 = directive.indexOf(\"file\", t1 + 7);\n                            t5 = 6;\n                        } else if (directive.startsWith(\"page\", t1)) {\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'page' directive!\");                            \n                            t2 = directive.indexOf(\"errorPage\", t1 + 4);\n                            t5 = 11;\n                        } else if (directive.startsWith(\"cms\", t1)) {\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Detected 'cms' directive!\");                            \n                            t2 = directive.indexOf(\"file\", t1 + 3);\n                            t5 = 4; t6 = 0; t7 = elen; \n                        }\n                        \n                        if (t2 > 0) {\n                            String sub = directive.substring(t2 + t5); \n                            char c1 = sub.charAt(t3);\n                            while ((c1 == ' ') || (c1 == '=') || (c1 == '\"')) c1 = sub.charAt(++t3);\n                            t4 = t3;\n                            while (c1 != '\"') c1 = sub.charAt(++t4);\n                            if (t4 > t3) filename=sub.substring(t3,t4);\n                            if (DEBUG > 2) System.err.println(\"JspLoader: File given in directive is: \" + filename);                            \n                        }\n                        \n                        if (filename != null) {\n                            // a file was found, changes have to be made\n                            String pre = ((t7 == 0)?directive.substring(0,t2+t3+t5):\"\");                            ;\n                            String suf = ((t7 == 0)?directive.substring(t2+t3+t5+filename.length()):\"\");\n                            // Now try to update the referenced file \n                            String absolute = req.toAbsolute(filename);\n                            if (DEBUG > 2) System.err.println(\"JspLoader: Absolute location=\" + absolute);\n                            String jspname = null;\n                            try {\n                                // Make sure the jsp referenced file is generated\n                                CmsResource jsp = cms.readFileHeader(absolute);\n                                updateJsp(cms, jsp, req, updates);\n                                jspname = getJspUri(jsp.getAbsolutePath(), req.isOnline());\n                            } catch (Exception e) {\n                                jspname = null;\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Error while creating jsp file \" + absolute + \"\\n\" + e);\n                            }\n                            if (jspname != null) {\n                                // Only change something in case no error had occured\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Name of jsp file is \" + jspname);\n                                directive = pre + jspname + suf;\n                                if (DEBUG > 2) System.err.println(\"JspLoader: Changed directive to \" + C_DIRECTIVE_START + directive + C_DIRECTIVE_END);                                                     \n                            }\n                        }\n                        \n                        buf.append(page.substring(p0, i1 + t6));\n                        buf.append(directive);\n                        p0 = i2 + t7;\n                        i1 = page.indexOf(C_DIRECTIVE_START, p0);\n                    }\n                }                  \n                if (i2 > 0) {\n                    buf.append(page.substring(p0, page.length()));\n                    // Encoding project:\n                    // Now we are ready to store String data in file system.\n                    // To convert String to bytes we also need to provide\n                    // some encoding. The default (by the JSP standard) encoding \n                    // for JSP is ISO-8859-1.\n                    contents = buf.toString().getBytes(jspEncoding);\n                } else {\n                    // Encoding project:\n                    // Contents of original file where not modified,\n                    // just translate to the required JSP encoding (if necessary)\n                    contents = Encoder.changeEncoding(contents, A_OpenCms.getDefaultEncoding(), jspEncoding);   \n                }                                         \n                fs.write(contents);                \n                fs.close();\n                \n                if (I_CmsLogChannels.C_LOGGING && A_OpenCms.isLogging(I_CmsLogChannels.C_OPENCMS_INFO)) \n                    A_OpenCms.log(I_CmsLogChannels.C_OPENCMS_INFO, \"Updated JSP file \\\"\" + jspfilename + \"\\\" for resource \\\"\" + file.getAbsolutePath() + \"\\\"\") ;\n            } catch (FileNotFoundException e) {\n                throw new ServletException(\"JspLauncher: Could not write to file '\" + f.getName() + \"'\\n\" + e, e);\n            }\n        }                      \n        return jspfilename;\n    }","commit_id":"ee42941aab8aa515993fc546221bcdb5127f2b5d","url":"https://github.com/alkacon/opencms-core"},{"original_method":"private String getFreeSpace(File dir) {\n\t\tString sz = \"\";\n\t\tif (dir.canRead()) {\n\t\t\tStatFs fs = new StatFs(dir.getAbsolutePath());\n\t\t\t@SuppressWarnings(\"deprecation\")\n\t\t\tfloat size = (float) fs.getAvailableBlocks() * fs.getBlockSize();\n\t\t\tif (size > 0) {\n\t\t\t\tif (size > 1 << 20) {\n\t\t\t\t\tsz = DownloadActivity.formatGb.format(new Object[]{size / (1 << 30)});\n\t\t\t\t} else {\n\t\t\t\t\tsz = DownloadActivity.formatMb.format(new Object[]{size / (1 << 20)});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn sz;\n\t}","id":36055,"modified_method":"private String getFreeSpace(File dir) {\n\t\tString sz = \"\";\n\t\tif (dir != null && dir.canRead()) {\n\t\t\tStatFs fs = new StatFs(dir.getAbsolutePath());\n\t\t\t@SuppressWarnings(\"deprecation\")\n\t\t\tfloat size = (float) fs.getAvailableBlocks() * fs.getBlockSize();\n\t\t\tif (size > 0) {\n\t\t\t\tif (size > 1 << 20) {\n\t\t\t\t\tsz = DownloadActivity.formatGb.format(new Object[]{size / (1 << 30)});\n\t\t\t\t} else {\n\t\t\t\t\tsz = DownloadActivity.formatMb.format(new Object[]{size / (1 << 20)});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn sz;\n\t}","commit_id":"40c7f7b7ce76abe05ae3c1bb804e6d57d7af1aaf","url":"https://github.com/osmandapp/Osmand"},{"original_method":"@Override\n\tpublic View onCreateView(LayoutInflater inflater, ViewGroup container,\n\t\t\t\t\t\t\t Bundle savedInstanceState) {\n\n\t\thasExternalStoragePermission = DownloadActivity.hasPermissionToWriteExternalStorage(getActivity());\n\n\t\tinternalStorage = getInternalStorageDirectory(getActivity());\n\t\tif (hasExternalStoragePermission) {\n\t\t\tsharedStorage = getSharedStorageDirectory(getActivity());\n\t\t\texternalStorage = getMyApplication().getSettings().getSecondaryStorage();\n\t\t}\n\n\t\tBundle args = null;\n\t\tif (savedInstanceState != null) {\n\t\t\targs = savedInstanceState;\n\t\t} else if (getArguments() != null) {\n\t\t\targs = getArguments();\n\t\t}\n\n\t\tif (args != null) {\n\t\t\tstorageReadOnly = args.getBoolean(STORAGE_READOLNY_KEY);\n\t\t}\n\n\t\tfinal View view = inflater.inflate(R.layout.fragment_data_storage_place_dialog, container,\n\t\t\t\tfalse);\n\t\t((ImageView) view.findViewById(R.id.folderIconImageView))\n\t\t\t\t.setImageDrawable(getIcon(R.drawable.ic_action_folder, R.color.map_widget_blue));\n\n\t\tif (storageReadOnly) {\n\t\t\t((TextView) view.findViewById(R.id.description))\n\t\t\t\t\t.setText(getString(R.string.storage_directory_readonly_desc));\n\t\t}\n\n\t\tView internalStorageRow = view.findViewById(R.id.deviceMemoryRow);\n\t\tinternalStorageRow.setOnClickListener(internalMemoryOnClickListener);\n\t\tImageView internalStorageImageView = (ImageView) view.findViewById(R.id.deviceMemoryImageView);\n\t\tinternalStorageImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\tTextView internalStorageDescription = (TextView) view.findViewById(R.id.deviceMemoryDescription);\n\t\tinternalStorageDescription.setText(getFreeSpace(internalStorage));\n\n\t\tView sharedMemoryRow = view.findViewById(R.id.sharedMemoryRow);\n\t\tsharedMemoryRow.setOnClickListener(sharedMemoryOnClickListener);\n\t\tImageView sharedMemoryImageView = (ImageView) view.findViewById(R.id.sharedMemoryImageView);\n\t\tsharedMemoryImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\tTextView sharedMemoryDescription = (TextView) view.findViewById(R.id.sharedMemoryDescription);\n\t\tsharedMemoryDescription.setText(getFreeSpace(sharedStorage));\n\n\t\tView memoryStickRow = view.findViewById(R.id.memoryStickRow);\n\t\tif (hasExternalStoragePermission && externalStorage != null) {\n\t\t\tmemoryStickRow.setOnClickListener(externalMemoryOnClickListener);\n\t\t\tImageView memoryStickImageView = (ImageView) view.findViewById(R.id.memoryStickImageView);\n\t\t\tmemoryStickImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\t\tTextView memoryStickDescription = (TextView) view.findViewById(R.id.memoryStickDescription);\n\t\t\tmemoryStickDescription.setText(getFreeSpace(externalStorage));\n\t\t} else {\n\t\t\tview.findViewById(R.id.divExtStorage).setVisibility(View.GONE);\n\t\t\tmemoryStickRow.setVisibility(View.GONE);\n\t\t}\n\n\t\tfinal ImageButton closeImageButton = (ImageButton) view.findViewById(R.id.closeImageButton);\n\t\tcloseImageButton.setImageDrawable(getContentIcon(R.drawable.ic_action_remove_dark));\n\t\tcloseImageButton.setOnClickListener(new View.OnClickListener() {\n\t\t\t@Override\n\t\t\tpublic void onClick(View v) {\n\t\t\t\tisInterestedInFirstTime = false;\n\t\t\t\tdismiss();\n\t\t\t}\n\t\t});\n\t\treturn view;\n\t}","id":36056,"modified_method":"@Override\n\tpublic View onCreateView(LayoutInflater inflater, ViewGroup container,\n\t\t\t\t\t\t\t Bundle savedInstanceState) {\n\n\t\thasExternalStoragePermission = DownloadActivity.hasPermissionToWriteExternalStorage(getActivity());\n\n\t\tinternalStorage = getInternalStorageDirectory(getActivity());\n\t\tif (hasExternalStoragePermission) {\n\t\t\tsharedStorage = getSharedStorageDirectory(getActivity());\n\t\t\texternalStorage = getMyApplication().getSettings().getSecondaryStorage();\n\t\t}\n\n\t\tBundle args = null;\n\t\tif (savedInstanceState != null) {\n\t\t\targs = savedInstanceState;\n\t\t} else if (getArguments() != null) {\n\t\t\targs = getArguments();\n\t\t}\n\n\t\tif (args != null) {\n\t\t\tstorageReadOnly = args.getBoolean(STORAGE_READOLNY_KEY);\n\t\t}\n\n\t\tfinal View view = inflater.inflate(R.layout.fragment_data_storage_place_dialog, container,\n\t\t\t\tfalse);\n\t\t((ImageView) view.findViewById(R.id.folderIconImageView))\n\t\t\t\t.setImageDrawable(getIcon(R.drawable.ic_action_folder, R.color.map_widget_blue));\n\n\t\tif (storageReadOnly) {\n\t\t\t((TextView) view.findViewById(R.id.description))\n\t\t\t\t\t.setText(getString(R.string.storage_directory_readonly_desc));\n\t\t}\n\n\t\tView internalStorageRow = view.findViewById(R.id.deviceMemoryRow);\n\t\tinternalStorageRow.setOnClickListener(internalMemoryOnClickListener);\n\t\tImageView internalStorageImageView = (ImageView) view.findViewById(R.id.deviceMemoryImageView);\n\t\tinternalStorageImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\tTextView internalStorageDescription = (TextView) view.findViewById(R.id.deviceMemoryDescription);\n\t\tinternalStorageDescription.setText(getFreeSpace(internalStorage));\n\n\t\tView sharedMemoryRow = view.findViewById(R.id.sharedMemoryRow);\n\t\tif (hasExternalStoragePermission && sharedStorage != null) {\n\t\t\tsharedMemoryRow.setOnClickListener(sharedMemoryOnClickListener);\n\t\t\tImageView sharedMemoryImageView = (ImageView) view.findViewById(R.id.sharedMemoryImageView);\n\t\t\tsharedMemoryImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\t\tTextView sharedMemoryDescription = (TextView) view.findViewById(R.id.sharedMemoryDescription);\n\t\t\tsharedMemoryDescription.setText(getFreeSpace(sharedStorage));\n\t\t} else {\n\t\t\tview.findViewById(R.id.divSharedStorage).setVisibility(View.GONE);\n\t\t\tsharedMemoryRow.setVisibility(View.GONE);\n\t\t}\n\n\t\tView memoryStickRow = view.findViewById(R.id.memoryStickRow);\n\t\tif (hasExternalStoragePermission && externalStorage != null) {\n\t\t\tmemoryStickRow.setOnClickListener(externalMemoryOnClickListener);\n\t\t\tImageView memoryStickImageView = (ImageView) view.findViewById(R.id.memoryStickImageView);\n\t\t\tmemoryStickImageView.setImageDrawable(getContentIcon(R.drawable.ic_sdcard));\n\t\t\tTextView memoryStickDescription = (TextView) view.findViewById(R.id.memoryStickDescription);\n\t\t\tmemoryStickDescription.setText(getFreeSpace(externalStorage));\n\t\t} else {\n\t\t\tview.findViewById(R.id.divExtStorage).setVisibility(View.GONE);\n\t\t\tmemoryStickRow.setVisibility(View.GONE);\n\t\t}\n\n\t\tfinal ImageButton closeImageButton = (ImageButton) view.findViewById(R.id.closeImageButton);\n\t\tcloseImageButton.setImageDrawable(getContentIcon(R.drawable.ic_action_remove_dark));\n\t\tcloseImageButton.setOnClickListener(new View.OnClickListener() {\n\t\t\t@Override\n\t\t\tpublic void onClick(View v) {\n\t\t\t\tisInterestedInFirstTime = false;\n\t\t\t\tdismiss();\n\t\t\t}\n\t\t});\n\t\treturn view;\n\t}","commit_id":"40c7f7b7ce76abe05ae3c1bb804e6d57d7af1aaf","url":"https://github.com/osmandapp/Osmand"},{"original_method":"public Destination lookup(String hostname) {\n        // Try to look it up in hosts.txt \n        // Reload file each time to catch changes.\n        // (and it's easier :P\n        String hostsfile = _context.getProperty(PROP_HOSTS_FILE, DEFAULT_HOSTS_FILE);\n        Properties hosts = new Properties();\n        FileInputStream fis = null;\n        try {\n            File f = new File(hostsfile);\n            if (f.canRead()) {\n                fis = new FileInputStream(f);\n                hosts.load(fis);\n            } else {\n                _log.error(\"Hosts file \" + hostsfile + \" does not exist.\");\n            }\n        } catch (Exception ioe) {\n            _log.error(\"Error loading hosts file \" + hostsfile, ioe);\n        } finally {\n            if (fis != null) try {\n                fis.close();\n            } catch (IOException ioe) { // nop\n            }\n        }\n        String res = hosts.getProperty(hostname);\n        // If we can't find name in hosts, assume it's a key.\n        if ((res == null) || (res.trim().length() == 0)) {\n            res = hostname;\n        }\n        return lookupBase64(res);\n    }","id":36057,"modified_method":"public Destination lookup(String hostname) {\n        // check the list each time, reloading the file on each\n        // lookup\n        \n        List filenames = getFilenames();\n        for (int i = 0; i < filenames.size(); i++) { \n            String hostsfile = (String)filenames.get(i);\n            Properties hosts = new Properties();\n            FileInputStream fis = null;\n            try {\n                File f = new File(hostsfile);\n                if ( (f.exists()) && (f.canRead()) ) {\n                    fis = new FileInputStream(f);\n                    hosts.load(fis);\n                    \n                    String key = hosts.getProperty(hostname);\n                    if ( (key != null) && (key.trim().length() > 0) ) {\n                        return lookupBase64(key);\n                    }\n                    \n                } else {\n                    _log.warn(\"Hosts file \" + hostsfile + \" does not exist.\");\n                }\n            } catch (Exception ioe) {\n                _log.error(\"Error loading hosts file \" + hostsfile, ioe);\n            } finally {\n                if (fis != null) try {\n                    fis.close();\n                } catch (IOException ioe) { // nop\n                }\n            }\n            // not found, continue to the next file\n        }\n        // If we can't find name in any of the hosts files, \n        // assume it's a key.\n        return lookupBase64(hostname);\n    }","commit_id":"54dce61a95886dc8a91f32342c42d8ac3ce3e76e","url":"https://github.com/i2p/i2p.i2p"},{"original_method":"public static FileInputList createFileList(String[] fileName, String[] fileMask, String[] fileRequired)\r\n    {\r\n        FileInputList fileInputList = new FileInputList();\r\n\r\n        // Replace possible environment variables...\r\n        final String realfile[] = StringUtil.environmentSubstitute(fileName);\r\n        final String realmask[] = StringUtil.environmentSubstitute(fileMask);\r\n\r\n        for (int i = 0; i < realfile.length; i++)\r\n        {\r\n            final String onefile = realfile[i];\r\n            final String onemask = realmask[i];\r\n            final boolean onerequired = YES.equalsIgnoreCase(fileRequired[i]);\r\n\r\n            // System.out.println(\"Checking file [\"+onefile+\"] mask\r\n            // [\"+onemask+\"]\");\r\n            if (onefile == null) continue;\r\n\r\n            if (onemask != null && onemask.length() > 0) // A directory & a\r\n            // wildcard\r\n            {\r\n                File file = new File(onefile);\r\n                try\r\n                {\r\n                    String[] fileNames = file.list(new FilenameFilter()\r\n                    {\r\n                        public boolean accept(File dir, String name)\r\n                        {\r\n                            return Pattern.matches(onemask, name);\r\n                        }\r\n                    });\r\n\r\n                    if (fileNames != null) \r\n                    {\r\n                        for (int j = 0; j < fileNames.length; j++)\r\n                        {\r\n                            fileInputList.addFile(new File(file, fileNames[j]));\r\n                        }\r\n                    }\r\n                    \r\n                    if (fileNames==null || fileNames.length==0)\r\n                    {\r\n                        if (onerequired) fileInputList.addNonAccessibleFile(file);\r\n                    }\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    LogWriter.getInstance().logError(\"FileInputList\", Const.getStackTracker(e));\r\n                }\r\n            }\r\n            else\r\n            // A normal file...\r\n            {\r\n                File file = new File(onefile);\r\n                if (file.exists())\r\n                {\r\n                    if (file.canRead())\r\n                    {\r\n                        if (file.isFile()) fileInputList.addFile(file);\r\n                    }\r\n                    else\r\n                    {\r\n                        if (onerequired) fileInputList.addNonAccessibleFile(file);\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    if (onerequired) fileInputList.addNonExistantFile(file);\r\n                }\r\n            }\r\n        }\r\n\r\n        // Sort the list: quicksort\r\n        fileInputList.sortFiles();\r\n\r\n        // OK, return the list in filelist...\r\n        // files = (String[]) filelist.toArray(new String[filelist.size()]);\r\n\r\n        return fileInputList;\r\n    }","id":36058,"modified_method":"public static FileInputList createFileList(String[] fileName, String[] fileMask, String[] fileRequired)\r\n    {\r\n        FileInputList fileInputList = new FileInputList();\r\n\r\n        // Replace possible environment variables...\r\n        final String realfile[] = StringUtil.environmentSubstitute(fileName);\r\n        final String realmask[] = StringUtil.environmentSubstitute(fileMask);\r\n\r\n        for (int i = 0; i < realfile.length; i++)\r\n        {\r\n            final String onefile = realfile[i];\r\n            final String onemask = realmask[i];\r\n            final boolean onerequired = YES.equalsIgnoreCase(fileRequired[i]);\r\n\r\n            // System.out.println(\"Checking file [\"+onefile+\"] mask\r\n            // [\"+onemask+\"]\");\r\n            if (onefile == null) continue;\r\n\r\n            if (onemask != null && onemask.length() > 0) // A directory & a\r\n            // wildcard\r\n            {\r\n                File file = new File(onefile);\r\n                try\r\n                {\r\n                    String[] fileNames = file.list(new FilenameFilter()\r\n                    {\r\n                        public boolean accept(File dir, String name)\r\n                        {\r\n                            return Pattern.matches(onemask, name);\r\n                        }\r\n                    });\r\n\r\n                    if (fileNames != null) \r\n                    {\r\n                        for (int j = 0; j < fileNames.length; j++)\r\n                        {\r\n                            File localFile = new File(file, fileNames[j]);\r\n                            if (!localFile.isDirectory() && localFile.isFile()) fileInputList.addFile(localFile);\r\n                        }\r\n                    }\r\n                    \r\n                    if (Const.isEmpty(fileNames))\r\n                    {\r\n                        if (onerequired) fileInputList.addNonAccessibleFile(file);\r\n                    }\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    LogWriter.getInstance().logError(\"FileInputList\", Const.getStackTracker(e));\r\n                }\r\n            }\r\n            else\r\n            // A normal file...\r\n            {\r\n                File file = new File(onefile);\r\n                if (file.exists())\r\n                {\r\n                    if (file.canRead() && file.isFile())\r\n                    {\r\n                        if (file.isFile()) fileInputList.addFile(file);\r\n                    }\r\n                    else\r\n                    {\r\n                        if (onerequired) fileInputList.addNonAccessibleFile(file);\r\n                    }\r\n                }\r\n                else\r\n                {\r\n                    if (onerequired) fileInputList.addNonExistantFile(file);\r\n                }\r\n            }\r\n        }\r\n\r\n        // Sort the list: quicksort\r\n        fileInputList.sortFiles();\r\n\r\n        // OK, return the list in filelist...\r\n        // files = (String[]) filelist.toArray(new String[filelist.size()]);\r\n\r\n        return fileInputList;\r\n    }","commit_id":"4bb32cd9a05a6718d31e38ddd4b768c7d96a15c4","url":"https://github.com/pentaho/pentaho-kettle"},{"original_method":"static SimpleFieldSet load(File filename, File tempFilename) throws IOException {\n\t\tboolean filenameExists = filename.exists();\n\t\tboolean tempFilenameExists = tempFilename.exists();\n\t\tif(filenameExists && !filename.canWrite()) {\n\t\t\tLogger.error(FilePersistentConfig.class, \"Warning: Cannot write to config file: \"+filename);\n\t\t\tSystem.err.println(\"Warning: Cannot write to config file: \"+filename);\n\t\t}\n\t\tif(tempFilenameExists && !tempFilename.canWrite()) {\n\t\t\tLogger.error(FilePersistentConfig.class, \"Warning: Cannot write to config tempfile: \"+tempFilename);\n\t\t\tSystem.err.println(\"Warning: Cannot write to config tempfile: \"+tempFilename);\n\t\t}\n\t\tif(filenameExists) {\n\t\t\tif(filename.canRead()) {\n\t\t\t\ttry {\n\t\t\t\t\treturn initialLoad(filename);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\tSystem.err.println(\"Cannot open config file \"+filename+\" : \"+e+\" - checking for temp file \"+tempFilename);\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tSystem.err.println(\"Empty config file \"+filename+\" (end of file)\");\n\t\t\t\t}\n\t\t\t\t// Other IOE's indicate a more serious problem.\n\t\t\t} else {\n\t\t\t\t// We probably won't be able to write it either.\n\t\t\t\tSystem.err.println(\"Cannot read config file \"+filename);\n\t\t\t\tthrow new IOException(\"Cannot read config file\");\n\t\t\t}\n\t\t}\n\t\tif(tempFilename.exists()) {\n\t\t\tif(tempFilename.canRead()) {\n\t\t\t\ttry {\n\t\t\t\t\treturn initialLoad(tempFilename);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\tSystem.err.println(\"Cannot open temp config file either: \"+tempFilename+\" : \"+e);\n\t\t\t\t} // Other IOE's indicate a more serious problem.\n\t\t\t} else {\n\t\t\t\tSystem.err.println(\"Cannot read (temp) config file \"+tempFilename);\n\t\t\t\tthrow new IOException(\"Cannot read (temp) config file \"+tempFilename);\n\t\t\t}\n\t\t}\n\t\tSystem.err.println(\"No config file found, creating new: \"+filename);\n\t\treturn null;\n\t}","id":36059,"modified_method":"static SimpleFieldSet load(File filename, File tempFilename) throws IOException {\n\t\tboolean filenameExists = filename.exists();\n\t\tboolean tempFilenameExists = tempFilename.exists();\n\t\tif(filenameExists && !filename.canWrite()) {\n\t\t\tLogger.error(FilePersistentConfig.class, \"Warning: Cannot write to config file: \"+filename);\n\t\t\tSystem.err.println(\"Warning: Cannot write to config file: \"+filename);\n\t\t}\n\t\tif(tempFilenameExists && !tempFilename.canWrite()) {\n\t\t\tLogger.error(FilePersistentConfig.class, \"Warning: Cannot write to config tempfile: \"+tempFilename);\n\t\t\tSystem.err.println(\"Warning: Cannot write to config tempfile: \"+tempFilename);\n\t\t}\n\t\tif(filenameExists) {\n\t\t\tif(filename.canRead() && filename.length() > 0) {\n\t\t\t\ttry {\n\t\t\t\t\treturn initialLoad(filename);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\tSystem.err.println(\"Cannot open config file \"+filename+\" : \"+e+\" - checking for temp file \"+tempFilename);\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tSystem.err.println(\"Empty config file \"+filename+\" (end of file)\");\n\t\t\t\t}\n\t\t\t\t// Other IOE's indicate a more serious problem.\n\t\t\t} else {\n\t\t\t\t// We probably won't be able to write it either.\n\t\t\t\tSystem.err.println(\"Cannot read config file \"+filename);\n\t\t\t\tthrow new IOException(\"Cannot read config file\");\n\t\t\t}\n\t\t}\n\t\tif(tempFilename.exists()) {\n\t\t\tif(tempFilename.canRead() && tempFilename.length() > 0) {\n\t\t\t\ttry {\n\t\t\t\t\treturn initialLoad(tempFilename);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\tSystem.err.println(\"Cannot open temp config file either: \"+tempFilename+\" : \"+e);\n\t\t\t\t} // Other IOE's indicate a more serious problem.\n\t\t\t} else {\n\t\t\t\tSystem.err.println(\"Cannot read (temp) config file \"+tempFilename);\n\t\t\t\tthrow new IOException(\"Cannot read (temp) config file \"+tempFilename);\n\t\t\t}\n\t\t}\n\t\tSystem.err.println(\"No config file found, creating new: \"+filename);\n\t\treturn null;\n\t}","commit_id":"cbb94dd02d1a37ea8fd37192e94f1f5dd58fd5ad","url":"https://github.com/freenet/fred"},{"original_method":"public static void doResponse(final Properties conProp, final httpRequestHeader requestHeader, final OutputStream out, final InputStream body) {\r\n  \r\n        String path = null;\r\n        try {\r\n            // getting some connection properties            \r\n            final String method = conProp.getProperty(httpHeader.CONNECTION_PROP_METHOD);\r\n            path = conProp.getProperty(httpHeader.CONNECTION_PROP_PATH);\r\n            String argsString = conProp.getProperty(httpHeader.CONNECTION_PROP_ARGS); // is null if no args were given\r\n            final String httpVersion = conProp.getProperty(httpHeader.CONNECTION_PROP_HTTP_VER);\r\n            final String clientIP = conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP, \"unknown-host\");\r\n            \r\n            // check hack attacks in path\r\n            if (path.indexOf(\"..\") >= 0) {\r\n                httpd.sendRespondError(conProp,out,4,403,null,\"Access not allowed\",null);\r\n                return;\r\n            }\r\n            \r\n            // url decoding of path\r\n            try {\r\n                path = URLDecoder.decode(path, \"UTF-8\");\r\n            } catch (final UnsupportedEncodingException e) {\r\n                // This should never occur\r\n                assert(false) : \"UnsupportedEncodingException: \" + e.getMessage();\r\n            }\r\n            \r\n            // check against hack attacks in path\r\n            if (path.indexOf(\"..\") >= 0) {\r\n                httpd.sendRespondError(conProp,out,4,403,null,\"Access not allowed\",null);\r\n                return;\r\n            }\r\n            \r\n            // check permission/granted access\r\n            String authorization = requestHeader.get(httpRequestHeader.AUTHORIZATION);\r\n            if (authorization != null && authorization.length() == 0) authorization = null;\r\n            final String adminAccountBase64MD5 = switchboard.getConfig(httpd.ADMIN_ACCOUNT_B64MD5, \"\");\r\n            \r\n            // a bad patch to map the /xml/ path to /api/\r\n            if (path.startsWith(\"/xml/\")) {\r\n                path = \"/api/\" + path.substring(5);\r\n            }\r\n\r\n            final boolean adminAccountForLocalhost = sb.getConfigBool(\"adminAccountForLocalhost\", false);\r\n            final String refererHost = requestHeader.refererHost();\r\n            final boolean accessFromLocalhost = serverCore.isLocalhost(clientIP) && (refererHost.length() == 0 || serverCore.isLocalhost(refererHost));\r\n            final boolean grantedForLocalhost = adminAccountForLocalhost && accessFromLocalhost;\r\n            final boolean protectedPage = path.indexOf(\"_p.\") > 0;\r\n            final boolean accountEmpty = adminAccountBase64MD5.length() == 0;\r\n            \r\n            if (!grantedForLocalhost && protectedPage && !accountEmpty) {\r\n                // authentication required\r\n                if (authorization == null) {\r\n                    // no authorization given in response. Ask for that\r\n                    final httpResponseHeader responseHeader = getDefaultHeaders(path);\r\n                    responseHeader.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"admin log-in\\\"\");\r\n                    //httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                    final servletProperties tp=new servletProperties();\r\n                    tp.put(\"returnto\", path);\r\n                    //TODO: separate error page Wrong Login / No Login\r\n                    httpd.sendRespondError(conProp, out, 5, 401, \"Wrong Authentication\", \"\", new File(\"proxymsg/authfail.inc\"), tp, null, responseHeader);\r\n                    return;\r\n                } else if (\r\n                    (httpd.staticAdminAuthenticated(authorization.trim().substring(6), switchboard) == 4) ||\r\n                    (sb.userDB.hasAdminRight(authorization, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP), requestHeader.getHeaderCookies()))) {\r\n                    //Authentication successful. remove brute-force flag\r\n                    serverCore.bfHost.remove(conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                } else {\r\n                    // a wrong authentication was given or the userDB user does not have admin access. Ask again\r\n                    serverLog.logInfo(\"HTTPD\", \"Wrong log-in for account 'admin' in http file handler for path '\" + path + \"' from host '\" + clientIP + \"'\");\r\n                    final Integer attempts = serverCore.bfHost.get(clientIP);\r\n                    if (attempts == null)\r\n                        serverCore.bfHost.put(clientIP, Integer.valueOf(1));\r\n                    else\r\n                        serverCore.bfHost.put(clientIP, Integer.valueOf(attempts.intValue() + 1));\r\n    \r\n                    final httpResponseHeader headers = getDefaultHeaders(path);\r\n                    headers.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"admin log-in\\\"\");\r\n                    httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                    return;\r\n                }\r\n            }\r\n        \r\n            // parse arguments\r\n            serverObjects args = new serverObjects();\r\n            int argc = 0;\r\n            if (argsString == null) {\r\n                // no args here, maybe a POST with multipart extension\r\n                int length = requestHeader.getContentLength();\r\n                //System.out.println(\"HEADER: \" + requestHeader.toString()); // DEBUG\r\n\r\n                /* don't parse body in case of a POST CGI call since it has to be\r\n                 * handed over to the CGI script unaltered and parsed by the script\r\n                 */\r\n                if (method.equals(httpHeader.METHOD_POST) &&\r\n                        !(switchboard.getConfigBool(\"cgi.allow\", false) &&\r\n                        httpdFileHandler.matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null)))\r\n                        ) {\r\n\r\n                    // if its a POST, it can be either multipart or as args in the body\r\n                    if ((requestHeader.containsKey(httpHeader.CONTENT_TYPE)) &&\r\n                            (requestHeader.get(httpHeader.CONTENT_TYPE).toLowerCase().startsWith(\"multipart\"))) {\r\n                        // parse multipart\r\n                        final HashMap<String, byte[]> files = httpd.parseMultipart(requestHeader, args, body);\r\n                        // integrate these files into the args\r\n                        if (files != null) {\r\n                            final Iterator<Map.Entry<String, byte[]>> fit = files.entrySet().iterator();\r\n                            Map.Entry<String, byte[]> entry;\r\n                            while (fit.hasNext()) {\r\n                                entry = fit.next();\r\n                                args.put(entry.getKey() + \"$file\", entry.getValue());\r\n                            }\r\n                        }\r\n                        argc = Integer.parseInt(requestHeader.get(\"ARGC\"));\r\n                    } else {\r\n                        // parse args in body\r\n                        argc = httpd.parseArgs(args, body, length);\r\n                    }\r\n                } else {\r\n                    // no args\r\n                    argsString = null;\r\n                    args = null;\r\n                    argc = 0;\r\n                }\r\n            } else {\r\n                // simple args in URL (stuff after the \"?\")\r\n                argc = httpd.parseArgs(args, argsString);\r\n            }\r\n        \r\n            // check for cross site scripting - attacks in request arguments\r\n            if (args != null && argc > 0) {\r\n                // check all values for occurrences of script values\r\n                final Iterator<String> e = args.values().iterator(); // enumeration of values\r\n                String val;\r\n                while (e.hasNext()) {\r\n                    val = e.next();\r\n                    if ((val != null) && (val.indexOf(\"<script\") >= 0)) {\r\n                        // deny request\r\n                        httpd.sendRespondError(conProp,out,4,403,null,\"bad post values\",null);\r\n                        return;\r\n                    }\r\n                }\r\n            }\r\n        \r\n            // we are finished with parsing\r\n            // the result of value hand-over is in args and argc\r\n            if (path.length() == 0) {\r\n                httpd.sendRespondError(conProp,out,4,400,null,\"Bad Request\",null);\r\n                out.flush();\r\n                return;\r\n            }\r\n            File targetClass=null;\r\n\r\n            // locate the file\r\n            if (!(path.startsWith(\"/\"))) path = \"/\" + path; // attach leading slash\r\n            \r\n            // a different language can be desired (by i.e. ConfigBasic.html) than the one stored in the locale.language\r\n            String localeSelection = switchboard.getConfig(\"locale.language\",\"default\");\r\n            if (args != null && (args.containsKey(\"language\"))) {\r\n                // TODO 9.11.06 Bost: a class with information about available languages is needed. \r\n                // the indexOf(\".\") is just a workaround because there from ConfigLanguage.html commes \"de.lng\" and\r\n                // from ConfigBasic.html comes just \"de\" in the \"language\" parameter\r\n                localeSelection = args.get(\"language\", localeSelection);\r\n                if (localeSelection.indexOf(\".\") != -1)\r\n                    localeSelection = localeSelection.substring(0, localeSelection.indexOf(\".\"));\r\n            }\r\n            \r\n            File targetFile = getLocalizedFile(path, localeSelection);\r\n            final String targetExt   = conProp.getProperty(\"EXT\",\"\");\r\n            targetClass = rewriteClassFile(new File(htDefaultPath, path));\r\n            if (path.endsWith(\"/\")) {\r\n                String testpath;\r\n                // attach default file name\r\n                for (int i = 0; i < defaultFiles.length; i++) {\r\n                    testpath = path + defaultFiles[i];\r\n                    targetFile = getOverlayedFile(testpath);\r\n                    targetClass = getOverlayedClass(testpath);\r\n                    if (targetFile.exists()) {\r\n                        path = testpath;\r\n                        break;\r\n                    }\r\n                }\r\n                \r\n                //no defaultfile, send a dirlisting\r\n                if (targetFile == null || !targetFile.exists()) {\r\n                    final StringBuilder aBuffer = new StringBuilder();\r\n                    aBuffer.append(\"<html>\\n<head>\\n<\/head>\\n<body>\\n<h1>Index of \" + path + \"<\/h1>\\n  <ul>\\n\");\r\n                    final File dir = new File(htDocsPath, path);\r\n                    String[] list = dir.list();\r\n                    if (list == null) list = new String[0]; // should not occur!\r\n                    File f;\r\n                    String size;\r\n                    long sz;\r\n                    String headline, author, description;\r\n                    int images, links;\r\n                    htmlFilterContentScraper scraper;\r\n                    for (int i = 0; i < list.length; i++) {\r\n                        f = new File(dir, list[i]);\r\n                        if (f.isDirectory()) {\r\n                            aBuffer.append(\"    <li><a href=\\\"\" + path + list[i] + \"/\\\">\" + list[i] + \"/<\/a><br><\/li>\\n\");\r\n                        } else {\r\n                            if (list[i].endsWith(\"html\") || (list[i].endsWith(\"htm\"))) {\r\n                                scraper = htmlFilterContentScraper.parseResource(f);\r\n                                headline = scraper.getTitle();\r\n                                author = scraper.getAuthor();\r\n                                description = scraper.getDescription();\r\n                                images = scraper.getImages().size();\r\n                                links = scraper.getAnchors().size();\r\n                            } else {\r\n                                headline = null;\r\n                                author = null;\r\n                                description = null;\r\n                                images = 0;\r\n                                links = 0;\r\n                            }\r\n                            sz = f.length();\r\n                            if (sz < 1024) {\r\n                                size = sz + \" bytes\";\r\n                            } else if (sz < 1024 * 1024) {\r\n                                size = (sz / 1024) + \" KB\";\r\n                            } else {\r\n                                size = (sz / 1024 / 1024) + \" MB\";\r\n                            }\r\n                            aBuffer.append(\"    <li>\");\r\n                            if ((headline != null) && (headline.length() > 0)) aBuffer.append(\"<a href=\\\"\" + list[i] + \"\\\"><b>\" + headline + \"<\/b><\/a><br>\");\r\n                            aBuffer.append(\"<a href=\\\"\" + path + list[i] + \"\\\">\" + list[i] + \"<\/a><br>\");\r\n                            if ((author != null) && (author.length() > 0)) aBuffer.append(\"Author: \" + author + \"<br>\");\r\n                            if ((description != null) && (description.length() > 0)) aBuffer.append(\"Description: \" + description + \"<br>\");\r\n                            aBuffer.append(serverDate.formatShortDay(new Date(f.lastModified())) + \", \" + size + ((images > 0) ? \", \" + images + \" images\" : \"\") + ((links > 0) ? \", \" + links + \" links\" : \"\") + \"<br><\/li>\\n\");\r\n                        }\r\n                    }\r\n                    aBuffer.append(\"  <\/ul>\\n<\/body>\\n<\/html>\\n\");\r\n\r\n                    // write the list to the client\r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, \"text/html; charset=UTF-8\", aBuffer.length(), new Date(dir.lastModified()), null, new httpResponseHeader(), null, null, true);\r\n                    if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        out.write(aBuffer.toString().getBytes(\"UTF-8\"));\r\n                    }\r\n                    return;\r\n                }\r\n            } else {\r\n                    //XXX: you cannot share a .png/.gif file with a name like a class in htroot.\r\n                    if ( !(targetFile.exists()) &&\r\n                            !((path.endsWith(\"png\")||path.endsWith(\"gif\") ||\r\n                            matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null)) ||\r\n                            path.endsWith(\".stream\")) &&\r\n                            targetClass!=null ) ){\r\n                        targetFile = new File(htDocsPath, path);\r\n                        targetClass = rewriteClassFile(new File(htDocsPath, path));\r\n                    }\r\n            }\r\n            \r\n            //File targetClass = rewriteClassFile(targetFile);\r\n            //We need tp here\r\n            servletProperties templatePatterns = null;\r\n            Date targetDate;\r\n            boolean nocache = false;\r\n            \r\n            if ((targetClass != null) && (path.endsWith(\"png\"))) {\r\n                // call an image-servlet to produce an on-the-fly - generated image\r\n                Object img = null;\r\n                try {\r\n                    requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                    requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                    // in case that there are no args given, args = null or empty hashmap\r\n                    img = invokeServlet(targetClass, requestHeader, args);\r\n                } catch (final InvocationTargetException e) {\r\n                    theLogger.logSevere(\"INTERNAL ERROR: \" + e.toString() + \":\" +\r\n                    e.getMessage() +\r\n                    \" target exception at \" + targetClass + \": \" +\r\n                    e.getTargetException().toString() + \":\" +\r\n                    e.getTargetException().getMessage() +\r\n                    \"; java.awt.graphicsenv='\" + System.getProperty(\"java.awt.graphicsenv\",\"\") + \"'\");\r\n                    targetClass = null;\r\n                }\r\n                if (img == null) {\r\n                    // error with image generation; send file-not-found\r\n                    httpd.sendRespondError(conProp, out, 3, 404, \"File not Found\", null, null);\r\n                } else {\r\n                    if (img instanceof ymageMatrix) {\r\n                        final ymageMatrix yp = (ymageMatrix) img;\r\n                        // send an image to client\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                        final String mimeType = mimeTable.getProperty(targetExt, \"text/html\");\r\n                        final serverByteBuffer result = ymageMatrix.exportImage(yp.getImage(), targetExt);\r\n\r\n                        // write the array to the client\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, result.length(), targetDate, null, null, null, null, nocache);\r\n                        if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        \tresult.writeTo(out);\r\n                        }\r\n                    }\r\n                    if (img instanceof Image) {\r\n                        final Image i = (Image) img;\r\n                        // send an image to client\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                        final String mimeType = mimeTable.getProperty(targetExt, \"text/html\");\r\n\r\n                        // generate an byte array from the generated image\r\n                        int width = i.getWidth(null); if (width < 0) width = 96; // bad hack\r\n                        int height = i.getHeight(null); if (height < 0) height = 96; // bad hack\r\n                        final BufferedImage bi = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);\r\n                        bi.createGraphics().drawImage(i, 0, 0, width, height, null); \r\n                        final serverByteBuffer result = ymageMatrix.exportImage(bi, targetExt);\r\n\r\n                        // write the array to the client\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, result.length(), targetDate, null, null, null, null, nocache);\r\n                        if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        \tresult.writeTo(out);\r\n                        }\r\n                    }\r\n                }\r\n            } else if (((switchboard.getConfigBool(\"cgi.allow\", false)) &&                                  // check if CGI execution is allowed in config\r\n                    (httpdFileHandler.matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null))) &&  // \"right\" file extension?\r\n                    (path.substring(0, path.indexOf(targetFile.getName())).contains(\"/CGI-BIN/\") ||\r\n                    path.substring(0, path.indexOf(targetFile.getName())).contains(\"/cgi-bin/\")) &&         // file in right directory?\r\n                    targetFile.exists())\r\n                    ) {\r\n\r\n                String mimeType = \"text/html\";\r\n                int statusCode = 200;\r\n\r\n                ProcessBuilder pb;\r\n\r\n                pb = new ProcessBuilder(targetFile.getAbsolutePath());\r\n\r\n                String fileSeparator = System.getProperty(\"file.separator\", \"/\");\r\n\r\n                // set environment variables\r\n                Map<String, String> env = pb.environment();\r\n                env.put(\"SERVER_SOFTWARE\", getDefaultHeaders(path).get(httpResponseHeader.SERVER));\r\n                env.put(\"SERVER_NAME\", switchboard.getConfig(\"peerName\", \"<nameless>\"));\r\n                env.put(\"GATEWAY_INTERFACE\", \"CGI/1.1\");\r\n                if (httpVersion != null) {\r\n                    env.put(\"SERVER_PROTOCOL\", httpVersion);\r\n                }\r\n                env.put(\"SERVER_PORT\", switchboard.getConfig(\"port\", \"8080\"));\r\n                env.put(\"REQUEST_METHOD\", method);\r\n//                env.put(\"PATH_INFO\", \"\");         // TODO: implement\r\n//                env.put(\"PATH_TRANSLATED\", \"\");   // TODO: implement\r\n                env.put(\"SCRIPT_NAME\", path);\r\n                if (argsString != null) {\r\n                    env.put(\"QUERY_STRING\", argsString);\r\n                }\r\n                env.put(\"REMOTE_HOST\", InetAddress.getByName(clientIP).getHostName());\r\n                env.put(\"REMOTE_ADDR\", clientIP);\r\n//                env.put(\"AUTH_TYPE\", \"\");         // TODO: implement\r\n//                env.put(\"REMOTE_USER\", \"\");       // TODO: implement\r\n//                env.put(\"REMOTE_IDENT\", \"\");      // I don't think we need this\r\n                env.put(\"DOCUMENT_ROOT\", switchboard.getRootPath().getAbsolutePath() + fileSeparator + switchboard.getConfig(\"htDocsPath\", \"DATA/HTDOCS\"));\r\n                if (requestHeader.getContentType() != null) {\r\n                    env.put(\"CONTENT_TYPE\", requestHeader.getContentType());\r\n                }\r\n                if (method.equalsIgnoreCase(httpHeader.METHOD_POST) && body != null) {\r\n                    env.put(\"CONTENT_LENGTH\", requestHeader.getContentLength() + \"\");\r\n                }\r\n\r\n                // add values from request header to environment (see: http://hoohoo.ncsa.uiuc.edu/cgi/env.html#headers)\r\n                Set<String> requestHeaderKeys = requestHeader.keySet();\r\n                for (String requestHeaderKey : requestHeaderKeys) {\r\n                    env.put(\"HTTP_\" + requestHeaderKey.toUpperCase().replace(\"-\", \"_\"), requestHeader.get(requestHeaderKey));\r\n                }\r\n\r\n                int exitValue = 0;\r\n                String cgiBody = null;\r\n\r\n                try {\r\n                    // start execution of script\r\n                    Process p = pb.start();\r\n\r\n                    OutputStream os = new BufferedOutputStream(p.getOutputStream());\r\n\r\n                    if (method.equalsIgnoreCase(httpHeader.METHOD_POST) && body != null) {\r\n                        byte[] buffer = new byte[1024];\r\n                        int len = requestHeader.getContentLength();\r\n                        while (len > 0) {\r\n                            body.read(buffer);\r\n                            len = len - buffer.length;\r\n                            os.write(buffer);\r\n                        }\r\n                    }\r\n\r\n                    os.close();\r\n\r\n                    try {\r\n                        p.waitFor();\r\n                    } catch (InterruptedException ex) {\r\n\r\n                    }\r\n\r\n                    exitValue = p.exitValue();\r\n\r\n                    InputStream is = new BufferedInputStream(p.getInputStream());\r\n\r\n                    StringBuilder stringBuffer = new StringBuilder(1024);\r\n\r\n                    while (is.available() > 0) {\r\n                        stringBuffer.append((char) is.read());\r\n                    }\r\n\r\n                    String cgiReturn = stringBuffer.toString();\r\n                    int indexOfDelimiter = cgiReturn.indexOf(\"\\n\\n\");\r\n                    String[] cgiHeader = new String[0];\r\n                    if (indexOfDelimiter > -1) {\r\n                        cgiHeader = cgiReturn.substring(0, indexOfDelimiter).split(\"\\n\");\r\n                    }\r\n                    cgiBody = cgiReturn.substring(indexOfDelimiter + 1);\r\n\r\n                    String key;\r\n                    String value;\r\n                    for (int i = 0; i < cgiHeader.length; i++) {\r\n                        indexOfDelimiter = cgiHeader[i].indexOf(\":\");\r\n                        key = cgiHeader[i].substring(0, indexOfDelimiter).trim();\r\n                        value = cgiHeader[i].substring(indexOfDelimiter + 1).trim();\r\n                        conProp.setProperty(key, value);\r\n                        if (key.equals(\"Cache-Control\") && value.equals(\"no-cache\")) {\r\n                            nocache = true;\r\n                        } else if (key.equals(\"Content-type\")) {\r\n                            mimeType = value;\r\n                        } else if (key.equals(\"Status\")) {\r\n                            if (key.length() > 2) {\r\n                                try {\r\n                                    statusCode = Integer.parseInt(value.substring(0, 3));\r\n                                } catch (NumberFormatException ex) {\r\n                                    /* tough luck, we will just have to use 200 as default value */\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                } catch (IOException ex) {\r\n                    exitValue = -1;\r\n                }\r\n\r\n                /* did the script return an exit value != 0 and still there is supposed to be\r\n                 * everything right with the HTTP status? -> change status to 500 since 200 would\r\n                 * be a lie\r\n                 */\r\n                if (exitValue != 0 && statusCode == 200) {\r\n                    statusCode = 500;\r\n                }\r\n\r\n                targetDate = new Date(System.currentTimeMillis());\r\n\r\n                if (exitValue == 0 || (cgiBody != null && !cgiBody.equals(\"\"))) {\r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, statusCode, null, mimeType, cgiBody.length(), targetDate, null, null, null, null, nocache);\r\n                    out.write(cgiBody.getBytes());\r\n                } else {\r\n                    httpd.sendRespondError(conProp, out, exitValue, statusCode, null, httpHeader.http1_1.get(statusCode + \"\"), null);\r\n                }\r\n                \r\n\r\n            } else if ((targetClass != null) && (path.endsWith(\".stream\"))) {\r\n                // call rewrite-class\r\n                requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                //requestHeader.put(httpHeader.CONNECTION_PROP_INPUTSTREAM, body);\r\n                //requestHeader.put(httpHeader.CONNECTION_PROP_OUTPUTSTREAM, out);\r\n             \r\n                httpd.sendRespondHeader(conProp, out, httpVersion, 200, null);                \r\n                \r\n                // in case that there are no args given, args = null or empty hashmap\r\n                /* servletProperties tp = (servlerObjects) */ invokeServlet(targetClass, requestHeader, args);\r\n                forceConnectionClose(conProp);\r\n                return;                \r\n            } else if ((targetFile.exists()) && (targetFile.canRead())) {\r\n                // we have found a file that can be written to the client\r\n                // if this file uses templates, then we use the template\r\n                // re-write - method to create an result\r\n                String mimeType = mimeTable.getProperty(targetExt,\"text/html\");\r\n                final boolean zipContent = requestHeader.acceptGzip() && httpd.shallTransportZipped(\".\" + conProp.getProperty(\"EXT\",\"\"));\r\n                if (path.endsWith(\"html\") || \r\n                        path.endsWith(\"htm\") || \r\n                        path.endsWith(\"xml\") || \r\n                        path.endsWith(\"json\") || \r\n                        path.endsWith(\"rdf\") || \r\n                        path.endsWith(\"rss\") || \r\n                        path.endsWith(\"csv\") ||\r\n                        path.endsWith(\"pac\") ||\r\n                        path.endsWith(\"src\") ||\r\n                        path.endsWith(\"vcf\") ||\r\n                        path.endsWith(\"/\") ||\r\n                        path.equals(\"/robots.txt\")) {\r\n                            \r\n                    /*targetFile = getLocalizedFile(path);\r\n\t\t\t\t\tif (!(targetFile.exists())) {\r\n\t\t                // try to find that file in the htDocsPath\r\n\t\t\t\t        File trialFile = new File(htDocsPath, path);\r\n\t\t\t\t\t\tif (trialFile.exists()) targetFile = trialFile;\r\n\t\t            }*/\r\n            \r\n                    \r\n                    // call rewrite-class\r\n                   \r\n                    if (targetClass == null) {\r\n                        targetDate = new Date(targetFile.lastModified());\r\n                    } else {\r\n                        // CGI-class: call the class to create a property for rewriting\r\n                        try {\r\n                            requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                            requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                            // in case that there are no args given, args = null or empty hashmap\r\n                            final Object tmp = invokeServlet(targetClass, requestHeader, args);\r\n                            if (tmp == null) {\r\n                                // if no args given, then tp will be an empty Hashtable object (not null)\r\n                                templatePatterns = new servletProperties();\r\n                            } else if (tmp instanceof servletProperties) {\r\n                                templatePatterns = (servletProperties) tmp;\r\n                            } else {\r\n                                templatePatterns = new servletProperties((serverObjects) tmp);\r\n                            }\r\n                            // check if the servlets requests authentification\r\n                            if (templatePatterns.containsKey(servletProperties.ACTION_AUTHENTICATE)) {\r\n                                // handle brute-force protection\r\n                                if (authorization != null) {\r\n                                    serverLog.logInfo(\"HTTPD\", \"dynamic log-in for account 'admin' in http file handler for path '\" + path + \"' from host '\" + clientIP + \"'\");\r\n                                    final Integer attempts = serverCore.bfHost.get(clientIP);\r\n                                    if (attempts == null)\r\n                                        serverCore.bfHost.put(clientIP, Integer.valueOf(1));\r\n                                    else\r\n                                        serverCore.bfHost.put(clientIP, Integer.valueOf(attempts.intValue() + 1));\r\n                                }\r\n                                // send authentication request to browser\r\n                                final httpResponseHeader headers = getDefaultHeaders(path);\r\n                                headers.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"\" + templatePatterns.get(servletProperties.ACTION_AUTHENTICATE, \"\") + \"\\\"\");\r\n                                httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                                return;\r\n                            } else if (templatePatterns.containsKey(servletProperties.ACTION_LOCATION)) {\r\n                                String location = templatePatterns.get(servletProperties.ACTION_LOCATION, \"\");\r\n                                if (location.length() == 0) location = path;\r\n                                \r\n                                final httpResponseHeader headers = getDefaultHeaders(path);\r\n                                headers.setCookieVector(templatePatterns.getOutgoingHeader().getCookieVector()); //put the cookies into the new header TODO: can we put all headerlines, without trouble?\r\n                                headers.put(httpHeader.LOCATION,location);\r\n                                httpd.sendRespondHeader(conProp,out,httpVersion,302,headers);\r\n                                return;\r\n                            }\r\n                            // add the application version, the uptime and the client name to every rewrite table\r\n                            templatePatterns.put(servletProperties.PEER_STAT_VERSION, switchboard.getConfig(\"version\", \"\"));\r\n                            templatePatterns.put(servletProperties.PEER_STAT_UPTIME, ((System.currentTimeMillis() -  serverCore.startupTime) / 1000) / 60); // uptime in minutes\r\n                            templatePatterns.putHTML(servletProperties.PEER_STAT_CLIENTNAME, switchboard.getConfig(\"peerName\", \"anomic\"));\r\n                            templatePatterns.put(servletProperties.PEER_STAT_MYTIME, serverDate.formatShortSecond());\r\n                            //System.out.println(\"respond props: \" + ((tp == null) ? \"null\" : tp.toString())); // debug\r\n                        } catch (final InvocationTargetException e) {\r\n                            if (e.getCause() instanceof InterruptedException) {\r\n                                throw new InterruptedException(e.getCause().getMessage());\r\n                            }                            \r\n                            \r\n                            theLogger.logSevere(\"INTERNAL ERROR: \" + e.toString() + \":\" +\r\n                                    e.getMessage() +\r\n                                    \" target exception at \" + targetClass + \": \" +\r\n                                    e.getTargetException().toString() + \":\" +\r\n                                    e.getTargetException().getMessage(),e);\r\n                            targetClass = null;\r\n                            throw e;\r\n                        }\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                    }\r\n                    \r\n                    // rewrite the file\r\n                    InputStream fis = null;\r\n                    \r\n                    // read the file/template\r\n                    TemplateCacheEntry templateCacheEntry = null;\r\n                    if (useTemplateCache) {\r\n                        final long fileSize = targetFile.length();\r\n                        if (fileSize <= 512 * 1024) {\r\n                            // read from cache\r\n                            SoftReference<TemplateCacheEntry> ref = templateCache.get(targetFile);\r\n                            if (ref != null) {\r\n                                templateCacheEntry = ref.get();\r\n                                if (templateCacheEntry == null) templateCache.remove(targetFile);\r\n                            }\r\n\r\n                            Date targetFileDate = new Date(targetFile.lastModified());\r\n                            if (templateCacheEntry == null || targetFileDate.after(templateCacheEntry.lastModified)) {\r\n                                // loading the content of the template file into\r\n                                // a byte array\r\n                        \ttemplateCacheEntry = new TemplateCacheEntry();\r\n                                templateCacheEntry.lastModified = targetFileDate;\r\n                                templateCacheEntry.content = serverFileUtils.read(targetFile);\r\n\r\n                                // storing the content into the cache\r\n                                ref = new SoftReference<TemplateCacheEntry>(templateCacheEntry);\r\n                                templateCache.put(targetFile, ref);\r\n                                if (theLogger.isFinest()) theLogger.logFinest(\"Cache MISS for file \" + targetFile);\r\n                            } else {\r\n                                if (theLogger.isFinest()) theLogger.logFinest(\"Cache HIT for file \" + targetFile);\r\n                            }\r\n\r\n                            // creating an inputstream needed by the template\r\n                            // rewrite function\r\n                            fis = new ByteArrayInputStream(templateCacheEntry.content);\r\n                            templateCacheEntry = null;\r\n                        } else {\r\n                            // read from file directly\r\n                            fis = new BufferedInputStream(new FileInputStream(targetFile));\r\n                        }\r\n                    } else {\r\n                        fis = new BufferedInputStream(new FileInputStream(targetFile));\r\n                    }\r\n                    \r\n                    if(mimeType.startsWith(\"text\")) {\r\n                    \t// every text-file distributed by yacy is UTF-8\r\n                    \tif(!path.startsWith(\"/repository\")) {\r\n                    \t\tmimeType = mimeType + \"; charset=UTF-8\";\r\n                    \t} else {\r\n                    \t\t// detect charset of html-files\r\n                    \t\tif((path.endsWith(\"html\") || path.endsWith(\"htm\"))) {\r\n                    \t\t\t// save position\r\n                    \t\t\tfis.mark(1000);\r\n                    \t\t\t// scrape document to look up charset\r\n                    \t\t\tfinal htmlFilterInputStream htmlFilter = new htmlFilterInputStream(fis,\"UTF-8\",new yacyURL(\"http://localhost\", null),null,false);\r\n                    \t\t\tfinal String charset = plasmaParser.patchCharsetEncoding(htmlFilter.detectCharset());\r\n                    \t\t\tif(charset != null)\r\n                    \t\t\t\tmimeType = mimeType + \"; charset=\"+charset;\r\n                    \t\t\t// reset position\r\n                    \t\t\tfis.reset();\r\n                    \t\t}\r\n                    \t}\r\n                \t}\r\n\r\n                    // write the array to the client\r\n                    // we can do that either in standard mode (whole thing completely) or in chunked mode\r\n                    // since yacy clients do not understand chunked mode (yet), we use this only for communication with the administrator\r\n                    final boolean yacyClient = requestHeader.userAgent().startsWith(\"yacy\");\r\n                    final boolean chunked = !method.equals(httpHeader.METHOD_HEAD) && !yacyClient && httpVersion.equals(httpHeader.HTTP_VERSION_1_1);\r\n                    if (chunked) {\r\n                        // send page in chunks and parse SSIs\r\n                        final serverByteBuffer o = new serverByteBuffer();\r\n                        // apply templates\r\n                        httpTemplate.writeTemplate(fis, o, templatePatterns, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, -1, targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(), null, \"chunked\", nocache);\r\n                        // send the content in chunked parts, see RFC 2616 section 3.6.1\r\n                        final httpChunkedOutputStream chos = new httpChunkedOutputStream(out);\r\n                        httpSSI.writeSSI(o, chos, authorization, clientIP);\r\n                        //chos.write(result);\r\n                        chos.finish();\r\n                    } else {\r\n                        // send page as whole thing, SSIs are not possible\r\n                        final String contentEncoding = (zipContent) ? \"gzip\" : null;\r\n                        // apply templates\r\n                        final serverByteBuffer o1 = new serverByteBuffer();\r\n                        httpTemplate.writeTemplate(fis, o1, templatePatterns, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        \r\n                        final serverByteBuffer o = new serverByteBuffer();\r\n                        \r\n                        if (zipContent) {\r\n                            GZIPOutputStream zippedOut = new GZIPOutputStream(o);\r\n                            httpSSI.writeSSI(o1, zippedOut, authorization, clientIP);\r\n                            //httpTemplate.writeTemplate(fis, zippedOut, tp, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                            zippedOut.finish();\r\n                            zippedOut.flush();\r\n                            zippedOut.close();\r\n                            zippedOut = null;\r\n                        } else {\r\n                            httpSSI.writeSSI(o1, o, authorization, clientIP);\r\n                            //httpTemplate.writeTemplate(fis, o, tp, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        }\r\n                        if (method.equals(httpHeader.METHOD_HEAD)) {\r\n                            httpd.sendRespondHeader(conProp, out,\r\n                                    httpVersion, 200, null, mimeType, o.length(),\r\n                                    targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(),\r\n                                    contentEncoding, null, nocache);\r\n                        } else {\r\n                            final byte[] result = o.getBytes(); // this interrupts streaming (bad idea!)\r\n                            httpd.sendRespondHeader(conProp, out,\r\n                                    httpVersion, 200, null, mimeType, result.length,\r\n                                    targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(),\r\n                                    contentEncoding, null, nocache);\r\n                            serverFileUtils.copy(result, out);\r\n                        }  \r\n                    }\r\n                } else { // no html\r\n                    \r\n                    int statusCode = 200;\r\n                    int rangeStartOffset = 0;\r\n                    httpResponseHeader header = new httpResponseHeader();\r\n                    \r\n                    // adding the accept ranges header\r\n                    header.put(httpHeader.ACCEPT_RANGES, \"bytes\");\r\n                    \r\n                    // reading the files md5 hash if availabe and use it as ETAG of the resource\r\n                    String targetMD5 = null;\r\n                    final File targetMd5File = new File(targetFile + \".md5\");\r\n                    try {\r\n                        if (targetMd5File.exists()) {\r\n                            //String description = null;\r\n                            targetMD5 = new String(serverFileUtils.read(targetMd5File));\r\n                            int pos = targetMD5.indexOf('\\n');\r\n                            if (pos >= 0) {\r\n                                //description = targetMD5.substring(pos + 1);\r\n                                targetMD5 = targetMD5.substring(0, pos);\r\n                            }\r\n\r\n                            // using the checksum as ETAG header\r\n                            header.put(httpHeader.ETAG, targetMD5);\r\n                        }\r\n                    } catch (final IOException e) {\r\n                        e.printStackTrace();\r\n                    }                        \r\n                    \r\n                    if (requestHeader.containsKey(httpHeader.RANGE)) {\r\n                        final Object ifRange = requestHeader.ifRange();\r\n                        if ((ifRange == null)||\r\n                            (ifRange instanceof Date && targetFile.lastModified() == ((Date)ifRange).getTime()) ||\r\n                            (ifRange instanceof String && ifRange.equals(targetMD5))) {\r\n                            final String rangeHeaderVal = requestHeader.get(httpHeader.RANGE).trim();\r\n                            if (rangeHeaderVal.startsWith(\"bytes=\")) {\r\n                                final String rangesVal = rangeHeaderVal.substring(\"bytes=\".length());\r\n                                final String[] ranges = rangesVal.split(\",\");\r\n                                if ((ranges.length == 1)&&(ranges[0].endsWith(\"-\"))) {\r\n                                    rangeStartOffset = Integer.valueOf(ranges[0].substring(0,ranges[0].length()-1)).intValue();\r\n                                    statusCode = 206;\r\n                                    if (header == null) header = new httpResponseHeader();\r\n                                    header.put(httpHeader.CONTENT_RANGE, \"bytes \" + rangeStartOffset + \"-\" + (targetFile.length()-1) + \"/\" + targetFile.length());\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                    \r\n                    // write the file to the client\r\n                    targetDate = new Date(targetFile.lastModified());\r\n                    final long   contentLength    = (zipContent)?-1:targetFile.length()-rangeStartOffset;\r\n                    final String contentEncoding  = (zipContent)?\"gzip\":null;\r\n                    final String transferEncoding = (!httpVersion.equals(httpHeader.HTTP_VERSION_1_1))?null:(zipContent)?\"chunked\":null;\r\n                    if (!httpVersion.equals(httpHeader.HTTP_VERSION_1_1) && zipContent) forceConnectionClose(conProp);\r\n                    \r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, statusCode, null, mimeType, contentLength, targetDate, null, header, contentEncoding, transferEncoding, nocache);\r\n                \r\n                    if (!method.equals(httpHeader.METHOD_HEAD)) {                        \r\n                        httpChunkedOutputStream chunkedOut = null;\r\n                        GZIPOutputStream zipped = null;\r\n                        OutputStream newOut = out;\r\n                        \r\n                        if (transferEncoding != null) {\r\n                            chunkedOut = new httpChunkedOutputStream(newOut);\r\n                            newOut = chunkedOut;\r\n                        }\r\n                        if (contentEncoding != null) {\r\n                            zipped = new GZIPOutputStream(newOut);\r\n                            newOut = zipped;\r\n                        }\r\n                        \r\n                        serverFileUtils.copyRange(targetFile, newOut, rangeStartOffset);\r\n                        \r\n                        if (zipped != null) {\r\n                            zipped.flush();\r\n                            zipped.finish();\r\n                        }\r\n                        if (chunkedOut != null) {\r\n                            chunkedOut.finish();\r\n                        }\r\n\r\n                        // flush all\r\n                        try {newOut.flush();}catch (final Exception e) {}\r\n                        \r\n                        // wait a little time until everything closes so that clients can read from the streams/sockets\r\n                        if ((contentLength >= 0) && ((String)requestHeader.get(httpRequestHeader.CONNECTION, \"close\")).indexOf(\"keep-alive\") == -1) {\r\n                            // in case that the client knows the size in advance (contentLength present) the waiting will have no effect on the interface performance\r\n                            // but if the client waits on a connection interruption this will slow down.\r\n                            try {Thread.sleep(2000);} catch (final InterruptedException e) {} // FIXME: is this necessary?\r\n                        }\r\n                    }\r\n                    \r\n                    // check mime type again using the result array: these are 'magics'\r\n//                    if (serverByteBuffer.equals(result, 1, \"PNG\".getBytes())) mimeType = mimeTable.getProperty(\"png\",\"text/html\");\r\n//                    else if (serverByteBuffer.equals(result, 0, \"GIF89\".getBytes())) mimeType = mimeTable.getProperty(\"gif\",\"text/html\");\r\n//                    else if (serverByteBuffer.equals(result, 6, \"JFIF\".getBytes())) mimeType = mimeTable.getProperty(\"jpg\",\"text/html\");\r\n                    //System.out.print(\"MAGIC:\"); for (int i = 0; i < 10; i++) System.out.print(Integer.toHexString((int) result[i]) + \",\"); System.out.println();\r\n                }\r\n            } else {\r\n                httpd.sendRespondError(conProp,out,3,404,\"File not Found\",null,null);\r\n                return;\r\n            }\r\n        } catch (final Exception e) {     \r\n            try {\r\n                // doing some errorhandling ...\r\n                int httpStatusCode = 400; \r\n                final String httpStatusText = null; \r\n                final StringBuilder errorMessage = new StringBuilder(2000); \r\n                Exception errorExc = null;            \r\n                \r\n                final String errorMsg = e.getMessage();\r\n                if (\r\n                        (e instanceof InterruptedException) ||\r\n                        ((errorMsg != null) && (errorMsg.startsWith(\"Socket closed\")) && (Thread.currentThread().isInterrupted()))\r\n                   ) {\r\n                    errorMessage.append(\"Interruption detected while processing query.\");\r\n                    httpStatusCode = 503;\r\n                } else {\r\n                    if ((errorMsg != null) && \r\n                        (\r\n                           errorMsg.contains(\"broken pipe\") || \r\n                           errorMsg.contains(\"Connection reset\") ||\r\n                           errorMsg.contains(\"Software caused connection abort\")                           \r\n                       )) {\r\n                        // client closed the connection, so we just end silently\r\n                        errorMessage.append(\"Client unexpectedly closed connection while processing query.\");\r\n                    } else if ((errorMsg != null) && (errorMsg.startsWith(\"Connection timed out\"))) {\r\n                        errorMessage.append(\"Connection timed out.\");\r\n                    } else {\r\n                        errorMessage.append(\"Unexpected error while processing query.\");\r\n                        httpStatusCode = 500;\r\n                        errorExc = e;\r\n                    }\r\n                }\r\n                \r\n                errorMessage.append(\"\\nSession: \").append(Thread.currentThread().getName())\r\n                            .append(\"\\nQuery:   \").append(path)\r\n                            .append(\"\\nClient:  \").append(conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP,\"unknown\")) \r\n                            .append(\"\\nReason:  \").append(e.toString());    \r\n                \r\n                if (!conProp.containsKey(httpHeader.CONNECTION_PROP_PROXY_RESPOND_HEADER)) {\r\n                    // sending back an error message to the client \r\n                    // if we have not already send an http header\r\n                    httpd.sendRespondError(conProp,out, 4, httpStatusCode, httpStatusText, new String(errorMessage),errorExc);\r\n                } else {\r\n                    // otherwise we close the connection\r\n                    forceConnectionClose(conProp);\r\n                }    \r\n                \r\n                // if it is an unexpected error we log it \r\n                if (httpStatusCode == 500) {\r\n                    theLogger.logWarning(new String(errorMessage),e);\r\n                }\r\n                \r\n            } catch (final Exception ee) {\r\n                forceConnectionClose(conProp);\r\n            }            \r\n            \r\n        } finally {\r\n            try {out.flush();}catch (final Exception e) {}\r\n        }\r\n    }","id":36060,"modified_method":"public static void doResponse(final Properties conProp, final httpRequestHeader requestHeader, final OutputStream out, final InputStream body) {\r\n  \r\n        String path = null;\r\n        try {\r\n            // getting some connection properties            \r\n            final String method = conProp.getProperty(httpHeader.CONNECTION_PROP_METHOD);\r\n            path = conProp.getProperty(httpHeader.CONNECTION_PROP_PATH);\r\n            String argsString = conProp.getProperty(httpHeader.CONNECTION_PROP_ARGS); // is null if no args were given\r\n            final String httpVersion = conProp.getProperty(httpHeader.CONNECTION_PROP_HTTP_VER);\r\n            final String clientIP = conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP, \"unknown-host\");\r\n            \r\n            // check hack attacks in path\r\n            if (path.indexOf(\"..\") >= 0) {\r\n                httpd.sendRespondError(conProp,out,4,403,null,\"Access not allowed\",null);\r\n                return;\r\n            }\r\n            \r\n            // url decoding of path\r\n            try {\r\n                path = URLDecoder.decode(path, \"UTF-8\");\r\n            } catch (final UnsupportedEncodingException e) {\r\n                // This should never occur\r\n                assert(false) : \"UnsupportedEncodingException: \" + e.getMessage();\r\n            }\r\n            \r\n            // check against hack attacks in path\r\n            if (path.indexOf(\"..\") >= 0) {\r\n                httpd.sendRespondError(conProp,out,4,403,null,\"Access not allowed\",null);\r\n                return;\r\n            }\r\n            \r\n            // check permission/granted access\r\n            String authorization = requestHeader.get(httpRequestHeader.AUTHORIZATION);\r\n            if (authorization != null && authorization.length() == 0) authorization = null;\r\n            final String adminAccountBase64MD5 = switchboard.getConfig(httpd.ADMIN_ACCOUNT_B64MD5, \"\");\r\n            \r\n            // a bad patch to map the /xml/ path to /api/\r\n            if (path.startsWith(\"/xml/\")) {\r\n                path = \"/api/\" + path.substring(5);\r\n            }\r\n\r\n            final boolean adminAccountForLocalhost = sb.getConfigBool(\"adminAccountForLocalhost\", false);\r\n            final String refererHost = requestHeader.refererHost();\r\n            final boolean accessFromLocalhost = serverCore.isLocalhost(clientIP) && (refererHost.length() == 0 || serverCore.isLocalhost(refererHost));\r\n            final boolean grantedForLocalhost = adminAccountForLocalhost && accessFromLocalhost;\r\n            final boolean protectedPage = path.indexOf(\"_p.\") > 0;\r\n            final boolean accountEmpty = adminAccountBase64MD5.length() == 0;\r\n            \r\n            if (!grantedForLocalhost && protectedPage && !accountEmpty) {\r\n                // authentication required\r\n                if (authorization == null) {\r\n                    // no authorization given in response. Ask for that\r\n                    final httpResponseHeader responseHeader = getDefaultHeaders(path);\r\n                    responseHeader.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"admin log-in\\\"\");\r\n                    //httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                    final servletProperties tp=new servletProperties();\r\n                    tp.put(\"returnto\", path);\r\n                    //TODO: separate error page Wrong Login / No Login\r\n                    httpd.sendRespondError(conProp, out, 5, 401, \"Wrong Authentication\", \"\", new File(\"proxymsg/authfail.inc\"), tp, null, responseHeader);\r\n                    return;\r\n                } else if (\r\n                    (httpd.staticAdminAuthenticated(authorization.trim().substring(6), switchboard) == 4) ||\r\n                    (sb.userDB.hasAdminRight(authorization, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP), requestHeader.getHeaderCookies()))) {\r\n                    //Authentication successful. remove brute-force flag\r\n                    serverCore.bfHost.remove(conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                } else {\r\n                    // a wrong authentication was given or the userDB user does not have admin access. Ask again\r\n                    serverLog.logInfo(\"HTTPD\", \"Wrong log-in for account 'admin' in http file handler for path '\" + path + \"' from host '\" + clientIP + \"'\");\r\n                    final Integer attempts = serverCore.bfHost.get(clientIP);\r\n                    if (attempts == null)\r\n                        serverCore.bfHost.put(clientIP, Integer.valueOf(1));\r\n                    else\r\n                        serverCore.bfHost.put(clientIP, Integer.valueOf(attempts.intValue() + 1));\r\n    \r\n                    final httpResponseHeader headers = getDefaultHeaders(path);\r\n                    headers.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"admin log-in\\\"\");\r\n                    httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                    return;\r\n                }\r\n            }\r\n        \r\n            // parse arguments\r\n            serverObjects args = new serverObjects();\r\n            int argc = 0;\r\n            if (argsString == null) {\r\n                // no args here, maybe a POST with multipart extension\r\n                int length = requestHeader.getContentLength();\r\n                //System.out.println(\"HEADER: \" + requestHeader.toString()); // DEBUG\r\n\r\n                /* don't parse body in case of a POST CGI call since it has to be\r\n                 * handed over to the CGI script unaltered and parsed by the script\r\n                 */\r\n                if (method.equals(httpHeader.METHOD_POST) &&\r\n                        !(switchboard.getConfigBool(\"cgi.allow\", false) &&\r\n                        httpdFileHandler.matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null)))\r\n                        ) {\r\n\r\n                    // if its a POST, it can be either multipart or as args in the body\r\n                    if ((requestHeader.containsKey(httpHeader.CONTENT_TYPE)) &&\r\n                            (requestHeader.get(httpHeader.CONTENT_TYPE).toLowerCase().startsWith(\"multipart\"))) {\r\n                        // parse multipart\r\n                        final HashMap<String, byte[]> files = httpd.parseMultipart(requestHeader, args, body);\r\n                        // integrate these files into the args\r\n                        if (files != null) {\r\n                            final Iterator<Map.Entry<String, byte[]>> fit = files.entrySet().iterator();\r\n                            Map.Entry<String, byte[]> entry;\r\n                            while (fit.hasNext()) {\r\n                                entry = fit.next();\r\n                                args.put(entry.getKey() + \"$file\", entry.getValue());\r\n                            }\r\n                        }\r\n                        argc = Integer.parseInt(requestHeader.get(\"ARGC\"));\r\n                    } else {\r\n                        // parse args in body\r\n                        argc = httpd.parseArgs(args, body, length);\r\n                    }\r\n                } else {\r\n                    // no args\r\n                    argsString = null;\r\n                    args = null;\r\n                    argc = 0;\r\n                }\r\n            } else {\r\n                // simple args in URL (stuff after the \"?\")\r\n                argc = httpd.parseArgs(args, argsString);\r\n            }\r\n        \r\n            // check for cross site scripting - attacks in request arguments\r\n            if (args != null && argc > 0) {\r\n                // check all values for occurrences of script values\r\n                final Iterator<String> e = args.values().iterator(); // enumeration of values\r\n                String val;\r\n                while (e.hasNext()) {\r\n                    val = e.next();\r\n                    if ((val != null) && (val.indexOf(\"<script\") >= 0)) {\r\n                        // deny request\r\n                        httpd.sendRespondError(conProp,out,4,403,null,\"bad post values\",null);\r\n                        return;\r\n                    }\r\n                }\r\n            }\r\n        \r\n            // we are finished with parsing\r\n            // the result of value hand-over is in args and argc\r\n            if (path.length() == 0) {\r\n                httpd.sendRespondError(conProp,out,4,400,null,\"Bad Request\",null);\r\n                out.flush();\r\n                return;\r\n            }\r\n            File targetClass=null;\r\n\r\n            // locate the file\r\n            if (!path.startsWith(\"/\") && !path.startsWith(\"\\\\\")) path = \"/\" + path; // attach leading slash\r\n            \r\n            // a different language can be desired (by i.e. ConfigBasic.html) than the one stored in the locale.language\r\n            String localeSelection = switchboard.getConfig(\"locale.language\",\"default\");\r\n            if (args != null && (args.containsKey(\"language\"))) {\r\n                // TODO 9.11.06 Bost: a class with information about available languages is needed. \r\n                // the indexOf(\".\") is just a workaround because there from ConfigLanguage.html commes \"de.lng\" and\r\n                // from ConfigBasic.html comes just \"de\" in the \"language\" parameter\r\n                localeSelection = args.get(\"language\", localeSelection);\r\n                if (localeSelection.indexOf(\".\") != -1)\r\n                    localeSelection = localeSelection.substring(0, localeSelection.indexOf(\".\"));\r\n            }\r\n            \r\n            File targetFile = getLocalizedFile(path, localeSelection);\r\n            final String targetExt = conProp.getProperty(\"EXT\",\"\");\r\n            targetClass = rewriteClassFile(new File(htDefaultPath, path));\r\n            if (path.endsWith(\"/\") || path.endsWith(\"\\\\\")) {\r\n                String testpath;\r\n                // attach default file name\r\n                for (int i = 0; i < defaultFiles.length; i++) {\r\n                    testpath = path + defaultFiles[i];\r\n                    targetFile = getOverlayedFile(testpath);\r\n                    targetClass = getOverlayedClass(testpath);\r\n                    if (targetFile.exists()) {\r\n                        path = testpath;\r\n                        break;\r\n                    }\r\n                }\r\n                targetFile = getLocalizedFile(path, localeSelection);\r\n                \r\n                //no defaultfile, send a dirlisting\r\n                if (targetFile == null || !targetFile.exists() || (targetFile.exists() && targetFile.isDirectory())) {\r\n                    final StringBuilder aBuffer = new StringBuilder();\r\n                    aBuffer.append(\"<html>\\n<head>\\n<\/head>\\n<body>\\n<h1>Index of \" + path + \"<\/h1>\\n  <ul>\\n\");\r\n                    String[] list = targetFile.list();\r\n                    if (list == null) list = new String[0]; // should not occur!\r\n                    File f;\r\n                    String size;\r\n                    long sz;\r\n                    String headline, author, description;\r\n                    int images, links;\r\n                    htmlFilterContentScraper scraper;\r\n                    for (int i = 0; i < list.length; i++) {\r\n                        f = new File(targetFile, list[i]);\r\n                        if (f.isDirectory()) {\r\n                            aBuffer.append(\"    <li><a href=\\\"\" + path + list[i] + \"/\\\">\" + list[i] + \"/<\/a><br><\/li>\\n\");\r\n                        } else {\r\n                            if (list[i].endsWith(\"html\") || (list[i].endsWith(\"htm\"))) {\r\n                                scraper = htmlFilterContentScraper.parseResource(f);\r\n                                headline = scraper.getTitle();\r\n                                author = scraper.getAuthor();\r\n                                description = scraper.getDescription();\r\n                                images = scraper.getImages().size();\r\n                                links = scraper.getAnchors().size();\r\n                            } else {\r\n                                headline = null;\r\n                                author = null;\r\n                                description = null;\r\n                                images = 0;\r\n                                links = 0;\r\n                            }\r\n                            sz = f.length();\r\n                            if (sz < 1024) {\r\n                                size = sz + \" bytes\";\r\n                            } else if (sz < 1024 * 1024) {\r\n                                size = (sz / 1024) + \" KB\";\r\n                            } else {\r\n                                size = (sz / 1024 / 1024) + \" MB\";\r\n                            }\r\n                            aBuffer.append(\"    <li>\");\r\n                            if ((headline != null) && (headline.length() > 0)) aBuffer.append(\"<a href=\\\"\" + list[i] + \"\\\"><b>\" + headline + \"<\/b><\/a><br>\");\r\n                            aBuffer.append(\"<a href=\\\"\" + path + list[i] + \"\\\">\" + list[i] + \"<\/a><br>\");\r\n                            if ((author != null) && (author.length() > 0)) aBuffer.append(\"Author: \" + author + \"<br>\");\r\n                            if ((description != null) && (description.length() > 0)) aBuffer.append(\"Description: \" + description + \"<br>\");\r\n                            aBuffer.append(serverDate.formatShortDay(new Date(f.lastModified())) + \", \" + size + ((images > 0) ? \", \" + images + \" images\" : \"\") + ((links > 0) ? \", \" + links + \" links\" : \"\") + \"<br><\/li>\\n\");\r\n                        }\r\n                    }\r\n                    aBuffer.append(\"  <\/ul>\\n<\/body>\\n<\/html>\\n\");\r\n\r\n                    // write the list to the client\r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, \"text/html; charset=UTF-8\", aBuffer.length(), new Date(targetFile.lastModified()), null, new httpResponseHeader(), null, null, true);\r\n                    if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        out.write(aBuffer.toString().getBytes(\"UTF-8\"));\r\n                    }\r\n                    return;\r\n                }\r\n            } else {\r\n                    //XXX: you cannot share a .png/.gif file with a name like a class in htroot.\r\n                    if ( !(targetFile.exists()) &&\r\n                            !((path.endsWith(\"png\")||path.endsWith(\"gif\") ||\r\n                            matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null)) ||\r\n                            path.endsWith(\".stream\")) &&\r\n                            targetClass!=null ) ){\r\n                        targetFile = new File(htDocsPath, path);\r\n                        targetClass = rewriteClassFile(new File(htDocsPath, path));\r\n                    }\r\n            }\r\n            \r\n            //File targetClass = rewriteClassFile(targetFile);\r\n            //We need tp here\r\n            servletProperties templatePatterns = null;\r\n            Date targetDate;\r\n            boolean nocache = false;\r\n            \r\n            if ((targetClass != null) && (path.endsWith(\"png\"))) {\r\n                // call an image-servlet to produce an on-the-fly - generated image\r\n                Object img = null;\r\n                try {\r\n                    requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                    requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                    // in case that there are no args given, args = null or empty hashmap\r\n                    img = invokeServlet(targetClass, requestHeader, args);\r\n                } catch (final InvocationTargetException e) {\r\n                    theLogger.logSevere(\"INTERNAL ERROR: \" + e.toString() + \":\" +\r\n                    e.getMessage() +\r\n                    \" target exception at \" + targetClass + \": \" +\r\n                    e.getTargetException().toString() + \":\" +\r\n                    e.getTargetException().getMessage() +\r\n                    \"; java.awt.graphicsenv='\" + System.getProperty(\"java.awt.graphicsenv\",\"\") + \"'\");\r\n                    targetClass = null;\r\n                }\r\n                if (img == null) {\r\n                    // error with image generation; send file-not-found\r\n                    httpd.sendRespondError(conProp, out, 3, 404, \"File not Found\", null, null);\r\n                } else {\r\n                    if (img instanceof ymageMatrix) {\r\n                        final ymageMatrix yp = (ymageMatrix) img;\r\n                        // send an image to client\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                        final String mimeType = mimeTable.getProperty(targetExt, \"text/html\");\r\n                        final serverByteBuffer result = ymageMatrix.exportImage(yp.getImage(), targetExt);\r\n\r\n                        // write the array to the client\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, result.length(), targetDate, null, null, null, null, nocache);\r\n                        if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        \tresult.writeTo(out);\r\n                        }\r\n                    }\r\n                    if (img instanceof Image) {\r\n                        final Image i = (Image) img;\r\n                        // send an image to client\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                        final String mimeType = mimeTable.getProperty(targetExt, \"text/html\");\r\n\r\n                        // generate an byte array from the generated image\r\n                        int width = i.getWidth(null); if (width < 0) width = 96; // bad hack\r\n                        int height = i.getHeight(null); if (height < 0) height = 96; // bad hack\r\n                        final BufferedImage bi = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);\r\n                        bi.createGraphics().drawImage(i, 0, 0, width, height, null); \r\n                        final serverByteBuffer result = ymageMatrix.exportImage(bi, targetExt);\r\n\r\n                        // write the array to the client\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, result.length(), targetDate, null, null, null, null, nocache);\r\n                        if (!method.equals(httpHeader.METHOD_HEAD)) {\r\n                        \tresult.writeTo(out);\r\n                        }\r\n                    }\r\n                }\r\n            } else if (((switchboard.getConfigBool(\"cgi.allow\", false)) &&                                  // check if CGI execution is allowed in config\r\n                    (httpdFileHandler.matchesSuffix(path, switchboard.getConfig(\"cgi.suffixes\", null))) &&  // \"right\" file extension?\r\n                    (path.substring(0, path.indexOf(targetFile.getName())).contains(\"/CGI-BIN/\") ||\r\n                    path.substring(0, path.indexOf(targetFile.getName())).contains(\"/cgi-bin/\")) &&         // file in right directory?\r\n                    targetFile.exists())\r\n                    ) {\r\n\r\n                String mimeType = \"text/html\";\r\n                int statusCode = 200;\r\n\r\n                ProcessBuilder pb;\r\n\r\n                pb = new ProcessBuilder(targetFile.getAbsolutePath());\r\n\r\n                String fileSeparator = System.getProperty(\"file.separator\", \"/\");\r\n\r\n                // set environment variables\r\n                Map<String, String> env = pb.environment();\r\n                env.put(\"SERVER_SOFTWARE\", getDefaultHeaders(path).get(httpResponseHeader.SERVER));\r\n                env.put(\"SERVER_NAME\", switchboard.getConfig(\"peerName\", \"<nameless>\"));\r\n                env.put(\"GATEWAY_INTERFACE\", \"CGI/1.1\");\r\n                if (httpVersion != null) {\r\n                    env.put(\"SERVER_PROTOCOL\", httpVersion);\r\n                }\r\n                env.put(\"SERVER_PORT\", switchboard.getConfig(\"port\", \"8080\"));\r\n                env.put(\"REQUEST_METHOD\", method);\r\n//                env.put(\"PATH_INFO\", \"\");         // TODO: implement\r\n//                env.put(\"PATH_TRANSLATED\", \"\");   // TODO: implement\r\n                env.put(\"SCRIPT_NAME\", path);\r\n                if (argsString != null) {\r\n                    env.put(\"QUERY_STRING\", argsString);\r\n                }\r\n                env.put(\"REMOTE_HOST\", InetAddress.getByName(clientIP).getHostName());\r\n                env.put(\"REMOTE_ADDR\", clientIP);\r\n//                env.put(\"AUTH_TYPE\", \"\");         // TODO: implement\r\n//                env.put(\"REMOTE_USER\", \"\");       // TODO: implement\r\n//                env.put(\"REMOTE_IDENT\", \"\");      // I don't think we need this\r\n                env.put(\"DOCUMENT_ROOT\", switchboard.getRootPath().getAbsolutePath() + fileSeparator + switchboard.getConfig(\"htDocsPath\", \"DATA/HTDOCS\"));\r\n                if (requestHeader.getContentType() != null) {\r\n                    env.put(\"CONTENT_TYPE\", requestHeader.getContentType());\r\n                }\r\n                if (method.equalsIgnoreCase(httpHeader.METHOD_POST) && body != null) {\r\n                    env.put(\"CONTENT_LENGTH\", requestHeader.getContentLength() + \"\");\r\n                }\r\n\r\n                // add values from request header to environment (see: http://hoohoo.ncsa.uiuc.edu/cgi/env.html#headers)\r\n                Set<String> requestHeaderKeys = requestHeader.keySet();\r\n                for (String requestHeaderKey : requestHeaderKeys) {\r\n                    env.put(\"HTTP_\" + requestHeaderKey.toUpperCase().replace(\"-\", \"_\"), requestHeader.get(requestHeaderKey));\r\n                }\r\n\r\n                int exitValue = 0;\r\n                String cgiBody = null;\r\n\r\n                try {\r\n                    // start execution of script\r\n                    Process p = pb.start();\r\n\r\n                    OutputStream os = new BufferedOutputStream(p.getOutputStream());\r\n\r\n                    if (method.equalsIgnoreCase(httpHeader.METHOD_POST) && body != null) {\r\n                        byte[] buffer = new byte[1024];\r\n                        int len = requestHeader.getContentLength();\r\n                        while (len > 0) {\r\n                            body.read(buffer);\r\n                            len = len - buffer.length;\r\n                            os.write(buffer);\r\n                        }\r\n                    }\r\n\r\n                    os.close();\r\n\r\n                    try {\r\n                        p.waitFor();\r\n                    } catch (InterruptedException ex) {\r\n\r\n                    }\r\n\r\n                    exitValue = p.exitValue();\r\n\r\n                    InputStream is = new BufferedInputStream(p.getInputStream());\r\n\r\n                    StringBuilder stringBuffer = new StringBuilder(1024);\r\n\r\n                    while (is.available() > 0) {\r\n                        stringBuffer.append((char) is.read());\r\n                    }\r\n\r\n                    String cgiReturn = stringBuffer.toString();\r\n                    int indexOfDelimiter = cgiReturn.indexOf(\"\\n\\n\");\r\n                    String[] cgiHeader = new String[0];\r\n                    if (indexOfDelimiter > -1) {\r\n                        cgiHeader = cgiReturn.substring(0, indexOfDelimiter).split(\"\\n\");\r\n                    }\r\n                    cgiBody = cgiReturn.substring(indexOfDelimiter + 1);\r\n\r\n                    String key;\r\n                    String value;\r\n                    for (int i = 0; i < cgiHeader.length; i++) {\r\n                        indexOfDelimiter = cgiHeader[i].indexOf(\":\");\r\n                        key = cgiHeader[i].substring(0, indexOfDelimiter).trim();\r\n                        value = cgiHeader[i].substring(indexOfDelimiter + 1).trim();\r\n                        conProp.setProperty(key, value);\r\n                        if (key.equals(\"Cache-Control\") && value.equals(\"no-cache\")) {\r\n                            nocache = true;\r\n                        } else if (key.equals(\"Content-type\")) {\r\n                            mimeType = value;\r\n                        } else if (key.equals(\"Status\")) {\r\n                            if (key.length() > 2) {\r\n                                try {\r\n                                    statusCode = Integer.parseInt(value.substring(0, 3));\r\n                                } catch (NumberFormatException ex) {\r\n                                    /* tough luck, we will just have to use 200 as default value */\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                } catch (IOException ex) {\r\n                    exitValue = -1;\r\n                }\r\n\r\n                /* did the script return an exit value != 0 and still there is supposed to be\r\n                 * everything right with the HTTP status? -> change status to 500 since 200 would\r\n                 * be a lie\r\n                 */\r\n                if (exitValue != 0 && statusCode == 200) {\r\n                    statusCode = 500;\r\n                }\r\n\r\n                targetDate = new Date(System.currentTimeMillis());\r\n\r\n                if (exitValue == 0 || (cgiBody != null && !cgiBody.equals(\"\"))) {\r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, statusCode, null, mimeType, cgiBody.length(), targetDate, null, null, null, null, nocache);\r\n                    out.write(cgiBody.getBytes());\r\n                } else {\r\n                    httpd.sendRespondError(conProp, out, exitValue, statusCode, null, httpHeader.http1_1.get(statusCode + \"\"), null);\r\n                }\r\n                \r\n\r\n            } else if ((targetClass != null) && (path.endsWith(\".stream\"))) {\r\n                // call rewrite-class\r\n                requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                //requestHeader.put(httpHeader.CONNECTION_PROP_INPUTSTREAM, body);\r\n                //requestHeader.put(httpHeader.CONNECTION_PROP_OUTPUTSTREAM, out);\r\n             \r\n                httpd.sendRespondHeader(conProp, out, httpVersion, 200, null);                \r\n                \r\n                // in case that there are no args given, args = null or empty hashmap\r\n                /* servletProperties tp = (servlerObjects) */ invokeServlet(targetClass, requestHeader, args);\r\n                forceConnectionClose(conProp);\r\n                return;                \r\n            } else if (targetFile.exists() && targetFile.isFile() && targetFile.canRead()) {\r\n                // we have found a file that can be written to the client\r\n                // if this file uses templates, then we use the template\r\n                // re-write - method to create an result\r\n                String mimeType = mimeTable.getProperty(targetExt,\"text/html\");\r\n                final boolean zipContent = requestHeader.acceptGzip() && httpd.shallTransportZipped(\".\" + conProp.getProperty(\"EXT\",\"\"));\r\n                if (path.endsWith(\"html\") || \r\n                        path.endsWith(\"htm\") || \r\n                        path.endsWith(\"xml\") || \r\n                        path.endsWith(\"json\") || \r\n                        path.endsWith(\"rdf\") || \r\n                        path.endsWith(\"rss\") || \r\n                        path.endsWith(\"csv\") ||\r\n                        path.endsWith(\"pac\") ||\r\n                        path.endsWith(\"src\") ||\r\n                        path.endsWith(\"vcf\") ||\r\n                        path.endsWith(\"/\") ||\r\n                        path.equals(\"/robots.txt\")) {\r\n                            \r\n                    /*targetFile = getLocalizedFile(path);\r\n\t\t\t\t\tif (!(targetFile.exists())) {\r\n\t\t                // try to find that file in the htDocsPath\r\n\t\t\t\t        File trialFile = new File(htDocsPath, path);\r\n\t\t\t\t\t\tif (trialFile.exists()) targetFile = trialFile;\r\n\t\t            }*/\r\n            \r\n                    \r\n                    // call rewrite-class\r\n                   \r\n                    if (targetClass == null) {\r\n                        targetDate = new Date(targetFile.lastModified());\r\n                    } else {\r\n                        // CGI-class: call the class to create a property for rewriting\r\n                        try {\r\n                            requestHeader.put(httpHeader.CONNECTION_PROP_CLIENTIP, conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP));\r\n                            requestHeader.put(httpHeader.CONNECTION_PROP_PATH, path);\r\n                            // in case that there are no args given, args = null or empty hashmap\r\n                            final Object tmp = invokeServlet(targetClass, requestHeader, args);\r\n                            if (tmp == null) {\r\n                                // if no args given, then tp will be an empty Hashtable object (not null)\r\n                                templatePatterns = new servletProperties();\r\n                            } else if (tmp instanceof servletProperties) {\r\n                                templatePatterns = (servletProperties) tmp;\r\n                            } else {\r\n                                templatePatterns = new servletProperties((serverObjects) tmp);\r\n                            }\r\n                            // check if the servlets requests authentification\r\n                            if (templatePatterns.containsKey(servletProperties.ACTION_AUTHENTICATE)) {\r\n                                // handle brute-force protection\r\n                                if (authorization != null) {\r\n                                    serverLog.logInfo(\"HTTPD\", \"dynamic log-in for account 'admin' in http file handler for path '\" + path + \"' from host '\" + clientIP + \"'\");\r\n                                    final Integer attempts = serverCore.bfHost.get(clientIP);\r\n                                    if (attempts == null)\r\n                                        serverCore.bfHost.put(clientIP, Integer.valueOf(1));\r\n                                    else\r\n                                        serverCore.bfHost.put(clientIP, Integer.valueOf(attempts.intValue() + 1));\r\n                                }\r\n                                // send authentication request to browser\r\n                                final httpResponseHeader headers = getDefaultHeaders(path);\r\n                                headers.put(httpRequestHeader.WWW_AUTHENTICATE,\"Basic realm=\\\"\" + templatePatterns.get(servletProperties.ACTION_AUTHENTICATE, \"\") + \"\\\"\");\r\n                                httpd.sendRespondHeader(conProp,out,httpVersion,401,headers);\r\n                                return;\r\n                            } else if (templatePatterns.containsKey(servletProperties.ACTION_LOCATION)) {\r\n                                String location = templatePatterns.get(servletProperties.ACTION_LOCATION, \"\");\r\n                                if (location.length() == 0) location = path;\r\n                                \r\n                                final httpResponseHeader headers = getDefaultHeaders(path);\r\n                                headers.setCookieVector(templatePatterns.getOutgoingHeader().getCookieVector()); //put the cookies into the new header TODO: can we put all headerlines, without trouble?\r\n                                headers.put(httpHeader.LOCATION,location);\r\n                                httpd.sendRespondHeader(conProp,out,httpVersion,302,headers);\r\n                                return;\r\n                            }\r\n                            // add the application version, the uptime and the client name to every rewrite table\r\n                            templatePatterns.put(servletProperties.PEER_STAT_VERSION, switchboard.getConfig(\"version\", \"\"));\r\n                            templatePatterns.put(servletProperties.PEER_STAT_UPTIME, ((System.currentTimeMillis() -  serverCore.startupTime) / 1000) / 60); // uptime in minutes\r\n                            templatePatterns.putHTML(servletProperties.PEER_STAT_CLIENTNAME, switchboard.getConfig(\"peerName\", \"anomic\"));\r\n                            templatePatterns.put(servletProperties.PEER_STAT_MYTIME, serverDate.formatShortSecond());\r\n                            //System.out.println(\"respond props: \" + ((tp == null) ? \"null\" : tp.toString())); // debug\r\n                        } catch (final InvocationTargetException e) {\r\n                            if (e.getCause() instanceof InterruptedException) {\r\n                                throw new InterruptedException(e.getCause().getMessage());\r\n                            }                            \r\n                            \r\n                            theLogger.logSevere(\"INTERNAL ERROR: \" + e.toString() + \":\" +\r\n                                    e.getMessage() +\r\n                                    \" target exception at \" + targetClass + \": \" +\r\n                                    e.getTargetException().toString() + \":\" +\r\n                                    e.getTargetException().getMessage(),e);\r\n                            targetClass = null;\r\n                            throw e;\r\n                        }\r\n                        targetDate = new Date(System.currentTimeMillis());\r\n                        nocache = true;\r\n                    }\r\n                    \r\n                    // rewrite the file\r\n                    InputStream fis = null;\r\n                    \r\n                    // read the file/template\r\n                    TemplateCacheEntry templateCacheEntry = null;\r\n                    if (useTemplateCache) {\r\n                        final long fileSize = targetFile.length();\r\n                        if (fileSize <= 512 * 1024) {\r\n                            // read from cache\r\n                            SoftReference<TemplateCacheEntry> ref = templateCache.get(targetFile);\r\n                            if (ref != null) {\r\n                                templateCacheEntry = ref.get();\r\n                                if (templateCacheEntry == null) templateCache.remove(targetFile);\r\n                            }\r\n\r\n                            Date targetFileDate = new Date(targetFile.lastModified());\r\n                            if (templateCacheEntry == null || targetFileDate.after(templateCacheEntry.lastModified)) {\r\n                                // loading the content of the template file into\r\n                                // a byte array\r\n                        \ttemplateCacheEntry = new TemplateCacheEntry();\r\n                                templateCacheEntry.lastModified = targetFileDate;\r\n                                templateCacheEntry.content = serverFileUtils.read(targetFile);\r\n\r\n                                // storing the content into the cache\r\n                                ref = new SoftReference<TemplateCacheEntry>(templateCacheEntry);\r\n                                templateCache.put(targetFile, ref);\r\n                                if (theLogger.isFinest()) theLogger.logFinest(\"Cache MISS for file \" + targetFile);\r\n                            } else {\r\n                                if (theLogger.isFinest()) theLogger.logFinest(\"Cache HIT for file \" + targetFile);\r\n                            }\r\n\r\n                            // creating an inputstream needed by the template\r\n                            // rewrite function\r\n                            fis = new ByteArrayInputStream(templateCacheEntry.content);\r\n                            templateCacheEntry = null;\r\n                        } else {\r\n                            // read from file directly\r\n                            fis = new BufferedInputStream(new FileInputStream(targetFile));\r\n                        }\r\n                    } else {\r\n                        fis = new BufferedInputStream(new FileInputStream(targetFile));\r\n                    }\r\n                    \r\n                    if(mimeType.startsWith(\"text\")) {\r\n                    \t// every text-file distributed by yacy is UTF-8\r\n                    \tif(!path.startsWith(\"/repository\")) {\r\n                    \t\tmimeType = mimeType + \"; charset=UTF-8\";\r\n                    \t} else {\r\n                    \t\t// detect charset of html-files\r\n                    \t\tif((path.endsWith(\"html\") || path.endsWith(\"htm\"))) {\r\n                    \t\t\t// save position\r\n                    \t\t\tfis.mark(1000);\r\n                    \t\t\t// scrape document to look up charset\r\n                    \t\t\tfinal htmlFilterInputStream htmlFilter = new htmlFilterInputStream(fis,\"UTF-8\",new yacyURL(\"http://localhost\", null),null,false);\r\n                    \t\t\tfinal String charset = plasmaParser.patchCharsetEncoding(htmlFilter.detectCharset());\r\n                    \t\t\tif(charset != null)\r\n                    \t\t\t\tmimeType = mimeType + \"; charset=\"+charset;\r\n                    \t\t\t// reset position\r\n                    \t\t\tfis.reset();\r\n                    \t\t}\r\n                    \t}\r\n                \t}\r\n\r\n                    // write the array to the client\r\n                    // we can do that either in standard mode (whole thing completely) or in chunked mode\r\n                    // since yacy clients do not understand chunked mode (yet), we use this only for communication with the administrator\r\n                    final boolean yacyClient = requestHeader.userAgent().startsWith(\"yacy\");\r\n                    final boolean chunked = !method.equals(httpHeader.METHOD_HEAD) && !yacyClient && httpVersion.equals(httpHeader.HTTP_VERSION_1_1);\r\n                    if (chunked) {\r\n                        // send page in chunks and parse SSIs\r\n                        final serverByteBuffer o = new serverByteBuffer();\r\n                        // apply templates\r\n                        httpTemplate.writeTemplate(fis, o, templatePatterns, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        httpd.sendRespondHeader(conProp, out, httpVersion, 200, null, mimeType, -1, targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(), null, \"chunked\", nocache);\r\n                        // send the content in chunked parts, see RFC 2616 section 3.6.1\r\n                        final httpChunkedOutputStream chos = new httpChunkedOutputStream(out);\r\n                        httpSSI.writeSSI(o, chos, authorization, clientIP);\r\n                        //chos.write(result);\r\n                        chos.finish();\r\n                    } else {\r\n                        // send page as whole thing, SSIs are not possible\r\n                        final String contentEncoding = (zipContent) ? \"gzip\" : null;\r\n                        // apply templates\r\n                        final serverByteBuffer o1 = new serverByteBuffer();\r\n                        httpTemplate.writeTemplate(fis, o1, templatePatterns, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        \r\n                        final serverByteBuffer o = new serverByteBuffer();\r\n                        \r\n                        if (zipContent) {\r\n                            GZIPOutputStream zippedOut = new GZIPOutputStream(o);\r\n                            httpSSI.writeSSI(o1, zippedOut, authorization, clientIP);\r\n                            //httpTemplate.writeTemplate(fis, zippedOut, tp, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                            zippedOut.finish();\r\n                            zippedOut.flush();\r\n                            zippedOut.close();\r\n                            zippedOut = null;\r\n                        } else {\r\n                            httpSSI.writeSSI(o1, o, authorization, clientIP);\r\n                            //httpTemplate.writeTemplate(fis, o, tp, \"-UNRESOLVED_PATTERN-\".getBytes(\"UTF-8\"));\r\n                        }\r\n                        if (method.equals(httpHeader.METHOD_HEAD)) {\r\n                            httpd.sendRespondHeader(conProp, out,\r\n                                    httpVersion, 200, null, mimeType, o.length(),\r\n                                    targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(),\r\n                                    contentEncoding, null, nocache);\r\n                        } else {\r\n                            final byte[] result = o.getBytes(); // this interrupts streaming (bad idea!)\r\n                            httpd.sendRespondHeader(conProp, out,\r\n                                    httpVersion, 200, null, mimeType, result.length,\r\n                                    targetDate, null, (templatePatterns == null) ? new httpResponseHeader() : templatePatterns.getOutgoingHeader(),\r\n                                    contentEncoding, null, nocache);\r\n                            serverFileUtils.copy(result, out);\r\n                        }  \r\n                    }\r\n                } else { // no html\r\n                    \r\n                    int statusCode = 200;\r\n                    int rangeStartOffset = 0;\r\n                    httpResponseHeader header = new httpResponseHeader();\r\n                    \r\n                    // adding the accept ranges header\r\n                    header.put(httpHeader.ACCEPT_RANGES, \"bytes\");\r\n                    \r\n                    // reading the files md5 hash if availabe and use it as ETAG of the resource\r\n                    String targetMD5 = null;\r\n                    final File targetMd5File = new File(targetFile + \".md5\");\r\n                    try {\r\n                        if (targetMd5File.exists()) {\r\n                            //String description = null;\r\n                            targetMD5 = new String(serverFileUtils.read(targetMd5File));\r\n                            int pos = targetMD5.indexOf('\\n');\r\n                            if (pos >= 0) {\r\n                                //description = targetMD5.substring(pos + 1);\r\n                                targetMD5 = targetMD5.substring(0, pos);\r\n                            }\r\n\r\n                            // using the checksum as ETAG header\r\n                            header.put(httpHeader.ETAG, targetMD5);\r\n                        }\r\n                    } catch (final IOException e) {\r\n                        e.printStackTrace();\r\n                    }                        \r\n                    \r\n                    if (requestHeader.containsKey(httpHeader.RANGE)) {\r\n                        final Object ifRange = requestHeader.ifRange();\r\n                        if ((ifRange == null)||\r\n                            (ifRange instanceof Date && targetFile.lastModified() == ((Date)ifRange).getTime()) ||\r\n                            (ifRange instanceof String && ifRange.equals(targetMD5))) {\r\n                            final String rangeHeaderVal = requestHeader.get(httpHeader.RANGE).trim();\r\n                            if (rangeHeaderVal.startsWith(\"bytes=\")) {\r\n                                final String rangesVal = rangeHeaderVal.substring(\"bytes=\".length());\r\n                                final String[] ranges = rangesVal.split(\",\");\r\n                                if ((ranges.length == 1)&&(ranges[0].endsWith(\"-\"))) {\r\n                                    rangeStartOffset = Integer.valueOf(ranges[0].substring(0,ranges[0].length()-1)).intValue();\r\n                                    statusCode = 206;\r\n                                    if (header == null) header = new httpResponseHeader();\r\n                                    header.put(httpHeader.CONTENT_RANGE, \"bytes \" + rangeStartOffset + \"-\" + (targetFile.length()-1) + \"/\" + targetFile.length());\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                    \r\n                    // write the file to the client\r\n                    targetDate = new Date(targetFile.lastModified());\r\n                    final long   contentLength    = (zipContent)?-1:targetFile.length()-rangeStartOffset;\r\n                    final String contentEncoding  = (zipContent)?\"gzip\":null;\r\n                    final String transferEncoding = (!httpVersion.equals(httpHeader.HTTP_VERSION_1_1))?null:(zipContent)?\"chunked\":null;\r\n                    if (!httpVersion.equals(httpHeader.HTTP_VERSION_1_1) && zipContent) forceConnectionClose(conProp);\r\n                    \r\n                    httpd.sendRespondHeader(conProp, out, httpVersion, statusCode, null, mimeType, contentLength, targetDate, null, header, contentEncoding, transferEncoding, nocache);\r\n                \r\n                    if (!method.equals(httpHeader.METHOD_HEAD)) {                        \r\n                        httpChunkedOutputStream chunkedOut = null;\r\n                        GZIPOutputStream zipped = null;\r\n                        OutputStream newOut = out;\r\n                        \r\n                        if (transferEncoding != null) {\r\n                            chunkedOut = new httpChunkedOutputStream(newOut);\r\n                            newOut = chunkedOut;\r\n                        }\r\n                        if (contentEncoding != null) {\r\n                            zipped = new GZIPOutputStream(newOut);\r\n                            newOut = zipped;\r\n                        }\r\n                        \r\n                        serverFileUtils.copyRange(targetFile, newOut, rangeStartOffset);\r\n                        \r\n                        if (zipped != null) {\r\n                            zipped.flush();\r\n                            zipped.finish();\r\n                        }\r\n                        if (chunkedOut != null) {\r\n                            chunkedOut.finish();\r\n                        }\r\n\r\n                        // flush all\r\n                        try {newOut.flush();}catch (final Exception e) {}\r\n                        \r\n                        // wait a little time until everything closes so that clients can read from the streams/sockets\r\n                        if ((contentLength >= 0) && ((String)requestHeader.get(httpRequestHeader.CONNECTION, \"close\")).indexOf(\"keep-alive\") == -1) {\r\n                            // in case that the client knows the size in advance (contentLength present) the waiting will have no effect on the interface performance\r\n                            // but if the client waits on a connection interruption this will slow down.\r\n                            try {Thread.sleep(2000);} catch (final InterruptedException e) {} // FIXME: is this necessary?\r\n                        }\r\n                    }\r\n                    \r\n                    // check mime type again using the result array: these are 'magics'\r\n//                    if (serverByteBuffer.equals(result, 1, \"PNG\".getBytes())) mimeType = mimeTable.getProperty(\"png\",\"text/html\");\r\n//                    else if (serverByteBuffer.equals(result, 0, \"GIF89\".getBytes())) mimeType = mimeTable.getProperty(\"gif\",\"text/html\");\r\n//                    else if (serverByteBuffer.equals(result, 6, \"JFIF\".getBytes())) mimeType = mimeTable.getProperty(\"jpg\",\"text/html\");\r\n                    //System.out.print(\"MAGIC:\"); for (int i = 0; i < 10; i++) System.out.print(Integer.toHexString((int) result[i]) + \",\"); System.out.println();\r\n                }\r\n            } else {\r\n                httpd.sendRespondError(conProp,out,3,404,\"File not Found\",null,null);\r\n                return;\r\n            }\r\n        } catch (final Exception e) {     \r\n            try {\r\n                // doing some errorhandling ...\r\n                int httpStatusCode = 400; \r\n                final String httpStatusText = null; \r\n                final StringBuilder errorMessage = new StringBuilder(2000); \r\n                Exception errorExc = null;            \r\n                \r\n                final String errorMsg = e.getMessage();\r\n                if (\r\n                        (e instanceof InterruptedException) ||\r\n                        ((errorMsg != null) && (errorMsg.startsWith(\"Socket closed\")) && (Thread.currentThread().isInterrupted()))\r\n                   ) {\r\n                    errorMessage.append(\"Interruption detected while processing query.\");\r\n                    httpStatusCode = 503;\r\n                } else {\r\n                    if ((errorMsg != null) && \r\n                        (\r\n                           errorMsg.contains(\"broken pipe\") || \r\n                           errorMsg.contains(\"Connection reset\") ||\r\n                           errorMsg.contains(\"Software caused connection abort\")                           \r\n                       )) {\r\n                        // client closed the connection, so we just end silently\r\n                        errorMessage.append(\"Client unexpectedly closed connection while processing query.\");\r\n                    } else if ((errorMsg != null) && (errorMsg.startsWith(\"Connection timed out\"))) {\r\n                        errorMessage.append(\"Connection timed out.\");\r\n                    } else {\r\n                        errorMessage.append(\"Unexpected error while processing query.\");\r\n                        httpStatusCode = 500;\r\n                        errorExc = e;\r\n                    }\r\n                }\r\n                \r\n                errorMessage.append(\"\\nSession: \").append(Thread.currentThread().getName())\r\n                            .append(\"\\nQuery:   \").append(path)\r\n                            .append(\"\\nClient:  \").append(conProp.getProperty(httpHeader.CONNECTION_PROP_CLIENTIP,\"unknown\")) \r\n                            .append(\"\\nReason:  \").append(e.toString());    \r\n                \r\n                if (!conProp.containsKey(httpHeader.CONNECTION_PROP_PROXY_RESPOND_HEADER)) {\r\n                    // sending back an error message to the client \r\n                    // if we have not already send an http header\r\n                    httpd.sendRespondError(conProp,out, 4, httpStatusCode, httpStatusText, new String(errorMessage),errorExc);\r\n                } else {\r\n                    // otherwise we close the connection\r\n                    forceConnectionClose(conProp);\r\n                }    \r\n                \r\n                // if it is an unexpected error we log it \r\n                if (httpStatusCode == 500) {\r\n                    theLogger.logWarning(new String(errorMessage),e);\r\n                }\r\n                \r\n            } catch (final Exception ee) {\r\n                forceConnectionClose(conProp);\r\n            }            \r\n            \r\n        } finally {\r\n            try {out.flush();}catch (final Exception e) {}\r\n        }\r\n    }","commit_id":"fe77fc3d62e1c2a86354de1d42ac771edfddb7cd","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"/** Returns a path to the localized or default file according to the parameter localeSelection\r\n\t * @param path relative from htroot\r\n\t * @param localeSelection language of localized file; locale.language from switchboard is used if localeSelection.equals(\"\") */\r\n\tpublic static File getLocalizedFile(final String path, final String localeSelection){\r\n        if (htDefaultPath == null) htDefaultPath = switchboard.getConfigPath(\"htDefaultPath\",\"htroot\");\r\n        if (htLocalePath == null) htLocalePath = switchboard.getConfigPath(\"locale.translated_html\",\"DATA/LOCALE/htroot\");\r\n\r\n        if (!(localeSelection.equals(\"default\"))) {\r\n            final File localePath = new File(htLocalePath, localeSelection + '/' + path);\r\n            if (localePath.exists())  // avoid \"NoSuchFile\" troubles if the \"localeSelection\" is misspelled\r\n                return localePath;\r\n        }\r\n        return new File(htDefaultPath, path);\r\n\t}","id":36061,"modified_method":"/** Returns a path to the localized or default file according to the parameter localeSelection\r\n\t * @param path relative from htroot\r\n\t * @param localeSelection language of localized file; locale.language from switchboard is used if localeSelection.equals(\"\") */\r\n\tpublic static File getLocalizedFile(final String path, final String localeSelection){\r\n        //if (htDefaultPath == null) htDefaultPath = switchboard.getConfigPath(\"htDefaultPath\", \"htroot\");\r\n        //if (htLocalePath == null) htLocalePath = switchboard.getConfigPath(\"locale.translated_html\", \"DATA/LOCALE/htroot\");\r\n\t    //if (htDocsPath == null) htDocsPath = switchboard.getConfigPath(plasmaSwitchboardConstants.HTDOCS_PATH, plasmaSwitchboardConstants.HTDOCS_PATH_DEFAULT);\r\n\r\n        if (path.startsWith(\"/repository/\"))\r\n            return new File(switchboard.getConfig(\"repositoryPath\", \"DATA/HTDOCS/repository\"), path.substring(11));\r\n        if (!(localeSelection.equals(\"default\"))) {\r\n            final File localePath = new File(htLocalePath, localeSelection + '/' + path);\r\n            if (localePath.exists()) return localePath;  // avoid \"NoSuchFile\" troubles if the \"localeSelection\" is misspelled\r\n        }\r\n\r\n        File docsPath  = new File(htDocsPath, path);\r\n        if (docsPath.exists()) return docsPath;\r\n        return new File(htDefaultPath, path);\r\n\t}","commit_id":"fe77fc3d62e1c2a86354de1d42ac771edfddb7cd","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static <T extends SNode> Set<T> toNodes(Set<? extends INodeAdapter> list) {\n    Set<T> result = new HashSet<T>();\n    for (INodeAdapter ba : list) {\n      result.add((T) ba.getNode());\n    }\n    return result;\n  }","id":36062,"modified_method":"public static Set<SNode> toNodes(Set<? extends INodeAdapter> list) {\n    Set<SNode> result = new HashSet<SNode>();\n    for (INodeAdapter ba : list) {\n      result.add(ba.getNode());\n    }\n    return result;\n  }","commit_id":"b0ae5ac09de6b6a697e717a0f4ae8771726cf790","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static <T extends SNode> List<T> toNodes(List<? extends INodeAdapter> list) {\n    List<T> result = new ArrayList<T>();\n    for (INodeAdapter ba : list) {\n      result.add((T) ba.getNode());\n    }\n    return result;\n  }","id":36063,"modified_method":"public static List<SNode> toNodes(List<? extends INodeAdapter> list) {\n    List<SNode> result = new ArrayList<SNode>();\n    for (INodeAdapter ba : list) {\n      result.add(ba.getNode());\n    }\n    return result;\n  }","commit_id":"b0ae5ac09de6b6a697e717a0f4ae8771726cf790","url":"https://github.com/JetBrains/MPS"},{"original_method":"public ISearchScope createNodeReferentSearchScope(SModel model, SNode enclosingNode, SNode referenceNode, IScope scope) {\n    SNode conceptOfParent = SLinkOperations.getTarget(referenceNode, \"conceptOfParent\", false);\n    List links = SModelSearchUtil_new.getAggregationLinkDeclarationsExcludingOverridden(((AbstractConceptDeclaration)SNodeOperations.getAdapter(conceptOfParent)));\n    return new SimpleSearchScope((List<SNode>)BaseAdapter.toNodes((List<? extends INodeAdapter>)links));\n  }","id":36064,"modified_method":"public ISearchScope createNodeReferentSearchScope(SModel model, SNode enclosingNode, SNode referenceNode, IScope scope) {\n    SNode conceptOfParent = SLinkOperations.getTarget(referenceNode, \"conceptOfParent\", false);\n    List links = SModelSearchUtil_new.getAggregationLinkDeclarationsExcludingOverridden(((AbstractConceptDeclaration)SNodeOperations.getAdapter(conceptOfParent)));\n    return new SimpleSearchScope(BaseAdapter.toNodes((List<? extends INodeAdapter>)links));\n  }","commit_id":"b0ae5ac09de6b6a697e717a0f4ae8771726cf790","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_FieldReference_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode instance = SLinkOperations.getTarget(node, \"instance\", true);\n    if(instance == null) {\n      return result;\n    }\n    ClassifierType instanceType = BaseLanguageTypesUtil_new.tryObtain_ClassifierType(((Expression)SNodeOperations.getAdapter(instance)));\n    if(instanceType == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(instanceType, IClassifiersSearchScope.INSTANCE_METHOD);\n    result = (List)BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n    return result;\n  }","id":36065,"modified_method":"public static List<SNode> replaceNodeMenu_FieldReference_getParameterObjects(SNode node) {\n    SNode instance = SLinkOperations.getTarget(node, \"instance\", true);\n    if(instance == null) {\n      return new LinkedList<SNode>();\n    }\n    ClassifierType instanceType = BaseLanguageTypesUtil_new.tryObtain_ClassifierType(((Expression)SNodeOperations.getAdapter(instance)));\n    if(instanceType == null) {\n      return new LinkedList<SNode>();\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(instanceType, IClassifiersSearchScope.INSTANCE_METHOD);\n    return BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n  }","commit_id":"281b2c9438f71621807f2f53895bed3f2511d19b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_StaticMethodCall_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classConcept\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope((Classifier)BaseAdapter.fromNode(classifier), IClassifiersSearchScope.STATIC_MEMBER);\n    List staticFields = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, (List<SNode>)staticFields);\n    List<SNode> allStaticMembers = classHierarchy.getNodes();\n    ListOperations.addAllElements(result, SequenceOperations.where(allStaticMembers, new zPredicate1(null, null)));\n    return result;\n  }","id":36066,"modified_method":"public static List<SNode> replaceNodeMenu_StaticMethodCall_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classConcept\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(((Classifier)SNodeOperations.getAdapter(classifier)), IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> staticFields = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, staticFields);\n    List<SNode> allStaticMembers = classHierarchy.getNodes();\n    ListOperations.addAllElements(result, SequenceOperations.where(allStaticMembers, new zPredicate1(null, null)));\n    return result;\n  }","commit_id":"281b2c9438f71621807f2f53895bed3f2511d19b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_InstanceMethodCall_getParameterObjects(SNode referenceNode) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode instance = SLinkOperations.getTarget(referenceNode, \"instance\", true);\n    if(instance == null) {\n      return result;\n    }\n    ClassifierType instanceType = BaseLanguageTypesUtil_new.tryObtain_ClassifierType(((Expression)SNodeOperations.getAdapter(instance)));\n    if(instanceType == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(instanceType, IClassifiersSearchScope.INSTANCE_FIELD);\n    result = (List)BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n    return result;\n  }","id":36067,"modified_method":"public static List<SNode> replaceNodeMenu_InstanceMethodCall_getParameterObjects(SNode referenceNode) {\n    SNode instance = SLinkOperations.getTarget(referenceNode, \"instance\", true);\n    if(instance == null) {\n      return new LinkedList<SNode>();\n    }\n    ClassifierType instanceType = BaseLanguageTypesUtil_new.tryObtain_ClassifierType(((Expression)SNodeOperations.getAdapter(instance)));\n    if(instanceType == null) {\n      return new LinkedList<SNode>();\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(instanceType, IClassifiersSearchScope.INSTANCE_FIELD);\n    return BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n  }","commit_id":"281b2c9438f71621807f2f53895bed3f2511d19b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_StaticFieldReference_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classifier\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope((Classifier)BaseAdapter.fromNode(classifier), IClassifiersSearchScope.STATIC_MEMBER);\n    List staticMethods = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, (List<SNode>)staticMethods);\n    List<SNode> allStaticMembers = classHierarchy.getNodes();\n    ListOperations.addAllElements(result, SequenceOperations.where(allStaticMembers, new zPredicate(null, null)));\n    return result;\n  }","id":36068,"modified_method":"public static List<SNode> replaceNodeMenu_StaticFieldReference_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"classifier\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(((Classifier)SNodeOperations.getAdapter(classifier)), IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> staticMethods = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, staticMethods);\n    List<SNode> allStaticMembers = classHierarchy.getNodes();\n    ListOperations.addAllElements(result, SequenceOperations.where(allStaticMembers, new zPredicate(null, null)));\n    return result;\n  }","commit_id":"281b2c9438f71621807f2f53895bed3f2511d19b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> replaceNodeMenu_EnumConstantReference_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"enumClass\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope((Classifier)BaseAdapter.fromNode(classifier), IClassifiersSearchScope.STATIC_MEMBER);\n    List staticFields = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, (List<SNode>)staticFields);\n    List staticMethods = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, (List<SNode>)staticMethods);\n    return result;\n  }","id":36069,"modified_method":"public static List<SNode> replaceNodeMenu_EnumConstantReference_getParameterObjects(SNode node) {\n    List<SNode> result = new LinkedList<SNode>();\n    SNode classifier = SLinkOperations.getTarget(node, \"enumClass\", false);\n    if(classifier == null) {\n      return result;\n    }\n    ISearchScope classHierarchy = BaseLanguageSearchUtil_new.createClassifierHierarchyScope(((Classifier)SNodeOperations.getAdapter(classifier)), IClassifiersSearchScope.STATIC_MEMBER);\n    List<SNode> staticFields = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getFieldsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, staticFields);\n    List<SNode> staticMethods = BaseAdapter.toNodes(BaseLanguageSearchUtil_new.getMethodsExcludingOverridden(classHierarchy));\n    ListOperations.addAllElements(result, staticMethods);\n    return result;\n  }","commit_id":"281b2c9438f71621807f2f53895bed3f2511d19b","url":"https://github.com/JetBrains/MPS"},{"original_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_2_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CLASS, WEIGHT)\n                    .addRejectCheck(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .setValueConverter(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .end();\n        }\n    }","id":36070,"modified_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CLASS, WEIGHT)\n                    .addRejectCheck(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .setValueConverter(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .end();\n        }\n    }","commit_id":"42bf9782c40046b504b525dde17ba30c70e42477","url":"https://github.com/wildfly/wildfly"},{"original_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_2_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, DECAY, HISTORY)\n                    .end();\n        }\n\n        LoadMetricDefinition.buildTransformation(version, builder);\n        CustomLoadMetricDefinition.buildTransformation(version, builder);\n    }","id":36071,"modified_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        ResourceTransformationDescriptionBuilder loadProviderBuilder = builder.addChildResource(PATH);\n\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version)) {\n            loadProviderBuilder\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, DECAY, HISTORY)\n                    .end();\n        }\n\n        LoadMetricDefinition.buildTransformation(version, loadProviderBuilder);\n        CustomLoadMetricDefinition.buildTransformation(version, loadProviderBuilder);\n    }","commit_id":"42bf9782c40046b504b525dde17ba30c70e42477","url":"https://github.com/wildfly/wildfly"},{"original_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_2_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, TYPE, WEIGHT, CAPACITY, PROPERTY)\n                    .addRejectCheck(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .setValueConverter(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .addRejectCheck(PropertyCheckerAndConverter.INSTANCE, PROPERTY)\n                    .setValueConverter(PropertyCheckerAndConverter.INSTANCE, PROPERTY)\n                    .end();\n        }\n    }","id":36072,"modified_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, TYPE, WEIGHT, CAPACITY, PROPERTY)\n                    .addRejectCheck(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .setValueConverter(CapacityCheckerAndConverter.INSTANCE, CAPACITY)\n                    .addRejectCheck(PropertyCheckerAndConverter.INSTANCE, PROPERTY)\n                    .setValueConverter(PropertyCheckerAndConverter.INSTANCE, PROPERTY)\n                    .end();\n        }\n    }","commit_id":"42bf9782c40046b504b525dde17ba30c70e42477","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder parent) {\n        ResourceTransformationDescriptionBuilder builder = parent.addChildResource(PATH);\n\n        if (ModClusterModel.VERSION_2_0_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    // Discard if using default value, reject if set to other than previously hard-coded default of 10 seconds\n                    .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(STATUS_INTERVAL.getDefaultValue()), STATUS_INTERVAL)\n                    .addRejectCheck(new RejectAttributeChecker.SimpleAcceptAttributeChecker(STATUS_INTERVAL.getDefaultValue()), STATUS_INTERVAL)\n                    .end();\n        }\n\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version) || ModClusterModel.VERSION_1_4_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    .addRejectCheck(SessionDrainingStrategyChecker.INSTANCE, SESSION_DRAINING_STRATEGY)\n                    .setDiscard(SessionDrainingStrategyChecker.INSTANCE, SESSION_DRAINING_STRATEGY)\n                    .end();\n        }\n\n        if (ModClusterModel.VERSION_1_2_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, ADVERTISE, AUTO_ENABLE_CONTEXTS, FLUSH_PACKETS, STICKY_SESSION, STICKY_SESSION_REMOVE, STICKY_SESSION_FORCE, PING)\n                    .end();\n        }\n\n        DynamicLoadProviderDefinition.buildTransformation(version, builder);\n        ModClusterSSLResourceDefinition.buildTransformation(version, builder);\n    }","id":36073,"modified_method":"public static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder parent) {\n        ResourceTransformationDescriptionBuilder builder = parent.addChildResource(PATH);\n\n        if (ModClusterModel.VERSION_3_0_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    // Discard if using default value, reject if set to other than previously hard-coded default of 10 seconds\n                    .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(STATUS_INTERVAL.getDefaultValue()), STATUS_INTERVAL)\n                    .addRejectCheck(new RejectAttributeChecker.SimpleAcceptAttributeChecker(STATUS_INTERVAL.getDefaultValue()), STATUS_INTERVAL)\n                    .end();\n        }\n\n        if (ModClusterModel.VERSION_2_0_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    .addRejectCheck(SessionDrainingStrategyChecker.INSTANCE, SESSION_DRAINING_STRATEGY)\n                    .setDiscard(SessionDrainingStrategyChecker.INSTANCE, SESSION_DRAINING_STRATEGY)\n                    .end();\n        }\n\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version)) {\n            builder.getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, ADVERTISE, AUTO_ENABLE_CONTEXTS, FLUSH_PACKETS, STICKY_SESSION, STICKY_SESSION_REMOVE, STICKY_SESSION_FORCE, PING)\n                    .end();\n        }\n\n        DynamicLoadProviderDefinition.buildTransformation(version, builder);\n        ModClusterSSLResourceDefinition.buildTransformation(version, builder);\n    }","commit_id":"42bf9782c40046b504b525dde17ba30c70e42477","url":"https://github.com/wildfly/wildfly"},{"original_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_2_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CIPHER_SUITE, KEY_ALIAS, PROTOCOL);\n        }\n    }","id":36074,"modified_method":"static void buildTransformation(ModelVersion version, ResourceTransformationDescriptionBuilder builder) {\n        if (ModClusterModel.VERSION_1_3_0.requiresTransformation(version)) {\n            builder.addChildResource(PATH)\n                    .getAttributeBuilder()\n                    .addRejectCheck(RejectAttributeChecker.SIMPLE_EXPRESSIONS, CIPHER_SUITE, KEY_ALIAS, PROTOCOL);\n        }\n    }","commit_id":"42bf9782c40046b504b525dde17ba30c70e42477","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test public void testSimpleAllMappersWithReparseWithStore() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/store-mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        String builtMapping = docMapper.buildSource();\n        System.out.println(builtMapping);\n        // reparse it\n        XContentDocumentMapper builtDocMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(builtMapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = builtDocMapper.parse(json).doc();\n\n        Field field = doc.getField(\"_all\");\n        AllEntries allEntries = ((AllTokenFilter) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n\n        String text = field.stringValue();\n        assertThat(text, equalTo(allEntries.buildText()));\n    }","id":36075,"modified_method":"@Test public void testSimpleAllMappersWithReparseWithStore() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/store-mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        String builtMapping = docMapper.buildSource();\n        System.out.println(builtMapping);\n        // reparse it\n        XContentDocumentMapper builtDocMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(builtMapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = builtDocMapper.parse(json).doc();\n\n        AllField field = (AllField) doc.getFieldable(\"_all\");\n        AllEntries allEntries = ((AllTokenStream) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n\n        String text = field.stringValue();\n        assertThat(text, equalTo(allEntries.buildText()));\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testSimpleAllMappersWithStore() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/store-mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = docMapper.parse(json).doc();\n        Field field = doc.getField(\"_all\");\n        AllEntries allEntries = ((AllTokenFilter) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n\n        String text = field.stringValue();\n        assertThat(text, equalTo(allEntries.buildText()));\n    }","id":36076,"modified_method":"@Test public void testSimpleAllMappersWithStore() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/store-mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = docMapper.parse(json).doc();\n        AllField field = (AllField) doc.getFieldable(\"_all\");\n        AllEntries allEntries = ((AllTokenStream) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n\n        String text = field.stringValue();\n        assertThat(text, equalTo(allEntries.buildText()));\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testSimpleAllMappers() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = docMapper.parse(json).doc();\n        Field field = doc.getField(\"_all\");\n        AllEntries allEntries = ((AllTokenFilter) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n    }","id":36077,"modified_method":"@Test public void testSimpleAllMappers() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = docMapper.parse(json).doc();\n        AllField field = (AllField) doc.getFieldable(\"_all\");\n        AllEntries allEntries = ((AllTokenStream) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testSimpleAllMappersWithReparse() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        String builtMapping = docMapper.buildSource();\n//        System.out.println(builtMapping);\n        // reparse it\n        XContentDocumentMapper builtDocMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(builtMapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = builtDocMapper.parse(json).doc();\n\n        Field field = doc.getField(\"_all\");\n        AllEntries allEntries = ((AllTokenFilter) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n    }","id":36078,"modified_method":"@Test public void testSimpleAllMappersWithReparse() throws Exception {\n        String mapping = copyToStringFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/mapping.json\");\n        XContentDocumentMapper docMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(mapping);\n        String builtMapping = docMapper.buildSource();\n//        System.out.println(builtMapping);\n        // reparse it\n        XContentDocumentMapper builtDocMapper = (XContentDocumentMapper) new XContentDocumentMapperParser(new AnalysisService(new Index(\"test\"))).parse(builtMapping);\n        byte[] json = copyToBytesFromClasspath(\"/org/elasticsearch/index/mapper/xcontent/all/test1.json\");\n        Document doc = builtDocMapper.parse(json).doc();\n\n        AllField field = (AllField) doc.getFieldable(\"_all\");\n        AllEntries allEntries = ((AllTokenStream) field.tokenStreamValue()).allEntries();\n        assertThat(allEntries.fields().size(), equalTo(2));\n        assertThat(allEntries.fields().contains(\"name.last\"), equalTo(true));\n        assertThat(allEntries.fields().contains(\"simple1\"), equalTo(true));\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testMultipleTokensAllWithBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something moo\", 1.0f);\n        allEntries.addText(\"field2\", \"else koo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else koo\", 2.0f);\n        allEntries.addText(\"field2\", \"something moo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"koo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"moo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","id":36079,"modified_method":"@Test public void testMultipleTokensAllWithBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something moo\", 1.0f);\n        allEntries.addText(\"field2\", \"else koo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else koo\", 2.0f);\n        allEntries.addText(\"field2\", \"something moo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"koo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"moo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testSimpleAllWithBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something\", 1.0f);\n        allEntries.addText(\"field2\", \"else\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else\", 2.0f);\n        allEntries.addText(\"field2\", \"something\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        // this one is boosted. so the second doc is more relevant\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","id":36080,"modified_method":"@Test public void testSimpleAllWithBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something\", 1.0f);\n        allEntries.addText(\"field2\", \"else\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else\", 2.0f);\n        allEntries.addText(\"field2\", \"something\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        // this one is boosted. so the second doc is more relevant\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(1));\n        assertThat(docs.scoreDocs[1].doc, equalTo(0));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testMultipleTokensAllNoBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something moo\", 1.0f);\n        allEntries.addText(\"field2\", \"else koo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else koo\", 1.0f);\n        allEntries.addText(\"field2\", \"something moo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"koo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"moo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","id":36081,"modified_method":"@Test public void testMultipleTokensAllNoBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something moo\", 1.0f);\n        allEntries.addText(\"field2\", \"else koo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else koo\", 1.0f);\n        allEntries.addText(\"field2\", \"something moo\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"koo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"moo\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test public void testSimpleAllNoBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something\", 1.0f);\n        allEntries.addText(\"field2\", \"else\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else\", 1.0f);\n        allEntries.addText(\"field2\", \"something\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenFilter.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","id":36082,"modified_method":"@Test public void testSimpleAllNoBoost() throws Exception {\n        Directory dir = new RAMDirectory();\n        IndexWriter indexWriter = new IndexWriter(dir, Lucene.STANDARD_ANALYZER, true, IndexWriter.MaxFieldLength.UNLIMITED);\n\n        Document doc = new Document();\n        doc.add(new Field(\"_id\", \"1\", Field.Store.YES, Field.Index.NO));\n        AllEntries allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"something\", 1.0f);\n        allEntries.addText(\"field2\", \"else\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        doc = new Document();\n        doc.add(new Field(\"_id\", \"2\", Field.Store.YES, Field.Index.NO));\n        allEntries = new AllEntries();\n        allEntries.addText(\"field1\", \"else\", 1.0f);\n        allEntries.addText(\"field2\", \"something\", 1.0f);\n        allEntries.reset();\n        doc.add(new Field(\"_all\", AllTokenStream.allTokenStream(\"_all\", allEntries, Lucene.STANDARD_ANALYZER)));\n\n        indexWriter.addDocument(doc);\n\n        IndexReader reader = indexWriter.getReader();\n        IndexSearcher searcher = new IndexSearcher(reader);\n\n        TopDocs docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"else\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        docs = searcher.search(new AllTermQuery(new Term(\"_all\", \"something\")), 10);\n        assertThat(docs.totalHits, equalTo(2));\n        assertThat(docs.scoreDocs[0].doc, equalTo(0));\n        assertThat(docs.scoreDocs[1].doc, equalTo(1));\n\n        searcher.close();\n\n        indexWriter.close();\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected Field parseCreateField(ParseContext context) throws IOException {\n        if (!enabled) {\n            return null;\n        }\n        // reset the entries\n        context.allEntries().reset();\n\n        Analyzer analyzer = findAnalyzer(context.docMapper());\n        TokenStream tokenStream = allTokenStream(names.indexName(), context.allEntries(), analyzer);\n        if (stored()) {\n            // TODO when its possible to pass char[] to field, we can optimize\n            Field field = new Field(names.indexName(), context.allEntries().buildText(), store, index, termVector);\n            field.setTokenStream(tokenStream);\n            return field;\n        } else {\n            return new Field(names.indexName(), tokenStream, termVector);\n        }\n    }","id":36083,"modified_method":"@Override protected Fieldable parseCreateField(ParseContext context) throws IOException {\n        if (!enabled) {\n            return null;\n        }\n        // reset the entries\n        context.allEntries().reset();\n\n        Analyzer analyzer = findAnalyzer(context.docMapper());\n        return new AllField(names.indexName(), store, termVector, context.allEntries(), analyzer);\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected abstract Field parseCreateField(ParseContext context) throws IOException;","id":36084,"modified_method":"protected abstract Fieldable parseCreateField(ParseContext context) throws IOException;","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void parse(ParseContext context) throws IOException {\n        Field field = parseCreateField(context);\n        if (field == null) {\n            return;\n        }\n        field.setOmitNorms(omitNorms);\n        field.setOmitTermFreqAndPositions(omitTermFreqAndPositions);\n        field.setBoost(boost);\n        if (context.listener().beforeFieldAdded(this, field, context)) {\n            context.doc().add(field);\n        }\n    }","id":36085,"modified_method":"@Override public void parse(ParseContext context) throws IOException {\n        Fieldable field = parseCreateField(context);\n        if (field == null) {\n            return;\n        }\n        field.setOmitNorms(omitNorms);\n        field.setOmitTermFreqAndPositions(omitTermFreqAndPositions);\n        field.setBoost(boost);\n        if (context.listener().beforeFieldAdded(this, field, context)) {\n            context.doc().add(field);\n        }\n    }","commit_id":"23d2799d712838642ccffa70b83e09a2fc94cdd6","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Initializes affinity with given topology version and assignment. The assignment is calculated on remote nodes\n     * and brought to local node on partition map exchange.\n     *\n     * @param topVer Topology version.\n     * @param affAssignment Affinity assignment for topology version.\n     */\n    public void initialize(AffinityTopologyVersion topVer, List<List<ClusterNode>> affAssignment) {\n        GridAffinityAssignment assignment = new GridAffinityAssignment(topVer, affAssignment);\n\n        affCache.put(topVer, assignment);\n        head.set(assignment);\n\n        for (Map.Entry<AffinityTopologyVersion, AffinityReadyFuture> entry : readyFuts.entrySet()) {\n            if (entry.getKey().compareTo(topVer) >= 0)\n                entry.getValue().onDone(topVer);\n        }\n    }","id":36086,"modified_method":"/**\n     * Initializes affinity with given topology version and assignment. The assignment is calculated on remote nodes\n     * and brought to local node on partition map exchange.\n     *\n     * @param topVer Topology version.\n     * @param affAssignment Affinity assignment for topology version.\n     */\n    public void initialize(AffinityTopologyVersion topVer, List<List<ClusterNode>> affAssignment) {\n        GridAffinityAssignment assignment = new GridAffinityAssignment(topVer, affAssignment);\n\n        affCache.put(topVer, assignment);\n        head.set(assignment);\n\n        for (Map.Entry<AffinityTopologyVersion, AffinityReadyFuture> entry : readyFuts.entrySet()) {\n            if (entry.getKey().compareTo(topVer) <= 0) {\n                if (log.isDebugEnabled())\n                    log.debug(\"Completing topology ready future (initialized affinity) \" +\n                        \"[locNodeId=\" + ctx.localNodeId() + \", futVer=\" + entry.getKey() + \", topVer=\" + topVer + ']');\n\n                entry.getValue().onDone(topVer);\n            }\n        }\n    }","commit_id":"d7e8b59924265d9a1eb8e832d93d054d33ef4c9a","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @return Ignite Cache Failover test suite.\n     * @throws Exception Thrown in case of the failure.\n     */\n    public static TestSuite suite() throws Exception {\n        TestSuite suite = new TestSuite(\"Cache Failover Test Suite\");\n\n        suite.addTestSuite(GridCacheAtomicInvalidPartitionHandlingSelfTest.class);\n\n        suite.addTestSuite(GridCacheIncrementTransformTest.class);\n\n        // Failure consistency tests.\n        suite.addTestSuite(GridCacheAtomicRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderRemoveFailureTest.class);\n\n        suite.addTestSuite(GridCacheDhtAtomicRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheDhtRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheNearRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicNearRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderNearRemoveFailureTest.class);\n\n        suite.addTestSuite(GridCacheAtomicFailoverSelfTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderFailoverSelfTest.class);\n        suite.addTestSuite(GridCacheAtomicReplicatedFailoverSelfTest.class);\n\n        //suite.addTestSuite(GridCachePartitionedFailoverSelfTest.class);  TODO IGNITE-631.\n        //suite.addTestSuite(GridCacheColocatedFailoverSelfTest.class); TODO IGNITE-631.\n        //suite.addTestSuite(GridCacheReplicatedFailoverSelfTest.class); TODO IGNITE-631.\n\n        suite.addTestSuite(IgniteCacheAtomicNodeJoinTest.class);\n        suite.addTestSuite(IgniteCacheTxNodeJoinTest.class);\n\n        suite.addTestSuite(IgniteCacheTxNearDisabledPutGetRestartTest.class);\n\n        return suite;\n    }","id":36087,"modified_method":"/**\n     * @return Ignite Cache Failover test suite.\n     * @throws Exception Thrown in case of the failure.\n     */\n    public static TestSuite suite() throws Exception {\n        TestSuite suite = new TestSuite(\"Cache Failover Test Suite\");\n\n        suite.addTestSuite(GridCacheAtomicInvalidPartitionHandlingSelfTest.class);\n\n        suite.addTestSuite(GridCacheIncrementTransformTest.class);\n\n        // Failure consistency tests.\n        suite.addTestSuite(GridCacheAtomicRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderRemoveFailureTest.class);\n\n        suite.addTestSuite(GridCacheDhtAtomicRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheDhtRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheNearRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicNearRemoveFailureTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderNearRemoveFailureTest.class);\n\n        suite.addTestSuite(GridCacheAtomicFailoverSelfTest.class);\n        suite.addTestSuite(GridCacheAtomicPrimaryWriteOrderFailoverSelfTest.class);\n        suite.addTestSuite(GridCacheAtomicReplicatedFailoverSelfTest.class);\n\n        //suite.addTestSuite(GridCachePartitionedFailoverSelfTest.class);  TODO IGNITE-631.\n        //suite.addTestSuite(GridCacheColocatedFailoverSelfTest.class); TODO IGNITE-631.\n        //suite.addTestSuite(GridCacheReplicatedFailoverSelfTest.class); TODO IGNITE-631.\n\n        suite.addTestSuite(IgniteCacheAtomicNodeJoinTest.class);\n        suite.addTestSuite(IgniteCacheTxNodeJoinTest.class);\n        suite.addTestSuite(IgniteCacheTxFairAffinityNodeJoinTest.class);\n\n        //suite.addTestSuite(IgniteCacheTxNearDisabledPutGetRestartTest.class);\n\n        return suite;\n    }","commit_id":"d7e8b59924265d9a1eb8e832d93d054d33ef4c9a","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @throws Exception If failed.\n     */\n    public void testTxPutGetRestart() throws Exception {\n        final IgniteTransactions txs = ignite(0).transactions();\n\n        final IgniteCache<Integer, Integer> cache = jcache(0);\n\n        updateCache(cache, txs);\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> updateFut = GridTestUtils.runAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                assertTrue(latch.await(30_000, TimeUnit.MILLISECONDS));\n\n                int iter = 0;\n\n                while (!stop.get()) {\n                    log.info(\"Start update: \" + iter);\n\n                    synchronized (mux) {\n                        updateCache(cache, txs);\n                    }\n\n                    log.info(\"End update: \" + iter++);\n                }\n\n                log.info(\"Update iterations: \" + iter);\n\n                return null;\n            }\n        });\n\n        IgniteInternalFuture<?> restartFut = GridTestUtils.runAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                assertTrue(latch.await(30_000, TimeUnit.MILLISECONDS));\n\n                while (!stop.get()) {\n                    log.info(\"Stop node.\");\n\n                    stopGrid(1);\n\n                    U.sleep(100);\n\n                    log.info(\"Start node.\");\n\n                    startGrid(1);\n\n                    U.sleep(100);\n                }\n\n                return null;\n            }\n        });\n\n        long endTime = System.currentTimeMillis() + 2 * 60_000;\n\n        try {\n            int iter = 0;\n\n            while (System.currentTimeMillis() < endTime) {\n                try {\n                    log.info(\"Start get: \" + iter);\n\n                    synchronized (mux) {\n                        readCache(cache, txs);\n                    }\n\n                    log.info(\"End get: \" + iter++);\n                }\n                finally {\n                    if (latch.getCount() > 0)\n                        latch.countDown();\n                }\n            }\n\n            log.info(\"Get iterations: \" + iter);\n        }\n        finally {\n            stop.set(true);\n        }\n\n        updateFut.get();\n\n        restartFut.get();\n\n        readCache(cache, txs);\n    }","id":36088,"modified_method":"/**\n     * @throws Exception If failed.\n     */\n    public void testTxPutGetRestart() throws Exception {\n        int clientGrid = gridCount() - 1;\n\n        assertTrue(ignite(clientGrid).configuration().isClientMode());\n\n        final IgniteTransactions txs = ignite(clientGrid).transactions();\n\n        final IgniteCache<Integer, Integer> cache = jcache(clientGrid);\n\n        updateCache(cache, txs);\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> updateFut = GridTestUtils.runAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                Thread.currentThread().setName(\"update-thread\");\n\n                assertTrue(latch.await(30_000, TimeUnit.MILLISECONDS));\n\n                int iter = 0;\n\n                while (!stop.get()) {\n                    log.info(\"Start update: \" + iter);\n\n                    synchronized (mux) {\n                        updateCache(cache, txs);\n                    }\n\n                    log.info(\"End update: \" + iter++);\n                }\n\n                log.info(\"Update iterations: \" + iter);\n\n                return null;\n            }\n        });\n\n        IgniteInternalFuture<?> restartFut = GridTestUtils.runAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                Thread.currentThread().setName(\"restart-thread\");\n\n                ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                while (!stop.get()) {\n                    assertTrue(latch.await(30_000, TimeUnit.MILLISECONDS));\n\n                    int node = rnd.nextInt(0, gridCount() - 1);\n\n                    log.info(\"Stop node: \" + node);\n\n                    stopGrid(node);\n\n                    U.sleep(100);\n\n                    log.info(\"Start node: \" + node);\n\n                    startGrid(node);\n\n                    latch = new CountDownLatch(1);\n\n                    U.sleep(100);\n                }\n\n                return null;\n            }\n        });\n\n        long endTime = System.currentTimeMillis() + 2 * 60_000;\n\n        try {\n            int iter = 0;\n\n            while (System.currentTimeMillis() < endTime && !updateFut.isDone() && !restartFut.isDone()) {\n                try {\n                    log.info(\"Start get: \" + iter);\n\n                    synchronized (mux) {\n                        readCache(cache, txs);\n                    }\n\n                    log.info(\"End get: \" + iter++);\n                }\n                finally {\n                    latch.countDown();\n                }\n            }\n\n            log.info(\"Get iterations: \" + iter);\n        }\n        finally {\n            latch.countDown();\n\n            stop.set(true);\n        }\n\n        updateFut.get();\n\n        restartFut.get();\n\n        readCache(cache, txs);\n    }","commit_id":"d7e8b59924265d9a1eb8e832d93d054d33ef4c9a","url":"https://github.com/apache/ignite"},{"original_method":"/** {@inheritDoc} */\n    @Override protected IgniteConfiguration getConfiguration(String gridName) throws Exception {\n        IgniteConfiguration cfg = super.getConfiguration(gridName);\n\n        if (gridName.equals(getTestGridName(0)))\n            cfg.setClientMode(true);\n\n        cfg.setPeerClassLoadingEnabled(false);\n\n        return cfg;\n    }","id":36089,"modified_method":"/** {@inheritDoc} */\n    @Override protected IgniteConfiguration getConfiguration(String gridName) throws Exception {\n        IgniteConfiguration cfg = super.getConfiguration(gridName);\n\n        if (gridName.equals(getTestGridName(gridCount() - 1)))\n            cfg.setClientMode(true);\n\n        cfg.setPeerClassLoadingEnabled(false);\n\n        return cfg;\n    }","commit_id":"d7e8b59924265d9a1eb8e832d93d054d33ef4c9a","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @param node Node.\n     * @param id ID.\n     * @throws IgniteCheckedException If failed.\n     */\n    private void sendLocalPartitions(ClusterNode node, @Nullable GridDhtPartitionExchangeId id) throws IgniteCheckedException {\n        GridDhtPartitionsSingleMessage m = new GridDhtPartitionsSingleMessage(id,\n            cctx.kernalContext().clientNode(),\n            cctx.versions().last());\n\n        for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n            if (!cacheCtx.isLocal())\n                m.addLocalPartitionMap(cacheCtx.cacheId(), cacheCtx.topology().localPartitionMap());\n        }\n\n        if (log.isDebugEnabled())\n            log.debug(\"Sending local partitions [nodeId=\" + node.id() + \", exchId=\" + exchId + \", msg=\" + m + ']');\n\n        cctx.io().send(node, m, SYSTEM_POOL);\n    }","id":36090,"modified_method":"/**\n     * @param node Node.\n     * @param id ID.\n     * @throws IgniteCheckedException If failed.\n     */\n    private void sendLocalPartitions(ClusterNode node, @Nullable GridDhtPartitionExchangeId id) throws IgniteCheckedException {\n        GridDhtPartitionsSingleMessage m = new GridDhtPartitionsSingleMessage(id,\n            clientOnlyExchange,\n            cctx.versions().last());\n\n        for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n            if (!cacheCtx.isLocal())\n                m.addLocalPartitionMap(cacheCtx.cacheId(), cacheCtx.topology().localPartitionMap());\n        }\n\n        if (log.isDebugEnabled())\n            log.debug(\"Sending local partitions [nodeId=\" + node.id() + \", exchId=\" + exchId + \", msg=\" + m + ']');\n\n        cctx.io().send(node, m, SYSTEM_POOL);\n    }","commit_id":"a6cda33a8b76925d09c21262e88467421025fa77","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Starts activity.\n     *\n     * @throws IgniteInterruptedCheckedException If interrupted.\n     */\n    public void init() throws IgniteInterruptedCheckedException {\n        if (isDone())\n            return;\n\n        if (init.compareAndSet(false, true)) {\n            if (isDone())\n                return;\n\n            try {\n                // Wait for event to occur to make sure that discovery\n                // will return corresponding nodes.\n                U.await(evtLatch);\n\n                assert discoEvt != null : this;\n                assert !dummy && !forcePreload : this;\n\n                ClusterNode oldest = CU.oldestAliveCacheServerNode(cctx, exchId.topologyVersion());\n\n                oldestNode.set(oldest);\n\n                startCaches();\n\n                // True if client node joined or failed.\n                boolean clientNodeEvt;\n\n                if (F.isEmpty(reqs)) {\n                    int type = discoEvt.type();\n\n                    assert type == EVT_NODE_JOINED || type == EVT_NODE_LEFT || type == EVT_NODE_FAILED : discoEvt;\n\n                    clientNodeEvt = CU.clientNode(discoEvt.eventNode());\n                }\n                else {\n                    assert discoEvt.type() == EVT_DISCOVERY_CUSTOM_EVT : discoEvt;\n\n                    boolean clientOnlyStart = true;\n\n                    for (DynamicCacheChangeRequest req : reqs) {\n                        if (!req.clientStartOnly()) {\n                            clientOnlyStart = false;\n\n                            break;\n                        }\n                    }\n\n                    clientNodeEvt = clientOnlyStart;\n                }\n\n                if (clientNodeEvt) {\n                    ClusterNode node = discoEvt.eventNode();\n\n                    // Client need to initialize affinity for local join event or for stated client caches.\n                    if (!node.isLocal()) {\n                        for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                            if (cacheCtx.isLocal())\n                                continue;\n\n                            GridDhtPartitionTopology top = cacheCtx.topology();\n\n                            top.updateTopologyVersion(exchId, this, -1, stopping(cacheCtx.cacheId()));\n\n                            if (cacheCtx.affinity().affinityTopologyVersion() == AffinityTopologyVersion.NONE) {\n                                initTopology(cacheCtx);\n\n                                top.beforeExchange(this);\n                            }\n                            else\n                                cacheCtx.affinity().clientEventTopologyChange(discoEvt, exchId.topologyVersion());\n                        }\n\n                        if (exchId.isLeft())\n                            cctx.mvcc().removeExplicitNodeLocks(exchId.nodeId(), exchId.topologyVersion());\n\n                        onDone(exchId.topologyVersion());\n\n                        skipPreload = cctx.kernalContext().clientNode();\n\n                        return;\n                    }\n                }\n\n                if (cctx.kernalContext().clientNode()) {\n                    skipPreload = true;\n\n                    for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                        if (cacheCtx.isLocal())\n                            continue;\n\n                        GridDhtPartitionTopology top = cacheCtx.topology();\n\n                        top.updateTopologyVersion(exchId, this, -1, stopping(cacheCtx.cacheId()));\n                    }\n\n                    for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                        if (cacheCtx.isLocal())\n                            continue;\n\n                        initTopology(cacheCtx);\n                    }\n\n                    if (oldestNode.get() != null) {\n                        rmtNodes = new ConcurrentLinkedQueue<>(CU.aliveRemoteServerNodesWithCaches(cctx,\n                            exchId.topologyVersion()));\n\n                        rmtIds = Collections.unmodifiableSet(new HashSet<>(F.nodeIds(rmtNodes)));\n\n                        ready.set(true);\n\n                        initFut.onDone(true);\n\n                        if (log.isDebugEnabled())\n                            log.debug(\"Initialized future: \" + this);\n\n                        sendPartitions();\n                    }\n                    else\n                        onDone(exchId.topologyVersion());\n\n                    return;\n                }\n\n                assert oldestNode.get() != null;\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (isCacheAdded(cacheCtx.cacheId(), exchId.topologyVersion())) {\n                        if (cacheCtx.discovery().cacheAffinityNodes(cacheCtx.name(), topologyVersion()).isEmpty())\n                            U.quietAndWarn(log, \"No server nodes found for cache client: \" + cacheCtx.namex());\n                    }\n\n                    cacheCtx.preloader().onExchangeFutureAdded();\n                }\n\n                List<String> cachesWithoutNodes = null;\n\n                if (exchId.isLeft()) {\n                    for (String name : cctx.cache().cacheNames()) {\n                        if (cctx.discovery().cacheAffinityNodes(name, topologyVersion()).isEmpty()) {\n                            if (cachesWithoutNodes == null)\n                                cachesWithoutNodes = new ArrayList<>();\n\n                            cachesWithoutNodes.add(name);\n\n                            // Fire event even if there is no client cache started.\n                            if (cctx.gridEvents().isRecordable(EventType.EVT_CACHE_NODES_LEFT)) {\n                                Event evt = new CacheEvent(\n                                    name,\n                                    cctx.localNode(),\n                                    cctx.localNode(),\n                                    \"All server nodes have left the cluster.\",\n                                    EventType.EVT_CACHE_NODES_LEFT,\n                                    0,\n                                    false,\n                                    null,\n                                    null,\n                                    null,\n                                    null,\n                                    false,\n                                    null,\n                                    false,\n                                    null,\n                                    null,\n                                    null\n                                );\n\n                                cctx.gridEvents().record(evt);\n                            }\n                        }\n                    }\n                }\n\n                if (cachesWithoutNodes != null) {\n                    StringBuilder sb =\n                        new StringBuilder(\"All server nodes for the following caches have left the cluster: \");\n\n                    for (int i = 0; i < cachesWithoutNodes.size(); i++) {\n                        String cache = cachesWithoutNodes.get(i);\n\n                        sb.append('\\'').append(cache).append('\\'');\n\n                        if (i != cachesWithoutNodes.size() - 1)\n                            sb.append(\", \");\n                    }\n\n                    U.quietAndWarn(log, sb.toString());\n\n                    U.quietAndWarn(log, \"Must have server nodes for caches to operate.\");\n                }\n\n                assert discoEvt != null;\n\n                assert exchId.nodeId().equals(discoEvt.eventNode().id());\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    GridClientPartitionTopology clientTop = cctx.exchange().clearClientTopology(\n                        cacheCtx.cacheId());\n\n                    long updSeq = clientTop == null ? -1 : clientTop.lastUpdateSequence();\n\n                    // Update before waiting for locks.\n                    if (!cacheCtx.isLocal())\n                        cacheCtx.topology().updateTopologyVersion(exchId, this, updSeq, stopping(cacheCtx.cacheId()));\n                }\n\n                // Grab all alive remote nodes with order of equal or less than last joined node.\n                rmtNodes = new ConcurrentLinkedQueue<>(CU.aliveRemoteServerNodesWithCaches(cctx,\n                    exchId.topologyVersion()));\n\n                rmtIds = Collections.unmodifiableSet(new HashSet<>(F.nodeIds(rmtNodes)));\n\n                for (Map.Entry<UUID, GridDhtPartitionsSingleMessage> m : singleMsgs.entrySet())\n                    // If received any messages, process them.\n                    onReceive(m.getKey(), m.getValue());\n\n                for (Map.Entry<UUID, GridDhtPartitionsFullMessage> m : fullMsgs.entrySet())\n                    // If received any messages, process them.\n                    onReceive(m.getKey(), m.getValue());\n\n                AffinityTopologyVersion topVer = exchId.topologyVersion();\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (cacheCtx.isLocal())\n                        continue;\n\n                    // Must initialize topology after we get discovery event.\n                    initTopology(cacheCtx);\n\n                    cacheCtx.preloader().updateLastExchangeFuture(this);\n                }\n\n                IgniteInternalFuture<?> partReleaseFut = cctx.partitionReleaseFuture(topVer);\n\n                // Assign to class variable so it will be included into toString() method.\n                this.partReleaseFut = partReleaseFut;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Before waiting for partition release future: \" + this);\n\n                while (true) {\n                    try {\n                        partReleaseFut.get(2 * cctx.gridConfig().getNetworkTimeout(), TimeUnit.MILLISECONDS);\n\n                        break;\n                    }\n                    catch (IgniteFutureTimeoutCheckedException ignored) {\n                        // Print pending transactions and locks that might have led to hang.\n                        dumpPendingObjects();\n                    }\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"After waiting for partition release future: \" + this);\n\n                if (!F.isEmpty(reqs))\n                    blockGateways();\n\n                if (exchId.isLeft())\n                    cctx.mvcc().removeExplicitNodeLocks(exchId.nodeId(), exchId.topologyVersion());\n\n                IgniteInternalFuture<?> locksFut = cctx.mvcc().finishLocks(exchId.topologyVersion());\n\n                while (true) {\n                    try {\n                        locksFut.get(2 * cctx.gridConfig().getNetworkTimeout(), TimeUnit.MILLISECONDS);\n\n                        break;\n                    }\n                    catch (IgniteFutureTimeoutCheckedException ignored) {\n                        U.warn(log, \"Failed to wait for locks release future. \" +\n                            \"Dumping pending objects that might be the cause: \" + cctx.localNodeId());\n\n                        U.warn(log, \"Locked entries:\");\n\n                        Map<IgniteTxKey, Collection<GridCacheMvccCandidate>> locks =\n                            cctx.mvcc().unfinishedLocks(exchId.topologyVersion());\n\n                        for (Map.Entry<IgniteTxKey, Collection<GridCacheMvccCandidate>> e : locks.entrySet())\n                            U.warn(log, \"Locked entry [key=\" + e.getKey() + \", mvcc=\" + e.getValue() + ']');\n                    }\n                }\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (cacheCtx.isLocal())\n                        continue;\n\n                    // Notify replication manager.\n                    GridCacheContext drCacheCtx = cacheCtx.isNear() ? cacheCtx.near().dht().context() : cacheCtx;\n\n                    if (drCacheCtx.isDrEnabled())\n                        drCacheCtx.dr().beforeExchange(topVer, exchId.isLeft());\n\n                    // Partition release future is done so we can flush the write-behind store.\n                    cacheCtx.store().forceFlush();\n\n                    // Process queued undeploys prior to sending/spreading map.\n                    cacheCtx.preloader().unwindUndeploys();\n\n                    GridDhtPartitionTopology top = cacheCtx.topology();\n\n                    assert topVer.equals(top.topologyVersion()) :\n                        \"Topology version is updated only in this class instances inside single ExchangeWorker thread.\";\n\n                    top.beforeExchange(this);\n                }\n\n                for (GridClientPartitionTopology top : cctx.exchange().clientTopologies()) {\n                    top.updateTopologyVersion(exchId, this, -1, stopping(top.cacheId()));\n\n                    top.beforeExchange(this);\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                onDone(e);\n\n                throw e;\n            }\n            catch (Throwable e) {\n                U.error(log, \"Failed to reinitialize local partitions (preloading will be stopped): \" + exchId, e);\n\n                onDone(e);\n\n                if (e instanceof Error)\n                    throw (Error)e;\n\n                return;\n            }\n\n            if (F.isEmpty(rmtIds)) {\n                onDone(exchId.topologyVersion());\n\n                return;\n            }\n\n            ready.set(true);\n\n            initFut.onDone(true);\n\n            if (log.isDebugEnabled())\n                log.debug(\"Initialized future: \" + this);\n\n            // If this node is not oldest.\n            if (!oldestNode.get().id().equals(cctx.localNodeId()))\n                sendPartitions();\n            else {\n                boolean allReceived = allReceived();\n\n                if (allReceived && replied.compareAndSet(false, true)) {\n                    if (spreadPartitions())\n                        onDone(exchId.topologyVersion());\n                }\n            }\n\n            scheduleRecheck();\n        }\n        else\n            assert false : \"Skipped init future: \" + this;\n    }","id":36091,"modified_method":"/**\n     * Starts activity.\n     *\n     * @throws IgniteInterruptedCheckedException If interrupted.\n     */\n    public void init() throws IgniteInterruptedCheckedException {\n        if (isDone())\n            return;\n\n        if (init.compareAndSet(false, true)) {\n            if (isDone())\n                return;\n\n            try {\n                // Wait for event to occur to make sure that discovery\n                // will return corresponding nodes.\n                U.await(evtLatch);\n\n                assert discoEvt != null : this;\n                assert !dummy && !forcePreload : this;\n\n                ClusterNode oldest = CU.oldestAliveCacheServerNode(cctx, exchId.topologyVersion());\n\n                oldestNode.set(oldest);\n\n                startCaches();\n\n                // True if client node joined or failed.\n                boolean clientNodeEvt;\n\n                if (F.isEmpty(reqs)) {\n                    int type = discoEvt.type();\n\n                    assert type == EVT_NODE_JOINED || type == EVT_NODE_LEFT || type == EVT_NODE_FAILED : discoEvt;\n\n                    clientNodeEvt = CU.clientNode(discoEvt.eventNode());\n                }\n                else {\n                    assert discoEvt.type() == EVT_DISCOVERY_CUSTOM_EVT : discoEvt;\n\n                    boolean clientOnlyStart = true;\n\n                    for (DynamicCacheChangeRequest req : reqs) {\n                        if (!req.clientStartOnly()) {\n                            clientOnlyStart = false;\n\n                            break;\n                        }\n                    }\n\n                    clientNodeEvt = clientOnlyStart;\n                }\n\n                if (clientNodeEvt) {\n                    ClusterNode node = discoEvt.eventNode();\n\n                    // Client need to initialize affinity for local join event or for stated client caches.\n                    if (!node.isLocal()) {\n                        for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                            if (cacheCtx.isLocal())\n                                continue;\n\n                            GridDhtPartitionTopology top = cacheCtx.topology();\n\n                            top.updateTopologyVersion(exchId, this, -1, stopping(cacheCtx.cacheId()));\n\n                            if (cacheCtx.affinity().affinityTopologyVersion() == AffinityTopologyVersion.NONE) {\n                                initTopology(cacheCtx);\n\n                                top.beforeExchange(this);\n                            }\n                            else\n                                cacheCtx.affinity().clientEventTopologyChange(discoEvt, exchId.topologyVersion());\n                        }\n\n                        if (exchId.isLeft())\n                            cctx.mvcc().removeExplicitNodeLocks(exchId.nodeId(), exchId.topologyVersion());\n\n                        rmtIds = Collections.emptyList();\n                        rmtNodes = Collections.emptyList();\n\n                        onDone(exchId.topologyVersion());\n\n                        skipPreload = cctx.kernalContext().clientNode();\n\n                        return;\n                    }\n                }\n\n                clientOnlyExchange = clientNodeEvt || cctx.kernalContext().clientNode();\n\n                if (clientOnlyExchange) {\n                    skipPreload = cctx.kernalContext().clientNode();\n\n                    for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                        if (cacheCtx.isLocal())\n                            continue;\n\n                        GridDhtPartitionTopology top = cacheCtx.topology();\n\n                        top.updateTopologyVersion(exchId, this, -1, stopping(cacheCtx.cacheId()));\n                    }\n\n                    for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                        if (cacheCtx.isLocal())\n                            continue;\n\n                        initTopology(cacheCtx);\n                    }\n\n                    if (oldest != null) {\n                        rmtNodes = new ConcurrentLinkedQueue<>(CU.aliveRemoteServerNodesWithCaches(cctx,\n                            exchId.topologyVersion()));\n\n                        rmtIds = Collections.unmodifiableSet(new HashSet<>(F.nodeIds(rmtNodes)));\n\n                        initFut.onDone(true);\n\n                        if (log.isDebugEnabled())\n                            log.debug(\"Initialized future: \" + this);\n\n                        if (cctx.localNode().equals(oldest)) {\n                            for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                                boolean updateTop = !cacheCtx.isLocal() &&\n                                    exchId.topologyVersion().equals(cacheCtx.startTopologyVersion());\n\n                                if (updateTop) {\n                                    for (GridClientPartitionTopology top : cctx.exchange().clientTopologies()) {\n                                        if (top.cacheId() == cacheCtx.cacheId()) {\n                                            cacheCtx.topology().update(exchId, top.partitionMap(true));\n\n                                            break;\n                                        }\n                                    }\n\n                                }\n                            }\n\n                            onDone(exchId.topologyVersion());\n                        }\n                        else\n                            sendPartitions();\n                    }\n                    else {\n                        rmtIds = Collections.emptyList();\n                        rmtNodes = Collections.emptyList();\n\n                        onDone(exchId.topologyVersion());\n                    }\n\n                    return;\n                }\n\n                assert oldestNode.get() != null;\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (isCacheAdded(cacheCtx.cacheId(), exchId.topologyVersion())) {\n                        if (cacheCtx.discovery().cacheAffinityNodes(cacheCtx.name(), topologyVersion()).isEmpty())\n                            U.quietAndWarn(log, \"No server nodes found for cache client: \" + cacheCtx.namex());\n                    }\n\n                    cacheCtx.preloader().onExchangeFutureAdded();\n                }\n\n                List<String> cachesWithoutNodes = null;\n\n                if (exchId.isLeft()) {\n                    for (String name : cctx.cache().cacheNames()) {\n                        if (cctx.discovery().cacheAffinityNodes(name, topologyVersion()).isEmpty()) {\n                            if (cachesWithoutNodes == null)\n                                cachesWithoutNodes = new ArrayList<>();\n\n                            cachesWithoutNodes.add(name);\n\n                            // Fire event even if there is no client cache started.\n                            if (cctx.gridEvents().isRecordable(EventType.EVT_CACHE_NODES_LEFT)) {\n                                Event evt = new CacheEvent(\n                                    name,\n                                    cctx.localNode(),\n                                    cctx.localNode(),\n                                    \"All server nodes have left the cluster.\",\n                                    EventType.EVT_CACHE_NODES_LEFT,\n                                    0,\n                                    false,\n                                    null,\n                                    null,\n                                    null,\n                                    null,\n                                    false,\n                                    null,\n                                    false,\n                                    null,\n                                    null,\n                                    null\n                                );\n\n                                cctx.gridEvents().record(evt);\n                            }\n                        }\n                    }\n                }\n\n                if (cachesWithoutNodes != null) {\n                    StringBuilder sb =\n                        new StringBuilder(\"All server nodes for the following caches have left the cluster: \");\n\n                    for (int i = 0; i < cachesWithoutNodes.size(); i++) {\n                        String cache = cachesWithoutNodes.get(i);\n\n                        sb.append('\\'').append(cache).append('\\'');\n\n                        if (i != cachesWithoutNodes.size() - 1)\n                            sb.append(\", \");\n                    }\n\n                    U.quietAndWarn(log, sb.toString());\n\n                    U.quietAndWarn(log, \"Must have server nodes for caches to operate.\");\n                }\n\n                assert discoEvt != null;\n\n                assert exchId.nodeId().equals(discoEvt.eventNode().id());\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    GridClientPartitionTopology clientTop = cctx.exchange().clearClientTopology(\n                        cacheCtx.cacheId());\n\n                    long updSeq = clientTop == null ? -1 : clientTop.lastUpdateSequence();\n\n                    // Update before waiting for locks.\n                    if (!cacheCtx.isLocal())\n                        cacheCtx.topology().updateTopologyVersion(exchId, this, updSeq, stopping(cacheCtx.cacheId()));\n                }\n\n                // Grab all alive remote nodes with order of equal or less than last joined node.\n                rmtNodes = new ConcurrentLinkedQueue<>(CU.aliveRemoteServerNodesWithCaches(cctx,\n                    exchId.topologyVersion()));\n\n                rmtIds = Collections.unmodifiableSet(new HashSet<>(F.nodeIds(rmtNodes)));\n\n                for (Map.Entry<UUID, GridDhtPartitionsSingleMessage> m : singleMsgs.entrySet())\n                    // If received any messages, process them.\n                    onReceive(m.getKey(), m.getValue());\n\n                for (Map.Entry<UUID, GridDhtPartitionsFullMessage> m : fullMsgs.entrySet())\n                    // If received any messages, process them.\n                    onReceive(m.getKey(), m.getValue());\n\n                AffinityTopologyVersion topVer = exchId.topologyVersion();\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (cacheCtx.isLocal())\n                        continue;\n\n                    // Must initialize topology after we get discovery event.\n                    initTopology(cacheCtx);\n\n                    cacheCtx.preloader().updateLastExchangeFuture(this);\n                }\n\n                IgniteInternalFuture<?> partReleaseFut = cctx.partitionReleaseFuture(topVer);\n\n                // Assign to class variable so it will be included into toString() method.\n                this.partReleaseFut = partReleaseFut;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Before waiting for partition release future: \" + this);\n\n                while (true) {\n                    try {\n                        partReleaseFut.get(2 * cctx.gridConfig().getNetworkTimeout(), TimeUnit.MILLISECONDS);\n\n                        break;\n                    }\n                    catch (IgniteFutureTimeoutCheckedException ignored) {\n                        // Print pending transactions and locks that might have led to hang.\n                        dumpPendingObjects();\n                    }\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"After waiting for partition release future: \" + this);\n\n                if (!F.isEmpty(reqs))\n                    blockGateways();\n\n                if (exchId.isLeft())\n                    cctx.mvcc().removeExplicitNodeLocks(exchId.nodeId(), exchId.topologyVersion());\n\n                IgniteInternalFuture<?> locksFut = cctx.mvcc().finishLocks(exchId.topologyVersion());\n\n                while (true) {\n                    try {\n                        locksFut.get(2 * cctx.gridConfig().getNetworkTimeout(), TimeUnit.MILLISECONDS);\n\n                        break;\n                    }\n                    catch (IgniteFutureTimeoutCheckedException ignored) {\n                        U.warn(log, \"Failed to wait for locks release future. \" +\n                            \"Dumping pending objects that might be the cause: \" + cctx.localNodeId());\n\n                        U.warn(log, \"Locked entries:\");\n\n                        Map<IgniteTxKey, Collection<GridCacheMvccCandidate>> locks =\n                            cctx.mvcc().unfinishedLocks(exchId.topologyVersion());\n\n                        for (Map.Entry<IgniteTxKey, Collection<GridCacheMvccCandidate>> e : locks.entrySet())\n                            U.warn(log, \"Locked entry [key=\" + e.getKey() + \", mvcc=\" + e.getValue() + ']');\n                    }\n                }\n\n                for (GridCacheContext cacheCtx : cctx.cacheContexts()) {\n                    if (cacheCtx.isLocal())\n                        continue;\n\n                    // Notify replication manager.\n                    GridCacheContext drCacheCtx = cacheCtx.isNear() ? cacheCtx.near().dht().context() : cacheCtx;\n\n                    if (drCacheCtx.isDrEnabled())\n                        drCacheCtx.dr().beforeExchange(topVer, exchId.isLeft());\n\n                    // Partition release future is done so we can flush the write-behind store.\n                    cacheCtx.store().forceFlush();\n\n                    // Process queued undeploys prior to sending/spreading map.\n                    cacheCtx.preloader().unwindUndeploys();\n\n                    GridDhtPartitionTopology top = cacheCtx.topology();\n\n                    assert topVer.equals(top.topologyVersion()) :\n                        \"Topology version is updated only in this class instances inside single ExchangeWorker thread.\";\n\n                    top.beforeExchange(this);\n                }\n\n                for (GridClientPartitionTopology top : cctx.exchange().clientTopologies()) {\n                    top.updateTopologyVersion(exchId, this, -1, stopping(top.cacheId()));\n\n                    top.beforeExchange(this);\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                onDone(e);\n\n                throw e;\n            }\n            catch (Throwable e) {\n                U.error(log, \"Failed to reinitialize local partitions (preloading will be stopped): \" + exchId, e);\n\n                onDone(e);\n\n                if (e instanceof Error)\n                    throw (Error)e;\n\n                return;\n            }\n\n            if (F.isEmpty(rmtIds)) {\n                onDone(exchId.topologyVersion());\n\n                return;\n            }\n\n            ready.set(true);\n\n            initFut.onDone(true);\n\n            if (log.isDebugEnabled())\n                log.debug(\"Initialized future: \" + this);\n\n            // If this node is not oldest.\n            if (!oldestNode.get().id().equals(cctx.localNodeId()))\n                sendPartitions();\n            else {\n                boolean allReceived = allReceived();\n\n                if (allReceived && replied.compareAndSet(false, true)) {\n                    if (spreadPartitions())\n                        onDone(exchId.topologyVersion());\n                }\n            }\n\n            scheduleRecheck();\n        }\n        else\n            assert false : \"Skipped init future: \" + this;\n    }","commit_id":"a6cda33a8b76925d09c21262e88467421025fa77","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @param nearCache If {@code true} creates near cache on client.\n     * @throws Exception If failed.\n     */\n    private void clientOnlyCacheStart(boolean nearCache, boolean srvNode) throws Exception {\n        Ignite ignite0 = startGrid(0);\n        Ignite ignite1 = startGrid(1);\n\n        waitForTopologyUpdate(2, 2);\n\n        final String CACHE_NAME1 = \"cache1\";\n\n        CacheConfiguration ccfg = new CacheConfiguration();\n\n        ccfg.setName(CACHE_NAME1);\n\n        if (srvNode)\n            ccfg.setNodeFilter(new TestFilter(getTestGridName(2)));\n\n        ignite0.createCache(ccfg);\n\n        client = !srvNode;\n\n        Ignite ignite2 = startGrid(2);\n\n        waitForTopologyUpdate(3, 3);\n\n        TestCommunicationSpi spi0 = (TestCommunicationSpi)ignite0.configuration().getCommunicationSpi();\n        TestCommunicationSpi spi1 = (TestCommunicationSpi)ignite1.configuration().getCommunicationSpi();\n        TestCommunicationSpi spi2 = (TestCommunicationSpi)ignite2.configuration().getCommunicationSpi();\n\n        spi0.reset();\n        spi1.reset();\n        spi2.reset();\n\n        assertNull(((IgniteKernal)ignite2).context().cache().context().cache().internalCache(\"cache1\"));\n\n        if (nearCache)\n            ignite2.getOrCreateNearCache(CACHE_NAME1, new NearCacheConfiguration<>());\n        else\n            ignite2.cache(CACHE_NAME1);\n\n        waitForTopologyUpdate(3, new AffinityTopologyVersion(3, 1));\n\n        GridCacheAdapter cache = ((IgniteKernal)ignite2).context().cache().context().cache().internalCache(\"cache1\");\n\n        assertNotNull(cache);\n        assertEquals(nearCache, cache.context().isNear());\n\n        assertEquals(0, spi0.partitionsSingleMessages());\n        assertEquals(1, spi0.partitionsFullMessages());\n        assertEquals(0, spi1.partitionsSingleMessages());\n        assertEquals(0, spi1.partitionsFullMessages());\n        assertEquals(1, spi2.partitionsSingleMessages());\n        assertEquals(0, spi2.partitionsFullMessages());\n\n        ClusterNode clientNode = ((IgniteKernal)ignite2).localNode();\n\n        for (Ignite ignite : Ignition.allGrids()) {\n            GridDiscoveryManager disco = ((IgniteKernal)ignite).context().discovery();\n\n            assertTrue(disco.cacheNode(clientNode, CACHE_NAME1));\n            assertFalse(disco.cacheAffinityNode(clientNode, CACHE_NAME1));\n            assertEquals(nearCache, disco.cacheNearNode(clientNode, CACHE_NAME1));\n        }\n\n        spi0.reset();\n        spi1.reset();\n        spi2.reset();\n\n        final String CACHE_NAME2 = \"cache2\";\n\n        ccfg = new CacheConfiguration();\n\n        ccfg.setName(CACHE_NAME2);\n\n        ignite2.createCache(ccfg);\n\n        waitForTopologyUpdate(3, new AffinityTopologyVersion(3, 2));\n\n        assertEquals(0, spi0.partitionsSingleMessages());\n        assertEquals(2, spi0.partitionsFullMessages());\n        assertEquals(1, spi1.partitionsSingleMessages());\n        assertEquals(0, spi1.partitionsFullMessages());\n        assertEquals(1, spi2.partitionsSingleMessages());\n        assertEquals(0, spi2.partitionsFullMessages());\n    }","id":36092,"modified_method":"/**\n     * @param nearCache If {@code true} creates near cache on client.\n     * @param srvNode If {@code true} creates client cache on server node.\n     * @throws Exception If failed.\n     */\n    private void clientOnlyCacheStart(boolean nearCache, boolean srvNode) throws Exception {\n        Ignite ignite0 = startGrid(0);\n        Ignite ignite1 = startGrid(1);\n\n        waitForTopologyUpdate(2, 2);\n\n        final String CACHE_NAME1 = \"cache1\";\n\n        CacheConfiguration ccfg = new CacheConfiguration();\n\n        ccfg.setName(CACHE_NAME1);\n\n        if (srvNode)\n            ccfg.setNodeFilter(new TestFilter(getTestGridName(2)));\n\n        ignite0.createCache(ccfg);\n\n        client = !srvNode;\n\n        Ignite ignite2 = startGrid(2);\n\n        waitForTopologyUpdate(3, 3);\n\n        TestCommunicationSpi spi0 = (TestCommunicationSpi)ignite0.configuration().getCommunicationSpi();\n        TestCommunicationSpi spi1 = (TestCommunicationSpi)ignite1.configuration().getCommunicationSpi();\n        TestCommunicationSpi spi2 = (TestCommunicationSpi)ignite2.configuration().getCommunicationSpi();\n\n        spi0.reset();\n        spi1.reset();\n        spi2.reset();\n\n        assertNull(((IgniteKernal)ignite2).context().cache().context().cache().internalCache(\"cache1\"));\n\n        if (nearCache)\n            ignite2.getOrCreateNearCache(CACHE_NAME1, new NearCacheConfiguration<>());\n        else\n            ignite2.cache(CACHE_NAME1);\n\n        waitForTopologyUpdate(3, new AffinityTopologyVersion(3, 1));\n\n        GridCacheAdapter cache = ((IgniteKernal)ignite2).context().cache().context().cache().internalCache(\"cache1\");\n\n        assertNotNull(cache);\n        assertEquals(nearCache, cache.context().isNear());\n\n        assertEquals(0, spi0.partitionsSingleMessages());\n        assertEquals(1, spi0.partitionsFullMessages());\n        assertEquals(0, spi1.partitionsSingleMessages());\n        assertEquals(0, spi1.partitionsFullMessages());\n        assertEquals(1, spi2.partitionsSingleMessages());\n        assertEquals(0, spi2.partitionsFullMessages());\n\n        ClusterNode clientNode = ((IgniteKernal)ignite2).localNode();\n\n        for (Ignite ignite : Ignition.allGrids()) {\n            GridDiscoveryManager disco = ((IgniteKernal)ignite).context().discovery();\n\n            assertTrue(disco.cacheNode(clientNode, CACHE_NAME1));\n            assertFalse(disco.cacheAffinityNode(clientNode, CACHE_NAME1));\n            assertEquals(nearCache, disco.cacheNearNode(clientNode, CACHE_NAME1));\n        }\n\n        spi0.reset();\n        spi1.reset();\n        spi2.reset();\n\n        final String CACHE_NAME2 = \"cache2\";\n\n        ccfg = new CacheConfiguration();\n\n        ccfg.setName(CACHE_NAME2);\n\n        ignite2.createCache(ccfg);\n\n        waitForTopologyUpdate(3, new AffinityTopologyVersion(3, 2));\n\n        assertEquals(0, spi0.partitionsSingleMessages());\n        assertEquals(2, spi0.partitionsFullMessages());\n        assertEquals(1, spi1.partitionsSingleMessages());\n        assertEquals(0, spi1.partitionsFullMessages());\n        assertEquals(1, spi2.partitionsSingleMessages());\n        assertEquals(0, spi2.partitionsFullMessages());\n    }","commit_id":"a6cda33a8b76925d09c21262e88467421025fa77","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @return IgniteCache test suite.\n     * @throws Exception Thrown in case of the failure.\n     */\n    public static TestSuite suite() throws Exception {\n        TestSuite suite = new TestSuite(\"IgniteCache Test Suite part 4\");\n\n        // Multi node update.\n        suite.addTestSuite(GridCacheMultinodeUpdateSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateNearEnabledSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateNearEnabledNoBackupsSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateAtomicSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateAtomicNearEnabledSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheTxLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalLoadAllTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLoaderWriterTest.class);\n        suite.addTestSuite(IgniteCacheTxLoaderWriterTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicStoreSessionTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreSessionTest.class);\n        suite.addTestSuite(IgniteCacheAtomicStoreSessionWriteBehindTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreSessionWriteBehindTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoReadThroughTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoLoadPreviousValueTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoWriteThroughTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicReplicatedPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxNearPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxReplicatedPeekModesTest.class);\n\n        suite.addTestSuite(IgniteCacheInvokeReadThroughTest.class);\n        suite.addTestSuite(GridCacheVersionMultinodeTest.class);\n\n        suite.addTestSuite(IgniteCacheNearReadCommittedTest.class);\n        suite.addTestSuite(IgniteCacheAtomicCopyOnReadDisabledTest.class);\n        suite.addTestSuite(IgniteCacheTxCopyOnReadDisabledTest.class);\n\n        suite.addTestSuite(IgniteCacheTxPreloadNoWriteTest.class);\n\n        suite.addTestSuite(IgniteDynamicCacheStartSelfTest.class);\n        suite.addTestSuite(IgniteDynamicCacheWithConfigStartSelfTest.class);\n        suite.addTestSuite(IgniteCacheDynamicStopSelfTest.class);\n        suite.addTestSuite(IgniteCacheConfigurationTemplateTest.class);\n        suite.addTestSuite(IgniteCacheConfigurationDefaultTemplateTest.class);\n        suite.addTestSuite(IgniteDynamicClientCacheStartSelfTest.class);\n\n        suite.addTestSuite(GridCacheTxLoadFromStoreOnLockSelfTest.class);\n\n        suite.addTestSuite(GridCacheMarshallingNodeJoinSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheJdbcBlobStoreNodeRestartTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLocalStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicPrimaryWriteOrderStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicPrimaryWriteOrderNearEnabledStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledStoreValueTest.class);\n\n        suite.addTestSuite(IgniteCacheLockFailoverSelfTest.class);\n        suite.addTestSuite(IgniteCacheMultiTxLockSelfTest.class);\n\n        suite.addTestSuite(IgniteInternalCacheTypesTest.class);\n\n        suite.addTestSuite(IgniteExchangeFutureHistoryTest.class);\n\n        suite.addTestSuite(CacheNoValueClassOnServerNodeTest.class);\n        suite.addTestSuite(IgniteSystemCacheOnClientTest.class);\n\n        suite.addTestSuite(CacheRemoveAllSelfTest.class);\n\n        suite.addTestSuite(CacheOffheapMapEntrySelfTest.class);\n\n        suite.addTestSuite(CacheJdbcStoreSessionListenerSelfTest.class);\n\n        suite.addTestSuite(CacheClientStoreSelfTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeStaticStartAtomicTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeStaticStartTxTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeDynamicStartAtomicTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeDynamicStartTxTest.class);\n\n        suite.addTestSuite(IgniteStartCacheInTransactionSelfTest.class);\n        suite.addTestSuite(IgniteStartCacheInTransactionAtomicSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheManyClientsTest.class);\n\n        return suite;\n    }","id":36093,"modified_method":"/**\n     * @return IgniteCache test suite.\n     * @throws Exception Thrown in case of the failure.\n     */\n    public static TestSuite suite() throws Exception {\n        TestSuite suite = new TestSuite(\"IgniteCache Test Suite part 4\");\n\n        // Multi node update.\n        suite.addTestSuite(GridCacheMultinodeUpdateSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateNearEnabledSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateNearEnabledNoBackupsSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateAtomicSelfTest.class);\n        suite.addTestSuite(GridCacheMultinodeUpdateAtomicNearEnabledSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheTxLoadAllTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalLoadAllTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLoaderWriterTest.class);\n        suite.addTestSuite(IgniteCacheTxLoaderWriterTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicStoreSessionTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreSessionTest.class);\n        suite.addTestSuite(IgniteCacheAtomicStoreSessionWriteBehindTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreSessionWriteBehindTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoReadThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoReadThroughTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoLoadPreviousValueTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoLoadPreviousValueTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledNoWriteThroughTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalNoWriteThroughTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicReplicatedPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheAtomicLocalPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxNearPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalPeekModesTest.class);\n        suite.addTestSuite(IgniteCacheTxReplicatedPeekModesTest.class);\n\n        suite.addTestSuite(IgniteCacheInvokeReadThroughTest.class);\n        suite.addTestSuite(GridCacheVersionMultinodeTest.class);\n\n        suite.addTestSuite(IgniteCacheNearReadCommittedTest.class);\n        suite.addTestSuite(IgniteCacheAtomicCopyOnReadDisabledTest.class);\n        suite.addTestSuite(IgniteCacheTxCopyOnReadDisabledTest.class);\n\n        suite.addTestSuite(IgniteCacheTxPreloadNoWriteTest.class);\n\n        suite.addTestSuite(IgniteDynamicCacheStartSelfTest.class);\n        suite.addTestSuite(IgniteDynamicCacheWithConfigStartSelfTest.class);\n        suite.addTestSuite(IgniteCacheDynamicStopSelfTest.class);\n        suite.addTestSuite(IgniteCacheConfigurationTemplateTest.class);\n        suite.addTestSuite(IgniteCacheConfigurationDefaultTemplateTest.class);\n        suite.addTestSuite(IgniteDynamicClientCacheStartSelfTest.class);\n        suite.addTestSuite(IgniteDynamicCacheStartNoExchangeTimeoutTest.class);\n\n        suite.addTestSuite(GridCacheTxLoadFromStoreOnLockSelfTest.class);\n\n        suite.addTestSuite(GridCacheMarshallingNodeJoinSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheJdbcBlobStoreNodeRestartTest.class);\n\n        suite.addTestSuite(IgniteCacheAtomicLocalStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicNearEnabledStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicPrimaryWriteOrderStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheAtomicPrimaryWriteOrderNearEnabledStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxLocalStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxStoreValueTest.class);\n        suite.addTestSuite(IgniteCacheTxNearEnabledStoreValueTest.class);\n\n        suite.addTestSuite(IgniteCacheLockFailoverSelfTest.class);\n        suite.addTestSuite(IgniteCacheMultiTxLockSelfTest.class);\n\n        suite.addTestSuite(IgniteInternalCacheTypesTest.class);\n\n        suite.addTestSuite(IgniteExchangeFutureHistoryTest.class);\n\n        suite.addTestSuite(CacheNoValueClassOnServerNodeTest.class);\n        suite.addTestSuite(IgniteSystemCacheOnClientTest.class);\n\n        suite.addTestSuite(CacheRemoveAllSelfTest.class);\n\n        suite.addTestSuite(CacheOffheapMapEntrySelfTest.class);\n\n        suite.addTestSuite(CacheJdbcStoreSessionListenerSelfTest.class);\n\n        suite.addTestSuite(CacheClientStoreSelfTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeStaticStartAtomicTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeStaticStartTxTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeDynamicStartAtomicTest.class);\n        suite.addTestSuite(CacheStoreUsageMultinodeDynamicStartTxTest.class);\n\n        suite.addTestSuite(IgniteStartCacheInTransactionSelfTest.class);\n        suite.addTestSuite(IgniteStartCacheInTransactionAtomicSelfTest.class);\n\n        suite.addTestSuite(IgniteCacheManyClientsTest.class);\n\n        return suite;\n    }","commit_id":"a6cda33a8b76925d09c21262e88467421025fa77","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     *\n     */\n    private void checkBackup() {\n        assert mappings.size() <= 1;\n\n        for (Map.Entry<UUID, GridDistributedTxMapping> entry : mappings.entrySet()) {\n            UUID nodeId = entry.getKey();\n            GridDistributedTxMapping mapping = entry.getValue();\n\n            Collection<UUID> backups = tx.transactionNodes().get(nodeId);\n\n            if (!F.isEmpty(backups)) {\n                assert backups.size() == 1;\n\n                UUID backupId = F.first(backups);\n\n                ClusterNode backup = cctx.discovery().node(backupId);\n\n                // Nothing to do if backup has left the grid.\n                if (backup == null)\n                    return;\n\n                MiniFuture mini = new MiniFuture(backup, mapping);\n\n                add(mini);\n\n                if (backup.isLocal()) {\n                    if (cctx.tm().txHandler().checkDhtRemoteTxCommitted(tx.xidVersion())) {\n                        readyNearMappingFromBackup(mapping);\n\n                        mini.onDone(tx);\n                    }\n                    else\n                        mini.onDone(new IgniteTxRollbackCheckedException(\"Failed to commit transaction \" +\n                            \"(transaction has been rolled back on backup node): \" + tx.xidVersion()));\n                }\n                else {\n                    GridDhtTxFinishRequest finishReq = new GridDhtTxFinishRequest(\n                        cctx.localNodeId(),\n                        futureId(),\n                        mini.futureId(),\n                        tx.topologyVersion(),\n                        tx.xidVersion(),\n                        tx.commitVersion(),\n                        tx.threadId(),\n                        tx.isolation(),\n                        true,\n                        false,\n                        tx.system(),\n                        tx.ioPolicy(),\n                        false,\n                        true,\n                        true,\n                        null,\n                        null,\n                        null,\n                        null,\n                        0,\n                        null,\n                        0);\n\n                    finishReq.checkCommitted(true);\n\n                    try {\n                        if (FINISH_NEAR_ONE_PHASE_SINCE.compareTo(backup.version()) <= 0)\n                            cctx.io().send(backup, finishReq, tx.ioPolicy());\n                        else\n                            mini.onDone(new IgniteTxHeuristicCheckedException(\"Failed to check for tx commit on \" +\n                                \"the backup node (node has an old Ignite version) [rmtNodeId=\" + backup.id() +\n                                \", ver=\" + backup.version() + ']'));\n                    }\n                    catch (ClusterTopologyCheckedException e) {\n                        mini.onResult(e);\n                    }\n                    catch (IgniteCheckedException e) {\n                        mini.onResult(e);\n                    }\n                }\n            }\n            else\n                readyNearMappingFromBackup(mapping);\n        }\n    }","id":36094,"modified_method":"/**\n     *\n     */\n    private void checkBackup() {\n        assert mappings.size() <= 1;\n\n        for (Map.Entry<UUID, GridDistributedTxMapping> entry : mappings.entrySet()) {\n            UUID nodeId = entry.getKey();\n            GridDistributedTxMapping mapping = entry.getValue();\n\n            Collection<UUID> backups = tx.transactionNodes().get(nodeId);\n\n            if (!F.isEmpty(backups)) {\n                assert backups.size() == 1;\n\n                UUID backupId = F.first(backups);\n\n                ClusterNode backup = cctx.discovery().node(backupId);\n\n                MiniFuture mini = new MiniFuture(backup, mapping);\n\n                add(mini);\n\n                // Nothing to do if backup has left the grid.\n                if (backup == null) {\n                    readyNearMappingFromBackup(mapping);\n\n                    mini.onDone(new IgniteTxRollbackCheckedException(\"Failed to commit transaction \" +\n                        \"(backup has left grid): \" + tx.xidVersion()));\n                }\n                else if (backup.isLocal()) {\n                    boolean committed = cctx.tm().txHandler().checkDhtRemoteTxCommitted(tx.xidVersion());\n\n                    readyNearMappingFromBackup(mapping);\n\n                    if (committed)\n                        mini.onDone(tx);\n                    else\n                        mini.onDone(new IgniteTxRollbackCheckedException(\"Failed to commit transaction \" +\n                            \"(transaction has been rolled back on backup node): \" + tx.xidVersion()));\n                }\n                else {\n                    GridDhtTxFinishRequest finishReq = new GridDhtTxFinishRequest(\n                        cctx.localNodeId(),\n                        futureId(),\n                        mini.futureId(),\n                        tx.topologyVersion(),\n                        tx.xidVersion(),\n                        tx.commitVersion(),\n                        tx.threadId(),\n                        tx.isolation(),\n                        true,\n                        false,\n                        tx.system(),\n                        tx.ioPolicy(),\n                        false,\n                        true,\n                        true,\n                        null,\n                        null,\n                        null,\n                        null,\n                        0,\n                        null,\n                        0);\n\n                    finishReq.checkCommitted(true);\n\n                    try {\n                        if (FINISH_NEAR_ONE_PHASE_SINCE.compareTo(backup.version()) <= 0)\n                            cctx.io().send(backup, finishReq, tx.ioPolicy());\n                        else\n                            mini.onDone(new IgniteTxHeuristicCheckedException(\"Failed to check for tx commit on \" +\n                                \"the backup node (node has an old Ignite version) [rmtNodeId=\" + backup.id() +\n                                \", ver=\" + backup.version() + ']'));\n                    }\n                    catch (ClusterTopologyCheckedException e) {\n                        mini.onResult(e);\n                    }\n                    catch (IgniteCheckedException e) {\n                        mini.onResult(e);\n                    }\n                }\n            }\n            else\n                readyNearMappingFromBackup(mapping);\n        }\n    }","commit_id":"06fdd7d44dda36900b4c7a76dec2a7848ca9e8fb","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Checks if future is ready to be completed.\n     */\n    private synchronized void checkComplete() {\n        if ((syncMode == FULL_ASYNC && cctx.config().getAtomicWriteOrderMode() == PRIMARY) || mappings.isEmpty()) {\n            CachePartialUpdateCheckedException err0 = err;\n\n            if (err0 != null)\n                onDone(err0);\n            else\n                onDone(opRes);\n        }\n    }","id":36095,"modified_method":"/**\n     * Checks if future is ready to be completed.\n     */\n    private void checkComplete() {\n        boolean remap = false;\n\n        synchronized (this) {\n            if ((syncMode == FULL_ASYNC && cctx.config().getAtomicWriteOrderMode() == PRIMARY) || mappings.isEmpty()) {\n                CachePartialUpdateCheckedException err0 = err;\n\n                if (err0 != null)\n                    onDone(err0);\n                else {\n                    if (fastMapRemap) {\n                        assert cctx.kernalContext().clientNode();\n\n                        remap = true;\n                    }\n                    else\n                        onDone(opRes);\n                }\n            }\n        }\n\n        if (remap)\n            mapOnTopology(null, true, null, true);\n    }","commit_id":"00eadd62ea451922e9fe3396085f5f003f36c32e","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Response callback.\n     *\n     * @param nodeId Node ID.\n     * @param res Update response.\n     */\n    public void onResult(UUID nodeId, GridNearAtomicUpdateResponse res) {\n        if (res.remapKeys() != null) {\n            assert !fastMap || cctx.kernalContext().clientNode();\n\n            Collection<?> remapKeys = fastMap && cctx.kernalContext().clientNode() ? null : res.remapKeys();\n\n            mapOnTopology(remapKeys, true, nodeId, true);\n\n            return;\n        }\n\n        GridCacheReturn ret = res.returnValue();\n\n        Boolean single0 = single;\n\n        if (single0 != null && single0) {\n            assert singleNodeId.equals(nodeId) : \"Invalid response received for single-node mapped future \" +\n                \"[singleNodeId=\" + singleNodeId + \", nodeId=\" + nodeId + \", res=\" + res + ']';\n\n            updateNear(singleReq, res);\n\n            if (res.error() != null)\n                onDone(res.failedKeys() != null ? addFailedKeys(res.failedKeys(), res.error()) : res.error());\n            else {\n                if (op == TRANSFORM) {\n                    if (ret != null)\n                        addInvokeResults(ret);\n\n                    onDone(opRes);\n                }\n                else {\n                    GridCacheReturn opRes0 = opRes = ret;\n\n                    onDone(opRes0);\n                }\n            }\n        }\n        else {\n            GridNearAtomicUpdateRequest req = mappings.get(nodeId);\n\n            if (req != null) { // req can be null if onResult is being processed concurrently with onNodeLeft.\n                updateNear(req, res);\n\n                if (res.error() != null)\n                    addFailedKeys(req.keys(), res.error());\n                else {\n                    if (op == TRANSFORM) {\n                        assert !req.fastMap();\n\n                        if (ret != null)\n                            addInvokeResults(ret);\n                    }\n                    else if (req.fastMap() && req.hasPrimary())\n                        opRes = ret;\n                }\n\n                mappings.remove(nodeId);\n            }\n\n            checkComplete();\n        }\n    }","id":36096,"modified_method":"/**\n     * Response callback.\n     *\n     * @param nodeId Node ID.\n     * @param res Update response.\n     */\n    public void onResult(UUID nodeId, GridNearAtomicUpdateResponse res) {\n        if (res.remapKeys() != null) {\n            assert !fastMap || cctx.kernalContext().clientNode();\n\n            Collection<KeyCacheObject> remapKeys = fastMap ? null : res.remapKeys();\n\n            mapOnTopology(remapKeys, true, nodeId, true);\n\n            return;\n        }\n\n        GridCacheReturn ret = res.returnValue();\n\n        Boolean single0 = single;\n\n        if (single0 != null && single0) {\n            assert singleNodeId.equals(nodeId) : \"Invalid response received for single-node mapped future \" +\n                \"[singleNodeId=\" + singleNodeId + \", nodeId=\" + nodeId + \", res=\" + res + ']';\n\n            updateNear(singleReq, res);\n\n            if (res.error() != null)\n                onDone(res.failedKeys() != null ? addFailedKeys(res.failedKeys(), res.error()) : res.error());\n            else {\n                if (op == TRANSFORM) {\n                    if (ret != null)\n                        addInvokeResults(ret);\n\n                    onDone(opRes);\n                }\n                else {\n                    GridCacheReturn opRes0 = opRes = ret;\n\n                    onDone(opRes0);\n                }\n            }\n        }\n        else {\n            GridNearAtomicUpdateRequest req = mappings.get(nodeId);\n\n            if (req != null) { // req can be null if onResult is being processed concurrently with onNodeLeft.\n                updateNear(req, res);\n\n                if (res.error() != null)\n                    addFailedKeys(req.keys(), res.error());\n                else {\n                    if (op == TRANSFORM) {\n                        assert !req.fastMap();\n\n                        if (ret != null)\n                            addInvokeResults(ret);\n                    }\n                    else if (req.fastMap() && req.hasPrimary())\n                        opRes = ret;\n                }\n\n                mappings.remove(nodeId);\n            }\n\n            checkComplete();\n        }\n    }","commit_id":"00eadd62ea451922e9fe3396085f5f003f36c32e","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @param topVer Topology version.\n     * @param remapKeys Keys to remap or {@code null} to map all keys.\n     * @param remap Flag indicating if this is partial remap for this future.\n     * @param oldNodeId Old node ID if was remap.\n     */\n    private void map0(\n        AffinityTopologyVersion topVer,\n        @Nullable Collection<?> remapKeys,\n        boolean remap,\n        @Nullable UUID oldNodeId) {\n        assert oldNodeId == null || remap;\n\n        Collection<ClusterNode> topNodes = CU.affinityNodes(cctx, topVer);\n\n        if (F.isEmpty(topNodes)) {\n            onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache (all partition nodes \" +\n                \"left the grid).\"));\n\n            return;\n        }\n\n        if (futVer == null)\n            // Assign future version in topology read lock before first exception may be thrown.\n            futVer = cctx.versions().next(topVer);\n\n        if (!remap && (cctx.config().getAtomicWriteOrderMode() == CLOCK || syncMode != FULL_ASYNC))\n            cctx.mvcc().addAtomicFuture(version(), this);\n\n        CacheConfiguration ccfg = cctx.config();\n\n        // Assign version on near node in CLOCK ordering mode even if fastMap is false.\n        GridCacheVersion updVer = ccfg.getAtomicWriteOrderMode() == CLOCK ? cctx.versions().next(topVer) : null;\n\n        if (updVer != null && log.isDebugEnabled())\n            log.debug(\"Assigned fast-map version for update on near node: \" + updVer);\n\n        if (keys.size() == 1 && !fastMap && (single == null || single)) {\n            assert remapKeys == null || remapKeys.size() == 1 : remapKeys;\n\n            Object key = F.first(keys);\n\n            Object val;\n            GridCacheVersion conflictVer;\n            long conflictTtl;\n            long conflictExpireTime;\n\n            if (vals != null) {\n                // Regular PUT.\n                val = F.first(vals);\n                conflictVer = null;\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n            else if (conflictPutVals != null) {\n                // Conflict PUT.\n                GridCacheDrInfo conflictPutVal = F.first(conflictPutVals);\n\n                val = conflictPutVal.value();\n                conflictVer = conflictPutVal.version();\n                conflictTtl = conflictPutVal.ttl();\n                conflictExpireTime = conflictPutVal.expireTime();\n            }\n            else if (conflictRmvVals != null) {\n                // Conflict REMOVE.\n                val = null;\n                conflictVer = F.first(conflictRmvVals);\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n            else {\n                // Regular REMOVE.\n                val = null;\n                conflictVer = null;\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n\n            // We still can get here if user pass map with single element.\n            if (key == null) {\n                NullPointerException err = new NullPointerException(\"Null key.\");\n\n                onDone(err);\n\n                return;\n            }\n\n            if (val == null && op != GridCacheOperation.DELETE) {\n                NullPointerException err = new NullPointerException(\"Null value.\");\n\n                onDone(err);\n\n                return;\n            }\n\n            KeyCacheObject cacheKey = cctx.toCacheKeyObject(key);\n\n            if (op != TRANSFORM)\n                val = cctx.toCacheObject(val);\n\n            ClusterNode primary = cctx.affinity().primary(cacheKey, topVer);\n\n            if (primary == null) {\n                onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache (all partition nodes \" +\n                    \"left the grid).\"));\n\n                return;\n            }\n\n            GridNearAtomicUpdateRequest req = new GridNearAtomicUpdateRequest(\n                cctx.cacheId(),\n                primary.id(),\n                futVer,\n                fastMap,\n                updVer,\n                topVer,\n                topLocked,\n                syncMode,\n                op,\n                retval,\n                expiryPlc,\n                invokeArgs,\n                filter,\n                subjId,\n                taskNameHash,\n                skipStore,\n                cctx.kernalContext().clientNode());\n\n            req.addUpdateEntry(cacheKey,\n                val,\n                conflictTtl,\n                conflictExpireTime,\n                conflictVer,\n                true);\n\n            single = true;\n\n            // Optimize mapping for single key.\n            mapSingle(primary.id(), req);\n\n            return;\n        }\n\n        Iterator<?> it = null;\n\n        if (vals != null)\n            it = vals.iterator();\n\n        Iterator<GridCacheDrInfo> conflictPutValsIt = null;\n\n        if (conflictPutVals != null)\n            conflictPutValsIt = conflictPutVals.iterator();\n\n        Iterator<GridCacheVersion> conflictRmvValsIt = null;\n\n        if (conflictRmvVals != null)\n            conflictRmvValsIt = conflictRmvVals.iterator();\n\n        Map<UUID, GridNearAtomicUpdateRequest> pendingMappings = new HashMap<>(topNodes.size(), 1.0f);\n\n        // Must do this in synchronized block because we need to atomically remove and add mapping.\n        // Otherwise checkComplete() may see empty intermediate state.\n        synchronized (this) {\n            if (remap)\n                removeMapping(oldNodeId);\n\n            // Create mappings first, then send messages.\n            for (Object key : keys) {\n                if (key == null) {\n                    NullPointerException err = new NullPointerException(\"Null key.\");\n\n                    onDone(err);\n\n                    return;\n                }\n\n                Object val;\n                GridCacheVersion conflictVer;\n                long conflictTtl;\n                long conflictExpireTime;\n\n                if (vals != null) {\n                    val = it.next();\n                    conflictVer = null;\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n\n                    if (val == null) {\n                        NullPointerException err = new NullPointerException(\"Null value.\");\n\n                        onDone(err);\n\n                        return;\n                    }\n                }\n                else if (conflictPutVals != null) {\n                    GridCacheDrInfo conflictPutVal =  conflictPutValsIt.next();\n\n                    val = conflictPutVal.value();\n                    conflictVer = conflictPutVal.version();\n                    conflictTtl =  conflictPutVal.ttl();\n                    conflictExpireTime = conflictPutVal.expireTime();\n                }\n                else if (conflictRmvVals != null) {\n                    val = null;\n                    conflictVer = conflictRmvValsIt.next();\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n                }\n                else {\n                    val = null;\n                    conflictVer = null;\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n                }\n\n                if (val == null && op != GridCacheOperation.DELETE)\n                    continue;\n\n                KeyCacheObject cacheKey = cctx.toCacheKeyObject(key);\n\n                if (remapKeys != null && !remapKeys.contains(cacheKey))\n                    continue;\n\n                if (op != TRANSFORM)\n                    val = cctx.toCacheObject(val);\n\n                Collection<ClusterNode> affNodes = mapKey(cacheKey, topVer, fastMap);\n\n                if (affNodes.isEmpty()) {\n                    onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache \" +\n                        \"(all partition nodes left the grid).\"));\n\n                    return;\n                }\n\n                int i = 0;\n\n                for (ClusterNode affNode : affNodes) {\n                    if (affNode == null) {\n                        onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache \" +\n                            \"(all partition nodes left the grid).\"));\n\n                        return;\n                    }\n\n                    UUID nodeId = affNode.id();\n\n                    GridNearAtomicUpdateRequest mapped = pendingMappings.get(nodeId);\n\n                    if (mapped == null) {\n                        mapped = new GridNearAtomicUpdateRequest(\n                            cctx.cacheId(),\n                            nodeId,\n                            futVer,\n                            fastMap,\n                            updVer,\n                            topVer,\n                            topLocked,\n                            syncMode,\n                            op,\n                            retval,\n                            expiryPlc,\n                            invokeArgs,\n                            filter,\n                            subjId,\n                            taskNameHash,\n                            skipStore,\n                            cctx.kernalContext().clientNode());\n\n                        pendingMappings.put(nodeId, mapped);\n\n                        GridNearAtomicUpdateRequest old = mappings.put(nodeId, mapped);\n\n                        assert old == null || (old != null && remap) :\n                            \"Invalid mapping state [old=\" + old + \", remap=\" + remap + ']';\n                    }\n\n                    mapped.addUpdateEntry(cacheKey, val, conflictTtl, conflictExpireTime, conflictVer, i == 0);\n\n                    i++;\n                }\n            }\n        }\n\n        if ((single == null || single) && pendingMappings.size() == 1) {\n            Map.Entry<UUID, GridNearAtomicUpdateRequest> entry = F.first(pendingMappings.entrySet());\n\n            single = true;\n\n            mapSingle(entry.getKey(), entry.getValue());\n\n            return;\n        }\n        else\n            single = false;\n\n        doUpdate(pendingMappings);\n    }","id":36097,"modified_method":"/**\n     * @param topVer Topology version.\n     * @param remapKeys Keys to remap or {@code null} to map all keys.\n     * @param remap Flag indicating if this is partial remap for this future.\n     * @param oldNodeId Old node ID if was remap.\n     */\n    private void map0(\n        AffinityTopologyVersion topVer,\n        @Nullable Collection<?> remapKeys,\n        boolean remap,\n        @Nullable UUID oldNodeId) {\n        assert oldNodeId == null || remap || fastMapRemap;\n\n        Collection<ClusterNode> topNodes = CU.affinityNodes(cctx, topVer);\n\n        if (F.isEmpty(topNodes)) {\n            onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache (all partition nodes \" +\n                \"left the grid).\"));\n\n            return;\n        }\n\n        if (futVer == null)\n            // Assign future version in topology read lock before first exception may be thrown.\n            futVer = cctx.versions().next(topVer);\n\n        if (!remap && (cctx.config().getAtomicWriteOrderMode() == CLOCK || syncMode != FULL_ASYNC))\n            cctx.mvcc().addAtomicFuture(version(), this);\n\n        CacheConfiguration ccfg = cctx.config();\n\n        // Assign version on near node in CLOCK ordering mode even if fastMap is false.\n        GridCacheVersion updVer = ccfg.getAtomicWriteOrderMode() == CLOCK ? cctx.versions().next(topVer) : null;\n\n        if (updVer != null && log.isDebugEnabled())\n            log.debug(\"Assigned fast-map version for update on near node: \" + updVer);\n\n        if (keys.size() == 1 && !fastMap && (single == null || single)) {\n            assert remapKeys == null || remapKeys.size() == 1 : remapKeys;\n\n            Object key = F.first(keys);\n\n            Object val;\n            GridCacheVersion conflictVer;\n            long conflictTtl;\n            long conflictExpireTime;\n\n            if (vals != null) {\n                // Regular PUT.\n                val = F.first(vals);\n                conflictVer = null;\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n            else if (conflictPutVals != null) {\n                // Conflict PUT.\n                GridCacheDrInfo conflictPutVal = F.first(conflictPutVals);\n\n                val = conflictPutVal.value();\n                conflictVer = conflictPutVal.version();\n                conflictTtl = conflictPutVal.ttl();\n                conflictExpireTime = conflictPutVal.expireTime();\n            }\n            else if (conflictRmvVals != null) {\n                // Conflict REMOVE.\n                val = null;\n                conflictVer = F.first(conflictRmvVals);\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n            else {\n                // Regular REMOVE.\n                val = null;\n                conflictVer = null;\n                conflictTtl = CU.TTL_NOT_CHANGED;\n                conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n            }\n\n            // We still can get here if user pass map with single element.\n            if (key == null) {\n                NullPointerException err = new NullPointerException(\"Null key.\");\n\n                onDone(err);\n\n                return;\n            }\n\n            if (val == null && op != GridCacheOperation.DELETE) {\n                NullPointerException err = new NullPointerException(\"Null value.\");\n\n                onDone(err);\n\n                return;\n            }\n\n            KeyCacheObject cacheKey = cctx.toCacheKeyObject(key);\n\n            if (op != TRANSFORM)\n                val = cctx.toCacheObject(val);\n\n            ClusterNode primary = cctx.affinity().primary(cacheKey, topVer);\n\n            if (primary == null) {\n                onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache (all partition nodes \" +\n                    \"left the grid).\"));\n\n                return;\n            }\n\n            GridNearAtomicUpdateRequest req = new GridNearAtomicUpdateRequest(\n                cctx.cacheId(),\n                primary.id(),\n                futVer,\n                fastMap,\n                updVer,\n                topVer,\n                topLocked,\n                syncMode,\n                op,\n                retval,\n                expiryPlc,\n                invokeArgs,\n                filter,\n                subjId,\n                taskNameHash,\n                skipStore,\n                cctx.kernalContext().clientNode());\n\n            req.addUpdateEntry(cacheKey,\n                val,\n                conflictTtl,\n                conflictExpireTime,\n                conflictVer,\n                true);\n\n            single = true;\n\n            // Optimize mapping for single key.\n            mapSingle(primary.id(), req);\n\n            return;\n        }\n\n        Iterator<?> it = null;\n\n        if (vals != null)\n            it = vals.iterator();\n\n        Iterator<GridCacheDrInfo> conflictPutValsIt = null;\n\n        if (conflictPutVals != null)\n            conflictPutValsIt = conflictPutVals.iterator();\n\n        Iterator<GridCacheVersion> conflictRmvValsIt = null;\n\n        if (conflictRmvVals != null)\n            conflictRmvValsIt = conflictRmvVals.iterator();\n\n        Map<UUID, GridNearAtomicUpdateRequest> pendingMappings = new HashMap<>(topNodes.size(), 1.0f);\n\n        // Must do this in synchronized block because we need to atomically remove and add mapping.\n        // Otherwise checkComplete() may see empty intermediate state.\n        synchronized (this) {\n            if (oldNodeId != null)\n                removeMapping(oldNodeId);\n\n            // For fastMap mode wait for all responses before remapping.\n            if (remap && fastMap && !mappings.isEmpty()) {\n                fastMapRemap = true;\n\n                return;\n            }\n\n            // Create mappings first, then send messages.\n            for (Object key : keys) {\n                if (key == null) {\n                    NullPointerException err = new NullPointerException(\"Null key.\");\n\n                    onDone(err);\n\n                    return;\n                }\n\n                Object val;\n                GridCacheVersion conflictVer;\n                long conflictTtl;\n                long conflictExpireTime;\n\n                if (vals != null) {\n                    val = it.next();\n                    conflictVer = null;\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n\n                    if (val == null) {\n                        NullPointerException err = new NullPointerException(\"Null value.\");\n\n                        onDone(err);\n\n                        return;\n                    }\n                }\n                else if (conflictPutVals != null) {\n                    GridCacheDrInfo conflictPutVal =  conflictPutValsIt.next();\n\n                    val = conflictPutVal.value();\n                    conflictVer = conflictPutVal.version();\n                    conflictTtl =  conflictPutVal.ttl();\n                    conflictExpireTime = conflictPutVal.expireTime();\n                }\n                else if (conflictRmvVals != null) {\n                    val = null;\n                    conflictVer = conflictRmvValsIt.next();\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n                }\n                else {\n                    val = null;\n                    conflictVer = null;\n                    conflictTtl = CU.TTL_NOT_CHANGED;\n                    conflictExpireTime = CU.EXPIRE_TIME_CALCULATE;\n                }\n\n                if (val == null && op != GridCacheOperation.DELETE)\n                    continue;\n\n                KeyCacheObject cacheKey = cctx.toCacheKeyObject(key);\n\n                if (remapKeys != null && !remapKeys.contains(cacheKey))\n                    continue;\n\n                if (op != TRANSFORM)\n                    val = cctx.toCacheObject(val);\n\n                Collection<ClusterNode> affNodes = mapKey(cacheKey, topVer, fastMap);\n\n                if (affNodes.isEmpty()) {\n                    onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache \" +\n                        \"(all partition nodes left the grid).\"));\n\n                    return;\n                }\n\n                int i = 0;\n\n                for (ClusterNode affNode : affNodes) {\n                    if (affNode == null) {\n                        onDone(new ClusterTopologyServerNotFoundException(\"Failed to map keys for cache \" +\n                            \"(all partition nodes left the grid).\"));\n\n                        return;\n                    }\n\n                    UUID nodeId = affNode.id();\n\n                    GridNearAtomicUpdateRequest mapped = pendingMappings.get(nodeId);\n\n                    if (mapped == null) {\n                        mapped = new GridNearAtomicUpdateRequest(\n                            cctx.cacheId(),\n                            nodeId,\n                            futVer,\n                            fastMap,\n                            updVer,\n                            topVer,\n                            topLocked,\n                            syncMode,\n                            op,\n                            retval,\n                            expiryPlc,\n                            invokeArgs,\n                            filter,\n                            subjId,\n                            taskNameHash,\n                            skipStore,\n                            cctx.kernalContext().clientNode());\n\n                        pendingMappings.put(nodeId, mapped);\n\n                        GridNearAtomicUpdateRequest old = mappings.put(nodeId, mapped);\n\n                        assert old == null || (old != null && remap) :\n                            \"Invalid mapping state [old=\" + old + \", remap=\" + remap + ']';\n                    }\n\n                    mapped.addUpdateEntry(cacheKey, val, conflictTtl, conflictExpireTime, conflictVer, i == 0);\n\n                    i++;\n                }\n            }\n\n            fastMapRemap = false;\n        }\n\n        if ((single == null || single) && pendingMappings.size() == 1) {\n            Map.Entry<UUID, GridNearAtomicUpdateRequest> entry = F.first(pendingMappings.entrySet());\n\n            single = true;\n\n            mapSingle(entry.getKey(), entry.getValue());\n\n            return;\n        }\n        else\n            single = false;\n\n        doUpdate(pendingMappings);\n    }","commit_id":"00eadd62ea451922e9fe3396085f5f003f36c32e","url":"https://github.com/apache/ignite"},{"original_method":"public BuildOperationInternal(Object id, Object parentId, BuildOperationType operationType, Object payload, long startTime) {\n        this(id, parentId, operationType, payload, startTime, 0);\n    }","id":36098,"modified_method":"public BuildOperationInternal(Object id, Object parentId, BuildOperationType operationType, long startTime) {\n        this(id, parentId, operationType, null, startTime, 0);\n    }","commit_id":"f841d8dda2bf461f595755f85c3eba786783702d","url":"https://github.com/gradle/gradle"},{"original_method":"public BuildOperationInternal(Object id, Object parentId, BuildOperationType operationType, Object payload, long startTime, long endTime) {\n        this.id = id;\n        this.parentId = parentId;\n        this.operationType = operationType;\n        this.payload = payload;\n        this.startTime = startTime;\n        this.endTime = endTime;\n    }","id":36099,"modified_method":"public BuildOperationInternal(Object id, Object parentId, BuildOperationType operationType, @Nullable Throwable failure, long startTime, long endTime) {\n        this.id = id;\n        this.parentId = parentId;\n        this.operationType = operationType;\n        this.failure = failure;\n        this.startTime = startTime;\n        this.endTime = endTime;\n    }","commit_id":"f841d8dda2bf461f595755f85c3eba786783702d","url":"https://github.com/gradle/gradle"},{"original_method":"private AbstractOperationResult adaptResult(BuildOperationInternal source) {\n        Object result = source.getPayload();\n        long startTime = source.getStartTime();\n        long endTime = source.getEndTime();\n\n        if (result instanceof BuildResult) {\n            return adaptResult((BuildResult) result, startTime, endTime);\n        } else if (result instanceof Throwable) {\n            return adaptResult((Throwable) result, startTime, endTime);\n        } else {\n            return new DefaultSuccessResult(startTime, endTime);\n        }\n    }","id":36100,"modified_method":"private AbstractOperationResult adaptResult(BuildOperationInternal source) {\n        Throwable failure = source.getFailure();\n        long startTime = source.getStartTime();\n        long endTime = source.getEndTime();\n        if (failure != null) {\n            return new DefaultFailureResult(startTime, endTime, Collections.singletonList(DefaultFailure.fromThrowable(failure)));\n        }\n        return new DefaultSuccessResult(startTime, endTime);\n    }","commit_id":"f841d8dda2bf461f595755f85c3eba786783702d","url":"https://github.com/gradle/gradle"},{"original_method":"private <T> T runBuildOperation(Object id, Object parentId, BuildOperationType operationType, Factory<T> factory) {\n        long startTime = System.currentTimeMillis();\n        BuildOperationInternal startEvent = new BuildOperationInternal(id, parentId, operationType, gradle, startTime);\n        internalBuildListener.started(startEvent);\n\n        T result = null;\n        Throwable error = null;\n        try {\n            result = factory.create();\n        } catch (Throwable e) {\n            error = e;\n        }\n\n        BuildOperationInternal endEvent = new BuildOperationInternal(id, parentId, operationType, error != null ? error : result, startTime, System.currentTimeMillis());\n        internalBuildListener.finished(endEvent);\n\n        if (error != null) {\n            UncheckedException.throwAsUncheckedException(error);\n        }\n        return result;\n    }","id":36101,"modified_method":"private <T> T runBuildOperation(Object id, Object parentId, BuildOperationType operationType, Factory<T> factory) {\n        long startTime = System.currentTimeMillis();\n        BuildOperationInternal startEvent = new BuildOperationInternal(id, parentId, operationType, startTime);\n        internalBuildListener.started(startEvent);\n\n        T result = null;\n        Throwable error = null;\n        try {\n            result = factory.create();\n        } catch (Throwable e) {\n            error = e;\n        }\n        BuildOperationInternal endEvent;\n        if (error == null && result instanceof BuildResult) {\n            endEvent = new BuildOperationInternal(id, parentId, operationType, ((BuildResult) result).getFailure(), startTime, System.currentTimeMillis());\n        } else {\n            endEvent = new BuildOperationInternal(id, parentId, operationType, error, startTime, System.currentTimeMillis());\n        }\n        internalBuildListener.finished(endEvent);\n\n        if (error != null) {\n            throw UncheckedException.throwAsUncheckedException(error);\n        }\n        return result;\n    }","commit_id":"f841d8dda2bf461f595755f85c3eba786783702d","url":"https://github.com/gradle/gradle"},{"original_method":"public Object getBuildLink(final ClassLoader classLoader, final File projectPath, final File applicationJar, final Iterable<File> changingClasspath, final File assetsJar, final Iterable<File> assetsDirs) throws ClassNotFoundException {\n        final ClassLoader assetsClassLoader = createAssetsClassLoader(assetsJar, assetsDirs, classLoader);\n        forceReloadNextTime(BuildStatus.SUCCESS);\n        final ExceptionAdapter exceptionAdapter = new DefaultExceptionAdapter(classLoader);\n        return Proxy.newProxyInstance(classLoader, new Class<?>[]{getBuildLinkClass(classLoader)}, new InvocationHandler() {\n            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\n                if (method.getName().equals(\"projectPath\")) {\n                    return projectPath;\n                } else if (method.getName().equals(\"reload\")) {\n\n                    // We can't close replaced loaders immediately, because their classes may be used during shutdown,\n                    // after the return of the reload() call that caused the loader to be swapped out.\n                    // We have no way of knowing when the loader is actually done with, so we use the request after the request\n                    // that triggered the reload as the trigger point to close the replaced loader.\n                    closeOldLoaders();\n                    BuildStatus reason = reload.get();\n                    if (reason == null) {\n                        // no reload needs to occur\n                        return null;\n                    } else if (reason.isSuccessful()) {\n                        // reload classpath\n                        reload.compareAndSet(reason, null); // clear rebuild flag\n                        ClassPath classpath = new DefaultClassPath(applicationJar).plus(new DefaultClassPath(changingClasspath));\n                        URLClassLoader currentClassLoader = new URLClassLoader(classpath.getAsURLArray(), assetsClassLoader);\n                        storeClassLoader(currentClassLoader);\n                        return currentClassLoader;\n                    } else {\n                        // present failure\n                        Throwable failure = reason.getFailure();\n                        return exceptionAdapter.adapt(\"Gradle Build Failure\", failure.getMessage(), failure);\n                    }\n                } else if (method.getName().equals(\"settings\")) {\n                    return new HashMap<String, String>();\n                }\n                //TODO: all methods\n                return null;\n            }\n        });\n    }","id":36102,"modified_method":"public Object getBuildLink(final ClassLoader classLoader, final File projectPath, final File applicationJar, final Iterable<File> changingClasspath, final File assetsJar, final Iterable<File> assetsDirs) throws ClassNotFoundException {\n        final ClassLoader assetsClassLoader = createAssetsClassLoader(assetsJar, assetsDirs, classLoader);\n        final Class<? extends Throwable> playExceptionClass = Cast.uncheckedCast(classLoader.loadClass(PLAY_EXCEPTION_CLASSNAME));\n        reload();\n        return Proxy.newProxyInstance(classLoader, new Class<?>[]{getBuildLinkClass(classLoader)}, new InvocationHandler() {\n            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                if (method.getName().equals(\"projectPath\")) {\n                    return projectPath;\n                } else if (method.getName().equals(\"reload\")) {\n\n                    // We can't close replaced loaders immediately, because their classes may be used during shutdown,\n                    // after the return of the reload() call that caused the loader to be swapped out.\n                    // We have no way of knowing when the loader is actually done with, so we use the request after the request\n                    // that triggered the reload as the trigger point to close the replaced loader.\n                    closeOldLoaders();\n                    if (reload.getAndSet(false)) {\n                        ClassPath classpath = new DefaultClassPath(applicationJar).plus(new DefaultClassPath(changingClasspath));\n                        URLClassLoader currentClassLoader = new URLClassLoader(classpath.getAsURLArray(), assetsClassLoader);\n                        storeClassLoader(currentClassLoader);\n                        return currentClassLoader;\n                    } else {\n                        Throwable failure = buildFailure;\n                        if (failure == null) {\n                            return null;\n                        } else {\n                            try {\n                                return DirectInstantiator.instantiate(playExceptionClass, \"Gradle Build Failure\", failure.getMessage(), failure);\n                            } catch (Exception e) {\n                                LOGGER.warn(\"Could not translate \" + failure + \" to \" + PLAY_EXCEPTION_CLASSNAME, e);\n                                return failure;\n                            }\n                        }\n                    }\n                } else if (method.getName().equals(\"settings\")) {\n                    return new HashMap<String, String>();\n                }\n                //TODO: all methods\n                return null;\n            }\n        });\n    }","commit_id":"8d0f67f0b67bc4014eb366a991fb07f46c60abf8","url":"https://github.com/gradle/gradle"},{"original_method":"public void rebuildSuccess() {\n        workerServer.rebuild(BuildStatus.SUCCESS);\n    }","id":36103,"modified_method":"public void rebuildSuccess() {\n        workerServer.reload();\n    }","commit_id":"8d0f67f0b67bc4014eb366a991fb07f46c60abf8","url":"https://github.com/gradle/gradle"},{"original_method":"public void rebuildFailure(Throwable failure) {\n        workerServer.rebuild(new BuildStatus(failure));\n    }","id":36104,"modified_method":"public void rebuildFailure(Throwable failure) {\n        workerServer.buildError(failure);\n    }","commit_id":"8d0f67f0b67bc4014eb366a991fb07f46c60abf8","url":"https://github.com/gradle/gradle"},{"original_method":"private void run() {\n        disableUrlConnectionCaching();\n        final Thread thread = Thread.currentThread();\n        final ClassLoader previousContextClassLoader = thread.getContextClassLoader();\n        final ClassLoader classLoader = new URLClassLoader(new DefaultClassPath(runSpec.getClasspath()).getAsURLArray(), null);\n        thread.setContextClassLoader(classLoader);\n        try {\n            ClassLoader docsClassLoader = classLoader;\n\n            Object buildDocHandler = runAdapter.getBuildDocHandler(docsClassLoader, runSpec.getClasspath());\n\n            Object buildLink = runAdapter.getBuildLink(classLoader, runSpec.getProjectPath(), runSpec.getApplicationJar(), runSpec.getChangingClasspath(), runSpec.getAssetsJar(), runSpec.getAssetsDirs());\n            runAdapter.runDevHttpServer(classLoader, docsClassLoader, buildLink, buildDocHandler, runSpec.getHttpPort());\n        } catch (Exception e) {\n            throw UncheckedException.throwAsUncheckedException(e);\n        } finally {\n            thread.setContextClassLoader(previousContextClassLoader);\n        }\n    }","id":36105,"modified_method":"private void run() {\n        disableUrlConnectionCaching();\n        final Thread thread = Thread.currentThread();\n        final ClassLoader previousContextClassLoader = thread.getContextClassLoader();\n        final ClassLoader classLoader = new URLClassLoader(new DefaultClassPath(runSpec.getClasspath()).getAsURLArray(), null);\n        thread.setContextClassLoader(classLoader);\n        try {\n            Object buildDocHandler = runAdapter.getBuildDocHandler(classLoader, runSpec.getClasspath());\n            Object buildLink = runAdapter.getBuildLink(classLoader, runSpec.getProjectPath(), runSpec.getApplicationJar(), runSpec.getChangingClasspath(), runSpec.getAssetsJar(), runSpec.getAssetsDirs());\n            runAdapter.runDevHttpServer(classLoader, classLoader, buildLink, buildDocHandler, runSpec.getHttpPort());\n        } catch (Exception e) {\n            throw UncheckedException.throwAsUncheckedException(e);\n        } finally {\n            thread.setContextClassLoader(previousContextClassLoader);\n        }\n    }","commit_id":"8d0f67f0b67bc4014eb366a991fb07f46c60abf8","url":"https://github.com/gradle/gradle"},{"original_method":"private void disableUrlConnectionCaching() {\n        // fix problems in updating jar files by disabling default caching of URL connections.\n        // URLConnection default caching should be disabled since it causes jar file locking issues and JVM crashes in updating jar files.\n        // Changes to jar files won't be noticed in all cases when caching is enabled.\n        // sun.net.www.protocol.jar.JarURLConnection leaves the JarFile instance open if URLConnection caching is enabled.\n        try {\n            URL url = new URL(\"jar:file://valid_jar_url_syntax.jar!/\");\n            URLConnection urlConnection = url.openConnection();\n            urlConnection.setDefaultUseCaches(false);\n        } catch (MalformedURLException e) {\n            UncheckedException.throwAsUncheckedException(e);\n        } catch (IOException e) {\n            UncheckedException.throwAsUncheckedException(e);\n        }\n    }","id":36106,"modified_method":"private void disableUrlConnectionCaching() {\n        // fix problems in updating jar files by disabling default caching of URL connections.\n        // URLConnection default caching should be disabled since it causes jar file locking issues and JVM crashes in updating jar files.\n        // Changes to jar files won't be noticed in all cases when caching is enabled.\n        // sun.net.www.protocol.jar.JarURLConnection leaves the JarFile instance open if URLConnection caching is enabled.\n        try {\n            URL url = new URL(\"jar:file://valid_jar_url_syntax.jar!/\");\n            URLConnection urlConnection = url.openConnection();\n            urlConnection.setDefaultUseCaches(false);\n        } catch (MalformedURLException e) {\n            throw UncheckedException.throwAsUncheckedException(e);\n        } catch (IOException e) {\n            throw UncheckedException.throwAsUncheckedException(e);\n        }\n    }","commit_id":"8d0f67f0b67bc4014eb366a991fb07f46c60abf8","url":"https://github.com/gradle/gradle"},{"original_method":"public void taskComplete(TaskInfo task) {\n        lock.lock();\n        try {\n            task.executionSucceeded();\n            condition.signalAll();\n        } finally {\n            lock.unlock();\n        }\n    }","id":36107,"modified_method":"public void taskComplete(TaskInfo taskInfo) {\n        lock.lock();\n        try {\n            if (taskInfo.isFailed()) {\n                handleFailure(taskInfo);\n            }\n\n            taskInfo.finishExecution();\n            condition.signalAll();\n        } finally {\n            lock.unlock();\n        }\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"private void abortExecution(Exception e) {\n        for (TaskInfo taskInfo : executionPlan.values()) {\n            if (taskInfo.isReady()) {\n                taskInfo.startExecution();\n                taskInfo.executionFailed();\n            }\n        }\n        this.failure = e;\n    }","id":36108,"modified_method":"private void abortExecution(Throwable e) {\n        // Allow currently executing tasks to complete, but skip everything else.\n        for (TaskInfo taskInfo : executionPlan.values()) {\n            if (taskInfo.isReady()) {\n                taskInfo.skipExecution();\n            }\n        }\n        this.failure = e;\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public void awaitCompletion() {\n        lock.lock();\n        try {\n            while (!allTasksComplete()) {\n                try {\n                    condition.await();\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n            }\n            if (failure != null) {\n                UncheckedException.throwAsUncheckedException(failure);\n            }\n        } finally {\n            lock.unlock();\n        }\n    }","id":36109,"modified_method":"public void awaitCompletion() {\n        lock.lock();\n        try {\n            while (!allTasksComplete()) {\n                try {\n                    condition.await();\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n            }\n            if (failure != null) {\n                throw UncheckedException.throwAsUncheckedException(failure);\n            }\n        } finally {\n            lock.unlock();\n        }\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public TaskInfo getTaskToExecute(Spec<TaskInfo> criteria) {\n        lock.lock();\n        try {\n\n            TaskInfo nextMatching;\n            while ((nextMatching = getNextReadyAndMatching(criteria)) != null) {\n                while (!nextMatching.dependenciesExecuted()) {\n                    try {\n                        condition.await();\n                    } catch (InterruptedException e) {\n                        throw new RuntimeException(e);\n                    }\n                }\n\n                nextMatching.startExecution();\n\n                if (nextMatching.dependenciesFailed()) {\n                    abortTask(nextMatching);\n                } else {\n                    return nextMatching;\n                }\n            }\n\n            return null;\n\n        } finally {\n            lock.unlock();\n        }\n\n    }","id":36110,"modified_method":"public TaskInfo getTaskToExecute(Spec<TaskInfo> criteria) {\n        lock.lock();\n        try {\n\n            TaskInfo nextMatching;\n            while ((nextMatching = getNextReadyAndMatching(criteria)) != null) {\n                while (!nextMatching.allDependenciesComplete()) {\n                    try {\n                        condition.await();\n                    } catch (InterruptedException e) {\n                        throw new RuntimeException(e);\n                    }\n                }\n\n                if (nextMatching.allDependenciesSuccessful()) {\n                    nextMatching.startExecution();\n                    return nextMatching;\n                } else {\n                    nextMatching.skipExecution();\n                    condition.signalAll();\n                }\n            }\n\n            return null;\n\n        } finally {\n            lock.unlock();\n        }\n\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public void taskFailed(TaskInfo taskInfo) {\n        lock.lock();\n        try {\n            taskInfo.executionFailed();\n            try {\n                failureHandler.onTaskFailure(taskInfo.getTask());\n            } catch (Exception e) {\n                abortExecution(e);\n            }\n            condition.signalAll();\n        } finally {\n            lock.unlock();\n        }\n    }","id":36111,"modified_method":"private void handleFailure(TaskInfo taskInfo) {\n        if (taskInfo.getExecutionFailure() != null) {\n            abortExecution(taskInfo.getExecutionFailure());\n            return;\n        }\n\n        try {\n            failureHandler.onTaskFailure(taskInfo.getTask());\n        } catch (Exception e) {\n            // The failure handler rethrows exception: this means that execution of other tasks is aborted\n            abortExecution(e);\n        }\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public void process(TaskExecutionPlan taskExecutionPlan, TaskExecutionListener taskListener) {\n        Spec<TaskInfo> anyTask = Specs.satisfyAll();\n        TaskInfo taskInfo = taskExecutionPlan.getTaskToExecute(anyTask);\n        while (taskInfo != null) {\n            executeTask(taskInfo, taskExecutionPlan, taskListener);\n            taskInfo = taskExecutionPlan.getTaskToExecute(anyTask);\n        }\n        taskExecutionPlan.awaitCompletion();\n    }","id":36112,"modified_method":"public void process(TaskExecutionPlan taskExecutionPlan, TaskExecutionListener taskListener) {\n        Spec<TaskInfo> anyTask = Specs.satisfyAll();\n        TaskInfo taskInfo = taskExecutionPlan.getTaskToExecute(anyTask);\n        while (taskInfo != null) {\n            processTask(taskInfo, taskExecutionPlan, taskListener);\n            taskInfo = taskExecutionPlan.getTaskToExecute(anyTask);\n        }\n        taskExecutionPlan.awaitCompletion();\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"protected void executeTask(TaskInfo taskInfo, TaskExecutionPlan taskExecutionPlan, TaskExecutionListener taskListener) {\n        TaskInternal task = taskInfo.getTask();\n        for (TaskInfo dependency : taskInfo.getDependencies()) {\n            if (!dependency.isComplete()) {\n                // Cannot execute this task, as some dependencies have not been executed\n                String message = String.format(\"Cannot execute %s, as dependency %s has not been executed\", task.getPath(), dependency.getTask().getPath());\n                // TODO:DAZ This should not be warning\n                LOGGER.warn(message);\n                return;\n            }\n        }\n\n        taskListener.beforeExecute(task);\n        try {\n            task.executeWithoutThrowingTaskFailure();\n        } finally {\n            taskListener.afterExecute(task, task.getState());\n        }\n\n        if (task.getState().getFailure() != null) {\n            // TODO Not sure if we play well with --continue\n            taskExecutionPlan.taskFailed(taskInfo);\n        } else {\n            taskExecutionPlan.taskComplete(taskInfo);\n        }\n    }","id":36113,"modified_method":"private void executeTask(TaskInfo taskInfo, TaskExecutionListener taskListener) {\n        TaskInternal task = taskInfo.getTask();\n        taskListener.beforeExecute(task);\n        try {\n            task.executeWithoutThrowingTaskFailure();\n        } finally {\n            taskListener.afterExecute(task, task.getState());\n        }\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"private void executeTaskWithCacheLock(final TaskInfo taskInfo) {\n            final String taskPath = taskInfo.getTask().getPath();\n            LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \" - start\");\n            stateCacheAccess.useCache(\"Executing \" + taskPath, new Runnable() {\n                public void run() {\n                    LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - have cache: executing\");\n                    executeTask(taskInfo, taskExecutionPlan, taskListener);\n                    LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - execute done: releasing cache\");\n                }\n            });\n            LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - complete\");\n        }","id":36114,"modified_method":"private void executeTaskWithCacheLock(final TaskInfo taskInfo) {\n            final String taskPath = taskInfo.getTask().getPath();\n            LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \" - start\");\n            stateCacheAccess.useCache(\"Executing \" + taskPath, new Runnable() {\n                public void run() {\n                    LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - have cache: executing\");\n                    processTask(taskInfo, taskExecutionPlan, taskListener);\n                    LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - execute done: releasing cache\");\n                }\n            });\n            LOGGER.warn(taskPath + \" (\" + Thread.currentThread() + \") - complete\");\n        }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public void executionFailed() {\n        assert state == TaskExecutionState.EXECUTING;\n        state = TaskExecutionState.FAILED;\n    }","id":36115,"modified_method":"public Throwable getExecutionFailure() {\n        return this.executionFailure;\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public boolean isFailed() {\n        return state == TaskExecutionState.FAILED;\n    }","id":36116,"modified_method":"public boolean isFailed() {\n        return getTaskFailure() != null || getExecutionFailure() != null;\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public boolean isComplete() {\n        return state == TaskExecutionState.SUCCEEDED || state == TaskExecutionState.FAILED;\n    }","id":36117,"modified_method":"public boolean isComplete() {\n        return state == TaskExecutionState.EXECUTED || state == TaskExecutionState.SKIPPED;\n    }","commit_id":"23f8e11968cd276ce50fde341397ae2aba28accf","url":"https://github.com/gradle/gradle"},{"original_method":"public void execute(final Runnable command) {\n            executor.execute(new Runnable() {\n                public void run() {\n                    executing.set(command);\n                    try {\n                        command.run();\n                    } catch (Throwable throwable) {\n                        failureHandler.dispatchFailed(command, throwable);\n                    } finally {\n                        executing.set(null);\n                    }\n                }\n            });\n        }","id":36118,"modified_method":"public void execute(final Runnable command) {\n            executor.execute(new Runnable() {\n                public void run() {\n                    executing.set(command);\n                    try {\n                        command.run();\n                    } catch (Throwable throwable) {\n                        if (!failure.compareAndSet(null, throwable)) {\n                            LOGGER.error(String.format(\"Failed to execute %s.\", command), throwable);\n                        }\n                    } finally {\n                        executing.set(null);\n                    }\n                }\n            });\n        }","commit_id":"4a9226bc00828a289f01a638b06a03802277f132","url":"https://github.com/gradle/gradle"},{"original_method":"public StoppableExecutorImpl(ExecutorService executor) {\n            this.executor = executor;\n            failureHandler = new ExceptionTrackingFailureHandler(LoggerFactory.getLogger(StoppableExecutorImpl.class));\n        }","id":36119,"modified_method":"public StoppableExecutorImpl(ExecutorService executor) {\n            this.executor = executor;\n        }","commit_id":"4a9226bc00828a289f01a638b06a03802277f132","url":"https://github.com/gradle/gradle"},{"original_method":"public void stop(int timeoutValue, TimeUnit timeoutUnits) throws IllegalStateException {\n            requestStop();\n            if (executing.get() != null) {\n                throw new IllegalStateException(\"Cannot stop this executor from an executor thread.\");\n            }\n            try {\n                try {\n                    if (!executor.awaitTermination(timeoutValue, timeoutUnits)) {\n                        executor.shutdownNow();\n                        throw new IllegalStateException(\"Timeout waiting for concurrent jobs to complete.\");\n                    }\n                } catch (InterruptedException e) {\n                    throw new UncheckedException(e);\n                }\n                try {\n                    failureHandler.stop();\n                } catch (DispatchException e) {\n                    throw UncheckedException.throwAsUncheckedException(e.getCause());\n                }\n            } finally {\n                executors.remove(this);\n            }\n        }","id":36120,"modified_method":"public void stop(int timeoutValue, TimeUnit timeoutUnits) throws IllegalStateException {\n            requestStop();\n            if (executing.get() != null) {\n                throw new IllegalStateException(\"Cannot stop this executor from an executor thread.\");\n            }\n            try {\n                try {\n                    if (!executor.awaitTermination(timeoutValue, timeoutUnits)) {\n                        executor.shutdownNow();\n                        throw new IllegalStateException(\"Timeout waiting for concurrent jobs to complete.\");\n                    }\n                } catch (InterruptedException e) {\n                    throw new UncheckedException(e);\n                }\n                if (failure.get() != null) {\n                    throw UncheckedException.throwAsUncheckedException(failure.get());\n                }\n            } finally {\n                executors.remove(this);\n            }\n        }","commit_id":"4a9226bc00828a289f01a638b06a03802277f132","url":"https://github.com/gradle/gradle"},{"original_method":"@Override\n    public FileWatcher watch(Iterable<? extends File> roots, FileWatcherListener listener) {\n        WatchServiceFileWatcher fileWatcher = null;\n        try {\n            fileWatcher = new WatchServiceFileWatcher(roots, listener);\n        } catch (IOException e) {\n            UncheckedException.throwAsUncheckedException(e);\n        }\n        executor.submit(fileWatcher);\n        return fileWatcher;\n    }","id":36121,"modified_method":"@Override\n    public FileWatcher watch(Iterable<? extends File> roots, FileWatcherListener listener) {\n        try {\n            WatchService watchService = FileSystems.getDefault().newWatchService();\n            WatchServiceFileWatcherBacking backing = new WatchServiceFileWatcherBacking(roots, listener, watchService);\n            return backing.start(executor);\n        } catch (IOException e) {\n            throw UncheckedException.throwAsUncheckedException(e);\n        }\n    }","commit_id":"04e5d3334d6afa6ab57b56be7032811efe2c8a76","url":"https://github.com/gradle/gradle"},{"original_method":"public Jdk7FileWatcherFactory(ExecutorService executor) {\n        this.executor = executor;\n    }","id":36122,"modified_method":"public Jdk7FileWatcherFactory(ExecutorService executor) {\n        this.executor = MoreExecutors.listeningDecorator(executor);\n    }","commit_id":"04e5d3334d6afa6ab57b56be7032811efe2c8a76","url":"https://github.com/gradle/gradle"},{"original_method":"@Override\n\tpublic void enableLocalStaging(\n\t\t\tlong userId, Group scopeGroup, Group liveGroup,\n\t\t\tboolean branchingPublic, boolean branchingPrivate,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tif (liveGroup.isStagedRemotely()) {\n\t\t\tdisableStaging(liveGroup, serviceContext);\n\t\t}\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branchingPrivate\", String.valueOf(branchingPrivate));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branchingPublic\", String.valueOf(branchingPublic));\n\t\ttypeSettingsProperties.setProperty(\"staged\", Boolean.TRUE.toString());\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"stagedRemotely\", String.valueOf(false));\n\n\t\tsetCommonStagingOptions(\n\t\t\tliveGroup, typeSettingsProperties, serviceContext);\n\n\t\tif (!liveGroup.hasStagingGroup()) {\n\t\t\tserviceContext.setAttribute(\"staging\", String.valueOf(true));\n\n\t\t\tGroup stagingGroup = GroupLocalServiceUtil.addGroup(\n\t\t\t\tuserId, GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\t\tliveGroup.getClassName(), liveGroup.getClassPK(),\n\t\t\t\tliveGroup.getGroupId(), liveGroup.getDescriptiveName(),\n\t\t\t\tliveGroup.getDescription(), liveGroup.getType(),\n\t\t\t\tliveGroup.isManualMembership(),\n\t\t\t\tliveGroup.getMembershipRestriction(),\n\t\t\t\tliveGroup.getFriendlyURL(), false, liveGroup.isActive(),\n\t\t\t\tserviceContext);\n\n\t\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\t\tif (liveGroup.hasPrivateLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\ttrue, parameterMap, null, null);\n\t\t\t}\n\n\t\t\tif (liveGroup.hasPublicLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\tfalse, parameterMap, null, null);\n\t\t\t}\n\n\t\t\tcheckDefaultLayoutSetBranches(\n\t\t\t\tuserId, liveGroup, branchingPublic, branchingPrivate, false,\n\t\t\t\tserviceContext);\n\t\t}\n\t\telse {\n\t\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\t\tcheckDefaultLayoutSetBranches(\n\t\t\t\tuserId, liveGroup, branchingPublic, branchingPrivate, false,\n\t\t\t\tserviceContext);\n\n\t\t\tif (!branchingPublic) {\n\t\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\t\tliveGroup.getStagingGroup().getGroupId(), false, true);\n\t\t\t}\n\n\t\t\tif (!branchingPrivate) {\n\t\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\t\tliveGroup.getStagingGroup().getGroupId(), true, true);\n\t\t\t}\n\t\t}\n\t}","id":36123,"modified_method":"@Override\n\tpublic void enableLocalStaging(\n\t\t\tlong userId, Group scopeGroup, Group liveGroup,\n\t\t\tboolean branchingPublic, boolean branchingPrivate,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tif (liveGroup.isStagedRemotely()) {\n\t\t\tdisableStaging(liveGroup, serviceContext);\n\t\t}\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branchingPrivate\", String.valueOf(branchingPrivate));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branchingPublic\", String.valueOf(branchingPublic));\n\t\ttypeSettingsProperties.setProperty(\"staged\", Boolean.TRUE.toString());\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"stagedRemotely\", String.valueOf(false));\n\n\t\tsetCommonStagingOptions(\n\t\t\tliveGroup, typeSettingsProperties, serviceContext);\n\n\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\tif (!liveGroup.hasStagingGroup()) {\n\t\t\tserviceContext.setAttribute(\"staging\", String.valueOf(true));\n\n\t\t\tGroup stagingGroup = GroupLocalServiceUtil.addGroup(\n\t\t\t\tuserId, GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\t\tliveGroup.getClassName(), liveGroup.getClassPK(),\n\t\t\t\tliveGroup.getGroupId(), liveGroup.getDescriptiveName(),\n\t\t\t\tliveGroup.getDescription(), liveGroup.getType(),\n\t\t\t\tliveGroup.isManualMembership(),\n\t\t\t\tliveGroup.getMembershipRestriction(),\n\t\t\t\tliveGroup.getFriendlyURL(), false, liveGroup.isActive(),\n\t\t\t\tserviceContext);\n\n\t\t\tif (liveGroup.hasPrivateLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\ttrue, parameterMap, null, null);\n\t\t\t}\n\n\t\t\tif (liveGroup.hasPublicLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\tfalse, parameterMap, null, null);\n\t\t\t}\n\t\t}\n\n\t\tcheckDefaultLayoutSetBranches(\n\t\t\tuserId, liveGroup, branchingPublic, branchingPrivate, false,\n\t\t\tserviceContext);\n\t}","commit_id":"02889ad0498b73241df88f0e357161ef993f53c8","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void checkDefaultLayoutSetBranches(\n\t\t\tlong userId, Group liveGroup, boolean branchingPublic,\n\t\t\tboolean branchingPrivate, boolean remote,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tlong targetGroupId = 0;\n\n\t\tif (remote) {\n\t\t\ttargetGroupId = liveGroup.getGroupId();\n\t\t}\n\t\telse {\n\t\t\tGroup stagingGroup = liveGroup.getStagingGroup();\n\n\t\t\tif (stagingGroup == null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\ttargetGroupId = stagingGroup.getGroupId();\n\t\t}\n\n\t\tif (branchingPublic) {\n\t\t\tLayoutSetBranch layoutSetBranch =\n\t\t\t\tLayoutSetBranchLocalServiceUtil.fetchLayoutSetBranch(\n\t\t\t\t\ttargetGroupId, false,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME);\n\n\t\t\tif (layoutSetBranch == null) {\n\t\t\t\taddDefaultLayoutSetBranch(\n\t\t\t\t\tuserId, targetGroupId, liveGroup.getDescriptiveName(),\n\t\t\t\t\tfalse, serviceContext);\n\t\t\t}\n\t\t}\n\n\t\tif (branchingPrivate) {\n\t\t\tLayoutSetBranch layoutSetBranch =\n\t\t\t\tLayoutSetBranchLocalServiceUtil.fetchLayoutSetBranch(\n\t\t\t\t\ttargetGroupId, true,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME);\n\n\t\t\tif (layoutSetBranch == null) {\n\t\t\t\taddDefaultLayoutSetBranch(\n\t\t\t\t\tuserId, targetGroupId, liveGroup.getDescriptiveName(), true,\n\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t}","id":36124,"modified_method":"protected void checkDefaultLayoutSetBranches(\n\t\t\tlong userId, Group liveGroup, boolean branchingPublic,\n\t\t\tboolean branchingPrivate, boolean remote,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tlong targetGroupId = 0;\n\n\t\tif (remote) {\n\t\t\ttargetGroupId = liveGroup.getGroupId();\n\t\t}\n\t\telse {\n\t\t\tGroup stagingGroup = liveGroup.getStagingGroup();\n\n\t\t\tif (stagingGroup == null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\ttargetGroupId = stagingGroup.getGroupId();\n\t\t}\n\n\t\tif (branchingPublic) {\n\t\t\tLayoutSetBranch layoutSetBranch =\n\t\t\t\tLayoutSetBranchLocalServiceUtil.fetchLayoutSetBranch(\n\t\t\t\t\ttargetGroupId, false,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME);\n\n\t\t\tif (layoutSetBranch == null) {\n\t\t\t\taddDefaultLayoutSetBranch(\n\t\t\t\t\tuserId, targetGroupId, liveGroup.getDescriptiveName(),\n\t\t\t\t\tfalse, serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\ttargetGroupId, false, true);\n\t\t}\n\n\t\tif (branchingPrivate) {\n\t\t\tLayoutSetBranch layoutSetBranch =\n\t\t\t\tLayoutSetBranchLocalServiceUtil.fetchLayoutSetBranch(\n\t\t\t\t\ttargetGroupId, true,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME);\n\n\t\t\tif (layoutSetBranch == null) {\n\t\t\t\taddDefaultLayoutSetBranch(\n\t\t\t\t\tuserId, targetGroupId, liveGroup.getDescriptiveName(), true,\n\t\t\t\t\tserviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\ttargetGroupId, true, true);\n\t\t}\n\t}","commit_id":"02889ad0498b73241df88f0e357161ef993f53c8","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testWithLayoutGroup() throws Exception {\n\t\tGroup group = setTrashEntriesMaxAge(\n\t\t\tcreateGroup(TestPropsValues.getCompanyId()), 2);\n\n\t\tverifyCleanUpAfterTwoDays(createLayoutGroup(group.getGroupId()));\n\t}","id":36125,"modified_method":"@Test\n\tpublic void testWithLayoutGroup() throws Exception {\n\t\tGroup group = setTrashEntriesMaxAge(\n\t\t\tcreateGroup(TestPropsValues.getCompanyId()), 2);\n\n\t\tverifyCleanUpAfterTwoDays(createLayoutGroup(group));\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Group createLayoutGroup(long groupId) throws Exception {\n\t\tGroup group = GroupLocalServiceUtil.getGroup(groupId);\n\n\t\tLayout layout = LayoutTestUtil.addLayout(group);\n\n\t\tlayout = LayoutLocalServiceUtil.getLayout(layout.getPlid());\n\n\t\tString name = String.valueOf(layout.getPlid());\n\n\t\tUser user = UserTestUtil.getAdminUser(group.getCompanyId());\n\n\t\tGroup layoutGroup = GroupLocalServiceUtil.addGroup(\n\t\t\tuser.getUserId(), GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\tLayout.class.getName(), layout.getPlid(),\n\t\t\tGroupConstants.DEFAULT_LIVE_GROUP_ID, name, null, 0, true,\n\t\t\tGroupConstants.DEFAULT_MEMBERSHIP_RESTRICTION, null, false, true,\n\t\t\tnull);\n\n\t\treturn GroupLocalServiceUtil.getGroup(layoutGroup.getGroupId());\n\t}","id":36126,"modified_method":"protected Group createLayoutGroup(Group group) throws Exception {\n\t\tLayout layout = LayoutTestUtil.addLayout(group);\n\n\t\tString name = String.valueOf(layout.getPlid());\n\n\t\tUser user = UserTestUtil.getAdminUser(group.getCompanyId());\n\n\t\treturn GroupLocalServiceUtil.addGroup(\n\t\t\tuser.getUserId(), GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\tLayout.class.getName(), layout.getPlid(),\n\t\t\tGroupConstants.DEFAULT_LIVE_GROUP_ID, name, null, 0, true,\n\t\t\tGroupConstants.DEFAULT_MEMBERSHIP_RESTRICTION, null, false, true,\n\t\t\tnull);\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testWithStaging() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEntriesMaxAge(createGroup(companyId), 2);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false,\n\t\t\tServiceContextTestUtil.getServiceContext(group, user.getUserId()));\n\n\t\tgroup = GroupLocalServiceUtil.getGroup(group.getGroupId());\n\n\t\tverifyCleanUpAfterTwoDays(group.getStagingGroup());\n\t}","id":36127,"modified_method":"@Test\n\tpublic void testWithStaging() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEntriesMaxAge(createGroup(companyId), 2);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false,\n\t\t\tServiceContextTestUtil.getServiceContext(group, user.getUserId()));\n\n\t\tverifyCleanUpAfterTwoDays(group.getStagingGroup());\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Group createGroup(long companyId) throws Exception {\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tGroup group = GroupTestUtil.addGroup(\n\t\t\tcompanyId, user.getUserId(), GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\tRandomTestUtil.randomString(), \"This is a test group.\");\n\n\t\treturn GroupLocalServiceUtil.getGroup(group.getGroupId());\n\t}","id":36128,"modified_method":"protected Group createGroup(long companyId) throws Exception {\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\treturn GroupTestUtil.addGroup(\n\t\t\tcompanyId, user.getUserId(), GroupConstants.DEFAULT_PARENT_GROUP_ID,\n\t\t\tRandomTestUtil.randomString(), \"This is a test group.\");\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Group setTrashEnableForGroup(Group group, boolean value)\n\t\tthrows Exception {\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tgroup.getParentLiveGroupTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"trashEnabled\", String.valueOf(value));\n\n\t\tgroup.setTypeSettingsProperties(typeSettingsProperties);\n\n\t\tGroupLocalServiceUtil.updateGroup(group);\n\n\t\treturn GroupLocalServiceUtil.getGroup(group.getGroupId());\n\t}","id":36129,"modified_method":"protected Group setTrashEnableForGroup(Group group, boolean value)\n\t\tthrows Exception {\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tgroup.getParentLiveGroupTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"trashEnabled\", String.valueOf(value));\n\n\t\tgroup.setTypeSettingsProperties(typeSettingsProperties);\n\n\t\treturn GroupLocalServiceUtil.updateGroup(group);\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Group setTrashEntriesMaxAge(Group group, double days)\n\t\tthrows Exception {\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tgroup.getParentLiveGroupTypeSettingsProperties();\n\n\t\tint companyTrashEntriesMaxAge = PrefsPropsUtil.getInteger(\n\t\t\tgroup.getCompanyId(), PropsKeys.TRASH_ENTRIES_MAX_AGE);\n\n\t\tif (days > 0) {\n\t\t\tdays *= 1440;\n\t\t}\n\t\telse {\n\t\t\tdays = GetterUtil.getInteger(\n\t\t\t\ttypeSettingsProperties.getProperty(\"trashEntriesMaxAge\"),\n\t\t\t\tcompanyTrashEntriesMaxAge);\n\t\t}\n\n\t\tif (days != companyTrashEntriesMaxAge) {\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"trashEntriesMaxAge\",\n\t\t\t\tString.valueOf(GetterUtil.getInteger(days)));\n\t\t}\n\t\telse {\n\t\t\ttypeSettingsProperties.remove(\"trashEntriesMaxAge\");\n\t\t}\n\n\t\tgroup.setTypeSettingsProperties(typeSettingsProperties);\n\n\t\tGroupLocalServiceUtil.updateGroup(group);\n\n\t\treturn GroupLocalServiceUtil.getGroup(group.getGroupId());\n\t}","id":36130,"modified_method":"protected Group setTrashEntriesMaxAge(Group group, double days)\n\t\tthrows Exception {\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tgroup.getParentLiveGroupTypeSettingsProperties();\n\n\t\tint companyTrashEntriesMaxAge = PrefsPropsUtil.getInteger(\n\t\t\tgroup.getCompanyId(), PropsKeys.TRASH_ENTRIES_MAX_AGE);\n\n\t\tif (days > 0) {\n\t\t\tdays *= 1440;\n\t\t}\n\t\telse {\n\t\t\tdays = GetterUtil.getInteger(\n\t\t\t\ttypeSettingsProperties.getProperty(\"trashEntriesMaxAge\"),\n\t\t\t\tcompanyTrashEntriesMaxAge);\n\t\t}\n\n\t\tif (days != companyTrashEntriesMaxAge) {\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"trashEntriesMaxAge\",\n\t\t\t\tString.valueOf(GetterUtil.getInteger(days)));\n\t\t}\n\t\telse {\n\t\t\ttypeSettingsProperties.remove(\"trashEntriesMaxAge\");\n\t\t}\n\n\t\tgroup.setTypeSettingsProperties(typeSettingsProperties);\n\n\t\treturn GroupLocalServiceUtil.updateGroup(group);\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testWithStagingTrashDisabled() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEnableForGroup(createGroup(companyId), false);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tServiceContext serviceContext =\n\t\t\t\tServiceContextTestUtil.getServiceContext(\n\t\t\t\t\tgroup, user.getUserId());\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false, serviceContext);\n\n\t\tgroup = GroupLocalServiceUtil.getGroup(group.getGroupId());\n\n\t\tGroup stagingGroup = group.getStagingGroup();\n\n\t\tcreateFileEntriesAndMoveThemToTrash(stagingGroup.getGroupId(), 5, 0);\n\n\t\tTrashEntryLocalServiceUtil.checkEntries();\n\n\t\t// Note that this should be empty\n\n\t\tAssert.assertEquals(\n\t\t\t0, TrashEntryLocalServiceUtil.getTrashEntriesCount());\n\t}","id":36131,"modified_method":"@Test\n\tpublic void testWithStagingTrashDisabled() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEnableForGroup(createGroup(companyId), false);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tServiceContext serviceContext =\n\t\t\tServiceContextTestUtil.getServiceContext(group, user.getUserId());\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false, serviceContext);\n\n\t\tGroup stagingGroup = group.getStagingGroup();\n\n\t\tcreateFileEntriesAndMoveThemToTrash(stagingGroup.getGroupId(), 5, 0);\n\n\t\tTrashEntryLocalServiceUtil.checkEntries();\n\n\t\t// Note that this should be empty\n\n\t\tAssert.assertEquals(\n\t\t\t0, TrashEntryLocalServiceUtil.getTrashEntriesCount());\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testWithStagingPageScope() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEntriesMaxAge(createGroup(companyId), 2);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tServiceContext serviceContext =\n\t\t\tServiceContextTestUtil.getServiceContext(group, user.getUserId());\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false, serviceContext);\n\n\t\tgroup = GroupLocalServiceUtil.getGroup(group.getGroupId());\n\n\t\tgroup = createLayoutGroup(group.getStagingGroup().getGroupId());\n\n\t\tverifyCleanUpAfterTwoDays(group);\n\t}","id":36132,"modified_method":"@Test\n\tpublic void testWithStagingPageScope() throws Exception {\n\t\tlong companyId = TestPropsValues.getCompanyId();\n\n\t\tGroup group = setTrashEntriesMaxAge(createGroup(companyId), 2);\n\n\t\tUser user = UserTestUtil.getAdminUser(companyId);\n\n\t\tServiceContext serviceContext =\n\t\t\tServiceContextTestUtil.getServiceContext(group, user.getUserId());\n\n\t\tStagingLocalServiceUtil.enableLocalStaging(\n\t\t\tuser.getUserId(), group, false, false, serviceContext);\n\n\t\tgroup = createLayoutGroup(group.getStagingGroup());\n\n\t\tverifyCleanUpAfterTwoDays(group);\n\t}","commit_id":"27d82ee8a16fdf53cc89817189988a88bec616a1","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void doReceive(Message message, MessageStatus messageStatus)\n\t\tthrows Exception {\n\n\t\tLayoutsLocalPublisherRequest publisherRequest =\n\t\t\t(LayoutsLocalPublisherRequest)message.getPayload();\n\n\t\tmessageStatus.setPayload(publisherRequest);\n\n\t\tString command = publisherRequest.getCommand();\n\t\tlong userId = publisherRequest.getUserId();\n\t\tlong sourceGroupId = publisherRequest.getSourceGroupId();\n\t\tlong targetGroupId = publisherRequest.getTargetGroupId();\n\t\tboolean privateLayout = publisherRequest.isPrivateLayout();\n\t\tMap<Long, Boolean> layoutIdMap = publisherRequest.getLayoutIdMap();\n\t\tMap<String, String[]> parameterMap = publisherRequest.getParameterMap();\n\t\tDate startDate = publisherRequest.getStartDate();\n\t\tDate endDate = publisherRequest.getEndDate();\n\n\t\tString range = MapUtil.getString(parameterMap, \"range\");\n\n\t\tif (range.equals(\"last\")) {\n\t\t\tint last = MapUtil.getInteger(parameterMap, \"last\");\n\n\t\t\tif (last > 0) {\n\t\t\t\tDate scheduledFireTime =\n\t\t\t\t\tpublisherRequest.getScheduledFireTime();\n\n\t\t\t\tstartDate = new Date(\n\t\t\t\t\tscheduledFireTime.getTime() - (last * Time.HOUR));\n\n\t\t\t\tendDate = scheduledFireTime;\n\t\t\t}\n\t\t}\n\n\t\tPrincipalThreadLocal.setName(userId);\n\n\t\tUser user = UserLocalServiceUtil.getUserById(userId);\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tPermissionCheckerFactoryUtil.create(user, false);\n\n\t\tPermissionThreadLocal.setPermissionChecker(permissionChecker);\n\n\t\ttry {\n\t\t\tif (command.equals(\n\t\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_ALL_PAGES)) {\n\n\t\t\t\tStagingUtil.publishLayouts(\n\t\t\t\t\tsourceGroupId, targetGroupId, privateLayout, parameterMap,\n\t\t\t\t\tstartDate, endDate);\n\t\t\t}\n\t\t\telse if (command.equals(\n\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_SELECTED_PAGES)) {\n\n\t\t\t\tStagingUtil.publishLayouts(\n\t\t\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIdMap,\n\t\t\t\t\tparameterMap, startDate, endDate);\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tPrincipalThreadLocal.setName(null);\n\t\t\tPermissionThreadLocal.setPermissionChecker(null);\n\t\t}\n\t}","id":36133,"modified_method":"protected void doReceive(Message message, MessageStatus messageStatus)\n\t\tthrows Exception {\n\n\t\tLayoutsLocalPublisherRequest publisherRequest =\n\t\t\t(LayoutsLocalPublisherRequest)message.getPayload();\n\n\t\tmessageStatus.setPayload(publisherRequest);\n\n\t\tString command = publisherRequest.getCommand();\n\t\tlong userId = publisherRequest.getUserId();\n\t\tlong sourceGroupId = publisherRequest.getSourceGroupId();\n\t\tlong targetGroupId = publisherRequest.getTargetGroupId();\n\t\tboolean privateLayout = publisherRequest.isPrivateLayout();\n\t\tMap<Long, Boolean> layoutIdMap = publisherRequest.getLayoutIdMap();\n\t\tMap<String, String[]> parameterMap = publisherRequest.getParameterMap();\n\t\tDate startDate = publisherRequest.getStartDate();\n\t\tDate endDate = publisherRequest.getEndDate();\n\n\t\tString range = MapUtil.getString(parameterMap, \"range\");\n\n\t\tif (range.equals(\"last\")) {\n\t\t\tint last = MapUtil.getInteger(parameterMap, \"last\");\n\n\t\t\tif (last > 0) {\n\t\t\t\tDate scheduledFireTime =\n\t\t\t\t\tpublisherRequest.getScheduledFireTime();\n\n\t\t\t\tstartDate = new Date(\n\t\t\t\t\tscheduledFireTime.getTime() - (last * Time.HOUR));\n\n\t\t\t\tendDate = scheduledFireTime;\n\t\t\t}\n\t\t}\n\n\t\tPrincipalThreadLocal.setName(userId);\n\n\t\tUser user = UserLocalServiceUtil.getUserById(userId);\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tPermissionCheckerFactoryUtil.create(user, false);\n\n\t\tPermissionThreadLocal.setPermissionChecker(permissionChecker);\n\n\t\ttry {\n\t\t\tif (command.equals(\n\t\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_ALL_PAGES)) {\n\n\t\t\t\tStagingUtil.publishLayouts(\n\t\t\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\tparameterMap, startDate, endDate);\n\t\t\t}\n\t\t\telse if (command.equals(\n\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_SELECTED_PAGES)) {\n\n\t\t\t\tStagingUtil.publishLayouts(\n\t\t\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\tlayoutIdMap, parameterMap, startDate, endDate);\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tPrincipalThreadLocal.setName(null);\n\t\t\tPermissionThreadLocal.setPermissionChecker(null);\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected String getWorkflowRoleNames(PortletRequest portletRequest) {\n\t\tint workflowStages = ParamUtil.getInteger(\n\t\t\tportletRequest, \"workflowStages\");\n\n\t\tString workflowRoleNames = null;\n\n\t\tif (workflowStages == 0) {\n\t\t\tworkflowRoleNames = StringPool.BLANK;\n\t\t}\n\t\telse {\n\t\t\tStringBundler sb = new StringBundler(workflowStages * 2 - 1);\n\n\t\t\tfor (int i = 1; i <= (workflowStages - 1); i++) {\n\t\t\t\tif (i > 1) {\n\t\t\t\t\tsb.append(StringPool.COMMA);\n\t\t\t\t}\n\n\t\t\t\tString workflowRoleName = ParamUtil.getString(\n\t\t\t\t\tportletRequest, \"workflowRoleName_\" + i);\n\n\t\t\t\tsb.append(workflowRoleName);\n\t\t\t}\n\n\t\t\tString workflowRoleName = ParamUtil.getString(\n\t\t\t\tportletRequest, \"workflowRoleName_Last\");\n\n\t\t\tsb.append(\",\");\n\t\t\tsb.append(workflowRoleName);\n\n\t\t\tworkflowRoleNames = sb.toString();\n\t\t}\n\n\t\treturn workflowRoleNames;\n\t}","id":36134,"modified_method":"protected String getWorkflowRoleNames(ServiceContext serviceContext) {\n\t\tint workflowStages = ParamUtil.getInteger(\n\t\t\tserviceContext, \"workflowStages\");\n\n\t\tString workflowRoleNames = null;\n\n\t\tif (workflowStages == 0) {\n\t\t\tworkflowRoleNames = StringPool.BLANK;\n\t\t}\n\t\telse {\n\t\t\tStringBundler sb = new StringBundler(workflowStages * 2 - 1);\n\n\t\t\tfor (int i = 1; i <= (workflowStages - 1); i++) {\n\t\t\t\tif (i > 1) {\n\t\t\t\t\tsb.append(StringPool.COMMA);\n\t\t\t\t}\n\n\t\t\t\tString workflowRoleName = ParamUtil.getString(\n\t\t\t\t\tserviceContext, \"workflowRoleName_\" + i);\n\n\t\t\t\tsb.append(workflowRoleName);\n\t\t\t}\n\n\t\t\tString workflowRoleName = ParamUtil.getString(\n\t\t\t\tserviceContext, \"workflowRoleName_Last\");\n\n\t\t\tsb.append(\",\");\n\t\t\tsb.append(workflowRoleName);\n\n\t\t\tworkflowRoleNames = sb.toString();\n\t\t}\n\n\t\treturn workflowRoleNames;\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Calendar getDate(\n\t\t\tPortletRequest portletRequest, String paramPrefix,\n\t\t\tboolean timeZoneSensitive)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tint dateMonth = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Month\");\n\t\tint dateDay = ParamUtil.getInteger(portletRequest, paramPrefix + \"Day\");\n\t\tint dateYear = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Year\");\n\t\tint dateHour = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Hour\");\n\t\tint dateMinute = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Minute\");\n\t\tint dateAmPm = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"AmPm\");\n\n\t\tif (dateAmPm == Calendar.PM) {\n\t\t\tdateHour += 12;\n\t\t}\n\n\t\tLocale locale = null;\n\t\tTimeZone timeZone = null;\n\n\t\tif (timeZoneSensitive) {\n\t\t\tlocale = themeDisplay.getLocale();\n\t\t\ttimeZone = themeDisplay.getTimeZone();\n\t\t}\n\t\telse {\n\t\t\tlocale = LocaleUtil.getDefault();\n\t\t\ttimeZone = TimeZoneUtil.getDefault();\n\t\t}\n\n\t\tCalendar cal = CalendarFactoryUtil.getCalendar(timeZone, locale);\n\n\t\tcal.set(Calendar.MONTH, dateMonth);\n\t\tcal.set(Calendar.DATE, dateDay);\n\t\tcal.set(Calendar.YEAR, dateYear);\n\t\tcal.set(Calendar.HOUR_OF_DAY, dateHour);\n\t\tcal.set(Calendar.MINUTE, dateMinute);\n\t\tcal.set(Calendar.SECOND, 0);\n\t\tcal.set(Calendar.MILLISECOND, 0);\n\n\t\treturn cal;\n\t}","id":36135,"modified_method":"protected Calendar getDate(\n\t\t\tPortletRequest portletRequest, String paramPrefix,\n\t\t\tboolean timeZoneSensitive)\n\t\tthrows Exception {\n\n\t\tint dateMonth = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Month\");\n\t\tint dateDay = ParamUtil.getInteger(portletRequest, paramPrefix + \"Day\");\n\t\tint dateYear = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Year\");\n\t\tint dateHour = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Hour\");\n\t\tint dateMinute = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"Minute\");\n\t\tint dateAmPm = ParamUtil.getInteger(\n\t\t\tportletRequest, paramPrefix + \"AmPm\");\n\n\t\tif (dateAmPm == Calendar.PM) {\n\t\t\tdateHour += 12;\n\t\t}\n\n\t\tLocale locale = null;\n\t\tTimeZone timeZone = null;\n\n\t\tif (timeZoneSensitive) {\n\t\t\tThemeDisplay themeDisplay =\n\t\t\t\t(ThemeDisplay)portletRequest.getAttribute(\n\t\t\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\t\tlocale = themeDisplay.getLocale();\n\t\t\ttimeZone = themeDisplay.getTimeZone();\n\t\t}\n\t\telse {\n\t\t\tlocale = LocaleUtil.getDefault();\n\t\t\ttimeZone = TimeZoneUtil.getDefault();\n\t\t}\n\n\t\tCalendar cal = CalendarFactoryUtil.getCalendar(timeZone, locale);\n\n\t\tcal.set(Calendar.MONTH, dateMonth);\n\t\tcal.set(Calendar.DATE, dateDay);\n\t\tcal.set(Calendar.YEAR, dateYear);\n\t\tcal.set(Calendar.HOUR_OF_DAY, dateHour);\n\t\tcal.set(Calendar.MINUTE, dateMinute);\n\t\tcal.set(Calendar.SECOND, 0);\n\t\tcal.set(Calendar.MILLISECOND, 0);\n\n\t\treturn cal;\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void updateStaging(PortletRequest portletRequest) throws Exception {\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tthemeDisplay.getPermissionChecker();\n\n\t\tlong liveGroupId = ParamUtil.getLong(portletRequest, \"liveGroupId\");\n\n\t\tif (!GroupPermissionUtil.contains(\n\t\t\t\tpermissionChecker, liveGroupId, ActionKeys.MANAGE_STAGING)) {\n\n\t\t\tthrow new PrincipalException();\n\t\t}\n\n\t\tint stagingType = ParamUtil.getInteger(portletRequest, \"stagingType\");\n\n\t\tServiceContext serviceContext = ServiceContextFactory.getInstance(\n\t\t\tportletRequest);\n\n\t\tif (stagingType == StagingConstants.TYPE_NOT_STAGED) {\n\t\t\tdisableStaging(portletRequest, liveGroupId);\n\t\t}\n\t\telse if (stagingType == StagingConstants.TYPE_LOCAL_STAGING) {\n\t\t\tenableLocalStaging(portletRequest, liveGroupId, serviceContext);\n\t\t}\n\t\telse if (stagingType == StagingConstants.TYPE_REMOTE_STAGING) {\n\t\t\tenableRemoteStaging(portletRequest, liveGroupId, serviceContext);\n\t\t}\n\t}","id":36136,"modified_method":"public void updateStaging(PortletRequest portletRequest) throws Exception {\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tthemeDisplay.getPermissionChecker();\n\n\t\tlong userId = permissionChecker.getUserId();\n\n\t\tlong scopeGroupId = themeDisplay.getScopeGroupId();\n\n\t\tlong liveGroupId = ParamUtil.getLong(portletRequest, \"liveGroupId\");\n\n\t\tif (!GroupPermissionUtil.contains(\n\t\t\t\tpermissionChecker, liveGroupId, ActionKeys.MANAGE_STAGING)) {\n\n\t\t\tthrow new PrincipalException();\n\t\t}\n\n\t\tint stagingType = ParamUtil.getInteger(portletRequest, \"stagingType\");\n\n\t\tboolean branchingPublic = ParamUtil.getBoolean(\n\t\t\tportletRequest, \"branchingPublic\", false);\n\t\tboolean branchingPrivate = ParamUtil.getBoolean(\n\t\t\tportletRequest, \"branchingPrivate\", false);\n\t\tboolean lockingPublic = ParamUtil.getBoolean(\n\t\t\tportletRequest, \"lockingPublic\", false);\n\t\tboolean lockingPrivate = ParamUtil.getBoolean(\n\t\t\tportletRequest, \"lockingPrivate\", false);\n\n\t\tServiceContext serviceContext =\n\t\t\tServiceContextThreadLocal.getServiceContext();\n\n\t\tif (stagingType == StagingConstants.TYPE_NOT_STAGED) {\n\t\t\tdisableStaging(\n\t\t\t\tportletRequest, scopeGroupId, liveGroupId, serviceContext);\n\t\t}\n\t\telse if (stagingType == StagingConstants.TYPE_LOCAL_STAGING) {\n\t\t\tenableLocalStaging(\n\t\t\t\tuserId, scopeGroupId, liveGroupId, branchingPublic,\n\t\t\t\tbranchingPrivate, lockingPublic, lockingPrivate,\n\t\t\t\tserviceContext);\n\t\t}\n\t\telse if (stagingType == StagingConstants.TYPE_REMOTE_STAGING) {\n\t\t\tString remoteAddress = ParamUtil.getString(\n\t\t\t\tportletRequest, \"remoteAddress\");\n\t\t\tlong remoteGroupId = ParamUtil.getLong(\n\t\t\t\tportletRequest, \"remoteGroupId\");\n\t\t\tint remotePort = ParamUtil.getInteger(portletRequest, \"remotePort\");\n\t\t\tboolean secureConnection = ParamUtil.getBoolean(\n\t\t\t\tportletRequest, \"secureConnection\");\n\n\t\t\tenableRemoteStaging(\n\t\t\t\tuserId, scopeGroupId, liveGroupId, branchingPublic,\n\t\t\t\tbranchingPrivate, lockingPublic, lockingPrivate,\n\t\t\t\tremoteAddress, remoteGroupId, remotePort, secureConnection,\n\t\t\t\tserviceContext);\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void setCommonStagingOptions(\n\t\t\tPortletRequest portletRequest, Group liveGroup,\n\t\t\tUnicodeProperties typeSettingsProperties)\n\t\tthrows Exception {\n\n\t\tLayoutExporter.updateLastPublishDate(\n\t\t\tliveGroup.getPrivateLayoutSet(), 0);\n\t\tLayoutExporter.updateLastPublishDate(\n\t\t\tliveGroup.getPublicLayoutSet(), 0);\n\n\t\tEnumeration<String> enu = portletRequest.getParameterNames();\n\n\t\twhile (enu.hasMoreElements()) {\n\t\t\tString parameterName = enu.nextElement();\n\n\t\t\tboolean staged = MapUtil.getBoolean(\n\t\t\t\tportletRequest.getParameterMap(), parameterName);\n\n\t\t\tif (parameterName.startsWith(StagingConstants.STAGED_PORTLET) &&\n\t\t\t\t!parameterName.endsWith(\"Checkbox\")) {\n\n\t\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\tparameterName, String.valueOf(staged));\n\t\t\t}\n\t\t}\n\n\t\tboolean workflowEnabled = false;\n\n\t\tint workflowStages = ParamUtil.getInteger(\n\t\t\tportletRequest, \"workflowStages\");\n\n\t\tif (workflowStages > 1) {\n\t\t\tworkflowEnabled = true;\n\t\t}\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"workflowEnabled\", String.valueOf(workflowEnabled));\n\n\t\tif (workflowEnabled) {\n\t\t\tString workflowRoleNames = getWorkflowRoleNames(portletRequest);\n\n\t\t\tif (Validator.isNull(workflowRoleNames)) {\n\t\t\t\tworkflowRoleNames = PropsValues.TASKS_DEFAULT_ROLE_NAMES;\n\t\t\t}\n\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"workflowRoleNames\", workflowRoleNames);\n\n\t\t\tif (workflowStages < PropsValues.TASKS_DEFAULT_STAGES) {\n\t\t\t\tworkflowStages = PropsValues.TASKS_DEFAULT_STAGES;\n\t\t\t}\n\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"workflowStages\", String.valueOf(workflowStages));\n\t\t}\n\t}","id":36137,"modified_method":"protected void setCommonStagingOptions(\n\t\t\tGroup liveGroup, UnicodeProperties typeSettingsProperties,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tLayoutExporter.updateLastPublishDate(\n\t\t\tliveGroup.getPrivateLayoutSet(), 0);\n\t\tLayoutExporter.updateLastPublishDate(\n\t\t\tliveGroup.getPublicLayoutSet(), 0);\n\n\t\tSet<String> parameterNames = serviceContext.getAttributes().keySet();\n\n\t\tfor (String parameterName : parameterNames) {\n\t\t\tboolean staged = ParamUtil.getBoolean(\n\t\t\t\tserviceContext, parameterName);\n\n\t\t\tif (parameterName.startsWith(StagingConstants.STAGED_PORTLET) &&\n\t\t\t\t!parameterName.endsWith(\"Checkbox\")) {\n\n\t\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\tparameterName, String.valueOf(staged));\n\t\t\t}\n\t\t}\n\n\t\tboolean workflowEnabled = false;\n\n\t\tint workflowStages = ParamUtil.getInteger(\n\t\t\tserviceContext, \"workflowStages\", 1);\n\n\t\tif (workflowStages > 1) {\n\t\t\tworkflowEnabled = true;\n\t\t}\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"workflowEnabled\", String.valueOf(workflowEnabled));\n\n\t\tif (workflowEnabled) {\n\t\t\tString workflowRoleNames = getWorkflowRoleNames(serviceContext);\n\n\t\t\tif (Validator.isNull(workflowRoleNames)) {\n\t\t\t\tworkflowRoleNames = PropsValues.TASKS_DEFAULT_ROLE_NAMES;\n\t\t\t}\n\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"workflowRoleNames\", workflowRoleNames);\n\n\t\t\tif (workflowStages < PropsValues.TASKS_DEFAULT_STAGES) {\n\t\t\t\tworkflowStages = PropsValues.TASKS_DEFAULT_STAGES;\n\t\t\t}\n\n\t\t\ttypeSettingsProperties.setProperty(\n\t\t\t\t\"workflowStages\", String.valueOf(workflowStages));\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void copyPortlet(\n\t\t\tPortletRequest portletRequest, long sourceGroupId,\n\t\t\tlong targetGroupId, long sourcePlid, long targetPlid,\n\t\t\tString portletId)\n\t\tthrows Exception {\n\n\t\tMap<String, String[]> parameterMap = getStagingParameters(\n\t\t\tportletRequest);\n\n\t\tFile file = LayoutLocalServiceUtil.exportPortletInfoAsFile(\n\t\t\tsourcePlid, sourceGroupId, portletId, parameterMap, null, null);\n\n\t\ttry {\n\t\t\tLayoutServiceUtil.importPortletInfo(\n\t\t\t\ttargetPlid, targetGroupId, portletId, parameterMap, file);\n\t\t}\n\t\tfinally {\n\t\t\tfile.delete();\n\t\t}\n\t}","id":36138,"modified_method":"public void copyPortlet(\n\t\t\tPortletRequest portletRequest, long sourceGroupId,\n\t\t\tlong targetGroupId, long sourcePlid, long targetPlid,\n\t\t\tString portletId)\n\t\tthrows Exception {\n\n\t\tlong userId = PortalUtil.getUserId(portletRequest);\n\n\t\tMap<String, String[]> parameterMap = getStagingParameters(\n\t\t\tportletRequest);\n\n\t\tFile file = LayoutLocalServiceUtil.exportPortletInfoAsFile(\n\t\t\tsourcePlid, sourceGroupId, portletId, parameterMap, null, null);\n\n\t\ttry {\n\t\t\tLayoutLocalServiceUtil.importPortletInfo(\n\t\t\t\tuserId, targetPlid, targetGroupId, portletId, parameterMap,\n\t\t\t\tfile);\n\t\t}\n\t\tfinally {\n\t\t\tfile.delete();\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void copyRemoteLayouts(\n\t\t\tlong sourceGroupId, boolean privateLayout,\n\t\t\tMap<Long, Boolean> layoutIdMap,\n\t\t\tMap<String, String[]> exportParameterMap, String remoteAddress,\n\t\t\tint remotePort, boolean secureConnection, long remoteGroupId,\n\t\t\tboolean remotePrivateLayout,\n\t\t\tMap<String, String[]> importParameterMap, Date startDate,\n\t\t\tDate endDate)\n\t\tthrows Exception {\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tPermissionThreadLocal.getPermissionChecker();\n\n\t\tUser user = UserLocalServiceUtil.getUser(permissionChecker.getUserId());\n\n\t\tStringBundler sb = new StringBundler(4);\n\n\t\tif (secureConnection) {\n\t\t\tsb.append(Http.HTTPS_WITH_SLASH);\n\t\t}\n\t\telse {\n\t\t\tsb.append(Http.HTTP_WITH_SLASH);\n\t\t}\n\n\t\tsb.append(remoteAddress);\n\t\tsb.append(StringPool.COLON);\n\t\tsb.append(remotePort);\n\n\t\tString url = sb.toString();\n\n\t\tHttpPrincipal httpPrincipal = new HttpPrincipal(\n\t\t\turl, user.getEmailAddress(), user.getPassword(),\n\t\t\tuser.getPasswordEncrypted());\n\n\t\t// Ping remote host and verify that the group exists\n\n\t\ttry {\n\t\t\tGroupServiceHttp.getGroup(httpPrincipal, remoteGroupId);\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tRemoteExportException ree = new RemoteExportException(\n\t\t\t\tRemoteExportException.NO_GROUP);\n\n\t\t\tree.setGroupId(remoteGroupId);\n\n\t\t\tthrow ree;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tRemoteExportException ree = new RemoteExportException(\n\t\t\t\tRemoteExportException.BAD_CONNECTION);\n\n\t\t\tree.setURL(url);\n\n\t\t\tthrow ree;\n\t\t}\n\n\t\tbyte[] bytes = null;\n\n\t\tif (layoutIdMap == null) {\n\t\t\tbytes = LayoutServiceUtil.exportLayouts(\n\t\t\t\tsourceGroupId, privateLayout, exportParameterMap, startDate,\n\t\t\t\tendDate);\n\t\t}\n\t\telse {\n\t\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\t\tIterator<Map.Entry<Long, Boolean>> itr1 =\n\t\t\t\tlayoutIdMap.entrySet().iterator();\n\n\t\t\twhile (itr1.hasNext()) {\n\t\t\t\tEntry<Long, Boolean> entry = itr1.next();\n\n\t\t\t\tlong plid = GetterUtil.getLong(String.valueOf(entry.getKey()));\n\t\t\t\tboolean includeChildren = entry.getValue();\n\n\t\t\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\t\t\tif (!layouts.contains(layout)) {\n\t\t\t\t\tlayouts.add(layout);\n\t\t\t\t}\n\n\t\t\t\tIterator<Layout> itr2 = getMissingParentLayouts(\n\t\t\t\t\tlayout, sourceGroupId).iterator();\n\n\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\tLayout parentLayout = itr2.next();\n\n\t\t\t\t\tif (!layouts.contains(parentLayout)) {\n\t\t\t\t\t\tlayouts.add(parentLayout);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (includeChildren) {\n\t\t\t\t\titr2 = layout.getAllChildren().iterator();\n\n\t\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\t\tLayout childLayout = itr2.next();\n\n\t\t\t\t\t\tif (!layouts.contains(childLayout)) {\n\t\t\t\t\t\t\tlayouts.add(childLayout);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\t\tfor (int i = 0; i < layouts.size(); i++) {\n\t\t\t\tLayout curLayout = layouts.get(i);\n\n\t\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t\t}\n\n\t\t\tif (layoutIds.length <= 0) {\n\t\t\t\tthrow new RemoteExportException(\n\t\t\t\t\tRemoteExportException.NO_LAYOUTS);\n\t\t\t}\n\n\t\t\tbytes = LayoutServiceUtil.exportLayouts(\n\t\t\t\tsourceGroupId, privateLayout, layoutIds, exportParameterMap,\n\t\t\t\tstartDate, endDate);\n\t\t}\n\n\t\tLayoutServiceHttp.importLayouts(\n\t\t\thttpPrincipal, remoteGroupId, remotePrivateLayout,\n\t\t\timportParameterMap, bytes);\n\t}","id":36139,"modified_method":"public void copyRemoteLayouts(\n\t\t\tlong sourceGroupId, boolean privateLayout,\n\t\t\tMap<Long, Boolean> layoutIdMap,\n\t\t\tMap<String, String[]> exportParameterMap, String remoteAddress,\n\t\t\tint remotePort, boolean secureConnection, long remoteGroupId,\n\t\t\tboolean remotePrivateLayout,\n\t\t\tMap<String, String[]> importParameterMap, Date startDate,\n\t\t\tDate endDate)\n\t\tthrows Exception {\n\n\t\tPermissionChecker permissionChecker =\n\t\t\tPermissionThreadLocal.getPermissionChecker();\n\n\t\tUser user = UserLocalServiceUtil.getUser(permissionChecker.getUserId());\n\n\t\tStringBundler sb = new StringBundler(4);\n\n\t\tif (secureConnection) {\n\t\t\tsb.append(Http.HTTPS_WITH_SLASH);\n\t\t}\n\t\telse {\n\t\t\tsb.append(Http.HTTP_WITH_SLASH);\n\t\t}\n\n\t\tsb.append(remoteAddress);\n\t\tsb.append(StringPool.COLON);\n\t\tsb.append(remotePort);\n\n\t\tString url = sb.toString();\n\n\t\tHttpPrincipal httpPrincipal = new HttpPrincipal(\n\t\t\turl, user.getEmailAddress(), user.getPassword(),\n\t\t\tuser.getPasswordEncrypted());\n\n\t\t// Ping remote host and verify that the group exists\n\n\t\ttry {\n\t\t\tGroupServiceHttp.getGroup(httpPrincipal, remoteGroupId);\n\t\t}\n\t\tcatch (NoSuchGroupException nsge) {\n\t\t\tRemoteExportException ree = new RemoteExportException(\n\t\t\t\tRemoteExportException.NO_GROUP);\n\n\t\t\tree.setGroupId(remoteGroupId);\n\n\t\t\tthrow ree;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tRemoteExportException ree = new RemoteExportException(\n\t\t\t\tRemoteExportException.BAD_CONNECTION);\n\n\t\t\tree.setURL(url);\n\n\t\t\tthrow ree;\n\t\t}\n\n\t\tbyte[] bytes = null;\n\n\t\tif (layoutIdMap == null) {\n\t\t\tbytes = LayoutLocalServiceUtil.exportLayouts(\n\t\t\t\tsourceGroupId, privateLayout, exportParameterMap, startDate,\n\t\t\t\tendDate);\n\t\t}\n\t\telse {\n\t\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\t\tIterator<Map.Entry<Long, Boolean>> itr1 =\n\t\t\t\tlayoutIdMap.entrySet().iterator();\n\n\t\t\twhile (itr1.hasNext()) {\n\t\t\t\tEntry<Long, Boolean> entry = itr1.next();\n\n\t\t\t\tlong plid = GetterUtil.getLong(String.valueOf(entry.getKey()));\n\t\t\t\tboolean includeChildren = entry.getValue();\n\n\t\t\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\t\t\tif (!layouts.contains(layout)) {\n\t\t\t\t\tlayouts.add(layout);\n\t\t\t\t}\n\n\t\t\t\tIterator<Layout> itr2 = getMissingParentLayouts(\n\t\t\t\t\tlayout, sourceGroupId).iterator();\n\n\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\tLayout parentLayout = itr2.next();\n\n\t\t\t\t\tif (!layouts.contains(parentLayout)) {\n\t\t\t\t\t\tlayouts.add(parentLayout);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (includeChildren) {\n\t\t\t\t\titr2 = layout.getAllChildren().iterator();\n\n\t\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\t\tLayout childLayout = itr2.next();\n\n\t\t\t\t\t\tif (!layouts.contains(childLayout)) {\n\t\t\t\t\t\t\tlayouts.add(childLayout);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\t\tfor (int i = 0; i < layouts.size(); i++) {\n\t\t\t\tLayout curLayout = layouts.get(i);\n\n\t\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t\t}\n\n\t\t\tif (layoutIds.length <= 0) {\n\t\t\t\tthrow new RemoteExportException(\n\t\t\t\t\tRemoteExportException.NO_LAYOUTS);\n\t\t\t}\n\n\t\t\tbytes = LayoutLocalServiceUtil.exportLayouts(\n\t\t\t\tsourceGroupId, privateLayout, layoutIds, exportParameterMap,\n\t\t\t\tstartDate, endDate);\n\t\t}\n\n\t\tLayoutServiceHttp.importLayouts(\n\t\t\thttpPrincipal, remoteGroupId, remotePrivateLayout,\n\t\t\timportParameterMap, bytes);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void publishLayout(\n\t\t\tlong plid, long liveGroupId, boolean includeChildren)\n\t\tthrows Exception {\n\n\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\tparameterMap.put(\n\t\t\tPortletDataHandlerKeys.DELETE_MISSING_LAYOUTS,\n\t\t\tnew String[] {Boolean.FALSE.toString()});\n\n\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\tlayouts.add(layout);\n\n\t\tlayouts.addAll(getMissingParentLayouts(layout, liveGroupId));\n\n\t\tif (includeChildren) {\n\t\t\tlayouts.addAll(layout.getAllChildren());\n\t\t}\n\n\t\tIterator<Layout> itr = layouts.iterator();\n\n\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\tfor (int i = 0; itr.hasNext(); i++) {\n\t\t\tLayout curLayout = itr.next();\n\n\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t}\n\n\t\tpublishLayouts(\n\t\t\tlayout.getGroupId(), liveGroupId, layout.isPrivateLayout(),\n\t\t\tlayoutIds, parameterMap, null, null);\n\t}","id":36140,"modified_method":"public void publishLayout(\n\t\t\tlong userId, long plid, long liveGroupId, boolean includeChildren)\n\t\tthrows Exception {\n\n\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\tparameterMap.put(\n\t\t\tPortletDataHandlerKeys.DELETE_MISSING_LAYOUTS,\n\t\t\tnew String[] {Boolean.FALSE.toString()});\n\n\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\tlayouts.add(layout);\n\n\t\tlayouts.addAll(getMissingParentLayouts(layout, liveGroupId));\n\n\t\tif (includeChildren) {\n\t\t\tlayouts.addAll(layout.getAllChildren());\n\t\t}\n\n\t\tIterator<Layout> itr = layouts.iterator();\n\n\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\tfor (int i = 0; itr.hasNext(); i++) {\n\t\t\tLayout curLayout = itr.next();\n\n\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t}\n\n\t\tpublishLayouts(\n\t\t\tuserId, layout.getGroupId(), liveGroupId, layout.isPrivateLayout(),\n\t\t\tlayoutIds, parameterMap, null, null);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void publishLayouts(\n\t\t\tPortletRequest portletRequest, long sourceGroupId,\n\t\t\tlong targetGroupId, Map<String, String[]> parameterMap,\n\t\t\tboolean schedule)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tString tabs1 = ParamUtil.getString(portletRequest, \"tabs1\");\n\n\t\tboolean privateLayout = true;\n\n\t\tif (tabs1.equals(\"public-pages\")) {\n\t\t\tprivateLayout = false;\n\t\t}\n\n\t\tString scope = ParamUtil.getString(portletRequest, \"scope\");\n\n\t\tMap<Long, Boolean> layoutIdMap = new LinkedHashMap<Long, Boolean>();\n\n\t\tif (scope.equals(\"selected-pages\")) {\n\t\t\tlong[] rowIds = ParamUtil.getLongValues(portletRequest, \"rowIds\");\n\n\t\t\tfor (long selPlid : rowIds) {\n\t\t\t\tboolean includeChildren = ParamUtil.getBoolean(\n\t\t\t\t\tportletRequest, \"includeChildren_\" + selPlid);\n\n\t\t\t\tlayoutIdMap.put(selPlid, includeChildren);\n\t\t\t}\n\t\t}\n\n\t\tString range = ParamUtil.getString(portletRequest, \"range\");\n\n\t\tDate startDate = null;\n\t\tDate endDate = null;\n\n\t\tif (range.equals(\"dateRange\")) {\n\t\t\tstartDate = getDate(portletRequest, \"startDate\", true).getTime();\n\n\t\t\tendDate = getDate(portletRequest, \"endDate\", true).getTime();\n\t\t}\n\t\telse if (range.equals(\"fromLastPublishDate\")) {\n\t\t\tLayoutSet layoutSet = LayoutSetLocalServiceUtil.getLayoutSet(\n\t\t\t\tsourceGroupId, privateLayout);\n\n\t\t\tUnicodeProperties settingsProperties =\n\t\t\t\tlayoutSet.getSettingsProperties();\n\n\t\t\tlong lastPublishDate = GetterUtil.getLong(\n\t\t\t\tsettingsProperties.getProperty(\"last-publish-date\"));\n\n\t\t\tif (lastPublishDate > 0) {\n\t\t\t\tCalendar cal = Calendar.getInstance(\n\t\t\t\t\tthemeDisplay.getTimeZone(), themeDisplay.getLocale());\n\n\t\t\t\tendDate = cal.getTime();\n\n\t\t\t\tcal.setTimeInMillis(lastPublishDate);\n\n\t\t\t\tstartDate = cal.getTime();\n\t\t\t}\n\t\t}\n\t\telse if (range.equals(\"last\")) {\n\t\t\tint rangeLast = ParamUtil.getInteger(portletRequest, \"last\");\n\n\t\t\tDate now = new Date();\n\n\t\t\tstartDate = new Date(now.getTime() - (rangeLast * Time.HOUR));\n\n\t\t\tendDate = now;\n\t\t}\n\n\t\tif (schedule) {\n\t\t\tString groupName = getSchedulerGroupName(\n\t\t\t\tDestinationNames.LAYOUTS_LOCAL_PUBLISHER, targetGroupId);\n\n\t\t\tint recurrenceType = ParamUtil.getInteger(\n\t\t\t\tportletRequest, \"recurrenceType\");\n\n\t\t\tCalendar startCal = getDate(\n\t\t\t\tportletRequest, \"schedulerStartDate\", true);\n\n\t\t\tString cronText = getCronText(\n\t\t\t\tportletRequest, startCal, true, recurrenceType);\n\n\t\t\tDate schedulerEndDate = null;\n\n\t\t\tint endDateType = ParamUtil.getInteger(\n\t\t\t\tportletRequest, \"endDateType\");\n\n\t\t\tif (endDateType == 1) {\n\t\t\t\tCalendar endCal = getDate(\n\t\t\t\t\tportletRequest, \"schedulerEndDate\", true);\n\n\t\t\t\tschedulerEndDate = endCal.getTime();\n\t\t\t}\n\n\t\t\tString description = ParamUtil.getString(\n\t\t\t\tportletRequest, \"description\");\n\n\t\t\tLayoutServiceUtil.schedulePublishToLive(\n\t\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIdMap,\n\t\t\t\tparameterMap, scope, startDate, endDate, groupName, cronText,\n\t\t\t\tstartCal.getTime(), schedulerEndDate, description);\n\t\t}\n\t\telse {\n\t\t\tMessageStatus messageStatus = new MessageStatus();\n\n\t\t\tmessageStatus.startTimer();\n\n\t\t\tString command =\n\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_SELECTED_PAGES;\n\n\t\t\ttry {\n\t\t\t\tif (scope.equals(\"all-pages\")) {\n\t\t\t\t\tcommand = LayoutsLocalPublisherRequest.COMMAND_ALL_PAGES;\n\n\t\t\t\t\tpublishLayouts(\n\t\t\t\t\t\tsourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\t\tparameterMap, startDate, endDate);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tpublishLayouts(\n\t\t\t\t\t\tsourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\t\tlayoutIdMap, parameterMap, startDate, endDate);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tmessageStatus.setException(e);\n\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tmessageStatus.stopTimer();\n\n\t\t\t\tLayoutsLocalPublisherRequest publisherRequest =\n\t\t\t\t\tnew LayoutsLocalPublisherRequest(\n\t\t\t\t\t\tcommand, themeDisplay.getUserId(), sourceGroupId,\n\t\t\t\t\t\ttargetGroupId, privateLayout, layoutIdMap, parameterMap,\n\t\t\t\t\t\tstartDate, endDate);\n\n\t\t\t\tmessageStatus.setPayload(publisherRequest);\n\n\t\t\t\tMessageBusUtil.sendMessage(\n\t\t\t\t\tDestinationNames.MESSAGE_BUS_MESSAGE_STATUS, messageStatus);\n\t\t\t}\n\t\t}\n\t}","id":36141,"modified_method":"protected void publishLayouts(\n\t\t\tPortletRequest portletRequest, long sourceGroupId,\n\t\t\tlong targetGroupId, Map<String, String[]> parameterMap,\n\t\t\tboolean schedule)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay =\n\t\t\t(ThemeDisplay)portletRequest.getAttribute(WebKeys.THEME_DISPLAY);\n\n\t\tlong userId = themeDisplay.getUserId();\n\n\t\tString tabs1 = ParamUtil.getString(portletRequest, \"tabs1\");\n\n\t\tboolean privateLayout = true;\n\n\t\tif (tabs1.equals(\"public-pages\")) {\n\t\t\tprivateLayout = false;\n\t\t}\n\n\t\tString scope = ParamUtil.getString(portletRequest, \"scope\");\n\n\t\tMap<Long, Boolean> layoutIdMap = new LinkedHashMap<Long, Boolean>();\n\n\t\tif (scope.equals(\"selected-pages\")) {\n\t\t\tlong[] rowIds = ParamUtil.getLongValues(portletRequest, \"rowIds\");\n\n\t\t\tfor (long selPlid : rowIds) {\n\t\t\t\tboolean includeChildren = ParamUtil.getBoolean(\n\t\t\t\t\tportletRequest, \"includeChildren_\" + selPlid);\n\n\t\t\t\tlayoutIdMap.put(selPlid, includeChildren);\n\t\t\t}\n\t\t}\n\n\t\tString range = ParamUtil.getString(portletRequest, \"range\");\n\n\t\tDate startDate = null;\n\t\tDate endDate = null;\n\n\t\tif (range.equals(\"dateRange\")) {\n\t\t\tstartDate = getDate(portletRequest, \"startDate\", true).getTime();\n\n\t\t\tendDate = getDate(portletRequest, \"endDate\", true).getTime();\n\t\t}\n\t\telse if (range.equals(\"fromLastPublishDate\")) {\n\t\t\tLayoutSet layoutSet = LayoutSetLocalServiceUtil.getLayoutSet(\n\t\t\t\tsourceGroupId, privateLayout);\n\n\t\t\tUnicodeProperties settingsProperties =\n\t\t\t\tlayoutSet.getSettingsProperties();\n\n\t\t\tlong lastPublishDate = GetterUtil.getLong(\n\t\t\t\tsettingsProperties.getProperty(\"last-publish-date\"));\n\n\t\t\tif (lastPublishDate > 0) {\n\t\t\t\tCalendar cal = Calendar.getInstance(\n\t\t\t\t\tthemeDisplay.getTimeZone(), themeDisplay.getLocale());\n\n\t\t\t\tendDate = cal.getTime();\n\n\t\t\t\tcal.setTimeInMillis(lastPublishDate);\n\n\t\t\t\tstartDate = cal.getTime();\n\t\t\t}\n\t\t}\n\t\telse if (range.equals(\"last\")) {\n\t\t\tint rangeLast = ParamUtil.getInteger(portletRequest, \"last\");\n\n\t\t\tDate now = new Date();\n\n\t\t\tstartDate = new Date(now.getTime() - (rangeLast * Time.HOUR));\n\n\t\t\tendDate = now;\n\t\t}\n\n\t\tif (schedule) {\n\t\t\tString groupName = getSchedulerGroupName(\n\t\t\t\tDestinationNames.LAYOUTS_LOCAL_PUBLISHER, targetGroupId);\n\n\t\t\tint recurrenceType = ParamUtil.getInteger(\n\t\t\t\tportletRequest, \"recurrenceType\");\n\n\t\t\tCalendar startCal = getDate(\n\t\t\t\tportletRequest, \"schedulerStartDate\", true);\n\n\t\t\tString cronText = getCronText(\n\t\t\t\tportletRequest, startCal, true, recurrenceType);\n\n\t\t\tDate schedulerEndDate = null;\n\n\t\t\tint endDateType = ParamUtil.getInteger(\n\t\t\t\tportletRequest, \"endDateType\");\n\n\t\t\tif (endDateType == 1) {\n\t\t\t\tCalendar endCal = getDate(\n\t\t\t\t\tportletRequest, \"schedulerEndDate\", true);\n\n\t\t\t\tschedulerEndDate = endCal.getTime();\n\t\t\t}\n\n\t\t\tString description = ParamUtil.getString(\n\t\t\t\tportletRequest, \"description\");\n\n\t\t\tLayoutServiceUtil.schedulePublishToLive(\n\t\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIdMap,\n\t\t\t\tparameterMap, scope, startDate, endDate, groupName, cronText,\n\t\t\t\tstartCal.getTime(), schedulerEndDate, description);\n\t\t}\n\t\telse {\n\t\t\tMessageStatus messageStatus = new MessageStatus();\n\n\t\t\tmessageStatus.startTimer();\n\n\t\t\tString command =\n\t\t\t\tLayoutsLocalPublisherRequest.COMMAND_SELECTED_PAGES;\n\n\t\t\ttry {\n\t\t\t\tif (scope.equals(\"all-pages\")) {\n\t\t\t\t\tcommand = LayoutsLocalPublisherRequest.COMMAND_ALL_PAGES;\n\n\t\t\t\t\tpublishLayouts(\n\t\t\t\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\t\tparameterMap, startDate, endDate);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tpublishLayouts(\n\t\t\t\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout,\n\t\t\t\t\t\tlayoutIdMap, parameterMap, startDate, endDate);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tmessageStatus.setException(e);\n\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tmessageStatus.stopTimer();\n\n\t\t\t\tLayoutsLocalPublisherRequest publisherRequest =\n\t\t\t\t\tnew LayoutsLocalPublisherRequest(\n\t\t\t\t\t\tcommand, themeDisplay.getUserId(), sourceGroupId,\n\t\t\t\t\t\ttargetGroupId, privateLayout, layoutIdMap, parameterMap,\n\t\t\t\t\t\tstartDate, endDate);\n\n\t\t\t\tmessageStatus.setPayload(publisherRequest);\n\n\t\t\t\tMessageBusUtil.sendMessage(\n\t\t\t\t\tDestinationNames.MESSAGE_BUS_MESSAGE_STATUS, messageStatus);\n\t\t\t}\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tpublishLayouts(\n\t\t\tsourceGroupId, targetGroupId, privateLayout, (long[])null,\n\t\t\tparameterMap, startDate, endDate);\n\t}","id":36142,"modified_method":"public void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tpublishLayouts(\n\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout, (long[])null,\n\t\t\tparameterMap, startDate, endDate);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void enableRemoteStaging(\n\t\t\tPortletRequest portletRequest, long liveGroupId,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tGroup liveGroup = GroupServiceUtil.getGroup(liveGroupId);\n\n\t\tString remoteAddress = ParamUtil.getString(\n\t\t\tportletRequest, \"remoteAddress\");\n\t\tlong remoteGroupId = ParamUtil.getLong(portletRequest, \"remoteGroupId\");\n\t\tint remotePort = ParamUtil.getInteger(portletRequest, \"remotePort\");\n\t\tboolean secureConnection = ParamUtil.getBoolean(\n\t\t\tportletRequest, \"secureConnection\");\n\n\t\tvalidate(remoteAddress, remoteGroupId, remotePort, secureConnection);\n\n\t\tif (liveGroup.hasStagingGroup()) {\n\t\t\tdisableStaging(portletRequest, liveGroupId);\n\t\t}\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\"remoteAddress\", remoteAddress);\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"remoteGroupId\", String.valueOf(remoteGroupId));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"remotePort\", String.valueOf(remotePort));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"secureConnection\", String.valueOf(secureConnection));\n\t\ttypeSettingsProperties.setProperty(\"staged\", Boolean.TRUE.toString());\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"stagedRemotely\", Boolean.TRUE.toString());\n\n\t\tsetCommonStagingOptions(\n\t\t\tportletRequest, liveGroup, typeSettingsProperties);\n\n\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\tthemeDisplay.getUserId(), themeDisplay.getScopeGroupId(), false,\n\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\" branch of \").concat(liveGroup.getDescriptiveName()),\n\t\t\tserviceContext);\n\n\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\tthemeDisplay.getUserId(), themeDisplay.getScopeGroupId(), true,\n\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\" branch of \").concat(liveGroup.getDescriptiveName()),\n\t\t\tserviceContext);\n\n\t\tGroupServiceUtil.updateGroup(\n\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\t}","id":36143,"modified_method":"public void disableStaging(\n\t\t\tPortletRequest portletRequest, long scopeGroupId, long liveGroupId,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tGroup liveGroup = GroupLocalServiceUtil.getGroup(liveGroupId);\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.remove(\"branching\");\n\t\ttypeSettingsProperties.remove(\"locking\");\n\t\ttypeSettingsProperties.remove(\"remoteAddress\");\n\t\ttypeSettingsProperties.remove(\"remoteGroupId\");\n\t\ttypeSettingsProperties.remove(\"remotePort\");\n\t\ttypeSettingsProperties.remove(\"secureConnection\");\n\t\ttypeSettingsProperties.remove(\"staged\");\n\t\ttypeSettingsProperties.remove(\"stagedRemotely\");\n\t\ttypeSettingsProperties.remove(\"workflowEnabled\");\n\t\ttypeSettingsProperties.remove(\"workflowRoleNames\");\n\t\ttypeSettingsProperties.remove(\"workflowStages\");\n\n\t\tSet<String> keys = new HashSet<String>();\n\n\t\tfor (String key : typeSettingsProperties.keySet()) {\n\t\t\tif (key.startsWith(StagingConstants.STAGED_PORTLET)) {\n\t\t\t\tkeys.add(key);\n\t\t\t}\n\t\t}\n\n\t\tfor (String key : keys) {\n\t\t\ttypeSettingsProperties.remove(key);\n\t\t}\n\n\t\tif (liveGroup.hasStagingGroup()) {\n\t\t\tif ((portletRequest != null) &&\n\t\t\t\t(scopeGroupId != liveGroup.getGroupId())) {\n\n\t\t\t\tString redirect = ParamUtil.getString(\n\t\t\t\t\tportletRequest, \"pagesRedirect\");\n\n\t\t\t\tredirect = HttpUtil.removeParameter(redirect, \"refererPlid\");\n\n\t\t\t\tredirect = StringUtil.replace(\n\t\t\t\t\tredirect, String.valueOf(scopeGroupId),\n\t\t\t\t\tString.valueOf(liveGroup.getGroupId()));\n\n\t\t\t\tportletRequest.setAttribute(WebKeys.REDIRECT, redirect);\n\t\t\t}\n\n\t\t\tGroup stagingGroup = liveGroup.getStagingGroup();\n\n\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\tstagingGroup.getGroupId(), true);\n\n\t\t\tGroupLocalServiceUtil.deleteGroup(stagingGroup.getGroupId());\n\t\t}\n\t\telse {\n\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\tliveGroup.getGroupId(), true);\n\t\t}\n\n\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void enableLocalStaging(\n\t\t\tPortletRequest portletRequest, long liveGroupId,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tThemeDisplay themeDisplay = (ThemeDisplay)portletRequest.getAttribute(\n\t\t\tWebKeys.THEME_DISPLAY);\n\n\t\tGroup liveGroup = GroupServiceUtil.getGroup(liveGroupId);\n\n\t\tif (liveGroup.isStagedRemotely()) {\n\t\t\tdisableStaging(portletRequest, liveGroupId);\n\t\t}\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"staged\", Boolean.TRUE.toString());\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"stagedRemotely\", String.valueOf(false));\n\n\t\tsetCommonStagingOptions(\n\t\t\tportletRequest, liveGroup, typeSettingsProperties);\n\n\t\tif (!liveGroup.hasStagingGroup()) {\n\t\t\tserviceContext.setAttribute(\"staging\", String.valueOf(true));\n\n\t\t\tGroup stagingGroup = GroupLocalServiceUtil.addGroup(\n\t\t\t\tliveGroup.getCreatorUserId(), liveGroup.getClassName(),\n\t\t\t\tliveGroup.getClassPK(), liveGroup.getGroupId(),\n\t\t\t\tliveGroup.getDescriptiveName(), liveGroup.getDescription(),\n\t\t\t\tliveGroup.getType(), liveGroup.getFriendlyURL(),\n\t\t\t\tliveGroup.isActive(), serviceContext);\n\n\t\t\tGroupServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\t\tif (liveGroup.hasPrivateLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tliveGroup.getGroupId(), stagingGroup.getGroupId(), true,\n\t\t\t\t\tparameterMap, null, null);\n\t\t\t}\n\n\t\t\tif (liveGroup.hasPublicLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tliveGroup.getGroupId(), stagingGroup.getGroupId(), false,\n\t\t\t\t\tparameterMap, null, null);\n\t\t\t}\n\n\t\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\t\tthemeDisplay.getUserId(), themeDisplay.getScopeGroupId(), false,\n\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\t\" branch of \").concat(stagingGroup.getDescriptiveName()),\n\t\t\t\tserviceContext);\n\n\t\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\t\tthemeDisplay.getUserId(), themeDisplay.getScopeGroupId(), true,\n\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\t\" branch of \").concat(stagingGroup.getDescriptiveName()),\n\t\t\t\tserviceContext);\n\t\t}\n\t\telse {\n\t\t\tGroupServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\t\t}\n\t}","id":36144,"modified_method":"public void enableLocalStaging(\n\t\t\tlong userId, long scopeGroupId, long liveGroupId,\n\t\t\tboolean branchingPublic, boolean branchingPrivate,\n\t\t\tboolean lockingPublic, boolean lockingPrivate,\n\t\t\tServiceContext serviceContext)\n\t\tthrows Exception {\n\n\t\tGroup liveGroup = GroupLocalServiceUtil.getGroup(liveGroupId);\n\n\t\tif (liveGroup.isStagedRemotely()) {\n\t\t\tdisableStaging(scopeGroupId, liveGroupId, serviceContext);\n\t\t}\n\n\t\tUnicodeProperties typeSettingsProperties =\n\t\t\tliveGroup.getTypeSettingsProperties();\n\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branching-public\", String.valueOf(branchingPublic));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"branching-private\", String.valueOf(branchingPrivate));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"locking-public\", String.valueOf(lockingPublic));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"locking-private\", String.valueOf(lockingPrivate));\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"staged\", Boolean.TRUE.toString());\n\t\ttypeSettingsProperties.setProperty(\n\t\t\t\"stagedRemotely\", String.valueOf(false));\n\n\t\tsetCommonStagingOptions(\n\t\t\tliveGroup, typeSettingsProperties, serviceContext);\n\n\t\tif (!liveGroup.hasStagingGroup()) {\n\t\t\tserviceContext.setAttribute(\"staging\", String.valueOf(true));\n\n\t\t\tGroup stagingGroup = GroupLocalServiceUtil.addGroup(\n\t\t\t\tuserId, liveGroup.getClassName(), liveGroup.getClassPK(),\n\t\t\t\tliveGroup.getGroupId(), liveGroup.getDescriptiveName(),\n\t\t\t\tliveGroup.getDescription(), liveGroup.getType(),\n\t\t\t\tliveGroup.getFriendlyURL(), liveGroup.isActive(),\n\t\t\t\tserviceContext);\n\n\t\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\t\tif (liveGroup.hasPrivateLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\ttrue, parameterMap, null, null);\n\t\t\t}\n\n\t\t\tif (liveGroup.hasPublicLayouts()) {\n\t\t\t\tMap<String, String[]> parameterMap = getStagingParameters();\n\n\t\t\t\tpublishLayouts(\n\t\t\t\t\tuserId, liveGroup.getGroupId(), stagingGroup.getGroupId(),\n\t\t\t\t\tfalse, parameterMap, null, null);\n\t\t\t}\n\n\t\t\tif (branchingPublic) {\n\t\t\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\t\t\tuserId, stagingGroup.getGroupId(), false,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\t\t\" branch of \").concat(\n\t\t\t\t\t\t\tstagingGroup.getDescriptiveName()), serviceContext);\n\t\t\t}\n\n\t\t\tif (branchingPrivate) {\n\t\t\t\tLayoutSetBranchLocalServiceUtil.addLayoutSetBranch(\n\t\t\t\t\tuserId, stagingGroup.getGroupId(), true,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME,\n\t\t\t\t\tLayoutSetBranchConstants.MASTER_BRANCH_NAME.concat(\n\t\t\t\t\t\t\" branch of \").concat(\n\t\t\t\t\t\t\tstagingGroup.getDescriptiveName()), serviceContext);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tGroupLocalServiceUtil.updateGroup(\n\t\t\t\tliveGroup.getGroupId(), typeSettingsProperties.toString());\n\n\t\t\tif (!branchingPublic) {\n\t\t\t\tLayoutSetBranchLocalServiceUtil.deleteLayoutSetBranches(\n\t\t\t\t\tliveGroup.getStagingGroup().getGroupId(), true);\n\t\t\t}\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tlong[] layoutIds, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tFile file = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\tsourceGroupId, privateLayout, layoutIds, parameterMap, startDate,\n\t\t\tendDate);\n\n\t\ttry {\n\t\t\tLayoutServiceUtil.importLayouts(\n\t\t\t\ttargetGroupId, privateLayout, parameterMap, file);\n\t\t}\n\t\tfinally {\n\t\t\tfile.delete();\n\t\t}\n\t}","id":36145,"modified_method":"public void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, long[] layoutIds,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tFile file = LayoutLocalServiceUtil.exportLayoutsAsFile(\n\t\t\tsourceGroupId, privateLayout, layoutIds, parameterMap, startDate,\n\t\t\tendDate);\n\n\t\ttry {\n\t\t\tLayoutLocalServiceUtil.importLayouts(\n\t\t\t\tuserId, targetGroupId, privateLayout, parameterMap, file);\n\t\t}\n\t\tfinally {\n\t\t\tfile.delete();\n\t\t}\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tMap<Long, Boolean> layoutIdMap, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tparameterMap.put(\n\t\t\tPortletDataHandlerKeys.DELETE_MISSING_LAYOUTS,\n\t\t\tnew String[] {Boolean.FALSE.toString()});\n\n\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\tIterator<Map.Entry<Long, Boolean>> itr1 =\n\t\t\tlayoutIdMap.entrySet().iterator();\n\n\t\twhile (itr1.hasNext()) {\n\t\t\tEntry<Long, Boolean> entry = itr1.next();\n\n\t\t\tlong plid = GetterUtil.getLong(String.valueOf(entry.getKey()));\n\t\t\tboolean includeChildren = entry.getValue();\n\n\t\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\t\tif (!layouts.contains(layout)) {\n\t\t\t\tlayouts.add(layout);\n\t\t\t}\n\n\t\t\tIterator<Layout> itr2 = getMissingParentLayouts(\n\t\t\t\tlayout, targetGroupId).iterator();\n\n\t\t\twhile (itr2.hasNext()) {\n\t\t\t\tLayout parentLayout = itr2.next();\n\n\t\t\t\tif (!layouts.contains(parentLayout)) {\n\t\t\t\t\tlayouts.add(parentLayout);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (includeChildren) {\n\t\t\t\titr2 = layout.getAllChildren().iterator();\n\n\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\tLayout childLayout = itr2.next();\n\n\t\t\t\t\tif (!layouts.contains(childLayout)) {\n\t\t\t\t\t\tlayouts.add(childLayout);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\tfor (int i = 0; i < layouts.size(); i++) {\n\t\t\tLayout curLayout = layouts.get(i);\n\n\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t}\n\n\t\tpublishLayouts(\n\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIds,\n\t\t\tparameterMap, startDate, endDate);\n\t}","id":36146,"modified_method":"public void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, Map<Long, Boolean> layoutIdMap,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tparameterMap.put(\n\t\t\tPortletDataHandlerKeys.DELETE_MISSING_LAYOUTS,\n\t\t\tnew String[] {Boolean.FALSE.toString()});\n\n\t\tList<Layout> layouts = new ArrayList<Layout>();\n\n\t\tIterator<Map.Entry<Long, Boolean>> itr1 =\n\t\t\tlayoutIdMap.entrySet().iterator();\n\n\t\twhile (itr1.hasNext()) {\n\t\t\tEntry<Long, Boolean> entry = itr1.next();\n\n\t\t\tlong plid = GetterUtil.getLong(String.valueOf(entry.getKey()));\n\t\t\tboolean includeChildren = entry.getValue();\n\n\t\t\tLayout layout = LayoutLocalServiceUtil.getLayout(plid);\n\n\t\t\tif (!layouts.contains(layout)) {\n\t\t\t\tlayouts.add(layout);\n\t\t\t}\n\n\t\t\tIterator<Layout> itr2 = getMissingParentLayouts(\n\t\t\t\tlayout, targetGroupId).iterator();\n\n\t\t\twhile (itr2.hasNext()) {\n\t\t\t\tLayout parentLayout = itr2.next();\n\n\t\t\t\tif (!layouts.contains(parentLayout)) {\n\t\t\t\t\tlayouts.add(parentLayout);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (includeChildren) {\n\t\t\t\titr2 = layout.getAllChildren().iterator();\n\n\t\t\t\twhile (itr2.hasNext()) {\n\t\t\t\t\tLayout childLayout = itr2.next();\n\n\t\t\t\t\tif (!layouts.contains(childLayout)) {\n\t\t\t\t\t\tlayouts.add(childLayout);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tlong[] layoutIds = new long[layouts.size()];\n\n\t\tfor (int i = 0; i < layouts.size(); i++) {\n\t\t\tLayout curLayout = layouts.get(i);\n\n\t\t\tlayoutIds[i] = curLayout.getLayoutId();\n\t\t}\n\n\t\tpublishLayouts(\n\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout, layoutIds,\n\t\t\tparameterMap, startDate, endDate);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tlong[] layoutIds, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIds,\n\t\t\tparameterMap, startDate, endDate);\n\t}","id":36147,"modified_method":"public static void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, long[] layoutIds,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout, layoutIds,\n\t\t\tparameterMap, startDate, endDate);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tMap<Long, Boolean> layoutIdMap, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tsourceGroupId, targetGroupId, privateLayout, layoutIdMap,\n\t\t\tparameterMap, startDate, endDate);\n\t}","id":36148,"modified_method":"public static void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, Map<Long, Boolean> layoutIdMap,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout, layoutIdMap,\n\t\t\tparameterMap, startDate, endDate);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void publishLayouts(\n\t\t\tlong sourceGroupId, long targetGroupId, boolean privateLayout,\n\t\t\tMap<String, String[]> parameterMap, Date startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tsourceGroupId, targetGroupId, privateLayout, parameterMap,\n\t\t\tstartDate, endDate);\n\t}","id":36149,"modified_method":"public static void publishLayouts(\n\t\t\tlong userId, long sourceGroupId, long targetGroupId,\n\t\t\tboolean privateLayout, Map<String, String[]> parameterMap,\n\t\t\tDate startDate, Date endDate)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayouts(\n\t\t\tuserId, sourceGroupId, targetGroupId, privateLayout, parameterMap,\n\t\t\tstartDate, endDate);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void publishLayout(\n\t\t\tlong plid, long liveGroupId, boolean includeChildren)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayout(plid, liveGroupId, includeChildren);\n\t}","id":36150,"modified_method":"public static void publishLayout(\n\t\t\tlong userId, long plid, long liveGroupId, boolean includeChildren)\n\t\tthrows Exception {\n\n\t\tgetStaging().publishLayout(userId, plid, liveGroupId, includeChildren);\n\t}","commit_id":"12a60f26deb515e3d1b3e651b1e1d0554e53fbd3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public Default_KeymapChanges() {\n    // simple \n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneModel_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneRoot_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNodeReference_Action\", getShortcut(\"ctrl shift C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNode_Action\", getShortcut(\"ctrl C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CreateAspect_Action\", getShortcut(\"ctrl alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CutNode_Action\", getShortcut(\"ctrl X\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModels_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModules_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteNode_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeletePropertyAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteReferenceAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FastFindNodeUsages_Action\", getShortcut(\"ctrl F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindModelUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindNext_Action\", getShortcut(\" F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindPrevious_Action\", getShortcut(\"shift F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindSpecificNodeUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.Find_Action\", getShortcut(\"ctrl F\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoByCurrentReferenceToIDEA_Action\", getShortcut(\"ctrl shift B\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightInstances_Action\", getShortcut(\"ctrl shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightUsages_Action\", getShortcut(\"ctrl shift F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MPSProjectPaths_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModelProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModuleProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MoveFileOrDirectory_Action\", getShortcut(\" F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.PasteNode_Action\", getShortcut(\"ctrl V\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.QuickCreate_Action\", getShortcut(\"alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RemoveFromFavorites_Action\", getShortcut(\"ctrl DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameFileOrDirectory_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameModel_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenamePackage_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameSolution_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SafeDelete_Action\", getShortcut(\"alt DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SetBookmarkNoNumber_Action\", getShortcut(\" F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowBookmarksDialog_Action\", getShortcut(\"shift F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowClassInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowConceptInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowImplementations_Action\", getShortcut(\"ctrl shift I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowInLogicalView_Action\", getShortcut(\"alt F2\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInInspector_Action\", getShortcut(\"ctrl I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInfo_Action\", getShortcut(\"ctrl Q\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowParameters_Action\", getShortcut(\"ctrl P\"));\n    // simple parameterized \n    addComplexShortcut(\"jetbrains.mps.ide.actions.FileDelete_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\" DELETE\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToAction_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift A\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToFile_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift N\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModel_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift M\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModule_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift S\"), getShortcut(\"ctrl alt shift L\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToNamedNode_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift N\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToRootNode_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl N\")));\n    // complex \n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToBookmark_Action\", new Default_KeymapChanges.GoToBookmark_ShortcutChange_qjewi8_ub());\n    addComplexShortcut(\"jetbrains.mps.ide.actions.SetBookmark_Action\", new Default_KeymapChanges.SetBookmark_ShortcutChange_qjewi8_vb());\n  }","id":36151,"modified_method":"public Default_KeymapChanges() {\n    // simple \n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneModel_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneRoot_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNodeReference_Action\", getShortcut(\"ctrl shift C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNode_Action\", getShortcut(\"ctrl C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CreateAspect_Action\", getShortcut(\"ctrl alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CutNode_Action\", getShortcut(\"ctrl X\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModels_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModules_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteNode_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeletePropertyAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteReferenceAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FastFindNodeUsages_Action\", getShortcut(\"ctrl F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindModelUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindNext_Action\", getShortcut(\" F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindPrevious_Action\", getShortcut(\"shift F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindSpecificNodeUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.Find_Action\", getShortcut(\"ctrl F\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoByCurrentReferenceToIDEA_Action\", getShortcut(\"ctrl shift B\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoToRootNode_Action\", getShortcut(\"ctrl N\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightInstances_Action\", getShortcut(\"ctrl shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightUsages_Action\", getShortcut(\"ctrl shift F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MPSProjectPaths_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModelProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModuleProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MoveFileOrDirectory_Action\", getShortcut(\" F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.PasteNode_Action\", getShortcut(\"ctrl V\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.QuickCreate_Action\", getShortcut(\"alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RemoveFromFavorites_Action\", getShortcut(\"ctrl DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameFileOrDirectory_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameModel_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenamePackage_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameSolution_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SafeDelete_Action\", getShortcut(\"alt DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SetBookmarkNoNumber_Action\", getShortcut(\" F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowBookmarksDialog_Action\", getShortcut(\"shift F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowClassInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowConceptInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowImplementations_Action\", getShortcut(\"ctrl shift I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowInLogicalView_Action\", getShortcut(\"alt F2\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInInspector_Action\", getShortcut(\"ctrl I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInfo_Action\", getShortcut(\"ctrl Q\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowParameters_Action\", getShortcut(\"ctrl P\"));\n    // simple parameterized \n    addComplexShortcut(\"jetbrains.mps.ide.actions.FileDelete_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\" DELETE\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToAction_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift A\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToFile_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift N\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModel_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift M\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModule_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift S\"), getShortcut(\"ctrl alt shift L\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToNamedNode_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift N\")));\n    // complex \n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToBookmark_Action\", new Default_KeymapChanges.GoToBookmark_ShortcutChange_qjewi8_ub());\n    addComplexShortcut(\"jetbrains.mps.ide.actions.SetBookmark_Action\", new Default_KeymapChanges.SetBookmark_ShortcutChange_qjewi8_vb());\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public GoToRootNode_Action(AnAction action_par) {\n    super(\"Go to Root Node\", \"\", ICON);\n    this.action = action_par;\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(true);\n  }","id":36152,"modified_method":"public GoToRootNode_Action() {\n    super(\"Go to Root Node\", \"\", ICON);\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(true);\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      FeatureUsageTracker.getInstance().triggerFeatureUsed(\"navigation.goto.rootNode\");\n      GoToRootNode_Action.this.action.actionPerformed(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToRootNode\", t);\n      }\n    }\n  }","id":36153,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      FeatureUsageTracker.getInstance().triggerFeatureUsed(\"navigation.goto.rootNode\");\n\n      Project project = event.getData(PlatformDataKeys.PROJECT);\n      assert project != null;\n\n      MPSChooseSNodeDescriptor chooseSNodeResult = new MPSChooseSNodeDescriptor(project, new RootNodeNameIndex());\n      ChooseByNamePopup popup = MpsPopupFactory.createNodePopup(project, chooseSNodeResult);\n\n      popup.invoke(new ChooseByNamePopupComponent.Callback() {\n        public void onClose() {\n        }\n\n        public void elementChosen(Object element) {\n          ((NavigationItem) element).navigate(true);\n        }\n      }, ModalityState.current(), true);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToRootNode\", t);\n      }\n    }\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      GoToRootNode_Action.this.action.update(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToRootNode\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","id":36154,"modified_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToRootNode\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public Goto_ActionGroup() {\n    super(\"Go To\", ID);\n    this.setIsInternal(false);\n    this.setPopup(false);\n    try {\n      Goto_ActionGroup.this.addParameterizedAction(new GoToAction_Action(new GotoActionAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoActionAction());\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoVCS);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToFile_Action(new GotoFileAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoFileAction());\n      Goto_ActionGroup.this.addParameterizedAction(new GoToRootNode_Action(new GoToRootNodeAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToRootNodeAction());\n      Goto_ActionGroup.this.addSeparator();\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoConceptAspects);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModel_Action(new GoToModelAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModelAction());\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModule_Action(new GoToModuleAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModuleAction());\n    } catch (Throwable t) {\n      LOG.error(\"User group error\", t);\n    }\n  }","id":36155,"modified_method":"public Goto_ActionGroup() {\n    super(\"Go To\", ID);\n    this.setIsInternal(false);\n    this.setPopup(false);\n    try {\n      Goto_ActionGroup.this.addParameterizedAction(new GoToAction_Action(new GotoActionAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoActionAction());\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoVCS);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToFile_Action(new GotoFileAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoFileAction());\n      Goto_ActionGroup.this.addAction(\"jetbrains.mps.ide.actions.GoToRootNode_Action\");\n      Goto_ActionGroup.this.addSeparator();\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoConceptAspects);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModel_Action(new GoToModelAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModelAction());\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModule_Action(new GoToModuleAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModuleAction());\n    } catch (Throwable t) {\n      LOG.error(\"User group error\", t);\n    }\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void createGroups() {\n    // actions w/o parameters \n    addAction(new AddMissingImportsInProject_Action());\n    addAction(new AddMissingImports_Action());\n    addAction(new AddModuleToProject_Action());\n    addAction(new AddToNewFavoritesList_Action());\n    addAction(new AnalyzeClasspath_Action());\n    addAction(new AnalyzeDependencies_Action());\n    addAction(new AnalyzeModuleDependencies_Action());\n    addAction(new AnalyzeStacktrace_Action());\n    addAction(new CloneModel_Action());\n    addAction(new CloneRoot_Action());\n    addAction(new CopyModelName_Action());\n    addAction(new CopyModuleName_Action());\n    addAction(new CopyNodeName_Action());\n    addAction(new CopyNodeReference_Action());\n    addAction(new CopyNode_Action());\n    addAction(new CreateAspect_Action());\n    addAction(new CutNode_Action());\n    addAction(new DeleteFavoritesList_Action());\n    addAction(new DeleteModels_Action());\n    addAction(new DeleteModules_Action());\n    addAction(new DeleteNode_Action());\n    addAction(new DeletePropertyAction_Action());\n    addAction(new DeleteReferenceAction_Action());\n    addAction(new EditNode_Action());\n    addAction(new ExpandNode_Action());\n    addAction(new FastFindNodeUsages_Action());\n    addAction(new FindModelUsages_Action());\n    addAction(new FindNext_Action());\n    addAction(new FindPrevious_Action());\n    addAction(new FindRootableConceptsWithoutIcons_Action());\n    addAction(new FindSpecificNodeUsages_Action());\n    addAction(new Find_Action());\n    addAction(new GoByCurrentReferenceToIDEA_Action());\n    addAction(new GoToNode_Action());\n    addAction(new GoToRule_Action());\n    addAction(new HighlightInstances_Action());\n    addAction(new HighlightUsages_Action());\n    addAction(new MPSProjectPaths_Action());\n    addAction(new ModelProperties_Action());\n    addAction(new ModuleProperties_Action());\n    addAction(new MoveFileOrDirectory_Action());\n    addAction(new NewDirectory_Action());\n    addAction(new NewFile_Action());\n    addAction(new NewModel_Action());\n    addAction(new NewRuntimeModule_Action());\n    addAction(new NewSolution_Action());\n    addAction(new NewSubModel_Action());\n    addAction(new NewSubTestModel_Action());\n    addAction(new OptimizeModelImports_Action());\n    addAction(new OptimizeModuleImports_Action());\n    addAction(new OptimizeProjectImports_Action());\n    addAction(new PasteNode_Action());\n    addAction(new PrintNodePosition_Action());\n    addAction(new QuickCreate_Action());\n    addAction(new RemoveAllBookmarks_Action());\n    addAction(new RemoveFromFavorites_Action());\n    addAction(new RemoveModuleFromProject_Action());\n    addAction(new RemoveTransientModels_Action());\n    addAction(new RenameFavoritesList_Action());\n    addAction(new RenameFileOrDirectory_Action());\n    addAction(new RenameModel_Action());\n    addAction(new RenameNamespace_Action());\n    addAction(new RenamePackage_Action());\n    addAction(new RenameSolution_Action());\n    addAction(new RevertMemoryChanges_Action());\n    addAction(new SafeDeleteModuleDependency_Action());\n    addAction(new SafeDelete_Action());\n    addAction(new SetBookmarkNoNumber_Action());\n    addAction(new SetModuleFolder_Action());\n    addAction(new SetNodePackage_Action());\n    addAction(new ShowBookmarksDialog_Action());\n    addAction(new ShowBookmarks_Action());\n    addAction(new ShowClassInHierarchy_Action());\n    addAction(new ShowConceptInHierarchy_Action());\n    addAction(new ShowErrorMessage_Action());\n    addAction(new ShowImplementations_Action());\n    addAction(new ShowInDependenciesViewer_Action());\n    addAction(new ShowInLogicalView_Action());\n    addAction(new ShowModuleDependencyLoop_Action());\n    addAction(new ShowNodeInInspector_Action());\n    addAction(new ShowNodeInfo_Action());\n    addAction(new ShowParameters_Action());\n    addAction(new ShowTodoViewer_Action());\n    addAction(new SubmitToTracker_Action());\n    // groups \n    addGroup(new AbstractFileActions_ActionGroup());\n    addGroup(new AddToFavoritesGroup_ActionGroup());\n    addGroup(new AnalyzeModule_ActionGroup());\n    addGroup(new Analyze_ActionGroup());\n    addGroup(new Bookmarks_ActionGroup());\n    addGroup(new Build_ActionGroup());\n    addGroup(new CommonModuleActions_ActionGroup());\n    addGroup(new CreateRootNode_ActionGroup());\n    addGroup(new DebugActions_ActionGroup());\n    addGroup(new DevkitActions_ActionGroup());\n    addGroup(new Edit_ActionGroup());\n    addGroup(new EditorInternal_ActionGroup());\n    addGroup(new EditorPopupEx_ActionGroup());\n    addGroup(new EditorPopupEx_Goto_ActionGroup());\n    addGroup(new EditorPopup_Show_ActionGroup());\n    addGroup(new EditorTabActions_ActionGroup());\n    addGroup(new FavoritesPopupWrapper_ActionGroup());\n    addGroup(new FavoritesPopup_ActionGroup());\n    addGroup(new Favorites_ActionGroup());\n    addGroup(new FileActions_ActionGroup());\n    addGroup(new FileSystemNewActions_ActionGroup());\n    addGroup(new FindModelUsages_ActionGroup());\n    addGroup(new FindUsages_ActionGroup());\n    addGroup(new FolderActions_ActionGroup());\n    addGroup(new GeneratorActions_ActionGroup());\n    addGroup(new GeneratorNewActions_ActionGroup());\n    addGroup(new GoByReference_ActionGroup());\n    addGroup(new Goto_ActionGroup());\n    addGroup(new JUnitTestCaseActions_ActionGroup());\n    addGroup(new JUnitTestMethodActions_ActionGroup());\n    addGroup(new LanguageActions_ActionGroup());\n    addGroup(new LanguageNewActions_ActionGroup());\n    addGroup(new LibraryActions_ActionGroup());\n    addGroup(new MessagesViewActions_ActionGroup());\n    addGroup(new ModelActionsInternal_ActionGroup());\n    addGroup(new ModelActions_ActionGroup());\n    addGroup(new ModelNewActions_ActionGroup());\n    addGroup(new ModelRefactoring_ActionGroup());\n    addGroup(new ModuleActions_ActionGroup());\n    addGroup(new NamespaceActions_ActionGroup());\n    addGroup(new NamespaceInternalActions_ActionGroup());\n    addGroup(new NamespaceMakeActions_ActionGroup());\n    addGroup(new NamespaceNewActions_ActionGroup());\n    addGroup(new NodeActionsInternal_ActionGroup());\n    addGroup(new NodeActions_ActionGroup());\n    addGroup(new PackageActions_ActionGroup());\n    addGroup(new PackageNewActions_ActionGroup());\n    addGroup(new PrintNodePosition_Addition_ActionGroup());\n    addGroup(new ProjectActions_ActionGroup());\n    addGroup(new ProjectNewActions_ActionGroup());\n    addGroup(new PropertyNodeActions_ActionGroup());\n    addGroup(new ReferenceNodeActions_ActionGroup());\n    addGroup(new RuntimeFolderActions_ActionGroup());\n    addGroup(new Search_ActionGroup());\n    addGroup(new SolutionActions_ActionGroup());\n    addGroup(new SolutionNewActions_ActionGroup());\n    addGroup(new SolutionRefactoring_ActionGroup());\n    addGroup(new ToolsInternal_ActionGroup());\n    addGroup(new Tools_ActionGroup());\n    addGroup(new TransientModulesActions_ActionGroup());\n    addGroup(new View_ActionGroup());\n  }","id":36156,"modified_method":"public void createGroups() {\n    // actions w/o parameters \n    addAction(new AddMissingImportsInProject_Action());\n    addAction(new AddMissingImports_Action());\n    addAction(new AddModuleToProject_Action());\n    addAction(new AddToNewFavoritesList_Action());\n    addAction(new AnalyzeClasspath_Action());\n    addAction(new AnalyzeDependencies_Action());\n    addAction(new AnalyzeModuleDependencies_Action());\n    addAction(new AnalyzeStacktrace_Action());\n    addAction(new CloneModel_Action());\n    addAction(new CloneRoot_Action());\n    addAction(new CopyModelName_Action());\n    addAction(new CopyModuleName_Action());\n    addAction(new CopyNodeName_Action());\n    addAction(new CopyNodeReference_Action());\n    addAction(new CopyNode_Action());\n    addAction(new CreateAspect_Action());\n    addAction(new CutNode_Action());\n    addAction(new DeleteFavoritesList_Action());\n    addAction(new DeleteModels_Action());\n    addAction(new DeleteModules_Action());\n    addAction(new DeleteNode_Action());\n    addAction(new DeletePropertyAction_Action());\n    addAction(new DeleteReferenceAction_Action());\n    addAction(new EditNode_Action());\n    addAction(new ExpandNode_Action());\n    addAction(new FastFindNodeUsages_Action());\n    addAction(new FindModelUsages_Action());\n    addAction(new FindNext_Action());\n    addAction(new FindPrevious_Action());\n    addAction(new FindRootableConceptsWithoutIcons_Action());\n    addAction(new FindSpecificNodeUsages_Action());\n    addAction(new Find_Action());\n    addAction(new GoByCurrentReferenceToIDEA_Action());\n    addAction(new GoToNode_Action());\n    addAction(new GoToRootNode_Action());\n    addAction(new GoToRule_Action());\n    addAction(new HighlightInstances_Action());\n    addAction(new HighlightUsages_Action());\n    addAction(new MPSProjectPaths_Action());\n    addAction(new ModelProperties_Action());\n    addAction(new ModuleProperties_Action());\n    addAction(new MoveFileOrDirectory_Action());\n    addAction(new NewDirectory_Action());\n    addAction(new NewFile_Action());\n    addAction(new NewModel_Action());\n    addAction(new NewRuntimeModule_Action());\n    addAction(new NewSolution_Action());\n    addAction(new NewSubModel_Action());\n    addAction(new NewSubTestModel_Action());\n    addAction(new OptimizeModelImports_Action());\n    addAction(new OptimizeModuleImports_Action());\n    addAction(new OptimizeProjectImports_Action());\n    addAction(new PasteNode_Action());\n    addAction(new PrintNodePosition_Action());\n    addAction(new QuickCreate_Action());\n    addAction(new RemoveAllBookmarks_Action());\n    addAction(new RemoveFromFavorites_Action());\n    addAction(new RemoveModuleFromProject_Action());\n    addAction(new RemoveTransientModels_Action());\n    addAction(new RenameFavoritesList_Action());\n    addAction(new RenameFileOrDirectory_Action());\n    addAction(new RenameModel_Action());\n    addAction(new RenameNamespace_Action());\n    addAction(new RenamePackage_Action());\n    addAction(new RenameSolution_Action());\n    addAction(new RevertMemoryChanges_Action());\n    addAction(new SafeDeleteModuleDependency_Action());\n    addAction(new SafeDelete_Action());\n    addAction(new SetBookmarkNoNumber_Action());\n    addAction(new SetModuleFolder_Action());\n    addAction(new SetNodePackage_Action());\n    addAction(new ShowBookmarksDialog_Action());\n    addAction(new ShowBookmarks_Action());\n    addAction(new ShowClassInHierarchy_Action());\n    addAction(new ShowConceptInHierarchy_Action());\n    addAction(new ShowErrorMessage_Action());\n    addAction(new ShowImplementations_Action());\n    addAction(new ShowInDependenciesViewer_Action());\n    addAction(new ShowInLogicalView_Action());\n    addAction(new ShowModuleDependencyLoop_Action());\n    addAction(new ShowNodeInInspector_Action());\n    addAction(new ShowNodeInfo_Action());\n    addAction(new ShowParameters_Action());\n    addAction(new ShowTodoViewer_Action());\n    addAction(new SubmitToTracker_Action());\n    // groups \n    addGroup(new AbstractFileActions_ActionGroup());\n    addGroup(new AddToFavoritesGroup_ActionGroup());\n    addGroup(new AnalyzeModule_ActionGroup());\n    addGroup(new Analyze_ActionGroup());\n    addGroup(new Bookmarks_ActionGroup());\n    addGroup(new Build_ActionGroup());\n    addGroup(new CommonModuleActions_ActionGroup());\n    addGroup(new CreateRootNode_ActionGroup());\n    addGroup(new DebugActions_ActionGroup());\n    addGroup(new DevkitActions_ActionGroup());\n    addGroup(new Edit_ActionGroup());\n    addGroup(new EditorInternal_ActionGroup());\n    addGroup(new EditorPopupEx_ActionGroup());\n    addGroup(new EditorPopupEx_Goto_ActionGroup());\n    addGroup(new EditorPopup_Show_ActionGroup());\n    addGroup(new EditorTabActions_ActionGroup());\n    addGroup(new FavoritesPopupWrapper_ActionGroup());\n    addGroup(new FavoritesPopup_ActionGroup());\n    addGroup(new Favorites_ActionGroup());\n    addGroup(new FileActions_ActionGroup());\n    addGroup(new FileSystemNewActions_ActionGroup());\n    addGroup(new FindModelUsages_ActionGroup());\n    addGroup(new FindUsages_ActionGroup());\n    addGroup(new FolderActions_ActionGroup());\n    addGroup(new GeneratorActions_ActionGroup());\n    addGroup(new GeneratorNewActions_ActionGroup());\n    addGroup(new GoByReference_ActionGroup());\n    addGroup(new Goto_ActionGroup());\n    addGroup(new JUnitTestCaseActions_ActionGroup());\n    addGroup(new JUnitTestMethodActions_ActionGroup());\n    addGroup(new LanguageActions_ActionGroup());\n    addGroup(new LanguageNewActions_ActionGroup());\n    addGroup(new LibraryActions_ActionGroup());\n    addGroup(new MessagesViewActions_ActionGroup());\n    addGroup(new ModelActionsInternal_ActionGroup());\n    addGroup(new ModelActions_ActionGroup());\n    addGroup(new ModelNewActions_ActionGroup());\n    addGroup(new ModelRefactoring_ActionGroup());\n    addGroup(new ModuleActions_ActionGroup());\n    addGroup(new NamespaceActions_ActionGroup());\n    addGroup(new NamespaceInternalActions_ActionGroup());\n    addGroup(new NamespaceMakeActions_ActionGroup());\n    addGroup(new NamespaceNewActions_ActionGroup());\n    addGroup(new NodeActionsInternal_ActionGroup());\n    addGroup(new NodeActions_ActionGroup());\n    addGroup(new PackageActions_ActionGroup());\n    addGroup(new PackageNewActions_ActionGroup());\n    addGroup(new PrintNodePosition_Addition_ActionGroup());\n    addGroup(new ProjectActions_ActionGroup());\n    addGroup(new ProjectNewActions_ActionGroup());\n    addGroup(new PropertyNodeActions_ActionGroup());\n    addGroup(new ReferenceNodeActions_ActionGroup());\n    addGroup(new RuntimeFolderActions_ActionGroup());\n    addGroup(new Search_ActionGroup());\n    addGroup(new SolutionActions_ActionGroup());\n    addGroup(new SolutionNewActions_ActionGroup());\n    addGroup(new SolutionRefactoring_ActionGroup());\n    addGroup(new ToolsInternal_ActionGroup());\n    addGroup(new Tools_ActionGroup());\n    addGroup(new TransientModulesActions_ActionGroup());\n    addGroup(new View_ActionGroup());\n  }","commit_id":"a99d91fb3384efe325d18c7cba1377c685791167","url":"https://github.com/JetBrains/MPS"},{"original_method":"public Default_KeymapChanges() {\n    // simple \n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneModel_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneRoot_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNodeReference_Action\", getShortcut(\"ctrl shift C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNode_Action\", getShortcut(\"ctrl C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CreateAspect_Action\", getShortcut(\"ctrl alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CutNode_Action\", getShortcut(\"ctrl X\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModels_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModules_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteNode_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeletePropertyAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteReferenceAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FastFindNodeUsages_Action\", getShortcut(\"ctrl F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindModelUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindNext_Action\", getShortcut(\" F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindPrevious_Action\", getShortcut(\"shift F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindSpecificNodeUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.Find_Action\", getShortcut(\"ctrl F\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoByCurrentReferenceToIDEA_Action\", getShortcut(\"ctrl shift B\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoToRootNode_Action\", getShortcut(\"ctrl N\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightInstances_Action\", getShortcut(\"ctrl shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightUsages_Action\", getShortcut(\"ctrl shift F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MPSProjectPaths_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModelProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModuleProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MoveFileOrDirectory_Action\", getShortcut(\" F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.PasteNode_Action\", getShortcut(\"ctrl V\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.QuickCreate_Action\", getShortcut(\"alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RemoveFromFavorites_Action\", getShortcut(\"ctrl DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameFileOrDirectory_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameModel_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenamePackage_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameSolution_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SafeDelete_Action\", getShortcut(\"alt DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SetBookmarkNoNumber_Action\", getShortcut(\" F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowBookmarksDialog_Action\", getShortcut(\"shift F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowClassInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowConceptInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowImplementations_Action\", getShortcut(\"ctrl shift I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowInLogicalView_Action\", getShortcut(\"alt F2\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInInspector_Action\", getShortcut(\"ctrl I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInfo_Action\", getShortcut(\"ctrl Q\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowParameters_Action\", getShortcut(\"ctrl P\"));\n    // simple parameterized \n    addComplexShortcut(\"jetbrains.mps.ide.actions.FileDelete_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\" DELETE\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToAction_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift A\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToFile_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift N\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModel_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift M\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToModule_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift S\"), getShortcut(\"ctrl alt shift L\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToNamedNode_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift N\")));\n    // complex \n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToBookmark_Action\", new Default_KeymapChanges.GoToBookmark_ShortcutChange_qjewi8_ub());\n    addComplexShortcut(\"jetbrains.mps.ide.actions.SetBookmark_Action\", new Default_KeymapChanges.SetBookmark_ShortcutChange_qjewi8_vb());\n  }","id":36157,"modified_method":"public Default_KeymapChanges() {\n    // simple \n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneModel_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CloneRoot_Action\", getShortcut(\"shift F5\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNodeReference_Action\", getShortcut(\"ctrl shift C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CopyNode_Action\", getShortcut(\"ctrl C\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CreateAspect_Action\", getShortcut(\"ctrl alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.CutNode_Action\", getShortcut(\"ctrl X\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModels_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteModules_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteNode_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeletePropertyAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.DeleteReferenceAction_Action\", getShortcut(\" DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FastFindNodeUsages_Action\", getShortcut(\"ctrl F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindModelUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindNext_Action\", getShortcut(\" F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindPrevious_Action\", getShortcut(\"shift F3\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.FindSpecificNodeUsages_Action\", getShortcut(\"alt F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.Find_Action\", getShortcut(\"ctrl F\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoByCurrentReferenceToIDEA_Action\", getShortcut(\"ctrl shift B\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoToModel_Action\", getShortcut(\"ctrl alt shift M\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoToModule_Action\", getShortcut(\"ctrl alt shift S\"), getShortcut(\"ctrl alt shift L\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.GoToRootNode_Action\", getShortcut(\"ctrl N\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightInstances_Action\", getShortcut(\"ctrl shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.HighlightUsages_Action\", getShortcut(\"ctrl shift F7\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MPSProjectPaths_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModelProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ModuleProperties_Action\", getShortcut(\"alt ENTER\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.MoveFileOrDirectory_Action\", getShortcut(\" F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.PasteNode_Action\", getShortcut(\"ctrl V\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.QuickCreate_Action\", getShortcut(\"alt INSERT\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RemoveFromFavorites_Action\", getShortcut(\"ctrl DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameFileOrDirectory_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameModel_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenamePackage_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.RenameSolution_Action\", getShortcut(\"shift F6\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SafeDelete_Action\", getShortcut(\"alt DELETE\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.SetBookmarkNoNumber_Action\", getShortcut(\" F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowBookmarksDialog_Action\", getShortcut(\"shift F11\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowClassInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowConceptInHierarchy_Action\", getShortcut(\"ctrl H\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowImplementations_Action\", getShortcut(\"ctrl shift I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowInLogicalView_Action\", getShortcut(\"alt F2\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInInspector_Action\", getShortcut(\"ctrl I\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowNodeInfo_Action\", getShortcut(\"ctrl Q\"));\n    addSimpleShortcut(\"jetbrains.mps.ide.actions.ShowParameters_Action\", getShortcut(\"ctrl P\"));\n    // simple parameterized \n    addComplexShortcut(\"jetbrains.mps.ide.actions.FileDelete_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\" DELETE\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToAction_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift A\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToFile_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl shift N\")));\n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToNamedNode_Action\", new BaseKeymapChanges.ComplexShortcut.ParameterizedSimpleShortcut(getShortcut(\"ctrl alt shift N\")));\n    // complex \n    addComplexShortcut(\"jetbrains.mps.ide.actions.GoToBookmark_Action\", new Default_KeymapChanges.GoToBookmark_ShortcutChange_qjewi8_ub());\n    addComplexShortcut(\"jetbrains.mps.ide.actions.SetBookmark_Action\", new Default_KeymapChanges.SetBookmark_ShortcutChange_qjewi8_vb());\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public GoToModel_Action(AnAction action_par) {\n    super(\"Go to Model\", \"\", ICON);\n    this.action = action_par;\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(true);\n  }","id":36158,"modified_method":"public GoToModel_Action() {\n    super(\"Go to Model\", \"\", ICON);\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(false);\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      GoToModel_Action.this.action.update(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToModel\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","id":36159,"modified_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      this.enable(event.getPresentation());\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToModel\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      GoToModel_Action.this.action.actionPerformed(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToModel\", t);\n      }\n    }\n  }","id":36160,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final Project project = event.getData(PlatformDataKeys.PROJECT);\n      assert project != null;\n      FeatureUsageTracker.getInstance().triggerFeatureUsed(\"navigation.goto.model\");\n      // PsiDocumentManager.getInstance(project).commitAllDocuments(); \n      BaseModelModel goToModelModel = new BaseModelModel(project) {\n        public NavigationItem doGetNavigationItem(final SModelReference modelReference) {\n          return new BaseModelItem(modelReference) {\n            public void navigate(boolean requestFocus) {\n              ProjectPane projectPane = ProjectPane.getInstance(project);\n              SModelDescriptor md = SModelRepository.getInstance().getModelDescriptor(modelReference);\n              projectPane.selectModel(md, true);\n            }\n          };\n        }\n\n        public SModelReference[] find(IScope scope) {\n          Condition<SModelDescriptor> cond = new Condition<SModelDescriptor>() {\n            public boolean met(SModelDescriptor modelDescriptor) {\n              boolean rightStereotype = SModelStereotype.isUserModel(modelDescriptor) || SModelStereotype.isStubModelStereotype(modelDescriptor.getStereotype());\n              boolean hasModule = modelDescriptor.getModule() != null;\n              return rightStereotype && hasModule;\n            }\n          };\n          ConditionalIterable<SModelDescriptor> iter = new ConditionalIterable<SModelDescriptor>(scope.getModelDescriptors(), cond);\n          List<SModelReference> result = new ArrayList<SModelReference>();\n          for (SModelDescriptor md : iter) {\n            result.add(md.getSModelReference());\n          }\n          return result.toArray(new SModelReference[result.size()]);\n        }\n      };\n      ChooseByNamePopup popup = MpsPopupFactory.createPackagePopup(project, goToModelModel);\n      popup.setShowListForEmptyPattern(true);\n      popup.invoke(new NavigateCallback(), ModalityState.current(), true);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToModel\", t);\n      }\n    }\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      GoToModule_Action.this.action.update(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToModule\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","id":36161,"modified_method":"public void doUpdate(@NotNull AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      this.enable(event.getPresentation());\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action doUpdate method failed. Action:\" + \"GoToModule\", t);\n      }\n      this.disable(event.getPresentation());\n    }\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      GoToModule_Action.this.action.actionPerformed(event);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToModule\", t);\n      }\n    }\n  }","id":36162,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final Project project = event.getData(PlatformDataKeys.PROJECT);\n      assert project != null;\n      FeatureUsageTracker.getInstance().triggerFeatureUsed(\"navigation.goto.module\");\n      // PsiDocumentManager.getInstance(project).commitAllDocuments(); \n      BaseModuleModel goToModuleModel = new BaseModuleModel(project, \"module\") {\n        public NavigationItem doGetNavigationItem(final ModuleReference ref) {\n          return new BaseModuleItem(ref) {\n            public void navigate(boolean requestFocus) {\n              ProjectPane projectPane = ProjectPane.getInstance(project);\n              IModule module = MPSModuleRepository.getInstance().getModule(ref);\n              projectPane.selectModule(module, true);\n            }\n          };\n        }\n\n        public ModuleReference[] find(IScope scope) {\n          List<ModuleReference> modules = new ArrayList<ModuleReference>();\n          for (IModule module : scope.getVisibleModules()) {\n            if (!((module instanceof Solution || module instanceof Language || module instanceof DevKit))) {\n              continue;\n            }\n            modules.add(module.getModuleReference());\n          }\n          return modules.toArray(new ModuleReference[modules.size()]);\n        }\n      };\n      ChooseByNamePopup popup = MpsPopupFactory.createPackagePopup(project, goToModuleModel);\n      popup.invoke(new NavigateCallback(), ModalityState.current(), true);\n    } catch (Throwable t) {\n      if (log.isErrorEnabled()) {\n        log.error(\"User's action execute method failed. Action:\" + \"GoToModule\", t);\n      }\n    }\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public GoToModule_Action(AnAction action_par) {\n    super(\"Go to Module\", \"\", ICON);\n    this.action = action_par;\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(true);\n  }","id":36163,"modified_method":"public GoToModule_Action() {\n    super(\"Go to Module\", \"\", ICON);\n    this.setIsAlwaysVisible(false);\n    this.setExecuteOutsideCommand(false);\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public Goto_ActionGroup() {\n    super(\"Go To\", ID);\n    this.setIsInternal(false);\n    this.setPopup(false);\n    try {\n      Goto_ActionGroup.this.addParameterizedAction(new GoToAction_Action(new GotoActionAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoActionAction());\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoVCS);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToFile_Action(new GotoFileAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoFileAction());\n      Goto_ActionGroup.this.addAction(\"jetbrains.mps.ide.actions.GoToRootNode_Action\");\n      Goto_ActionGroup.this.addSeparator();\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoConceptAspects);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModel_Action(new GoToModelAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModelAction());\n      Goto_ActionGroup.this.addParameterizedAction(new GoToModule_Action(new GoToModuleAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GoToModuleAction());\n    } catch (Throwable t) {\n      LOG.error(\"User group error\", t);\n    }\n  }","id":36164,"modified_method":"public Goto_ActionGroup() {\n    super(\"Go To\", ID);\n    this.setIsInternal(false);\n    this.setPopup(false);\n    try {\n      Goto_ActionGroup.this.addParameterizedAction(new GoToAction_Action(new GotoActionAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoActionAction());\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoVCS);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addParameterizedAction(new GoToFile_Action(new GotoFileAction()), PluginId.getId(\"jetbrains.mps.ide\"), new GotoFileAction());\n      Goto_ActionGroup.this.addAction(\"jetbrains.mps.ide.actions.GoToRootNode_Action\");\n      Goto_ActionGroup.this.addSeparator();\n      {\n        LabelledAnchor action = new LabelledAnchor(Goto_ActionGroup.LABEL_ID_gotoConceptAspects);\n        ActionManagerEx manager = ActionManagerEx.getInstanceEx();\n        manager.registerAction(action.getId(), action, PluginId.getId(\"jetbrains.mps.ide\"));\n        Goto_ActionGroup.this.addAction(action);\n      }\n      Goto_ActionGroup.this.addSeparator();\n      Goto_ActionGroup.this.addAction(\"jetbrains.mps.ide.actions.GoToModel_Action\");\n      Goto_ActionGroup.this.addAction(\"jetbrains.mps.ide.actions.GoToModule_Action\");\n    } catch (Throwable t) {\n      LOG.error(\"User group error\", t);\n    }\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void createGroups() {\n    // actions w/o parameters \n    addAction(new AddMissingImportsInProject_Action());\n    addAction(new AddMissingImports_Action());\n    addAction(new AddModuleToProject_Action());\n    addAction(new AddToNewFavoritesList_Action());\n    addAction(new AnalyzeClasspath_Action());\n    addAction(new AnalyzeDependencies_Action());\n    addAction(new AnalyzeModuleDependencies_Action());\n    addAction(new AnalyzeStacktrace_Action());\n    addAction(new CloneModel_Action());\n    addAction(new CloneRoot_Action());\n    addAction(new CopyModelName_Action());\n    addAction(new CopyModuleName_Action());\n    addAction(new CopyNodeName_Action());\n    addAction(new CopyNodeReference_Action());\n    addAction(new CopyNode_Action());\n    addAction(new CreateAspect_Action());\n    addAction(new CutNode_Action());\n    addAction(new DeleteFavoritesList_Action());\n    addAction(new DeleteModels_Action());\n    addAction(new DeleteModules_Action());\n    addAction(new DeleteNode_Action());\n    addAction(new DeletePropertyAction_Action());\n    addAction(new DeleteReferenceAction_Action());\n    addAction(new EditNode_Action());\n    addAction(new ExpandNode_Action());\n    addAction(new FastFindNodeUsages_Action());\n    addAction(new FindModelUsages_Action());\n    addAction(new FindNext_Action());\n    addAction(new FindPrevious_Action());\n    addAction(new FindRootableConceptsWithoutIcons_Action());\n    addAction(new FindSpecificNodeUsages_Action());\n    addAction(new Find_Action());\n    addAction(new GoByCurrentReferenceToIDEA_Action());\n    addAction(new GoToNode_Action());\n    addAction(new GoToRootNode_Action());\n    addAction(new GoToRule_Action());\n    addAction(new HighlightInstances_Action());\n    addAction(new HighlightUsages_Action());\n    addAction(new MPSProjectPaths_Action());\n    addAction(new ModelProperties_Action());\n    addAction(new ModuleProperties_Action());\n    addAction(new MoveFileOrDirectory_Action());\n    addAction(new NewDirectory_Action());\n    addAction(new NewFile_Action());\n    addAction(new NewModel_Action());\n    addAction(new NewRuntimeModule_Action());\n    addAction(new NewSolution_Action());\n    addAction(new NewSubModel_Action());\n    addAction(new NewSubTestModel_Action());\n    addAction(new OptimizeModelImports_Action());\n    addAction(new OptimizeModuleImports_Action());\n    addAction(new OptimizeProjectImports_Action());\n    addAction(new PasteNode_Action());\n    addAction(new PrintNodePosition_Action());\n    addAction(new QuickCreate_Action());\n    addAction(new RemoveAllBookmarks_Action());\n    addAction(new RemoveFromFavorites_Action());\n    addAction(new RemoveModuleFromProject_Action());\n    addAction(new RemoveTransientModels_Action());\n    addAction(new RenameFavoritesList_Action());\n    addAction(new RenameFileOrDirectory_Action());\n    addAction(new RenameModel_Action());\n    addAction(new RenameNamespace_Action());\n    addAction(new RenamePackage_Action());\n    addAction(new RenameSolution_Action());\n    addAction(new RevertMemoryChanges_Action());\n    addAction(new SafeDeleteModuleDependency_Action());\n    addAction(new SafeDelete_Action());\n    addAction(new SetBookmarkNoNumber_Action());\n    addAction(new SetModuleFolder_Action());\n    addAction(new SetNodePackage_Action());\n    addAction(new ShowBookmarksDialog_Action());\n    addAction(new ShowBookmarks_Action());\n    addAction(new ShowClassInHierarchy_Action());\n    addAction(new ShowConceptInHierarchy_Action());\n    addAction(new ShowErrorMessage_Action());\n    addAction(new ShowImplementations_Action());\n    addAction(new ShowInDependenciesViewer_Action());\n    addAction(new ShowInLogicalView_Action());\n    addAction(new ShowModuleDependencyLoop_Action());\n    addAction(new ShowNodeInInspector_Action());\n    addAction(new ShowNodeInfo_Action());\n    addAction(new ShowParameters_Action());\n    addAction(new ShowTodoViewer_Action());\n    addAction(new SubmitToTracker_Action());\n    // groups \n    addGroup(new AbstractFileActions_ActionGroup());\n    addGroup(new AddToFavoritesGroup_ActionGroup());\n    addGroup(new AnalyzeModule_ActionGroup());\n    addGroup(new Analyze_ActionGroup());\n    addGroup(new Bookmarks_ActionGroup());\n    addGroup(new Build_ActionGroup());\n    addGroup(new CommonModuleActions_ActionGroup());\n    addGroup(new CreateRootNode_ActionGroup());\n    addGroup(new DebugActions_ActionGroup());\n    addGroup(new DevkitActions_ActionGroup());\n    addGroup(new Edit_ActionGroup());\n    addGroup(new EditorInternal_ActionGroup());\n    addGroup(new EditorPopupEx_ActionGroup());\n    addGroup(new EditorPopupEx_Goto_ActionGroup());\n    addGroup(new EditorPopup_Show_ActionGroup());\n    addGroup(new EditorTabActions_ActionGroup());\n    addGroup(new FavoritesPopupWrapper_ActionGroup());\n    addGroup(new FavoritesPopup_ActionGroup());\n    addGroup(new Favorites_ActionGroup());\n    addGroup(new FileActions_ActionGroup());\n    addGroup(new FileSystemNewActions_ActionGroup());\n    addGroup(new FindModelUsages_ActionGroup());\n    addGroup(new FindUsages_ActionGroup());\n    addGroup(new FolderActions_ActionGroup());\n    addGroup(new GeneratorActions_ActionGroup());\n    addGroup(new GeneratorNewActions_ActionGroup());\n    addGroup(new GoByReference_ActionGroup());\n    addGroup(new Goto_ActionGroup());\n    addGroup(new JUnitTestCaseActions_ActionGroup());\n    addGroup(new JUnitTestMethodActions_ActionGroup());\n    addGroup(new LanguageActions_ActionGroup());\n    addGroup(new LanguageNewActions_ActionGroup());\n    addGroup(new LibraryActions_ActionGroup());\n    addGroup(new MessagesViewActions_ActionGroup());\n    addGroup(new ModelActionsInternal_ActionGroup());\n    addGroup(new ModelActions_ActionGroup());\n    addGroup(new ModelNewActions_ActionGroup());\n    addGroup(new ModelRefactoring_ActionGroup());\n    addGroup(new ModuleActions_ActionGroup());\n    addGroup(new NamespaceActions_ActionGroup());\n    addGroup(new NamespaceInternalActions_ActionGroup());\n    addGroup(new NamespaceMakeActions_ActionGroup());\n    addGroup(new NamespaceNewActions_ActionGroup());\n    addGroup(new NodeActionsInternal_ActionGroup());\n    addGroup(new NodeActions_ActionGroup());\n    addGroup(new PackageActions_ActionGroup());\n    addGroup(new PackageNewActions_ActionGroup());\n    addGroup(new PrintNodePosition_Addition_ActionGroup());\n    addGroup(new ProjectActions_ActionGroup());\n    addGroup(new ProjectNewActions_ActionGroup());\n    addGroup(new PropertyNodeActions_ActionGroup());\n    addGroup(new ReferenceNodeActions_ActionGroup());\n    addGroup(new RuntimeFolderActions_ActionGroup());\n    addGroup(new Search_ActionGroup());\n    addGroup(new SolutionActions_ActionGroup());\n    addGroup(new SolutionNewActions_ActionGroup());\n    addGroup(new SolutionRefactoring_ActionGroup());\n    addGroup(new ToolsInternal_ActionGroup());\n    addGroup(new Tools_ActionGroup());\n    addGroup(new TransientModulesActions_ActionGroup());\n    addGroup(new View_ActionGroup());\n  }","id":36165,"modified_method":"public void createGroups() {\n    // actions w/o parameters \n    addAction(new AddMissingImportsInProject_Action());\n    addAction(new AddMissingImports_Action());\n    addAction(new AddModuleToProject_Action());\n    addAction(new AddToNewFavoritesList_Action());\n    addAction(new AnalyzeClasspath_Action());\n    addAction(new AnalyzeDependencies_Action());\n    addAction(new AnalyzeModuleDependencies_Action());\n    addAction(new AnalyzeStacktrace_Action());\n    addAction(new CloneModel_Action());\n    addAction(new CloneRoot_Action());\n    addAction(new CopyModelName_Action());\n    addAction(new CopyModuleName_Action());\n    addAction(new CopyNodeName_Action());\n    addAction(new CopyNodeReference_Action());\n    addAction(new CopyNode_Action());\n    addAction(new CreateAspect_Action());\n    addAction(new CutNode_Action());\n    addAction(new DeleteFavoritesList_Action());\n    addAction(new DeleteModels_Action());\n    addAction(new DeleteModules_Action());\n    addAction(new DeleteNode_Action());\n    addAction(new DeletePropertyAction_Action());\n    addAction(new DeleteReferenceAction_Action());\n    addAction(new EditNode_Action());\n    addAction(new ExpandNode_Action());\n    addAction(new FastFindNodeUsages_Action());\n    addAction(new FindModelUsages_Action());\n    addAction(new FindNext_Action());\n    addAction(new FindPrevious_Action());\n    addAction(new FindRootableConceptsWithoutIcons_Action());\n    addAction(new FindSpecificNodeUsages_Action());\n    addAction(new Find_Action());\n    addAction(new GoByCurrentReferenceToIDEA_Action());\n    addAction(new GoToModel_Action());\n    addAction(new GoToModule_Action());\n    addAction(new GoToNode_Action());\n    addAction(new GoToRootNode_Action());\n    addAction(new GoToRule_Action());\n    addAction(new HighlightInstances_Action());\n    addAction(new HighlightUsages_Action());\n    addAction(new MPSProjectPaths_Action());\n    addAction(new ModelProperties_Action());\n    addAction(new ModuleProperties_Action());\n    addAction(new MoveFileOrDirectory_Action());\n    addAction(new NewDirectory_Action());\n    addAction(new NewFile_Action());\n    addAction(new NewModel_Action());\n    addAction(new NewRuntimeModule_Action());\n    addAction(new NewSolution_Action());\n    addAction(new NewSubModel_Action());\n    addAction(new NewSubTestModel_Action());\n    addAction(new OptimizeModelImports_Action());\n    addAction(new OptimizeModuleImports_Action());\n    addAction(new OptimizeProjectImports_Action());\n    addAction(new PasteNode_Action());\n    addAction(new PrintNodePosition_Action());\n    addAction(new QuickCreate_Action());\n    addAction(new RemoveAllBookmarks_Action());\n    addAction(new RemoveFromFavorites_Action());\n    addAction(new RemoveModuleFromProject_Action());\n    addAction(new RemoveTransientModels_Action());\n    addAction(new RenameFavoritesList_Action());\n    addAction(new RenameFileOrDirectory_Action());\n    addAction(new RenameModel_Action());\n    addAction(new RenameNamespace_Action());\n    addAction(new RenamePackage_Action());\n    addAction(new RenameSolution_Action());\n    addAction(new RevertMemoryChanges_Action());\n    addAction(new SafeDeleteModuleDependency_Action());\n    addAction(new SafeDelete_Action());\n    addAction(new SetBookmarkNoNumber_Action());\n    addAction(new SetModuleFolder_Action());\n    addAction(new SetNodePackage_Action());\n    addAction(new ShowBookmarksDialog_Action());\n    addAction(new ShowBookmarks_Action());\n    addAction(new ShowClassInHierarchy_Action());\n    addAction(new ShowConceptInHierarchy_Action());\n    addAction(new ShowErrorMessage_Action());\n    addAction(new ShowImplementations_Action());\n    addAction(new ShowInDependenciesViewer_Action());\n    addAction(new ShowInLogicalView_Action());\n    addAction(new ShowModuleDependencyLoop_Action());\n    addAction(new ShowNodeInInspector_Action());\n    addAction(new ShowNodeInfo_Action());\n    addAction(new ShowParameters_Action());\n    addAction(new ShowTodoViewer_Action());\n    addAction(new SubmitToTracker_Action());\n    // groups \n    addGroup(new AbstractFileActions_ActionGroup());\n    addGroup(new AddToFavoritesGroup_ActionGroup());\n    addGroup(new AnalyzeModule_ActionGroup());\n    addGroup(new Analyze_ActionGroup());\n    addGroup(new Bookmarks_ActionGroup());\n    addGroup(new Build_ActionGroup());\n    addGroup(new CommonModuleActions_ActionGroup());\n    addGroup(new CreateRootNode_ActionGroup());\n    addGroup(new DebugActions_ActionGroup());\n    addGroup(new DevkitActions_ActionGroup());\n    addGroup(new Edit_ActionGroup());\n    addGroup(new EditorInternal_ActionGroup());\n    addGroup(new EditorPopupEx_ActionGroup());\n    addGroup(new EditorPopupEx_Goto_ActionGroup());\n    addGroup(new EditorPopup_Show_ActionGroup());\n    addGroup(new EditorTabActions_ActionGroup());\n    addGroup(new FavoritesPopupWrapper_ActionGroup());\n    addGroup(new FavoritesPopup_ActionGroup());\n    addGroup(new Favorites_ActionGroup());\n    addGroup(new FileActions_ActionGroup());\n    addGroup(new FileSystemNewActions_ActionGroup());\n    addGroup(new FindModelUsages_ActionGroup());\n    addGroup(new FindUsages_ActionGroup());\n    addGroup(new FolderActions_ActionGroup());\n    addGroup(new GeneratorActions_ActionGroup());\n    addGroup(new GeneratorNewActions_ActionGroup());\n    addGroup(new GoByReference_ActionGroup());\n    addGroup(new Goto_ActionGroup());\n    addGroup(new JUnitTestCaseActions_ActionGroup());\n    addGroup(new JUnitTestMethodActions_ActionGroup());\n    addGroup(new LanguageActions_ActionGroup());\n    addGroup(new LanguageNewActions_ActionGroup());\n    addGroup(new LibraryActions_ActionGroup());\n    addGroup(new MessagesViewActions_ActionGroup());\n    addGroup(new ModelActionsInternal_ActionGroup());\n    addGroup(new ModelActions_ActionGroup());\n    addGroup(new ModelNewActions_ActionGroup());\n    addGroup(new ModelRefactoring_ActionGroup());\n    addGroup(new ModuleActions_ActionGroup());\n    addGroup(new NamespaceActions_ActionGroup());\n    addGroup(new NamespaceInternalActions_ActionGroup());\n    addGroup(new NamespaceMakeActions_ActionGroup());\n    addGroup(new NamespaceNewActions_ActionGroup());\n    addGroup(new NodeActionsInternal_ActionGroup());\n    addGroup(new NodeActions_ActionGroup());\n    addGroup(new PackageActions_ActionGroup());\n    addGroup(new PackageNewActions_ActionGroup());\n    addGroup(new PrintNodePosition_Addition_ActionGroup());\n    addGroup(new ProjectActions_ActionGroup());\n    addGroup(new ProjectNewActions_ActionGroup());\n    addGroup(new PropertyNodeActions_ActionGroup());\n    addGroup(new ReferenceNodeActions_ActionGroup());\n    addGroup(new RuntimeFolderActions_ActionGroup());\n    addGroup(new Search_ActionGroup());\n    addGroup(new SolutionActions_ActionGroup());\n    addGroup(new SolutionNewActions_ActionGroup());\n    addGroup(new SolutionRefactoring_ActionGroup());\n    addGroup(new ToolsInternal_ActionGroup());\n    addGroup(new Tools_ActionGroup());\n    addGroup(new TransientModulesActions_ActionGroup());\n    addGroup(new View_ActionGroup());\n  }","commit_id":"485a8f3f91351e034b6614e4cb0ca09b3dcb3fcf","url":"https://github.com/JetBrains/MPS"},{"original_method":"/**\n     * Process a single command.\n     * @throws IOException If we could not write the data to stdout.\n     */\n    private void processLine(BufferedReader reader, OutputStream out) throws IOException {\n        String line;\n        StringBuffer outsb = new StringBuffer();\n        try {\n            line = reader.readLine();\n        } catch (IOException e) {\n            outsb.append(\"Bye... (\"+e+\")\");\n            System.err.println(\"Bye... (\"+e+\")\");\n            return;\n        }\n        boolean getCHKOnly = false;\n        if(line == null) return;\n        String uline = line.toUpperCase();\n        Logger.minor(this, \"Command: \"+line);\n        if(uline.startsWith(\"GET:\")) {\n            // Should have a key next\n            String key = line.substring(\"GET:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            Logger.normal(this, \"Key: \"+key);\n            FreenetURI uri;\n            try {\n                uri = new FreenetURI(key);\n                Logger.normal(this, \"Key: \"+uri);\n            } catch (MalformedURLException e2) {\n                outsb.append(\"Malformed URI: \"+key+\" : \"+e2);\n                return;\n            }\n            try {\n\t\t\t\tFetchResult result = client.fetch(uri);\n\t\t\t\tClientMetadata cm = result.getMetadata();\n\t\t\t\toutsb.append(\"Content MIME type: \"+cm.getMIMEType());\n\t\t\t\tBucket data = result.asBucket();\n\t\t\t\t// FIXME limit it above\n\t\t\t\tif(data.size() > 32*1024) {\n\t\t\t\t\tSystem.err.println(\"Data is more than 32K: \"+data.size());\n\t\t\t\t\toutsb.append(\"Data is more than 32K: \"+data.size());\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tbyte[] dataBytes = BucketTools.toByteArray(data);\n\t\t\t\tboolean evil = false;\n\t\t\t\tfor(int i=0;i<dataBytes.length;i++) {\n\t\t\t\t\t// Look for escape codes\n\t\t\t\t\tif(dataBytes[i] == '\\n') continue;\n\t\t\t\t\tif(dataBytes[i] == '\\r') continue;\n\t\t\t\t\tif(dataBytes[i] < 32) evil = true;\n\t\t\t\t}\n\t\t\t\tif(evil) {\n\t\t\t\t\tSystem.err.println(\"Data may contain escape codes which could cause the terminal to run arbitrary commands! Save it to a file if you must with GETFILE:\");\n\t\t\t\t\toutsb.append(\"Data may contain escape codes which could cause the terminal to run arbitrary commands! Save it to a file if you must with GETFILE:\");\n\t\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\toutsb.append(\"Data:\\r\\n\");\n\t\t\t\toutsb.append(new String(dataBytes));\n\t\t\t} catch (FetchException e) {\n\t\t\t\toutsb.append(\"Error: \"+e.getMessage()+\"\\r\\n\");\n            \tif(e.getMode() == e.SPLITFILE_ERROR && e.errorCodes != null) {\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tif(e.newURI != null)\n            \t\toutsb.append(\"Permanent redirect: \"+e.newURI+\"\\r\\n\");\n\t\t\t}\n        } else if(uline.startsWith(\"GETFILE:\")) {\n            // Should have a key next\n            String key = line.substring(\"GETFILE:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            Logger.normal(this, \"Key: \"+key);\n            FreenetURI uri;\n            try {\n                uri = new FreenetURI(key);\n            } catch (MalformedURLException e2) {\n                outsb.append(\"Malformed URI: \"+key+\" : \"+e2);\n                return;\n            }\n            try {\n            \tlong startTime = System.currentTimeMillis();\n\t\t\t\tFetchResult result = client.fetch(uri);\n\t\t\t\tClientMetadata cm = result.getMetadata();\n\t\t\t\toutsb.append(\"Content MIME type: \"+cm.getMIMEType());\n\t\t\t\tBucket data = result.asBucket();\n                // Now calculate filename\n                String fnam = uri.getDocName();\n                fnam = sanitize(fnam);\n                if(fnam.length() == 0) {\n                    fnam = \"freenet-download-\"+HexUtil.bytesToHex(BucketTools.hash(data), 0, 10);\n                    String ext = DefaultMIMETypes.getExtension(cm.getMIMEType());\n                    if(ext != null && !ext.equals(\"\"))\n                    \tfnam += \".\" + ext;\n                }\n                File f = new File(downloadsDir, fnam);\n                if(f.exists()) {\n                    outsb.append(\"File exists already: \"+fnam);\n                    fnam = \"freenet-\"+System.currentTimeMillis()+\"-\"+fnam;\n                }\n                FileOutputStream fos = null;\n                try {\n                    fos = new FileOutputStream(f);\n                    BucketTools.copyTo(data, fos, Long.MAX_VALUE);\n                    fos.close();\n                    outsb.append(\"Written to \"+fnam);\n                } catch (IOException e) {\n                    outsb.append(\"Could not write file: caught \"+e);\n                    e.printStackTrace();\n                } finally {\n                    if(fos != null) try {\n                        fos.close();\n                    } catch (IOException e1) {\n                        // Ignore\n                    }\n                }\n                long endTime = System.currentTimeMillis();\n                long sz = data.size();\n                double rate = 1000.0 * sz / (endTime-startTime);\n                outsb.append(\"Download rate: \"+rate+\" bytes / second\");\n\t\t\t} catch (FetchException e) {\n\t\t\t\toutsb.append(\"Error: \"+e.getMessage());\n            \tif(e.getMode() == e.SPLITFILE_ERROR && e.errorCodes != null) {\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tif(e.newURI != null)\n            \t\toutsb.append(\"Permanent redirect: \"+e.newURI+\"\\r\\n\");\n\t\t\t}\n        } else if(uline.startsWith(\"QUIT\")) {\n            n.exit();\n        } else if(uline.startsWith(\"PUT:\") || (getCHKOnly = uline.startsWith(\"GETCHK:\"))) {\n            // Just insert to local store\n        \tif(getCHKOnly)\n        \t\tline = line.substring((\"GETCHK:\").length());\n        \telse\n        \t\tline = line.substring(\"PUT:\".length());\n            while(line.length() > 0 && line.charAt(0) == ' ')\n                line = line.substring(1);\n            while(line.length() > 0 && line.charAt(line.length()-1) == ' ')\n                line = line.substring(0, line.length()-2);\n            String content;\n            if(line.length() > 0) {\n                // Single line insert\n                content = line;\n            } else {\n                // Multiple line insert\n                content = readLines(reader, false);\n            }\n            // Insert\n            byte[] data = content.getBytes();\n            \n            InsertBlock block = new InsertBlock(new ArrayBucket(data), null, FreenetURI.EMPTY_CHK_URI);\n\n            FreenetURI uri;\n            try {\n            \turi = client.insert(block, getCHKOnly);\n            } catch (InserterException e) {\n            \toutsb.append(\"Error: \"+e.getMessage());\n            \tif(e.uri != null)\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n            \tint mode = e.getMode();\n            \tif(mode == InserterException.FATAL_ERRORS_IN_BLOCKS || mode == InserterException.TOO_MANY_RETRIES_IN_BLOCKS) {\n            \t\toutsb.append(\"Splitfile-specific error:\\n\"+e.errorCodes.toVerboseString());\n            \t}\n            \treturn;\n            }\n            \n            outsb.append(\"URI: \"+uri);\n            ////////////////////////////////////////////////////////////////////////////////\n        } else if(uline.startsWith(\"PUTDIR:\") || (uline.startsWith(\"PUTSSKDIR\")) || (getCHKOnly = uline.startsWith(\"GETCHKDIR:\"))) {\n        \t// TODO: Check for errors?\n        \tboolean ssk = false;\n        \tif(uline.startsWith(\"PUTDIR:\"))\n        \t\tline = line.substring(\"PUTDIR:\".length());\n        \telse if(uline.startsWith(\"PUTSSKDIR:\")) {\n        \t\tline = line.substring(\"PUTSSKDIR:\".length());\n        \t\tssk = true;\n        \t} else if(uline.startsWith(\"GETCHKDIR:\"))\n        \t\tline = line.substring((\"GETCHKDIR:\").length());\n        \telse {\n        \t\tSystem.err.println(\"Impossible\");\n        \t\toutsb.append(\"Impossible\");\n        \t}\n        \t\n        \tline = line.trim();\n        \t\n        \tif(line.length() < 1) {\n        \t\tprintHeader(out);\n        \t\treturn;\n        \t}\n        \t\n        \tString defaultFile = null;\n        \t\n        \tFreenetURI insertURI = FreenetURI.EMPTY_CHK_URI;\n        \t\n        \t// set default file?\n        \tif (line.matches(\"^.*#.*$\")) {\n        \t\tString[] split = line.split(\"#\");\n        \t\tif(ssk) {\n        \t\t\tinsertURI = new FreenetURI(split[0]);\n        \t\t\tline = split[1];\n        \t\t\tif(split.length > 2)\n        \t\t\t\tdefaultFile = split[2];\n        \t\t} else {\n        \t\t\tdefaultFile = split[1];\n        \t\t\tline = split[0];\n        \t\t}\n        \t}\n        \t\n        \tHashMap bucketsByName =\n        \t\tmakeBucketsByName(line);\n        \t\n        \tif(defaultFile == null) {\n        \t\tString[] defaultFiles = \n        \t\t\tnew String[] { \"index.html\", \"index.htm\", \"default.html\", \"default.htm\" };\n        \t\tfor(int i=0;i<defaultFiles.length;i++) {\n        \t\t\tif(bucketsByName.containsKey(defaultFiles[i])) {\n        \t\t\t\tdefaultFile = defaultFiles[i];\n        \t\t\t\tbreak;\n        \t\t\t}        \t\t\t\t\n        \t\t}\n        \t}\n        \t\n        \tFreenetURI uri;\n\t\t\ttry {\n\t\t\t\turi = client.insertManifest(insertURI, bucketsByName, defaultFile);\n\t\t\t\turi = uri.addMetaStrings(new String[] { \"\" });\n\t        \toutsb.append(\"=======================================================\");\n\t            outsb.append(\"URI: \"+uri);\n\t        \toutsb.append(\"=======================================================\");\n\t\t\t} catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tif(e.uri != null) {\n            \t\turi = e.uri;\n    \t\t\t\turi = uri.addMetaStrings(new String[] { \"\" });\n            \t\toutsb.append(\"URI would have been: \"+uri);\n            \t}\n            \tif(e.errorCodes != null) {\n            \t\toutsb.append(\"Splitfile errors breakdown:\");\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tLogger.error(this, \"Caught \"+e, e);\n\t\t\t}\n            \n        } else if(uline.startsWith(\"PUTFILE:\") || (getCHKOnly = uline.startsWith(\"GETCHKFILE:\"))) {\n            // Just insert to local store\n        \tif(getCHKOnly) {\n        \t\tline = line.substring((\"GETCHKFILE:\").length());\n        \t} else {\n        \t\tline = line.substring(\"PUTFILE:\".length());\n        \t}\n            while(line.length() > 0 && line.charAt(0) == ' ')\n                line = line.substring(1);\n            while(line.length() > 0 && line.charAt(line.length()-1) == ' ')\n                line = line.substring(0, line.length()-2);\n            File f = new File(line);\n            outsb.append(\"Attempting to read file \"+line);\n            long startTime = System.currentTimeMillis();\n            try {\n            \tif(!(f.exists() && f.canRead())) {\n            \t\tthrow new FileNotFoundException();\n            \t}\n            \t\n            \t// Guess MIME type\n            \tString mimeType = DefaultMIMETypes.guessMIMEType(line);\n            \toutsb.append(\"Using MIME type: \"+mimeType);\n            \tif(mimeType.equals(DefaultMIMETypes.DEFAULT_MIME_TYPE))\n            \t\tmimeType = \"\"; // don't need to override it\n            \t\n            \tFileBucket fb = new FileBucket(f, true, false, false, false);\n            \tInsertBlock block = new InsertBlock(fb, new ClientMetadata(mimeType), FreenetURI.EMPTY_CHK_URI);\n\n            \tstartTime = System.currentTimeMillis();\n            \tFreenetURI uri = client.insert(block, getCHKOnly);\n            \t\n            \t// FIXME depends on CHK's still being renamable\n                //uri = uri.setDocName(f.getName());\n            \t\n                outsb.append(\"URI: \"+uri+\"\\r\\n\");\n            \tlong endTime = System.currentTimeMillis();\n                long sz = f.length();\n                double rate = 1000.0 * sz / (endTime-startTime);\n                outsb.append(\"Upload rate: \"+rate+\" bytes / second\\r\\n\");\n            } catch (FileNotFoundException e1) {\n                outsb.append(\"File not found\");\n            } catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tif(e.uri != null) {\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n                \tlong endTime = System.currentTimeMillis();\n                    long sz = f.length();\n                    double rate = 1000.0 * sz / (endTime-startTime);\n                    outsb.append(\"Upload rate: \"+rate+\" bytes / second\");\n            \t}\n            \tif(e.errorCodes != null) {\n            \t\toutsb.append(\"Splitfile errors breakdown:\");\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            } catch (Throwable t) {\n                outsb.append(\"Insert threw: \"+t);\n                t.printStackTrace();\n            }\n        } else if(uline.startsWith(\"MAKESSK\")) {\n        \tInsertableClientSSK key = InsertableClientSSK.createRandom(r);\n        \toutsb.append(\"Insert URI: \"+key.getInsertURI().toString(false));\n        \toutsb.append(\"Request URI: \"+key.getURI().toString(false));\n        \tFreenetURI insertURI = key.getInsertURI().setDocName(\"testsite\");\n        \tString fixedInsertURI = insertURI.toString(false);\n        \toutsb.append(\"Note that you MUST add a filename to the end of the above URLs e.g.:\\r\\n\"+fixedInsertURI);\n        \toutsb.append(\"Normally you will then do PUTSSKDIR:<insert URI>#<directory to upload>, for example:\\r\\nPUTSSKDIR:\"+fixedInsertURI+\"#directoryToUpload/\");\n        \toutsb.append(\"This will then produce a manifest site containing all the files, the default document can be accessed at\\r\\n\"+insertURI.addMetaStrings(new String[] { \"\" }).toString(false));\n        } else if(uline.startsWith(\"PUTSSK:\")) {\n        \tString cmd = line.substring(\"PUTSSK:\".length());\n        \tcmd = cmd.trim();\n        \tif(cmd.indexOf(';') <= 0) {\n        \t\toutsb.append(\"No target URI provided.\");\n        \t\toutsb.append(\"PUTSSK:<insert uri>;<url to redirect to>\");\n        \t\treturn;\n        \t}\n        \tString[] split = cmd.split(\";\");\n        \tString insertURI = split[0];\n        \tString targetURI = split[1];\n        \toutsb.append(\"Insert URI: \"+insertURI);\n        \toutsb.append(\"Target URI: \"+targetURI);\n        \tFreenetURI insert = new FreenetURI(insertURI);\n        \tFreenetURI target = new FreenetURI(targetURI);\n        \ttry {\n\t\t\t\tFreenetURI result = client.insertRedirect(insert, target);\n\t\t\t\toutsb.append(\"Successfully inserted to fetch URI: \"+result);\n\t\t\t} catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tLogger.normal(this, \"Error: \"+e, e);\n            \tif(e.uri != null) {\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n            \t}\n\t\t\t}\n        \t\n        } else if(uline.startsWith(\"STATUS\")) {\n            SimpleFieldSet fs = n.exportFieldSet();\n            outsb.append(fs.toString());\n            outsb.append(n.getStatus());\n\t    if(Version.buildNumber()<Version.highestSeenBuild){\n\t            outsb.append(\"The latest version is : \"+Version.highestSeenBuild);\n\t    }\n        } else if(uline.startsWith(\"CONNECT:\")) {\n            String key = line.substring(\"CONNECT:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            \n            String content = null;\n            if(key.length() > 0) {\n                // Filename\n            \tBufferedReader in;\n                outsb.append(\"Trying to connect to noderef in \"+key);\n                File f = new File(key);\n                if (f.isFile()) {\n                \toutsb.append(\"Given string seems to be a file, loading...\");\n                \tin = new BufferedReader(new FileReader(f));\n                } else {\n                \toutsb.append(\"Given string seems to be an URL, loading...\");\n                    URL url = new URL(key);\n                    URLConnection uc = url.openConnection();\n                \tin = new BufferedReader(\n                \t\t\tnew InputStreamReader(uc.getInputStream()));\n                }\n                content = readLines(in, true);\n                in.close();\n            } else {\n                content = readLines(reader, true);\n            }\n            if(content == null) return;\n            if(content.equals(\"\")) return;\n            connect(content);\n        \n        } else if(uline.startsWith(\"NAME:\")) {\n            outsb.append(\"Node name currently: \"+n.myName);\n            String key = line.substring(\"NAME:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            outsb.append(\"New name: \"+key);\n            n.setName(key);\n        } else if(uline.startsWith(\"DISCONNECT:\")) {\n        \tString ipAndPort = line.substring(\"DISCONNECT:\".length());\n        \tdisconnect(ipAndPort.trim());\n        \t\n        } else if(uline.startsWith(\"PLUGLOAD:\")) {\n        \tif (line.substring(\"PLUGLOAD:\".length()).trim().equals(\"?\")) {\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class                  - Load plugin from current classpath\");        \t\t\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class@file:<filename>  - Load plugin from file\");\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class@http://...       - Load plugin from online file\");\n        \t\toutsb.append(\"  PLUGLOAD:         *@...              - Load plugin from manifest in given jarfile\");\n        \t\toutsb.append(\"\");\n        \t\toutsb.append(\"If the filename/url ends with \\\".url\\\", it\" +\n        \t\t\t\t\" is treated as a link, meaning that the first line is\" +\n        \t\t\t\t\" the accual URL. Else it is loaded as classpath and\" +\n        \t\t\t\t\" the class it loaded from it (meaning the file could\" +\n        \t\t\t\t\" be either a jar-file or a class-file).\");\n        \t\toutsb.append(\"\");\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class*  - Load newest version of plugin from http://downloads.freenetproject.org/alpha/plugins/\");        \t\t\n        \t\toutsb.append(\"\");\n        \t\t\n        \t} else\n        \t\tn.pluginManager.startPlugin(line.substring(\"PLUGLOAD:\".length()).trim());\n            //outsb.append(\"PLUGLOAD: <pkg.classname>[(@<URI to jarfile.jar>|<<URI to file containing real URI>|* (will load from freenets pluginpool))] - Load plugin.\");\n        } else if(uline.startsWith(\"PLUGLIST\")) {\n        \toutsb.append(n.pluginManager.dumpPlugins());\n        } else if(uline.startsWith(\"PLUGKILL:\")) {\n        \tn.pluginManager.killPlugin(line.substring(\"PLUGKILL:\".length()).trim());\n        } else {\n        \tif(uline.length() > 0)\n        \t\tprintHeader(out);\n        }\n        outsb.append(\"\\r\\n\");\n        out.write(outsb.toString().getBytes());\n        out.flush();\n    }","id":36166,"modified_method":"/**\n     * Process a single command.\n     * @throws IOException If we could not write the data to stdout.\n     */\n    private boolean processLine(BufferedReader reader, OutputStream out) throws IOException {\n        String line;\n        StringBuffer outsb = new StringBuffer();\n        try {\n            line = reader.readLine();\n        } catch (IOException e) {\n            outsb.append(\"Bye... (\"+e+\")\");\n            System.err.println(\"Bye... (\"+e+\")\");\n            return true;\n        }\n        boolean getCHKOnly = false;\n        if(line == null) return true;\n        String uline = line.toUpperCase();\n        Logger.minor(this, \"Command: \"+line);\n        if(uline.startsWith(\"GET:\")) {\n            // Should have a key next\n            String key = line.substring(\"GET:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            Logger.normal(this, \"Key: \"+key);\n            FreenetURI uri;\n            try {\n                uri = new FreenetURI(key);\n                Logger.normal(this, \"Key: \"+uri);\n            } catch (MalformedURLException e2) {\n                outsb.append(\"Malformed URI: \"+key+\" : \"+e2);\n                return false;\n            }\n            try {\n\t\t\t\tFetchResult result = client.fetch(uri);\n\t\t\t\tClientMetadata cm = result.getMetadata();\n\t\t\t\toutsb.append(\"Content MIME type: \"+cm.getMIMEType());\n\t\t\t\tBucket data = result.asBucket();\n\t\t\t\t// FIXME limit it above\n\t\t\t\tif(data.size() > 32*1024) {\n\t\t\t\t\tSystem.err.println(\"Data is more than 32K: \"+data.size());\n\t\t\t\t\toutsb.append(\"Data is more than 32K: \"+data.size());\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\tbyte[] dataBytes = BucketTools.toByteArray(data);\n\t\t\t\tboolean evil = false;\n\t\t\t\tfor(int i=0;i<dataBytes.length;i++) {\n\t\t\t\t\t// Look for escape codes\n\t\t\t\t\tif(dataBytes[i] == '\\n') continue;\n\t\t\t\t\tif(dataBytes[i] == '\\r') continue;\n\t\t\t\t\tif(dataBytes[i] < 32) evil = true;\n\t\t\t\t}\n\t\t\t\tif(evil) {\n\t\t\t\t\tSystem.err.println(\"Data may contain escape codes which could cause the terminal to run arbitrary commands! Save it to a file if you must with GETFILE:\");\n\t\t\t\t\toutsb.append(\"Data may contain escape codes which could cause the terminal to run arbitrary commands! Save it to a file if you must with GETFILE:\");\n\t\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\toutsb.append(\"Data:\\r\\n\");\n\t\t\t\toutsb.append(new String(dataBytes));\n\t\t\t} catch (FetchException e) {\n\t\t\t\toutsb.append(\"Error: \"+e.getMessage()+\"\\r\\n\");\n            \tif(e.getMode() == e.SPLITFILE_ERROR && e.errorCodes != null) {\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tif(e.newURI != null)\n            \t\toutsb.append(\"Permanent redirect: \"+e.newURI+\"\\r\\n\");\n\t\t\t}\n        } else if(uline.startsWith(\"GETFILE:\")) {\n            // Should have a key next\n            String key = line.substring(\"GETFILE:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            Logger.normal(this, \"Key: \"+key);\n            FreenetURI uri;\n            try {\n                uri = new FreenetURI(key);\n            } catch (MalformedURLException e2) {\n                outsb.append(\"Malformed URI: \"+key+\" : \"+e2);\n                return false;\n            }\n            try {\n            \tlong startTime = System.currentTimeMillis();\n\t\t\t\tFetchResult result = client.fetch(uri);\n\t\t\t\tClientMetadata cm = result.getMetadata();\n\t\t\t\toutsb.append(\"Content MIME type: \"+cm.getMIMEType());\n\t\t\t\tBucket data = result.asBucket();\n                // Now calculate filename\n                String fnam = uri.getDocName();\n                fnam = sanitize(fnam);\n                if(fnam.length() == 0) {\n                    fnam = \"freenet-download-\"+HexUtil.bytesToHex(BucketTools.hash(data), 0, 10);\n                    String ext = DefaultMIMETypes.getExtension(cm.getMIMEType());\n                    if(ext != null && !ext.equals(\"\"))\n                    \tfnam += \".\" + ext;\n                }\n                File f = new File(downloadsDir, fnam);\n                if(f.exists()) {\n                    outsb.append(\"File exists already: \"+fnam);\n                    fnam = \"freenet-\"+System.currentTimeMillis()+\"-\"+fnam;\n                }\n                FileOutputStream fos = null;\n                try {\n                    fos = new FileOutputStream(f);\n                    BucketTools.copyTo(data, fos, Long.MAX_VALUE);\n                    fos.close();\n                    outsb.append(\"Written to \"+fnam);\n                } catch (IOException e) {\n                    outsb.append(\"Could not write file: caught \"+e);\n                    e.printStackTrace();\n                } finally {\n                    if(fos != null) try {\n                        fos.close();\n                    } catch (IOException e1) {\n                        // Ignore\n                    }\n                }\n                long endTime = System.currentTimeMillis();\n                long sz = data.size();\n                double rate = 1000.0 * sz / (endTime-startTime);\n                outsb.append(\"Download rate: \"+rate+\" bytes / second\");\n\t\t\t} catch (FetchException e) {\n\t\t\t\toutsb.append(\"Error: \"+e.getMessage());\n            \tif(e.getMode() == e.SPLITFILE_ERROR && e.errorCodes != null) {\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tif(e.newURI != null)\n            \t\toutsb.append(\"Permanent redirect: \"+e.newURI+\"\\r\\n\");\n\t\t\t}\n        } else if(uline.startsWith(\"QUIT\")) {\n            n.exit();\n        } else if(uline.startsWith(\"PUT:\") || (getCHKOnly = uline.startsWith(\"GETCHK:\"))) {\n            // Just insert to local store\n        \tif(getCHKOnly)\n        \t\tline = line.substring((\"GETCHK:\").length());\n        \telse\n        \t\tline = line.substring(\"PUT:\".length());\n            while(line.length() > 0 && line.charAt(0) == ' ')\n                line = line.substring(1);\n            while(line.length() > 0 && line.charAt(line.length()-1) == ' ')\n                line = line.substring(0, line.length()-2);\n            String content;\n            if(line.length() > 0) {\n                // Single line insert\n                content = line;\n            } else {\n                // Multiple line insert\n                content = readLines(reader, false);\n            }\n            // Insert\n            byte[] data = content.getBytes();\n            \n            InsertBlock block = new InsertBlock(new ArrayBucket(data), null, FreenetURI.EMPTY_CHK_URI);\n\n            FreenetURI uri;\n            try {\n            \turi = client.insert(block, getCHKOnly);\n            } catch (InserterException e) {\n            \toutsb.append(\"Error: \"+e.getMessage());\n            \tif(e.uri != null)\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n            \tint mode = e.getMode();\n            \tif(mode == InserterException.FATAL_ERRORS_IN_BLOCKS || mode == InserterException.TOO_MANY_RETRIES_IN_BLOCKS) {\n            \t\toutsb.append(\"Splitfile-specific error:\\n\"+e.errorCodes.toVerboseString());\n            \t}\n            \treturn false;\n            }\n            \n            outsb.append(\"URI: \"+uri);\n            ////////////////////////////////////////////////////////////////////////////////\n        } else if(uline.startsWith(\"PUTDIR:\") || (uline.startsWith(\"PUTSSKDIR\")) || (getCHKOnly = uline.startsWith(\"GETCHKDIR:\"))) {\n        \t// TODO: Check for errors?\n        \tboolean ssk = false;\n        \tif(uline.startsWith(\"PUTDIR:\"))\n        \t\tline = line.substring(\"PUTDIR:\".length());\n        \telse if(uline.startsWith(\"PUTSSKDIR:\")) {\n        \t\tline = line.substring(\"PUTSSKDIR:\".length());\n        \t\tssk = true;\n        \t} else if(uline.startsWith(\"GETCHKDIR:\"))\n        \t\tline = line.substring((\"GETCHKDIR:\").length());\n        \telse {\n        \t\tSystem.err.println(\"Impossible\");\n        \t\toutsb.append(\"Impossible\");\n        \t}\n        \t\n        \tline = line.trim();\n        \t\n        \tif(line.length() < 1) {\n        \t\tprintHeader(out);\n        \t\treturn false;\n        \t}\n        \t\n        \tString defaultFile = null;\n        \t\n        \tFreenetURI insertURI = FreenetURI.EMPTY_CHK_URI;\n        \t\n        \t// set default file?\n        \tif (line.matches(\"^.*#.*$\")) {\n        \t\tString[] split = line.split(\"#\");\n        \t\tif(ssk) {\n        \t\t\tinsertURI = new FreenetURI(split[0]);\n        \t\t\tline = split[1];\n        \t\t\tif(split.length > 2)\n        \t\t\t\tdefaultFile = split[2];\n        \t\t} else {\n        \t\t\tdefaultFile = split[1];\n        \t\t\tline = split[0];\n        \t\t}\n        \t}\n        \t\n        \tHashMap bucketsByName =\n        \t\tmakeBucketsByName(line);\n        \t\n        \tif(defaultFile == null) {\n        \t\tString[] defaultFiles = \n        \t\t\tnew String[] { \"index.html\", \"index.htm\", \"default.html\", \"default.htm\" };\n        \t\tfor(int i=0;i<defaultFiles.length;i++) {\n        \t\t\tif(bucketsByName.containsKey(defaultFiles[i])) {\n        \t\t\t\tdefaultFile = defaultFiles[i];\n        \t\t\t\tbreak;\n        \t\t\t}        \t\t\t\t\n        \t\t}\n        \t}\n        \t\n        \tFreenetURI uri;\n\t\t\ttry {\n\t\t\t\turi = client.insertManifest(insertURI, bucketsByName, defaultFile);\n\t\t\t\turi = uri.addMetaStrings(new String[] { \"\" });\n\t        \toutsb.append(\"=======================================================\");\n\t            outsb.append(\"URI: \"+uri);\n\t        \toutsb.append(\"=======================================================\");\n\t\t\t} catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tif(e.uri != null) {\n            \t\turi = e.uri;\n    \t\t\t\turi = uri.addMetaStrings(new String[] { \"\" });\n            \t\toutsb.append(\"URI would have been: \"+uri);\n            \t}\n            \tif(e.errorCodes != null) {\n            \t\toutsb.append(\"Splitfile errors breakdown:\");\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            \tLogger.error(this, \"Caught \"+e, e);\n\t\t\t}\n            \n        } else if(uline.startsWith(\"PUTFILE:\") || (getCHKOnly = uline.startsWith(\"GETCHKFILE:\"))) {\n            // Just insert to local store\n        \tif(getCHKOnly) {\n        \t\tline = line.substring((\"GETCHKFILE:\").length());\n        \t} else {\n        \t\tline = line.substring(\"PUTFILE:\".length());\n        \t}\n            while(line.length() > 0 && line.charAt(0) == ' ')\n                line = line.substring(1);\n            while(line.length() > 0 && line.charAt(line.length()-1) == ' ')\n                line = line.substring(0, line.length()-2);\n            File f = new File(line);\n            outsb.append(\"Attempting to read file \"+line);\n            long startTime = System.currentTimeMillis();\n            try {\n            \tif(!(f.exists() && f.canRead())) {\n            \t\tthrow new FileNotFoundException();\n            \t}\n            \t\n            \t// Guess MIME type\n            \tString mimeType = DefaultMIMETypes.guessMIMEType(line);\n            \toutsb.append(\"Using MIME type: \"+mimeType);\n            \tif(mimeType.equals(DefaultMIMETypes.DEFAULT_MIME_TYPE))\n            \t\tmimeType = \"\"; // don't need to override it\n            \t\n            \tFileBucket fb = new FileBucket(f, true, false, false, false);\n            \tInsertBlock block = new InsertBlock(fb, new ClientMetadata(mimeType), FreenetURI.EMPTY_CHK_URI);\n\n            \tstartTime = System.currentTimeMillis();\n            \tFreenetURI uri = client.insert(block, getCHKOnly);\n            \t\n            \t// FIXME depends on CHK's still being renamable\n                //uri = uri.setDocName(f.getName());\n            \t\n                outsb.append(\"URI: \"+uri+\"\\r\\n\");\n            \tlong endTime = System.currentTimeMillis();\n                long sz = f.length();\n                double rate = 1000.0 * sz / (endTime-startTime);\n                outsb.append(\"Upload rate: \"+rate+\" bytes / second\\r\\n\");\n            } catch (FileNotFoundException e1) {\n                outsb.append(\"File not found\");\n            } catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tif(e.uri != null) {\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n                \tlong endTime = System.currentTimeMillis();\n                    long sz = f.length();\n                    double rate = 1000.0 * sz / (endTime-startTime);\n                    outsb.append(\"Upload rate: \"+rate+\" bytes / second\");\n            \t}\n            \tif(e.errorCodes != null) {\n            \t\toutsb.append(\"Splitfile errors breakdown:\");\n            \t\toutsb.append(e.errorCodes.toVerboseString());\n            \t}\n            } catch (Throwable t) {\n                outsb.append(\"Insert threw: \"+t);\n                t.printStackTrace();\n            }\n        } else if(uline.startsWith(\"MAKESSK\")) {\n        \tInsertableClientSSK key = InsertableClientSSK.createRandom(r);\n        \toutsb.append(\"Insert URI: \"+key.getInsertURI().toString(false));\n        \toutsb.append(\"Request URI: \"+key.getURI().toString(false));\n        \tFreenetURI insertURI = key.getInsertURI().setDocName(\"testsite\");\n        \tString fixedInsertURI = insertURI.toString(false);\n        \toutsb.append(\"Note that you MUST add a filename to the end of the above URLs e.g.:\\r\\n\"+fixedInsertURI);\n        \toutsb.append(\"Normally you will then do PUTSSKDIR:<insert URI>#<directory to upload>, for example:\\r\\nPUTSSKDIR:\"+fixedInsertURI+\"#directoryToUpload/\");\n        \toutsb.append(\"This will then produce a manifest site containing all the files, the default document can be accessed at\\r\\n\"+insertURI.addMetaStrings(new String[] { \"\" }).toString(false));\n        } else if(uline.startsWith(\"PUTSSK:\")) {\n        \tString cmd = line.substring(\"PUTSSK:\".length());\n        \tcmd = cmd.trim();\n        \tif(cmd.indexOf(';') <= 0) {\n        \t\toutsb.append(\"No target URI provided.\");\n        \t\toutsb.append(\"PUTSSK:<insert uri>;<url to redirect to>\");\n        \t\treturn false;\n        \t}\n        \tString[] split = cmd.split(\";\");\n        \tString insertURI = split[0];\n        \tString targetURI = split[1];\n        \toutsb.append(\"Insert URI: \"+insertURI);\n        \toutsb.append(\"Target URI: \"+targetURI);\n        \tFreenetURI insert = new FreenetURI(insertURI);\n        \tFreenetURI target = new FreenetURI(targetURI);\n        \ttry {\n\t\t\t\tFreenetURI result = client.insertRedirect(insert, target);\n\t\t\t\toutsb.append(\"Successfully inserted to fetch URI: \"+result);\n\t\t\t} catch (InserterException e) {\n            \toutsb.append(\"Finished insert but: \"+e.getMessage());\n            \tLogger.normal(this, \"Error: \"+e, e);\n            \tif(e.uri != null) {\n            \t\toutsb.append(\"URI would have been: \"+e.uri);\n            \t}\n\t\t\t}\n        \t\n        } else if(uline.startsWith(\"STATUS\")) {\n            SimpleFieldSet fs = n.exportFieldSet();\n            outsb.append(fs.toString());\n            outsb.append(n.getStatus());\n\t    if(Version.buildNumber()<Version.highestSeenBuild){\n\t            outsb.append(\"The latest version is : \"+Version.highestSeenBuild);\n\t    }\n        } else if(uline.startsWith(\"CONNECT:\")) {\n            String key = line.substring(\"CONNECT:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            \n            String content = null;\n            if(key.length() > 0) {\n                // Filename\n            \tBufferedReader in;\n                outsb.append(\"Trying to connect to noderef in \"+key);\n                File f = new File(key);\n                if (f.isFile()) {\n                \toutsb.append(\"Given string seems to be a file, loading...\");\n                \tin = new BufferedReader(new FileReader(f));\n                } else {\n                \toutsb.append(\"Given string seems to be an URL, loading...\");\n                    URL url = new URL(key);\n                    URLConnection uc = url.openConnection();\n                \tin = new BufferedReader(\n                \t\t\tnew InputStreamReader(uc.getInputStream()));\n                }\n                content = readLines(in, true);\n                in.close();\n            } else {\n                content = readLines(reader, true);\n            }\n            if(content == null) return false;\n            if(content.equals(\"\")) return false;\n            connect(content);\n        \n        } else if(uline.startsWith(\"NAME:\")) {\n            outsb.append(\"Node name currently: \"+n.myName);\n            String key = line.substring(\"NAME:\".length());\n            while(key.length() > 0 && key.charAt(0) == ' ')\n                key = key.substring(1);\n            while(key.length() > 0 && key.charAt(key.length()-1) == ' ')\n                key = key.substring(0, key.length()-2);\n            outsb.append(\"New name: \"+key);\n            n.setName(key);\n        } else if(uline.startsWith(\"DISCONNECT:\")) {\n        \tString ipAndPort = line.substring(\"DISCONNECT:\".length());\n        \tdisconnect(ipAndPort.trim());\n        \t\n        } else if(uline.startsWith(\"PLUGLOAD:\")) {\n        \tif (line.substring(\"PLUGLOAD:\".length()).trim().equals(\"?\")) {\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class                  - Load plugin from current classpath\");        \t\t\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class@file:<filename>  - Load plugin from file\");\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class@http://...       - Load plugin from online file\");\n        \t\toutsb.append(\"  PLUGLOAD:         *@...              - Load plugin from manifest in given jarfile\");\n        \t\toutsb.append(\"\");\n        \t\toutsb.append(\"If the filename/url ends with \\\".url\\\", it\" +\n        \t\t\t\t\" is treated as a link, meaning that the first line is\" +\n        \t\t\t\t\" the accual URL. Else it is loaded as classpath and\" +\n        \t\t\t\t\" the class it loaded from it (meaning the file could\" +\n        \t\t\t\t\" be either a jar-file or a class-file).\");\n        \t\toutsb.append(\"\");\n        \t\toutsb.append(\"  PLUGLOAD: pkg.Class*  - Load newest version of plugin from http://downloads.freenetproject.org/alpha/plugins/\");        \t\t\n        \t\toutsb.append(\"\");\n        \t\t\n        \t} else\n        \t\tn.pluginManager.startPlugin(line.substring(\"PLUGLOAD:\".length()).trim());\n            //outsb.append(\"PLUGLOAD: <pkg.classname>[(@<URI to jarfile.jar>|<<URI to file containing real URI>|* (will load from freenets pluginpool))] - Load plugin.\");\n        } else if(uline.startsWith(\"PLUGLIST\")) {\n        \toutsb.append(n.pluginManager.dumpPlugins());\n        } else if(uline.startsWith(\"PLUGKILL:\")) {\n        \tn.pluginManager.killPlugin(line.substring(\"PLUGKILL:\".length()).trim());\n        } else {\n        \tif(uline.length() > 0)\n        \t\tprintHeader(out);\n        }\n        outsb.append(\"\\r\\n\");\n        out.write(outsb.toString().getBytes());\n        out.flush();\n        return false;\n    }","commit_id":"8fb84ecb4f999d46d9f08a051b57d64c234b5ce4","url":"https://github.com/freenet/fred"},{"original_method":"public void realRun() throws IOException {\n\t\tprintHeader(out);\n\n\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(in));\n        while(true) {\n            try {\n                processLine(reader,out);\n            } catch (SocketException e) {\n            \tLogger.error(this, \"Socket error: \"+e, e);\n            \treturn;\n            } catch (Throwable t) {\n                Logger.error(this, \"Caught \"+t, t);\n                System.out.println(\"Caught: \"+t);\n                StringWriter sw = new StringWriter();\n                t.printStackTrace(new PrintWriter(sw));\n                try {\n\t\t\t\t\tout.write(sw.toString().getBytes());\n\t\t\t\t} catch (IOException e) {\n\t            \tLogger.error(this, \"Socket error: \"+e, e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n            }\n        }\n    }","id":36167,"modified_method":"public void realRun() throws IOException {\n\t\tprintHeader(out);\n\n\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(in));\n        while(true) {\n            try {\n                if(processLine(reader,out)) {\n                \treader.close();\n                \treturn;\n                }\n            } catch (SocketException e) {\n            \tLogger.error(this, \"Socket error: \"+e, e);\n            \treturn;\n            } catch (Throwable t) {\n                Logger.error(this, \"Caught \"+t, t);\n                System.out.println(\"Caught: \"+t);\n                StringWriter sw = new StringWriter();\n                t.printStackTrace(new PrintWriter(sw));\n                try {\n\t\t\t\t\tout.write(sw.toString().getBytes());\n\t\t\t\t} catch (IOException e) {\n\t            \tLogger.error(this, \"Socket error: \"+e, e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n            }\n        }\n    }","commit_id":"8fb84ecb4f999d46d9f08a051b57d64c234b5ce4","url":"https://github.com/freenet/fred"},{"original_method":"private static Reader createInputStreamReader(final @NotNull InputStream streamToRead, @Nullable Charset charset) {\n    if (charset == null) {\n      return new BaseInputStreamReader(streamToRead);\n    }\n    else {\n      return new BaseInputStreamReader(streamToRead, charset);\n    }\n  }","id":36168,"modified_method":"private static Reader createInputStreamReader(@NotNull InputStream stream, @Nullable Charset charset) {\n    return charset == null ? new BaseInputStreamReader(stream) : new BaseInputStreamReader(stream, charset);\n  }","commit_id":"36e95f77f7fdffcaaded41cf0af79edbc3658fb2","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * Reads as much data as possible without blocking.\n   * Relies on InputStream.ready method.\n   * In case of doubts look at #readAvailableBlocking\n   *\n   * @return true if non-zero amount of data has been read\n   * @throws IOException If an I/O error occurs\n   */\n  protected final boolean readAvailableNonBlocking() throws IOException {\n    char[] buffer = myBuffer;\n    StringBuilder token = myTextBuffer;\n    token.setLength(0);\n\n    boolean read = false;\n    while (myReader.ready()) {\n      int n = myReader.read(buffer);\n      if (n <= 0) break;\n      read = true;\n\n      processLine(buffer, token, n);\n    }\n\n    submitToken();\n\n    return read;\n  }","id":36169,"modified_method":"/**\n   * Reads as much data as possible without blocking.\n   * Relies on InputStream.ready method.\n   * In case of doubts look at #readAvailableBlocking\n   *\n   * @return true if non-zero amount of data has been read\n   * @throws IOException If an I/O error occurs\n   */\n  protected final boolean readAvailableNonBlocking() throws IOException {\n    char[] buffer = new char[8192];\n    StringBuilder line = new StringBuilder();\n    boolean read = false;\n\n    int n;\n    while (myReader.ready() && (n = myReader.read(buffer)) > 0) {\n      read = true;\n      processLine(buffer, line, n);\n    }\n\n    if (line.length() > 0) {\n      onTextAvailable(line.toString());\n    }\n\n    return read;\n  }","commit_id":"36e95f77f7fdffcaaded41cf0af79edbc3658fb2","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * Reads data with blocking.\n   * Should be used in case when ready method always returns false for your input stream.\n   * Should be used if we want to to make our reader exit when end of stream reached.\n   * Could be used if we prefer IO-blocking over CPU sleeping.\n   *\n   * @return true if non-zero amount of data has been read, false if end of the stream is reached\n   * @throws IOException If an I/O error occurs\n   */\n  protected final boolean readAvailableBlocking() throws IOException {\n    char[] buffer = myBuffer;\n    StringBuilder token = myTextBuffer;\n    token.setLength(0);\n\n    boolean read = false;\n    int n;\n    while ((n = myReader.read(buffer)) > 0) {\n      if (myScheduledSubmitter != null) myScheduledSubmitter.cancel(true);\n\n      read = true;\n\n      synchronized (myTextBuffer) {\n        processLine(buffer, token, n);\n      }\n\n      myScheduledSubmitter = myExecutorService.submit(myTokenSubmitter);\n    }\n\n    submitToken();\n\n    return read;\n  }","id":36170,"modified_method":"/**\n   * Reads data with blocking.\n   * Should be used in case when ready method always returns false for your input stream.\n   * Should be used if we want to to make our reader exit when end of stream reached.\n   * Could be used if we prefer IO-blocking over CPU sleeping.\n   *\n   * @return true if non-zero amount of data has been read, false if end of the stream is reached\n   * @throws IOException If an I/O error occurs\n   */\n  protected final boolean readAvailableBlocking() throws IOException {\n    char[] buffer = new char[8192];\n    StringBuilder line = new StringBuilder();\n    boolean read = false;\n\n    int n;\n    while ((n = myReader.read(buffer)) > 0) {\n      read = true;\n      processLine(buffer, line, n);\n    }\n\n    if (line.length() > 0) {\n      onTextAvailable(line.toString());\n    }\n\n    return read;\n  }","commit_id":"36e95f77f7fdffcaaded41cf0af79edbc3658fb2","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void processLine(char[] buffer, StringBuilder token, int n) {\n    for (int i = 0; i < n; i++) {\n      char c = buffer[i];\n      if (skipLF && c != '\\n') {\n        token.append('\\r');\n      }\n\n      if (c == '\\r') {\n        skipLF = true;\n      }\n      else {\n        skipLF = false;\n        token.append(c);\n      }\n\n      if (c == '\\n') {\n        onTextAvailable(token.toString());\n        token.setLength(0);\n      }\n    }\n  }","id":36171,"modified_method":"protected final void processLine(char[] buffer, StringBuilder line, int n) {\n    for (int i = 0; i < n; i++) {\n      char c = buffer[i];\n\n      if (c == '\\n' && line.length() > 0 && line.charAt(line.length() - 1) == '\\r') {\n        line.setCharAt(line.length() - 1, '\\n');\n      }\n      else {\n        line.append(c);\n      }\n\n      if (c == '\\n') {\n        onTextAvailable(line.toString());\n        line.setLength(0);\n      }\n    }\n  }","commit_id":"36e95f77f7fdffcaaded41cf0af79edbc3658fb2","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public BaseOutputReader(@NotNull Reader reader, SleepingPolicy sleepingPolicy) {\n    super(sleepingPolicy);\n    if (sleepingPolicy == SleepingPolicy.BLOCKING) {\n      if (!(reader instanceof BaseInputStreamReader)) {\n        throw new IllegalArgumentException(\"Blocking policy can be used only with BaseInputStreamReader, that doesn't lock on close\");\n      }\n      myExecutorService = Executors.newSingleThreadExecutor(ConcurrencyUtil.newNamedThreadFactory(\"Base output reader\"));\n      myTokenSubmitter = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            Thread.sleep(DELAY_AFTER_BLOCKING_READ);\n            submitToken();\n          }\n          catch (InterruptedException ignore) { }\n        }\n      };\n    }\n    myReader = reader;\n  }","id":36172,"modified_method":"public BaseOutputReader(@NotNull Reader reader, SleepingPolicy sleepingPolicy) {\n    super(sleepingPolicy);\n    if (sleepingPolicy == SleepingPolicy.BLOCKING && !(reader instanceof BaseInputStreamReader)) {\n      throw new IllegalArgumentException(\"Blocking policy can be used only with BaseInputStreamReader, that doesn't lock on close\");\n    }\n    myReader = reader;\n  }","commit_id":"36e95f77f7fdffcaaded41cf0af79edbc3658fb2","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void main(String[] args) throws Exception {\n        Security.addProvider(new JBossSaslProvider());\n\n        String argError = null;\n        String[] commands = null;\n        File file = null;\n        boolean connect = false;\n        String defaultControllerHost = null;\n        int defaultControllerPort = -1;\n        boolean version = false;\n        for(String arg : args) {\n            if(arg.startsWith(\"controller=\") || arg.startsWith(\"--controller=\")) {\n                final String value;\n                if(arg.startsWith(\"--\")) {\n                    value = arg.substring(13);\n                } else {\n                    value = arg.substring(11);\n                }\n                String portStr = null;\n                int colonIndex = value.indexOf(':');\n                if(colonIndex < 0) {\n                    // default port\n                    defaultControllerHost = value;\n                } else if(colonIndex == 0) {\n                    // default host\n                    portStr = value.substring(1);\n                } else {\n                    defaultControllerHost = value.substring(0, colonIndex);\n                    portStr = value.substring(colonIndex + 1);\n                }\n\n                if(portStr != null) {\n                    int port = -1;\n                    try {\n                        port = Integer.parseInt(portStr);\n                        if(port < 0) {\n                            argError = \"The port must be a valid non-negative integer: '\" + args + \"'\";\n                        } else {\n                            defaultControllerPort = port;\n                        }\n                    } catch(NumberFormatException e) {\n                        argError = \"The port must be a valid non-negative integer: '\" + arg + \"'\";\n                    }\n                }\n            } else if(\"--connect\".equals(arg) || \"-c\".equals(arg)) {\n                connect = true;\n            } else if(\"--version\".equals(arg)) {\n                version = true;\n            } else if(arg.startsWith(\"file=\") || arg.startsWith(\"--file=\")) {\n                if(file != null) {\n                    argError = \"Duplicate argument 'file'.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n\n                final String fileName = arg.startsWith(\"--\") ? arg.substring(7) : arg.substring(5);\n                if(!fileName.isEmpty()) {\n                    file = new File(fileName);\n                    if(!file.exists()) {\n                        argError = \"File \" + file.getAbsolutePath() + \" doesn't exist.\";\n                        break;\n                    }\n                } else {\n                    argError = \"Argument 'file' is missing value.\";\n                    break;\n                }\n            } else if(arg.startsWith(\"commands=\") || arg.startsWith(\"--commands=\")) {\n                if(file != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Duplicate argument 'command'/'commands'.\";\n                    break;\n                }\n                final String value = arg.startsWith(\"--\") ? arg.substring(11) : arg.substring(9);\n                commands = value.split(\",+\");\n            } else if(arg.startsWith(\"command=\") || arg.startsWith(\"--command=\")) {\n                if(file != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Duplicate argument 'command'/'commands'.\";\n                    break;\n                }\n                final String value = arg.startsWith(\"--\") ? arg.substring(10) : arg.substring(8);\n                commands = new String[]{value};\n            }\n        }\n\n        if(argError != null) {\n            System.err.println(argError);\n            return;\n        }\n\n        if(version) {\n            final CommandContextImpl cmdCtx = new CommandContextImpl();\n            VersionHandler.INSTANCE.handle(cmdCtx);\n            return;\n        }\n\n        if(file != null) {\n            processFile(file, defaultControllerHost, defaultControllerPort, connect);\n            return;\n        }\n\n        if(commands != null) {\n            processCommands(commands, defaultControllerHost, defaultControllerPort, connect);\n            return;\n        }\n\n        // Interactive mode\n\n        final jline.ConsoleReader console = initConsoleReader();\n        final CommandContextImpl cmdCtx = new CommandContextImpl(console);\n        SecurityActions.addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                cmdCtx.disconnectController();\n            }\n        }));\n        console.addCompletor(cmdCtx.cmdCompleter);\n\n        if(defaultControllerHost != null) {\n            cmdCtx.defaultControllerHost = defaultControllerHost;\n        }\n        if(defaultControllerPort != -1) {\n            cmdCtx.defaultControllerPort = defaultControllerPort;\n        }\n\n        if(connect) {\n            cmdCtx.connectController(null, -1);\n        } else {\n            cmdCtx.printLine(\"You are disconnected at the moment.\" +\n                \" Type 'connect' to connect to the server or\" +\n                \" 'help' for the list of supported commands.\");\n        }\n\n        try {\n            while (!cmdCtx.terminate) {\n                String line = console.readLine(cmdCtx.getPrompt());\n                line = line != null ? line.trim() : \"\";\n                processLine(cmdCtx, line);\n            }\n        } finally {\n            cmdCtx.disconnectController();\n        }\n        System.exit(0);\n    }","id":36173,"modified_method":"public static void main(String[] args) throws Exception {\n        Security.addProvider(new JBossSaslProvider());\n\n        String argError = null;\n        String[] commands = null;\n        File file = null;\n        boolean connect = false;\n        String defaultControllerHost = null;\n        int defaultControllerPort = -1;\n        boolean version = false;\n        for(String arg : args) {\n            if(arg.startsWith(\"controller=\") || arg.startsWith(\"--controller=\")) {\n                final String value;\n                if(arg.startsWith(\"--\")) {\n                    value = arg.substring(13);\n                } else {\n                    value = arg.substring(11);\n                }\n                String portStr = null;\n                int colonIndex = value.indexOf(':');\n                if(colonIndex < 0) {\n                    // default port\n                    defaultControllerHost = value;\n                } else if(colonIndex == 0) {\n                    // default host\n                    portStr = value.substring(1);\n                } else {\n                    defaultControllerHost = value.substring(0, colonIndex);\n                    portStr = value.substring(colonIndex + 1);\n                }\n\n                if(portStr != null) {\n                    int port = -1;\n                    try {\n                        port = Integer.parseInt(portStr);\n                        if(port < 0) {\n                            argError = \"The port must be a valid non-negative integer: '\" + args + \"'\";\n                        } else {\n                            defaultControllerPort = port;\n                        }\n                    } catch(NumberFormatException e) {\n                        argError = \"The port must be a valid non-negative integer: '\" + arg + \"'\";\n                    }\n                }\n            } else if(\"--connect\".equals(arg) || \"-c\".equals(arg)) {\n                connect = true;\n            } else if(\"--version\".equals(arg)) {\n                version = true;\n            } else if(arg.startsWith(\"file=\") || arg.startsWith(\"--file=\")) {\n                if(file != null) {\n                    argError = \"Duplicate argument 'file'.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n\n                final String fileName = arg.startsWith(\"--\") ? arg.substring(7) : arg.substring(5);\n                if(!fileName.isEmpty()) {\n                    file = new File(fileName);\n                    if(!file.exists()) {\n                        argError = \"File \" + file.getAbsolutePath() + \" doesn't exist.\";\n                        break;\n                    }\n                } else {\n                    argError = \"Argument 'file' is missing value.\";\n                    break;\n                }\n            } else if(arg.startsWith(\"commands=\") || arg.startsWith(\"--commands=\")) {\n                if(file != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Duplicate argument 'command'/'commands'.\";\n                    break;\n                }\n                final String value = arg.startsWith(\"--\") ? arg.substring(11) : arg.substring(9);\n                commands = value.split(\",+\");\n            } else if(arg.startsWith(\"command=\") || arg.startsWith(\"--command=\")) {\n                if(file != null) {\n                    argError = \"Only one of 'file', 'commands' or 'command' can appear as the argument at a time.\";\n                    break;\n                }\n                if(commands != null) {\n                    argError = \"Duplicate argument 'command'/'commands'.\";\n                    break;\n                }\n                final String value = arg.startsWith(\"--\") ? arg.substring(10) : arg.substring(8);\n                commands = new String[]{value};\n            }\n        }\n\n        if(argError != null) {\n            System.err.println(argError);\n            return;\n        }\n\n        if(version) {\n            final CommandContextImpl cmdCtx = new CommandContextImpl();\n            VersionHandler.INSTANCE.handle(cmdCtx);\n            return;\n        }\n\n        if(file != null) {\n            processFile(file, defaultControllerHost, defaultControllerPort, connect);\n            return;\n        }\n\n        if(commands != null) {\n            processCommands(commands, defaultControllerHost, defaultControllerPort, connect);\n            return;\n        }\n\n        // Interactive mode\n\n        final jline.ConsoleReader console = initConsoleReader();\n        final CommandContextImpl cmdCtx = new CommandContextImpl(console);\n        SecurityActions.addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                cmdCtx.disconnectController();\n            }\n        }));\n        console.addCompletor(cmdCtx.cmdCompleter);\n\n        if(defaultControllerHost != null) {\n            cmdCtx.defaultControllerHost = defaultControllerHost;\n        }\n        if(defaultControllerPort != -1) {\n            cmdCtx.defaultControllerPort = defaultControllerPort;\n        }\n\n        if(connect) {\n            cmdCtx.connectController(null, -1);\n        } else {\n            cmdCtx.printLine(\"You are disconnected at the moment.\" +\n                \" Type 'connect' to connect to the server or\" +\n                \" 'help' for the list of supported commands.\");\n        }\n\n        try {\n            while (!cmdCtx.terminate) {\n                final String line = console.readLine(cmdCtx.getPrompt());\n                if(line == null) {\n                    cmdCtx.terminateSession();\n                } else {\n                    processLine(cmdCtx, line.trim());\n                }\n            }\n        } finally {\n            cmdCtx.disconnectController();\n        }\n        System.exit(0);\n    }","commit_id":"59d9902d6d063fbf867909cf5295b74abdb859bc","url":"https://github.com/wildfly/wildfly"},{"original_method":"public CouchbaseNoSqlAdapter(CouchbaseClient couchbaseClient, String cacheKeyPrefix) {\n        this.couchbaseClient = couchbaseClient;\n        this.cacheKeyPrefix = cacheKeyPrefix;\n        \n        // make sure primary index and index on parentPath is present - ignore error if it is already present\n        Index.createPrimaryIndex().on(couchbaseClient.getBucketName());\n        Index.createIndex(PN_PARENT_PATH).on(couchbaseClient.getBucketName(), x(PN_PARENT_PATH));\n    }","id":36174,"modified_method":"public CouchbaseNoSqlAdapter(CouchbaseClient couchbaseClient, String cacheKeyPrefix) {\n        this.couchbaseClient = couchbaseClient;\n        this.cacheKeyPrefix = cacheKeyPrefix;\n        \n        // make sure primary index and index on parentPath is present - ignore error if it is already present\n        Bucket bucket = couchbaseClient.getBucket();\n        bucket.query(N1qlQuery.simple(\"CREATE PRIMARY INDEX ON `\" + couchbaseClient.getBucketName() + \"`\"));\n        bucket.query(N1qlQuery.simple(\"CREATE INDEX \" + PN_PARENT_PATH + \" ON `\" + couchbaseClient.getBucketName() + \"`(\" + PN_PARENT_PATH + \")\"));\n    }","commit_id":"0dcff21038793d990b547cef77ef6ad1e426ec39","url":"https://github.com/apache/sling"},{"original_method":"@Test\n  public void testS3ObjectEventCreation() {\n    final S3ObjectEvent putEvent = S3ObjectEvent.with(\n        S3ObjectEvent.forS3ObjectCreate(),\n        \"bucket1\",\n        \"object1\",\n        null,\n        Principals.systemFullName(),\n        12L\n    );\n\n    assertEquals(\"action\", S3ObjectEvent.S3ObjectAction.OBJECTCREATE, putEvent.getAction());\n    assertEquals(\"bucket name\", \"bucket1\", putEvent.getBucketName());\n    assertEquals(\"object key\", \"object1\", putEvent.getObjectKey());\n    assertNull(\"version\", putEvent.getVersion());\n    assertEquals(\"owner\", Principals.systemFullName(), putEvent.getOwner());\n    assertEquals(\"size\", (Long) 12L, putEvent.getSize());\n    assertEquals(\"get event string\", \"S3ObjectEvent [action=OBJECTCREATE, ownerFullName=arn:aws:euare::000000000000:user/eucalyptus, size=12, bucketName=bucket1, objectKey=object1, version=null]\", putEvent.toString());\n\n    final S3ObjectEvent deleteEvent = S3ObjectEvent.with(\n        S3ObjectEvent.forS3ObjectDelete(),\n        \"bucket1\",\n        \"object1\",\n        \"version1\",\n        Principals.systemFullName(),\n        12L\n    );\n\n    assertEquals(\"action\", S3ObjectEvent.S3ObjectAction.OBJECTDELETE, deleteEvent.getAction());\n    assertEquals(\"bucket name\", \"bucket1\", deleteEvent.getBucketName());\n    assertEquals(\"version\", \"version1\", deleteEvent.getVersion());\n    assertEquals(\"owner\", Principals.systemFullName(), deleteEvent.getOwner());\n    assertEquals(\"size\", (Long) 12L, deleteEvent.getSize());\n    assertEquals(\"get event string\", \"S3ObjectEvent [action=OBJECTDELETE, ownerFullName=arn:aws:euare::000000000000:user/eucalyptus, size=12, bucketName=bucket1, objectKey=object1, version=version1]\", deleteEvent.toString());\n  }","id":36175,"modified_method":"@Test\n  public void testS3ObjectEventCreation() {\n    final S3ObjectEvent putEvent = S3ObjectEvent.with(\n        S3ObjectEvent.forS3ObjectCreate(),\n        \"bucket1\",\n        \"object1\",\n        null,\n        Principals.systemFullName().getUserId(),\n        12L\n    );\n\n    assertEquals(\"action\", S3ObjectEvent.S3ObjectAction.OBJECTCREATE, putEvent.getAction());\n    assertEquals(\"bucket name\", \"bucket1\", putEvent.getBucketName());\n    assertEquals(\"object key\", \"object1\", putEvent.getObjectKey());\n    assertNull(\"version\", putEvent.getVersion());\n    assertEquals(\"owner\", Principals.systemFullName().getUserId(), putEvent.getOwnerUserId());\n    assertEquals(\"size\", (Long) 12L, putEvent.getSize());\n    assertEquals(\"get event string\", \"S3ObjectEvent [action=OBJECTCREATE, ownerFullName=arn:aws:euare::000000000000:user/eucalyptus, size=12, bucketName=bucket1, objectKey=object1, version=null]\", putEvent.toString());\n\n    final S3ObjectEvent deleteEvent = S3ObjectEvent.with(\n        S3ObjectEvent.forS3ObjectDelete(),\n        \"bucket1\",\n        \"object1\",\n        \"version1\",\n        Principals.systemFullName().getUserId(),\n        12L\n    );\n\n    assertEquals(\"action\", S3ObjectEvent.S3ObjectAction.OBJECTDELETE, deleteEvent.getAction());\n    assertEquals(\"bucket name\", \"bucket1\", deleteEvent.getBucketName());\n    assertEquals(\"version\", \"version1\", deleteEvent.getVersion());\n    assertEquals(\"owner\", Principals.systemFullName().getUserId(), deleteEvent.getOwnerUserId());\n    assertEquals(\"size\", (Long) 12L, deleteEvent.getSize());\n    assertEquals(\"get event string\", \"S3ObjectEvent [action=OBJECTDELETE, ownerFullName=arn:aws:euare::000000000000:user/eucalyptus, size=12, bucketName=bucket1, objectKey=object1, version=version1]\", deleteEvent.toString());\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Nonnull\n  public OwnerFullName getOwner() {\n    return ownerFullName;\n  }","id":36176,"modified_method":"@Nonnull\n  public String getOwnerUserId() {\n    return ownerUserId;\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"S3EventSupport( @Nonnull final E action,\n                  @Nonnull final String bucketName,\n                  @Nonnull final OwnerFullName ownerFullName,\n                  @Nonnull final Long size ) {\n    assertThat(action, notNullValue());\n    assertThat(bucketName, not(isEmptyOrNullString()));\n    assertThat(ownerFullName, notNullValue());\n    assertThat(ownerFullName.getUserId(), not(isEmptyOrNullString()));\n    assertThat(size, notNullValue());\n\n    this.action = action;\n    this.ownerFullName = ownerFullName;\n    this.size = size;\n    this.bucketName = bucketName;\n  }","id":36177,"modified_method":"S3EventSupport( @Nonnull final E action,\n                  @Nonnull final String bucketName,\n                  @Nonnull final String ownerUserId,\n                  @Nonnull final Long size ) {\n    assertThat(action, notNullValue());\n    assertThat(bucketName, not(isEmptyOrNullString()));\n    assertThat(ownerUserId, not(isEmptyOrNullString()));\n    assertThat(size, notNullValue());\n\n    this.action = action;\n    this.ownerUserId = ownerUserId;\n    this.size = size;\n    this.bucketName = bucketName;\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public String toString() {\n    return \"S3ObjectEvent [action=\" + getAction()\n        + \", ownerFullName=\" + getOwner()\n        + \", size=\" + getSize() + \", bucketName=\" + getBucketName()\n        + \", objectKey=\" + getObjectKey() + \", version=\" + getVersion() + \"]\";\n  }","id":36178,"modified_method":"@Override\n  public String toString() {\n    return \"S3ObjectEvent [action=\" + getAction()\n        + \", ownerUserId=\" + getOwnerUserId()\n        + \", size=\" + getSize() + \", bucketName=\" + getBucketName()\n        + \", objectKey=\" + getObjectKey() + \", version=\" + getVersion() + \"]\";\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"S3ObjectEvent( @Nonnull  final S3ObjectAction action,\n                 @Nonnull  final String bucketName,\n                 @Nonnull  final String objectKey,\n                 @Nullable final String version,\n                 @Nonnull  final OwnerFullName ownerFullName,\n                 @Nonnull  final Long size ) {\n    super( action, bucketName, ownerFullName, size );\n    assertThat(objectKey, not( isEmptyOrNullString() ));\n    this.objectKey = objectKey;\n    this.version = version;\n  }","id":36179,"modified_method":"S3ObjectEvent( @Nonnull  final S3ObjectAction action,\n                 @Nonnull  final String bucketName,\n                 @Nonnull  final String objectKey,\n                 @Nullable final String version,\n                 @Nonnull  final String ownerUserId,\n                 @Nonnull  final Long size ) {\n    super( action, bucketName, ownerUserId, size );\n    assertThat(objectKey, not( isEmptyOrNullString() ));\n    this.objectKey = objectKey;\n    this.version = version;\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"/**\n   * @see #forS3ObjectCreate\n   * @see #forS3ObjectDelete\n   */\n  public static S3ObjectEvent with( @Nonnull  final S3ObjectAction action,\n                                    @Nonnull  final String bucketName,\n                                    @Nonnull  final String objectKey,\n                                    @Nullable final String version,\n                                    @Nonnull  final OwnerFullName ownerFullName,\n                                    @Nonnull  final Long size ) {\n\n    return new S3ObjectEvent( action, bucketName, objectKey, version, ownerFullName, size );\n  }","id":36180,"modified_method":"/**\n   * @see #forS3ObjectCreate\n   * @see #forS3ObjectDelete\n   */\n  public static S3ObjectEvent with( @Nonnull  final S3ObjectAction action,\n                                    @Nonnull  final String bucketName,\n                                    @Nonnull  final String objectKey,\n                                    @Nullable final String version,\n                                    @Nonnull  final String ownerUserId,\n                                    @Nonnull  final Long size ) {\n\n    return new S3ObjectEvent( action, bucketName, objectKey, version, ownerUserId, size );\n  }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n    public void fireEvent( @Nonnull final S3ObjectEvent event ) {\n      Preconditions.checkNotNull(event, \"Event is required\");\n\n      final long timeInMs = getCurrentTimeMillis();\n\n      try {\n        final User user = lookupUser( event.getOwner().getUserId() );\n\n        getReportingAccountCrud().createOrUpdateAccount(user.getAccount()\n            .getName(), user.getAccount().getAccountNumber());\n        getReportingUserCrud().createOrUpdateUser(user.getUserId(), user\n            .getAccount().getAccountNumber(), user.getName());\n\n        final ReportingS3ObjectEventStore eventStore = getReportingS3ObjectEventStore();\n        switch (event.getAction()) {\n          case OBJECTCREATE:\n            eventStore.insertS3ObjectCreateEvent(event.getBucketName(), event.getObjectKey(), event.getVersion(), event.getSize(), timeInMs, event.getOwner().getUserId());\n            break;\n          case OBJECTDELETE:\n            eventStore.insertS3ObjectDeleteEvent(event.getBucketName(), event.getObjectKey(), event.getVersion(), timeInMs);\n            break;\n        }\n      } catch (AuthException e) {\n          LOG.error(\"Unable fire s3 object reporting event\", e.getCause());\n      }\n    }","id":36181,"modified_method":"@Override\n    public void fireEvent( @Nonnull final S3ObjectEvent event ) {\n      Preconditions.checkNotNull(event, \"Event is required\");\n\n      final long timeInMs = getCurrentTimeMillis();\n\n      try {\n        final User user = lookupUser( event.getOwnerUserId() );\n\n        getReportingAccountCrud().createOrUpdateAccount(user.getAccount()\n            .getName(), user.getAccount().getAccountNumber());\n        getReportingUserCrud().createOrUpdateUser(user.getUserId(), user\n            .getAccount().getAccountNumber(), user.getName());\n\n        final ReportingS3ObjectEventStore eventStore = getReportingS3ObjectEventStore();\n        switch (event.getAction()) {\n          case OBJECTCREATE:\n            eventStore.insertS3ObjectCreateEvent(event.getBucketName(), event.getObjectKey(), event.getVersion(), event.getSize(), timeInMs, event.getOwnerUserId());\n            break;\n          case OBJECTDELETE:\n            eventStore.insertS3ObjectDeleteEvent(event.getBucketName(), event.getObjectKey(), event.getVersion(), timeInMs);\n            break;\n        }\n      } catch (AuthException e) {\n          LOG.error(\"Unable fire s3 object reporting event\", e.getCause());\n      }\n    }","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public ObjectDeleter(String bucketName, String objectName, Long size, String user, String userId, String account, String accountNumber) {\n\t\t\tthis.bucketName = bucketName;\n\t\t\tthis.objectName = objectName;\n\t\t\tthis.size = size;\n\t\t\tthis.user = user;\n\t\t\tthis.userId = userId;\n\t\t\tthis.account = account;\n\t\t\tthis.accountNumber = accountNumber;\n\t\t}","id":36182,"modified_method":"public ObjectDeleter(String bucketName, String objectName, String objectKey, String version,\n\t\t    Long size, String user, String userId, String account, String accountNumber) {\n\t\t\tthis.bucketName = bucketName;\n\t\t\tthis.objectName = objectName;\n\t\t\tthis.objectKey = objectKey;\n\t\t\tthis.version = version;\n\t\t\tthis.size = size;\n\t\t\tthis.user = user;\n\t\t\tthis.userId = userId;\n\t\t\tthis.account = account;\n\t\t\tthis.accountNumber = accountNumber;\n\t\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public DeleteVersionResponseType deleteVersion(DeleteVersionType request) throws EucalyptusCloudException {\n\t\tDeleteVersionResponseType reply = (DeleteVersionResponseType) request.getReply();\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfos = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfos);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucketInfo = bucketList.get(0);\n\t\t\tBucketLogData logData = bucketInfo.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tObjectInfo foundObject = null;\n\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\n\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\tif(request.getVersionid() == null) {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new EucalyptusCloudException(\"versionId is null\");\n\t\t\t}\n\t\t\tsearchObjectInfo.setVersionId(request.getVersionid());\n\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\tif (objectInfos.size() > 0) {\n\t\t\t\tfoundObject = objectInfos.get(0);\n\t\t\t}\n\n\t\t\t/* The admin can always delete object versions, and if versioning is suspended then only the bucket owner can delete a specific\n\t\t\t * version. If bucket versioning is enabled then do the normal permissions check to grant permissions.\n\t\t\t */\n\t\t\tif (foundObject != null) {\n\t\t\t\tif (ctx.hasAdministrativePrivileges() \n\t\t\t\t\t\t|| ( (bucketInfo.isVersioningSuspended() && bucketInfo.getOwnerId().equals(ctx.getUser().getUserId())) \n\t\t\t\t\t\t\t\t|| (bucketInfo.isVersioningEnabled() &&\n\t\t\t\t\t\t\t\t\t\tLookups.checkPrivilege(PolicySpec.S3_DELETEOBJECTVERSION,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.objectFullName(bucketName, objectKey),\n\t\t\t\t\t\t\t\t\t\t\t\tfoundObject.getOwnerId())) ) ) {\n\n\t\t\t\t\tdbObject.delete(foundObject);\n\t\t\t\t\tif(!foundObject.getDeleted()) {\n\t\t\t\t\t\tString objectName = foundObject.getObjectName();\t\t\t\t\t\t\t \n\t\t\t\t\t\tfor (GrantInfo grantInfo : foundObject.getGrants()) {\n\t\t\t\t\t\t\tdb.delete(grantInfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tLong size = foundObject.getSize();\n\n\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdecrementBucketSize(bucketName, size);\n\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\n\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\tobjectName, \n\t\t\t\t\t\t\t\tsize, \n\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t}\n\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\tupdateLogData(bucketInfo, logData);\n\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tdb.rollback();\n\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey, logData);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\tdb.commit();\n\t\treturn reply;\n\t}","id":36183,"modified_method":"public DeleteVersionResponseType deleteVersion(DeleteVersionType request) throws EucalyptusCloudException {\n\t\tDeleteVersionResponseType reply = (DeleteVersionResponseType) request.getReply();\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfos = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfos);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucketInfo = bucketList.get(0);\n\t\t\tBucketLogData logData = bucketInfo.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tObjectInfo foundObject = null;\n\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\n\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\tif(request.getVersionid() == null) {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new EucalyptusCloudException(\"versionId is null\");\n\t\t\t}\n\t\t\tsearchObjectInfo.setVersionId(request.getVersionid());\n\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\tif (objectInfos.size() > 0) {\n\t\t\t\tfoundObject = objectInfos.get(0);\n\t\t\t}\n\n\t\t\t/* The admin can always delete object versions, and if versioning is suspended then only the bucket owner can delete a specific\n\t\t\t * version. If bucket versioning is enabled then do the normal permissions check to grant permissions.\n\t\t\t */\n\t\t\tif (foundObject != null) {\n\t\t\t\tif (ctx.hasAdministrativePrivileges() \n\t\t\t\t\t\t|| ( (bucketInfo.isVersioningSuspended() && bucketInfo.getOwnerId().equals(ctx.getUser().getUserId())) \n\t\t\t\t\t\t\t\t|| (bucketInfo.isVersioningEnabled() &&\n\t\t\t\t\t\t\t\t\t\tLookups.checkPrivilege(PolicySpec.S3_DELETEOBJECTVERSION,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\t\t\t\tPolicySpec.objectFullName(bucketName, objectKey),\n\t\t\t\t\t\t\t\t\t\t\t\tfoundObject.getOwnerId())) ) ) {\n\n\t\t\t\t\tdbObject.delete(foundObject);\n\t\t\t\t\tif(!foundObject.getDeleted()) {\n\t\t\t\t\t\tString objectName = foundObject.getObjectName();\t\t\t\t\t\t\t \n\t\t\t\t\t\tfor (GrantInfo grantInfo : foundObject.getGrants()) {\n\t\t\t\t\t\t\tdb.delete(grantInfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tLong size = foundObject.getSize();\n\n\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdecrementBucketSize(bucketName, size);\n\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\n\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\tobjectName,\n\t\t\t\t\t\t\t\tfoundObject.getObjectKey(),\n\t\t\t\t\t\t\t\tfoundObject.getVersionId(),\n\t\t\t\t\t\t\t\tsize, \n\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t}\n\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\tupdateLogData(bucketInfo, logData);\n\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tdb.rollback();\n\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey, logData);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\tdb.commit();\n\t\treturn reply;\n\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public DeleteObjectResponseType deleteObject(DeleteObjectType request)\n\t\t\tthrows EucalyptusCloudException {\n\t\tDeleteObjectResponseType reply = (DeleteObjectResponseType) request.getReply();\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfos = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfos);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucketInfo = bucketList.get(0);\n\t\t\tBucketLogData logData = bucketInfo.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucketInfo.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucketInfo.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_DELETEOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketInfo.getBucketName(),\n\t\t\t\t\t\t\tnull)))) {\n\n\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\t\t\t\t\n\n\t\t\t\tif(bucketInfo.isVersioningEnabled()) {\n\t\t\t\t\t//Versioning is enabled, so place delete marker.\t\t\t\t\t\n\t\t\t\t\tObjectInfo searchDeletedObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tsearchDeletedObjectInfo.setDeleted(true);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdbObject.getUniqueEscape(searchDeletedObjectInfo);\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t//Delete marker already exists, can't double delete\n\t\t\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t\t\t} catch(NoSuchEntityException ex) {\n\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t} catch(EucalyptusCloudException ex) {\n\t\t\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tsearchObjectInfo.setLast(true);\n\t\t\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\t\t\t\tfor(ObjectInfo objInfo : objectInfos) {\n\t\t\t\t\t\t\tobjInfo.setLast(false);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t//Add the delete marker\n\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\tdeleteMarker.setLast(true);\n\t\t\t\t\t\tdeleteMarker.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\tdeleteMarker.setLastModified(new Date());\n\t\t\t\t\t\tdeleteMarker.setVersionId(UUID.randomUUID().toString().replaceAll(\"-\", \"\"));\n\t\t\t\t\t\tdbObject.add(deleteMarker);\n\n\t\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\t}\n\t\t\t\t} else {\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t/* Versioning disabled or suspended.\n\t\t\t\t\t * \n\t\t\t\t\t * Only delete 'null' versioned objects. If versioning is suspended then insert a delete marker.\n\t\t\t\t\t * If versioning is suspended and no 'null' version object exists then simply insert a delete marker\n\t\t\t\t\t */\n\t\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t//searchObjectInfo.setVersionId(WalrusProperties.NULL_VERSION_ID);\n\t\t\t\t\tsearchObjectInfo.setLast(true);\n\t\t\t\t\tsearchObjectInfo.setDeleted(false);\n\t\t\t\t\tList<ObjectInfo>objectInfos = dbObject.queryEscape(searchObjectInfo);\n\n\t\t\t\t\tif (objectInfos.size() > 0) {\n\t\t\t\t\t\tif(objectInfos.size() > 1) {\n\t\t\t\t\t\t\t//This shouldn't happen, so bail if it does\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"More than one object set to 'last' found\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tObjectInfo lastObject = objectInfos.get(0);\n\t\t\t\t\t\tif(lastObject.getVersionId().equals(WalrusProperties.NULL_VERSION_ID)) {\t\t\t\t\t\t\n\t\t\t\t\t\t\t//Remove the 'null' versioned object\n\t\t\t\t\t\t\tObjectInfo nullObject = lastObject;\n\t\t\t\t\t\t\tdbObject.delete(nullObject);\n\t\t\t\t\t\t\tString objectName = nullObject.getObjectName();\n\t\t\t\t\t\t\tfor (GrantInfo grantInfo : nullObject.getGrants()) {\n\t\t\t\t\t\t\t\tdb.delete(grantInfo);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tLong size = nullObject.getSize();\n\t\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tdecrementBucketSize(bucketName, size);\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName, \n\t\t\t\t\t\t\t\t\tobjectName, \n\t\t\t\t\t\t\t\t\tsize, \n\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tif(bucketInfo.isVersioningSuspended()) {\n\t\t\t\t\t\t\t\t//Some version found, don't delete it, just make it not last.\n\t\t\t\t\t\t\t\t//This is possible when versiong was suspended and no object uploaded since then\n\t\t\t\t\t\t\t\tlastObject.setLast(false);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"Non 'null' versioned object found in a versioning disabled bucket, not sure how to proceed with delete.\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\tupdateLogData(bucketInfo, logData);\n\t\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif(bucketInfo.isVersioningSuspended()) {\n\t\t\t\t\t\t\t//Add the delete marker\n\t\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\t\tdeleteMarker.setLast(true);\n\t\t\t\t\t\t\tdeleteMarker.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\t\tdeleteMarker.setLastModified(new Date());\n\t\t\t\t\t\t\tdeleteMarker.setVersionId(UUID.randomUUID().toString().replaceAll(\"-\", \"\"));\n\t\t\t\t\t\t\tdbObject.add(deleteMarker);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t//No 'last' record found that isn't 'deleted'\n\t\t\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\t\t\t  \n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\tdb.commit();\n\t\treturn reply;\n\t}","id":36184,"modified_method":"public DeleteObjectResponseType deleteObject(DeleteObjectType request)\n\t\t\tthrows EucalyptusCloudException {\n\t\tDeleteObjectResponseType reply = (DeleteObjectResponseType) request.getReply();\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfos = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfos);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucketInfo = bucketList.get(0);\n\t\t\tBucketLogData logData = bucketInfo.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucketInfo.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucketInfo.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_DELETEOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketInfo.getBucketName(),\n\t\t\t\t\t\t\tnull)))) {\n\n\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\t\t\t\t\n\n\t\t\t\tif(bucketInfo.isVersioningEnabled()) {\n\t\t\t\t\t//Versioning is enabled, so place delete marker.\t\t\t\t\t\n\t\t\t\t\tObjectInfo searchDeletedObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tsearchDeletedObjectInfo.setDeleted(true);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdbObject.getUniqueEscape(searchDeletedObjectInfo);\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t//Delete marker already exists, can't double delete\n\t\t\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t\t\t} catch(NoSuchEntityException ex) {\n\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t} catch(EucalyptusCloudException ex) {\n\t\t\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tsearchObjectInfo.setLast(true);\n\t\t\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\t\t\t\tfor(ObjectInfo objInfo : objectInfos) {\n\t\t\t\t\t\t\tobjInfo.setLast(false);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t//Add the delete marker\n\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\tdeleteMarker.setLast(true);\n\t\t\t\t\t\tdeleteMarker.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\tdeleteMarker.setLastModified(new Date());\n\t\t\t\t\t\tdeleteMarker.setVersionId(UUID.randomUUID().toString().replaceAll(\"-\", \"\"));\n\t\t\t\t\t\tdbObject.add(deleteMarker);\n\n\t\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\t}\n\t\t\t\t} else {\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t/* Versioning disabled or suspended.\n\t\t\t\t\t * \n\t\t\t\t\t * Only delete 'null' versioned objects. If versioning is suspended then insert a delete marker.\n\t\t\t\t\t * If versioning is suspended and no 'null' version object exists then simply insert a delete marker\n\t\t\t\t\t */\n\t\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t//searchObjectInfo.setVersionId(WalrusProperties.NULL_VERSION_ID);\n\t\t\t\t\tsearchObjectInfo.setLast(true);\n\t\t\t\t\tsearchObjectInfo.setDeleted(false);\n\t\t\t\t\tList<ObjectInfo>objectInfos = dbObject.queryEscape(searchObjectInfo);\n\n\t\t\t\t\tif (objectInfos.size() > 0) {\n\t\t\t\t\t\tif(objectInfos.size() > 1) {\n\t\t\t\t\t\t\t//This shouldn't happen, so bail if it does\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"More than one object set to 'last' found\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tObjectInfo lastObject = objectInfos.get(0);\n\t\t\t\t\t\tif(lastObject.getVersionId().equals(WalrusProperties.NULL_VERSION_ID)) {\t\t\t\t\t\t\n\t\t\t\t\t\t\t//Remove the 'null' versioned object\n\t\t\t\t\t\t\tObjectInfo nullObject = lastObject;\n\t\t\t\t\t\t\tdbObject.delete(nullObject);\n\t\t\t\t\t\t\tString objectName = nullObject.getObjectName();\n\t\t\t\t\t\t\tfor (GrantInfo grantInfo : nullObject.getGrants()) {\n\t\t\t\t\t\t\t\tdb.delete(grantInfo);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tLong size = nullObject.getSize();\n\t\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tdecrementBucketSize(bucketName, size);\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName, \n\t\t\t\t\t\t\t\t\tobjectName,\n\t\t\t\t\t\t\t\t\tobjectKey,\n\t\t\t\t\t\t\t\t\tWalrusProperties.NULL_VERSION_ID,\n\t\t\t\t\t\t\t\t\tsize, \n\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tif(bucketInfo.isVersioningSuspended()) {\n\t\t\t\t\t\t\t\t//Some version found, don't delete it, just make it not last.\n\t\t\t\t\t\t\t\t//This is possible when versiong was suspended and no object uploaded since then\n\t\t\t\t\t\t\t\tlastObject.setLast(false);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"Non 'null' versioned object found in a versioning disabled bucket, not sure how to proceed with delete.\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treply.setCode(\"200\");\n\t\t\t\t\t\treply.setDescription(\"OK\");\n\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\tupdateLogData(bucketInfo, logData);\n\t\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif(bucketInfo.isVersioningSuspended()) {\n\t\t\t\t\t\t\t//Add the delete marker\n\t\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\t\tdeleteMarker.setLast(true);\n\t\t\t\t\t\t\tdeleteMarker.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\t\tdeleteMarker.setLastModified(new Date());\n\t\t\t\t\t\t\tdeleteMarker.setVersionId(UUID.randomUUID().toString().replaceAll(\"-\", \"\"));\n\t\t\t\t\t\t\tdbObject.add(deleteMarker);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t//No 'last' record found that isn't 'deleted'\n\t\t\t\t\t\tthrow new NoSuchEntityException(objectKey, logData);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\t\t\t  \n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\tdb.commit();\n\t\treturn reply;\n\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public void run() {\n\t\t\ttry {\n\t\t\t\tstorageManager.deleteObject(bucketName, objectName);\n\t\t\t\tif (WalrusProperties.trackUsageStatistics && (size > 0))\n\t\t\t\t\twalrusStatistics.updateSpaceUsed(-size);\n\n\t\t\t\t\t/* Send an event to reporting to report this S3 usage. */\n\t\t\t\t\t// //fireUsageEvent For Delete Object \n\t\t\t\t\t//reportWalrusEvent(genObjectEvent(userId,user,accountNumber,account,false,size));\n\t\t\t\t\tfireObjectUsageEvent(S3ObjectAction.OBJECTDELETE,\n\t\t\t\t\t\t    Integer.toString(this.hashCode()), this.bucketName, this.objectName, \n\t\t\t\t\t\t    UserFullName.getInstance(Accounts.lookupUserById(userId)), this.size);\n\t\t\t} catch (Exception ex) {\n\t\t\t\tLOG.error(ex, ex);\n\t\t\t}\n\t\t}","id":36185,"modified_method":"public void run() {\n\t\t\ttry {\n\t\t\t\tstorageManager.deleteObject(bucketName, objectName);\n\t\t\t\tif (WalrusProperties.trackUsageStatistics && (size > 0))\n\t\t\t\t\twalrusStatistics.updateSpaceUsed(-size);\n\n\t\t\t\t/* Send an event to reporting to report this S3 usage. */\n\t\t\t\tif ( size > 0 ) {\n\t\t\t\t\tfireObjectUsageEvent( S3ObjectAction.OBJECTDELETE,\n\t\t\t\t\t\tthis.bucketName, this.objectKey, this.version, this.userId, this.size );\n\t\t\t\t}\n\t\t\t} catch (Exception ex) {\n\t\t\t\tLOG.error(ex, ex);\n\t\t\t}\n\t\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public PutObjectResponseType putObject(PutObjectType request) throws EucalyptusCloudException {\n\t\tPutObjectResponseType reply = (PutObjectResponseType) request.getReply();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount() ;\n\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tLong oldBucketSize = 0L;\n\t\tString md5 = \"\";\n\t\tDate lastModified = null;\n\n\t\tAccessControlListType accessControlList = request.getAccessControlList();\n\t\tif (accessControlList == null) {\n\t\t\taccessControlList = new AccessControlListType();\n\t\t}\n\n\t\tString key = bucketName + \".\" + objectKey;\n\t\tString randomKey = request.getRandomKey();\n\t\tWalrusDataMessenger messenger = WalrusRESTBinding.getWriteMessenger();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfo = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfo);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucket = bucketList.get(0);\n\t\t\tBucketLogData logData = bucket.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tlong objSize = 0;\n\t\t\ttry {\n\t\t\t\tobjSize = Long.valueOf( request.getContentLength( ) );\n\t\t\t} catch ( NumberFormatException e ) {\n\t\t\t\tLOG.error( \"Invalid content length \" + request.getContentLength( ) );\n\t\t\t\t// TODO(wenye): should handle this properly.\n\t\t\t\tobjSize = 1L;\n\t\t\t}\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucket.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucket.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\tnull)))) {\n\t\t\t\tif (logData != null) {\n\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t}\n\t\t\t\tString objectName = null;\n\t\t\t\tString versionId =  null;\n\t\t\t\tObjectInfo objectInfo = null;\n\t\t\t\tif (bucket.isVersioningEnabled()) {\n\t\t\t\t\t//If versioning, add new object with new version id and make it the 'latest' version.\n\t\t\t\t\tobjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tobjectInfo.setOwnerId(account.getAccountNumber());\n\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\tobjectInfo.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\tobjectInfo.setGrants(grantInfos);\n\t\t\t\t\tobjectName = UUID.randomUUID().toString();\n\t\t\t\t\tobjectInfo.setObjectName(objectName);\n\t\t\t\t\tobjectInfo.setSize(0L);\n\t\t\t\t\tversionId = UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n\t\t\t\t\treply.setVersionId(versionId);\n\t\t\t\t} else {\n\t\t\t\t\t//If no versioning enabled, put using a null version id, this will replace any previous 'null' versioned object but not one with a version id.\n\t\t\t\t\tversionId = WalrusProperties.NULL_VERSION_ID;\n\t\t\t\t\tObjectInfo searchObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tsearchObject.setVersionId(versionId);\t\t\t\t\t\t\t\n\t\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tObjectInfo foundObject = dbObject.getUniqueEscape(searchObject);\n\t\t\t\t\t\tif (!foundObject.canWrite(account.getAccountNumber())) {\n\t\t\t\t\t\t\t//Found existing object, but don't have write access\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey, logData);\n\t\t\t\t\t\t} \n\t\t\t\t\t\tobjectName = foundObject.getObjectName();\n\t\t\t\t\t} catch(AccessDeniedException ex) { \n\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t} catch(EucalyptusCloudException ex) {\n\t\t\t\t\t\t//No existing object found\n\t\t\t\t\t\tobjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tobjectInfo.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\t\tobjectInfo.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\t\tobjectInfo.setGrants(grantInfos);\n\t\t\t\t\t\tobjectName =  UUID.randomUUID().toString();\n\t\t\t\t\t\tobjectInfo.setObjectName(objectName);\n\t\t\t\t\t\tobjectInfo.setSize(0L);\n\t\t\t\t\t}\n\t\t\t\t}\t\t\t\t\n\n\t\t\t\tString bucketOwnerId = bucket.getOwnerId();\n\t\t\t\tdb.commit();\n\t\t\t\t// writes are unconditional\n\t\t\t\tWalrusDataQueue<WalrusDataMessage> putQueue = messenger.getQueue(key, randomKey);\n\n\t\t\t\ttry {\n\t\t\t\t\tWalrusDataMessage dataMessage;\n\t\t\t\t\tString tempObjectName = objectName;\n\t\t\t\t\tMessageDigest digest = null;\n\t\t\t\t\tlong size = 0;\n\t\t\t\t\tFileIO fileIO = null;\n\t\t\t\t\twhile ((dataMessage = putQueue.take()) != null) {\n\t\t\t\t\t\tif(putQueue.getInterrupted()) {                                         \n\t\t\t\t\t\t\tif(WalrusDataMessage.isEOF(dataMessage)) {\n\t\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\t\tif(monitor.getLastModified() == null) {\n\t\t\t\t\t\t\t\t\tLOG.trace(\"Monitor wait: \" + key + \" random: \" + randomKey);\n\t\t\t\t\t\t\t\t\tsynchronized (monitor) {\n\t\t\t\t\t\t\t\t\t\tmonitor.wait();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tLOG.trace(\"Monitor resume: \" + key + \" random: \" + randomKey);\n\t\t\t\t\t\t\t\tlastModified = monitor.getLastModified();\n\t\t\t\t\t\t\t\tmd5 = monitor.getMd5();\n\t\t\t\t\t\t\t\t//ok we are done here\n\t\t\t\t\t\t\t\tif(fileIO != null) {\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\t\t\ttempObjectName,\n\t\t\t\t\t\t\t\t\t\t-1L,\n\t\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t\t\tLOG.info(\"Transfer interrupted: \"+ key);\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tbreak;  \n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (WalrusDataMessage.isStart(dataMessage)) {\n\t\t\t\t\t\t\ttempObjectName = UUID.randomUUID().toString();\n\t\t\t\t\t\t\tdigest = Digest.MD5.get();\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfileIO = storageManager.prepareForWrite(bucketName, tempObjectName);\n\t\t\t\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else if (WalrusDataMessage.isEOF(dataMessage)) {\n\t\t\t\t\t\t\tif (digest != null) {\n\t\t\t\t\t\t\t\tmd5 = Hashes.bytesToHex(digest.digest());\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\t\tmd5 = monitor.getMd5();\n\t\t\t\t\t\t\t\tlastModified = monitor.getLastModified();\n\t\t\t\t\t\t\t\tif (md5 == null) {\n\t\t\t\t\t\t\t\t\tLOG.error(\"ETag did not match for: \" + randomKey + \" Computed MD5 is null\");\n\t\t\t\t\t\t\t\t\tthrow new ContentMismatchException(bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tString contentMD5 = request.getContentMD5();\n\t\t\t\t\t\t\tif (contentMD5 != null) {\n\t\t\t\t\t\t\t\tString contentMD5AsHex = Hashes.bytesToHex(Base64.decode(contentMD5));\n\t\t\t\t\t\t\t\tif(!contentMD5AsHex.equals(md5)) {\n\t\t\t\t\t\t\t\t\tif(fileIO != null) {\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\t\t\t\ttempObjectName,\n\t\t\t\t\t\t\t\t\t\t\t-1L,\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\t\tLOG.error(\"ETag did not match for: \" + randomKey + \" Expected: \" + contentMD5AsHex + \" Computed: \" + md5);\n\t\t\t\t\t\t\t\t\tthrow new ContentMismatchException(bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// commit object\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif (fileIO != null) { \n\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tstorageManager.renameObject(bucketName, tempObjectName, objectName);\n\t\t\t\t\t\t\t} catch (IOException ex) {\n\t\t\t\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(objectKey);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlastModified = new Date();\n\t\t\t\t\t\t\tObjectInfo searchObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tsearchObject.setVersionId(versionId);\n\t\t\t\t\t\t\tEntityWrapper<ObjectInfo> dbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tObjectInfo foundObject;\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfoundObject = dbObject.getUniqueEscape(searchObject);\n\t\t\t\t\t\t\t\tif (ctx.hasAdministrativePrivileges() || foundObject.canWriteACP(account.getAccountNumber())) {\n\t\t\t\t\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucketOwnerId, grantInfos, accessControlList);\n\t\t\t\t\t\t\t\t\tfoundObject.setGrants(grantInfos);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (WalrusProperties.enableTorrents) {\n\t\t\t\t\t\t\t\t\tEntityWrapper<TorrentInfo> dbTorrent = dbObject.recast(TorrentInfo.class);\n\t\t\t\t\t\t\t\t\tTorrentInfo torrentInfo = new TorrentInfo(bucketName, objectKey);\n\t\t\t\t\t\t\t\t\tList<TorrentInfo> torrentInfos = dbTorrent.queryEscape(torrentInfo);\n\t\t\t\t\t\t\t\t\tif (torrentInfos.size() > 0) {\n\t\t\t\t\t\t\t\t\t\tTorrentInfo foundTorrentInfo = torrentInfos.get(0);\n\t\t\t\t\t\t\t\t\t\tTorrentClient torrentClient = Torrents.getClient(bucketName + objectKey);\n\t\t\t\t\t\t\t\t\t\tif (torrentClient != null) {\n\t\t\t\t\t\t\t\t\t\t\ttorrentClient.bye();\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tdbTorrent.delete(foundTorrentInfo);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"Bittorrent support has been disabled. Please check pre-requisites\");\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\tif(objectInfo != null) {\n\t\t\t\t\t\t\t\t\tfoundObject = objectInfo;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"Unable to update object: \" + bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfoundObject.setVersionId(versionId);\n\t\t\t\t\t\t\tfoundObject.replaceMetaData(request.getMetaData());\n\t\t\t\t\t\t\tfoundObject.setEtag(md5);\n\t\t\t\t\t\t\tfoundObject.setSize(size);\n\t\t\t\t\t\t\tfoundObject.setLastModified(lastModified);\n\t\t\t\t\t\t\tfoundObject.setStorageClass(\"STANDARD\");\n\t\t\t\t\t\t\tfoundObject.setContentType(request.getContentType());\n\t\t\t\t\t\t\tfoundObject.setContentDisposition(request.getContentDisposition());\n\t\t\t\t\t\t\tfoundObject.setLast(true);\n\t\t\t\t\t\t\tfoundObject.setDeleted(false);\n\t\t\t\t\t\t\treply.setSize(size);\n\t\t\t\t\t\t\tif (!ctx.hasAdministrativePrivileges() &&\n\t\t\t\t\t\t\t\t\t!Permissions.canAllocate(PolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser(),\n\t\t\t\t\t\t\t\t\t\t\toldBucketSize + size)) {\n\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\tLOG.error(\"Quota exceeded for Walrus putObject\");\n\t\t\t\t\t\t\t\tthrow new EntityTooLargeException(\"Key\", objectKey);\n\t\t\t\t\t\t\t}\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tincrementBucketSize(bucketName, objectKey, oldBucketSize, size);\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t} catch (EntityTooLargeException ex) {\n\t\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\t\t\tif (WalrusProperties.trackUsageStatistics) {\n\t\t\t\t\t\t\t\twalrusStatistics.updateBytesIn(size);\n\t\t\t\t\t\t\t\twalrusStatistics.updateSpaceUsed(size);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\t\tlogData.setObjectSize(size);\n\t\t\t\t\t\t\t\tupdateLogData(bucket, logData);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(objectInfo != null) {\n\t\t\t\t\t\t\t\tdbObject.add(foundObject);\n\t\t\t\t\t\t\t} \n\t\t\t\t\t\t\tsuccess = false;\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdbObject.commit();\n\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\tLOG.error(ex, ex);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tdbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(new ObjectInfo(bucketName, objectKey));\n\t\t\t\t\t\t\tfor(ObjectInfo objInfo : objectInfos) {\n\t\t\t\t\t\t\t\tif (!success) {\n\t\t\t\t\t\t\t\t\tif (objInfo.getLast()) {\n\t\t\t\t\t\t\t\t\t\tlastModified = objInfo.getLastModified();\n\t\t\t\t\t\t\t\t\t\tmd5 = objInfo.getEtag();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (!versionId.equals(objInfo.getVersionId())) {\n\t\t\t\t\t\t\t\t\tobjInfo.setLast(false);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdbObject.commit();\n\n\t\t\t\t\t\t\t//See if a delete marker exists that needs to be removed now\n\t\t\t\t\t\t\tdbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\t\tObjectInfo foundDeleteMarker = null;\t\t\t\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfoundDeleteMarker = dbObject.getUniqueEscape(deleteMarker);\n\t\t\t\t\t\t\t\tdbObject.delete(foundDeleteMarker);\n\t\t\t\t\t\t\t} catch(Exception ex) {\n\t\t\t\t\t\t\t\tif(foundDeleteMarker != null) {\n\t\t\t\t\t\t\t\t\tLOG.error(\"Deletion of delete marker failed for: \" + bucketName + \"/\" + objectKey, ex);\t\n\t\t\t\t\t\t\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tdbObject.commit();\n\n\t\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\t\tlogData.setTurnAroundTime(Long\n\t\t\t\t\t\t\t\t\t\t.parseLong(new String(dataMessage\n\t\t\t\t\t\t\t\t\t\t\t\t.getPayload())));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// restart all interrupted puts\n\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\tsynchronized (monitor) {\n\t\t\t\t\t\t\t\tmonitor.setLastModified(lastModified);\n\t\t\t\t\t\t\t\tmonitor.setMd5(md5);\n\t\t\t\t\t\t\t\tmonitor.notifyAll();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t//messenger.removeMonitor(key);\n\t\t\t\t\t\t\tmessenger.clearQueues(key);\n\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\tLOG.info(\"Transfer complete: \" + key);\n\n\t\t\t\t\t\t\t/* Send an event to reporting to report this S3 usage. */\n\t\n\t\t\t\t\t\t\t// TODO : Need to validate the naturalId is correct via unit testing \n\t\t\t\t\t\t\tfireObjectUsageEvent(S3ObjectAction.OBJECTCREATE, foundDeleteMarker.getNaturalId(), bucketName, objectName, ctx.getUserFullName(), size);\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tassert (WalrusDataMessage.isData(dataMessage));\n\t\t\t\t\t\t\tbyte[] data = dataMessage.getPayload();\n\t\t\t\t\t\t\t// start writing object (but do not commit yet)\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif (fileIO != null)\n\t\t\t\t\t\t\t\t\tfileIO.write(data);\n\t\t\t\t\t\t\t} catch (IOException ex) {\n\t\t\t\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// calculate md5 on the fly\n\t\t\t\t\t\t\tsize += data.length;\n\t\t\t\t\t\t\tif (digest != null) {\n\t\t\t\t\t\t\t\tdigest.update(data);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\tLOG.error(ex, ex);\n\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\tthrow new EucalyptusCloudException(\"Transfer interrupted: \" + key + \".\" + randomKey);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\t\n\t\t\n\t\treply.setEtag(md5);\n\t\treply.setLastModified(DateUtils.format(lastModified.getTime(),\n\t\t\t\tDateUtils.ISO8601_DATETIME_PATTERN)\n\t\t\t\t+ \".000Z\");\n\t\treturn reply;\n\t}","id":36186,"modified_method":"public PutObjectResponseType putObject(PutObjectType request) throws EucalyptusCloudException {\n\t\tPutObjectResponseType reply = (PutObjectResponseType) request.getReply();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount() ;\n\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\t\tLong oldBucketSize = 0L;\n\t\tString md5 = \"\";\n\t\tDate lastModified = null;\n\n\t\tAccessControlListType accessControlList = request.getAccessControlList();\n\t\tif (accessControlList == null) {\n\t\t\taccessControlList = new AccessControlListType();\n\t\t}\n\n\t\tString key = bucketName + \".\" + objectKey;\n\t\tString randomKey = request.getRandomKey();\n\t\tWalrusDataMessenger messenger = WalrusRESTBinding.getWriteMessenger();\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfo = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfo);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucket = bucketList.get(0);\n\t\t\tBucketLogData logData = bucket.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tlong objSize = 0;\n\t\t\ttry {\n\t\t\t\tobjSize = Long.valueOf( request.getContentLength( ) );\n\t\t\t} catch ( NumberFormatException e ) {\n\t\t\t\tLOG.error( \"Invalid content length \" + request.getContentLength( ) );\n\t\t\t\t// TODO(wenye): should handle this properly.\n\t\t\t\tobjSize = 1L;\n\t\t\t}\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucket.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucket.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\tnull)))) {\n\t\t\t\tif (logData != null) {\n\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t}\n\t\t\t\tString objectName = null;\n\t\t\t\tString versionId =  null;\n\t\t\t\tLong oldObjectSize = 0L;\n\t\t\t\tObjectInfo objectInfo = null;\n\t\t\t\tif (bucket.isVersioningEnabled()) {\n\t\t\t\t\t//If versioning, add new object with new version id and make it the 'latest' version.\n\t\t\t\t\tobjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tobjectInfo.setOwnerId(account.getAccountNumber());\n\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\tobjectInfo.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\tobjectInfo.setGrants(grantInfos);\n\t\t\t\t\tobjectName = UUID.randomUUID().toString();\n\t\t\t\t\tobjectInfo.setObjectName(objectName);\n\t\t\t\t\tobjectInfo.setSize(0L);\n\t\t\t\t\tversionId = UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n\t\t\t\t\treply.setVersionId(versionId);\n\t\t\t\t} else {\n\t\t\t\t\t//If no versioning enabled, put using a null version id, this will replace any previous 'null' versioned object but not one with a version id.\n\t\t\t\t\tversionId = WalrusProperties.NULL_VERSION_ID;\n\t\t\t\t\tObjectInfo searchObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tsearchObject.setVersionId(versionId);\t\t\t\t\t\t\t\n\t\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db.recast(ObjectInfo.class);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tObjectInfo foundObject = dbObject.getUniqueEscape(searchObject);\n\t\t\t\t\t\tif (!foundObject.canWrite(account.getAccountNumber())) {\n\t\t\t\t\t\t\t//Found existing object, but don't have write access\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey, logData);\n\t\t\t\t\t\t} \n\t\t\t\t\t\tobjectName = foundObject.getObjectName();\n\t\t\t\t\t\toldObjectSize = foundObject.getSize();\n\t\t\t\t\t} catch(AccessDeniedException ex) { \n\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t} catch(EucalyptusCloudException ex) {\n\t\t\t\t\t\t//No existing object found\n\t\t\t\t\t\tobjectInfo = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\tobjectInfo.setOwnerId(account.getAccountNumber());\n\t\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\t\tobjectInfo.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\t\tobjectInfo.setGrants(grantInfos);\n\t\t\t\t\t\tobjectName =  UUID.randomUUID().toString();\n\t\t\t\t\t\tobjectInfo.setObjectName(objectName);\n\t\t\t\t\t\tobjectInfo.setSize(0L);\n\t\t\t\t\t}\n\t\t\t\t}\t\t\t\t\n\n\t\t\t\tString bucketOwnerId = bucket.getOwnerId();\n\t\t\t\tdb.commit();\n\t\t\t\t// writes are unconditional\n\t\t\t\tWalrusDataQueue<WalrusDataMessage> putQueue = messenger.getQueue(key, randomKey);\n\n\t\t\t\ttry {\n\t\t\t\t\tWalrusDataMessage dataMessage;\n\t\t\t\t\tString tempObjectName = objectName;\n\t\t\t\t\tMessageDigest digest = null;\n\t\t\t\t\tlong size = 0;\n\t\t\t\t\tFileIO fileIO = null;\n\t\t\t\t\twhile ((dataMessage = putQueue.take()) != null) {\n\t\t\t\t\t\tif(putQueue.getInterrupted()) {                                         \n\t\t\t\t\t\t\tif(WalrusDataMessage.isEOF(dataMessage)) {\n\t\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\t\tif(monitor.getLastModified() == null) {\n\t\t\t\t\t\t\t\t\tLOG.trace(\"Monitor wait: \" + key + \" random: \" + randomKey);\n\t\t\t\t\t\t\t\t\tsynchronized (monitor) {\n\t\t\t\t\t\t\t\t\t\tmonitor.wait();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tLOG.trace(\"Monitor resume: \" + key + \" random: \" + randomKey);\n\t\t\t\t\t\t\t\tlastModified = monitor.getLastModified();\n\t\t\t\t\t\t\t\tmd5 = monitor.getMd5();\n\t\t\t\t\t\t\t\t//ok we are done here\n\t\t\t\t\t\t\t\tif(fileIO != null) {\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\t\t\ttempObjectName,\n\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\t-1L,\n\t\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t\t\tLOG.info(\"Transfer interrupted: \"+ key);\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tbreak;  \n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (WalrusDataMessage.isStart(dataMessage)) {\n\t\t\t\t\t\t\ttempObjectName = UUID.randomUUID().toString();\n\t\t\t\t\t\t\tdigest = Digest.MD5.get();\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfileIO = storageManager.prepareForWrite(bucketName, tempObjectName);\n\t\t\t\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else if (WalrusDataMessage.isEOF(dataMessage)) {\n\t\t\t\t\t\t\tif (digest != null) {\n\t\t\t\t\t\t\t\tmd5 = Hashes.bytesToHex(digest.digest());\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\t\tmd5 = monitor.getMd5();\n\t\t\t\t\t\t\t\tlastModified = monitor.getLastModified();\n\t\t\t\t\t\t\t\tif (md5 == null) {\n\t\t\t\t\t\t\t\t\tLOG.error(\"ETag did not match for: \" + randomKey + \" Computed MD5 is null\");\n\t\t\t\t\t\t\t\t\tthrow new ContentMismatchException(bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tString contentMD5 = request.getContentMD5();\n\t\t\t\t\t\t\tif (contentMD5 != null) {\n\t\t\t\t\t\t\t\tString contentMD5AsHex = Hashes.bytesToHex(Base64.decode(contentMD5));\n\t\t\t\t\t\t\t\tif(!contentMD5AsHex.equals(md5)) {\n\t\t\t\t\t\t\t\t\tif(fileIO != null) {\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tObjectDeleter objectDeleter = new ObjectDeleter(bucketName,\n\t\t\t\t\t\t\t\t\t\t\ttempObjectName,\n\t\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t\t\t\t-1L,\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser().getName(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getAccount().getName(),\n\t\t\t\t\t\t\t\t\t\t\tctx.getAccount().getAccountNumber());\n\t\t\t\t\t\t\t\t\tThreads.lookup(Walrus.class, WalrusManager.ObjectDeleter.class).limitTo(10).submit(objectDeleter);\n\t\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\t\tLOG.error(\"ETag did not match for: \" + randomKey + \" Expected: \" + contentMD5AsHex + \" Computed: \" + md5);\n\t\t\t\t\t\t\t\t\tthrow new ContentMismatchException(bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// commit object\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif (fileIO != null) { \n\t\t\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tstorageManager.renameObject(bucketName, tempObjectName, objectName);\n\t\t\t\t\t\t\t} catch (IOException ex) {\n\t\t\t\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(objectKey);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlastModified = new Date();\n\t\t\t\t\t\t\tObjectInfo searchObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tsearchObject.setVersionId(versionId);\n\t\t\t\t\t\t\tEntityWrapper<ObjectInfo> dbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tObjectInfo foundObject;\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfoundObject = dbObject.getUniqueEscape(searchObject);\n\t\t\t\t\t\t\t\tif (ctx.hasAdministrativePrivileges() || foundObject.canWriteACP(account.getAccountNumber())) {\n\t\t\t\t\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucketOwnerId, grantInfos, accessControlList);\n\t\t\t\t\t\t\t\t\tfoundObject.setGrants(grantInfos);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (WalrusProperties.enableTorrents) {\n\t\t\t\t\t\t\t\t\tEntityWrapper<TorrentInfo> dbTorrent = dbObject.recast(TorrentInfo.class);\n\t\t\t\t\t\t\t\t\tTorrentInfo torrentInfo = new TorrentInfo(bucketName, objectKey);\n\t\t\t\t\t\t\t\t\tList<TorrentInfo> torrentInfos = dbTorrent.queryEscape(torrentInfo);\n\t\t\t\t\t\t\t\t\tif (torrentInfos.size() > 0) {\n\t\t\t\t\t\t\t\t\t\tTorrentInfo foundTorrentInfo = torrentInfos.get(0);\n\t\t\t\t\t\t\t\t\t\tTorrentClient torrentClient = Torrents.getClient(bucketName + objectKey);\n\t\t\t\t\t\t\t\t\t\tif (torrentClient != null) {\n\t\t\t\t\t\t\t\t\t\t\ttorrentClient.bye();\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tdbTorrent.delete(foundTorrentInfo);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"Bittorrent support has been disabled. Please check pre-requisites\");\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\tif(objectInfo != null) {\n\t\t\t\t\t\t\t\t\tfoundObject = objectInfo;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow new EucalyptusCloudException(\"Unable to update object: \" + bucketName + \"/\" + objectKey);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfoundObject.setVersionId(versionId);\n\t\t\t\t\t\t\tfoundObject.replaceMetaData(request.getMetaData());\n\t\t\t\t\t\t\tfoundObject.setEtag(md5);\n\t\t\t\t\t\t\tfoundObject.setSize(size);\n\t\t\t\t\t\t\tfoundObject.setLastModified(lastModified);\n\t\t\t\t\t\t\tfoundObject.setStorageClass(\"STANDARD\");\n\t\t\t\t\t\t\tfoundObject.setContentType(request.getContentType());\n\t\t\t\t\t\t\tfoundObject.setContentDisposition(request.getContentDisposition());\n\t\t\t\t\t\t\tfoundObject.setLast(true);\n\t\t\t\t\t\t\tfoundObject.setDeleted(false);\n\t\t\t\t\t\t\treply.setSize(size);\n\t\t\t\t\t\t\tif (!ctx.hasAdministrativePrivileges() &&\n\t\t\t\t\t\t\t\t\t!Permissions.canAllocate(PolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\t\t\t\t\tPolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\t\t\t\t\tctx.getUser(),\n\t\t\t\t\t\t\t\t\t\t\toldBucketSize + size)) {\n\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\tLOG.error(\"Quota exceeded for Walrus putObject\");\n\t\t\t\t\t\t\t\tthrow new EntityTooLargeException(\"Key\", objectKey);\n\t\t\t\t\t\t\t}\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tboolean success = false;\n\t\t\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tincrementBucketSize(bucketName, objectKey, oldBucketSize, size);\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t} catch (EntityTooLargeException ex) {\n\t\t\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\t\t\tif (WalrusProperties.trackUsageStatistics) {\n\t\t\t\t\t\t\t\twalrusStatistics.updateBytesIn(size);\n\t\t\t\t\t\t\t\twalrusStatistics.updateSpaceUsed(size);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\t\tlogData.setObjectSize(size);\n\t\t\t\t\t\t\t\tupdateLogData(bucket, logData);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif(objectInfo != null) {\n\t\t\t\t\t\t\t\tdbObject.add(foundObject);\n\t\t\t\t\t\t\t} \n\t\t\t\t\t\t\tsuccess = false;\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdbObject.commit();\n\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\t\tdbObject.rollback();\n\t\t\t\t\t\t\t\tLOG.error(ex, ex);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tdbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(new ObjectInfo(bucketName, objectKey));\n\t\t\t\t\t\t\tfor(ObjectInfo objInfo : objectInfos) {\n\t\t\t\t\t\t\t\tif (!success) {\n\t\t\t\t\t\t\t\t\tif (objInfo.getLast()) {\n\t\t\t\t\t\t\t\t\t\tlastModified = objInfo.getLastModified();\n\t\t\t\t\t\t\t\t\t\tmd5 = objInfo.getEtag();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (!versionId.equals(objInfo.getVersionId())) {\n\t\t\t\t\t\t\t\t\tobjInfo.setLast(false);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdbObject.commit();\n\n\t\t\t\t\t\t\t//See if a delete marker exists that needs to be removed now\n\t\t\t\t\t\t\tdbObject = EntityWrapper.get(ObjectInfo.class);\n\t\t\t\t\t\t\tObjectInfo deleteMarker = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\t\t\tdeleteMarker.setDeleted(true);\n\t\t\t\t\t\t\tObjectInfo foundDeleteMarker = null;\t\t\t\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tfoundDeleteMarker = dbObject.getUniqueEscape(deleteMarker);\n\t\t\t\t\t\t\t\tdbObject.delete(foundDeleteMarker);\n\t\t\t\t\t\t\t} catch(Exception ex) {\n\t\t\t\t\t\t\t\tif(foundDeleteMarker != null) {\n\t\t\t\t\t\t\t\t\tLOG.error(\"Deletion of delete marker failed for: \" + bucketName + \"/\" + objectKey, ex);\t\n\t\t\t\t\t\t\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tdbObject.commit();\n\n\t\t\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\t\t\tlogData.setTurnAroundTime(Long\n\t\t\t\t\t\t\t\t\t\t.parseLong(new String(dataMessage\n\t\t\t\t\t\t\t\t\t\t\t\t.getPayload())));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// restart all interrupted puts\n\t\t\t\t\t\t\tWalrusMonitor monitor = messenger.getMonitor(key);\n\t\t\t\t\t\t\tsynchronized (monitor) {\n\t\t\t\t\t\t\t\tmonitor.setLastModified(lastModified);\n\t\t\t\t\t\t\t\tmonitor.setMd5(md5);\n\t\t\t\t\t\t\t\tmonitor.notifyAll();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t//messenger.removeMonitor(key);\n\t\t\t\t\t\t\tmessenger.clearQueues(key);\n\t\t\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\t\t\tLOG.info(\"Transfer complete: \" + key);\n\n\t\t\t\t\t\t\tfireObjectCreationEvent(\n\t\t\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\t\t\tobjectKey,\n\t\t\t\t\t\t\t\t\tversionId,\n\t\t\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\t\t\tsize,\n\t\t\t\t\t\t\t\t\toldObjectSize );\n\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tassert (WalrusDataMessage.isData(dataMessage));\n\t\t\t\t\t\t\tbyte[] data = dataMessage.getPayload();\n\t\t\t\t\t\t\t// start writing object (but do not commit yet)\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tif (fileIO != null)\n\t\t\t\t\t\t\t\t\tfileIO.write(data);\n\t\t\t\t\t\t\t} catch (IOException ex) {\n\t\t\t\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// calculate md5 on the fly\n\t\t\t\t\t\t\tsize += data.length;\n\t\t\t\t\t\t\tif (digest != null) {\n\t\t\t\t\t\t\t\tdigest.update(data);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\tLOG.error(ex, ex);\n\t\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\t\tthrow new EucalyptusCloudException(\"Transfer interrupted: \" + key + \".\" + randomKey);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tmessenger.removeQueue(key, randomKey);\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\t\t\n\t\t\n\t\treply.setEtag(md5);\n\t\treply.setLastModified(DateUtils.format(lastModified.getTime(),\n\t\t\t\tDateUtils.ISO8601_DATETIME_PATTERN)\n\t\t\t\t+ \".000Z\");\n\t\treturn reply;\n\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public PutObjectInlineResponseType putObjectInline(\n\t\t\tPutObjectInlineType request) throws EucalyptusCloudException {\n\t\tPutObjectInlineResponseType reply = (PutObjectInlineResponseType) request\n\t\t\t\t.getReply();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\n\t\tString md5 = \"\";\n\t\tLong oldBucketSize = 0L;\n\t\tDate lastModified;\n\n\t\tAccessControlListType accessControlList = request\n\t\t\t\t.getAccessControlList();\n\t\tif (accessControlList == null) {\n\t\t\taccessControlList = new AccessControlListType();\n\t\t}\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfo = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfo);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucket = bucketList.get(0);\n\t\t\tBucketLogData logData = bucket.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tlong objSize = 0;\n\t\t\ttry {\n\t\t\t\tobjSize = Long.valueOf( request.getContentLength( ) );\n\t\t\t} catch ( NumberFormatException e ) {\n\t\t\t\tLOG.error( \"Invalid content length \" + request.getContentLength( ) );\n\t\t\t\t// TODO(wenye): should handle this properly.\n\t\t\t\tobjSize = 1L;\n\t\t\t}\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucket.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucket.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\tnull)))) {\n\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db\n\t\t\t\t\t\t.recast(ObjectInfo.class);\n\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo();\n\t\t\t\tsearchObjectInfo.setBucketName(bucketName);\n\n\t\t\t\tObjectInfo foundObject = null;\n\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\t\tfor (ObjectInfo objectInfo : objectInfos) {\n\t\t\t\t\tif (objectInfo.getObjectKey().equals(objectKey)) {\n\t\t\t\t\t\t// key (object) exists. check perms\n\t\t\t\t\t\tif (!objectInfo.canWrite(account.getAccountNumber())) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey,\n\t\t\t\t\t\t\t\t\tlogData);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfoundObject = objectInfo;\n\t\t\t\t\t\toldBucketSize = -foundObject.getSize();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// write object to bucket\n\t\t\t\tString objectName;\n\t\t\t\tif (foundObject == null) {\n\t\t\t\t\t// not found. create an object info\n\t\t\t\t\tfoundObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tfoundObject.setOwnerId(account.getAccountNumber());\n\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\tfoundObject.setGrants(grantInfos);\n\t\t\t\t\tobjectName = UUID.randomUUID().toString();\n\t\t\t\t\tfoundObject.setObjectName(objectName);\n\t\t\t\t\tdbObject.add(foundObject);\n\t\t\t\t} else {\n\t\t\t\t\t// object already exists. see if we can modify acl\n\t\t\t\t\tif (ctx.hasAdministrativePrivileges() || foundObject.canWriteACP(account.getAccountNumber())) {\n\t\t\t\t\t\tList<GrantInfo> grantInfos = foundObject.getGrants();\n\t\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\t}\n\t\t\t\t\tobjectName = foundObject.getObjectName();\n\t\t\t\t}\n\t\t\t\tfoundObject.setObjectKey(objectKey);\n\t\t\t\ttry {\n\t\t\t\t\t// writes are unconditional\n\t\t\t\t\tif (request.getBase64Data().getBytes().length > WalrusProperties.MAX_INLINE_DATA_SIZE) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tthrow new InlineDataTooLargeException(bucketName + \"/\"\n\t\t\t\t\t\t\t\t+ objectKey);\n\t\t\t\t\t}\n\t\t\t\t\tbyte[] base64Data = Hashes.base64decode(\n\t\t\t\t\t\t\trequest.getBase64Data()).getBytes();\n\t\t\t\t\tfoundObject.setObjectName(objectName);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tFileIO fileIO = storageManager.prepareForWrite(\n\t\t\t\t\t\t\t\tbucketName, objectName);\n\t\t\t\t\t\tif (fileIO != null) {\n\t\t\t\t\t\t\tfileIO.write(base64Data);\n\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tthrow new EucalyptusCloudException(ex);\n\t\t\t\t\t}\n\t\t\t\t\tmd5 = Hashes.getHexString(Digest.MD5.get().digest(base64Data));\n\t\t\t\t\tfoundObject.setEtag(md5);\n\t\t\t\t\tLong size = (long) base64Data.length;\n\t\t\t\t\tfoundObject.setSize(size);\n\t\t\t\t\tif (!ctx.hasAdministrativePrivileges() &&\n\t\t\t\t\t\t\t!Permissions.canAllocate(PolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\t\t\tPolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\t\t\tctx.getUser(),\n\t\t\t\t\t\t\t\t\toldBucketSize + size)) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tLOG.error(\"Quota exceeded in Walrus putObject\");\n\t\t\t\t\t\tthrow new EntityTooLargeException(\"Key\", objectKey, logData);\n\t\t\t\t\t}\n\t\t\t\t\tboolean success = false;\n\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\tdo {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tincrementBucketSize(bucketName, objectKey, oldBucketSize, size);\n\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t} catch (EntityTooLargeException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t}\n\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\tif (WalrusProperties.trackUsageStatistics) {\n\t\t\t\t\t\twalrusStatistics.updateBytesIn(size);\n\t\t\t\t\t\twalrusStatistics.updateSpaceUsed(size);\n\t\t\t\t\t}\n\t\t\t\t\t// Add meta data if specified\n\t\t\t\t\tif (request.getMetaData() != null)\n\t\t\t\t\t\tfoundObject.replaceMetaData(request.getMetaData());\n\n\t\t\t\t\t// TODO: add support for other storage classes\n\t\t\t\t\tfoundObject.setStorageClass(\"STANDARD\");\n\t\t\t\t\tlastModified = new Date();\n\t\t\t\t\tfoundObject.setLastModified(lastModified);\n\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\tupdateLogData(bucket, logData);\n\t\t\t\t\t\tlogData.setObjectSize(size);\n\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Send an event to reporting to report this S3 usage. */\n\t\t\t\t\t\n\t\t\t\t\t//fireUsageEvent For Put Object \n\t\t\t\t\t//reportWalrusEvent(genObjectEvent(ctx,true,size));\n\t\t\t\t\tfireObjectUsageEvent(S3ObjectAction.OBJECTCREATE,\n\t\t\t\t\t\t    foundObject.getNaturalId(), foundObject.getBucketName(), \n\t\t\t\t\t\t    foundObject.getObjectName(), ctx.getUserFullName(), foundObject.getSize());\n\t\t\t\t\t/* SOAP */\n\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\tdb.rollback();\n\t\t\t\t\tthrow new EucalyptusCloudException(bucketName);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\n\t\tdb.commit();\n\n\t\treply.setEtag(md5);\n\t\treply.setLastModified(DateUtils.format(lastModified.getTime(),\n\t\t\t\tDateUtils.ISO8601_DATETIME_PATTERN)\n\t\t\t\t+ \".000Z\");\n\t\treturn reply;\n\t}","id":36187,"modified_method":"public PutObjectInlineResponseType putObjectInline(\n\t\t\tPutObjectInlineType request) throws EucalyptusCloudException {\n\t\tPutObjectInlineResponseType reply = (PutObjectInlineResponseType) request\n\t\t\t\t.getReply();\n\t\tContext ctx = Contexts.lookup();\n\t\tAccount account = ctx.getAccount();\n\n\t\tString bucketName = request.getBucket();\n\t\tString objectKey = request.getKey();\n\n\t\tString md5 = \"\";\n\t\tLong oldBucketSize = 0L;\n\t\tDate lastModified;\n\n\t\tAccessControlListType accessControlList = request\n\t\t\t\t.getAccessControlList();\n\t\tif (accessControlList == null) {\n\t\t\taccessControlList = new AccessControlListType();\n\t\t}\n\n\t\tEntityWrapper<BucketInfo> db = EntityWrapper.get(BucketInfo.class);\n\t\tBucketInfo bucketInfo = new BucketInfo(bucketName);\n\t\tList<BucketInfo> bucketList = db.queryEscape(bucketInfo);\n\n\t\tif (bucketList.size() > 0) {\n\t\t\tBucketInfo bucket = bucketList.get(0);\n\t\t\tBucketLogData logData = bucket.getLoggingEnabled() ? request.getLogData() : null;\n\t\t\tlong objSize = 0;\n\t\t\ttry {\n\t\t\t\tobjSize = Long.valueOf( request.getContentLength( ) );\n\t\t\t} catch ( NumberFormatException e ) {\n\t\t\t\tLOG.error( \"Invalid content length \" + request.getContentLength( ) );\n\t\t\t\t// TODO(wenye): should handle this properly.\n\t\t\t\tobjSize = 1L;\n\t\t\t}\n\t\t\tif (ctx.hasAdministrativePrivileges() || (\n\t\t\t\t\tbucket.canWrite(account.getAccountNumber()) &&\n\t\t\t\t\t(bucket.isGlobalWrite() || Lookups.checkPrivilege(PolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\tPolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_BUCKET,\n\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\tnull)))) {\n\t\t\t\tEntityWrapper<ObjectInfo> dbObject = db\n\t\t\t\t\t\t.recast(ObjectInfo.class);\n\t\t\t\tObjectInfo searchObjectInfo = new ObjectInfo();\n\t\t\t\tsearchObjectInfo.setBucketName(bucketName);\n\n\t\t\t\tObjectInfo foundObject = null;\n\t\t\t\tList<ObjectInfo> objectInfos = dbObject.queryEscape(searchObjectInfo);\n\t\t\t\tfor (ObjectInfo objectInfo : objectInfos) {\n\t\t\t\t\tif (objectInfo.getObjectKey().equals(objectKey)) {\n\t\t\t\t\t\t// key (object) exists. check perms\n\t\t\t\t\t\tif (!objectInfo.canWrite(account.getAccountNumber())) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow new AccessDeniedException(\"Key\", objectKey,\n\t\t\t\t\t\t\t\t\tlogData);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfoundObject = objectInfo;\n\t\t\t\t\t\toldBucketSize = -foundObject.getSize();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// write object to bucket\n\t\t\t\tString objectName;\n\t\t\t\tLong oldObjectSize = 0L;\n\t\t\t\tif (foundObject == null) {\n\t\t\t\t\t// not found. create an object info\n\t\t\t\t\tfoundObject = new ObjectInfo(bucketName, objectKey);\n\t\t\t\t\tfoundObject.setOwnerId(account.getAccountNumber());\n\t\t\t\t\tList<GrantInfo> grantInfos = new ArrayList<GrantInfo>();\n\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\tfoundObject.setGrants(grantInfos);\n\t\t\t\t\tobjectName = UUID.randomUUID().toString();\n\t\t\t\t\tfoundObject.setObjectName(objectName);\n\t\t\t\t\tdbObject.add(foundObject);\n\t\t\t\t} else {\n\t\t\t\t\t// object already exists. see if we can modify acl\n\t\t\t\t\tif (ctx.hasAdministrativePrivileges() || foundObject.canWriteACP(account.getAccountNumber())) {\n\t\t\t\t\t\tList<GrantInfo> grantInfos = foundObject.getGrants();\n\t\t\t\t\t\tfoundObject.addGrants(account.getAccountNumber(), bucket.getOwnerId(), grantInfos, accessControlList);\n\t\t\t\t\t}\n\t\t\t\t\tobjectName = foundObject.getObjectName();\n\t\t\t\t\toldObjectSize = foundObject.getSize();\n\t\t\t\t}\n\t\t\t\tfoundObject.setObjectKey(objectKey);\n\t\t\t\ttry {\n\t\t\t\t\t// writes are unconditional\n\t\t\t\t\tif (request.getBase64Data().getBytes().length > WalrusProperties.MAX_INLINE_DATA_SIZE) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tthrow new InlineDataTooLargeException(bucketName + \"/\"\n\t\t\t\t\t\t\t\t+ objectKey);\n\t\t\t\t\t}\n\t\t\t\t\tbyte[] base64Data = Hashes.base64decode(\n\t\t\t\t\t\t\trequest.getBase64Data()).getBytes();\n\t\t\t\t\tfoundObject.setObjectName(objectName);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tFileIO fileIO = storageManager.prepareForWrite(\n\t\t\t\t\t\t\t\tbucketName, objectName);\n\t\t\t\t\t\tif (fileIO != null) {\n\t\t\t\t\t\t\tfileIO.write(base64Data);\n\t\t\t\t\t\t\tfileIO.finish();\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tthrow new EucalyptusCloudException(ex);\n\t\t\t\t\t}\n\t\t\t\t\tmd5 = Hashes.getHexString(Digest.MD5.get().digest(base64Data));\n\t\t\t\t\tfoundObject.setEtag(md5);\n\t\t\t\t\tLong size = (long) base64Data.length;\n\t\t\t\t\tfoundObject.setSize(size);\n\t\t\t\t\tif (!ctx.hasAdministrativePrivileges() &&\n\t\t\t\t\t\t\t!Permissions.canAllocate(PolicySpec.VENDOR_S3,\n\t\t\t\t\t\t\t\t\tPolicySpec.S3_RESOURCE_OBJECT,\n\t\t\t\t\t\t\t\t\tbucketName,\n\t\t\t\t\t\t\t\t\tPolicySpec.S3_PUTOBJECT,\n\t\t\t\t\t\t\t\t\tctx.getUser(),\n\t\t\t\t\t\t\t\t\toldBucketSize + size)) {\n\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\tLOG.error(\"Quota exceeded in Walrus putObject\");\n\t\t\t\t\t\tthrow new EntityTooLargeException(\"Key\", objectKey, logData);\n\t\t\t\t\t}\n\t\t\t\t\tboolean success = false;\n\t\t\t\t\tint retryCount = 0;\n\t\t\t\t\tdo {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tincrementBucketSize(bucketName, objectKey, oldBucketSize, size);\n\t\t\t\t\t\t\tsuccess = true;\n\t\t\t\t\t\t} catch (EntityTooLargeException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t} catch (NoSuchBucketException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t} catch (RollbackException ex) {\n\t\t\t\t\t\t\tretryCount++;\n\t\t\t\t\t\t\tLOG.trace(\"retrying update: \" + bucketName);\n\t\t\t\t\t\t} catch (EucalyptusCloudException ex) {\n\t\t\t\t\t\t\tdb.rollback();\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t}\n\t\t\t\t\t} while(!success && (retryCount < 5));\n\t\t\t\t\tif (WalrusProperties.trackUsageStatistics) {\n\t\t\t\t\t\twalrusStatistics.updateBytesIn(size);\n\t\t\t\t\t\twalrusStatistics.updateSpaceUsed(size);\n\t\t\t\t\t}\n\t\t\t\t\t// Add meta data if specified\n\t\t\t\t\tif (request.getMetaData() != null)\n\t\t\t\t\t\tfoundObject.replaceMetaData(request.getMetaData());\n\n\t\t\t\t\t// TODO: add support for other storage classes\n\t\t\t\t\tfoundObject.setStorageClass(\"STANDARD\");\n\t\t\t\t\tlastModified = new Date();\n\t\t\t\t\tfoundObject.setLastModified(lastModified);\n\t\t\t\t\tif (logData != null) {\n\t\t\t\t\t\tupdateLogData(bucket, logData);\n\t\t\t\t\t\tlogData.setObjectSize(size);\n\t\t\t\t\t\treply.setLogData(logData);\n\t\t\t\t\t}\n\n\t\t\t\t\tfireObjectCreationEvent(\n\t\t\t\t\t\t\tfoundObject.getBucketName(),\n\t\t\t\t\t\t\tfoundObject.getObjectKey(),\n\t\t\t\t\t\t\tfoundObject.getVersionId(),\n\t\t\t\t\t\t\tctx.getUser().getUserId(),\n\t\t\t\t\t\t\tfoundObject.getSize(),\n\t\t\t\t\t\t\toldObjectSize );\n\t\t\t\t\t/* SOAP */\n\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\tLOG.error(ex);\n\t\t\t\t\tdb.rollback();\n\t\t\t\t\tthrow new EucalyptusCloudException(bucketName);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdb.rollback();\n\t\t\t\tthrow new AccessDeniedException(\"Bucket\", bucketName, logData);\n\t\t\t}\n\t\t} else {\n\t\t\tdb.rollback();\n\t\t\tthrow new NoSuchBucketException(bucketName);\n\t\t}\n\n\t\tdb.commit();\n\n\t\treply.setEtag(md5);\n\t\treply.setLastModified(DateUtils.format(lastModified.getTime(),\n\t\t\t\tDateUtils.ISO8601_DATETIME_PATTERN)\n\t\t\t\t+ \".000Z\");\n\t\treturn reply;\n\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private static void fireObjectUsageEvent(final S3ObjectAction actionInfo,\n\t    String s3bUUID, String bucketName, String objectName, OwnerFullName ownerFullName, Long sizeInBytes) {\n\t\n\ttry {\n\t    ListenerRegistry.getInstance().fireEvent(\n\t\t    S3ObjectEvent.with(actionInfo, s3bUUID, bucketName, objectName, ownerFullName, sizeInBytes));\n\t    \t \n\t} catch (final Exception e) {\n\t    LOG.error(e, e);\n\t}\n    }","id":36188,"modified_method":"private static void fireObjectUsageEvent( S3ObjectAction actionInfo, String bucketName,\n\t\t    String objectKey, String version, String ownerUserId, Long sizeInBytes) {\n\t\ttry {\n\t\t\tListenerRegistry.getInstance().fireEvent(\n\t\t\t\t\tS3ObjectEvent.with( actionInfo, bucketName, objectKey, version, ownerUserId, sizeInBytes ) );\n\t\t} catch ( final Exception e ) {\n\t\t\tLOG.error( e, e );\n\t\t}\n\t}","commit_id":"cdb94d612223731dd0e55bb7b7e4cd8ddb30fe80","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public static AmazonS3 getClient() {\n    if( _s3 == null ) {\n      synchronized( _lock ) {\n        if( _s3 == null ) {\n          try {\n            H2OAWSCredentialsProviderChain c = new H2OAWSCredentialsProviderChain();\n            ClientConfiguration cc = s3ClientCfg();\n            _s3 = new AmazonS3Client(c, cc);\n          } catch( Throwable e ) {\n            e.printStackTrace();\n            StringBuilder msg = new StringBuilder();\n            msg.append(e.getMessage() + \"\\n\");\n            msg.append(\"Unable to load S3 credentials.\");\n            throw new RuntimeException(msg.toString());\n          }\n        }\n      }\n    }\n    return _s3;\n  }","id":36189,"modified_method":"public static AmazonS3 getClient() {\n    if( _s3 == null ) {\n      synchronized( _lock ) {\n        if( _s3 == null ) {\n          try {\n            H2OAWSCredentialsProviderChain c = new H2OAWSCredentialsProviderChain();\n            ClientConfiguration cc = s3ClientCfg();\n            _s3 = configureClient(new AmazonS3Client(c, cc));\n          } catch( Throwable e ) {\n            e.printStackTrace();\n            StringBuilder msg = new StringBuilder();\n            msg.append(e.getMessage() + \"\\n\");\n            msg.append(\"Unable to load S3 credentials.\");\n            throw new RuntimeException(msg.toString());\n          }\n        }\n      }\n    }\n    return _s3;\n  }","commit_id":"690388344fd20fed545d09f7b760194fab4821da","url":"https://github.com/h2oai/h2o-3"},{"original_method":"private static void processListing(ObjectListing listing, ArrayList<String> succ, ArrayList<String> fail, boolean doImport){\n    for( S3ObjectSummary obj : listing.getObjectSummaries() ) {\n      try {\n        if (doImport) {\n          Key k = loadKey(obj);\n          succ.add(k.toString());\n        } else {\n          succ.add(obj.getKey());\n        }\n      } catch( IOException e ) {\n        fail.add(obj.getKey());\n      }\n    }\n  }","id":36190,"modified_method":"private static void processListing(ObjectListing listing, ArrayList<String> succ, ArrayList<String> fail, boolean doImport){\n    for( S3ObjectSummary obj : listing.getObjectSummaries() ) {\n      try {\n        if (doImport) {\n          Key k = loadKey(listing, obj);\n          succ.add(k.toString());\n        } else {\n          succ.add(obj.getKey());\n        }\n      } catch( IOException e ) {\n        fail.add(obj.getKey());\n      }\n    }\n  }","commit_id":"690388344fd20fed545d09f7b760194fab4821da","url":"https://github.com/h2oai/h2o-3"},{"original_method":"public static Key loadKey(S3ObjectSummary obj) throws IOException {\n    return S3FileVec.make(encodePath(obj.getBucketName(), obj.getKey()),obj.getSize());\n  }","id":36191,"modified_method":"public static Key loadKey(ObjectListing listing, S3ObjectSummary obj) throws IOException {\n    // Note: Some of S3 implementations does not fill bucketName of returned object (for example, Minio).\n    // So guess it based on returned ObjectListing\n    String bucketName = obj.getBucketName() == null ? listing.getBucketName() : obj.getBucketName();\n    return S3FileVec.make(encodePath(bucketName, obj.getKey()),obj.getSize());\n  }","commit_id":"690388344fd20fed545d09f7b760194fab4821da","url":"https://github.com/h2oai/h2o-3"},{"original_method":"private String executeDeploymentPlan(final DeploymentPlan plan, final DeploymentAction deployAction) throws Exception {\n        final ServerDeploymentPlanResult planResult = deploymentManager.execute(plan).get();\n\n        final ServerDeploymentActionResult actionResult = planResult.getDeploymentActionResult(deployAction.getId());\n        if (actionResult != null) {\n            final Exception deploymentException = (Exception) actionResult.getDeploymentException();\n            if (deploymentException != null)\n                throw deploymentException;\n        }\n\n        return deployAction.getDeploymentUnitUniqueName();\n    }","id":36192,"modified_method":"private void executeDeploymentPlan(final DeploymentPlan plan, final DeploymentAction deployAction) throws Exception {\n        try {\n            final ServerDeploymentPlanResult planResult = deploymentManager.execute(plan).get();\n\n            if (deployAction != null) {\n                final ServerDeploymentActionResult actionResult = planResult\n                .getDeploymentActionResult(deployAction.getId());\n                if (actionResult != null) {\n                    final Exception deploymentException = (Exception) actionResult.getDeploymentException();\n                    if (deploymentException != null)\n                        throw deploymentException;\n                }\n            }\n        } catch (final Exception e) {\n            LOGGER.fatal(e.getMessage(), e);\n            throw e;\n        }\n    }","commit_id":"697056e1d88c948e6018ec91f5251454f64d47d3","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void undeploy(final URL archive) throws Exception {\n        final DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n        final String uniqueName = url2Id.get(archive);\n        final DeploymentPlan plan = builder.undeploy(uniqueName).remove(uniqueName).build();\n        final Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        url2Id.remove(archive);\n        future.get();\n    }","id":36193,"modified_method":"@Override\n    public void undeploy(final URL archiveURL) throws Exception {\n        final DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n        final String uniqueName = url2Id.get(archiveURL);\n        final DeploymentPlan plan = builder.undeploy(uniqueName).remove(uniqueName).build();\n        final DeploymentAction deployAction = builder.getLastAction();\n        try {\n            executeDeploymentPlan(plan, deployAction);\n        } finally {\n            url2Id.remove(archiveURL);\n        }\n    }","commit_id":"697056e1d88c948e6018ec91f5251454f64d47d3","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void deploy(final URL url) throws Exception {\n        final DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan().add(url).andDeploy();\n        final DeploymentPlan plan = builder.build();\n        final DeploymentAction deployAction = builder.getLastAction();\n        final String uniqueId = executeDeploymentPlan(plan, deployAction);\n        url2Id.put(url, uniqueId);\n    }","id":36194,"modified_method":"@Override\n    public void deploy(final URL archiveURL) throws Exception {\n        final DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan().add(archiveURL).andDeploy();\n        final DeploymentPlan plan = builder.build();\n        final DeploymentAction deployAction = builder.getLastAction();\n        final String uniqueId = deployAction.getDeploymentUnitUniqueName();\n        try {\n            executeDeploymentPlan(plan, deployAction);\n        } finally {\n            url2Id.put(archiveURL, uniqueId);\n        }\n    }","commit_id":"697056e1d88c948e6018ec91f5251454f64d47d3","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void deploy(TargetModuleID targetModuleID) throws Exception {\n        ROOT_LOGGER.beginDeploy(targetModuleID);\n        DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n        builder = builder.add(targetModuleID.getModuleID(), new URL(targetModuleID.getModuleID())).andDeploy();\n        DeploymentPlan plan = builder.build();\n        DeploymentAction deployAction = builder.getLastAction();\n        String runtimeName = executeDeploymentPlan(plan, deployAction);\n        runtimeNames.put(targetModuleID, runtimeName);\n        ROOT_LOGGER.endDeploy(targetModuleID);\n    }","id":36195,"modified_method":"@Override\n    public void deploy(TargetModuleID targetModuleID) throws Exception {\n        ROOT_LOGGER.beginDeploy(targetModuleID);\n        String deploymentName = targetModuleID.getModuleID();\n        DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n        builder = builder.add(deploymentName, new URL(deploymentName)).andDeploy();\n        DeploymentPlan plan = builder.build();\n        DeploymentAction deployAction = builder.getLastAction();\n        executeDeploymentPlan(plan, deployAction);\n        ROOT_LOGGER.endDeploy(targetModuleID);\n    }","commit_id":"ba0ee2cb6bd071129e6fba9804769e30a01907fe","url":"https://github.com/wildfly/wildfly"},{"original_method":"private String executeDeploymentPlan(DeploymentPlan plan, DeploymentAction deployAction) throws Exception {\n        Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        ServerDeploymentPlanResult planResult = future.get();\n\n        ServerDeploymentActionResult actionResult = planResult.getDeploymentActionResult(deployAction.getId());\n        if (actionResult != null) {\n            Exception deploymentException = (Exception) actionResult.getDeploymentException();\n            if (deploymentException != null)\n                throw deploymentException;\n        }\n\n        return deployAction.getDeploymentUnitUniqueName();\n    }","id":36196,"modified_method":"private void executeDeploymentPlan(DeploymentPlan plan, DeploymentAction deployAction) throws Exception {\n        Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        ServerDeploymentPlanResult planResult = future.get();\n\n        ServerDeploymentActionResult actionResult = planResult.getDeploymentActionResult(deployAction.getId());\n        if (actionResult != null) {\n            Exception deploymentException = (Exception) actionResult.getDeploymentException();\n            if (deploymentException != null)\n                throw deploymentException;\n        }\n    }","commit_id":"ba0ee2cb6bd071129e6fba9804769e30a01907fe","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void undeploy(TargetModuleID targetModuleID) throws Exception {\n        String runtimeName = runtimeNames.remove(targetModuleID);\n        if (runtimeName != null) {\n            DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n            DeploymentPlan plan = builder.undeploy(runtimeName).remove(runtimeName).build();\n            Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n            future.get();\n        }\n    }","id":36197,"modified_method":"@Override\n    public void undeploy(TargetModuleID targetModuleID) throws Exception {\n        String deploymentName = targetModuleID.getModuleID();\n        DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n        DeploymentPlan plan = builder.undeploy(deploymentName).remove(deploymentName).build();\n        Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        future.get();\n    }","commit_id":"ba0ee2cb6bd071129e6fba9804769e30a01907fe","url":"https://github.com/wildfly/wildfly"},{"original_method":"private String executeDeploymentPlan(DeploymentPlan plan, DeploymentAction deployAction) throws Exception {\n        Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        ServerDeploymentPlanResult planResult = future.get();\n\n        ServerDeploymentActionResult actionResult = planResult.getDeploymentActionResult(deployAction.getId());\n        if (actionResult != null) {\n            Exception deploymentException = (Exception) actionResult.getDeploymentException();\n            if (deploymentException != null)\n                throw deploymentException;\n        }\n\n        return deployAction.getDeploymentUnitUniqueName();\n    }","id":36198,"modified_method":"private String executeDeploymentPlan(DeploymentPlan plan, DeploymentAction deployAction, Archive<?> archive) throws Exception {\n        Future<ServerDeploymentPlanResult> future = deploymentManager.execute(plan);\n        registry.put(archive, deployAction.getDeploymentUnitUniqueName());\n        ServerDeploymentPlanResult planResult = future.get();\n\n        ServerDeploymentActionResult actionResult = planResult.getDeploymentActionResult(deployAction.getId());\n        if (actionResult != null) {\n            Exception deploymentException = (Exception) actionResult.getDeploymentException();\n            if (deploymentException != null)\n                throw deploymentException;\n        }\n\n        return deployAction.getDeploymentUnitUniqueName();\n    }","commit_id":"da588ac926b4bb7b55c9838b6906fe9426a91726","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public ContainerMethodExecutor deploy(Context context, Archive<?> archive) throws DeploymentException {\n        try {\n            InputStream input = archive.as(ZipExporter.class).exportZip();\n            DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n            builder = builder.add(archive.getName(), input).andDeploy();\n            DeploymentPlan plan = builder.build();\n            DeploymentAction deployAction = builder.getLastAction();\n            String runtimeName = executeDeploymentPlan(plan, deployAction);\n            registry.put(archive, runtimeName);\n\n            return getContainerMethodExecutor(context);\n        } catch (Exception e) {\n            throw new DeploymentException(\"Could not deploy to container\", e);\n        }\n    }","id":36199,"modified_method":"@Override\n    public ContainerMethodExecutor deploy(Context context, Archive<?> archive) throws DeploymentException {\n        try {\n            InputStream input = archive.as(ZipExporter.class).exportZip();\n            DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n            builder = builder.add(archive.getName(), input).andDeploy();\n            DeploymentPlan plan = builder.build();\n            DeploymentAction deployAction = builder.getLastAction();\n            executeDeploymentPlan(plan, deployAction,archive);\n\n            return getContainerMethodExecutor(context);\n        } catch (Exception e) {\n            throw new DeploymentException(\"Could not deploy to container\", e);\n        }\n    }","commit_id":"da588ac926b4bb7b55c9838b6906fe9426a91726","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void suggest(String token, List<SearchItem> result) {\n        Collection<SMT> items = all();\n        if(items==null)     return;\n        for (SMT o : items) {\n            if(o!=null && getName(o).contains(token))\n                result.add(o);\n        }\n    }","id":36200,"modified_method":"public void suggest(String token, List<SearchItem> result) {\n        Collection<SMT> items = all();\n        if(items==null)     return;\n        for (SMT o : items) {\n            if(o!=null && getName(o).toLowerCase().contains(token.toLowerCase()))\n                result.add(o);\n        }\n    }","commit_id":"c7005be6109338d6eb6946d86fe54cc0ae5baed2","url":"https://github.com/kohsuke/hudson"},{"original_method":"public void suggest(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(i.getSearchName().contains(token))\n                result.add(i);\n    }","id":36201,"modified_method":"public void suggest(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(i.getSearchName().toLowerCase().contains(token.toLowerCase()))\n                result.add(i);\n    }","commit_id":"c7005be6109338d6eb6946d86fe54cc0ae5baed2","url":"https://github.com/kohsuke/hudson"},{"original_method":"public void find(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(token.equals(i.getSearchName()))\n                result.add(i);\n    }","id":36202,"modified_method":"public void find(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(token.toLowerCase().equals(i.getSearchName().toLowerCase()))\n                result.add(i);\n    }","commit_id":"c7005be6109338d6eb6946d86fe54cc0ae5baed2","url":"https://github.com/kohsuke/hudson"},{"original_method":"public void suggest(String token, List<SearchItem> result) {\n        Collection<SMT> items = all();\n        if(items==null)     return;\n        for (SMT o : items) {\n            if(o!=null && getName(o).toLowerCase().contains(token.toLowerCase()))\n                result.add(o);\n        }\n    }","id":36203,"modified_method":"public void suggest(String token, List<SearchItem> result) {\n         Collection<SMT> items = all();\n        User user = User.current();\n        boolean caseSensitive = false;\n        if(user!=null && user.getProperty(Search.UserProperty.class).getInsensitiveSearch()){ //Searching for anonymous user is case-sensitive\n          token = token.toLowerCase();\n          caseSensitive=true;\n        }\n        if(items==null)     return;\n        for (SMT o : items) {\n            String name = getName(o);\n            if(caseSensitive)\n                name=name.toLowerCase();\n            if(o!=null && name.contains(token))\n                result.add(o);\n        }\n    }","commit_id":"24dc0008c557c65d3e4dcfa73503af818e1cfea0","url":"https://github.com/kohsuke/hudson"},{"original_method":"public void find(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(token.toLowerCase().equals(i.getSearchName().toLowerCase()))\n                result.add(i);\n    }","id":36204,"modified_method":"public void find(String token, List<SearchItem> result) {\n        boolean caseSensitive = getCaseSensitivity();\n        for (SearchItem i : items){\n            String name = i.getSearchName();\n            if(caseSensitive){\n                token=token.toLowerCase();\n                name=name.toLowerCase();\n            }\n            if(token.equals(i.getSearchName()))\n                result.add(i);\n        }\n    }","commit_id":"24dc0008c557c65d3e4dcfa73503af818e1cfea0","url":"https://github.com/kohsuke/hudson"},{"original_method":"public void suggest(String token, List<SearchItem> result) {\n        for (SearchItem i : items)\n            if(i.getSearchName().toLowerCase().contains(token.toLowerCase()))\n                result.add(i);\n    }","id":36205,"modified_method":"public void suggest(String token, List<SearchItem> result) {\n        boolean caseSensitive = getCaseSensitivity();\n        for (SearchItem i : items){\n            String name = i.getSearchName();\n            if(caseSensitive){\n                token=token.toLowerCase();\n                name=name.toLowerCase();\n            }\n            if(name.contains(token))\n                result.add(i);\n        }\n    }","commit_id":"24dc0008c557c65d3e4dcfa73503af818e1cfea0","url":"https://github.com/kohsuke/hudson"},{"original_method":"public final boolean set(final Input uniform, final int v1, final int v2, final int v3, final int v4) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(uniform.location, v1, v2, v3, v4);\n\t\treturn true;\n\t}","id":36206,"modified_method":"public final boolean set(final int uniform, final int v1, final int v2) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(locations[uniform], v1, v2);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final float v1, final float v2, final float v3) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, v1, v2, v3);\n\t\treturn true;\n\t}","id":36207,"modified_method":"public final boolean set(final int uniform, final float value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void render (Renderable renderable) {\n\t\tfor (final Input input : localUniforms)\n\t\t\tinput.setter.set(this, program, input, camera, context, renderable);\n\t\trenderable.mesh.render(program, renderable.primitiveType, renderable.meshPartOffset, renderable.meshPartSize);\n\t\t// FIXME Use vertexAttributes to bind and render the mesh\n\t}","id":36208,"modified_method":"@Override\n\tpublic void render (Renderable renderable) {\n\t\tfor (final int i: localUniforms.items)\n\t\t\tif (setters.get(i) != null)\n\t\t\t\tsetters.get(i).set(this, i, renderable);\n\t\tif (currentMesh != renderable.mesh) {\n\t\t\tif (currentMesh != null)\n\t\t\t\tcurrentMesh.unbind(program, tempArray.items);\n\t\t\tcurrentMesh = renderable.mesh;\n\t\t\tcurrentMesh.bind(program, getAttributeLocations(renderable.mesh.getVertexAttributes()));\n\t\t}\n\t\trenderable.mesh.render(program, renderable.primitiveType, renderable.meshPartOffset, renderable.meshPartSize, false);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final Matrix4 value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformMatrix(uniform.location, value);\n\t\treturn true;\n\t}","id":36209,"modified_method":"public final boolean set(final int uniform, final Matrix4 value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformMatrix(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final int v1, final int v2) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(uniform.location, v1, v2);\n\t\treturn true;\n\t}","id":36210,"modified_method":"public final boolean set(final int uniform, final int v1, final int v2, final int v3) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(locations[uniform], v1, v2, v3);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final Vector3 value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, value);\n\t\treturn true;\n\t}","id":36211,"modified_method":"public final boolean set(final int uniform, final Vector3 value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final Matrix3 value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformMatrix(uniform.location, value);\n\t\treturn true;\n\t}","id":36212,"modified_method":"public final boolean set(final int uniform, final Matrix3 value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformMatrix(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final float v1, final float v2) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, v1, v2);\n\t\treturn true;\n\t}","id":36213,"modified_method":"public final boolean set(final int uniform, final float v1, final float v2) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], v1, v2);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void end () {\n\t\tprogram.end();\n\t}","id":36214,"modified_method":"@Override\n\tpublic void end () {\n\t\tif (currentMesh != null) {\n\t\t\tcurrentMesh.unbind(program, tempArray.items);\n\t\t\tcurrentMesh = null;\n\t\t}\n\t\tprogram.end();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final Vector2 value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, value);\n\t\treturn true;\n\t}","id":36215,"modified_method":"public final boolean set(final int uniform, final Vector2 value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Initialize this shader, causing all registered uniforms/attributes to be fetched. */\n\tpublic void init(final ShaderProgram program, final long materialMask, final long vertexMask, final long userMask) {\n\t\tif (this.program != null)\n\t\t\tthrow new GdxRuntimeException(\"Already initialized\");\n\t\tif (!program.isCompiled())\n\t\t\tthrow new GdxRuntimeException(program.getLog());\n\t\tthis.program = program;\n\t\tfor (Input input : inputs) {\n\t\t\tif (input.compare(materialMask, vertexMask, userMask))  {\n\t\t\t\tif (input.scope == GLOBAL_UNIFORM) {\n\t\t\t\t\tinput.location = program.fetchUniformLocation(input.name, false);\n\t\t\t\t\tif (input.location >= 0 && input.setter != null)\n\t\t\t\t\t\tglobalUniforms.add(input);\n\t\t\t\t} else if (input.scope == LOCAL_UNIFORM) {\n\t\t\t\t\tinput.location = program.fetchUniformLocation(input.name, false);\n\t\t\t\t\tif (input.location >= 0 && input.setter != null)\n\t\t\t\t\t\tlocalUniforms.add(input);\n\t\t\t\t} else if (input.scope == VERTEX_ATTRIBUTE) {\n\t\t\t\t\tinput.location = program.getAttributeLocation(input.name);\n\t\t\t\t\tif (input.location >= 0)\n\t\t\t\t\t\tvertexAttributes.add(input);\n\t\t\t\t} else\n\t\t\t\t\tinput.location = -1;\n\t\t\t} else\n\t\t\t\tinput.location = -1;\n\t\t}\n\t}","id":36216,"modified_method":"/** Initialize this shader, causing all registered uniforms/attributes to be fetched. */\n\tpublic void init(final ShaderProgram program, final Renderable renderable) {\n\t\tif (locations != null)\n\t\t\tthrow new GdxRuntimeException(\"Already initialized\");\n\t\tif (!program.isCompiled())\n\t\t\tthrow new GdxRuntimeException(program.getLog());\n\t\tthis.program = program;\n\t\t\n\t\tfinal int n = uniforms.size;\n\t\tlocations = new int[n];\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tfinal String input = uniforms.get(i);\n\t\t\tfinal Validator validator = validators.get(i);\n\t\t\tfinal Setter setter = setters.get(i);\n\t\t\tif (validator != null && !validator.validate(this, i, renderable))\n\t\t\t\tlocations[i] = -1;\n\t\t\telse {\n\t\t\t\tlocations[i] = program.fetchUniformLocation(input, false);\n\t\t\t\tif (locations[i] >= 0 && setter != null) {\n\t\t\t\t\tif (setter.isGlobal(this, i))\n\t\t\t\t\t\tglobalUniforms.add(i);\n\t\t\t\t\telse\n\t\t\t\t\t\tlocalUniforms.add(i);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (locations[i] < 0) {\n\t\t\t\tvalidators.set(i, null);\n\t\t\t\tsetters.set(i, null);\n\t\t\t}\n\t\t}\n\t\tfinal VertexAttributes attrs = renderable.mesh.getVertexAttributes();\n\t\tfinal int c = attrs.size();\n\t\tfor (int i = 0; i < c; i++) {\n\t\t\tfinal VertexAttribute attr = attrs.get(i);\n\t\t\tfinal int location = program.getAttributeLocation(attr.alias);\n\t\t\tif (location >= 0)\n\t\t\t\tattributes.put(attr.getKey(), location);\n\t\t}\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final int v1, final int v2, final int v3) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(uniform.location, v1, v2, v3);\n\t\treturn true;\n\t}","id":36217,"modified_method":"public final boolean set(final int uniform, final int v1, final int v2, final int v3, final int v4) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(locations[uniform], v1, v2, v3, v4);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void begin (Camera camera, RenderContext context) {\n\t\tthis.camera = camera;\n\t\tthis.context = context;\n\t\tprogram.begin();\n\t\tfor (final Input input : globalUniforms)\n\t\t\tinput.setter.set(this, program, input, camera, context, null);\n\t}","id":36218,"modified_method":"@Override\n\tpublic void begin (Camera camera, RenderContext context) {\n\t\tthis.camera = camera;\n\t\tthis.context = context;\n\t\tprogram.begin();\n\t\tcurrentMesh = null;\n\t\tfor (final int i: globalUniforms.items)\n\t\t\tif (setters.get(i) != null)\n\t\t\t\tsetters.get(i).set(this, i, null);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final float v1, final float v2, final float v3, final float v4) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, v1, v2, v3, v4);\n\t\treturn true;\n\t}","id":36219,"modified_method":"public final boolean set(final int uniform, final float v1, final float v2, final float v3, final float v4) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], v1, v2, v3, v4);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final float value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, value);\n\t\treturn true;\n\t}","id":36220,"modified_method":"public final boolean set(final int uniform, final float v1, final float v2, final float v3) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], v1, v2, v3);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final int value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(uniform.location, value);\n\t\treturn true;\n\t}","id":36221,"modified_method":"public final boolean set(final int uniform, final int value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformi(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void dispose () {\n\t\tprogram = null;\n\t\tinputs.clear();\n\t\tvertexAttributes.clear();\n\t\tlocalUniforms.clear();\n\t\tglobalUniforms.clear();\n\t}","id":36222,"modified_method":"@Override\n\tpublic void dispose () {\n\t\tprogram = null;\n\t\tuniforms.clear();\n\t\tvalidators.clear();\n\t\tsetters.clear();\n\t\tlocalUniforms.clear();\n\t\tglobalUniforms.clear();\n\t\tlocations = null;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final boolean set(final Input uniform, final Color value) {\n\t\tif (uniform.location < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(uniform.location, value);\n\t\treturn true;\n\t}","id":36223,"modified_method":"public final boolean set(final int uniform, final Color value) {\n\t\tif (locations[uniform] < 0)\n\t\t\treturn false;\n\t\tprogram.setUniformf(locations[uniform], value);\n\t\treturn true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public BlendingAttribute(final int sourceFunc, final int destFunc, final float opacity) {\n\t\tsuper(Type);\n\t\tsourceFunction = sourceFunc;\n\t\tdestFunction = destFunc;\n\t\tthis.opacity = opacity; \n\t}","id":36224,"modified_method":"public BlendingAttribute(final int sourceFunc, final int destFunc, final float opacity) {\n\t\tthis(true, sourceFunc, destFunc, opacity);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public BlendingAttribute(final BlendingAttribute copyFrom) {\n\t\tthis(copyFrom == null ? GL10.GL_SRC_ALPHA : copyFrom.sourceFunction,\n\t\t\tcopyFrom == null ? GL10.GL_ONE_MINUS_SRC_ALPHA : copyFrom.destFunction,\n\t\t\tcopyFrom == null ? 1.f : copyFrom.opacity);\n\t}","id":36225,"modified_method":"public BlendingAttribute(final BlendingAttribute copyFrom) {\n\t\tthis(copyFrom == null ? true : copyFrom.blended,\n\t\t\tcopyFrom == null ? GL10.GL_SRC_ALPHA : copyFrom.sourceFunction,\n\t\t\tcopyFrom == null ? GL10.GL_ONE_MINUS_SRC_ALPHA : copyFrom.destFunction,\n\t\t\tcopyFrom == null ? 1.f : copyFrom.opacity);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic int compare (final Renderable o1, final Renderable o2) {\n\t\tfinal boolean b1 = o1.material.has(BlendingAttribute.Type);\n\t\tfinal boolean b2 = o2.material.has(BlendingAttribute.Type);\n\t\tif (b1 != b2) \n\t\t\treturn b1 ? 1 : -1;\n\t\t// FIXME implement better sorting algorithm\n\t\t// final boolean same = o1.shader == o2.shader && o1.mesh == o2.mesh && (o1.lights == null) == (o2.lights == null) && \n\t\t\t// o1.material.equals(o2.material);\n\t\to1.worldTransform.getTranslation(tmpV1);\n\t\to2.worldTransform.getTranslation(tmpV2);\n\t\tfinal float dst = camera.position.dst2(tmpV1) - camera.position.dst2(tmpV2);\n\t\treturn dst < 0f ? -1 : (dst > 0f ? 1 : 0);\n\t}","id":36226,"modified_method":"@Override\n\tpublic int compare (final Renderable o1, final Renderable o2) {\n\t\tfinal boolean b1 = o1.material.has(BlendingAttribute.Type) ? \n\t\t\t((BlendingAttribute)o1.material.get(BlendingAttribute.Type)).blended : false;\n\t\tfinal boolean b2 = o2.material.has(BlendingAttribute.Type) ?\n\t\t\t((BlendingAttribute)o2.material.get(BlendingAttribute.Type)).blended : false;\n\t\tif (b1 != b2) \n\t\t\treturn b1 ? 1 : -1;\n\t\t// FIXME implement better sorting algorithm\n\t\t// final boolean same = o1.shader == o2.shader && o1.mesh == o2.mesh && (o1.lights == null) == (o2.lights == null) && \n\t\t\t// o1.material.equals(o2.material);\n\t\to1.worldTransform.getTranslation(tmpV1);\n\t\to2.worldTransform.getTranslation(tmpV2);\n\t\tfinal float dst = camera.position.dst2(tmpV1) - camera.position.dst2(tmpV2);\n\t\tfinal int result = dst < 0f ? -1 : (dst > 0f ? 1 : 0);\n\t\treturn b1 ? -result : result;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void dispose () {\n\t\tprogram.dispose();\n\t}","id":36227,"modified_method":"@Override\n\tpublic void dispose () {\n\t\tprogram.dispose();\n\t\tsuper.dispose();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void render (final Renderable renderable) {\n\t\tif (!renderable.material.has(BlendingAttribute.Type))\n\t\t\tcontext.setBlending(false, GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA);\n\t\tsetWorldTransform(renderable.worldTransform);\n\t\tbindMaterial(renderable);\n\t\tif (lighting)\n\t\t\tbindLights(renderable);\n\t\tif (currentMesh != renderable.mesh) {\n\t\t\tif (currentMesh != null)\n\t\t\t\tcurrentMesh.unbind(program);\n\t\t\trenderable.mesh.setAutoBind(false); // FIXME this doesn't belong here\n\t\t\t(currentMesh = renderable.mesh).bind(program);\n\t\t}\n\t\tif (has(u_bones)) {\n\t\t\tfor (int i = 0; i < bones.length; i++) {\n\t\t\t\tfinal int idx = i/16;\n\t\t\t\tbones[i] = (renderable.bones == null || idx >= renderable.bones.length || renderable.bones[idx] == null) ? \n\t\t\t\t\tidtMatrix.val[i%16] : renderable.bones[idx].val[i%16];\n\t\t\t}\n\t\t\tprogram.setUniformMatrix4fv(u_bones.location, bones, 0, bones.length);\n\t\t}\n\t\tsuper.render(renderable);\n\t}","id":36228,"modified_method":"@Override\n\tpublic void render (final Renderable renderable) {\n\t\tif (!renderable.material.has(BlendingAttribute.Type))\n\t\t\tcontext.setBlending(false, GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA);\n\t\tbindMaterial(renderable);\n\t\tif (lighting)\n\t\t\tbindLights(renderable);\n\t\tsuper.render(renderable);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void begin (final Camera camera, final RenderContext context) {\n\t\tsuper.begin(camera, context);\n\t\t// FIXME add DepthTest Material Attribute ?\n\t\tif (defaultDepthFunc == 0)\n\t\t\tcontext.setDepthTest(false, GL10.GL_LEQUAL);\n\t\telse\n\t\t\tcontext.setDepthTest(true, defaultDepthFunc);\n\n\t\tfloat fogDist  = 1.09f / camera.far;\n\t\t\tfogDist *= fogDist;\n\n\t\tset(u_projTrans, camera.combined);\n\t\tset(u_cameraPosition, camera.position.x, camera.position.y, camera.position.z, fogDist);\n\t\tset(u_cameraDirection, camera.direction);\n\t\tset(u_cameraUp, camera.up);\n\t\t\n\t\tfor (final DirectionalLight dirLight : directionalLights)\n\t\t\tdirLight.set(0,0,0,0,-1,0);\n\t\tfor (final PointLight pointLight : pointLights)\n\t\t\tpointLight.set(0,0,0,0,0,0,0);\n\t\tfor (int i = 0; i < bones.length; i++)\n\t\t\tbones[i] = idtMatrix.val[i%16];\n\t}","id":36229,"modified_method":"@Override\n\tpublic void begin (final Camera camera, final RenderContext context) {\n\t\tsuper.begin(camera, context);\n\t\t\n\t\tfor (final DirectionalLight dirLight : directionalLights)\n\t\t\tdirLight.set(0,0,0,0,-1,0);\n\t\tfor (final PointLight pointLight : pointLights)\n\t\t\tpointLight.set(0,0,0,0,0,0,0);\n\t\tlightsSet = false;\n\t\t\n\t\tif (has(u_time))\n\t\t\tset(u_time, time+=Gdx.graphics.getDeltaTime());\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public DefaultShader(final String prefix, final String vertexShader, final String fragmentShader, final long materialMask, final long vertexMask, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(new ShaderProgram(prefix + vertexShader, prefix + fragmentShader), materialMask, vertexMask, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","id":36230,"modified_method":"public DefaultShader(final String vertexShader, final String fragmentShader, final Renderable renderable, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(createPrefix(renderable, lighting, fog, numDirectional, numPoint, numSpot, numBones), \n\t\t\tvertexShader, fragmentShader, renderable, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"private static String createPrefix(final long mask, final long attributes, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tString prefix = \"\";\n\t\tif (((attributes & Usage.Color) == Usage.Color) || ((attributes & Usage.ColorPacked) == Usage.ColorPacked))\n\t\t\tprefix += \"#define colorFlag\\n\";\n\t\tif ((attributes & Usage.Normal) == Usage.Normal) {\n\t\t\tprefix += \"#define normalFlag\\n\";\n\t\t\tif (lighting) {\n\t\t\t\tprefix += \"#define lightingFlag\\n\";\n\t\t\t\tprefix += \"#define ambientCubemapFlag\\n\";\n\t\t\t\tprefix += \"#define numDirectionalLights \"+numDirectional+\"\\n\";\n\t\t\t\tprefix += \"#define numPointLights \"+numPoint+\"\\n\";\n\n                if (fog) {\n                    prefix += \"#define fogFlag\\n\";\n                }\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < blendAttributes.length; i++) {\n\t\t\tif ((attributes & blendAttributes[i]) == blendAttributes[i])\n\t\t\t\tprefix += \"#define boneWeight\"+i+\"Flag\\n\";\n\t\t}\n\t\tif ((attributes & tangentAttribute) == tangentAttribute)\n\t\t\tprefix += \"#define tangentFlag\\n\";\n\t\tif ((attributes & binormalAttribute) == binormalAttribute)\n\t\t\tprefix += \"#define binormalFlag\\n\";\n\t\tif ((mask & BlendingAttribute.Type) == BlendingAttribute.Type)\n\t\t\tprefix += \"#define \"+BlendingAttribute.Alias+\"Flag\\n\";\n\t\tif ((mask & TextureAttribute.Diffuse) == TextureAttribute.Diffuse)\n\t\t\tprefix += \"#define \"+TextureAttribute.DiffuseAlias+\"Flag\\n\";\n\t\t//prefix += \"#define phongFlag\\n\";\n\t\tif ((mask & TextureAttribute.Normal) == TextureAttribute.Normal)\n\t\t\tprefix += \"#define \"+TextureAttribute.NormalAlias+\"Flag\\n\";\n\t\tif ((mask & ColorAttribute.Diffuse) == ColorAttribute.Diffuse)\n\t\t\tprefix += \"#define \"+ColorAttribute.DiffuseAlias+\"Flag\\n\";\n\t\tif ((mask & ColorAttribute.Specular) == ColorAttribute.Specular)\n\t\t\tprefix += \"#define \"+ColorAttribute.SpecularAlias+\"Flag\\n\";\n\t\tif ((mask & FloatAttribute.Shininess) == FloatAttribute.Shininess)\n\t\t\tprefix += \"#define \"+FloatAttribute.ShininessAlias+\"Flag\\n\";\n\t\tif ((mask & FloatAttribute.AlphaTest) == FloatAttribute.AlphaTest)\n\t\t\tprefix += \"#define \"+FloatAttribute.AlphaTestAlias+\"Flag\\n\";\n\t\tif (numBones > 0)\n\t\t\tprefix += \"#define numBones \"+numBones+\"\\n\";\n\t\treturn prefix;\n\t}","id":36231,"modified_method":"private static String createPrefix(final Renderable renderable, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tString prefix = \"\";\n\t\tfinal long mask = renderable.material.getMask();\n\t\tfinal long attributes = renderable.mesh.getVertexAttributes().getMask();\n\t\tif (((attributes & Usage.Color) == Usage.Color) || ((attributes & Usage.ColorPacked) == Usage.ColorPacked))\n\t\t\tprefix += \"#define colorFlag\\n\";\n\t\tif ((attributes & Usage.Normal) == Usage.Normal) {\n\t\t\tprefix += \"#define normalFlag\\n\";\n\t\t\tif (lighting) {\n\t\t\t\tprefix += \"#define lightingFlag\\n\";\n\t\t\t\tprefix += \"#define ambientCubemapFlag\\n\";\n\t\t\t\tprefix += \"#define numDirectionalLights \"+numDirectional+\"\\n\";\n\t\t\t\tprefix += \"#define numPointLights \"+numPoint+\"\\n\";\n\t\t\t\tif (fog) {\n\t \t\t\t\tprefix += \"#define fogFlag\\n\";\n \t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfinal int n = renderable.mesh.getVertexAttributes().size();\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tfinal VertexAttribute attr = renderable.mesh.getVertexAttributes().get(i);\n\t\t\tif (attr.usage == Usage.BoneWeight)\n\t\t\t\tprefix += \"#define boneWeight\"+attr.unit+\"Flag\\n\";\n\t\t}\n\t\tif ((attributes & Usage.Tangent) == Usage.Tangent)\n\t\t\tprefix += \"#define tangentFlag\\n\";\n\t\tif ((attributes & Usage.BiNormal) == Usage.BiNormal)\n\t\t\tprefix += \"#define binormalFlag\\n\";\n\t\tif ((mask & BlendingAttribute.Type) == BlendingAttribute.Type)\n\t\t\tprefix += \"#define \"+BlendingAttribute.Alias+\"Flag\\n\";\n\t\tif ((mask & TextureAttribute.Diffuse) == TextureAttribute.Diffuse)\n\t\t\tprefix += \"#define \"+TextureAttribute.DiffuseAlias+\"Flag\\n\";\n\t\tif ((mask & TextureAttribute.Normal) == TextureAttribute.Normal)\n\t\t\tprefix += \"#define \"+TextureAttribute.NormalAlias+\"Flag\\n\";\n\t\tif ((mask & ColorAttribute.Diffuse) == ColorAttribute.Diffuse)\n\t\t\tprefix += \"#define \"+ColorAttribute.DiffuseAlias+\"Flag\\n\";\n\t\tif ((mask & ColorAttribute.Specular) == ColorAttribute.Specular)\n\t\t\tprefix += \"#define \"+ColorAttribute.SpecularAlias+\"Flag\\n\";\n\t\tif ((mask & FloatAttribute.Shininess) == FloatAttribute.Shininess)\n\t\t\tprefix += \"#define \"+FloatAttribute.ShininessAlias+\"Flag\\n\";\n\t\tif ((mask & FloatAttribute.AlphaTest) == FloatAttribute.AlphaTest)\n\t\t\tprefix += \"#define \"+FloatAttribute.AlphaTestAlias+\"Flag\\n\";\n\t\tif (numBones > 0)\n\t\t\tprefix += \"#define numBones \"+numBones+\"\\n\";\n\t\tGdx.app.log(\"Prefix\",\"\\n\"+prefix);\n\t\treturn prefix;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"private final void bindMaterial(final Renderable renderable) {\n\t\tif (currentMaterial == renderable.material)\n\t\t\treturn;\n\t\tint cullFace = defaultCullFace;\n\t\tcurrentMaterial = renderable.material;\n\t\tfor (final Material.Attribute attr : currentMaterial) {\n\t\t\tfinal long t = attr.type;\n\t\t\tif (BlendingAttribute.is(t)) {\n\t\t\t\tcontext.setBlending(true, ((BlendingAttribute)attr).sourceFunction, ((BlendingAttribute)attr).destFunction);\n\t\t\t\tset(u_opacity, ((BlendingAttribute)attr).opacity);\n\t\t\t} else if (ColorAttribute.is(t)) {\n\t\t\t\tColorAttribute col = (ColorAttribute)attr;\n\t\t\t\tif ((t & ColorAttribute.Diffuse) == ColorAttribute.Diffuse)\n\t\t\t\t\tset(u_diffuseColor, col.color);\n\t\t\t\telse if ((t & ColorAttribute.Specular) == ColorAttribute.Specular)\n\t\t\t\t\tset(u_specularColor, col.color);\n\t\t\t}\n\t\t\telse if (TextureAttribute.is(t)) {\n\t\t\t\tfinal TextureAttribute tex = (TextureAttribute)attr;\n\t\t\t\tif ((t & TextureAttribute.Diffuse) == TextureAttribute.Diffuse && has(u_diffuseTexture))\n\t\t\t\t\tbindTextureAttribute(u_diffuseTexture.location, tex);\n\t\t\t\tif ((t & TextureAttribute.Normal) == TextureAttribute.Normal && has(u_normalTexture))\n\t\t\t\t\tbindTextureAttribute(u_normalTexture.location, tex);\n\t\t\t\t// TODO else if (..)\n\t\t\t}\n\t\t\telse if ((t & FloatAttribute.Shininess) == FloatAttribute.Shininess)\n\t\t\t\tset(u_shininess, ((FloatAttribute)attr).value);\n\t\t\telse if ((t & IntAttribute.CullFace) == IntAttribute.CullFace)\n\t\t\t\tcullFace = ((IntAttribute)attr).value;\n\t\t\telse if ((t & FloatAttribute.AlphaTest) == FloatAttribute.AlphaTest)\n\t\t\t\tset(u_alphaTest, ((FloatAttribute)attr).value);\n            else if(!ignoreUnimplemented)\n\t\t\t\t\tthrow new GdxRuntimeException(\"Unknown material attribute: \"+attr.toString());\n\t\t}\n\t\tcontext.setCullFace(cullFace);\n\t}","id":36232,"modified_method":"private final void bindMaterial(final Renderable renderable) {\n\t\tif (currentMaterial == renderable.material)\n\t\t\treturn;\n\t\t\n\t\tint cullFace = defaultCullFace;\n\t\tint depthFunc = defaultDepthFunc;\n\t\tfloat depthRangeNear = 0f;\n\t\tfloat depthRangeFar = 1f;\n\t\tboolean depthMask = true;\n\t\t\n\t\tcurrentMaterial = renderable.material;\n\t\tfor (final Material.Attribute attr : currentMaterial) {\n\t\t\tfinal long t = attr.type;\n\t\t\tif (BlendingAttribute.is(t)) {\n\t\t\t\tcontext.setBlending(true, ((BlendingAttribute)attr).sourceFunction, ((BlendingAttribute)attr).destFunction);\n\t\t\t\tset(u_opacity, ((BlendingAttribute)attr).opacity);\n\t\t\t}\n\t\t\telse if ((t & IntAttribute.CullFace) == IntAttribute.CullFace)\n\t\t\t\tcullFace = ((IntAttribute)attr).value;\n\t\t\telse if ((t & FloatAttribute.AlphaTest) == FloatAttribute.AlphaTest)\n\t\t\t\tset(u_alphaTest, ((FloatAttribute)attr).value);\n\t\t\telse if ((t & DepthTestAttribute.Type) == DepthTestAttribute.Type) {\n\t\t\t\tDepthTestAttribute dta = (DepthTestAttribute)attr;\n\t\t\t\tdepthFunc = dta.depthFunc;\n\t\t\t\tdepthRangeNear = dta.depthRangeNear;\n\t\t\t\tdepthRangeFar = dta.depthRangeFar;\n\t\t\t\tdepthMask = dta.depthMask;\n\t\t\t}\n\t\t\telse if(!ignoreUnimplemented)\n\t\t\t\tthrow new GdxRuntimeException(\"Unknown material attribute: \"+attr.toString());\n\t\t}\n\t\t\n\t\tcontext.setCullFace(cullFace);\n\t\tcontext.setDepthTest(depthFunc, depthRangeNear, depthRangeFar, depthMask);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public DefaultShader(final String vertexShader, final String fragmentShader, final long materialMask, final long vertexMask, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(createPrefix(materialMask, vertexMask, lighting, fog, numDirectional, numPoint, numSpot, numBones), \n\t\t\tvertexShader, fragmentShader, materialMask, vertexMask, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","id":36233,"modified_method":"public DefaultShader(final String prefix, final String vertexShader, final String fragmentShader, final Renderable renderable, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(new ShaderProgram(prefix + vertexShader, prefix + fragmentShader), renderable, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void end () {\n\t\tif (currentMesh != null) {\n\t\t\tcurrentMesh.unbind(program);\n\t\t\tcurrentMesh = null;\n\t\t}\n\t\tcurrentTextureAttribute = null;\n\t\tcurrentMaterial = null;\n\t\tsuper.end();\n\t}","id":36234,"modified_method":"@Override\n\tpublic void end () {\n\t\tcurrentMaterial = null;\n\t\tsuper.end();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"private final void bindLights(final Renderable renderable) {\n\t\tfinal Lights lights = renderable.lights;\n\t\tfinal Array<DirectionalLight> dirs = lights.directionalLights; \n\t\tfinal Array<PointLight> points = lights.pointLights;\n\t\t\n\t\tif (has(u_ambientCubemap)) {\n\t\t\trenderable.worldTransform.getTranslation(tmpV1);\n\t\t\tambientCubemap.set(lights.ambientLight);\n\t\t\t\n\t\t\tfor (int i = directionalLights.length; i < dirs.size; i++)\n\t\t\t\tambientCubemap.add(dirs.get(i).color, dirs.get(i).direction);\n\t\t\t\n\t\t\tfor (int i = pointLights.length; i < points.size; i++)\n\t\t\t\tambientCubemap.add(points.get(i).color, points.get(i).position, tmpV1, points.get(i).intensity);\n\t\t\t\n\t\t\tambientCubemap.clamp();\n\t\t\t\n\t\t\tprogram.setUniform3fv(u_ambientCubemap.location, ambientCubemap.data, 0, ambientCubemap.data.length);\n\t\t}\n\t\t\n\t\tif (dirLightsLoc >= 0) {\n\t\t\tfor (int i = 0; i < directionalLights.length; i++) {\n\t\t\t\tif (dirs == null || i >= dirs.size) {\n\t\t\t\t\tif (directionalLights[i].color.r == 0f && directionalLights[i].color.g == 0f && directionalLights[i].color.b == 0f)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tdirectionalLights[i].color.set(0,0,0,1);\n\t\t\t\t} else if (directionalLights[i].equals(dirs.get(i)))\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t\tdirectionalLights[i].set(dirs.get(i));\n\t\t\t\t\n\t\t\t\tint idx = dirLightsLoc + i * dirLightsSize; \n\t\t\t\tprogram.setUniformf(idx+dirLightsColorOffset, directionalLights[i].color.r, directionalLights[i].color.g, directionalLights[i].color.b);\n\t\t\t\tprogram.setUniformf(idx+dirLightsDirectionOffset, directionalLights[i].direction);\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (pointLightsLoc >= 0) {\n\t\t\tfor (int i = 0; i < pointLights.length; i++) {\n\t\t\t\tif (points == null || i >= points.size) {\n\t\t\t\t\tif (pointLights[i].intensity == 0f)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tpointLights[i].intensity = 0f;\n\t\t\t\t} else if (pointLights[i].equals(points.get(i)))\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t\tpointLights[i].set(points.get(i));\n\t\t\t\t\n\t\t\t\tint idx = pointLightsLoc + i * pointLightsSize;\n\t\t\t\tprogram.setUniformf(idx+pointLightsColorOffset, pointLights[i].color.r, pointLights[i].color.g, pointLights[i].color.b);\n\t\t\t\tprogram.setUniformf(idx+pointLightsPositionOffset, pointLights[i].position);\n\t\t\t\tif (pointLightsIntensityOffset >= 0)\n\t\t\t\t\tprogram.setUniformf(idx+pointLightsIntensityOffset, pointLights[i].intensity);\n\t\t\t}\n\t\t}\n\n        if (lights.fog != null) {\n            program.setUniformf(u_fogColor.location, lights.fog);\n        }\n\t}","id":36235,"modified_method":"private final void bindLights(final Renderable renderable) {\n\t\tfinal Lights lights = renderable.lights;\n\t\tfinal Array<DirectionalLight> dirs = lights.directionalLights; \n\t\tfinal Array<PointLight> points = lights.pointLights;\n\t\t\n\t\tif (dirLightsLoc >= 0) {\n\t\t\tfor (int i = 0; i < directionalLights.length; i++) {\n\t\t\t\tif (dirs == null || i >= dirs.size) {\n\t\t\t\t\tif (lightsSet && directionalLights[i].color.r == 0f && directionalLights[i].color.g == 0f && directionalLights[i].color.b == 0f)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tdirectionalLights[i].color.set(0,0,0,1);\n\t\t\t\t} else if (lightsSet && directionalLights[i].equals(dirs.get(i)))\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t\tdirectionalLights[i].set(dirs.get(i));\n\t\t\t\t\n\t\t\t\tint idx = dirLightsLoc + i * dirLightsSize; \n\t\t\t\tprogram.setUniformf(idx+dirLightsColorOffset, directionalLights[i].color.r, directionalLights[i].color.g, directionalLights[i].color.b);\n\t\t\t\tprogram.setUniformf(idx+dirLightsDirectionOffset, directionalLights[i].direction);\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (pointLightsLoc >= 0) {\n\t\t\tfor (int i = 0; i < pointLights.length; i++) {\n\t\t\t\tif (points == null || i >= points.size) {\n\t\t\t\t\tif (lightsSet && pointLights[i].intensity == 0f)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tpointLights[i].intensity = 0f;\n\t\t\t\t} else if (lightsSet && pointLights[i].equals(points.get(i)))\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t\tpointLights[i].set(points.get(i));\n\n\t\t\t\tint idx = pointLightsLoc + i * pointLightsSize;\n\t\t\t\tprogram.setUniformf(idx+pointLightsColorOffset, pointLights[i].color.r, pointLights[i].color.g, pointLights[i].color.b);\n\t\t\t\tprogram.setUniformf(idx+pointLightsPositionOffset, pointLights[i].position);\n\t\t\t\tif (pointLightsIntensityOffset >= 0)\n\t\t\t\t\tprogram.setUniformf(idx+pointLightsIntensityOffset, pointLights[i].intensity);\n\t\t\t}\n\t\t}\n\n\t\tif (lights.fog != null) {\n\t\t\tset(u_fogColor, lights.fog);\n\t\t}\n\t\tlightsSet = true;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic boolean canRender(final Renderable renderable) {\n\t\treturn materialMask == renderable.material.getMask() && \n\t\t\tvertexMask == getAttributesMask(renderable.mesh.getVertexAttributes()) && \n\t\t\t(renderable.lights != null) == lighting &&\n            ((renderable.lights != null && renderable.lights.fog != null) == fog);\n\t}","id":36236,"modified_method":"@Override\n\tpublic boolean canRender(final Renderable renderable) {\n\t\treturn (materialMask == (renderable.material.getMask() | optionalAttributes)) && \n\t\t\t(vertexMask == renderable.mesh.getVertexAttributes().getMask()) && \n\t\t\t(renderable.lights != null) == lighting &&\n            ((renderable.lights != null && renderable.lights.fog != null) == fog);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void init () {\n\t\tfinal ShaderProgram program = this.program;\n\t\tthis.program = null;\n\t\tinit(program, materialMask, vertexMask, 0);\n\t\t\n\t\tdirLightsLoc \t\t\t\t\t= u_dirLights0color.location;\n\t\tdirLightsColorOffset\t\t\t= u_dirLights0color.location - dirLightsLoc;\n\t\tdirLightsDirectionOffset \t= u_dirLights0direction.location - dirLightsLoc;\n\t\tdirLightsSize \t\t\t\t\t= u_dirLights1color.location - dirLightsLoc;\n\t\t\n\t\tpointLightsLoc \t\t\t\t= u_pointLights0color.location;\n\t\tpointLightsColorOffset \t\t= u_pointLights0color.location - pointLightsLoc;\n\t\tpointLightsPositionOffset \t= u_pointLights0position.location - pointLightsLoc;\n\t\tpointLightsIntensityOffset = u_pointLights0intensity.location - pointLightsLoc;\n\t\tpointLightsSize \t\t\t\t= u_pointLights1color.location - pointLightsLoc;\n\t}","id":36237,"modified_method":"@Override\n\tpublic void init () {\n\t\tfinal ShaderProgram program = this.program;\n\t\tthis.program = null;\n\t\tinit(program, renderable);\n\t\trenderable = null;\n\t\t\n\t\tdirLightsLoc \t\t\t\t\t= loc(u_dirLights0color);\n\t\tdirLightsColorOffset\t\t\t= loc(u_dirLights0color) - dirLightsLoc;\n\t\tdirLightsDirectionOffset \t= loc(u_dirLights0direction) - dirLightsLoc;\n\t\tdirLightsSize \t\t\t\t\t= loc(u_dirLights1color) - dirLightsLoc;\n\t\t\n\t\tpointLightsLoc \t\t\t\t= loc(u_pointLights0color);\n\t\tpointLightsColorOffset \t\t= loc(u_pointLights0color) - pointLightsLoc;\n\t\tpointLightsPositionOffset \t= loc(u_pointLights0position) - pointLightsLoc;\n\t\tpointLightsIntensityOffset = loc(u_pointLights0intensity) - pointLightsLoc;\n\t\tpointLightsSize \t\t\t\t= loc(u_pointLights1color) - pointLightsLoc;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public DefaultShader(final ShaderProgram shaderProgram, final long materialMask, final long vertexMask, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis.program = shaderProgram;\n\t\tthis.lighting = lighting;\n\t\tthis.fog = fog;\n\t\tthis.materialMask = materialMask;\n\t\tthis.vertexMask = vertexMask;\n\t\t\n\t\tthis.directionalLights = new DirectionalLight[lighting && numDirectional > 0 ? numDirectional : 0];\n\t\tfor (int i = 0; i < directionalLights.length; i++)\n\t\t\tdirectionalLights[i] = new DirectionalLight();\n\t\tthis.pointLights = new PointLight[lighting && numPoint > 0 ? numPoint : 0];\n\t\tfor (int i = 0; i < pointLights.length; i++)\n\t\t\tpointLights[i] = new PointLight();\n\t\tbones = new float[numBones > 0 ? numBones * 16 : 0];\n\t\t\t\t\n\t\tif (!ignoreUnimplemented && (implementedFlags & materialMask) != materialMask)\n\t\t\tthrow new GdxRuntimeException(\"Some attributes not implemented yet (\"+materialMask+\")\");\n\t}","id":36238,"modified_method":"public DefaultShader(final ShaderProgram shaderProgram, final Renderable renderable, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis.program = shaderProgram;\n\t\tthis.lighting = lighting;\n\t\tthis.fog = fog;\n\t\tthis.renderable = renderable;\n\t\tmaterialMask = renderable.material.getMask() | optionalAttributes;\n\t\tvertexMask = renderable.mesh.getVertexAttributes().getMask();\n\n\t\tthis.directionalLights = new DirectionalLight[lighting && numDirectional > 0 ? numDirectional : 0];\n\t\tfor (int i = 0; i < directionalLights.length; i++)\n\t\t\tdirectionalLights[i] = new DirectionalLight();\n\t\tthis.pointLights = new PointLight[lighting && numPoint > 0 ? numPoint : 0];\n\t\tfor (int i = 0; i < pointLights.length; i++)\n\t\t\tpointLights[i] = new PointLight();\n\n\t\tif (!ignoreUnimplemented && (implementedFlags & materialMask) != materialMask)\n\t\t\tthrow new GdxRuntimeException(\"Some attributes not implemented yet (\"+materialMask+\")\");\n\t\t\n\t\t// Global uniforms\n\t\tu_projTrans\t\t\t\t= register(Inputs.projTrans, Setters.projTrans);\n\t\tu_cameraPosition\t\t= register(Inputs.cameraPosition, Setters.cameraPosition);\n\t\tu_cameraDirection\t\t= register(Inputs.cameraDirection, Setters.cameraDirection);\n\t\tu_cameraUp\t\t\t\t= register(Inputs.cameraUp, Setters.cameraUp);\n\t\tu_time\t\t\t\t\t= register(new Uniform(\"u_time\"));\n\t\t// Object uniforms\n\t\tu_worldTrans\t\t\t= register(Inputs.worldTrans, Setters.worldTrans);\n\t\tu_normalMatrix\t\t\t= register(Inputs.normalMatrix, Setters.normalMatrix);\n\t\tu_bones \t\t\t\t\t= numBones > 0 ? register(Inputs.bones, new Setters.Bones(numBones)) : -1;\n\t\t\n\t\tu_shininess\t\t\t\t= register(Inputs.shininess, Setters.shininess);\n\t\tu_opacity \t\t\t\t= register(Inputs.opacity);\n\t\tu_diffuseColor\t\t\t= register(Inputs.diffuseColor, Setters.diffuseColor);\n\t\tu_diffuseTexture\t\t= register(Inputs.diffuseTexture, Setters.diffuseTexture);\n\t\tu_specularColor\t\t= register(Inputs.specularColor, Setters.specularColor);\n\t\tu_specularTexture\t\t= register(Inputs.specularTexture, Setters.specularTexture);\n\t\tu_normalTexture\t\t= register(Inputs.normalTexture);\n\t\tu_alphaTest\t\t\t\t= register(Inputs.alphaTest);\n\t\t\n\t\tu_ambientCubemap\t\t= lighting ? register(Inputs.ambientCube, new Setters.ACubemap(numDirectional, numPoint)) : -1;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public DefaultShader(final long materialMask, final long vertexMask, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(getDefaultVertexShader(), getDefaultFragmentShader(), materialMask, vertexMask, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","id":36239,"modified_method":"public DefaultShader(final Renderable renderable, boolean lighting, boolean fog, int numDirectional, int numPoint, int numSpot, int numBones) {\n\t\tthis(getDefaultVertexShader(), getDefaultFragmentShader(), renderable, lighting, fog, numDirectional, numPoint, numSpot, numBones);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tprotected Shader createShader(final Renderable renderable) {\n\t\tGdx.app.log(\"DefaultShaderProvider\", \"Creating new shader\");\n\t\tif (Gdx.graphics.isGL20Available()) {\n            return new DefaultShader(vertexShader, fragmentShader, renderable.material, renderable.mesh.getVertexAttributes(), renderable.lights != null, renderable.lights != null && renderable.lights.fog != null, 2, 5, 3, renderable.bones == null ? 0 : 12);\n        }\n\t\treturn new GLES10Shader();\n\t}","id":36240,"modified_method":"@Override\n\tprotected Shader createShader(final Renderable renderable) {\n\t\tGdx.app.log(\"DefaultShaderProvider\", \"Creating new shader\");\n\t\tif (Gdx.graphics.isGL20Available()) {\n            return new DefaultShader(vertexShader, fragmentShader, renderable, renderable.lights != null, renderable.lights != null && renderable.lights.fog != null, 2, 5, 3, renderable.bones == null ? 0 : 12);\n        }\n\t\treturn new GLES10Shader();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Uses all remaining texture units and reuse weight of 3 */\n\tpublic DefaultTextureBinder(final int method, final int offset) {\n\t\tthis(method, offset,  Math.min(getMaxTextureUnits(), MAX_GLES_UNITS) - offset);\n\t}","id":36241,"modified_method":"/** Uses all remaining texture units and reuse weight of 3 */\n\tpublic DefaultTextureBinder(final int method, final int offset) {\n\t\tthis(method, offset,  -1);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public DefaultTextureBinder(final int method, final int offset, final int count, final int reuseWeight) {\n\t\tfinal int max = Math.min(getMaxTextureUnits(), MAX_GLES_UNITS);\n\t\tif (offset < 0 || count < 0 || (offset + count) > max || reuseWeight < 1)\n\t\t\tthrow new GdxRuntimeException(\"Illegal arguments\");\n\t\tthis.method = method;\n\t\tthis.offset = offset;\n\t\tthis.count = count;\n\t\tthis.textures = new TextureDescriptor[count];\n\t\tfor (int i = 0; i < count; i++)\n\t\t\tthis.textures[i] = new TextureDescriptor();\n\t\tthis.reuseWeight = reuseWeight;\n\t\tthis.weights = (method == WEIGHTED) ? new int[count] : null;\n\t}","id":36242,"modified_method":"public DefaultTextureBinder(final int method, final int offset, int count, final int reuseWeight) {\n\t\tfinal int max = Math.min(getMaxTextureUnits(), MAX_GLES_UNITS);\n\t\tif (count < 0)\n\t\t\tcount = max - offset;\n\t\tif (offset < 0 || count < 0 || (offset + count) > max || reuseWeight < 1)\n\t\t\tthrow new GdxRuntimeException(\"Illegal arguments\");\n\t\tthis.method = method;\n\t\tthis.offset = offset;\n\t\tthis.count = count;\n\t\tthis.textures = new TextureDescriptor[count];\n\t\tfor (int i = 0; i < count; i++)\n\t\t\tthis.textures[i] = new TextureDescriptor();\n\t\tthis.reuseWeight = reuseWeight;\n\t\tthis.weights = (method == WEIGHTED) ? new int[count] : null;\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void begin (final Camera camera, final RenderContext context) {\n\t\tthis.context = context;\n\t\tthis.camera = camera;\n\t\tcontext.setDepthTest(true, GL10.GL_LEQUAL);\n\t\tGdx.gl10.glMatrixMode(GL10.GL_PROJECTION);\n\t\tGdx.gl10.glLoadMatrixf(camera.combined.val, 0);\n\t\tGdx.gl10.glMatrixMode(GL10.GL_MODELVIEW);\n\t}","id":36243,"modified_method":"@Override\n\tpublic void begin (final Camera camera, final RenderContext context) {\n\t\tthis.context = context;\n\t\tthis.camera = camera;\n\t\tcontext.setDepthTest(GL10.GL_LEQUAL, 0, 1, true);\n\t\tGdx.gl10.glMatrixMode(GL10.GL_PROJECTION);\n\t\tGdx.gl10.glLoadMatrixf(camera.combined.val, 0);\n\t\tGdx.gl10.glMatrixMode(GL10.GL_MODELVIEW);\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"/**\n\t * Sets up the render context, must be matched with a call to {@link #end()}. Assumes\n\t * that the OpenGL states are in their defaults.\n\t */\n\tpublic final void begin() {\n\t\tGdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\tdepthTest = false;\n\t\tGdx.gl.glDisable(GL10.GL_BLEND);\n\t\tblending = false;\n\t\tGdx.gl.glDisable(GL10.GL_CULL_FACE);\n\t\tcullFace = blendSFactor = blendDFactor = depthFunc = 0;\n\t\ttextureBinder.begin();\n\t}","id":36244,"modified_method":"/**\n\t * Sets up the render context, must be matched with a call to {@link #end()}. Assumes\n\t * that the OpenGL states are in their defaults.\n\t */\n\tpublic final void begin() {\n\t\tGdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\tdepthFunc = 0;\n\t\tGdx.gl.glDisable(GL10.GL_BLEND);\n\t\tblending = false;\n\t\tGdx.gl.glDisable(GL10.GL_CULL_FACE);\n\t\tcullFace = blendSFactor = blendDFactor;\n\t\ttextureBinder.begin();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"/**\n\t * Resest all changed OpenGL states to their defaults.\n\t */\n\tpublic final void end() {\n\t\tif(depthTest) Gdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\tif(blending) Gdx.gl.glDisable(GL10.GL_BLEND);\n\t\tif(cullFace>0) Gdx.gl.glDisable(GL10.GL_CULL_FACE);\n\t\ttextureBinder.end();\n\t}","id":36245,"modified_method":"/**\n\t * Resest all changed OpenGL states to their defaults.\n\t */\n\tpublic final void end() {\n\t\tif(depthFunc != 0) Gdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\tif(blending) Gdx.gl.glDisable(GL10.GL_BLEND);\n\t\tif(cullFace>0) Gdx.gl.glDisable(GL10.GL_CULL_FACE);\n\t\ttextureBinder.end();\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"public final void setDepthTest(final boolean enabled, final int depthFunction) {\n\t\tif (enabled != depthTest) {\n\t\t\tdepthTest = enabled;\n\t\t\tif (enabled)\n\t\t\t\tGdx.gl.glEnable(GL10.GL_DEPTH_TEST);\n\t\t\telse\n\t\t\t\tGdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\t}\n\t\tif (enabled && depthFunc != depthFunction) {\n\t\t\tGdx.gl.glDepthFunc(depthFunction);\n\t\t\tdepthFunc = depthFunction;\n\t\t}\n\t}","id":36246,"modified_method":"public final void setDepthTest(final int depthFunction, final float depthRangeNear, final float depthRangeFar, final boolean depthMask) {\n\t\tfinal boolean wasEnabled = depthFunc != 0;\n\t\tfinal boolean enabled = depthFunction != 0;\n\t\tif (depthFunc != depthFunction) {\n\t\t\tdepthFunc = depthFunction;\n\t\t\tif (enabled) {\n\t\t\t\tGdx.gl.glEnable(GL10.GL_DEPTH_TEST);\n\t\t\t\tGdx.gl.glDepthFunc(depthFunction);\n\t\t\t} else\n\t\t\t\tGdx.gl.glDisable(GL10.GL_DEPTH_TEST);\n\t\t}\n\t\tif (enabled) {\n\t\t\tif (!wasEnabled || depthFunc != depthFunction)\n\t\t\t\tGdx.gl.glDepthFunc(depthFunc = depthFunction);\n\t\t\tif (!wasEnabled || this.depthRangeNear != depthRangeNear || this.depthRangeFar != depthRangeFar)\n\t\t\t\tGdx.gl.glDepthRangef(this.depthRangeNear = depthRangeNear, this.depthRangeFar = depthRangeFar);\n\t\t\tif (!wasEnabled || this.depthMask != depthMask)\n\t\t\t\tGdx.gl.glDepthMask(this.depthMask = depthMask);\n\t\t}\n\t}","commit_id":"1a43bc39bc4599d581bffdfefd0fab3270247fc8","url":"https://github.com/libgdx/libgdx"},{"original_method":"private void fillBuffers( GL20 gl )\r\n\t{\t\t\t\t\r\n\t\tgl.glBindBuffer( GL20.GL_ARRAY_BUFFER, vertexBufferObjectHandle );\r\n\t\tgl.glBufferSubData( GL20.GL_ARRAY_BUFFER, 0, getNumVertices() * attributes.vertexSize, vertices );\r\n\t\tgl.glBindBuffer( GL20.GL_ARRAY_BUFFER, 0 );\r\n\t\t\r\n\t\tif( maxIndices > 0 )\r\n\t\t{\r\n\t\t\tgl.glBindBuffer( GL20.GL_ELEMENT_ARRAY_BUFFER, indexBufferObjectHandle );\r\n\t\t\tgl.glBufferSubData( GL20.GL_ELEMENT_ARRAY_BUFFER, 0, indices.limit() * 2, indices );\r\n\t\t\tgl.glBindBuffer( GL20.GL_ELEMENT_ARRAY_BUFFER, 0 );\r\n\t\t}\r\n\t}","id":36247,"modified_method":"private void fillBuffers( GL20 gl )\r\n\t{\t\t\t\t\r\n\t\tgl.glBindBuffer( GL20.GL_ARRAY_BUFFER, vertexBufferObjectHandle );\r\n\t\tif( Gdx.graphics.getType() == GraphicsType.AndroidGL )\r\n\t\t\tgl.glBufferData( GL20.GL_ARRAY_BUFFER, getNumVertices() * attributes.vertexSize, vertices, isStatic?GL20.GL_STATIC_DRAW:GL20.GL_DYNAMIC_DRAW);\r\n\t\telse\r\n\t\t\tgl.glBufferSubData( GL20.GL_ARRAY_BUFFER, 0, getNumVertices() * attributes.vertexSize, vertices );\t\t\r\n\t\tgl.glBindBuffer( GL20.GL_ARRAY_BUFFER, 0 );\r\n\t\t\r\n\t\tif( maxIndices > 0 )\r\n\t\t{\r\n\t\t\tgl.glBindBuffer( GL20.GL_ELEMENT_ARRAY_BUFFER, indexBufferObjectHandle );\r\n\t\t\tif( Gdx.graphics.getType() == GraphicsType.AndroidGL )\r\n\t\t\t\tgl.glBufferData( GL20.GL_ELEMENT_ARRAY_BUFFER, indices.limit() * 2, indices, isStatic?GL20.GL_STATIC_DRAW:GL20.GL_DYNAMIC_DRAW );\r\n\t\t\telse\r\n\t\t\t\tgl.glBufferSubData( GL20.GL_ELEMENT_ARRAY_BUFFER, 0, indices.limit() * 2, indices );\t\t\t\r\n\t\t\tgl.glBindBuffer( GL20.GL_ELEMENT_ARRAY_BUFFER, 0 );\r\n\t\t}\r\n\t}","commit_id":"1cf22df9e61f093b9f9278dd1c35dc33e36779d3","url":"https://github.com/libgdx/libgdx"},{"original_method":"protected void renderMesh( )\r\n\t{\r\n\t\tif( idx == 0 )\r\n\t\t\treturn;\r\n\t\t\t\r\n\t\trenderCalls++;\r\n\t\t\r\n\t\tlastTexture.bind();\t\t\r\n\t\tmesh.setVertices(vertices, 0, idx);\t\r\n\t\tif( Gdx.graphics.isGL20Available() )\r\n\t\t{\r\n\t\t\tif( useTextBlend )\r\n\t\t\t{\r\n\t\t\t\tGdx.graphics.getGL20().glBlendFunc( GL20.GL_ONE, GL20.GL_ONE_MINUS_SRC_ALPHA );\r\n\t\t\t\tif( blendingDisabled )\r\n\t\t\t\t\tGdx.graphics.getGL20().glEnable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t\tGdx.graphics.getGL20().glBlendFunc( blendSrcFunc, blendDstFunc );\r\n\t\t\tmesh.render( shader, GL10.GL_TRIANGLES );\r\n\t\t\tif( useTextBlend && blendingDisabled )\r\n\t\t\t{\t\t\t\t\r\n\t\t\t\tGdx.graphics.getGL20().glDisable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tif( useTextBlend )\r\n\t\t\t{\r\n\t\t\t\tGdx.graphics.getGL10().glBlendFunc( GL20.GL_ONE, GL20.GL_ONE_MINUS_SRC_ALPHA );\r\n\t\t\t\tif( blendingDisabled )\r\n\t\t\t\t\tGdx.graphics.getGL10().glEnable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t\tGdx.graphics.getGL10().glBlendFunc( blendSrcFunc, blendDstFunc );\r\n\t\t\tmesh.render( GL10.GL_TRIANGLES );\r\n\t\t\tif( useTextBlend && blendingDisabled )\r\n\t\t\t{\t\t\t\t\r\n\t\t\t\tGdx.graphics.getGL10().glDisable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\t\t}\r\n\t\tidx = 0;\r\n\t}","id":36248,"modified_method":"protected void renderMesh( )\r\n\t{\r\n\t\tif( idx == 0 )\r\n\t\t\treturn;\r\n\t\t\t\r\n\t\trenderCalls++;\r\n\t\t\r\n\t\tlastTexture.bind();\t\t\r\n\t\tmesh.setVertices(vertices, 0, idx);\t\r\n\t\t\r\n\t\tif( Gdx.graphics.isGL20Available() )\r\n\t\t{\r\n\t\t\tif( useTextBlend )\r\n\t\t\t{\r\n\t\t\t\tGdx.graphics.getGL20().glBlendFunc( GL20.GL_ONE, GL20.GL_ONE_MINUS_SRC_ALPHA );\r\n\t\t\t\tGdx.graphics.getGL20().glEnable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\tif( blendingDisabled )\r\n\t\t\t\t{\r\n\t\t\t\t\tGdx.graphics.getGL20().glDisable( GL20.GL_BLEND );\r\n\t\t\t\t}\r\n\t\t\t\telse\r\n\t\t\t\t{\r\n\t\t\t\t\tGdx.graphics.getGL20().glEnable( GL20.GL_BLEND );\r\n\t\t\t\t\tGdx.graphics.getGL20().glBlendFunc( blendSrcFunc, blendDstFunc );\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tmesh.render( shader, GL10.GL_TRIANGLES );\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tif( useTextBlend )\r\n\t\t\t{\r\n\t\t\t\tGdx.graphics.getGL10().glBlendFunc( GL10.GL_ONE, GL10.GL_ONE_MINUS_SRC_ALPHA );\r\n\t\t\t\tGdx.graphics.getGL10().glEnable( GL10.GL_BLEND );\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\tif( blendingDisabled )\r\n\t\t\t\t{\r\n\t\t\t\t\tGdx.graphics.getGL10().glDisable( GL10.GL_BLEND );\r\n\t\t\t\t}\r\n\t\t\t\telse\r\n\t\t\t\t{\r\n\t\t\t\t\tGdx.graphics.getGL10().glEnable( GL10.GL_BLEND );\r\n\t\t\t\t\tGdx.graphics.getGL10().glBlendFunc( blendSrcFunc, blendDstFunc );\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tmesh.render( GL10.GL_TRIANGLES );\r\n\t\t}\r\n\t\tidx = 0;\r\n\t}","commit_id":"1cf22df9e61f093b9f9278dd1c35dc33e36779d3","url":"https://github.com/libgdx/libgdx"},{"original_method":"/**\r\n\t * Sets up the SpriteBatch for drawing. This will disable\r\n\t * depth buffer testing and writting, culling and lighting.\r\n\t * It enables blending and alpha testing. If you have more texture units enabled than\r\n\t * the first one you have to disable them before calling this. Applies\r\n\t * the given transformation {@link Matrix} to all subsequently specified sprites. Uses\r\n\t * the provided projection matrix and therefore does not necessarily work\r\n\t * in screen coordinates anymore. You have to know what you do if you use this.\r\n\t * \r\n\t * @param projection the projection matrix;\r\n\t * @param transform the transformation matrix.\r\n\t */\r\n\tpublic void begin( Matrix projection, Matrix transform )\r\n\t{\r\n\t\trenderCalls = 0;\r\n\t\tif( Gdx.graphics.isGL20Available() == false )\r\n\t\t{\t\t\t\t\t\t\t\t\t\t\r\n\t\t\tGL10 gl = Gdx.graphics.getGL10();\r\n\t\t\tgl.glViewport( 0, 0, Gdx.graphics.getWidth(), Gdx.graphics.getHeight() );\r\n\t\t\tgl.glDisable( GL10.GL_LIGHTING );\r\n\t\t\tgl.glDisable( GL10.GL_DEPTH_TEST );\r\n\t\t\tgl.glDisable( GL10.GL_CULL_FACE );\r\n\t\t\tgl.glDepthMask ( false );\r\n\t\t\t\r\n\t\t\tgl.glEnable( GL10.GL_TEXTURE_2D );\r\n\t\t\t//gl.glActiveTexture( GL10.GL_TEXTURE0 );\r\n\t\t\t\r\n\t\t\tif( !blendingDisabled )\r\n\t\t\t{\r\n\t\t\t\tgl.glEnable( GL10.GL_BLEND );\r\n\t\t\t\tgl.glBlendFunc( GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA );\t\t\t\t\t\t\t\r\n\t\t\t}\t\t\t\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\tgl.glDisable( GL10.GL_BLEND );\t\t\t\t\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tgl.glMatrixMode( GL10.GL_PROJECTION );\r\n\t\t\tgl.glLoadMatrixf( projection.val, 0 );\r\n\t\t\tgl.glMatrixMode( GL10.GL_MODELVIEW );\r\n\t\t\tgl.glLoadMatrixf( transform.val, 0 );\r\n\t\t}\t\t\r\n\t\telse\r\n\t\t{\r\n\t\t\tviewMatrix.set(projection).mul(transform);\r\n\r\n\t\t\tGL20 gl = Gdx.graphics.getGL20();\r\n\t\t\tgl.glViewport( 0, 0, Gdx.graphics.getWidth(), Gdx.graphics.getHeight() );\r\n\t\t\tgl.glDisable( GL20.GL_DEPTH_TEST );\r\n\t\t\tgl.glDisable( GL20.GL_CULL_FACE );\r\n\t\t\tgl.glDepthMask ( false );\r\n\r\n\t\t\tgl.glEnable( GL20.GL_TEXTURE_2D );\r\n\t\t\t//gl.glActiveTexture( GL20.GL_TEXTURE0 );\r\n\r\n\t\t\tif( !blendingDisabled )\r\n\t\t\t{\r\n\t\t\t\tgl.glEnable( GL20.GL_BLEND );\r\n\t\t\t\tgl.glBlendFunc( GL20.GL_SRC_ALPHA, GL20.GL_ONE_MINUS_SRC_ALPHA );\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\tgl.glDisable( GL20.GL_BLEND );\r\n\t\t\t}\r\n\r\n\t\t\tshader.begin();\r\n\t\t\tshader.setUniformMatrix( \"u_projectionViewMatrix\", viewMatrix );\r\n\t\t\tshader.setUniformi( \"u_texture\", 0 );\r\n\t\t}\r\n\t\t\r\n\t\tidx = 0;\r\n\t\tlastTexture = null;\r\n\t\tdrawing = true;\r\n\t}","id":36249,"modified_method":"/**\r\n\t * Sets up the SpriteBatch for drawing. This will disable\r\n\t * depth buffer testing and writting, culling and lighting.\r\n\t * It enables blending and alpha testing. If you have more texture units enabled than\r\n\t * the first one you have to disable them before calling this. Applies\r\n\t * the given transformation {@link Matrix} to all subsequently specified sprites. Uses\r\n\t * the provided projection matrix and therefore does not necessarily work\r\n\t * in screen coordinates anymore. You have to know what you do if you use this.\r\n\t * \r\n\t * @param projection the projection matrix;\r\n\t * @param transform the transformation matrix.\r\n\t */\r\n\tpublic void begin( Matrix projection, Matrix transform )\r\n\t{\r\n\t\trenderCalls = 0;\r\n\t\tif( Gdx.graphics.isGL20Available() == false )\r\n\t\t{\t\t\t\t\t\t\t\t\t\t\r\n\t\t\tGL10 gl = Gdx.graphics.getGL10();\r\n\t\t\tgl.glViewport( 0, 0, Gdx.graphics.getWidth(), Gdx.graphics.getHeight() );\r\n\t\t\tgl.glDisable( GL10.GL_LIGHTING );\r\n\t\t\tgl.glDisable( GL10.GL_DEPTH_TEST );\r\n\t\t\tgl.glDisable( GL10.GL_CULL_FACE );\r\n\t\t\tgl.glDepthMask ( false );\r\n\t\t\t\r\n\t\t\tgl.glEnable( GL10.GL_TEXTURE_2D );\r\n\t\t\t//gl.glActiveTexture( GL10.GL_TEXTURE0 );\r\n\t\t\t\r\n\t\t\tgl.glMatrixMode( GL10.GL_PROJECTION );\r\n\t\t\tgl.glLoadMatrixf( projection.val, 0 );\r\n\t\t\tgl.glMatrixMode( GL10.GL_MODELVIEW );\r\n\t\t\tgl.glLoadMatrixf( transform.val, 0 );\r\n\t\t}\t\t\r\n\t\telse\r\n\t\t{\r\n\t\t\tviewMatrix.set(projection).mul(transform);\r\n\r\n\t\t\tGL20 gl = Gdx.graphics.getGL20();\r\n\t\t\tgl.glViewport( 0, 0, Gdx.graphics.getWidth(), Gdx.graphics.getHeight() );\r\n\t\t\tgl.glDisable( GL20.GL_DEPTH_TEST );\r\n\t\t\tgl.glDisable( GL20.GL_CULL_FACE );\r\n\t\t\tgl.glDepthMask ( false );\r\n\r\n\t\t\tgl.glEnable( GL20.GL_TEXTURE_2D );\r\n\t\t\t//gl.glActiveTexture( GL20.GL_TEXTURE0 );\r\n\r\n\t\t\tshader.begin();\r\n\t\t\tshader.setUniformMatrix( \"u_projectionViewMatrix\", viewMatrix );\r\n\t\t\tshader.setUniformi( \"u_texture\", 0 );\r\n\t\t}\r\n\t\t\r\n\t\tidx = 0;\r\n\t\tlastTexture = null;\r\n\t\tdrawing = true;\r\n\t}","commit_id":"1cf22df9e61f093b9f9278dd1c35dc33e36779d3","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n\tpublic void render (final Renderable renderable) {\n\t\tif (currentMaterial != renderable.material) {\n\t\t\tcurrentMaterial = renderable.material;\n\t\t\tif (!currentMaterial.has(BlendingAttribute.Type))\n\t\t\t\tcontext.setBlending(false, GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA);\n\t\t\tif (!currentMaterial.has(ColorAttribute.Diffuse)) {\n\t\t\t\tGdx.gl10.glColor4f(1,1,1,1);\n\t\t\t\tif (renderable.lights != null)\n\t\t\t\t\tGdx.gl10.glDisable(GL10.GL_COLOR_MATERIAL);\n\t\t\t} if (!currentMaterial.has(TextureAttribute.Diffuse))\n\t\t\t\tGdx.gl10.glDisable(GL10.GL_TEXTURE_2D);\n\t\t\tint cullFace = defaultCullFace;\n\t\t\tfor (final Material.Attribute attribute : currentMaterial) {\n\t\t\t\tif (attribute.type == BlendingAttribute.Type)\n\t\t\t\t\tcontext.setBlending(true, ((BlendingAttribute)attribute).sourceFunction, ((BlendingAttribute)attribute).destFunction);\n\t\t\t\telse if (attribute.type == ColorAttribute.Diffuse) {\n\t\t\t\t\tGdx.gl10.glColor4f(((ColorAttribute)attribute).color.r, ((ColorAttribute)attribute).color.g, ((ColorAttribute)attribute).color.b, ((ColorAttribute)attribute).color.a);\n\t\t\t\t\tif (renderable.lights != null) {\n\t\t\t\t\t\tGdx.gl10.glEnable(GL10.GL_COLOR_MATERIAL);\n\t\t\t\t\t\tGdx.gl10.glMaterialfv(GL10.GL_FRONT_AND_BACK, GL10.GL_AMBIENT, zeroVal4, 0);\n\t\t\t\t\t\tGdx.gl10.glMaterialfv(GL10.GL_FRONT_AND_BACK, GL10.GL_DIFFUSE, getValues(lightVal, ((ColorAttribute)attribute).color), 0);\n\t\t\t\t\t}\n\t\t\t\t} else if (attribute.type == TextureAttribute.Diffuse) {\n\t\t\t\t\tif (currentTexture0 != ((TextureAttribute)attribute).textureDescription.texture)\n\t\t\t\t\t\t(currentTexture0 = ((TextureAttribute)attribute).textureDescription.texture).bind(0);\n\t\t\t\t\tGdx.gl10.glEnable(GL10.GL_TEXTURE_2D);\n\t\t\t\t}\n\t\t\t\telse if ((attribute.type & IntAttribute.CullFace) == IntAttribute.CullFace)\n\t\t\t\t\tcullFace = ((IntAttribute)attribute).value;\n\t\t\t}\n\t\t\tcontext.setCullFace(cullFace);\n\t\t}\n\t\tif (currentTransform != renderable.worldTransform) { // FIXME mul localtransform\n\t\t\tif (currentTransform != null)\n\t\t\t\tGdx.gl10.glPopMatrix();\n\t\t\tcurrentTransform = renderable.worldTransform;\n\t\t\tGdx.gl10.glPushMatrix();\n\t\t\tGdx.gl10.glLoadMatrixf(currentTransform.val, 0);\n\t\t}\n\t\tbindLights(renderable.lights);\n\t\tif (currentMesh != renderable.mesh) {\n\t\t\tif (currentMesh != null)\n\t\t\t\tcurrentMesh.unbind();\n\t\t\t(currentMesh = renderable.mesh).bind();\n\t\t}\n\t\trenderable.mesh.render(renderable.primitiveType, renderable.meshPartOffset, renderable.meshPartSize);\n\t}","id":36250,"modified_method":"@Override\n\tpublic void render (final Renderable renderable) {\n\t\tif (currentMaterial != renderable.material) {\n\t\t\tcurrentMaterial = renderable.material;\n\t\t\tif (!currentMaterial.has(BlendingAttribute.Type))\n\t\t\t\tcontext.setBlending(false, GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA);\n\t\t\tif (!currentMaterial.has(ColorAttribute.Diffuse)) {\n\t\t\t\tGdx.gl10.glColor4f(1,1,1,1);\n\t\t\t\tif (renderable.lights != null)\n\t\t\t\t\tGdx.gl10.glDisable(GL10.GL_COLOR_MATERIAL);\n\t\t\t} if (!currentMaterial.has(TextureAttribute.Diffuse))\n\t\t\t\tGdx.gl10.glDisable(GL10.GL_TEXTURE_2D);\n\t\t\tint cullFace = defaultCullFace;\n\t\t\tfor (final Material.Attribute attribute : currentMaterial) {\n\t\t\t\tif (attribute.type == BlendingAttribute.Type)\n\t\t\t\t\tcontext.setBlending(true, ((BlendingAttribute)attribute).sourceFunction, ((BlendingAttribute)attribute).destFunction);\n\t\t\t\telse if (attribute.type == ColorAttribute.Diffuse) {\n\t\t\t\t\tGdx.gl10.glColor4f(((ColorAttribute)attribute).color.r, ((ColorAttribute)attribute).color.g, ((ColorAttribute)attribute).color.b, ((ColorAttribute)attribute).color.a);\n\t\t\t\t\tif (renderable.lights != null) {\n\t\t\t\t\t\tGdx.gl10.glEnable(GL10.GL_COLOR_MATERIAL);\n\t\t\t\t\t\tGdx.gl10.glMaterialfv(GL10.GL_FRONT_AND_BACK, GL10.GL_AMBIENT, zeroVal4, 0);\n\t\t\t\t\t\tGdx.gl10.glMaterialfv(GL10.GL_FRONT_AND_BACK, GL10.GL_DIFFUSE, getValues(lightVal, ((ColorAttribute)attribute).color), 0);\n\t\t\t\t\t}\n\t\t\t\t} else if (attribute.type == TextureAttribute.Diffuse) {\n\t\t\t\t\tTextureDescriptor textureDesc = ((TextureAttribute)attribute).textureDescription;\n\t\t\t\t\tif (currentTexture0 != textureDesc.texture)\n\t\t\t\t\t\t(currentTexture0 = textureDesc.texture).bind(0);\n\t\t\t\t\tGdx.gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MIN_FILTER, textureDesc.minFilter);\n\t\t\t\t\tGdx.gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MAG_FILTER, textureDesc.magFilter);\n\t\t\t\t\tGdx.gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_S, textureDesc.uWrap);\n\t\t\t\t\tGdx.gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_T, textureDesc.vWrap);\n\t\t\t\t\tGdx.gl10.glEnable(GL10.GL_TEXTURE_2D);\n\t\t\t\t}\n\t\t\t\telse if ((attribute.type & IntAttribute.CullFace) == IntAttribute.CullFace)\n\t\t\t\t\tcullFace = ((IntAttribute)attribute).value;\n\t\t\t}\n\t\t\tcontext.setCullFace(cullFace);\n\t\t}\n\t\tif (currentTransform != renderable.worldTransform) { // FIXME mul localtransform\n\t\t\tif (currentTransform != null)\n\t\t\t\tGdx.gl10.glPopMatrix();\n\t\t\tcurrentTransform = renderable.worldTransform;\n\t\t\tGdx.gl10.glPushMatrix();\n\t\t\tGdx.gl10.glLoadMatrixf(currentTransform.val, 0);\n\t\t}\n\t\tbindLights(renderable.lights);\n\t\tif (currentMesh != renderable.mesh) {\n\t\t\tif (currentMesh != null)\n\t\t\t\tcurrentMesh.unbind();\n\t\t\t(currentMesh = renderable.mesh).bind();\n\t\t}\n\t\trenderable.mesh.render(renderable.primitiveType, renderable.meshPartOffset, renderable.meshPartSize);\n\t}","commit_id":"9c136df4b963c000ebbfbf7e8459e4629d3bfe7d","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override\n    public void launch() {\n        VanillaJavaApp entity = getEntity();\n\n        String clazz = entity.getMainClass();\n        String args = getArgs();\n\n        Map flags = new HashMap();\n        flags.put(\"usePidFile\", true);\n\n        newScript(flags, LAUNCHING).\n            body.append(\n                format(\"echo \\\"launching: java $JAVA_OPTS -cp \\'lib/*\\' %s %s\\\"\",clazz,args),\n                format(\"java $JAVA_OPTS -cp \\\"lib/*\\\" %s %s >> %s/console 2>&1 <\/dev/null &\",clazz, args, getRunDir())\n        ).execute();\n    }","id":36251,"modified_method":"@Override\n    public void launch() {\n        VanillaJavaApp entity = getEntity();\n\n        String clazz = entity.getMainClass();\n        String args = getArgs();\n\n        Map flags = new HashMap();\n        flags.put(\"usePidFile\", true);\n\n        newScript(flags, LAUNCHING)\n            .body.append(\n                    format(\"echo \\\"launching: java $JAVA_OPTS -cp \\'%s\\' %s %s\\\"\", classpath, clazz, args),\n                    format(\"java $JAVA_OPTS -cp \\\"%s\\\" %s %s >> %s/console 2>&1 <\/dev/null &\", classpath, clazz, args, getRunDir())\n                )\n            .execute();\n    }","commit_id":"68e2dbb7eb8e31d7350f997160621b5901aa547e","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void customize() {\n        newScript(CUSTOMIZING).\n                failOnNonZeroResultCode().\n                body.append(format(\"mkdir -p %s/lib\", getRunDir())).\n                execute();\n\n        SshMachineLocation machine = getMachine();\n        VanillaJavaApp entity = getEntity();\n        for (String entry : entity.getClasspath()) {\n            // If a local folder, then create archive from contents first\n            if (Urls.isDirectory(entry)) {\n                File jarFile = ArchiveBuilder.jar().add(entry).create();\n                entry = jarFile.getAbsolutePath();\n            }\n\n            // Determine filename\n            String destFile = entry.contains(\"?\") ? entry.substring(0, entry.indexOf('?')) : entry;\n            destFile = destFile.substring(destFile.lastIndexOf('/') + 1);\n\n            ArchiveUtils.deploy(MutableMap.<String, Object>of(), entry, machine, getRunDir(), Os.mergePaths(getRunDir(), \"lib\"), destFile);\n        }\n    }","id":36252,"modified_method":"@Override\n    public void customize() {\n        newScript(CUSTOMIZING)\n                .body.append(format(\"mkdir -p %s/lib\", getRunDir()))\n                .failOnNonZeroResultCode()\n                .execute();\n\n        SshMachineLocation machine = getMachine();\n        VanillaJavaApp entity = getEntity();\n        for (String entry : entity.getClasspath()) {\n            // If a local folder, then create archive from contents first\n            if (Urls.isDirectory(entry)) {\n                File jarFile = ArchiveBuilder.jar().add(entry).create();\n                entry = jarFile.getAbsolutePath();\n            }\n\n            // Determine filename\n            String destFile = entry.contains(\"?\") ? entry.substring(0, entry.indexOf('?')) : entry;\n            destFile = destFile.substring(destFile.lastIndexOf('/') + 1);\n\n            ArchiveUtils.deploy(MutableMap.<String, Object>of(), entry, machine, getRunDir(), Os.mergePaths(getRunDir(), \"lib\"), destFile);\n        }\n\n        ScriptHelper helper = newScript(CUSTOMIZING+\" classpath\")\n            .body.append(\n                    \"echo --begin--\",\n                    format(\"ls -1 %s/lib\", getRunDir()),\n                    \"echo --end--\"\n                )\n            .gatherOutput(true);\n        int result = helper.execute();\n        if (result != 0) {\n            throw new IllegalStateException(\"Error listing classpath files: \" + helper.getResultStderr());\n        }\n\n        // Transform stdout into list of files in classpath\n        String stdout = Strings.getFragmentBetween(helper.getResultStdout(), \"--begin--\", \"--end--\");\n        if (Strings.isBlank(stdout)) {\n            classpath = Os.mergePaths(getRunDir(), \"lib\"); // Safe default\n        } else {\n            Iterable<String> lines = Splitter.on(CharMatcher.BREAKING_WHITESPACE).omitEmptyStrings().trimResults().split(stdout);\n            Iterable<String> files = Iterables.transform(lines, new Function<String, String>() {\n                        @Override\n                        public String apply(@Nullable String input) {\n                            return Os.mergePaths(getRunDir(), \"lib\", input);\n                        }\n                    });\n            getEntity().setAttribute(VanillaJavaApp.CLASSPATH_FILES, ImmutableList.copyOf(files));\n            classpath = Joiner.on(\":\").join(files);\n        }\n    }","commit_id":"68e2dbb7eb8e31d7350f997160621b5901aa547e","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public boolean isRunning() {\n        return newScript(ImmutableMap.of(\"usePidFile\", getPidFile()), CHECK_RUNNING).execute() == 0;\n    }","id":36253,"modified_method":"@Override\n    public boolean isRunning() {\n        return newScript(MutableMap.of(USE_PID_FILE, getPidFile()), CHECK_RUNNING).execute() == 0;\n    }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public String getPidFile() { return getRunDir() + \"/kafka.pid\"; }","id":36254,"modified_method":"public String getPidFile() { return Os.mergePathsUnix(getRunDir(), \"kafka.pid\"); }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void stop() {\n        newScript(ImmutableMap.of(\"usePidFile\", false), STOPPING)\n                .body.append(String.format(\"ps ax | grep %s | awk '{print $1}' | xargs kill\", getProcessIdentifier()))\n                .body.append(String.format(\"ps ax | grep %s | awk '{print $1}' | xargs kill -9\", getProcessIdentifier()))\n                .execute();\n    }","id":36255,"modified_method":"@Override\n    public void stop() {\n        newScript(MutableMap.of(USE_PID_FILE, false), STOPPING)\n                .body.append(String.format(\"ps ax | grep %s | awk '{print $1}' | xargs kill\", getProcessIdentifier()))\n                .body.append(String.format(\"ps ax | grep %s | awk '{print $1}' | xargs kill -9\", getProcessIdentifier()))\n                .execute();\n    }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void launch() {\n        newScript(ImmutableMap.of(\"usePidFile\", getPidFile()), LAUNCHING)\n                .failOnNonZeroResultCode()\n                .body.append(String.format(\"nohup ./bin/%s ./%s > console.out 2>&1 &\", getLaunchScriptName(), getConfigFileName()))\n                .execute();\n    }","id":36256,"modified_method":"@Override\n    public void launch() {\n        newScript(MutableMap.of(USE_PID_FILE, getPidFile()), LAUNCHING)\n                .failOnNonZeroResultCode()\n                .body.append(String.format(\"nohup ./bin/%s ./%s > console.out 2>&1 &\", getLaunchScriptName(), getConfigFileName()))\n                .execute();\n    }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void install() {\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n        setExpandedInstallDir(getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(format(\"kafka-%s-src\", getVersion())));\n\n        List<String> commands = new LinkedList<String>();\n        commands.addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs));\n        commands.add(BashCommands.INSTALL_TAR);\n        commands.add(\"tar xzfv \"+saveAs);\n        commands.add(\"cd \"+getExpandedInstallDir());\n        commands.add(\"./sbt update\");\n        commands.add(\"./sbt package\");\n        if (isV08()) {\n            // target not known in v0.7.x but required in v0.8.0-beta1\n            commands.add(\"./sbt assembly-package-dependency\");\n        }\n\n        newScript(INSTALLING)\n                .failOnNonZeroResultCode()\n                .body.append(commands)\n                .execute();\n    }","id":36257,"modified_method":"@Override\n    public void install() {\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n        setExpandedInstallDir(getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(format(\"kafka-%s-src\", getVersion())));\n\n        List<String> commands = new LinkedList<String>();\n        commands.addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs));\n        commands.add(BashCommands.INSTALL_TAR);\n        commands.add(\"tar xzfv \"+saveAs);\n        commands.add(\"cd \"+getExpandedInstallDir());\n        commands.add(\"./sbt update\");\n        commands.add(\"./sbt package\");\n        if (isV08()) {\n            // target not known in v0.7.x but required in v0.8.0-beta1\n            commands.add(\"./sbt assembly-package-dependency\");\n        }\n\n        newScript(INSTALLING)\n                .body.append(commands)\n                .execute();\n    }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    protected String getLogFileLocation() { return getRunDir()+\"/console.out\"; }","id":36258,"modified_method":"@Override\n    protected String getLogFileLocation() { return Os.mergePathsUnix(getRunDir(), \"console.out\"); }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"/**\n     * Use RMI agent to provide JMX.\n     */\n    @Override\n    public Map<String, String> getShellEnvironment() {\n        Map<String, String> orig = super.getShellEnvironment();\n        String kafkaJmxOpts = orig.remove(\"JAVA_OPTS\");\n        return MutableMap.<String, String>builder()\n                .putAll(orig)\n                .putIfNotNull(\"KAFKA_JMX_OPTS\", kafkaJmxOpts)\n                .build();\n    }","id":36259,"modified_method":"/**\n     * Use RMI agent to provide JMX.\n     */\n    @Override\n    public Map<String, String> getShellEnvironment() {\n        return MutableMap.<String, String>builder()\n                .putAll(super.getShellEnvironment())\n                .renameKey(\"JAVA_OPTS\", \"KAFKA_JMX_OPTS\")\n                .build();\n    }","commit_id":"6ae909955e6b926cbeff16e83a50902b31ab4d9f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n        public boolean isRunning() {\n            return newScript(CHECK_RUNNING)\n                .body.append(\"ls\")\n                .failOnNonZeroResultCode()\n                .execute() == 0;\n        }","id":36260,"modified_method":"@Override\n        public boolean isRunning() {\n            return newScript(CHECK_RUNNING)\n                .execute() == 0;\n        }","commit_id":"5d94cf4a8a3f0605fb7356cd18c77493c08c0bb8","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n        public int execute(List<String> script, String summaryForLogging) {\n            if (failExecution) {\n                throw new TestException(\"Simulated driver exception\");\n            }\n            return super.execute(script, summaryForLogging);\n        }","id":36261,"modified_method":"@Override\n        public int execute(List<String> script, String summaryForLogging) {\n            if (failExecution) {\n                throw new TestException(\"Simulated driver exception\");\n            }\n            return 0;\n        }","commit_id":"5d94cf4a8a3f0605fb7356cd18c77493c08c0bb8","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@SuppressWarnings(\"rawtypes\")\n        @Override\n        public int execute(Map flags2, List<String> script, String summaryForLogging) {\n            if (failExecution) {\n                throw new TestException(\"Simulated driver exception\");\n            }\n            return super.execute(flags2, script, summaryForLogging);\n        }","id":36262,"modified_method":"@SuppressWarnings(\"rawtypes\")\n        @Override\n        public int execute(Map flags2, List<String> script, String summaryForLogging) {\n            if (failExecution) {\n                throw new TestException(\"Simulated driver exception\");\n            }\n            return 0;\n        }","commit_id":"5d94cf4a8a3f0605fb7356cd18c77493c08c0bb8","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Test(groups = \"Integration\")\n    public void testCheckRunningForcesInessential() {\n        MyServiceInessentialDriverImpl entity = new MyServiceInessentialDriverImpl(app);\n        Entities.manage(entity);\n        \n        entity.start(ImmutableList.of(loc));\n        SimulatedInessentialIsRunningDriver driver = (SimulatedInessentialIsRunningDriver) entity.getDriver();\n        Assert.assertTrue(driver.isRunning());\n        \n        entity.connectPolling();\n        \n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, true);\n        driver.setFailExecution(true);\n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, false);\n        driver.setFailExecution(false);\n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, true);\n    }","id":36263,"modified_method":"@Test\n    public void testCheckRunningForcesInessential() {\n        MyServiceInessentialDriverImpl entity = new MyServiceInessentialDriverImpl(app);\n        Entities.manage(entity);\n        \n        entity.start(ImmutableList.of(loc));\n        SimulatedInessentialIsRunningDriver driver = (SimulatedInessentialIsRunningDriver) entity.getDriver();\n        Assert.assertTrue(driver.isRunning());\n        \n        entity.connectServiceUpIsRunning();\n        \n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, true);\n        driver.setFailExecution(true);\n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, false);\n        driver.setFailExecution(false);\n        EntityTestUtils.assertAttributeEqualsEventually(entity, Startable.SERVICE_UP, true);\n    }","commit_id":"5d94cf4a8a3f0605fb7356cd18c77493c08c0bb8","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void customize() {\n        newScript(CUSTOMIZING).failOnNonZeroResultCode()\n                .body.append(format(\"cp -R %s/rubyrep-%s .\", getExpandedInstallDir(), getVersion()))\n                .execute();\n        try {\n            customizeConfiguration();\n        } catch (Exception e) {\n            log.error(\"Failed to configure rubyrep, replication is unlikely to succeed\", e);\n        }\n    }","id":36264,"modified_method":"@Override\n    public void customize() {\n        newScript(CUSTOMIZING)\n                .body.append(format(\"cp -R %s %s\", getExpandedInstallDir(), getRunDir()))\n                .failOnNonZeroResultCode()\n                .execute();\n        try {\n            customizeConfiguration();\n        } catch (Exception e) {\n            log.error(\"Failed to configure rubyrep, replication is unlikely to succeed\", e);\n        }\n    }","commit_id":"a19e9b1a781d6721b6d35eb8e3d2d598654baf6f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"protected void customizeConfiguration() throws ExecutionException, InterruptedException, URISyntaxException {\n        log.info(\"Copying creation script \" + getEntity().toString());\n\n        // TODO check these semantics are what we really want?\n        String configScriptUrl = entity.getConfig(RubyRepNode.CONFIGURATION_SCRIPT_URL);\n        Reader configContents;\n        if (configScriptUrl != null) {\n            // If set accept as-is\n            configContents = Streams.reader(resource.getResourceFromUrl(configScriptUrl));\n        } else {\n            String configScriptContents = processTemplate(entity.getConfig(RubyRepNode.TEMPLATE_CONFIGURATION_URL));\n            configContents = Streams.newReaderWithContents(configScriptContents);\n        }\n\n        log.info(\"Sending \" + configContents);\n        getMachine().copyTo(configContents, getRunDir() + \"/rubyrep.conf\");\n    }","id":36265,"modified_method":"protected void customizeConfiguration() throws ExecutionException, InterruptedException, URISyntaxException {\n        log.info(\"Copying creation script \" + getEntity().toString());\n\n        // TODO check these semantics are what we really want?\n        String configScriptUrl = entity.getConfig(RubyRepNode.CONFIGURATION_SCRIPT_URL);\n        Reader configContents;\n        if (configScriptUrl != null) {\n            // If set accept as-is\n            configContents = Streams.reader(resource.getResourceFromUrl(configScriptUrl));\n        } else {\n            String configScriptContents = processTemplate(entity.getConfig(RubyRepNode.TEMPLATE_CONFIGURATION_URL));\n            configContents = Streams.newReaderWithContents(configScriptContents);\n        }\n\n        getMachine().copyTo(configContents, getRunDir() + \"/rubyrep.conf\");\n    }","commit_id":"a19e9b1a781d6721b6d35eb8e3d2d598654baf6f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void install() {\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n        expandedInstallDir = getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(\"rubrep\");\n\n        List<String> commands = ImmutableList.<String>builder()\n                .addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs))\n                .add(BashCommands.INSTALL_UNZIP)\n                .add(\"unzip \" + saveAs)\n                .build();\n\n        newScript(INSTALLING).failOnNonZeroResultCode().body.append(commands).execute();\n    }","id":36266,"modified_method":"@Override\n    public void install() {\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n\n        List<String> commands = ImmutableList.<String>builder()\n                .addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs))\n                .add(BashCommands.INSTALL_UNZIP)\n                .add(\"unzip \" + saveAs)\n                .build();\n\n        newScript(INSTALLING)\n                .body.append(commands)\n                .failOnNonZeroResultCode()\n                .execute();\n\n        expandedInstallDir = getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(format(\"rubyrep-%s\", getVersion()));\n    }","commit_id":"a19e9b1a781d6721b6d35eb8e3d2d598654baf6f","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void install() {\n        log.info(\"Installing {}\", entity);\n        List<String> commands = ImmutableList.<String>builder()\n                .add(chainGroup(\n                        \"which zypper\",\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/SLE_11_SP3 erlang_sles_11\"),\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/openSUSE_11.4 erlang_suse_11\"),\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/openSUSE_12.3 erlang_suse_12\")))\n                .add(installPackage( // NOTE only 'port' states the version of Erlang used, maybe remove this constraint?\n                        ImmutableMap.of(\n                                \"apt\", \"erlang-nox erlang-dev\",\n                                \"port\", \"erlang@\"+getErlangVersion()+\"+ssl\"),\n                        \"erlang\"))\n                .add(installPackage(\"couchdb\"))\n                .add(ifExecutableElse0(\"service\", sudo(\"service couchdb stop\")))\n                .build();\n\n        newScript(INSTALLING)\n                .failOnNonZeroResultCode()\n                .body.append(commands)\n                .execute();\n    }","id":36267,"modified_method":"@Override\n    public void install() {\n        log.info(\"Installing {}\", entity);\n        List<String> commands = ImmutableList.<String>builder()\n                .add(chainGroup(\n                        \"which zypper\",\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/SLE_11_SP3 erlang_sles_11\"),\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/openSUSE_11.4 erlang_suse_11\"),\n                        sudo(\"zypper --non-interactive addrepo http://download.opensuse.org/repositories/devel:/languages:/erlang/openSUSE_12.3 erlang_suse_12\")))\n                .add(installPackage( // NOTE only 'port' states the version of Erlang used, maybe remove this constraint?\n                        ImmutableMap.of(\n                                \"apt\", \"erlang-nox erlang-dev\",\n                                \"port\", \"erlang@\"+getErlangVersion()+\"+ssl\"),\n                        \"erlang\"))\n                .add(installPackage(\"couchdb\"))\n                .add(ifExecutableElse0(\"service\", sudo(\"service couchdb stop\")))\n                .build();\n\n        newScript(INSTALLING)\n                .body.append(commands)\n                .execute();\n    }","commit_id":"8167e41ecf49158a69a1017262504c7fe50d8817","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    protected String getLogFileLocation() { return Os.mergePathsUnix(getRunDir(), \"couchdb.log\"); }","id":36268,"modified_method":"public String getLogFileLocation() { return Os.mergePathsUnix(getRunDir(), \"couchdb.log\"); }","commit_id":"8167e41ecf49158a69a1017262504c7fe50d8817","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public CouchDBNodeSshDriver(CouchDBNodeImpl entity, SshMachineLocation machine) {\n        super(entity, machine);\n    }","id":36269,"modified_method":"public CouchDBNodeSshDriver(CouchDBNodeImpl entity, SshMachineLocation machine) {\n        super(entity, machine);\n\n        entity.setAttribute(Attributes.LOG_FILE_LOCATION, getLogFileLocation());\n    }","commit_id":"8167e41ecf49158a69a1017262504c7fe50d8817","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public ProcessTaskWrapper<Integer> executeScriptFromInstalledFileAsync(String fileToRun) {\n        ProcessTaskWrapper<Integer> task = SshEffectorTasks.ssh(\n                        \"cd \"+getRunDir(),\n                        scriptInvocationCommand(getEntity().getAttribute(CassandraNode.THRIFT_PORT), fileToRun))\n                .machine(getMachine())\n                .summary(\"executing cassandra script \"+fileToRun)\n                .newTask();\n        DynamicTasks.queueIfPossible(task).orSubmitAndBlock(getEntity());\n        return task;\n    }","id":36270,"modified_method":"public ProcessTaskWrapper<Integer> executeScriptFromInstalledFileAsync(String fileToRun) {\n        ProcessTaskWrapper<Integer> task = SshEffectorTasks.ssh(\n                        \"cd \"+getRunDir(),\n                        scriptInvocationCommand(getThriftPort(), fileToRun))\n                .machine(getMachine())\n                .summary(\"executing cassandra script \"+fileToRun)\n                .newTask();\n        DynamicTasks.queueIfPossible(task).orSubmitAndBlock(getEntity());\n        return task;\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"protected String scriptInvocationCommand(Integer optionalThriftPort, String fileToRun) {\n        List<String> args = Lists.newArrayList();\n        args.add(\"bin/cassandra-cli\");\n        if (optionalThriftPort != null) {\n            args.add(\"--port\");\n            args.add(Integer.toString(optionalThriftPort));\n        }\n        args.add(\"--file\");\n        args.add(fileToRun);\n        return Joiner.on(\" \").join(args);\n    }","id":36271,"modified_method":"protected String scriptInvocationCommand(Integer optionalThriftPort, String fileToRun) {\n        return \"bin/cassandra-cli \" +\n                (optionalThriftPort != null ? \"--port \" + optionalThriftPort : \"\") +\n                \" --file \"+fileToRun;\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void customize() {\n        log.debug(\"Customizing {} (Cluster {})\", entity, getClusterName());\n        Networking.checkPortsValid(getPortMap());\n        \n        customizeInitialSeeds();\n\n        String logFileEscaped = getLogFileLocation().replace(\"/\", \"\\\\/\"); // escape slashes\n\n        ImmutableList.Builder<String> commands = new ImmutableList.Builder<String>()\n                .add(String.format(\"cp -R %s/{bin,conf,lib,interface,pylib,tools} .\", getExpandedInstallDir()))\n                .add(\"mkdir -p data\")\n                .add(\"mkdir -p brooklyn_commands\")\n                .add(String.format(\"sed -i.bk 's/log4j.appender.R.File=.*/log4j.appender.R.File=%s/g' %s/conf/log4j-server.properties\", logFileEscaped, getRunDir()))\n                .add(String.format(\"sed -i.bk '/JMX_PORT/d' %s/conf/cassandra-env.sh\", getRunDir()))\n                // Script sets 180k on Linux which gives Java error:  The stack size specified is too small, Specify at least 228k \n                .add(String.format(\"sed -i.bk 's/-Xss180k/-Xss280k/g' %s/conf/cassandra-env.sh\", getRunDir())); \n\n        newScript(CUSTOMIZING)\n                .body.append(commands.build())\n                .failOnNonZeroResultCode()\n                .execute();\n\n        // Copy the cassandra.yaml configuration file across\n        String configFileContents = processTemplate(getCassandraConfigTemplateUrl());\n        String destinationConfigFile = String.format(\"%s/conf/%s\", getRunDir(), getCassandraConfigFileName());\n        getMachine().copyTo(new ByteArrayInputStream(configFileContents.getBytes()), destinationConfigFile);\n        \n        // Copy the cassandra-rackdc.properties configuration file across\n        String rackdcFileContents = processTemplate(getCassandraRackdcConfigTemplateUrl());\n        String rackdcDestinationFile = String.format(\"%s/conf/%s\", getRunDir(), getCassandraRackdcConfigFileName());\n        getMachine().copyTo(new ByteArrayInputStream(rackdcFileContents.getBytes()), rackdcDestinationFile);\n\n        customizeCopySnitch();\n    }","id":36272,"modified_method":"@Override\n    public void customize() {\n        log.debug(\"Customizing {} (Cluster {})\", entity, getClusterName());\n        Networking.checkPortsValid(getPortMap());\n\n        customizeInitialSeeds();\n\n        String logFileEscaped = getLogFileLocation().replace(\"/\", \"\\\\/\"); // escape slashes\n\n        ImmutableList.Builder<String> commands = new ImmutableList.Builder<String>()\n                .add(String.format(\"cp -R %s/{bin,conf,lib,interface,pylib,tools} .\", getExpandedInstallDir()))\n                .add(\"mkdir -p data\")\n                .add(\"mkdir -p brooklyn_commands\")\n                .add(String.format(\"sed -i.bk 's/log4j.appender.R.File=.*/log4j.appender.R.File=%s/g' %s/conf/log4j-server.properties\", logFileEscaped, getRunDir()))\n                .add(String.format(\"sed -i.bk '/JMX_PORT/d' %s/conf/cassandra-env.sh\", getRunDir()))\n                // Script sets 180k on Linux which gives Java error:  The stack size specified is too small, Specify at least 228k \n                .add(String.format(\"sed -i.bk 's/-Xss180k/-Xss280k/g' %s/conf/cassandra-env.sh\", getRunDir())); \n\n        newScript(CUSTOMIZING)\n                .body.append(commands.build())\n                .failOnNonZeroResultCode()\n                .execute();\n\n        // Copy the cassandra.yaml configuration file across\n        String configFileContents = processTemplate(getCassandraConfigTemplateUrl());\n        String destinationConfigFile = Os.mergePathsUnix(getRunDir(), \"conf\", getCassandraConfigFileName());\n        getMachine().copyTo(Streams.newInputStreamWithContents(configFileContents), destinationConfigFile);\n\n        // Copy the cassandra-rackdc.properties configuration file across\n        String rackdcFileContents = processTemplate(getCassandraRackdcConfigTemplateUrl());\n        String rackdcDestinationFile = Os.mergePathsUnix(getRunDir(), \"conf\", getCassandraRackdcConfigFileName());\n        getMachine().copyTo(Streams.newInputStreamWithContents(rackdcFileContents), rackdcDestinationFile);\n\n        customizeCopySnitch();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public CassandraNodeSshDriver(CassandraNodeImpl entity, SshMachineLocation machine) {\n        super(entity, machine);\n\n        entity.setAttribute(Attributes.LOG_FILE_LOCATION, getLogFileLocation());\n    }","id":36273,"modified_method":"public CassandraNodeSshDriver(CassandraNodeImpl entity, SshMachineLocation machine) {\n        super(entity, machine);\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public Set<Integer> getPortsUsed() {\n        Set<Integer> result = Sets.newLinkedHashSet(super.getPortsUsed());\n        result.addAll(getPortMap().values());\n        return result;\n    }","id":36274,"modified_method":"@Override\n    public Set<Integer> getPortsUsed() {\n        return ImmutableSet.<Integer>builder()\n                .addAll(super.getPortsUsed())\n                .addAll(getPortMap().values())\n                .build();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void install() {\n        log.debug(\"Installing {}\", entity);\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n        setExpandedInstallDir(getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(getDefaultUnpackedDirectoryName()));\n        \n        List<String> commands = ImmutableList.<String>builder()\n                .addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs))\n                .add(BashCommands.INSTALL_TAR)\n                .add(\"tar xzfv \" + saveAs)\n                .build();\n\n        newScript(INSTALLING)\n                .failOnNonZeroResultCode()\n                .body.append(commands)\n                .execute();\n    }","id":36275,"modified_method":"@Override\n    public void install() {\n        log.debug(\"Installing {}\", entity);\n        DownloadResolver resolver = Entities.newDownloader(this);\n        List<String> urls = resolver.getTargets();\n        String saveAs = resolver.getFilename();\n        setExpandedInstallDir(getInstallDir()+\"/\"+resolver.getUnpackedDirectoryName(getDefaultUnpackedDirectoryName()));\n\n        List<String> commands = ImmutableList.<String>builder()\n                .addAll(BashCommands.commandsToDownloadUrlsAs(urls, saveAs))\n                .add(BashCommands.INSTALL_TAR)\n                .add(\"tar xzfv \" + saveAs)\n                .build();\n\n        newScript(INSTALLING)\n                .body.append(commands)\n                .execute();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"protected void customizeCopySnitch() {\n        // Copy the custom snitch jar file across\n        String customSnitchJarUrl = entity.getConfig(CassandraNode.CUSTOM_SNITCH_JAR_URL);\n        if (Strings.isNonBlank(customSnitchJarUrl)) {\n            int lastSlashIndex = customSnitchJarUrl.lastIndexOf(\"/\");\n            String customSnitchJarName = (lastSlashIndex > 0) ? customSnitchJarUrl.substring(lastSlashIndex+1) : \"customBrooklynSnitch.jar\";\n            String jarDestinationFile = String.format(\"%s/lib/%s\", getRunDir(), customSnitchJarName);\n            InputStream customSnitchJarStream = checkNotNull(resource.getResourceFromUrl(customSnitchJarUrl), \"%s could not be loaded\", customSnitchJarUrl);\n            try {\n                getMachine().copyTo(customSnitchJarStream, jarDestinationFile);\n            } finally {\n                Streams.closeQuietly(customSnitchJarStream);\n            }\n        }\n    }","id":36276,"modified_method":"protected void customizeCopySnitch() {\n        // Copy the custom snitch jar file across\n        String customSnitchJarUrl = entity.getConfig(CassandraNode.CUSTOM_SNITCH_JAR_URL);\n        if (Strings.isNonBlank(customSnitchJarUrl)) {\n            int lastSlashIndex = customSnitchJarUrl.lastIndexOf(\"/\");\n            String customSnitchJarName = (lastSlashIndex > 0) ? customSnitchJarUrl.substring(lastSlashIndex+1) : \"customBrooklynSnitch.jar\";\n            String jarDestinationFile = Os.mergePathsUnix(getRunDir(), \"lib\", customSnitchJarName);\n            InputStream customSnitchJarStream = checkNotNull(resource.getResourceFromUrl(customSnitchJarUrl), \"%s could not be loaded\", customSnitchJarUrl);\n            try {\n                getMachine().copyTo(customSnitchJarStream, jarDestinationFile);\n            } finally {\n                Streams.closeQuietly(customSnitchJarStream);\n            }\n        }\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void launch() {\n        String subnetHostname = Machines.findSubnetOrPublicHostname(entity).get();\n        Set<Entity> seeds = getEntity().getConfig(CassandraNode.INITIAL_SEEDS);\n        List<Entity> ancestors = getCassandraAncestors();\n        log.info(\"Launching \" + entity + \": \" +\n                \"cluster \"+getClusterName()+\", \" +\n        \t\t\"hostname (public) \" + getEntity().getAttribute(Attributes.HOSTNAME) + \", \" +\n        \t\t\"hostname (subnet) \" + subnetHostname + \", \" +\n        \t\t\"seeds \"+((CassandraNode)entity).getSeeds()+\" (from \"+seeds+\")\");\n        \n        boolean isFirst = seeds.iterator().next().equals(entity);\n        if (isClustered() && !isFirst && CassandraDatacenter.WAIT_FOR_FIRST) {\n            // wait for the first node\n            long firstStartTime = Entities.submit(entity, DependentConfiguration.attributeWhenReady(\n                ancestors.get(ancestors.size()-1), CassandraDatacenter.FIRST_NODE_STARTED_TIME_UTC)).getUnchecked();\n            // optionally force a delay before starting subsequent nodes; see comment at CassandraCluster.DELAY_AFTER_FIRST\n            Duration toWait = Duration.millis(firstStartTime + CassandraDatacenter.DELAY_AFTER_FIRST.toMilliseconds() -  System.currentTimeMillis());\n            if (toWait.toMilliseconds()>0) {\n                log.info(\"Launching \" + entity + \": delaying launch of non-first node by \"+toWait+\" to prevent schema disagreements\");\n                Tasks.setBlockingDetails(\"Pausing to ensure first node has time to start\");\n                Time.sleep(toWait);\n                Tasks.resetBlockingDetails();\n            }\n        }\n        \n        List<Entity> queuedStart = null;\n        if (CassandraDatacenter.DELAY_BETWEEN_STARTS!=null && !ancestors.isEmpty()) {\n            Entity root = ancestors.get(ancestors.size()-1);\n            // TODO currently use the class as a semaphore; messy, and obviously will not federate;\n            // should develop a brooklyn framework semaphore (similar to that done on SshMachineLocation)\n            // and use it - note however the synch block is very very short so relatively safe at least\n            synchronized (CassandraNode.class) {\n                queuedStart = root.getAttribute(CassandraDatacenter.QUEUED_START_NODES);\n                if (queuedStart==null) {\n                    queuedStart = new ArrayList<Entity>();\n                    ((EntityLocal)root).setAttribute(CassandraDatacenter.QUEUED_START_NODES, queuedStart);\n                }\n                queuedStart.add(getEntity());\n                ((EntityLocal)root).setAttribute(CassandraDatacenter.QUEUED_START_NODES, queuedStart);\n            }\n            do {\n                // get it again in case it is backed by something external\n                queuedStart = root.getAttribute(CassandraDatacenter.QUEUED_START_NODES);\n                if (queuedStart.get(0).equals(getEntity()))\n                    break;\n                synchronized (queuedStart) {\n                    try {\n                        queuedStart.wait(1000);\n                    } catch (InterruptedException e) {\n                        Exceptions.propagate(e);\n                    }\n                }\n            } while (true);\n            \n            // TODO should look at last start time... but instead we always wait\n            CassandraDatacenter.DELAY_BETWEEN_STARTS.countdownTimer().waitForExpiryUnchecked();\n        }\n\n        try {\n            newScript(MutableMap.of(\"usePidFile\", getPidFile()), LAUNCHING)\n            .body.append(\n                // log the date to attempt to debug occasional http://wiki.apache.org/cassandra/FAQ#schema_disagreement\n                // (can be caused by machines out of synch time-wise; but in our case it seems to be caused by other things!)\n                \"echo date on cassandra server `hostname` when launching is `date`\",\n                launchEssentialCommand())\n                .execute();\n            if (!isClustered()) {\n                InputStream creationScript = DatastoreMixins.getDatabaseCreationScript(entity);\n                if (creationScript!=null) { \n                    Tasks.setBlockingDetails(\"Pausing to ensure Cassandra (singleton) has started before running creation script\");\n                    Time.sleep(Duration.seconds(20));\n                    Tasks.resetBlockingDetails();\n                    executeScriptAsync(Streams.readFullyString(creationScript));\n                }\n            }\n            if (isClustered() && isFirst) {\n                for (Entity ancestor: getCassandraAncestors())\n                    ((EntityLocal)ancestor).setAttribute(CassandraDatacenter.FIRST_NODE_STARTED_TIME_UTC, System.currentTimeMillis());\n            }\n            \n        } finally {\n            if (queuedStart!=null) {\n                Entity head = queuedStart.remove(0);\n                Preconditions.checkArgument(head.equals(getEntity()), \"first queued node was \"+head+\" but we are \"+getEntity());\n                synchronized (queuedStart) {\n                    queuedStart.notifyAll();\n                }\n            }\n        }\n    }","id":36277,"modified_method":"@Override\n    public void launch() {\n        String subnetHostname = Machines.findSubnetOrPublicHostname(entity).get();\n        Set<Entity> seeds = getEntity().getConfig(CassandraNode.INITIAL_SEEDS);\n        List<Entity> ancestors = getCassandraAncestors();\n        log.info(\"Launching \" + entity + \": \" +\n                \"cluster \"+getClusterName()+\", \" +\n                \"hostname (public) \" + getEntity().getAttribute(Attributes.HOSTNAME) + \", \" +\n                \"hostname (subnet) \" + subnetHostname + \", \" +\n                \"seeds \"+((CassandraNode)entity).getSeeds()+\" (from \"+seeds+\")\");\n\n        boolean isFirst = seeds.iterator().next().equals(entity);\n        if (isClustered() && !isFirst && CassandraDatacenter.WAIT_FOR_FIRST) {\n            // wait for the first node\n            long firstStartTime = Entities.submit(entity, DependentConfiguration.attributeWhenReady(\n                ancestors.get(ancestors.size()-1), CassandraDatacenter.FIRST_NODE_STARTED_TIME_UTC)).getUnchecked();\n            // optionally force a delay before starting subsequent nodes; see comment at CassandraCluster.DELAY_AFTER_FIRST\n            Duration toWait = Duration.millis(firstStartTime + CassandraDatacenter.DELAY_AFTER_FIRST.toMilliseconds() -  System.currentTimeMillis());\n            if (toWait.toMilliseconds()>0) {\n                log.info(\"Launching \" + entity + \": delaying launch of non-first node by \"+toWait+\" to prevent schema disagreements\");\n                Tasks.setBlockingDetails(\"Pausing to ensure first node has time to start\");\n                Time.sleep(toWait);\n                Tasks.resetBlockingDetails();\n            }\n        }\n\n        List<Entity> queuedStart = null;\n        if (CassandraDatacenter.DELAY_BETWEEN_STARTS!=null && !ancestors.isEmpty()) {\n            Entity root = ancestors.get(ancestors.size()-1);\n            // TODO currently use the class as a semaphore; messy, and obviously will not federate;\n            // should develop a brooklyn framework semaphore (similar to that done on SshMachineLocation)\n            // and use it - note however the synch block is very very short so relatively safe at least\n            synchronized (CassandraNode.class) {\n                queuedStart = root.getAttribute(CassandraDatacenter.QUEUED_START_NODES);\n                if (queuedStart==null) {\n                    queuedStart = new ArrayList<Entity>();\n                    ((EntityLocal)root).setAttribute(CassandraDatacenter.QUEUED_START_NODES, queuedStart);\n                }\n                queuedStart.add(getEntity());\n                ((EntityLocal)root).setAttribute(CassandraDatacenter.QUEUED_START_NODES, queuedStart);\n            }\n            do {\n                // get it again in case it is backed by something external\n                queuedStart = root.getAttribute(CassandraDatacenter.QUEUED_START_NODES);\n                if (queuedStart.get(0).equals(getEntity())) break;\n                synchronized (queuedStart) {\n                    try {\n                        queuedStart.wait(1000);\n                    } catch (InterruptedException e) {\n                        Exceptions.propagate(e);\n                    }\n                }\n            } while (true);\n            \n            // TODO should look at last start time... but instead we always wait\n            CassandraDatacenter.DELAY_BETWEEN_STARTS.countdownTimer().waitForExpiryUnchecked();\n        }\n\n        try {\n            newScript(MutableMap.of(USE_PID_FILE, getPidFile()), LAUNCHING)\n                    .body.append(\n                            // log the date to attempt to debug occasional http://wiki.apache.org/cassandra/FAQ#schema_disagreement\n                            // (can be caused by machines out of synch time-wise; but in our case it seems to be caused by other things!)\n                            \"echo date on cassandra server `hostname` when launching is `date`\",\n                            launchEssentialCommand())\n                    .execute();\n            if (!isClustered()) {\n                InputStream creationScript = DatastoreMixins.getDatabaseCreationScript(entity);\n                if (creationScript!=null) { \n                    Tasks.setBlockingDetails(\"Pausing to ensure Cassandra (singleton) has started before running creation script\");\n                    Time.sleep(Duration.seconds(20));\n                    Tasks.resetBlockingDetails();\n                    executeScriptAsync(Streams.readFullyString(creationScript));\n                }\n            }\n            if (isClustered() && isFirst) {\n                for (Entity ancestor: getCassandraAncestors()) {\n                    ((EntityLocal)ancestor).setAttribute(CassandraDatacenter.FIRST_NODE_STARTED_TIME_UTC, System.currentTimeMillis());\n                }\n            }\n        } finally {\n            if (queuedStart!=null) {\n                Entity head = queuedStart.remove(0);\n                checkArgument(head.equals(getEntity()), \"first queued node was \"+head+\" but we are \"+getEntity());\n                synchronized (queuedStart) {\n                    queuedStart.notifyAll();\n                }\n            }\n        }\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public boolean isRunning() {\n        return newScript(MutableMap.of(\"usePidFile\", getPidFile()), CHECK_RUNNING).body.append(\"true\").execute() == 0;\n    }","id":36278,"modified_method":"@Override\n    public boolean isRunning() {\n        return newScript(MutableMap.of(USE_PID_FILE, getPidFile()), CHECK_RUNNING).execute() == 0;\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public ProcessTaskWrapper<Integer> executeScriptAsync(String commands) {\n        String fileToRun = Os.mergePathsUnix(\"brooklyn_commands\", \"cassandra-commands-\"+Identifiers.makeRandomId(8));\n        DynamicTasks.queueIfPossible(SshEffectorTasks.put(Os.mergePaths(getRunDir(), fileToRun))\n                .machine(getMachine())\n                .contents(commands)\n                .summary(\"copying cassandra script to execute \"+fileToRun)).orSubmitAndBlock(getEntity());\n        return executeScriptFromInstalledFileAsync(fileToRun);\n    }","id":36279,"modified_method":"@Override\n    public ProcessTaskWrapper<Integer> executeScriptAsync(String commands) {\n        String fileToRun = Os.mergePathsUnix(\"brooklyn_commands\", \"cassandra-commands-\"+Identifiers.makeRandomId(8));\n        TaskWrapper<Void> task = SshEffectorTasks.put(Os.mergePathsUnix(getRunDir(), fileToRun))\n                .machine(getMachine())\n                .contents(commands)\n                .summary(\"copying cassandra script to execute \"+fileToRun)\n                .newTask();\n        DynamicTasks.queueIfPossible(task).orSubmitAndBlock(getEntity()).andWaitForSuccess();\n        return executeScriptFromInstalledFileAsync(fileToRun);\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public void stop() {\n        newScript(MutableMap.of(\"usePidFile\", getPidFile()), STOPPING).body.append(\"true\").execute();\n    }","id":36280,"modified_method":"@Override\n    public void stop() {\n        newScript(MutableMap.of(USE_PID_FILE, getPidFile()), STOPPING).execute();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    protected String getLogFileLocation() { return String.format(\"%s/cassandra.log\", getRunDir()); }","id":36281,"modified_method":"@Override\n    protected String getLogFileLocation() { return Os.mergePathsUnix(getRunDir(),\"cassandra.log\"); }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"protected Map<String, Integer> getPortMap() {\n        return ImmutableMap.<String, Integer>builder()\n                .put(\"jmxPort\", entity.getAttribute(UsesJmx.JMX_PORT))\n                .put(\"rmiPort\", entity.getAttribute(UsesJmx.RMI_REGISTRY_PORT))\n                .put(\"gossipPort\", getGossipPort())\n                .put(\"sslGossipPort:\", getSslGossipPort())\n                .put(\"thriftPort\", getThriftPort())\n                .build();\n    }","id":36282,"modified_method":"protected Map<String, Integer> getPortMap() {\n        return ImmutableMap.<String, Integer>builder()\n                .put(\"jmxPort\", entity.getAttribute(UsesJmx.JMX_PORT))\n                .put(\"rmiPort\", entity.getAttribute(UsesJmx.RMI_REGISTRY_PORT))\n                .put(\"gossipPort\", getGossipPort())\n                .put(\"sslGossipPort\", getSslGossipPort())\n                .put(\"thriftPort\", getThriftPort())\n                .build();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"public String getPidFile() { return String.format(\"%s/cassandra.pid\", getRunDir()); }","id":36283,"modified_method":"public String getPidFile() { return Os.mergePathsUnix(getRunDir(), \"cassandra.pid\"); }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"@Override\n    public Map<String, String> getShellEnvironment() {\n        return MutableMap.<String, String>builder()\n                .putAll(super.getShellEnvironment())\n                .put(\"CASSANDRA_CONF\", String.format(\"%s/conf\", getRunDir()))\n                .renameKey(\"JAVA_OPTS\", \"JVM_OPTS\")\n                .build();\n    }","id":36284,"modified_method":"@Override\n    public Map<String, String> getShellEnvironment() {\n        return MutableMap.<String, String>builder()\n                .putAll(super.getShellEnvironment())\n                .put(\"CASSANDRA_CONF\", Os.mergePathsUnix(getRunDir(), \"conf\"))\n                .renameKey(\"JAVA_OPTS\", \"JVM_OPTS\")\n                .build();\n    }","commit_id":"f11402e648cb17c95af0a99dc060396307c4a6b1","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"/**\n     * Restarts redis with the current configuration.\n     */\n    @Override\n    public void stop() {\n        newScript(MutableMap.of(\"usePidFile\", false), STOPPING)\n                .failOnNonZeroResultCode()\n                .body.append(\"./bin/redis-cli -p \" + getEntity().getAttribute(RedisStore.REDIS_PORT) + \" shutdown\")\n                .execute();\n    }","id":36285,"modified_method":"/**\n     * Restarts redis with the current configuration.\n     */\n    @Override\n    public void stop() {\n        int exitCode = newScript(MutableMap.of(\"usePidFile\", false), STOPPING)\n                .body.append(\"./bin/redis-cli -p \" + getEntity().getAttribute(RedisStore.REDIS_PORT) + \" shutdown\")\n                .execute();\n        // TODO: Good enough? Will cause warnings when trying to stop a server that is already not running.\n        if (exitCode != 0) {\n            LOG.warn(\"Unexpected exit code when stopping {}: {}\", entity, exitCode);\n        }\n    }","commit_id":"e5c189ac7350b66418525758a3e2e063bd108f77","url":"https://github.com/apache/incubator-brooklyn"},{"original_method":"private void openCurrentMessageNodeIfPossible() {\n    Message selectedMessage = (Message) myList.getSelectedValue();\n    if (selectedMessage == null) return;\n    SNode node = selectedMessage.getNode();\n    if (node == null) return;\n    IOperationContext context = selectedMessage.getContext();\n    if (context == null) return;\n    context.getComponent(EditorsPane.class).openEditor(node, context);\n  }","id":36286,"modified_method":"private void openCurrentMessageNodeIfPossible() {\n    Message selectedMessage = (Message) myList.getSelectedValue();\n    if (selectedMessage == null) return;\n    SNode node = selectedMessage.getNode();\n    if (node == null) return;\n    IOperationContext context = selectedMessage.getContext();\n    if (context == null) return;\n    AbstractEditorComponent editor = context.getComponent(EditorsPane.class).openEditor(node, context);\n    if (node.isRoot()) editor.selectFirstEditableCellOf(node);\n    else editor.selectNode(node);\n  }","commit_id":"97d61cc6e44ad1ece71e71d912415f5eb5a8da1a","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void openEditor(IEditorInput editorInput) throws Exception {\n\t\topenedEditor = (BaseTextEditor) PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage()\n\t\t\t\t.openEditor(editorInput, EDITOR_ID);\n\t\twaitForJobCompletion();\n\t\tsleep(STEP_DELAY);\n\t}","id":36287,"modified_method":"@SuppressWarnings(\"restriction\")\n\tprivate void openEditor(IEditorInput editorInput) throws Exception {\n\n\t\tIEditorPart openEditor = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage().openEditor(\n\t\t\t\teditorInput, EDITOR_ID);\n\t\tif (openEditor instanceof BaseTextEditor) {\n\t\t\topenedEditor = (BaseTextEditor) openEditor;\n\t\t\twaitForJobCompletion();\n\t\t\tsleep(STEP_DELAY);\n\t\t}\n\t\telse if (openEditor instanceof ErrorEditorPart) {\n\t\t\tfail(\"Could not open BaseTextEditor. Editor produced errors during initialization.\");\n\t\t}\n\t\telse {\n\t\t\tfail(\"Opened Editor with id:\" + EDITOR_ID + \", is not a BaseXtextEditor\");\n\t\t}\n\t}","commit_id":"d12f8ae676212bd7f1f5d2ff5b782db6582a8b02","url":"https://github.com/eclipse/xtext"},{"original_method":"public void doOpen(final URI uri) {\n\t\tIFile file = getContainingResourceSetFile(uri);\n\t\tIWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();\n\t\ttry {\n\t\t\tIEditorPart openEditor = IDE.openEditor(page, file);\n\t\t\tif (openEditor instanceof XtextEditor) {\n\t\t\t\tfinal XtextEditor edit = (XtextEditor) openEditor;\n\t\t\t\tif (uri.fragment()!=null) {\n\t\t\t\tedit.getDocument().readOnly(new UnitOfWork<Object>(){\n\n\t\t\t\t\tpublic Object exec(XtextResource resource) throws Exception {\n\t\t\t\t\t\tEObject object = resource.getEObject(uri.fragment());\n\t\t\t\t\t\tRegion region = locationProvider.getLocation(object);\n\t\t\t\t\t\tedit.selectAndReveal(region.getOffset(),region.getLength());\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}});\n\t\t\t\t}\n\t\t\t} else if (openEditor instanceof ISelectionProvider) {\n\t\t\t\t//TODO: use ISelectionProvider instead of ITextEditor\n\t\t\t}\n\t\t}\n\t\tcatch (PartInitException partInitException) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\",\n\t\t\t\t\tpartInitException);\n\t\t}\n\t}","id":36288,"modified_method":"public void doOpen(final URI uri) {\n\t\tIFile file = getContainingResourceSetFile(uri);\n\t\tIWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();\n\t\tIEditorPart openEditor = null;\n\t\ttry {\n\t\t\tif (file != null) {\n\t\t\t\topenEditor = IDE.openEditor(page, file);\n\t\t\t} else if (uri.isArchive()) {\n\t\t\t\t// TODO don't fall back to java.io\n\t\t\t\tIEditorInput input = new XtextReadonlyEditorInput(new ReadonlyArchiveStorage(uri));\n\t\t\t\topenEditor = IDE.openEditor(page, input, PlatformUI.getWorkbench().getEditorRegistry()\n\t\t\t\t\t\t.getDefaultEditor(uri.lastSegment()).getId());\n\t\t\t} else {\n\t\t\t\t// fall back: URI is bundle resource uri and has to converted\n\t\t\t\tURL url = FileLocator.toFileURL(new URL(uri.scheme()+ \":\" +uri.devicePath()));\n\t\t\t\tURI urlAsUri = URI.createURI(url.toString());\n\t\t\t\tString path = urlAsUri.toFileString();\n\t\t\t\tFile ioFile = new File(path);\n\t\t\t\t// TODO don't fall back to java.io\n\t\t\t\tIEditorInput input = new XtextReadonlyEditorInput(new ReadonlyFileStorage(ioFile, uri));\n\t\t\t\topenEditor = IDE.openEditor(page, input, PlatformUI.getWorkbench().getEditorRegistry()\n\t\t\t\t\t\t.getDefaultEditor(uri.lastSegment()).getId());\n\t\t\t}\n\t\t} catch (PartInitException partInitException) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\",\n\t\t\t\t\tpartInitException);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\", e);\n\t\t}\n\t\tif (openEditor != null && openEditor instanceof XtextEditor) {\n\t\t\tfinal XtextEditor edit = (XtextEditor) openEditor;\n\t\t\tif (uri.fragment()!=null) {\n\t\t\t\tedit.getDocument().readOnly(new UnitOfWork<Object>(){\n\t\t\t\tpublic Object exec(XtextResource resource) throws Exception {\n\t\t\t\t\tEObject object = resource.getEObject(uri.fragment());\n\t\t\t\t\tRegion region = locationProvider.getLocation(object);\n\t\t\t\t\tedit.selectAndReveal(region.getOffset(),region.getLength());\n\t\t\t\t\treturn null;\n\t\t\t\t}});\n\t\t\t}\n\t\t} else if (openEditor instanceof ISelectionProvider) {\n\t\t\t//TODO: use ISelectionProvider instead of ITextEditor\n\t\t}\n\t}","commit_id":"1ae4a26b4ecf7d172730a021fec9c8786f0a596a","url":"https://github.com/eclipse/xtext"},{"original_method":"private IFile getContainingResourceSetFile(URI uri) {\n\t\tIFile targetFile = uri.isPlatformResource() ?\n\t\t\t\tResourcesPlugin.getWorkspace().getRoot().getFile(\n\t\t\t\t\t\tnew Path(uri.toPlatformString(true)))\n\t\t\t\t: ResourcesPlugin.getWorkspace().getRoot().getFileForLocation(\n\t\t\t\t\t\tnew Path(uri.toFileString()));\n\t\treturn targetFile;\n\t}","id":36289,"modified_method":"private IFile getContainingResourceSetFile(URI uri) {\n\t\tString path = null;\n\t\tif (uri.isPlatformResource()) {\n\t\t\tpath = uri.toPlatformString(true);\n\t\t} else if (uri.isPlatformPlugin()) {\n\t\t\tpath = uri.toPlatformString(true);\n\t\t} else if (uri.isFile()) {\n\t\t\tpath = uri.toFileString();\n\t\t} else if (uri.isArchive()) {\n\t\t\tURI archiveUri = URI.createURI(uri.authority());\n\t\t\tString archive = null;\n\t\t\tif (archiveUri.isFile()) {\n\t\t\t\tarchive = archiveUri.toFileString();\n\t\t\t} else if (archiveUri.isPlatformResource()) {\n\t\t\t\tarchive = archiveUri.toPlatformString(true);\n\t\t\t} else {\n\t\t\t\tarchive = archiveUri.toString();\n\t\t\t}\n\t\t\tpath = uri.scheme() + \":\" + archive + uri.path();\n\t\t} else {\n\t\t\tpath = uri.toString();\n\t\t}\n\t\tIFile result = null;\n\t\tif (uri.isPlatformResource()) {\n\t\t\tresult = ResourcesPlugin.getWorkspace().getRoot().getFile(new Path(path));\n\t\t} else {\n\t\t\tresult = ResourcesPlugin.getWorkspace().getRoot().getFileForLocation(new Path(path));\n\t\t\tif (result == null) {\n\t\t\t\tIResource res = ResourcesPlugin.getWorkspace().getRoot().findMember(path);\n\t\t\t\tif (res != null && (res instanceof IFile))\n\t\t\t\t\tresult = (IFile) res;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}","commit_id":"1ae4a26b4ecf7d172730a021fec9c8786f0a596a","url":"https://github.com/eclipse/xtext"},{"original_method":"public void setInput(IEditorInput editorInput) {\n\t\tfile = ResourceUtil.getFile(editorInput);\n\n\t\tresourceSet = resourceSetProvider.get();\n\t\tif (file != null) {\n\t\t\t// TODO find a way to identify a project for an IStorageEditorInput\n\t\t\tIJavaProject javaProject = getIJavaProject(file);\n\t\t\tif (javaProject != null) {\n\t\t\t\tresourceSet.setClasspathUriResolver(new JdtClasspathUriResolver());\n\t\t\t\tresourceSet.setClasspathURIContext(javaProject);\n\t\t\t}\n\t\t}\n\n\t\tIPath path = null;\n\t\tif (file != null) {\n\t\t\tpath = file.getFullPath();\n\t\t} else {\n\t\t\tIStorageEditorInput storageInput = (IStorageEditorInput) editorInput;\n\t\t\ttry {\n\t\t\t\t// TODO get the FQN of the resource\n\t\t\t\tpath = storageInput.getStorage().getFullPath();\n\t\t\t}\n\t\t\tcatch (CoreException e) {\n\t\t\t\tthrow new WrappedException(e);\n\t\t\t}\n\t\t}\n\t\tResource aResource = resourceSet.createResource(URI.createPlatformResourceURI(path.toString(), true));\n\t\tif (!(aResource instanceof XtextResource))\n\t\t\tthrow new IllegalStateException(\"The resource factory registered for \" + path\n\t\t\t\t\t+ \" is not an XtextResourceFactory. Make sure the right resource factory has been registered.\");\n\t\tresource = (XtextResource) aResource;\n\t\tresource.setValidationDisabled(file == null);\n\t}","id":36290,"modified_method":"public void setInput(IEditorInput editorInput) {\n\t\tfile = ResourceUtil.getFile(editorInput);\n\n\t\tresourceSet = resourceSetProvider.get();\n\t\tif (file != null) {\n\t\t\t// TODO find a way to identify a project for an IStorageEditorInput\n\t\t\tIJavaProject javaProject = getIJavaProject(file);\n\t\t\tif (javaProject != null) {\n\t\t\t\tresourceSet.setClasspathUriResolver(new JdtClasspathUriResolver());\n\t\t\t\tresourceSet.setClasspathURIContext(javaProject);\n\t\t\t}\n\t\t}\n\n\t\tIPath path = null;\n\t\tResource aResource = null;\n\t\tURI uri = null;\n\t\tif (file != null) {\n\t\t\tpath = file.getFullPath();\n\t\t\turi = URI.createPlatformResourceURI(path.toString(), true);\n\t\t} else if (editorInput instanceof XtextReadonlyEditorInput){\n\t\t\turi = ((XtextReadonlyEditorInput) editorInput).getURI();\n\t\t} else {\n\t\t\tIStorageEditorInput storageInput = (IStorageEditorInput) editorInput;\n\t\t\ttry {\n\t\t\t\t// TODO get the FQN of the resource\n\t\t\t\tpath = storageInput.getStorage().getFullPath();\n\t\t\t\turi = URI.createPlatformResourceURI(path.toString(), true);\n\t\t\t}\n\t\t\tcatch (CoreException e) {\n\t\t\t\tthrow new WrappedException(e);\n\t\t\t}\n\t\t}\n\n\t\taResource = resourceSet.createResource(uri);\n\t\tif (!(aResource instanceof XtextResource))\n\t\t\tthrow new IllegalStateException(\"The resource factory registered for \" + path\n\t\t\t\t\t+ \" is not an XtextResourceFactory. Make sure the right resource factory has been registered.\");\n\t\tresource = (XtextResource) aResource;\n\t\tresource.setValidationDisabled(file == null);\n\t}","commit_id":"1ae4a26b4ecf7d172730a021fec9c8786f0a596a","url":"https://github.com/eclipse/xtext"},{"original_method":"public void doOpen(final URI uri) {\n\t\tIFile file = getContainingResourceSetFile(uri);\n\t\tIWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();\n\t\ttry {\n\t\t\tIEditorPart openEditor = IDE.openEditor(page, file);\n\t\t\tif (openEditor instanceof XtextEditor) {\n\t\t\t\tfinal XtextEditor edit = (XtextEditor) openEditor;\n\t\t\t\tif (uri.fragment()!=null) {\n\t\t\t\tedit.getDocument().readOnly(new UnitOfWork<Object>(){\n\n\t\t\t\t\tpublic Object exec(XtextResource resource) throws Exception {\n\t\t\t\t\t\tEObject object = resource.getEObject(uri.fragment());\n\t\t\t\t\t\tRegion region = locationProvider.getLocation(object);\n\t\t\t\t\t\tedit.selectAndReveal(region.getOffset(),region.getLength());\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}});\n\t\t\t\t}\n\t\t\t} else if (openEditor instanceof ISelectionProvider) {\n\t\t\t\t//TODO: use ISelectionProvider instead of ITextEditor\n\t\t\t}\n\t\t}\n\t\tcatch (PartInitException partInitException) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\",\n\t\t\t\t\tpartInitException);\n\t\t}\n\t}","id":36291,"modified_method":"public void doOpen(final URI uri) {\n\t\tIFile file = getContainingResourceSetFile(uri);\n\t\tIWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();\n\t\tIEditorPart openEditor = null;\n\t\ttry {\n\t\t\tif (file != null) {\n\t\t\t\topenEditor = IDE.openEditor(page, file);\n\t\t\t} else if (uri.isArchive()) {\n\t\t\t\t// TODO don't fall back to java.io\n\t\t\t\tIEditorInput input = new XtextReadonlyEditorInput(new ReadonlyArchiveStorage(uri));\n\t\t\t\topenEditor = IDE.openEditor(page, input, PlatformUI.getWorkbench().getEditorRegistry()\n\t\t\t\t\t\t.getDefaultEditor(uri.lastSegment()).getId());\n\t\t\t} else {\n\t\t\t\t// fall back: URI is bundle resource uri and has to converted\n\t\t\t\tURL url = FileLocator.toFileURL(new URL(uri.scheme()+ \":\" +uri.devicePath()));\n\t\t\t\tURI urlAsUri = URI.createURI(url.toString());\n\t\t\t\tString path = urlAsUri.toFileString();\n\t\t\t\tFile ioFile = new File(path);\n\t\t\t\t// TODO don't fall back to java.io\n\t\t\t\tIEditorInput input = new XtextReadonlyEditorInput(new ReadonlyFileStorage(ioFile, uri));\n\t\t\t\topenEditor = IDE.openEditor(page, input, PlatformUI.getWorkbench().getEditorRegistry()\n\t\t\t\t\t\t.getDefaultEditor(uri.lastSegment()).getId());\n\t\t\t}\n\t\t} catch (PartInitException partInitException) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\",\n\t\t\t\t\tpartInitException);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Error while opening editor part for EMF URI '\" + uri + \"'\", e);\n\t\t}\n\t\tif (openEditor != null && openEditor instanceof XtextEditor) {\n\t\t\tfinal XtextEditor edit = (XtextEditor) openEditor;\n\t\t\tif (uri.fragment()!=null) {\n\t\t\t\tedit.getDocument().readOnly(new UnitOfWork<Object>(){\n\t\t\t\tpublic Object exec(XtextResource resource) throws Exception {\n\t\t\t\t\tEObject object = resource.getEObject(uri.fragment());\n\t\t\t\t\tRegion region = locationProvider.getLocation(object);\n\t\t\t\t\tedit.selectAndReveal(region.getOffset(),region.getLength());\n\t\t\t\t\treturn null;\n\t\t\t\t}});\n\t\t\t}\n\t\t} else if (openEditor instanceof ISelectionProvider) {\n\t\t\t//TODO: use ISelectionProvider instead of ITextEditor\n\t\t}\n\t}","commit_id":"a580428f3816b2603069236cde8bd3dac5e301a6","url":"https://github.com/eclipse/xtext"},{"original_method":"private IFile getContainingResourceSetFile(URI uri) {\n\t\tIFile targetFile = uri.isPlatformResource() ?\n\t\t\t\tResourcesPlugin.getWorkspace().getRoot().getFile(\n\t\t\t\t\t\tnew Path(uri.toPlatformString(true)))\n\t\t\t\t: ResourcesPlugin.getWorkspace().getRoot().getFileForLocation(\n\t\t\t\t\t\tnew Path(uri.toFileString()));\n\t\treturn targetFile;\n\t}","id":36292,"modified_method":"private IFile getContainingResourceSetFile(URI uri) {\n\t\tString path = null;\n\t\tif (uri.isPlatformResource()) {\n\t\t\tpath = uri.toPlatformString(true);\n\t\t} else if (uri.isPlatformPlugin()) {\n\t\t\tpath = uri.toPlatformString(true);\n\t\t} else if (uri.isFile()) {\n\t\t\tpath = uri.toFileString();\n\t\t} else if (uri.isArchive()) {\n\t\t\tURI archiveUri = URI.createURI(uri.authority());\n\t\t\tString archive = null;\n\t\t\tif (archiveUri.isFile()) {\n\t\t\t\tarchive = archiveUri.toFileString();\n\t\t\t} else if (archiveUri.isPlatformResource()) {\n\t\t\t\tarchive = archiveUri.toPlatformString(true);\n\t\t\t} else {\n\t\t\t\tarchive = archiveUri.toString();\n\t\t\t}\n\t\t\tpath = uri.scheme() + \":\" + archive + uri.path();\n\t\t} else {\n\t\t\tpath = uri.toString();\n\t\t}\n\t\tIFile result = null;\n\t\tif (uri.isPlatformResource()) {\n\t\t\tresult = ResourcesPlugin.getWorkspace().getRoot().getFile(new Path(path));\n\t\t} else {\n\t\t\tresult = ResourcesPlugin.getWorkspace().getRoot().getFileForLocation(new Path(path));\n\t\t\tif (result == null) {\n\t\t\t\tIResource res = ResourcesPlugin.getWorkspace().getRoot().findMember(path);\n\t\t\t\tif (res != null && (res instanceof IFile))\n\t\t\t\t\tresult = (IFile) res;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}","commit_id":"a580428f3816b2603069236cde8bd3dac5e301a6","url":"https://github.com/eclipse/xtext"},{"original_method":"public void setInput(IEditorInput editorInput) {\n\t\tfile = ResourceUtil.getFile(editorInput);\n\n\t\tresourceSet = resourceSetProvider.get();\n\t\tif (file != null) {\n\t\t\t// TODO find a way to identify a project for an IStorageEditorInput\n\t\t\tIJavaProject javaProject = getIJavaProject(file);\n\t\t\tif (javaProject != null) {\n\t\t\t\tresourceSet.setClasspathUriResolver(new JdtClasspathUriResolver());\n\t\t\t\tresourceSet.setClasspathURIContext(javaProject);\n\t\t\t}\n\t\t}\n\n\t\tIPath path = null;\n\t\tif (file != null) {\n\t\t\tpath = file.getFullPath();\n\t\t} else {\n\t\t\tIStorageEditorInput storageInput = (IStorageEditorInput) editorInput;\n\t\t\ttry {\n\t\t\t\t// TODO get the FQN of the resource\n\t\t\t\tpath = storageInput.getStorage().getFullPath();\n\t\t\t}\n\t\t\tcatch (CoreException e) {\n\t\t\t\tthrow new WrappedException(e);\n\t\t\t}\n\t\t}\n\t\tResource aResource = resourceSet.createResource(URI.createPlatformResourceURI(path.toString(), true));\n\t\tif (!(aResource instanceof XtextResource))\n\t\t\tthrow new IllegalStateException(\"The resource factory registered for \" + path\n\t\t\t\t\t+ \" is not an XtextResourceFactory. Make sure the right resource factory has been registered.\");\n\t\tresource = (XtextResource) aResource;\n\t\tresource.setValidationDisabled(file == null);\n\t}","id":36293,"modified_method":"public void setInput(IEditorInput editorInput) {\n\t\tfile = ResourceUtil.getFile(editorInput);\n\n\t\tresourceSet = resourceSetProvider.get();\n\t\tif (file != null) {\n\t\t\t// TODO find a way to identify a project for an IStorageEditorInput\n\t\t\tIJavaProject javaProject = getIJavaProject(file);\n\t\t\tif (javaProject != null) {\n\t\t\t\tresourceSet.setClasspathUriResolver(new JdtClasspathUriResolver());\n\t\t\t\tresourceSet.setClasspathURIContext(javaProject);\n\t\t\t}\n\t\t}\n\n\t\tIPath path = null;\n\t\tResource aResource = null;\n\t\tURI uri = null;\n\t\tif (file != null) {\n\t\t\tpath = file.getFullPath();\n\t\t\turi = URI.createPlatformResourceURI(path.toString(), true);\n\t\t} else if (editorInput instanceof XtextReadonlyEditorInput){\n\t\t\turi = ((XtextReadonlyEditorInput) editorInput).getURI();\n\t\t} else {\n\t\t\tIStorageEditorInput storageInput = (IStorageEditorInput) editorInput;\n\t\t\ttry {\n\t\t\t\t// TODO get the FQN of the resource\n\t\t\t\tpath = storageInput.getStorage().getFullPath();\n\t\t\t\turi = URI.createPlatformResourceURI(path.toString(), true);\n\t\t\t}\n\t\t\tcatch (CoreException e) {\n\t\t\t\tthrow new WrappedException(e);\n\t\t\t}\n\t\t}\n\n\t\taResource = resourceSet.createResource(uri);\n\t\tif (!(aResource instanceof XtextResource))\n\t\t\tthrow new IllegalStateException(\"The resource factory registered for \" + path\n\t\t\t\t\t+ \" is not an XtextResourceFactory. Make sure the right resource factory has been registered.\");\n\t\tresource = (XtextResource) aResource;\n\t\tresource.setValidationDisabled(file == null);\n\t}","commit_id":"a580428f3816b2603069236cde8bd3dac5e301a6","url":"https://github.com/eclipse/xtext"},{"original_method":"public void setEncryptionUser(WSSecEncryptedKey encrKeyBuilder, TokenWrapper token, boolean sign) {\n        String encrUser = (String)message.getContextualProperty(sign \n                                                                ? SecurityConstants.USERNAME\n                                                                : SecurityConstants.ENCRYPT_USERNAME);\n        if (encrUser == null || \"\".equals(encrUser)) {\n            policyNotAsserted(token, \"No \" + (sign ? \"signature\" : \"encryption\") + \" username found.\");\n        }\n        if (encrUser.equals(WSHandlerConstants.USE_REQ_SIG_CERT)) {\n            Object resultsObj = message.getExchange().getInMessage().get(WSHandlerConstants.RECV_RESULTS);\n            if (resultsObj != null) {\n                encrKeyBuilder.setUseThisCert(getReqSigCert((Vector)resultsObj));\n                 \n                //TODO This is a hack, this should not come under USE_REQ_SIG_CERT\n                if (encrKeyBuilder.isCertSet()) {\n                    encrKeyBuilder.setUserInfo(getUsername((Vector)resultsObj));\n                }\n            } else {\n                policyNotAsserted(token, \"No security results in incoming message\");\n            }\n        } else {\n            encrKeyBuilder.setUserInfo(encrUser);\n        }\n    }","id":36294,"modified_method":"public void setEncryptionUser(WSSecEncryptedKey encrKeyBuilder, TokenWrapper token, boolean sign) {\n        String encrUser = (String)message.getContextualProperty(sign \n                                                                ? SecurityConstants.USERNAME\n                                                                : SecurityConstants.ENCRYPT_USERNAME);\n        if (encrUser == null || \"\".equals(encrUser)) {\n            policyNotAsserted(token, \"No \" + (sign ? \"signature\" : \"encryption\") + \" username found.\");\n        }\n        if (WSHandlerConstants.USE_REQ_SIG_CERT.equals(encrUser)) {\n            Object resultsObj = message.getExchange().getInMessage().get(WSHandlerConstants.RECV_RESULTS);\n            if (resultsObj != null) {\n                encrKeyBuilder.setUseThisCert(getReqSigCert((Vector)resultsObj));\n                 \n                //TODO This is a hack, this should not come under USE_REQ_SIG_CERT\n                if (encrKeyBuilder.isCertSet()) {\n                    encrKeyBuilder.setUserInfo(getUsername((Vector)resultsObj));\n                }\n            } else {\n                policyNotAsserted(token, \"No security results in incoming message\");\n            }\n        } else {\n            encrKeyBuilder.setUserInfo(encrUser);\n        }\n    }","commit_id":"4d4cf4d322db069851e03183ac20a982017ce9cc","url":"https://github.com/apache/cxf"},{"original_method":"private WSSecBase doEncryption(TokenWrapper recToken,\n                                   SecurityToken encrTok,\n                                   Element encrElem,\n                                   Vector<WSEncryptionPart> encrParts) {\n        //Do encryption\n        if (recToken != null && recToken.getToken() != null && encrParts.size() > 0) {\n            Token encrToken = recToken.getToken();\n            policyAsserted(recToken);\n            policyAsserted(encrToken);\n            AlgorithmSuite algorithmSuite = sbinding.getAlgorithmSuite();\n            if (encrToken.isDerivedKeys()) {\n                try {\n                    WSSecDKEncrypt dkEncr = new WSSecDKEncrypt();\n                    \n                    if (encrElem != null && encrTok.getAttachedReference() != null) {\n                        dkEncr.setExternalKey(encrTok.getSecret(),\n                                              (Element)saaj.getSOAPPart()\n                                                  .importNode((Element) encrTok.getAttachedReference(),\n                                        true));\n                    } else if (encrTok.getUnattachedReference() != null) {\n                        dkEncr.setExternalKey(encrTok.getSecret(), (Element)saaj.getSOAPPart()\n                                .importNode((Element) encrTok.getUnattachedReference(),\n                                        true));\n                    } else if (!isRequestor()) { \n                        // If the Encrypted key used to create the derived key is not\n                        // attached use key identifier as defined in WSS1.1 section\n                        // 7.7 Encrypted Key reference\n                        SecurityTokenReference tokenRef = new SecurityTokenReference(saaj.getSOAPPart());\n                        if (encrTok.getSHA1() != null) {\n                            tokenRef.setKeyIdentifierEncKeySHA1(encrTok.getSHA1());\n                        }\n                        dkEncr.setExternalKey(encrTok.getSecret(), tokenRef.getElement());\n                    } else {\n                        dkEncr.setExternalKey(encrTok.getSecret(), encrTok.getId());\n                    }\n                    \n                    if (encrTok.getSHA1() != null) {\n                        dkEncr.setCustomValueType(WSConstants.SOAPMESSAGE_NS11 + \"#\"\n                                + WSConstants.ENC_KEY_VALUE_TYPE);\n                    }\n                    \n                    dkEncr.setSymmetricEncAlgorithm(sbinding.getAlgorithmSuite().getEncryption());\n                    dkEncr.setDerivedKeyLength(sbinding.getAlgorithmSuite()\n                                                   .getEncryptionDerivedKeyLength() / 8);\n                    dkEncr.prepare(saaj.getSOAPPart());\n                    Element encrDKTokenElem = null;\n                    encrDKTokenElem = dkEncr.getdktElement();\n                    addDerivedKeyElement(encrDKTokenElem);\n                    Element refList = dkEncr.encryptForExternalRef(null, encrParts);\n                    this.addDerivedKeyElement(refList);\n                    return dkEncr;\n                } catch (Exception e) {\n                    policyNotAsserted(recToken, e);\n                }\n            } else {\n                try {\n                    WSSecEncrypt encr = new WSSecEncrypt();\n                    String encrTokId = encrTok.getId();\n                    if (encrTokId.startsWith(\"#\")) {\n                        encrTokId = encrTokId.substring(1);\n                    }\n                    encr.setEncKeyId(encrTokId);\n                    encr.setEphemeralKey(encrTok.getSecret());\n                    setEncryptionUser(encr, recToken, false);\n                   \n                    encr.setDocument(saaj.getSOAPPart());\n                    encr.setEncryptSymmKey(false);\n                    encr.setSymmetricEncAlgorithm(algorithmSuite.getEncryption());\n                    \n                    if (!isRequestor()) {\n                        encr.setUseKeyIdentifier(true);\n                        encr.setCustomReferenceValue(encrTok.getSHA1());\n                        encr.setKeyIdentifierType(WSConstants.ENCRYPTED_KEY_SHA1_IDENTIFIER);\n                    }\n\n                    \n                    encr.prepare(saaj.getSOAPPart(),\n                                 getEncryptionCrypto(recToken));\n                   \n                    if (encr.getBSTTokenId() != null) {\n                        encr.prependBSTElementToHeader(secHeader);\n                    }\n                   \n                   \n                    Element refList = encr.encryptForExternalRef(null, encrParts);\n                    this.addDerivedKeyElement(refList);\n\n                    return encr;\n                } catch (WSSecurityException e) {\n                    policyNotAsserted(recToken, e.getMessage());\n                }    \n            }\n        }\n        return null;\n    }","id":36295,"modified_method":"private WSSecBase doEncryption(TokenWrapper recToken,\n                                   SecurityToken encrTok,\n                                   boolean attached,\n                                   Vector<WSEncryptionPart> encrParts,\n                                   boolean atEnd) {\n        //Do encryption\n        if (recToken != null && recToken.getToken() != null && encrParts.size() > 0) {\n            Token encrToken = recToken.getToken();\n            policyAsserted(recToken);\n            policyAsserted(encrToken);\n            AlgorithmSuite algorithmSuite = sbinding.getAlgorithmSuite();\n            if (encrToken.isDerivedKeys()) {\n                try {\n                    WSSecDKEncrypt dkEncr = new WSSecDKEncrypt();\n                    \n                    if (attached && encrTok.getAttachedReference() != null) {\n                        dkEncr.setExternalKey(encrTok.getSecret(),\n                                              (Element)saaj.getSOAPPart()\n                                                  .importNode((Element) encrTok.getAttachedReference(),\n                                        true));\n                    } else if (encrTok.getUnattachedReference() != null) {\n                        dkEncr.setExternalKey(encrTok.getSecret(), (Element)saaj.getSOAPPart()\n                                .importNode((Element) encrTok.getUnattachedReference(),\n                                        true));\n                    } else if (!isRequestor()) { \n                        // If the Encrypted key used to create the derived key is not\n                        // attached use key identifier as defined in WSS1.1 section\n                        // 7.7 Encrypted Key reference\n                        SecurityTokenReference tokenRef = new SecurityTokenReference(saaj.getSOAPPart());\n                        if (encrTok.getSHA1() != null) {\n                            tokenRef.setKeyIdentifierEncKeySHA1(encrTok.getSHA1());\n                        }\n                        dkEncr.setExternalKey(encrTok.getSecret(), tokenRef.getElement());\n                    } else {\n                        dkEncr.setExternalKey(encrTok.getSecret(), encrTok.getId());\n                    }\n                    \n                    if (encrTok.getSHA1() != null) {\n                        dkEncr.setCustomValueType(WSConstants.SOAPMESSAGE_NS11 + \"#\"\n                                + WSConstants.ENC_KEY_VALUE_TYPE);\n                    }\n                    \n                    dkEncr.setSymmetricEncAlgorithm(sbinding.getAlgorithmSuite().getEncryption());\n                    dkEncr.setDerivedKeyLength(sbinding.getAlgorithmSuite()\n                                                   .getEncryptionDerivedKeyLength() / 8);\n                    dkEncr.prepare(saaj.getSOAPPart());\n                    Element encrDKTokenElem = null;\n                    encrDKTokenElem = dkEncr.getdktElement();\n                    addDerivedKeyElement(encrDKTokenElem);\n                    Element refList = dkEncr.encryptForExternalRef(null, encrParts);\n                    if (atEnd) {\n                        this.insertBeforeBottomUp(refList);\n                    } else {\n                        this.addDerivedKeyElement(refList);                        \n                    }\n                    return dkEncr;\n                } catch (Exception e) {\n                    policyNotAsserted(recToken, e);\n                }\n            } else {\n                try {\n                    WSSecEncrypt encr = new WSSecEncrypt();\n                    String encrTokId = encrTok.getId();\n                    if (encrTokId.startsWith(\"#\")) {\n                        encrTokId = encrTokId.substring(1);\n                    }\n                    encr.setEncKeyId(encrTokId);\n                    encr.setEphemeralKey(encrTok.getSecret());\n                    setEncryptionUser(encr, recToken, false);\n                   \n                    encr.setDocument(saaj.getSOAPPart());\n                    encr.setEncryptSymmKey(false);\n                    encr.setSymmetricEncAlgorithm(algorithmSuite.getEncryption());\n                    \n                    if (!isRequestor()) {\n                        encr.setUseKeyIdentifier(true);\n                        encr.setCustomReferenceValue(encrTok.getSHA1());\n                        encr.setKeyIdentifierType(WSConstants.ENCRYPTED_KEY_SHA1_IDENTIFIER);\n                    }\n\n                    \n                    encr.prepare(saaj.getSOAPPart(),\n                                 getEncryptionCrypto(recToken));\n                   \n                    if (encr.getBSTTokenId() != null) {\n                        encr.prependBSTElementToHeader(secHeader);\n                    }\n                   \n                   \n                    Element refList = encr.encryptForExternalRef(null, encrParts);\n                    if (atEnd) {\n                        this.insertBeforeBottomUp(refList);\n                    } else {\n                        this.addDerivedKeyElement(refList);                        \n                    }\n                    return encr;\n                } catch (WSSecurityException e) {\n                    policyNotAsserted(recToken, e.getMessage());\n                }    \n            }\n        }\n        return null;\n    }","commit_id":"4d4cf4d322db069851e03183ac20a982017ce9cc","url":"https://github.com/apache/cxf"},{"original_method":"public void handleBinding() {\n        WSSecTimestamp timestamp = createTimestamp();\n        handleLayout(timestamp);\n        \n        if (isRequestor()) {\n            //Setup required tokens\n            initializeTokens();\n        }\n        \n        if (sbinding.getProtectionOrder() == SPConstants.ProtectionOrder.EncryptBeforeSigning) {\n//            doEncryptBeforeSign();\n            System.err.println(\"encrypt before sign, not yet\");\n        } else {\n            doSignBeforeEncrypt();\n        }\n\n    }","id":36296,"modified_method":"public void handleBinding() {\n        WSSecTimestamp timestamp = createTimestamp();\n        handleLayout(timestamp);\n        \n        if (isRequestor()) {\n            //Setup required tokens\n            initializeTokens();\n        }\n        \n        if (sbinding.getProtectionOrder() == SPConstants.ProtectionOrder.EncryptBeforeSigning) {\n            try {\n                doEncryptBeforeSign();\n            } catch (Exception e) {\n                e.printStackTrace();\n                //REVISIT - exception\n            }\n        } else {\n            doSignBeforeEncrypt();\n        }\n        //REVIST - what to do with these policies?\n        policyAsserted(SP11Constants.TRUST_10);\n        policyAsserted(SP12Constants.TRUST_13);\n\n    }","commit_id":"4d4cf4d322db069851e03183ac20a982017ce9cc","url":"https://github.com/apache/cxf"},{"original_method":"private void doSignBeforeEncrypt() {\n        TokenWrapper sigTokenWrapper = getSignatureToken();\n        Token sigToken = sigTokenWrapper.getToken();\n        \n        \n        String sigTokId = null;\n        Element sigTokElem = null;\n        \n        try {\n            if (sigToken != null) {\n                if (sigToken instanceof SecureConversationToken) {\n                    //sigTokId = getSecConvTokenId();\n                } else if (sigToken instanceof IssuedToken) {\n                    //sigTokId = getIssuedSignatureTokenId();\n                } else if (sigToken instanceof X509Token) {\n                    if (isRequestor()) {\n                        sigTokId = setupEncryptedKey(sigTokenWrapper, sigToken);\n                    } else {\n                        sigTokId = getEncryptedKey();\n                    }\n                }\n            } else {\n                policyNotAsserted(sbinding, \"No signature token\");\n                return;\n            }\n            \n            if (StringUtils.isEmpty(sigTokId)) {\n                policyNotAsserted(sigTokenWrapper, \"No signature token id\");\n                return;\n            } else {\n                policyAsserted(sigTokenWrapper);\n            }\n            \n            SecurityToken sigTok = tokenStore.getToken(sigTokId);\n            if (sigTok == null) {\n                //REVISIT - no token?\n            }\n            if (SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS == sigToken.getInclusion()\n                || SPConstants.IncludeTokenType.INCLUDE_TOKEN_ONCE == sigToken.getInclusion()\n                || (isRequestor() \n                    && SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS_TO_RECIPIENT \n                        == sigToken.getInclusion())) {\n                \n                Element el = sigTok.getToken();\n                sigTokElem = (Element)secHeader.getSecurityHeader().getOwnerDocument()\n                        .importNode(el, true);\n                this.addEncyptedKeyElement((Element)sigTokElem);\n            } else if (isRequestor() && sigToken instanceof X509Token) {\n                Element el = sigTok.getToken();\n                sigTokElem = (Element)secHeader.getSecurityHeader().getOwnerDocument()\n                        .importNode(el, true);\n                this.addEncyptedKeyElement((Element)sigTokElem);\n            }\n        \n        \n            Vector<WSEncryptionPart> sigs = getSignedParts();\n            //Add timestamp\n            if (timestampEl != null) {\n                Element el = timestampEl.getElement();\n                sigs.add(new WSEncryptionPart(addWsuIdToElement(el)));\n            }\n\n            if (isRequestor()) {\n                addSupportingTokens(sigs);\n                signatures.add(doSignature(sigs, sigTokenWrapper, sigToken, sigTok));\n                doEndorse();\n            } else {\n                //confirm sig\n                assertSupportingTokens(sigs);\n                addSignatureConfirmation(sigs);\n                doSignature(sigs, sigTokenWrapper, sigToken, sigTok);\n            }\n\n            //REVIST - what to do with these policies?\n            policyAsserted(SP11Constants.TRUST_10);\n            policyAsserted(SP12Constants.TRUST_13);\n            \n            \n            //Encryption\n            TokenWrapper encrTokenWrapper = getEncryptionToken();\n            Token encrToken = encrTokenWrapper.getToken();\n            SecurityToken encrTok = null;\n            Element encrElem = null;\n            if (sigToken.equals(encrToken)) {\n                //Use the same token\n                encrTok = sigTok;\n                encrElem = sigTokElem;\n            } else {\n                String encrTokId = null;\n                //REVISIT - issued token from trust? \n                encrTok = tokenStore.getToken(encrTokId);\n                \n                if (SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS == encrToken.getInclusion()\n                    || SPConstants.IncludeTokenType.INCLUDE_TOKEN_ONCE == encrToken.getInclusion()\n                    || (isRequestor() \n                            && SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS_TO_RECIPIENT \n                            == encrToken.getInclusion())) {\n                    Element encrTokElem = (Element)encrTok.getToken();\n                    \n                    //Add the encrToken element before the sigToken element\n                    secHeader.getSecurityHeader().insertBefore(encrTokElem, sigTokElem);\n                }\n            }\n            \n            Vector<WSEncryptionPart> enc = getEncryptedParts();\n            \n            //Check for signature protection\n            if (sbinding.isSignatureProtection() && mainSigId != null) {\n                enc.add(new WSEncryptionPart(mainSigId, \"Element\"));\n            }\n            \n            if (isRequestor()) {\n                for (String id : encryptedTokensIdList) {\n                    enc.add(new WSEncryptionPart(id, \"Element\"));\n                }\n            }\n            doEncryption(encrTokenWrapper,\n                         encrTok,\n                         encrElem,\n                         enc);\n        } catch (Exception e) {\n            e.printStackTrace();\n            //REVISIT!!\n        }\n    }","id":36297,"modified_method":"private void doSignBeforeEncrypt() {\n        TokenWrapper sigTokenWrapper = getSignatureToken();\n        Token sigToken = sigTokenWrapper.getToken();\n        \n        \n        String sigTokId = null;\n        Element sigTokElem = null;\n        \n        try {\n            if (sigToken != null) {\n                if (sigToken instanceof SecureConversationToken) {\n                    //sigTokId = getSecConvTokenId();\n                } else if (sigToken instanceof IssuedToken) {\n                    //sigTokId = getIssuedSignatureTokenId();\n                } else if (sigToken instanceof X509Token) {\n                    if (isRequestor()) {\n                        sigTokId = setupEncryptedKey(sigTokenWrapper, sigToken);\n                    } else {\n                        sigTokId = getEncryptedKey();\n                    }\n                }\n            } else {\n                policyNotAsserted(sbinding, \"No signature token\");\n                return;\n            }\n            \n            if (StringUtils.isEmpty(sigTokId)) {\n                policyNotAsserted(sigTokenWrapper, \"No signature token id\");\n                return;\n            } else {\n                policyAsserted(sigTokenWrapper);\n            }\n            \n            SecurityToken sigTok = tokenStore.getToken(sigTokId);\n            if (sigTok == null) {\n                //REVISIT - no token?\n            }\n            if (SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS == sigToken.getInclusion()\n                || SPConstants.IncludeTokenType.INCLUDE_TOKEN_ONCE == sigToken.getInclusion()\n                || (isRequestor() \n                    && SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS_TO_RECIPIENT \n                        == sigToken.getInclusion())) {\n                \n                Element el = sigTok.getToken();\n                sigTokElem = (Element)secHeader.getSecurityHeader().getOwnerDocument()\n                        .importNode(el, true);\n                this.addEncyptedKeyElement((Element)sigTokElem);\n            } else if (isRequestor() && sigToken instanceof X509Token) {\n                Element el = sigTok.getToken();\n                sigTokElem = (Element)secHeader.getSecurityHeader().getOwnerDocument()\n                        .importNode(el, true);\n                this.addEncyptedKeyElement((Element)sigTokElem);\n            }\n        \n        \n            Vector<WSEncryptionPart> sigs = getSignedParts();\n            //Add timestamp\n            if (timestampEl != null) {\n                Element el = timestampEl.getElement();\n                sigs.add(new WSEncryptionPart(addWsuIdToElement(el)));\n            }\n\n            if (isRequestor()) {\n                addSupportingTokens(sigs);\n                signatures.add(doSignature(sigs, sigTokenWrapper, sigToken, sigTok));\n                doEndorse();\n            } else {\n                //confirm sig\n                assertSupportingTokens(sigs);\n                addSignatureConfirmation(sigs);\n                doSignature(sigs, sigTokenWrapper, sigToken, sigTok);\n            }\n\n            \n            \n            //Encryption\n            TokenWrapper encrTokenWrapper = getEncryptionToken();\n            Token encrToken = encrTokenWrapper.getToken();\n            SecurityToken encrTok = null;\n            if (sigToken.equals(encrToken)) {\n                //Use the same token\n                encrTok = sigTok;\n            } else {\n                String encrTokId = null;\n                //REVISIT - issued token from trust? \n                encrTok = tokenStore.getToken(encrTokId);\n                \n                if (SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS == encrToken.getInclusion()\n                    || SPConstants.IncludeTokenType.INCLUDE_TOKEN_ONCE == encrToken.getInclusion()\n                    || (isRequestor() \n                            && SPConstants.IncludeTokenType.INCLUDE_TOKEN_ALWAYS_TO_RECIPIENT \n                            == encrToken.getInclusion())) {\n                    Element encrTokElem = (Element)encrTok.getToken();\n                    \n                    //Add the encrToken element before the sigToken element\n                    secHeader.getSecurityHeader().insertBefore(encrTokElem, sigTokElem);\n                }\n            }\n            \n            Vector<WSEncryptionPart> enc = getEncryptedParts();\n            \n            //Check for signature protection\n            if (sbinding.isSignatureProtection() && mainSigId != null) {\n                enc.add(new WSEncryptionPart(mainSigId, \"Element\"));\n            }\n            \n            if (isRequestor()) {\n                for (String id : encryptedTokensIdList) {\n                    enc.add(new WSEncryptionPart(id, \"Element\"));\n                }\n            }\n            doEncryption(encrTokenWrapper,\n                         encrTok,\n                         true,\n                         enc,\n                         false);\n        } catch (Exception e) {\n            e.printStackTrace();\n            //REVISIT!!\n        }\n    }","commit_id":"4d4cf4d322db069851e03183ac20a982017ce9cc","url":"https://github.com/apache/cxf"},{"original_method":"private WSSecBase doEncryption(AbstractTokenWrapper recToken,\n                                    List<WSEncryptionPart> encrParts,\n                                    boolean externalRef) {\n        //Do encryption\n        if (recToken != null && recToken.getToken() != null && encrParts.size() > 0) {\n            AbstractToken encrToken = recToken.getToken();\n            assertPolicy(recToken);\n            assertPolicy(encrToken);\n            AlgorithmSuite algorithmSuite = abinding.getAlgorithmSuite();\n            if (encrToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys) {\n                try {\n                    WSSecDKEncrypt dkEncr = new WSSecDKEncrypt();\n                    dkEncr.setIdAllocator(wssConfig.getIdAllocator());\n                    dkEncr.setCallbackLookup(callbackLookup);\n                    dkEncr.setAttachmentCallbackHandler(new AttachmentCallbackHandler(message));\n                    dkEncr.setStoreBytesInAttachment(storeBytesInAttachment);\n                    if (recToken.getToken().getVersion() == SPConstants.SPVersion.SP11) {\n                        dkEncr.setWscVersion(ConversationConstants.VERSION_05_02);\n                    }\n                    \n                    if (encrKey == null) {\n                        setupEncryptedKey(recToken, encrToken);\n                    }\n                    \n                    dkEncr.setExternalKey(this.encryptedKeyValue, this.encryptedKeyId);\n                    dkEncr.getParts().addAll(encrParts);\n                    dkEncr.setCustomValueType(WSConstants.SOAPMESSAGE_NS11 + \"#\"\n                            + WSConstants.ENC_KEY_VALUE_TYPE);\n                    AlgorithmSuiteType algType = algorithmSuite.getAlgorithmSuiteType();\n                    dkEncr.setSymmetricEncAlgorithm(algType.getEncryption());\n                    dkEncr.setDerivedKeyLength(algType.getEncryptionDerivedKeyLength() / 8);\n                    dkEncr.prepare(saaj.getSOAPPart());\n                    \n                    addDerivedKeyElement(dkEncr.getdktElement());\n                    Element refList = dkEncr.encryptForExternalRef(null, encrParts);\n                    insertBeforeBottomUp(refList);\n                    return dkEncr;\n                } catch (Exception e) {\n                    LOG.log(Level.FINE, e.getMessage(), e);\n                    unassertPolicy(recToken, e);\n                }\n            } else {\n                try {\n                    WSSecEncrypt encr = new WSSecEncrypt();\n                    encr.setIdAllocator(wssConfig.getIdAllocator());\n                    encr.setCallbackLookup(callbackLookup);\n                    encr.setAttachmentCallbackHandler(new AttachmentCallbackHandler(message));\n                    encr.setStoreBytesInAttachment(storeBytesInAttachment);\n                    \n                    encr.setDocument(saaj.getSOAPPart());\n                    Crypto crypto = getEncryptionCrypto();\n                    \n                    SecurityToken securityToken = getSecurityToken();\n                    if (!isRequestor() && securityToken != null \n                        && recToken.getToken() instanceof SamlToken) {\n                        String tokenType = securityToken.getTokenType();\n                        if (WSConstants.WSS_SAML_TOKEN_TYPE.equals(tokenType)\n                            || WSConstants.SAML_NS.equals(tokenType)) {\n                            encr.setCustomEKTokenValueType(WSConstants.WSS_SAML_KI_VALUE_TYPE);\n                            encr.setKeyIdentifierType(WSConstants.CUSTOM_KEY_IDENTIFIER);\n                            encr.setCustomEKTokenId(securityToken.getId());\n                        } else if (WSConstants.WSS_SAML2_TOKEN_TYPE.equals(tokenType)\n                            || WSConstants.SAML2_NS.equals(tokenType)) {\n                            encr.setCustomEKTokenValueType(WSConstants.WSS_SAML2_KI_VALUE_TYPE);\n                            encr.setKeyIdentifierType(WSConstants.CUSTOM_KEY_IDENTIFIER);\n                            encr.setCustomEKTokenId(securityToken.getId());\n                        } else {\n                            setKeyIdentifierType(encr, encrToken);\n                        }\n                    } else {\n                        setKeyIdentifierType(encr, encrToken);\n                    }\n                    //\n                    // Using a stored cert is only suitable for the Issued Token case, where\n                    // we're extracting the cert from a SAML Assertion on the provider side\n                    //\n                    if (!isRequestor() && securityToken != null \n                        && securityToken.getX509Certificate() != null) {\n                        encr.setUseThisCert(securityToken.getX509Certificate());\n                    } else {\n                        setEncryptionUser(encr, encrToken, false, crypto);\n                    }\n                    if (!encr.isCertSet() && crypto == null) {\n                        unassertPolicy(recToken, \"Missing security configuration. \"\n                                + \"Make sure jaxws:client element is configured \" \n                                + \"with a \" + SecurityConstants.ENCRYPT_PROPERTIES + \" value.\");\n                    }\n                    AlgorithmSuiteType algType = algorithmSuite.getAlgorithmSuiteType();\n                    encr.setSymmetricEncAlgorithm(algType.getEncryption());\n                    encr.setKeyEncAlgo(algType.getAsymmetricKeyWrap());\n                    encr.prepare(saaj.getSOAPPart(), crypto);\n                    \n                    Element encryptedKeyElement = encr.getEncryptedKeyElement();\n                    List<Element> attachments = encr.getAttachmentEncryptedDataElements();\n                    //Encrypt, get hold of the ref list and add it\n                    if (externalRef) {\n                        Element refList = encr.encryptForRef(null, encrParts);\n                        insertBeforeBottomUp(refList);\n                        if (attachments != null) {\n                            for (Element attachment : attachments) {\n                                this.insertBeforeBottomUp(attachment);\n                            }\n                        }\n                        this.addEncryptedKeyElement(encryptedKeyElement);\n                    } else {\n                        Element refList = encr.encryptForRef(null, encrParts);\n                        this.addEncryptedKeyElement(encryptedKeyElement);\n                        \n                        // Add internal refs\n                        encryptedKeyElement.appendChild(refList);\n                        if (attachments != null) {\n                            for (Element attachment : attachments) {\n                                this.addEncryptedKeyElement(attachment);\n                            }\n                        }\n                    }\n\n                    // Put BST before EncryptedKey element\n                    if (encr.getBSTTokenId() != null) {\n                        encr.prependBSTElementToHeader(secHeader);\n                    }\n\n                    return encr;\n                } catch (WSSecurityException e) {\n                    LOG.log(Level.FINE, e.getMessage(), e);\n                    unassertPolicy(recToken, e);\n                }    \n            }\n        }\n        return null;\n    }","id":36298,"modified_method":"private WSSecBase doEncryption(AbstractTokenWrapper recToken,\n                                    List<WSEncryptionPart> encrParts,\n                                    boolean externalRef) {\n        //Do encryption\n        if (recToken != null && recToken.getToken() != null && encrParts.size() > 0) {\n            AbstractToken encrToken = recToken.getToken();\n            assertPolicy(recToken);\n            assertPolicy(encrToken);\n            AlgorithmSuite algorithmSuite = abinding.getAlgorithmSuite();\n            if (encrToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys) {\n                return doEncryptionDerived(recToken, encrToken, encrParts, algorithmSuite);\n            } else {\n                try {\n                    WSSecEncrypt encr = new WSSecEncrypt();\n                    encr.setIdAllocator(wssConfig.getIdAllocator());\n                    encr.setCallbackLookup(callbackLookup);\n                    encr.setAttachmentCallbackHandler(new AttachmentCallbackHandler(message));\n                    encr.setStoreBytesInAttachment(storeBytesInAttachment);\n                    \n                    encr.setDocument(saaj.getSOAPPart());\n                    Crypto crypto = getEncryptionCrypto();\n                    \n                    SecurityToken securityToken = getSecurityToken();\n                    if (!isRequestor() && securityToken != null \n                        && recToken.getToken() instanceof SamlToken) {\n                        String tokenType = securityToken.getTokenType();\n                        if (WSConstants.WSS_SAML_TOKEN_TYPE.equals(tokenType)\n                            || WSConstants.SAML_NS.equals(tokenType)) {\n                            encr.setCustomEKTokenValueType(WSConstants.WSS_SAML_KI_VALUE_TYPE);\n                            encr.setKeyIdentifierType(WSConstants.CUSTOM_KEY_IDENTIFIER);\n                            encr.setCustomEKTokenId(securityToken.getId());\n                        } else if (WSConstants.WSS_SAML2_TOKEN_TYPE.equals(tokenType)\n                            || WSConstants.SAML2_NS.equals(tokenType)) {\n                            encr.setCustomEKTokenValueType(WSConstants.WSS_SAML2_KI_VALUE_TYPE);\n                            encr.setKeyIdentifierType(WSConstants.CUSTOM_KEY_IDENTIFIER);\n                            encr.setCustomEKTokenId(securityToken.getId());\n                        } else {\n                            setKeyIdentifierType(encr, encrToken);\n                        }\n                    } else {\n                        setKeyIdentifierType(encr, encrToken);\n                    }\n                    //\n                    // Using a stored cert is only suitable for the Issued Token case, where\n                    // we're extracting the cert from a SAML Assertion on the provider side\n                    //\n                    if (!isRequestor() && securityToken != null \n                        && securityToken.getX509Certificate() != null) {\n                        encr.setUseThisCert(securityToken.getX509Certificate());\n                    } else {\n                        setEncryptionUser(encr, encrToken, false, crypto);\n                    }\n                    if (!encr.isCertSet() && crypto == null) {\n                        unassertPolicy(recToken, \"Missing security configuration. \"\n                                + \"Make sure jaxws:client element is configured \" \n                                + \"with a \" + SecurityConstants.ENCRYPT_PROPERTIES + \" value.\");\n                    }\n                    AlgorithmSuiteType algType = algorithmSuite.getAlgorithmSuiteType();\n                    encr.setSymmetricEncAlgorithm(algType.getEncryption());\n                    encr.setKeyEncAlgo(algType.getAsymmetricKeyWrap());\n                    encr.prepare(saaj.getSOAPPart(), crypto);\n                    \n                    Element encryptedKeyElement = encr.getEncryptedKeyElement();\n                    List<Element> attachments = encr.getAttachmentEncryptedDataElements();\n                    //Encrypt, get hold of the ref list and add it\n                    if (externalRef) {\n                        Element refList = encr.encryptForRef(null, encrParts);\n                        if (refList != null) {\n                            insertBeforeBottomUp(refList);\n                        }\n                        if (attachments != null) {\n                            for (Element attachment : attachments) {\n                                this.insertBeforeBottomUp(attachment);\n                            }\n                        }\n                        this.addEncryptedKeyElement(encryptedKeyElement);\n                    } else {\n                        Element refList = encr.encryptForRef(null, encrParts);\n                        this.addEncryptedKeyElement(encryptedKeyElement);\n                        \n                        // Add internal refs\n                        if (refList != null) {\n                            encryptedKeyElement.appendChild(refList);\n                        }\n                        if (attachments != null) {\n                            for (Element attachment : attachments) {\n                                this.addEncryptedKeyElement(attachment);\n                            }\n                        }\n                    }\n\n                    // Put BST before EncryptedKey element\n                    if (encr.getBSTTokenId() != null) {\n                        encr.prependBSTElementToHeader(secHeader);\n                    }\n\n                    return encr;\n                } catch (WSSecurityException e) {\n                    LOG.log(Level.FINE, e.getMessage(), e);\n                    unassertPolicy(recToken, e);\n                }    \n            }\n        }\n        return null;\n    }","commit_id":"5048d0b5a92cceb98fc46424d758b40107b47345","url":"https://github.com/apache/cxf"},{"original_method":"private void encryptTokensInSecurityHeader(AbstractToken encryptionToken, WSSecBase encrBase) {\n        List<WSEncryptionPart> secondEncrParts = new ArrayList<WSEncryptionPart>();\n        \n        // Check for signature protection\n        if (abinding.isEncryptSignature()) {\n            assertPolicy(\n                new QName(abinding.getName().getNamespaceURI(), SPConstants.ENCRYPT_SIGNATURE));\n\n            // Now encrypt the signature using the above token\n            if (mainSigId != null) {\n                WSEncryptionPart sigPart = new WSEncryptionPart(mainSigId, \"Element\");\n                sigPart.setElement(bottomUpElement);\n                secondEncrParts.add(sigPart);\n            }\n            \n            if (sigConfList != null && !sigConfList.isEmpty()) {\n                secondEncrParts.addAll(sigConfList);\n            }\n        }\n            \n        // Add any SupportingTokens that need to be encrypted\n        if (isRequestor()) {\n            secondEncrParts.addAll(encryptedTokensList);\n        }\n        \n        if (secondEncrParts.isEmpty()) {\n            return;\n        }\n\n        // Perform encryption\n        if (encryptionToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys\n            && encrBase instanceof WSSecDKEncrypt) {\n            try {\n                Element secondRefList = \n                    ((WSSecDKEncrypt)encrBase).encryptForExternalRef(null, secondEncrParts);\n                ((WSSecDKEncrypt)encrBase).addExternalRefElement(secondRefList, secHeader);\n\n            } catch (WSSecurityException ex) {\n                LOG.log(Level.FINE, ex.getMessage(), ex);\n                throw new Fault(ex);\n            }\n        } else if (encrBase instanceof WSSecEncrypt) {\n            try {\n                // Encrypt, get hold of the ref list and add it\n                Element secondRefList = saaj.getSOAPPart()\n                    .createElementNS(WSConstants.ENC_NS,\n                                     WSConstants.ENC_PREFIX + \":ReferenceList\");\n                if (lastEncryptedKeyElement != null) {\n                    insertAfter(secondRefList, lastEncryptedKeyElement);\n                } else {\n                    this.insertBeforeBottomUp(secondRefList);\n                }\n                ((WSSecEncrypt)encrBase).encryptForRef(secondRefList, secondEncrParts);\n\n            } catch (WSSecurityException ex) {\n                LOG.log(Level.FINE, ex.getMessage(), ex);\n                throw new Fault(ex);\n            }\n        }\n    }","id":36299,"modified_method":"private void encryptTokensInSecurityHeader(AbstractToken encryptionToken, WSSecBase encrBase) {\n        List<WSEncryptionPart> secondEncrParts = new ArrayList<WSEncryptionPart>();\n        \n        // Check for signature protection\n        if (abinding.isEncryptSignature()) {\n            assertPolicy(\n                new QName(abinding.getName().getNamespaceURI(), SPConstants.ENCRYPT_SIGNATURE));\n\n            // Now encrypt the signature using the above token\n            if (mainSigId != null) {\n                WSEncryptionPart sigPart = new WSEncryptionPart(mainSigId, \"Element\");\n                sigPart.setElement(bottomUpElement);\n                secondEncrParts.add(sigPart);\n            }\n            \n            if (sigConfList != null && !sigConfList.isEmpty()) {\n                secondEncrParts.addAll(sigConfList);\n            }\n        }\n            \n        // Add any SupportingTokens that need to be encrypted\n        if (isRequestor()) {\n            secondEncrParts.addAll(encryptedTokensList);\n        }\n        \n        if (secondEncrParts.isEmpty()) {\n            return;\n        }\n\n        // Perform encryption\n        if (encryptionToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys\n            && encrBase instanceof WSSecDKEncrypt) {\n            try {\n                Element secondRefList = \n                    ((WSSecDKEncrypt)encrBase).encryptForExternalRef(null, secondEncrParts);\n                if (secondRefList != null) {\n                    ((WSSecDKEncrypt)encrBase).addExternalRefElement(secondRefList, secHeader);\n                }\n\n            } catch (WSSecurityException ex) {\n                LOG.log(Level.FINE, ex.getMessage(), ex);\n                throw new Fault(ex);\n            }\n        } else if (encrBase instanceof WSSecEncrypt) {\n            try {\n                // Encrypt, get hold of the ref list and add it\n                Element secondRefList = saaj.getSOAPPart()\n                    .createElementNS(WSConstants.ENC_NS,\n                                     WSConstants.ENC_PREFIX + \":ReferenceList\");\n                if (lastEncryptedKeyElement != null) {\n                    insertAfter(secondRefList, lastEncryptedKeyElement);\n                } else {\n                    this.insertBeforeBottomUp(secondRefList);\n                }\n                ((WSSecEncrypt)encrBase).encryptForRef(secondRefList, secondEncrParts);\n\n            } catch (WSSecurityException ex) {\n                LOG.log(Level.FINE, ex.getMessage(), ex);\n                throw new Fault(ex);\n            }\n        }\n    }","commit_id":"5048d0b5a92cceb98fc46424d758b40107b47345","url":"https://github.com/apache/cxf"},{"original_method":"private void addAttachmentsForEncryption(boolean atEnd, Element refList, List<Element> attachments) {\n        if (atEnd) {\n            this.insertBeforeBottomUp(refList);\n            if (attachments != null) {\n                for (Element attachment : attachments) {\n                    this.insertBeforeBottomUp(attachment);\n                }\n            }\n        } else {\n            this.addDerivedKeyElement(refList);\n            if (attachments != null) {\n                for (Element attachment : attachments) {\n                    this.addDerivedKeyElement(attachment);\n                }\n            }\n        }\n    }","id":36300,"modified_method":"private void addAttachmentsForEncryption(boolean atEnd, Element refList, List<Element> attachments) {\n        if (atEnd) {\n            if (refList != null) {\n                this.insertBeforeBottomUp(refList);\n            }\n            if (attachments != null) {\n                for (Element attachment : attachments) {\n                    this.insertBeforeBottomUp(attachment);\n                }\n            }\n        } else {\n            if (refList != null) {\n                this.addDerivedKeyElement(refList);\n            }\n            if (attachments != null) {\n                for (Element attachment : attachments) {\n                    this.addDerivedKeyElement(attachment);\n                }\n            }\n        }\n    }","commit_id":"5048d0b5a92cceb98fc46424d758b40107b47345","url":"https://github.com/apache/cxf"},{"original_method":"private void doEncryptBeforeSign() {\n        try {\n            AbstractTokenWrapper encryptionWrapper = getEncryptionToken();\n            assertTokenWrapper(encryptionWrapper);\n            AbstractToken encryptionToken = encryptionWrapper.getToken();\n            \n            if (encryptionToken != null) {\n                //The encryption token can be an IssuedToken or a \n                //SecureConversationToken\n                String tokenId = null;\n                SecurityToken tok = null;\n                if (encryptionToken instanceof IssuedToken \n                    || encryptionToken instanceof KerberosToken\n                    || encryptionToken instanceof SecureConversationToken\n                    || encryptionToken instanceof SecurityContextToken\n                    || encryptionToken instanceof SpnegoContextToken) {\n                    tok = getSecurityToken();\n                } else if (encryptionToken instanceof X509Token) {\n                    if (isRequestor()) {\n                        tokenId = setupEncryptedKey(encryptionWrapper, encryptionToken);\n                    } else {\n                        tokenId = getEncryptedKey();\n                    }\n                } else if (encryptionToken instanceof UsernameToken) {\n                    if (isRequestor()) {\n                        tokenId = setupUTDerivedKey((UsernameToken)encryptionToken);\n                    } else {\n                        tokenId = getUTDerivedKey();\n                    }\n                }\n                assertToken(encryptionToken);\n                if (tok == null) {\n                    //if (tokenId == null || tokenId.length() == 0) {\n                        //REVISIT - no tokenId?   Exception?\n                    //}\n                    if (tokenId != null && tokenId.startsWith(\"#\")) {\n                        tokenId = tokenId.substring(1);\n                    }\n                    \n                    /*\n                     * Get hold of the token from the token storage\n                     */\n                    tok = tokenStore.getToken(tokenId);\n                }\n    \n                boolean attached = false;\n                if (isTokenRequired(encryptionToken.getIncludeTokenType())) {\n                    Element el = tok.getToken();\n                    this.addEncryptedKeyElement(cloneElement(el));\n                    attached = true;\n                } else if (encryptionToken instanceof X509Token && isRequestor()) {\n                    Element el = tok.getToken();\n                    this.addEncryptedKeyElement(cloneElement(el));\n                    attached = true;\n                }\n                \n                List<WSEncryptionPart> sigParts = new ArrayList<>();\n                if (timestampEl != null) {\n                    WSEncryptionPart timestampPart = \n                        convertToEncryptionPart(timestampEl.getElement());\n                    sigParts.add(timestampPart);        \n                }\n                addSupportingTokens(sigParts);\n                sigParts.addAll(this.getSignedParts(null));\n\n                List<WSEncryptionPart> encrParts = getEncryptedParts();\n                WSSecBase encr = doEncryption(encryptionWrapper, tok, attached, encrParts, true);\n                handleEncryptedSignedHeaders(encrParts, sigParts);\n                \n                if (!isRequestor()) {\n                    addSignatureConfirmation(sigParts);\n                }\n                \n                //Sign the message\n                //We should use the same key in the case of EncryptBeforeSig\n                if (sigParts.size() > 0) {\n                    addSig(this.doSignature(sigParts, encryptionWrapper, encryptionToken, \n                                                    tok, attached));\n                }\n                \n                if (isRequestor()) {\n                    this.doEndorse();\n                }\n                \n                //Check for signature protection and encryption of UsernameToken\n                if (sbinding.isEncryptSignature() \n                    || encryptedTokensList.size() > 0 && isRequestor()) {\n                    List<WSEncryptionPart> secondEncrParts = new ArrayList<>();\n                    \n                    //Now encrypt the signature using the above token\n                    if (sbinding.isEncryptSignature()) {\n                        if (this.mainSigId != null) {\n                            WSEncryptionPart sigPart = \n                                new WSEncryptionPart(this.mainSigId, \"Element\");\n                            sigPart.setElement(bottomUpElement);\n                            secondEncrParts.add(sigPart);\n                        }\n                        if (sigConfList != null && !sigConfList.isEmpty()) {\n                            secondEncrParts.addAll(sigConfList);\n                        }\n                        assertPolicy(\n                            new QName(sbinding.getName().getNamespaceURI(), SPConstants.ENCRYPT_SIGNATURE));\n                    }\n                    \n                    if (isRequestor()) {\n                        secondEncrParts.addAll(encryptedTokensList);\n                    }\n                    \n                    Element secondRefList = null;\n                    \n                    if (encryptionToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys \n                        && !secondEncrParts.isEmpty()) {\n                        secondRefList = ((WSSecDKEncrypt)encr).encryptForExternalRef(null, \n                                secondEncrParts);\n                        this.addDerivedKeyElement(secondRefList);\n                    } else if (!secondEncrParts.isEmpty()) {\n                        //Encrypt, get hold of the ref list and add it\n                        secondRefList = ((WSSecEncrypt)encr).encryptForRef(null, secondEncrParts);\n                        this.addDerivedKeyElement(secondRefList);\n                    }\n                }\n            }\n        } catch (RuntimeException ex) {\n            LOG.log(Level.FINE, ex.getMessage(), ex);\n            throw ex;\n        } catch (Exception ex) {\n            LOG.log(Level.FINE, ex.getMessage(), ex);\n            throw new Fault(ex);\n        }\n    }","id":36301,"modified_method":"private void doEncryptBeforeSign() {\n        try {\n            AbstractTokenWrapper encryptionWrapper = getEncryptionToken();\n            assertTokenWrapper(encryptionWrapper);\n            AbstractToken encryptionToken = encryptionWrapper.getToken();\n            \n            if (encryptionToken != null) {\n                //The encryption token can be an IssuedToken or a \n                //SecureConversationToken\n                String tokenId = null;\n                SecurityToken tok = null;\n                if (encryptionToken instanceof IssuedToken \n                    || encryptionToken instanceof KerberosToken\n                    || encryptionToken instanceof SecureConversationToken\n                    || encryptionToken instanceof SecurityContextToken\n                    || encryptionToken instanceof SpnegoContextToken) {\n                    tok = getSecurityToken();\n                } else if (encryptionToken instanceof X509Token) {\n                    if (isRequestor()) {\n                        tokenId = setupEncryptedKey(encryptionWrapper, encryptionToken);\n                    } else {\n                        tokenId = getEncryptedKey();\n                    }\n                } else if (encryptionToken instanceof UsernameToken) {\n                    if (isRequestor()) {\n                        tokenId = setupUTDerivedKey((UsernameToken)encryptionToken);\n                    } else {\n                        tokenId = getUTDerivedKey();\n                    }\n                }\n                assertToken(encryptionToken);\n                if (tok == null) {\n                    //if (tokenId == null || tokenId.length() == 0) {\n                        //REVISIT - no tokenId?   Exception?\n                    //}\n                    if (tokenId != null && tokenId.startsWith(\"#\")) {\n                        tokenId = tokenId.substring(1);\n                    }\n                    \n                    /*\n                     * Get hold of the token from the token storage\n                     */\n                    tok = tokenStore.getToken(tokenId);\n                }\n    \n                boolean attached = false;\n                if (isTokenRequired(encryptionToken.getIncludeTokenType())) {\n                    Element el = tok.getToken();\n                    this.addEncryptedKeyElement(cloneElement(el));\n                    attached = true;\n                } else if (encryptionToken instanceof X509Token && isRequestor()) {\n                    Element el = tok.getToken();\n                    this.addEncryptedKeyElement(cloneElement(el));\n                    attached = true;\n                }\n                \n                List<WSEncryptionPart> sigParts = new ArrayList<>();\n                if (timestampEl != null) {\n                    WSEncryptionPart timestampPart = \n                        convertToEncryptionPart(timestampEl.getElement());\n                    sigParts.add(timestampPart);        \n                }\n                addSupportingTokens(sigParts);\n                sigParts.addAll(this.getSignedParts(null));\n\n                List<WSEncryptionPart> encrParts = getEncryptedParts();\n                WSSecBase encr = doEncryption(encryptionWrapper, tok, attached, encrParts, true);\n                handleEncryptedSignedHeaders(encrParts, sigParts);\n                \n                if (!isRequestor()) {\n                    addSignatureConfirmation(sigParts);\n                }\n                \n                //Sign the message\n                //We should use the same key in the case of EncryptBeforeSig\n                if (sigParts.size() > 0) {\n                    addSig(this.doSignature(sigParts, encryptionWrapper, encryptionToken, \n                                                    tok, attached));\n                }\n                \n                if (isRequestor()) {\n                    this.doEndorse();\n                }\n                \n                //Check for signature protection and encryption of UsernameToken\n                if (sbinding.isEncryptSignature() \n                    || encryptedTokensList.size() > 0 && isRequestor()) {\n                    List<WSEncryptionPart> secondEncrParts = new ArrayList<>();\n                    \n                    //Now encrypt the signature using the above token\n                    if (sbinding.isEncryptSignature()) {\n                        if (this.mainSigId != null) {\n                            WSEncryptionPart sigPart = \n                                new WSEncryptionPart(this.mainSigId, \"Element\");\n                            sigPart.setElement(bottomUpElement);\n                            secondEncrParts.add(sigPart);\n                        }\n                        if (sigConfList != null && !sigConfList.isEmpty()) {\n                            secondEncrParts.addAll(sigConfList);\n                        }\n                        assertPolicy(\n                            new QName(sbinding.getName().getNamespaceURI(), SPConstants.ENCRYPT_SIGNATURE));\n                    }\n                    \n                    if (isRequestor()) {\n                        secondEncrParts.addAll(encryptedTokensList);\n                    }\n                    \n                    Element secondRefList = null;\n                    \n                    if (encryptionToken.getDerivedKeys() == DerivedKeys.RequireDerivedKeys \n                        && !secondEncrParts.isEmpty()) {\n                        secondRefList = ((WSSecDKEncrypt)encr).encryptForExternalRef(null, \n                                secondEncrParts);\n                    } else if (!secondEncrParts.isEmpty()) {\n                        //Encrypt, get hold of the ref list and add it\n                        secondRefList = ((WSSecEncrypt)encr).encryptForRef(null, secondEncrParts);\n                    }\n                    if (secondRefList != null) {\n                        this.addDerivedKeyElement(secondRefList);\n                    }\n                }\n            }\n        } catch (RuntimeException ex) {\n            LOG.log(Level.FINE, ex.getMessage(), ex);\n            throw ex;\n        } catch (Exception ex) {\n            LOG.log(Level.FINE, ex.getMessage(), ex);\n            throw new Fault(ex);\n        }\n    }","commit_id":"5048d0b5a92cceb98fc46424d758b40107b47345","url":"https://github.com/apache/cxf"},{"original_method":"/**\n   * Removes all mnemonics, then sets a mnemonic for each menu and menu item \n   * recursively by these rules:\n   * <ol>\n   * <li> It tries to assign one of <a href=\"http://techbase.kde.org/Projects/Usability/HIG/Keyboard_Accelerators\">\n   * KDE's defaults<\/a>.<\/li>\n   * <li> Failing that, it loops through the first letter of each word, where a word\n   *  is a block of Unicode \"alphabetical\" chars, looking for an upper-case ASCII mnemonic \n   *  that is not taken. This is to try to be relevant, by using a letter well-associated \n   *  with the command. (MS guidelines) <\/li>\n   * <li> Ditto, but with lowercase. <\/li>\n   * <li> Next, it tries the second ASCII character, if its width >= half the width of\n   *  'A'. <\/li>\n   * <li> If the first letters are all taken/non-ASCII, then it loops through the\n   *  ASCII letters in the item, widest to narrowest, seeing if any of them is not taken.\n   *  To improve readability, it discriminates against decenders (qypgj), imagining they\n   *  have 2/3 their actual width. (MS guidelines: avoid decenders). It also discriminates\n   *  against vowels, imagining they have 2/3 their actual width. (MS and Gnome guidelines:\n   *  avoid vowels. <\/li>\n   * <li>Failing that, it will loop left-to-right for an available digit. This is a last \n   *  resort because the normal setMnemonic dislikes them.<\/li>\n   * <li> If that doesn't work, it doesn't assign a mnemonic. <\/li>\n   * <\/ol>\n   *\n   * As a special case, strings starting \"sketchbook \\u2192 \" have that bit ignored\n   * because otherwise the Recent menu looks awful. However, the name <tt>\"sketchbook \\u2192\n   * Sketch\"<\/tt>, for example, will have the 'S' of \"Sketch\" chosen, but the 's' of 'sketchbook\n   * will get underlined.\n   * No letter by an underscore will be assigned.\n   * Disabled on Mac, per Apple guidelines.\n   * <tt>menu<\/tt> may contain nulls.\n   * @param menu\n   *          A menu, a list of menus or an array of menu items to set mnemonics for.\n   * @param font\n   *          A font for rendering character widths.\n   */\n  public static void setMenuMnemonics(JMenuItem... menu) {\n    if (Base.isMacOS()) return;\n    if (menu.length == 0) return;\n\n    // This list is the contents of http://techbase.kde.org/Projects/Usability/HIG/\n    // Keyboard_Accelerators, made lowercase, with nothing but letters left except\n    // for ampersands before mnemonics and \".+\" for changable text. (They are regexs.)\n    // Note that every ampersand MUST be followed by a lowercase ASCII letter.\n    final String[] kdePreDefs = { \"&file\", \"&new\", \"&open\", \"open&recent\", \"&save\",\n      \"save&as\", \"saveacop&y\", \"saveas&template\", \"savea&ll\", \"reloa&d\", \"&print\", \n      \"printpre&view\", \"&import\", \"e&xport\", \"&closefile\", \"clos&eallfiles\", \"&quit\", \n      \"&edit\", \"&undo\", \"re&do\", \"cu&t&\", \"&copy\", \"&paste\", \"&delete\", \"select&all\", \n      \"dese&lect\", \"&find\", \"find&next\", \"findpre&vious\", \"&replace\", \"&gotoline\", \n      \"&view\", \"&newview\", \"close&allviews\", \"&splitview\", \"&removeview\", \n      \"splitter&orientation\", \"&horizontal\", \"&vertical\", \"view&mode\", \"&fullscreenmode\", \n      \"&zoom\", \"zoom&in\", \"zoom&out\", \"zoomtopage&width\", \"zoomwhole&page\", \"zoom&factor\", \n      \"&insert\", \"&format\", \"&go\", \"&up\", \"&back\", \"&forward\", \"&home\", \"&go\", \"&previouspage\", \n      \"&nextpage\", \"&firstpage\", \"&lastpage\", \"read&updocument\", \"read&downdocument\", \"&back\", \n      \"&forward\", \"&gotopage\", \"&bookmarks\", \"&addbookmark\", \"bookmark&tabsasfolder\", \n      \"&editbookmarks\", \"&newbookmarksfolder\", \"&tools\", \"&settings\", \"&toolbars\",\n      \"configure&shortcuts\", \"configuretool&bars\", \"&configure*\", \"&help\", \".+&handbook\", \n      \"&whatsthis\", \"report&bug\", \"&about[^k].*\", \"about&kde\" };\n    \n    final FontMetrics fm = menu[0].getFontMetrics(menu[0].getFont());\n    final Comparator<Character> charComparator = new Comparator<Character>() {\n      public int compare(Character ch1, Character ch2) {\n        // Descriminates against decenders for readability, per MS\n\t// Human Interface Guide, and vowels per MS and Gnome.\n        float w1 = fm.charWidth(ch1), w2 = fm.charWidth(ch2);\n        for (char bad : \"qypgjaeiouQYPGJAEIOU\".toCharArray()) {\n          if (bad == ch1) w1 *= 0.66;\n          if (bad == ch2) w2 *= 0.66;\n\t}\n        return (int)Math.signum(w2 - w1);\n      }\n    };\n    // taken holds only [a-z], not uppercase.\n    // Prevents uppercase letters != lowercase letters, so\n    // \"Save\" and \"Save As\" aren't both given 'a'.\n    final List<Character> taken = new ArrayList<Character>(menu.length);\n    char firstChar;\n    char[] w; // temp char array\n    Character[] word;\n    boolean foundYet = false;\n\n    // METHOD 1: attempt to assign KDE defaults.\n    for (JMenuItem jmi : menu) {\n      if (jmi == null) continue;\n      jmi.setMnemonic(0); // Reset.\n      for (String kdePreDef : kdePreDefs) {\n        if (jmi.getText().toLowerCase().replaceAll(\"[^a-z]\",\"\").matches(kdePreDef.replace(\"&\",\"\"))) {\n\t  // mnem is lowercase: might be best to make uppercase if neccessary. \n          char mnem = kdePreDef.charAt(1+kdePreDef.indexOf(\"&\"));\n          jmi.setMnemonic(jmi.getText().indexOf(Character.toString(mnem).toUpperCase()) < 0 ?\n\t    mnem : (char)(mnem-32));\n\t  taken.add(mnem);\n\t  break;\n\t}\n      }\n    }\n    \n    // Where KDE defaults fail, use an algorithm.\n    algorithmicAssaignment:\n    for (JMenuItem jmi : menu) {\n      if (jmi == null) continue;\n      if (jmi.getMnemonic() != 0) continue; // Already assigned.\n\n      // The string can't be made lower-case as that would spoil\n      // the width comparison.\n      String cleanString = jmi.getText();\n      if (cleanString.startsWith(\"sketchbook \\u2192 \"))\n        cleanString = cleanString.substring(13);\n\t\n      if (cleanString.length() == 0) continue;\n\n      // First, ban letters by underscores.\n      final List<Character> banned = new ArrayList<Character>();\n      for (int i = 0; i < cleanString.length(); i++) {\n        if (cleanString.charAt(i) == '_') {\n          if (i > 0)\n\t    banned.add(Character.toLowerCase(cleanString.charAt(i-1)));\n\t  if (i+1 < cleanString.length())\n\t    banned.add(Character.toLowerCase(cleanString.charAt(i+1)));\n\t}\n      }\n\n      // METHOD 2: Uppercase starts of words.\n      // Splitting into blocks of ASCII letters wouldn't work\n      // because there could be non-ASCII letters in a word.\n      for (String wd : cleanString.split(\"[^\\\\p{IsAlphabetic}]\")) {\n        if (wd.length() == 0) continue;\n        firstChar = wd.charAt(0);\n        if (taken.contains(Character.toLowerCase(firstChar))) continue;\n\tif (banned.contains(Character.toLowerCase(firstChar))) continue;\n        if ('A' <= firstChar && firstChar <= 'Z') {\n          jmi.setMnemonic(firstChar);\n          taken.add((char)(firstChar | 32)); // tolowercase\n          continue algorithmicAssaignment;\n        }\n      }\n\n      // METHOD 3: Lowercase starts of words.\n      for (String wd : cleanString.split(\"[^\\\\p{IsAlphabetic}]\")) {\n        if (wd.length() == 0) continue;\n        firstChar = wd.charAt(0);\n        if (taken.contains(Character.toLowerCase(firstChar))) continue;\n\tif (banned.contains(Character.toLowerCase(firstChar))) continue;\n        if ('a' <= firstChar && firstChar <= 'z') {\n          jmi.setMnemonic(firstChar);\n          taken.add(firstChar); // is lowercase\n          continue algorithmicAssaignment;\n        }\n      }\n\n      // METHOD 4: Second ASCII letter.\n      cleanString = cleanString.replaceAll(\"[^A-Za-z]\", \"\");\n      if (cleanString.length() >= 2) {\n        if (!taken.contains((char)(cleanString.charAt(1)|32))) {\n\t  if (!banned.contains((char)(cleanString.charAt(1)|32))) {\n\t    if (fm.charWidth('A') <= 2*fm.charWidth(cleanString.charAt(1))) {\n              jmi.setMnemonic(cleanString.charAt(1));\n              taken.add((char)(cleanString.charAt(1)|32));\n              continue algorithmicAssaignment;\n\t    }\n\t  }\n        }\n      }\n\n      // METHOD 5: charComparator.\n      w = cleanString.toCharArray();\n      word = new Character[w.length];\n      for (int i = 0; i < w.length; i++) {\n        word[i] = new Character(w[i]);\n      }\n      Arrays.sort(word, charComparator); // sorts in increasing order\n      for (char mnem : word) {\n        if (taken.contains(Character.toLowerCase(mnem))) continue;\n\tif (banned.contains(Character.toLowerCase(mnem))) continue;\n        // NB: setMnemonic(char) doesn't want [^A-Za-z]\n        jmi.setMnemonic(mnem);\n        taken.add(Character.toLowerCase(mnem));\n        continue algorithmicAssaignment;\n      }\n\n      // METHOD 6: Digits\n      for (char digit : jmi.getText().replaceAll(\"[^0-9]\", \"\").toCharArray()) {\n        if (taken.contains(digit)) continue;\n        jmi.setMnemonic(KeyEvent.VK_0 + (digit - '0'));\n\ttaken.add(digit);\n\tcontinue algorithmicAssaignment;\n      }\n    }\n\n    // Finally, RECURSION.\n    for (JMenuItem jmi : menu) {\n      if (jmi instanceof JMenu) {\n        JMenu jm = (JMenu) jmi;\n        JMenuItem[] items = new JMenuItem[jm.getItemCount()];\n        for (int i = 0; i < items.length; i++) {\n          items[i] = jm.getItem(i);\n        }\n        setMenuMnemonics(items);\n      }\n    }\n  }","id":36302,"modified_method":"/**\n   * Removes all mnemonics, then sets a mnemonic for each menu and menu item \n   * recursively by these rules:\n   * <ol>\n   * <li> It tries to assign one of <a href=\"http://techbase.kde.org/Projects/Usability/HIG/Keyboard_Accelerators\">\n   * KDE's defaults<\/a>.<\/li>\n   * <li> Failing that, it loops through the first letter of each word, where a word\n   *  is a block of Unicode \"alphabetical\" chars, looking for an upper-case ASCII mnemonic \n   *  that is not taken. This is to try to be relevant, by using a letter well-associated \n   *  with the command. (MS guidelines) <\/li>\n   * <li> Ditto, but with lowercase. <\/li>\n   * <li> Next, it tries the second ASCII character, if its width >= half the width of\n   *  'A'. <\/li>\n   * <li> If the first letters are all taken/non-ASCII, then it loops through the\n   *  ASCII letters in the item, widest to narrowest, seeing if any of them is not taken.\n   *  To improve readability, it discriminates against decenders (qypgj), imagining they\n   *  have 2/3 their actual width. (MS guidelines: avoid decenders). It also discriminates\n   *  against vowels, imagining they have 2/3 their actual width. (MS and Gnome guidelines:\n   *  avoid vowels. <\/li>\n   * <li>Failing that, it will loop left-to-right for an available digit. This is a last \n   *  resort because the normal setMnemonic dislikes them.<\/li>\n   * <li> If that doesn't work, it doesn't assign a mnemonic. <\/li>\n   * <\/ol>\n   *\n   * As a special case, strings starting \"sketchbook \\u2192 \" have that bit ignored\n   * because otherwise the Recent menu looks awful. However, the name <tt>\"sketchbook \\u2192\n   * Sketch\"<\/tt>, for example, will have the 'S' of \"Sketch\" chosen, but the 's' of 'sketchbook\n   * will get underlined.\n   * No letter by an underscore will be assigned.\n   * Disabled on Mac, per Apple guidelines.\n   * <tt>menu<\/tt> may contain nulls.\n   *\n   * Author: George Bateman. Initial work Myer Nore.\n   * @param menu\n   *          A menu, a list of menus or an array of menu items to set mnemonics for.\n   * @param font\n   *          A font for rendering character widths.\n   */\n  public static void setMenuMnemonics(JMenuItem... menu) {\n    if (Base.isMacOS()) return;\n    if (menu.length == 0) return;\n\n    // This list is (mostly) the contents of http://techbase.kde.org/Projects/Usability/HIG/\n    // Keyboard_Accelerators, made lowercase, with nothing but letters left except\n    // for ampersands before mnemonics and \".+\" for changable text. (They are regexs.)\n    // Note that every ampersand MUST be followed by a lowercase ASCII letter.\n    final String[] kdePreDefStrs = { \"&file\", \"&new\", \"&open\", \"open&recent\", \"&save\",\n      \"save&as\", \"saveacop&y\", \"saveas&template\", \"savea&ll\", \"reloa&d\", \"&print\", \n      \"printpre&view\", \"&import\", \"e&xport\", \"&closefile\", \"clos&eallfiles\", \"&quit\", \n      \"&edit\", \"&undo\", \"re&do\", \"cu&t&\", \"&copy\", \"&paste\", \"&delete\", \"select&all\", \n      \"dese&lect\", \"&find\", \"find&next\", \"findpre&vious\", \"&replace\", \"&gotoline\", \n      \"&view\", \"&newview\", \"close&allviews\", \"&splitview\", \"&removeview\", \n      \"splitter&orientation\", \"&horizontal\", \"&vertical\", \"view&mode\", \"&fullscreenmode\", \n      \"&zoom\", \"zoom&in\", \"zoom&out\", \"zoomtopage&width\", \"zoomwhole&page\", \"zoom&factor\", \n      \"&insert\", \"&format\", \"&go\", \"&up\", \"&back\", \"&forward\", \"&home\", \"&go\", \"&previouspage\", \n      \"&nextpage\", \"&firstpage\", \"&lastpage\", \"read&updocument\", \"read&downdocument\", \"&back\", \n      \"&forward\", \"&gotopage\", \"&bookmarks\", \"&addbookmark\", \"bookmark&tabsasfolder\", \n      \"&editbookmarks\", \"&newbookmarksfolder\", \"&tools\", \"&settings\", \"&toolbars\",\n      \"configure&shortcuts\", \"configuretool&bars\", \"&configure*\", \"&help\", \".+&handbook\", \n      \"&whatsthis\", \"report&bug\", \"&aboutprocessing\", \"about&kde\" };\n    Pattern[] kdePreDefPats = new Pattern[kdePreDefStrs.length];\n    for (int i = 0; i < kdePreDefStrs.length; i++)\n      kdePreDefPats[i] = Pattern.compile(kdePreDefStrs[i].replace(\"&\",\"\"));\n    \n    final Pattern nonAAlpha = Pattern.compile(\"[^A-Za-z]\");\n    final FontMetrics fm = menu[0].getFontMetrics(menu[0].getFont());\n    final Comparator<Character> charComparator = new Comparator<Character>() {\n      char[] baddies = \"qypgjaeiouQYPGJAEIOU\".toCharArray();\n      public int compare(Character ch1, Character ch2) {\n        // Descriminates against decenders for readability, per MS\n\t// Human Interface Guide, and vowels per MS and Gnome.\n        float w1 = fm.charWidth(ch1), w2 = fm.charWidth(ch2);\n        for (char bad : baddies) {\n          if (bad == ch1) w1 *= 0.66;\n          if (bad == ch2) w2 *= 0.66;\n\t}\n        return (int)Math.signum(w2 - w1);\n      }\n    };\n    // taken holds only [0-9a-z], not uppercase.\n    // Prevents uppercase letters != lowercase letters, so\n    // \"Save\" and \"Save As\" aren't both given 'a'.\n    final List<Character> taken = new ArrayList<Character>(menu.length);\n    char firstChar;\n    char[] cleanChars;\n    Character[] cleanCharas;\n\n    // METHOD 1: attempt to assign KDE defaults.\n    for (JMenuItem jmi : menu) {\n      if (jmi == null) continue;\n      jmi.setMnemonic(0); // Reset.\n      for (int i = 0; i < kdePreDefStrs.length; i++) {\n        String cleanName = nonAAlpha.matcher(jmi.getText()).replaceAll(\"\").toLowerCase();\n\tif (kdePreDefPats[i].matcher(cleanName).matches()) {\n          char mnem = kdePreDefStrs[i].charAt(1+kdePreDefStrs[i].indexOf(\"&\"));\n          jmi.setMnemonic(mnem);\n\t  taken.add(mnem);\n\t  break;\n\t}\n      }\n    }\n    \n    // Where KDE defaults fail, use an algorithm.\n    algorithmicAssaignment:\n    for (JMenuItem jmi : menu) {\n      if (jmi == null) continue;\n      if (jmi.getMnemonic() != 0) continue; // Already assigned.\n\n      // The string can't be made lower-case as that would spoil\n      // the width comparison.\n      String cleanString = jmi.getText();\n      if (cleanString.startsWith(\"sketchbook \\u2192 \"))\n        cleanString = cleanString.substring(13);\n\t\n      if (cleanString.length() == 0) continue;\n\n      // First, ban letters by underscores.\n      final List<Character> banned = new ArrayList<Character>();\n      for (int i = 0; i < cleanString.length(); i++) {\n        if (cleanString.charAt(i) == '_') {\n          if (i > 0)\n\t    banned.add(Character.toLowerCase(cleanString.charAt(i-1)));\n\t  if (i+1 < cleanString.length())\n\t    banned.add(Character.toLowerCase(cleanString.charAt(i+1)));\n\t}\n      }\n\n      // METHOD 2: Uppercase starts of words.\n      // Splitting into blocks of ASCII letters wouldn't work\n      // because there could be non-ASCII letters in a word.\n      for (String wd : cleanString.split(\"[^\\\\p{IsAlphabetic}]\")) {\n        if (wd.length() == 0) continue;\n        firstChar = wd.charAt(0);\n        if (taken.contains(Character.toLowerCase(firstChar))) continue;\n\tif (banned.contains(Character.toLowerCase(firstChar))) continue;\n        if ('A' <= firstChar && firstChar <= 'Z') {\n          jmi.setMnemonic(firstChar);\n          taken.add((char)(firstChar | 32)); // tolowercase\n          continue algorithmicAssaignment;\n        }\n      }\n\n      // METHOD 3: Lowercase starts of words.\n      for (String wd : cleanString.split(\"[^\\\\p{IsAlphabetic}]\")) {\n        if (wd.length() == 0) continue;\n        firstChar = wd.charAt(0);\n        if (taken.contains(Character.toLowerCase(firstChar))) continue;\n\tif (banned.contains(Character.toLowerCase(firstChar))) continue;\n        if ('a' <= firstChar && firstChar <= 'z') {\n          jmi.setMnemonic(firstChar);\n          taken.add(firstChar); // is lowercase\n          continue algorithmicAssaignment;\n        }\n      }\n\n      // METHOD 4: Second ASCII letter.\n      cleanString = nonAAlpha.matcher(jmi.getText()).replaceAll(\"\"); \n      if (cleanString.length() >= 2) {\n        if (!taken.contains((char)(cleanString.charAt(1)|32))) {\n\t  if (!banned.contains((char)(cleanString.charAt(1)|32))) {\n\t    if (fm.charWidth('A') <= 2*fm.charWidth(cleanString.charAt(1))) {\n              jmi.setMnemonic(cleanString.charAt(1));\n              taken.add((char)(cleanString.charAt(1)|32));\n              continue algorithmicAssaignment;\n\t    }\n\t  }\n        }\n      }\n\n      // METHOD 5: charComparator.\n      cleanChars  = cleanString.toCharArray();\n      cleanCharas = new Character[cleanChars.length];\n      for (int i = 0; i < cleanChars.length; i++) {\n        cleanCharas[i] = new Character(cleanChars[i]);\n      }\n      Arrays.sort(cleanCharas, charComparator); // sorts in increasing order\n      for (char mnem : cleanCharas) {\n        if (taken.contains(Character.toLowerCase(mnem))) continue;\n\tif (banned.contains(Character.toLowerCase(mnem))) continue;\n        // NB: setMnemonic(char) doesn't want [^A-Za-z]\n        jmi.setMnemonic(mnem);\n        taken.add(Character.toLowerCase(mnem));\n        continue algorithmicAssaignment;\n      }\n\n      // METHOD 6: Digits\n      for (char digit : jmi.getText().replaceAll(\"[^0-9]\", \"\").toCharArray()) {\n        if (taken.contains(digit)) continue;\n        if (banned.contains(digit)) continue;\n        jmi.setMnemonic(KeyEvent.VK_0 + (digit - '0'));\n\ttaken.add(digit);\n\tcontinue algorithmicAssaignment;\n      }\n    }\n\n    // Finally, RECURSION.\n    for (JMenuItem jmi : menu) {\n      if (jmi instanceof JMenu) {\n        JMenu jm = (JMenu) jmi;\n        JMenuItem[] items = new JMenuItem[jm.getItemCount()];\n        for (int i = 0; i < items.length; i++) {\n          items[i] = jm.getItem(i);\n        }\n        setMenuMnemonics(items);\n      }\n    }\n  }","commit_id":"beb190fdfdc79b2dd96801dfe09aaf0f0af260af","url":"https://github.com/processing/processing"},{"original_method":"@SuppressWarnings({\"HardCodedStringLiteral\"})\n        public void parseLine(String line, boolean isErrorMessage) {\n                if (line.startsWith(\"RCS file:\")) {\n                        return;\n                }\n                if (line.startsWith(\"retrieving revision \")) {\n                        return;\n                }\n\n                if (line.indexOf(\" already contains the differences between \") > 0) {\n                        return;\n                }\n\n                if (line.startsWith(\"rcsmerge: warning: conflicts during merge\")) {\n                        return;\n                }\n\n                if (line.indexOf(EXAM_DIR) >= 0) {\n                        return;\n                }\n\n                if (line.indexOf(\": conflicts found in \") > 0) {\n                        return;\n                }\n\n                int index = line.indexOf(UNKNOWN);\n                if (index >= 0) {\n                        final String fileName = (line.substring(index + UNKNOWN.length())).trim();\n                        processUnknown(fileName);\n                        return;\n                }\n\n                index = line.indexOf(TO_ADD);\n                if (index >= 0) {\n                        final String fileName = (line.substring(index + TO_ADD.length())).trim();\n                        processUnknown(fileName);\n                        return;\n                }\n\n                if (line.startsWith(MERGING)) {\n//\t\t\toutputDone();\n//\t\t\tensureExistingFileInfoContainer();\n//\t\t\tindex = line.indexOf(UpdateCommand2.INTO, UpdateCommand2.MERGING.length() + 1);\n//\t\t\tif (index > 0) {\n//\t\t\t\tfileInfoContainer.setFile(createFile(line.substring(index + UpdateCommand2.INTO.length())));\n//\t\t\t}\n//\t\t\tfileInfoContainer.setType(DefaultFileInfoContainer.MERGED_FILE);\n                        return;\n                }\n\n        index = line.indexOf(LOCALLY_MODIFIED_FILE_HAS_BEEN_REMOVED);\n        if (index >= 0){\n            String warningPrefix = \"cvs server: file \";\n            if (!line.startsWith(warningPrefix)) return;\n            final String fileName = line.substring(warningPrefix.length(), index).trim();\n            final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n            ensureExistingFileInfoContainer(fileObject);\n            // HACK - will create conflict status in order to be able to have consistent info format\n            fileInfo.setType(\"C\");\n            return;\n        }\n\n                index = line.indexOf(WARNING);\n                if (index >= 0) {\n                        final int pertinentIndex = line.indexOf(PERTINENT);\n                        if (pertinentIndex > 0) {\n                                final String fileName = line.substring(index + WARNING.length(),\n                                                                       pertinentIndex).trim();\n                                final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n                                processNotPertinent(fileObject);\n                        }\n                        return;\n                }\n\n                index = line.indexOf(NOT_IN_REPOSITORY);\n                if (index > 0) {\n                        final String fileName = line.substring(line.indexOf(SERVER) + SERVER.length(),\n                                                               index).trim();\n                        final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n                        processNotPertinent(fileObject);\n                        return;\n                }\n\n                // otherwise\n                if (line.length() > 2) {\n                        if (line.charAt(1) == ' ') {\n                                final String firstChar = line.substring(0, 1);\n                                if (STATES.indexOf(firstChar) >= 0) {\n                                        processFile(line.substring(2), firstChar);\n                                }\n                        }\n                }\n        }","id":36303,"modified_method":"@SuppressWarnings({\"HardCodedStringLiteral\"})\n  public void parseLine(String line, boolean isErrorMessage) {\n    if (line.startsWith(\"RCS file:\")) {\n      return;\n    }\n    if (line.startsWith(\"retrieving revision \")) {\n      return;\n    }\n\n    if (line.indexOf(\" already contains the differences between \") > 0) {\n      return;\n    }\n\n    if (line.startsWith(\"rcsmerge: warning: conflicts during merge\")) {\n      return;\n    }\n\n    if (line.indexOf(EXAM_DIR) >= 0) {\n      return;\n    }\n\n    if (line.indexOf(\": conflicts found in \") > 0) {\n      return;\n    }\n\n    int index = line.indexOf(UNKNOWN);\n    if (index >= 0) {\n      final String fileName = (line.substring(index + UNKNOWN.length())).trim();\n      processUnknown(fileName);\n      return;\n    }\n\n    index = line.indexOf(TO_ADD);\n    if (index >= 0) {\n      final String fileName = (line.substring(index + TO_ADD.length())).trim();\n      processUnknown(fileName);\n      return;\n    }\n\n    if (line.startsWith(MERGING)) {\n//\t\t\toutputDone();\n//\t\t\tensureExistingFileInfoContainer();\n//\t\t\tindex = line.indexOf(UpdateCommand2.INTO, UpdateCommand2.MERGING.length() + 1);\n//\t\t\tif (index > 0) {\n//\t\t\t\tfileInfoContainer.setFile(createFile(line.substring(index + UpdateCommand2.INTO.length())));\n//\t\t\t}\n//\t\t\tfileInfoContainer.setType(DefaultFileInfoContainer.MERGED_FILE);\n      return;\n    }\n\n    index = line.indexOf(LOCALLY_MODIFIED_FILE_HAS_BEEN_REMOVED);\n    if (index >= 0) {\n      String warningPrefix = \"cvs server: file \";\n      if (!line.startsWith(warningPrefix)) return;\n      final String fileName = line.substring(warningPrefix.length(), index).trim();\n      final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n      ensureExistingFileInfoContainer(fileObject);\n      // HACK - will create conflict status in order to be able to have consistent info format\n      fileInfo.setType(\"C\");\n      return;\n    }\n\n    index = line.indexOf(WARNING);\n    if (index >= 0) {\n      final int pertinentIndex = line.indexOf(PERTINENT);\n      if (pertinentIndex > 0) {\n        final String fileName = line.substring(index + WARNING.length(), pertinentIndex).trim();\n        final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n        processNotPertinent(fileObject);\n      }\n      return;\n    }\n\n    Matcher m = NOT_IN_REPOSITORY_PATTERN.matcher(line);\n    if (m.matches()) {\n      final String fileName = m.group(1).trim();\n      final FileObject fileObject = cvsFileSystem.unixFileNameToFileObject(fileName);\n      processNotPertinent(fileObject);\n      return;\n    }\n\n    // otherwise\n    if (line.length() > 2) {\n      if (line.charAt(1) == ' ') {\n        final String firstChar = line.substring(0, 1);\n        if (STATES.indexOf(firstChar) >= 0) {\n          processFile(line.substring(2), firstChar);\n        }\n      }\n    }\n  }","commit_id":"bb84d1673b0ed5bd9b80472d61b43bde4cbbb090","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean isProjectOrModuleFile(VirtualFile virtualFile) {\n    if (virtualFile == null) return false;\n    FileType fileType = FileTypeManager.getInstance().getFileTypeByFile(virtualFile);\n    return\n      fileType == StdFileTypes.IDEA_PROJECT\n      || fileType == StdFileTypes.IDEA_MODULE\n      || fileType == StdFileTypes.IDEA_WORKSPACE;\n  }","id":36304,"modified_method":"private static boolean isProjectOrModuleFile(VirtualFile virtualFile) {\n    if (virtualFile == null) return false;\n    FileType fileType = FileTypeManager.getInstance().getFileTypeByFile(virtualFile);\n    return\n      fileType == StdFileTypes.IDEA_PROJECT\n      || fileType == StdFileTypes.IDEA_MODULE\n      || fileType == StdFileTypes.IDEA_WORKSPACE;\n  }","commit_id":"bb84d1673b0ed5bd9b80472d61b43bde4cbbb090","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private Map<Integer, String> replaceSoftHyphens(List<String> tokens) {\n    final Map<Integer, String> softHyphenTokens = new HashMap<>();\n    for (int i = 0; i < tokens.size(); i++) {\n      if (tokens.get(i).indexOf('\\u00ad') != -1) {\n        softHyphenTokens.put(i, tokens.get(i));\n        tokens.set(i, tokens.get(i).replaceAll(\"\\u00ad\", \"\"));\n      }\n    }\n    return softHyphenTokens;\n  }","id":36305,"modified_method":"private Map<Integer, String> replaceSoftHyphens(List<String> tokens) {\n    Pattern ignoredCharacterRegex = language.getIgnoredCharactersRegex();\n    \n    final Map<Integer, String> ignoredCharsTokens = new HashMap<>();\n    if( ignoredCharacterRegex == null )\n      return ignoredCharsTokens;\n    \n    for (int i = 0; i < tokens.size(); i++) {\n      if ( ignoredCharacterRegex.matcher(tokens.get(i)).find() ) {\n        ignoredCharsTokens.put(i, tokens.get(i));\n        tokens.set(i, ignoredCharacterRegex.matcher(tokens.get(i)).replaceAll(\"\"));\n      }\n    }\n    return ignoredCharsTokens;\n  }","commit_id":"af08112b42db60cb1dfec757c4b444db0ad66d60","url":"https://github.com/languagetool-org/languagetool"},{"original_method":"/**\n     * Given a interface name and map generated by the system record\n     * this method creates a new Network object.\n     * @param name the name of the interface\n     * @param ifaceInfo the interface information\n     * @return the netwrok object\n     */\n    static Network load(String name, Map<String, Object> ifaceInfo) {\n        Network net = new Network(name);\n        net.setMacAddress((String)ifaceInfo.get(MAC_ADDRESS));\n        net.setNetmask((String)ifaceInfo.get(SUBNET));\n        net.setIpAddress((String)ifaceInfo.get(IP_ADDRESS));\n        net.setStaticNetwork(ifaceInfo.containsKey(STATIC) &&\n                                    Boolean.TRUE.equals(ifaceInfo.get(STATIC)));\n        return net;\n    }","id":36306,"modified_method":"/**\n     * Given a interface name and map generated by the system record\n     * this method creates a new Network object.\n     * @param name the name of the interface\n     * @param ifaceInfo the interface information\n     * @return the netwrok object\n     */\n    static Network load(CobblerConnection connection, String name, Map<String, Object> ifaceInfo) {\n        Network net = new Network(connection, name);\n        net.setMacAddress((String)ifaceInfo.get(\"mac_address\"));\n        net.setIpAddress((String)ifaceInfo.get(\"ip_address\"));\n        net.setStaticNetwork(ifaceInfo.containsKey(\"static\") &&\n                                    Boolean.TRUE.equals(ifaceInfo.get(\"static\")));\n\n        // use the correct variable for the netmask/subnet\n        if (connection.getVersion() >= 2.2) {\n            net.setNetmask((String)ifaceInfo.get(\"netmask\"));\n        } else {\n            net.setNetmask((String)ifaceInfo.get(\"subnet\"));\n        }\n\n        return net;\n    }","commit_id":"92fed831e06ed6909807e232a5fb740b982f0fb0","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * @param subnetIn The subnet to set.\n     */\n    public void setNetmask(String subnetIn) {\n        subnet = subnetIn;\n    }","id":36307,"modified_method":"/**\n     * @param netmaskIn The netmask to set.\n     */\n    public void setNetmask(String netmaskIn) {\n        netmask = netmaskIn;\n    }","commit_id":"92fed831e06ed6909807e232a5fb740b982f0fb0","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * Intentionally given default/package scope\n     * returns a nicely formatted map that can be used by\n     * the system record to set it in xmlrpc.\n     * @return a map representation of the interface\n     */\n    Map<String, Object> toMap() {\n        Map<String, Object> inet = new HashMap<String, Object>();\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, \"subnet-\" + name, subnet);\n        addToMap(inet, \"ipaddress-\" + name, ipAddress);\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, \"static-\" + name, isStatic);\n        return inet;\n    }","id":36308,"modified_method":"/**\n     * Intentionally given default/package scope\n     * returns a nicely formatted map that can be used by\n     * the system record to set it in xmlrpc.\n     * @return a map representation of the interface\n     */\n    Map<String, Object> toMap() {\n        Map<String, Object> inet = new HashMap<String, Object>();\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, netmaskVariableName + \"-\" + name, netmask);\n        addToMap(inet, \"ipaddress-\" + name, ipAddress);\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, \"static-\" + name, isStatic);\n        return inet;\n    }","commit_id":"92fed831e06ed6909807e232a5fb740b982f0fb0","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * Given a interface name and map generated by the system record\n     * this method creates a new Network object.\n     * @param name the name of the interface\n     * @param ifaceInfo the interface information\n     * @return the network object\n     */\n    static Network load(CobblerConnection connection, String name,\n            Map<String, Object> ifaceInfo) {\n        Network net = new Network(connection, name);\n        net.setMacAddress((String)ifaceInfo.get(\"mac_address\"));\n        net.setIpAddress((String)ifaceInfo.get(\"ip_address\"));\n        net.setStaticNetwork(ifaceInfo.containsKey(\"static\") &&\n                Boolean.TRUE.equals(ifaceInfo.get(\"static\")));\n\n        // use the correct variable for the netmask/subnet\n        if (connection.getVersion() >= 2.2) {\n            net.setNetmask((String)ifaceInfo.get(\"netmask\"));\n        }\n        else {\n            net.setNetmask((String)ifaceInfo.get(\"subnet\"));\n        }\n\n        net.setIpv6Address((String) ifaceInfo.get(\"ipv6_address\"));\n        net.setIpv6Secondaries((ArrayList<String>) ifaceInfo.get(\"ipv6_secondaries\"));\n        net.setBonding((String) ifaceInfo.get(\"bonding\"));\n        net.setBondingMaster((String) ifaceInfo.get(\"bonding_master\"));\n        net.setBondingOptions((String) ifaceInfo.get(\"bonding_opts\"));\n\n        return net;\n    }","id":36309,"modified_method":"/**\n     * Given a interface name and map generated by the system record\n     * this method creates a new Network object.\n     * @param name the name of the interface\n     * @param ifaceInfo the interface information\n     * @return the network object\n     */\n    static Network load(CobblerConnection connection, String name,\n            Map<String, Object> ifaceInfo) {\n        Network net = new Network(connection, name);\n        net.setMacAddress((String)ifaceInfo.get(\"mac_address\"));\n        net.setIpAddress((String)ifaceInfo.get(\"ip_address\"));\n        net.setStaticNetwork(ifaceInfo.containsKey(\"static\") &&\n                Boolean.TRUE.equals(ifaceInfo.get(\"static\")));\n\n        if (connection.getVersion() >= 2.2) {\n            net.setNetmask((String)ifaceInfo.get(\"netmask\"));\n            net.setBondingMaster((String) ifaceInfo.get(\"interface_master\"));\n            net.setBonding((String) ifaceInfo.get(\"interface_type\"));\n        }\n        else {\n            net.setNetmask((String)ifaceInfo.get(\"subnet\"));\n            net.setBondingMaster((String) ifaceInfo.get(\"bonding_master\"));\n            net.setBonding((String) ifaceInfo.get(\"bonding\"));\n        }\n\n        net.setIpv6Address((String) ifaceInfo.get(\"ipv6_address\"));\n        net.setIpv6Secondaries((ArrayList<String>) ifaceInfo.get(\"ipv6_secondaries\"));\n        net.setBondingOptions((String) ifaceInfo.get(\"bonding_opts\"));\n\n        return net;\n    }","commit_id":"7ab3858e7c25447507c53fd868df90e2f93e3620","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * Intentionally given default/package scope\n     * returns a nicely formatted map that can be used by\n     * the system record to set it in xmlrpc.\n     * @return a map representation of the interface\n     */\n    Map<String, Object> toMap() {\n        Map<String, Object> inet = new HashMap<String, Object>();\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, netmaskVariableName + \"-\" + name, netmask);\n        addToMap(inet, \"ipaddress-\" + name, ipAddress);\n        addToMap(inet, \"static-\" + name, isStatic);\n        addToMap(inet, \"ipv6address-\" + name, ipv6Address);\n        addToMap(inet, \"ipv6secondaries-\" + name, ipv6Secondaries);\n        addToMap(inet, \"bonding-\" + name, bonding);\n        addToMap(inet, \"bondingmaster-\" + name, bondingMaster);\n        addToMap(inet, \"bondingopts-\" + name, bondingOptions);\n        return inet;\n    }","id":36310,"modified_method":"/**\n     * Intentionally given default/package scope\n     * returns a nicely formatted map that can be used by\n     * the system record to set it in xmlrpc.\n     * @return a map representation of the interface\n     */\n    Map<String, Object> toMap() {\n        Map<String, Object> inet = new HashMap<String, Object>();\n        addToMap(inet, \"macaddress-\" + name, macAddress);\n        addToMap(inet, netmaskVariableName + \"-\" + name, netmask);\n        addToMap(inet, \"ipaddress-\" + name, ipAddress);\n        addToMap(inet, \"static-\" + name, isStatic);\n        addToMap(inet, \"ipv6address-\" + name, ipv6Address);\n        addToMap(inet, \"ipv6secondaries-\" + name, ipv6Secondaries);\n        addToMap(inet, bondingTypeVariableName + \"-\" + name, bonding);\n        addToMap(inet, bondingMasterVariableName + \"-\" + name, bondingMaster);\n        addToMap(inet, \"bondingopts-\" + name, bondingOptions);\n        return inet;\n    }","commit_id":"7ab3858e7c25447507c53fd868df90e2f93e3620","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * Constructor to create a new network interface\n     * @param nameIn the name of the network\n     * @param connection CobblerConnection object\n     */\n    public Network(CobblerConnection connection, String nameIn) {\n        name = nameIn;\n\n        // 'subnet' changed to 'netmask' in newer versions of Cobbler\n        if (connection.getVersion() >= 2.2) {\n            netmaskVariableName = \"netmask\";\n        }\n        else {\n            netmaskVariableName = \"subnet\";\n        }\n    }","id":36311,"modified_method":"/**\n     * Constructor to create a new network interface\n     * @param nameIn the name of the network\n     * @param connection CobblerConnection object\n     */\n    public Network(CobblerConnection connection, String nameIn) {\n        name = nameIn;\n\n        // several variable names changed in cobbler 2.2\n        if (connection.getVersion() >= 2.2) {\n            netmaskVariableName = \"netmask\";\n            bondingMasterVariableName = \"interfacemaster\";\n            bondingTypeVariableName = \"interfacetype\";\n            BONDING_MASTER = \"bond\";\n            BONDING_SLAVE = \"bond_slave\";\n        }\n        else {\n            netmaskVariableName = \"subnet\";\n            bondingMasterVariableName = \"bondingmaster\";\n            bondingTypeVariableName = \"bonding\";\n            BONDING_MASTER = \"master\";\n            BONDING_SLAVE = \"slave\";\n        }\n    }","commit_id":"7ab3858e7c25447507c53fd868df90e2f93e3620","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"@SuppressWarnings({\"HardCodedStringLiteral\"})\n  @Nullable\n  public static JComponent getPreviewComponent(@NotNull final PsiElement element) {\n    final PsiNewExpression psiNewExpression = PsiTreeUtil.getParentOfType(element, PsiNewExpression.class);\n    if (psiNewExpression != null) {\n      final PsiJavaCodeReferenceElement referenceElement = PsiTreeUtil.getChildOfType(psiNewExpression, PsiJavaCodeReferenceElement.class);\n      if (referenceElement != null) {\n        final PsiReference reference = referenceElement.getReference();\n        if (reference != null) {\n          final PsiElement psiElement = reference.resolve();\n          if (psiElement instanceof PsiClass && \"java.awt.Color\".equals(((PsiClass)psiElement).getQualifiedName())) {\n            final PsiExpressionList argumentList = psiNewExpression.getArgumentList();\n            if (argumentList != null) {\n              final PsiExpression[] expressions = argumentList.getExpressions();\n              int[] values = new int[expressions.length];\n              float[] values2 = new float[expressions.length];\n              int i = 0;\n              int j = 0;\n              for (final PsiExpression each : expressions) {\n                if (each instanceof PsiLiteralExpression) {\n                  final Object o = ((PsiLiteralExpression)each).getValue();\n                  if (o instanceof Integer) {\n                    values[i] = ((Integer)o).intValue();\n                    i++;\n                  }\n                  else if (o instanceof Float) {\n                    values2[j] = ((Float)o).floatValue();\n                    j++;\n                  }\n                }\n              }\n\n\n              Color c = null;\n              if (i == expressions.length) {\n                switch (values.length) {\n                  case 1:\n                    c = new Color(values[0]);\n                    break;\n                  case 3:\n                    c = new Color(values[0], values[1], values[2]);\n                    break;\n                  case 4:\n                    c = new Color(values[0], values[1], values[2], values[3]);\n                    break;\n                  default:\n                    break;\n                }\n              }\n              else if (j == expressions.length) {\n                switch (values2.length) {\n                  case 3:\n                    c = new Color(values2[0], values2[1], values2[2]);\n                    break;\n                  case 4:\n                    c = new Color(values2[0], values2[1], values2[2], values2[3]);\n                    break;\n                  default:\n                    break;\n                }\n              }\n\n              if (c != null) {\n                return new ColorPreviewComponent(null, c);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (PlatformPatterns.psiElement(PsiIdentifier.class).withParent(PlatformPatterns.psiElement(PsiReferenceExpression.class))\n      .accepts(element)) {\n      final PsiReference reference = element.getParent().getReference();\n      if (reference != null) {\n        final PsiElement psiElement = reference.resolve();\n        if (psiElement instanceof PsiField) {\n          if (\"java.awt.Color\".equals(((PsiField)psiElement).getContainingClass().getQualifiedName())) {\n            final String colorName = ((PsiField)psiElement).getName().toLowerCase().replace(\"_\", \"\");\n            final String hex = ColorSampleLookupValue.getHexCodeForColorName(colorName);\n            return new ColorPreviewComponent(null, Color.decode(\"0x\" + hex.substring(1)));\n          }\n        }\n      }\n    }\n\n\n    if (element.getParent() instanceof XmlAttributeValue) {\n      final PsiElement parentParent = element.getParent().getParent();\n      if (parentParent instanceof XmlAttribute) {\n        XmlAttribute attribute = (XmlAttribute)parentParent;\n        String attrName = attribute.getName();\n        if (\"alink\".equals(attrName) ||\n            \"link\".equals(attrName) | \"text\".equals(attrName) ||\n            \"vlink\".equals(attrName) ||\n            \"bgcolor\".equals(attrName) ||\n            \"color\".equals(attrName)) {\n          String s = element.getText();\n          if (s.length() > 0) {\n            final String hexColor = (s.charAt(0) == '#') ? s : ColorSampleLookupValue.getHexCodeForColorName(s.toLowerCase());\n            if (hexColor != null) {\n              try {\n                return new ColorPreviewComponent(null, Color.decode(\"0x\" + hexColor.substring(1)));\n              }\n              catch (NumberFormatException e) {\n                return null;\n              }\n            }\n          }\n        }\n      }\n    }\n    else {\n      final Color color = CssUtil.getColor(element);\n      if (color != null) {\n        try {\n          return new ColorPreviewComponent(null, color);\n        }\n        catch (NumberFormatException e) {\n          return null;\n        }\n      }\n    }\n\n    return null;\n  }","id":36312,"modified_method":"@SuppressWarnings({\"HardCodedStringLiteral\"})\n  @Nullable\n  public static JComponent getPreviewComponent(@NotNull final PsiElement element) {\n    final PsiNewExpression psiNewExpression = PsiTreeUtil.getParentOfType(element, PsiNewExpression.class);\n\n    if (psiNewExpression != null) {\n      final PsiJavaCodeReferenceElement referenceElement = PsiTreeUtil.getChildOfType(psiNewExpression, PsiJavaCodeReferenceElement.class);\n\n      if (referenceElement != null) {\n        final PsiReference reference = referenceElement.getReference();\n\n        if (reference != null) {\n          final PsiElement psiElement = reference.resolve();\n\n          if (psiElement instanceof PsiClass && \"java.awt.Color\".equals(((PsiClass)psiElement).getQualifiedName())) {\n            final PsiExpressionList argumentList = psiNewExpression.getArgumentList();\n\n            if (argumentList != null) {\n              final PsiExpression[] expressions = argumentList.getExpressions();\n              int[] values = new int[expressions.length];\n              float[] values2 = new float[expressions.length];\n              int i = 0;\n              int j = 0;\n              \n              for (final PsiExpression each : expressions) {\n                if (each instanceof PsiLiteralExpression) {\n                  final Object o = ((PsiLiteralExpression)each).getValue();\n                  if (o instanceof Integer) {\n                    values[i] = ((Integer)o).intValue();\n                    i++;\n                  }\n                  else if (o instanceof Float) {\n                    values2[j] = ((Float)o).floatValue();\n                    j++;\n                  }\n                }\n              }\n\n\n              Color c = null;\n              if (i == expressions.length) {\n                switch (values.length) {\n                  case 1:\n                    c = new Color(values[0]);\n                    break;\n                  case 3:\n                    c = new Color(values[0], values[1], values[2]);\n                    break;\n                  case 4:\n                    c = new Color(values[0], values[1], values[2], values[3]);\n                    break;\n                  default:\n                    break;\n                }\n              }\n              else if (j == expressions.length) {\n                switch (values2.length) {\n                  case 3:\n                    c = new Color(values2[0], values2[1], values2[2]);\n                    break;\n                  case 4:\n                    c = new Color(values2[0], values2[1], values2[2], values2[3]);\n                    break;\n                  default:\n                    break;\n                }\n              }\n\n              if (c != null) {\n                return new ColorPreviewComponent(null, c);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (PlatformPatterns.psiElement(PsiIdentifier.class).withParent(PlatformPatterns.psiElement(PsiReferenceExpression.class))\n      .accepts(element)) {\n      final PsiReference reference = element.getParent().getReference();\n\n      if (reference != null) {\n        final PsiElement psiElement = reference.resolve();\n\n        if (psiElement instanceof PsiField) {\n          if (\"java.awt.Color\".equals(((PsiField)psiElement).getContainingClass().getQualifiedName())) {\n            final String colorName = ((PsiField)psiElement).getName().toLowerCase().replace(\"_\", \"\");\n            final String hex = ColorSampleLookupValue.getHexCodeForColorName(colorName);\n            return new ColorPreviewComponent(null, Color.decode(\"0x\" + hex.substring(1)));\n          }\n        }\n      }\n    }\n\n\n    if (element.getParent() instanceof XmlAttributeValue) {\n      final PsiElement parentParent = element.getParent().getParent();\n\n      if (parentParent instanceof XmlAttribute) {\n        final XmlAttribute attribute = (XmlAttribute)parentParent;\n        final String attrName = attribute.getName().toLowerCase();\n\n        if (\"alink\".equals(attrName) ||\n            \"link\".equals(attrName) ||\n            \"text\".equals(attrName) ||\n            \"vlink\".equals(attrName) ||\n            attrName.indexOf(\"color\") >= 0) {\n          String s = element.getText();  // TODO: support [#FFF, #FFF]\n\n          if (s.length() > 0) {\n            final String hexColor = (s.charAt(0) == '#') ? s : ColorSampleLookupValue.getHexCodeForColorName(s.toLowerCase());\n            if (hexColor != null) {\n              try {\n                return new ColorPreviewComponent(null, Color.decode(\"0x\" + hexColor.substring(1)));\n              }\n              catch (NumberFormatException e) {\n                return null;\n              }\n            }\n          }\n        }\n      }\n    }\n    else {\n      final Color color = CssUtil.getColor(element);\n      if (color != null) {\n        try {\n          return new ColorPreviewComponent(null, color);\n        }\n        catch (NumberFormatException e) {\n          return null;\n        }\n      }\n    }\n\n    return null;\n  }","commit_id":"95e0515d2d487dc738eec7bcdfc10972e124d72f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void sawOpcode(int seen) {\n\t\tif (seen == NEW\n\t\t        && getClassConstantOperand().equals(\"java/util/NoSuchElementException\"))\n\t\t\tsawNoSuchElement = true;\n\t\telse if (seen == INVOKESPECIAL\n\t\t        || seen == INVOKEVIRTUAL\n\t\t        || seen == INVOKEINTERFACE) {\n\t\t\t// System.out.println(\"Saw call to \" + nameConstant);\n\t\t\tif (getNameConstantOperand().equals(\"next\") || getNameConstantOperand().equals(\"previous\") || getNameConstantOperand().equals(\"hasNext\"))\n\t\t\t\tsawNoSuchElement = true;\n\t\t}\n\t}","id":36313,"modified_method":"public void sawOpcode(int seen) {\n\t\tif (seen == NEW\n\t\t        && getClassConstantOperand().equals(\"java/util/NoSuchElementException\"))\n\t\t\tsawNoSuchElement = true;\n\t\telse if (seen == INVOKESPECIAL\n\t\t        || seen == INVOKEVIRTUAL\n\t\t        || seen == INVOKEINTERFACE) {\n\t\t\t// System.out.println(\"Saw call to \" + nameConstant);\n\t\t\tif (getNameConstantOperand().toLowerCase().indexOf(\"next\")  >= 0 || getNameConstantOperand().toLowerCase().indexOf(\"previous\") >= 0 )\n\t\t\t\tsawNoSuchElement = true;\n\t\t}\n\t}","commit_id":"344b8796567908a5e9cca07ebb4660c71a5f9876","url":"https://github.com/findbugsproject/findbugs"},{"original_method":"public static <S extends Automata.State, P extends HasFullName<P>> Callable<CheckedListenableFuture<P>> sequenceTransitions( final HasStateMachine<P, S, ?> hasFsm, final S... toStates ) {\n    assertThat( toStates, not( emptyArray( ) ) );\n    //TODO:GRZE: enforce that the sequence of states denotes a valid transition path\n    LOG.debug( \"Preparing callback for \" + hasFsm.getFullName( ) + \" transition sequence: \" + Joiner.on( \"->\" ).join( toStates ) );\n    final List<Callable<CheckedListenableFuture<P>>> callables = makeTransitionCallables( hasFsm, toStates );\n    return Futures.sequence( callables.toArray( new Callable[] {} ) );\n  }","id":36314,"modified_method":"public static <S extends Automata.State, P extends HasFullName<P>> Callable<CheckedListenableFuture<P>> sequenceTransitions( final HasStateMachine<P, S, ?> hasFsm, final S... toStates ) {\n    assertThat( toStates, not( emptyArray( ) ) );\n    //TODO:GRZE: enforce that the sequence of states denotes a valid transition path\n    S currentState = hasFsm.getStateMachine( ).getState( );\n    int index = Lists.newArrayList( toStates ).indexOf( currentState );\n    S[] actualStates = toStates; \n    if( index > 0 && index < toStates.length ) {\n      actualStates = Arrays.copyOfRange( toStates, index+1, toStates.length );\n    }\n    LOG.debug( \"Preparing callback for \" + hasFsm.getFullName( ) + \" from state \" + currentState + \" followed by transition sequence: \" + Joiner.on( \"->\" ).join( actualStates ) );\n    final List<Callable<CheckedListenableFuture<P>>> callables = makeTransitionCallables( hasFsm, actualStates );\n    return Futures.sequence( callables.toArray( new Callable[] {} ) );\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public State getState( ) {\n    return this.getLocalServiceConfiguration( ).lookupState( );\n  }","id":36315,"modified_method":"public State getState( ) {\n    return this.hasLocalService( ) ? this.getLocalServiceConfiguration( ).lookupState( ) : State.NONE;\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public DescribeComponentsResponseType listComponents( final DescribeComponentsType request ) throws EucalyptusCloudException {\n    final DescribeComponentsResponseType reply = ( DescribeComponentsResponseType ) request.getReply( );\n    final List<ComponentInfoType> listConfigs = reply.getRegistered( );\n    if ( DescribeComponentsType.class.equals( request.getClass( ) ) ) {\n      for ( final Component c : Components.list( ) ) {\n        if ( c.lookupServices( ).isEmpty( ) ) {\n          listConfigs.add( new ComponentInfoType( String.format( \"%-15.15s\", c.getComponentId( ).name( ).toUpperCase( ) ), c.getComponentId( ).name( ), \"\",\n                                                  c.getState( ).toString( ), \"\" ) );\n        } else {\n          for ( final ServiceConfiguration conf : c.lookupServiceConfigurations( ) ) {\n            try {\n              listConfigs.add( new ComponentInfoType( String.format( \"%-15.15s\", conf.getComponentId( ).name( ).toUpperCase( ) )\n                                                      + ( conf.getPartition( ) != null\n                                                        ? conf.getPartition( )\n                                                        : \"-\" ),\n                                                      conf.getFullName( ).toString( ), conf.getHostName( ), conf.lookupStateMachine( ).getState( ).toString( ),\n                                                      \"\" ) );\n            } catch ( final Exception ex ) {\n              LOG.error( ex, ex );\n              listConfigs.add( new ComponentInfoType( String.format( \"%-15.15s\", conf.getComponentId( ).name( ).toUpperCase( ) )\n                                                      + ( conf.getPartition( ) != null\n                                                        ? conf.getPartition( )\n                                                        : \"-\" ),\n                                                      conf.getFullName( ).toString( ), conf.getHostName( ), \"none\", \"\" ) );\n            }\n            for ( final String d : Collections2.transform( conf.lookupDetails( ), Functions.toStringFunction( ) ) ) {\n              listConfigs.add( new ComponentInfoType( String.format( \"%-15.15s\", conf.getComponentId( ).name( ).toUpperCase( ) )\n                                                      + ( conf.getPartition( ) != null\n                                                        ? conf.getPartition( )\n                                                        : \"-\" ),\n                                                      conf.getName( ), \"detail\", d, \"\" ) );\n            }\n          }\n        }\n      }\n    } else {\n      for ( final ServiceConfiguration conf : ServiceBuilderRegistry.handles( request.getClass( ) ).list( ) ) {\n        try {\n          final Service s = Components.lookup( conf.getComponentId( ) ).lookupService( conf );\n          listConfigs.add( new ComponentInfoType( conf.getPartition( ), conf.getName( ), conf.getHostName( ),\n                                                  conf.lookupStateMachine( ).getState( ).toString( ), Collections2.transform( conf.lookupDetails( ), Functions.toStringFunction( ) ) ) );\n        } catch ( final NoSuchElementException ex ) {\n          listConfigs.add( new ComponentInfoType( conf.getPartition( ), conf.getName( ), conf.getHostName( ), Component.State.NOTREADY.toString( ), \"unknown\" ) );\n          LOG.error( ex, ex );\n        }\n      }\n    }\n    return reply;\n  }","id":36316,"modified_method":"public DescribeComponentsResponseType listComponents( final DescribeComponentsType request ) throws EucalyptusCloudException {\n    final DescribeComponentsResponseType reply = ( DescribeComponentsResponseType ) request.getReply( );\n    final List<ComponentInfoType> listConfigs = reply.getRegistered( );\n    if ( DescribeComponentsType.class.equals( request.getClass( ) ) ) {\n      for ( final Component c : Components.list( ) ) {\n        if ( !c.hasLocalService( ) ) {\n          listConfigs.add( new ComponentInfoType( ) {\n            {\n              setType( c.getComponentId( ).name( ) );\n              setPartition( c.getComponentId( ).getPartition( ) );\n              setName( \"\" );\n              setHostName( \"\" );\n              setFullName( \"\" );\n              setState( c.getState( ).toString( ) );\n              setDetail( \"\" );\n            }\n          } );\n        } else {\n          final ServiceConfiguration config = c.getLocalServiceConfiguration( );\n          listConfigs.add( new ComponentInfoType( ) {\n            {\n              setType( config.getComponentId( ).name( ) );\n              setPartition( config.getPartition( ) );\n              setName( config.getName( ) );\n              setHostName( config.getHostName( ) );\n              setFullName( config.getFullName( ).toString( ) );\n              setState( config.lookupState( ).toString( ) );\n              setDetail( config.lookupDetails( ).isEmpty( ) || !Boolean.TRUE.equals( request.getVerbose( ) )\n                         ? \"\"\n                         : config.lookupDetails( ).iterator( ).next( ).toString( ) );\n            }\n          } );\n        }\n      }\n    } else {\n      for ( final ServiceConfiguration config : ServiceBuilderRegistry.handles( request.getClass( ) ).list( ) ) {\n        try {\n          listConfigs.add( new ComponentInfoType( ) {\n            {\n              setType( config.getComponentId( ).name( ) );\n              setPartition( config.getPartition( ) );\n              setName( config.getName( ) );\n              setHostName( config.getHostName( ) );\n              setFullName( config.getFullName( ).toString( ) );\n              setState( config.lookupState( ).toString( ) );\n              setDetail( config.lookupDetails( ).isEmpty( ) || !Boolean.TRUE.equals( request.getVerbose( ) )\n                ? \"\"\n                : config.lookupDetails( ).iterator( ).next( ).toString( ) );\n            }\n          } );\n        } catch ( final NoSuchElementException ex ) {\n          LOG.error( ex, ex );\n          listConfigs.add( new ComponentInfoType( ) {\n            {\n              setType( config.getComponentId( ).name( ) );\n              setPartition( config.getPartition( ) );\n              setName( config.getName( ) );\n              setHostName( config.getHostName( ) );\n              setFullName( config.getFullName( ).toString( ) );\n              setState( config.lookupComponent( ).getState( ).toString( ) );\n              setDetail( config.lookupDetails( ).isEmpty( ) || !Boolean.TRUE.equals( request.getVerbose( ) )\n                         ? \"\"\n                         : config.lookupDetails( ).iterator( ).next( ).toString( ) );\n            }\n          } );\n        }\n      }\n    }\n    return reply;\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public String toString( ) {\n    StringBuilder builder = new StringBuilder( );\n    builder.append( \"ServiceCheckRecord \" ).append( this.severity )\n           .append( \" \" ).append( this.serviceFullName )\n           .append( \" name=\" ).append( this.serviceName )\n           .append( \" host=\" ).append( this.serviceHost )\n           .append( \" uuid=\" ).append( this.uuid )\n           .append( \" correlationId=\" ).append( this.correlationId )\n           .append( \" timestamp=\" ).append( this.timestamp )\n           .append( \" message=\" ).append( this.message )\n           .append( \" stackTrace=\" ).append( this.stackTrace );\n    return builder.toString( );\n  }","id":36317,"modified_method":"@Override\n  public String toString( ) {\n    StringBuilder builder = new StringBuilder( );\n    builder.append( \"ServiceCheckRecord \" ).append( this.severity )\n           .append( \" \" ).append( this.serviceFullName )\n           .append( \" name=\" ).append( this.serviceName )\n           .append( \" host=\" ).append( this.serviceHost )\n           .append( \" uuid=\" ).append( this.uuid )\n           .append( \" correlationId=\" ).append( this.correlationId )\n           .append( \" timestamp=\" ).append( this.timestamp )\n           .append( \" message=\" ).append( this.message );\n//           .append( \" stackTrace=\" ).append( this.stackTrace );\n    return builder.toString( );\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public boolean start( ) throws Exception {\n    Component euca = Components.lookup( Eucalyptus.class );\n    for ( final Component comp : Components.list( ) ) {\n      LOG.info( \"start(): \" + comp );\n      EventRecord.here( ServiceDispatchBootstrapper.class, EventType.COMPONENT_INFO, comp.getName( ), comp.isAvailableLocally( ).toString( ) ).info( );\n      for ( final ServiceConfiguration s : comp.lookupServiceConfigurations( ) ) {\n        if( !comp.getComponentId( ).hasDispatcher( ) ) {\n          continue;\n        } else if ( Bootstrap.isCloudController( ) ) {\n          try {\n            comp.enableTransition( s ).get( );\n            break;\n          } catch ( Throwable ex ) {\n            Exceptions.trace( \"start()/enable(): Starting service failed: \" + Components.Functions.componentToString( ).apply( comp ), ex );//TODO:GRZE: report error\n          }\n        }\n      }\n    }\n    return true;\n  }","id":36318,"modified_method":"@Override\n  public boolean start( ) throws Exception {\n    Component euca = Components.lookup( Eucalyptus.class );\n    for ( final Component comp : Components.list( ) ) {\n      LOG.info( \"start(): \" + comp );\n      EventRecord.here( ServiceDispatchBootstrapper.class, EventType.COMPONENT_INFO, comp.getName( ), comp.isAvailableLocally( ).toString( ) ).info( );\n      for ( final ServiceConfiguration s : comp.lookupServiceConfigurations( ) ) {\n        if ( !comp.getComponentId( ).hasDispatcher( ) ) {\n          continue;\n        } else if ( Bootstrap.isCloudController( ) ) {\n          try {\n            comp.enableTransition( s ).get( );\n            break;\n          } catch ( Throwable ex ) {\n            s.error( ex );\n            Exceptions.trace( \"start()/enable(): Starting service failed: \" + Components.Functions.componentToString( ).apply( comp ), ex );//TODO:GRZE: report error\n          }\n        }\n      }\n    }\n    return true;\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public boolean load( ) throws Exception {\n    /**\n     * TODO: ultimately remove this: it is legacy and enforces a one-to-one\n     * relationship between component impls\n     **/\n    for ( ComponentId c : ComponentIds.list( ) ) {\n      if ( c.hasDispatcher( ) && c.isAlwaysLocal( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          throw BootstrapException.throwFatal( \"Failed to lookup component which is alwaysLocal: \" + c.name( ), e );\n        }\n      } else if ( c.hasDispatcher( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          Exceptions.eat( \"Failed to lookup component which may have dispatcher references: \" + c.name( ), e );\n        }\n      }\n    }\n    for ( final Component comp : Components.list( ) ) {\n      LOG.info( \"load(): \" + comp );\n      if ( Bootstrap.isCloudController( ) && !( comp.getBuilder( ) instanceof DummyServiceBuilder ) ) {\n        for ( ServiceConfiguration config : comp.getBuilder( ).list( ) ) {\n          LOG.info( \"loadService(): \" + config );\n          comp.loadService( config );\n        }\n      } else if ( comp.hasLocalService( ) ) {\n        LOG.info( \"load(): \" + comp );\n        for ( final ServiceConfiguration s : comp.lookupServiceConfigurations( ) ) {\n          if ( s.isLocal( ) && comp.getComponentId( ).hasDispatcher( ) ) {\n            try {\n              comp.loadService( s ).get( );\n            } catch ( ServiceRegistrationException ex ) {\n              LOG.error( ex, ex );//TODO:GRZE: report error\n            } catch ( Throwable ex ) {\n              Exceptions.trace( \"load(): Building service failed: \" + Components.Functions.componentToString( ).apply( comp ), ex );\n            }\n          }\n        }\n      }\n    }\n    return true;\n  }","id":36319,"modified_method":"@Override\n  public boolean load( ) throws Exception {\n    /**\n     * TODO: ultimately remove this: it is legacy and enforces a one-to-one\n     * relationship between component impls\n     **/\n    for ( ComponentId c : ComponentIds.list( ) ) {\n      if ( c.hasDispatcher( ) && c.isAlwaysLocal( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          throw BootstrapException.throwFatal( \"Failed to lookup component which is alwaysLocal: \" + c.name( ), e );\n        }\n      } else if ( c.hasDispatcher( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          Exceptions.eat( \"Failed to lookup component which may have dispatcher references: \" + c.name( ), e );\n        }\n      }\n    }\n    for ( final Component comp : Components.list( ) ) {\n      LOG.info( \"load(): \" + comp );\n      if ( Bootstrap.isCloudController( ) && !( comp.getBuilder( ) instanceof DummyServiceBuilder ) ) {\n        for ( ServiceConfiguration config : comp.getBuilder( ).list( ) ) {\n          LOG.info( \"loadService(): \" + config );\n          try {\n            comp.loadService( config ).get( );\n          } catch ( ServiceRegistrationException ex ) {\n            config.error( ex );\n          } catch ( Throwable ex ) {\n            config.error( ex );\n          }\n        }\n      } else if ( comp.hasLocalService( ) ) {\n        LOG.info( \"load(): \" + comp );\n        final ServiceConfiguration s = comp.getLocalServiceConfiguration( );\n        if ( s.isLocal( ) && comp.getComponentId( ).hasDispatcher( ) ) {\n          try {\n            comp.loadService( s ).get( );\n          } catch ( ServiceRegistrationException ex ) {\n            s.error( ex );\n          } catch ( Throwable ex ) {\n            Exceptions.trace( \"load(): Building service failed: \" + Components.Functions.componentToString( ).apply( comp ), ex );\n            s.error( ex );\n          }\n        }\n      }\n    }\n    return true;\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"static final CheckedListenableFuture<ServiceConfiguration> startTransitionChain( final ServiceConfiguration config ) {\n    Callable<CheckedListenableFuture<ServiceConfiguration>> transition = null;\n    switch ( config.lookupStateMachine( ).getState( ) ) {\n      case NOTREADY:\n      case DISABLED:\n      case ENABLED:\n        break;\n      case LOADED:\n      case STOPPED:\n        transition = Automata.sequenceTransitions( config, Component.State.LOADED, Component.State.NOTREADY );\n        break;\n      case INITIALIZED:\n        transition = Automata.sequenceTransitions( config, Component.State.INITIALIZED, Component.State.LOADED, Component.State.NOTREADY );\n        break;\n      default:\n        throw new IllegalStateException( \"Failed to find transition for current component state: \" + config.lookupComponent( ).toString( ) );\n    }\n    CheckedListenableFuture<ServiceConfiguration> transitionResult = null;\n    try {\n      transitionResult = Threads.lookup( Empyrean.class ).submit( transition ).get( );\n    } catch ( InterruptedException ex ) {\n      LOG.error( ex, ex );\n      transitionResult = Futures.predestinedFailedFuture( ex );\n    } catch ( ExecutionException ex ) {\n      LOG.error( ex, ex );\n      transitionResult = Futures.predestinedFailedFuture( ex );\n    }\n    return transitionResult;\n  }","id":36320,"modified_method":"static final CheckedListenableFuture<ServiceConfiguration> startTransitionChain( final ServiceConfiguration config ) {\n    if ( !State.NOTREADY.equals( config.lookupState( ) ) && !State.DISABLED.equals( config.lookupState( ) ) ) {\n      CheckedListenableFuture<ServiceConfiguration> transitionResult = null;\n      try {\n        Callable<CheckedListenableFuture<ServiceConfiguration>> transition = Automata.sequenceTransitions( config, Component.State.PRIMORDIAL,\n                                                                                                           Component.State.INITIALIZED, Component.State.LOADED,\n                                                                                                           Component.State.NOTREADY );\n        \n        Future<CheckedListenableFuture<ServiceConfiguration>> result = Threads.lookup( Empyrean.class ).submit( transition );\n        transitionResult = result.get( );\n      } catch ( InterruptedException ex ) {\n        LOG.error( ex, ex );\n        transitionResult = Futures.predestinedFailedFuture( ex );\n      } catch ( ExecutionException ex ) {\n        LOG.error( ex.getCause( ), ex.getCause( ) );\n        transitionResult = Futures.predestinedFailedFuture( ex.getCause( ) );\n      }\n      return transitionResult;\n    } else {\n      return Futures.predestinedFuture( config );\n    }\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"static final CheckedListenableFuture<ServiceConfiguration> enableTransitionChain( final ServiceConfiguration config ) {\n    Callable<CheckedListenableFuture<ServiceConfiguration>> transition = null;\n    switch ( config.lookupStateMachine( ).getState( ) ) {\n      case ENABLED:\n        break;\n      case NOTREADY:\n      case DISABLED:\n        transition = Automata.sequenceTransitions( config, Component.State.DISABLED, Component.State.ENABLED );\n        break;\n      case LOADED:\n      case STOPPED:\n        transition = Automata.sequenceTransitions( config, Component.State.LOADED, Component.State.NOTREADY, Component.State.DISABLED,\n                                                                      Component.State.ENABLED );\n        break;\n      case INITIALIZED:\n        transition = Automata.sequenceTransitions( config, Component.State.INITIALIZED, Component.State.LOADED, Component.State.NOTREADY,\n                                                                      Component.State.DISABLED, Component.State.ENABLED );\n        break;\n      default:\n        throw new IllegalStateException( \"Failed to find transition for current component state: \" + config.lookupComponent( ).toString( ) );\n    }\n    CheckedListenableFuture<ServiceConfiguration> transitionResult = null;\n    try {\n      transitionResult = Threads.lookup( Empyrean.class ).submit( transition ).get( );\n    } catch ( InterruptedException ex ) {\n      LOG.error( ex, ex );\n      transitionResult = Futures.predestinedFailedFuture( ex );\n    } catch ( ExecutionException ex ) {\n      LOG.error( ex.getCause( ), ex.getCause( ) );\n      transitionResult = Futures.predestinedFailedFuture( ex.getCause( ) );\n    }\n    return transitionResult;\n  }","id":36321,"modified_method":"static final CheckedListenableFuture<ServiceConfiguration> enableTransitionChain( final ServiceConfiguration config ) {\n    if ( !State.ENABLED.equals( config.lookupState( ) ) ) {\n      CheckedListenableFuture<ServiceConfiguration> transitionResult = null;\n      try {\n        Callable<CheckedListenableFuture<ServiceConfiguration>> transition = Automata.sequenceTransitions( config, Component.State.PRIMORDIAL,\n                                                                                                           Component.State.INITIALIZED, Component.State.LOADED,\n                                                                                                           Component.State.NOTREADY,\n                                                                                                           Component.State.DISABLED, Component.State.ENABLED );\n        Future<CheckedListenableFuture<ServiceConfiguration>> result = Threads.lookup( Empyrean.class ).submit( transition );\n        transitionResult = result.get( );\n      } catch ( InterruptedException ex ) {\n        LOG.error( ex, ex );\n        transitionResult = Futures.predestinedFailedFuture( ex );\n      } catch ( ExecutionException ex ) {\n        LOG.error( ex.getCause( ), ex.getCause( ) );\n        transitionResult = Futures.predestinedFailedFuture( ex.getCause( ) );\n      }\n      return transitionResult;\n    } else {\n      return Futures.predestinedFuture( config );\n    }\n  }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n    public boolean processClass( Class candidate ) throws Throwable {\n      if ( Ats.from( candidate ).has( TypeMapper.class ) && Function.class.isAssignableFrom( candidate ) ) {\n        TypeMapper mapper = Ats.from( candidate ).get( TypeMapper.class );\n        Class[] types = mapper.value( );\n        //first try default @value\n        if ( !types[0].equals( Object.class ) && !types[1].equals( Object.class ) ) {\n          try {\n            registerMapper( types[0], types[1], ( Function ) candidate.newInstance( ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n        //try from= and to= in the annotation\n        if ( !mapper.from( ).equals( Object.class ) && !mapper.to( ).equals( Object.class ) ) {\n          try {\n            registerMapper( mapper.from( ), mapper.to( ), ( Function ) candidate.newInstance( ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n        //try generics\n        List<Class> generics = Lists.newArrayList( );\n        try {\n          generics.addAll( Classes.genericsToClasses( candidate.newInstance( ) ) );\n        } catch ( Exception ex ) {\n          LOG.error( ex, ex );\n        }\n        if ( generics.size( ) != 2 ) {\n          return false;\n        } else {\n          try {\n            registerMapper( generics.get( 0 ), generics.get( 1 ), ( Function ) candidate.newInstance( ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n      }\n      return false;\n    }","id":36322,"modified_method":"@Override\n    public boolean processClass( Class candidate ) throws Throwable {\n      if ( Ats.from( candidate ).has( TypeMapper.class ) && Function.class.isAssignableFrom( candidate ) ) {\n        TypeMapper mapper = Ats.from( candidate ).get( TypeMapper.class );\n        Class[] types = mapper.value( );\n        //first try default @value\n        if ( !types[0].equals( Object.class ) && !types[1].equals( Object.class ) ) {\n          try {\n            registerMapper( types[0], types[1], ( Function ) Classes.newInstance( candidate ).get( 0 ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n        //try from= and to= in the annotation\n        if ( !mapper.from( ).equals( Object.class ) && !mapper.to( ).equals( Object.class ) ) {\n          try {\n            registerMapper( mapper.from( ), mapper.to( ), ( Function ) Classes.newInstance( candidate ).get( 0 ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n        //try generics\n        List<Class> generics = Lists.newArrayList( );\n        try {\n          generics.addAll( Classes.genericsToClasses( Classes.newInstance( candidate ).get( 0 ) ) );\n        } catch ( Exception ex ) {\n          LOG.error( ex, ex );\n        }\n        if ( generics.size( ) != 2 ) {\n          return false;\n        } else {\n          try {\n            registerMapper( generics.get( 0 ), generics.get( 1 ), ( Function ) Classes.newInstance( candidate ).get( 0 ) );\n            return true;\n          } catch ( Exception ex1 ) {\n            LOG.error( ex1, ex1 );\n          }\n        }\n      }\n      return false;\n    }","commit_id":"965f83d4eba41d8e85452b74a750925905c4ce02","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private boolean setupCloudLocals( InetAddress addr ) {\n    if ( !Internets.testReachability( addr ) ) {\n      return false;\n    } else {\n      try {\n        for ( ComponentId compId : ComponentIds.list( ) ) {//TODO:GRZE:URGENT THIS LIES\n          if ( compId.isCloudLocal( ) ) {\n            try {\n              Component comp = Components.lookup( compId );\n              ServiceConfiguration config = comp.initRemoteService( addr );\n              comp.loadService( config );\n            } catch ( Exception ex ) {\n              LOG.error( ex, ex );\n            }\n          }\n        }\n        for ( Bootstrap.Stage stage : Bootstrap.Stage.values( ) ) {\n          stage.updateBootstrapDependencies( );\n        }\n      } catch ( RuntimeException ex ) {\n        LOG.error( ex, ex );\n        throw ex;\n      } finally {\n        this.currentView.set( this.currentView.getReference( ), false );\n      }\n      return true;\n    }\n  }","id":36323,"modified_method":"private boolean setupCloudLocals( InetAddress addr ) {\n    if ( !Internets.testReachability( addr ) ) {\n      return false;\n    } else {\n      try {\n        for ( ComponentId compId : ComponentIds.list( ) ) {//TODO:GRZE:URGENT THIS LIES\n          if ( compId.isCloudLocal( ) ) {\n            try {\n              Component comp = Components.lookup( compId );\n              ServiceConfiguration config = comp.initRemoteService( addr );\n              comp.loadService( config ).get( );\n            } catch ( Exception ex ) {\n              LOG.error( ex, ex );\n            }\n          }\n        }\n        for ( Bootstrap.Stage stage : Bootstrap.Stage.values( ) ) {\n          stage.updateBootstrapDependencies( );\n        }\n      } catch ( RuntimeException ex ) {\n        LOG.error( ex, ex );\n        throw ex;\n      } finally {\n        this.currentView.set( this.currentView.getReference( ), false );\n      }\n      return true;\n    }\n  }","commit_id":"9d682deb0a1689bdde62bd7e084f9025f9b60ee4","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public boolean load( ) throws Exception {\n    /**\n     * TODO: ultimately remove this: it is legacy and enforces a one-to-one\n     * relationship between component impls\n     **/\n    for ( ComponentId c : ComponentIds.list( ) ) {\n      if ( c.hasDispatcher( ) && c.isAlwaysLocal( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          throw BootstrapException.throwFatal( \"Failed to lookup component which is alwaysLocal: \" + c.name( ), e );\n        }\n      } else if ( c.hasDispatcher( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          Exceptions.eat( \"Failed to lookup component which may have dispatcher references: \" + c.name( ), e );\n        }\n      }\n    }\n    LOG.trace( \"Touching class: \" + ServiceDispatcher.class );\n    boolean failed = false;\n    Component euca = Components.lookup( Eucalyptus.class );\n    for ( Component comp : Components.list( ) ) {\n      EventRecord.here( ServiceVerifyBootstrapper.class, EventType.COMPONENT_INFO, comp.getName( ), comp.isAvailableLocally( ).toString( ) ).info( );\n      for ( ServiceConfiguration s : comp.lookupServiceConfigurations( ) ) {\n        if ( euca.isLocal( ) && euca.getComponentId( ).hasDispatcher( ) ) {\n          try {\n            comp.loadService( s );\n          } catch ( ServiceRegistrationException ex ) {\n            LOG.error( ex, ex );\n            failed = true;\n          } catch ( Throwable ex ) {\n            Exceptions.trace( \"load(): Building service failed: \" + Components.componentToString( ).apply( comp ), ex );\n          }\n        }\n      }\n    }\n    if ( failed ) {\n      Exceptions.trace( \"Failures occurred while attempting to load component services.  See the log files for more information.\" );\n    }\n    \n    return true;\n  }","id":36324,"modified_method":"@Override\n  public boolean load( ) throws Exception {\n    /**\n     * TODO: ultimately remove this: it is legacy and enforces a one-to-one\n     * relationship between component impls\n     **/\n    for ( ComponentId c : ComponentIds.list( ) ) {\n      if ( c.hasDispatcher( ) && c.isAlwaysLocal( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          throw BootstrapException.throwFatal( \"Failed to lookup component which is alwaysLocal: \" + c.name( ), e );\n        }\n      } else if ( c.hasDispatcher( ) ) {\n        try {\n          Component comp = Components.lookup( c );\n        } catch ( NoSuchElementException e ) {\n          Exceptions.eat( \"Failed to lookup component which may have dispatcher references: \" + c.name( ), e );\n        }\n      }\n    }\n    LOG.trace( \"Touching class: \" + ServiceDispatcher.class );\n    boolean failed = false;\n    Component euca = Components.lookup( Eucalyptus.class );\n    for ( Component comp : Components.list( ) ) {\n      EventRecord.here( ServiceVerifyBootstrapper.class, EventType.COMPONENT_INFO, comp.getName( ), comp.isAvailableLocally( ).toString( ) ).info( );\n      for ( ServiceConfiguration s : comp.lookupServiceConfigurations( ) ) {\n        if ( euca.isLocal( ) && euca.getComponentId( ).hasDispatcher( ) ) {\n          try {\n            comp.loadService( s ).get( );\n          } catch ( ServiceRegistrationException ex ) {\n            LOG.error( ex, ex );\n            failed = true;\n          } catch ( Throwable ex ) {\n            Exceptions.trace( \"load(): Building service failed: \" + Components.componentToString( ).apply( comp ), ex );\n          }\n        }\n      }\n    }\n    if ( failed ) {\n      Exceptions.trace( \"Failures occurred while attempting to load component services.  See the log files for more information.\" );\n    }\n    \n    return true;\n  }","commit_id":"48a8f2ef7b12341b1a4c310fa46d8d27f4ec633d","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        out.writeVLong(startTime);\n        out.writeString(documentType);\n        out.writeBytesReference(documentSource);\n    }","id":36325,"modified_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        out.writeString(documentType);\n        out.writeOptionalString(routing);\n        out.writeOptionalString(preference);\n        out.writeBytesReference(documentSource);\n        out.writeVLong(startTime);\n    }","commit_id":"2f7d1189b1453744003c87ebc878633421dfbcaa","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        super.readFrom(in);\n        startTime = in.readVLong();\n        documentType = in.readString();\n        documentUnsafe = false;\n        documentSource = in.readBytesReference();\n    }","id":36326,"modified_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        super.readFrom(in);\n        documentType = in.readString();\n        routing = in.readOptionalString();\n        preference = in.readOptionalString();\n        documentUnsafe = false;\n        documentSource = in.readBytesReference();\n        startTime = in.readVLong();\n    }","commit_id":"2f7d1189b1453744003c87ebc878633421dfbcaa","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        insertOrder = in.readVLong();\n        priority = Priority.readFrom(in);\n        source = in.readText();\n        timeInQueue = in.readVLong();\n        if (in.getVersion().onOrAfter(Version.V_1_3_0)) {\n            executing = in.readBoolean();\n        }\n    }","id":36327,"modified_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        insertOrder = in.readVLong();\n        priority = Priority.readFrom(in);\n        source = in.readText();\n        if (in.getVersion().onOrAfter(Version.V_1_4_0)) {\n            timeInQueue = in.readLong();\n        } else {\n            timeInQueue = in.readVLong();\n        }\n        if (in.getVersion().onOrAfter(Version.V_1_3_0)) {\n            executing = in.readBoolean();\n        }\n    }","commit_id":"cd8e02351b78099614b2f8feddb15fc5eef071b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(insertOrder);\n        Priority.writeTo(priority, out);\n        out.writeText(source);\n        out.writeVLong(timeInQueue);\n        if (out.getVersion().onOrAfter(Version.V_1_3_0)) {\n            out.writeBoolean(executing);\n        }\n    }","id":36328,"modified_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(insertOrder);\n        Priority.writeTo(priority, out);\n        out.writeText(source);\n        if (out.getVersion().onOrAfter(Version.V_1_4_0)) {\n            // timeInQueue is set to -1 when unknown and can be negative if time goes backwards\n            out.writeLong(timeInQueue);\n        } else {\n            out.writeVLong(timeInQueue);\n        }\n        if (out.getVersion().onOrAfter(Version.V_1_3_0)) {\n            out.writeBoolean(executing);\n        }\n    }","commit_id":"cd8e02351b78099614b2f8feddb15fc5eef071b8","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public MergeStats stats() {\n        MergeStats mergeStats = new MergeStats();\n        for (CustomConcurrentMergeScheduler scheduler : schedulers) {\n            mergeStats.add(scheduler.totalMerges(), scheduler.currentMerges(), scheduler.totalMergeTime());\n        }\n        return mergeStats;\n    }","id":36329,"modified_method":"@Override public MergeStats stats() {\n        MergeStats mergeStats = new MergeStats();\n        for (CustomConcurrentMergeScheduler scheduler : schedulers) {\n            mergeStats.add(scheduler.totalMerges(), scheduler.totalMergeTime(), scheduler.totalMergeNumDocs(), scheduler.totalMergeSizeInBytes(),\n                    scheduler.currentMerges(), scheduler.currentMergesNumDocs(), scheduler.currentMergesSizeInBytes());\n        }\n        return mergeStats;\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void add(long totalMerges, long currentMerges, long totalMergeTime) {\n        this.total += totalMerges;\n        this.current += currentMerges;\n        this.totalTimeInMillis += totalMergeTime;\n    }","id":36330,"modified_method":"public void add(long totalMerges, long totalMergeTime, long totalNumDocs, long totalSizeInBytes, long currentMerges, long currentNumDocs, long currentSizeInBytes) {\n        this.total += totalMerges;\n        this.totalTimeInMillis += totalMergeTime;\n        this.totalNumDocs += totalNumDocs;\n        this.totalSizeInBytes += totalSizeInBytes;\n        this.current += currentMerges;\n        this.currentNumDocs += currentNumDocs;\n        this.currentSizeInBytes += currentSizeInBytes;\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        total = in.readVLong();\n        current = in.readVLong();\n        totalTimeInMillis = in.readVLong();\n    }","id":36331,"modified_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        total = in.readVLong();\n        totalTimeInMillis = in.readVLong();\n        totalNumDocs = in.readVLong();\n        totalSizeInBytes = in.readVLong();\n        current = in.readVLong();\n        currentNumDocs = in.readVLong();\n        currentSizeInBytes = in.readVLong();\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void add(MergeStats mergeStats) {\n        if (mergeStats == null) {\n            return;\n        }\n        this.total += mergeStats.total;\n        this.current += mergeStats.current;\n        this.totalTimeInMillis += mergeStats.totalTimeInMillis;\n    }","id":36332,"modified_method":"public void add(MergeStats mergeStats) {\n        if (mergeStats == null) {\n            return;\n        }\n        this.total += mergeStats.total;\n        this.totalTimeInMillis += mergeStats.totalTimeInMillis;\n        this.totalNumDocs += mergeStats.totalNumDocs;\n        this.totalSizeInBytes += mergeStats.totalSizeInBytes;\n        this.current += mergeStats.current;\n        this.currentNumDocs += mergeStats.currentNumDocs;\n        this.currentSizeInBytes += mergeStats.currentSizeInBytes;\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(Fields.MERGES);\n        builder.field(Fields.CURRENT, current);\n        builder.field(Fields.TOTAL, total);\n        builder.field(Fields.TOTAL_TIME, totalTime().toString());\n        builder.field(Fields.TOTAL_TIME_IN_MILLIS, totalTimeInMillis);\n        builder.endObject();\n        return builder;\n    }","id":36333,"modified_method":"@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(Fields.MERGES);\n        builder.field(Fields.CURRENT, current);\n        builder.field(Fields.CURRENT_DOCS, currentNumDocs);\n        builder.field(Fields.CURRENT_SIZE, currentSize().toString());\n        builder.field(Fields.CURRENT_SIZE_IN_BYTES, currentSizeInBytes);\n        builder.field(Fields.TOTAL, total);\n        builder.field(Fields.TOTAL_TIME, totalTime().toString());\n        builder.field(Fields.TOTAL_TIME_IN_MILLIS, totalTimeInMillis);\n        builder.field(Fields.TOTAL_DOCS, totalNumDocs);\n        builder.field(Fields.TOTAL_SIZE, totalSize().toString());\n        builder.field(Fields.TOTAL_SIZE_IN_BYTES, totalSizeInBytes);\n        builder.endObject();\n        return builder;\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(total);\n        out.writeVLong(current);\n        out.writeVLong(totalTimeInMillis);\n    }","id":36334,"modified_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(total);\n        out.writeVLong(totalTimeInMillis);\n        out.writeVLong(totalNumDocs);\n        out.writeVLong(totalSizeInBytes);\n        out.writeVLong(current);\n        out.writeVLong(currentNumDocs);\n        out.writeVLong(currentSizeInBytes);\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public MergeStats stats() {\n        MergeStats mergeStats = new MergeStats();\n        for (CustomSerialMergeScheduler scheduler : schedulers) {\n            mergeStats.add(scheduler.totalMerges(), scheduler.currentMerges(), scheduler.totalMergeTime());\n        }\n        return mergeStats;\n    }","id":36335,"modified_method":"@Override public MergeStats stats() {\n        MergeStats mergeStats = new MergeStats();\n        for (CustomSerialMergeScheduler scheduler : schedulers) {\n            mergeStats.add(scheduler.totalMerges(), scheduler.totalMergeTime(), scheduler.totalMergeNumDocs(), scheduler.totalMergeSizeInBytes(),\n                    scheduler.currentMerges(), scheduler.currentMergesNumDocs(), scheduler.currentMergesSizeInBytes());\n        }\n        return mergeStats;\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doMerge(MergePolicy.OneMerge merge) throws IOException {\n        long time = System.currentTimeMillis();\n        currentMerges.inc();\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"merge [{}] starting...\", merge.info.name);\n        }\n        try {\n            super.doMerge(merge);\n        } finally {\n            currentMerges.dec();\n            long took = System.currentTimeMillis() - time;\n            totalMerges.inc(took);\n            if (took > 20000) { // if more than 20 seconds, DEBUG log it\n                logger.debug(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n            } else if (logger.isTraceEnabled()) {\n                logger.trace(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n            }\n        }\n    }","id":36336,"modified_method":"@Override protected void doMerge(MergePolicy.OneMerge merge) throws IOException {\n        int totalNumDocs = merge.totalNumDocs();\n        long totalSizeInBytes = merge.totalBytesSize();\n        long time = System.currentTimeMillis();\n        currentMerges.inc();\n        currentMergesNumDocs.inc(totalNumDocs);\n        currentMergesSizeInBytes.inc(totalSizeInBytes);\n        if (logger.isTraceEnabled()) {\n            logger.trace(\"merge [{}] starting...\", merge.info.name);\n        }\n        try {\n            super.doMerge(merge);\n        } finally {\n            long took = System.currentTimeMillis() - time;\n\n            currentMerges.dec();\n            currentMergesNumDocs.dec(totalNumDocs);\n            currentMergesSizeInBytes.dec(totalSizeInBytes);\n\n            totalMergesNumDocs.inc(totalNumDocs);\n            totalMergesSizeInBytes.inc(totalSizeInBytes);\n            totalMerges.inc(took);\n            if (took > 20000) { // if more than 20 seconds, DEBUG log it\n                logger.debug(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n            } else if (logger.isTraceEnabled()) {\n                logger.trace(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n            }\n        }\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Just do the merges in sequence. We do this\n     * \"synchronized\" so that even if the application is using\n     * multiple threads, only one merge may run at a time.\n     */\n    @Override\n    synchronized public void merge(IndexWriter writer) throws CorruptIndexException, IOException {\n        while (true) {\n            MergePolicy.OneMerge merge = writer.getNextMerge();\n            if (merge == null)\n                break;\n\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"merge [{}] starting...\", merge.info.name);\n            }\n\n            long time = System.currentTimeMillis();\n            currentMerges.inc();\n            try {\n                writer.merge(merge);\n            } finally {\n                currentMerges.dec();\n                long took = System.currentTimeMillis() - time;\n                totalMerges.inc(took);\n                if (took > 20000) { // if more than 20 seconds, DEBUG log it\n                    logger.debug(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n                } else if (logger.isTraceEnabled()) {\n                    logger.trace(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n                }\n            }\n        }\n    }","id":36337,"modified_method":"/**\n     * Just do the merges in sequence. We do this\n     * \"synchronized\" so that even if the application is using\n     * multiple threads, only one merge may run at a time.\n     */\n    @Override\n    synchronized public void merge(IndexWriter writer) throws CorruptIndexException, IOException {\n        while (true) {\n            MergePolicy.OneMerge merge = writer.getNextMerge();\n            if (merge == null)\n                break;\n\n            if (logger.isTraceEnabled()) {\n                logger.trace(\"merge [{}] starting...\", merge.info.name);\n            }\n\n            int totalNumDocs = merge.totalNumDocs();\n            long totalSizeInBytes = merge.totalBytesSize();\n            long time = System.currentTimeMillis();\n            currentMerges.inc();\n            currentMergesNumDocs.inc(totalNumDocs);\n            currentMergesSizeInBytes.inc(totalSizeInBytes);\n            try {\n                writer.merge(merge);\n            } finally {\n                long took = System.currentTimeMillis() - time;\n\n                currentMerges.dec();\n                currentMergesNumDocs.dec(totalNumDocs);\n                currentMergesSizeInBytes.dec(totalSizeInBytes);\n\n                totalMergesNumDocs.inc(totalNumDocs);\n                totalMergesSizeInBytes.inc(totalSizeInBytes);\n                totalMerges.inc(took);\n                if (took > 20000) { // if more than 20 seconds, DEBUG log it\n                    logger.debug(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n                } else if (logger.isTraceEnabled()) {\n                    logger.trace(\"merge [{}] done, took [{}]\", merge.info.name, TimeValue.timeValueMillis(took));\n                }\n            }\n        }\n    }","commit_id":"f4a36a2d87a7baa323b0f9d92cf9541f5f749199","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        percolateCount = in.readVLong();\n        percolateTimeInMillis = in.readVLong();\n        current = in.readVLong();\n        memorySizeInBytes = in.readVLong();\n        numQueries = in.readVLong();\n    }","id":36338,"modified_method":"@Override\n    public void readFrom(StreamInput in) throws IOException {\n        percolateCount = in.readVLong();\n        percolateTimeInMillis = in.readVLong();\n        current = in.readVLong();\n        if (in.getVersion().before(Version.V_1_1_0)) {\n            in.readVLong();\n        } else {\n            in.readLong();\n        }\n        numQueries = in.readVLong();\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(percolateCount);\n        out.writeVLong(percolateTimeInMillis);\n        out.writeVLong(current);\n        out.writeVLong(memorySizeInBytes);\n        out.writeVLong(numQueries);\n    }","id":36339,"modified_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeVLong(percolateCount);\n        out.writeVLong(percolateTimeInMillis);\n        out.writeVLong(current);\n        if (out.getVersion().before(Version.V_1_1_0)) {\n            out.writeVLong(0);\n        } else {\n            out.writeLong(-1);\n        }\n        out.writeVLong(numQueries);\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void add(PercolateStats percolate) {\n        if (percolate == null) {\n            return;\n        }\n\n        percolateCount += percolate.getCount();\n        percolateTimeInMillis += percolate.getTimeInMillis();\n        current += percolate.getCurrent();\n        memorySizeInBytes += percolate.getMemorySizeInBytes();\n        numQueries += percolate.getNumQueries();\n    }","id":36340,"modified_method":"public void add(PercolateStats percolate) {\n        if (percolate == null) {\n            return;\n        }\n\n        percolateCount += percolate.getCount();\n        percolateTimeInMillis += percolate.getTimeInMillis();\n        current += percolate.getCurrent();\n        numQueries += percolate.getNumQueries();\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testPercolateStatistics() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> register a query\");\n        client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().admin().indices().prepareRefresh(\"test\").execute().actionGet();\n\n        logger.info(\"--> First percolate request\");\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n\n        NumShards numShards = getNumShards(\"test\");\n\n        IndicesStatsResponse indicesResponse = client().admin().indices().prepareStats(\"test\").execute().actionGet();\n        assertThat(indicesResponse.getTotal().getPercolate().getCount(), equalTo((long) numShards.numPrimaries));\n        assertThat(indicesResponse.getTotal().getPercolate().getCurrent(), equalTo(0l));\n        assertThat(indicesResponse.getTotal().getPercolate().getNumQueries(), equalTo((long)numShards.dataCopies)); //number of copies\n        assertThat(indicesResponse.getTotal().getPercolate().getMemorySizeInBytes(), greaterThan(0l));\n\n        NodesStatsResponse nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        long percolateCount = 0;\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n        }\n        assertThat(percolateCount, equalTo((long) numShards.numPrimaries));\n\n        logger.info(\"--> Second percolate request\");\n        response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n        assertThat(response.getMatches(), arrayWithSize(1));\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n\n        indicesResponse = client().admin().indices().prepareStats().setPercolate(true).execute().actionGet();\n        assertThat(indicesResponse.getTotal().getPercolate().getCount(), equalTo((long) numShards.numPrimaries * 2));\n        assertThat(indicesResponse.getTotal().getPercolate().getCurrent(), equalTo(0l));\n        assertThat(indicesResponse.getTotal().getPercolate().getNumQueries(), equalTo((long)numShards.dataCopies)); //number of copies\n        assertThat(indicesResponse.getTotal().getPercolate().getMemorySizeInBytes(), greaterThan(0l));\n\n        percolateCount = 0;\n        nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n        }\n        assertThat(percolateCount, equalTo((long) numShards.numPrimaries *2));\n\n        // We might be faster than 1 ms, so run upto 1000 times until have spend 1ms or more on percolating\n        boolean moreThanOneMs = false;\n        int counter = 3; // We already ran two times.\n        do {\n            indicesResponse = client().admin().indices().prepareStats(\"test\").execute().actionGet();\n            if (indicesResponse.getTotal().getPercolate().getTimeInMillis() > 0) {\n                moreThanOneMs = true;\n                break;\n            }\n\n            logger.info(\"--> {}th percolate request\", counter);\n            response = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(response.getMatches(), arrayWithSize(1));\n            assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n        } while (++counter <= 1000);\n        assertTrue(\"Something is off, we should have spent at least 1ms on percolating...\", moreThanOneMs);\n\n        long percolateSumTime = 0;\n        nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n            percolateSumTime += nodeStats.getIndices().getPercolate().getTimeInMillis();\n        }\n        assertThat(percolateSumTime, greaterThan(0l));\n    }","id":36341,"modified_method":"@Test\n    public void testPercolateStatistics() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> register a query\");\n        client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().admin().indices().prepareRefresh(\"test\").execute().actionGet();\n\n        logger.info(\"--> First percolate request\");\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n\n        NumShards numShards = getNumShards(\"test\");\n\n        IndicesStatsResponse indicesResponse = client().admin().indices().prepareStats(\"test\").execute().actionGet();\n        assertThat(indicesResponse.getTotal().getPercolate().getCount(), equalTo((long) numShards.numPrimaries));\n        assertThat(indicesResponse.getTotal().getPercolate().getCurrent(), equalTo(0l));\n        assertThat(indicesResponse.getTotal().getPercolate().getNumQueries(), equalTo((long)numShards.dataCopies)); //number of copies\n        assertThat(indicesResponse.getTotal().getPercolate().getMemorySizeInBytes(), equalTo(-1l));\n\n        NodesStatsResponse nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        long percolateCount = 0;\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n        }\n        assertThat(percolateCount, equalTo((long) numShards.numPrimaries));\n\n        logger.info(\"--> Second percolate request\");\n        response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n        assertThat(response.getMatches(), arrayWithSize(1));\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n\n        indicesResponse = client().admin().indices().prepareStats().setPercolate(true).execute().actionGet();\n        assertThat(indicesResponse.getTotal().getPercolate().getCount(), equalTo((long) numShards.numPrimaries * 2));\n        assertThat(indicesResponse.getTotal().getPercolate().getCurrent(), equalTo(0l));\n        assertThat(indicesResponse.getTotal().getPercolate().getNumQueries(), equalTo((long)numShards.dataCopies)); //number of copies\n        assertThat(indicesResponse.getTotal().getPercolate().getMemorySizeInBytes(), equalTo(-1l));\n\n        percolateCount = 0;\n        nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n        }\n        assertThat(percolateCount, equalTo((long) numShards.numPrimaries *2));\n\n        // We might be faster than 1 ms, so run upto 1000 times until have spend 1ms or more on percolating\n        boolean moreThanOneMs = false;\n        int counter = 3; // We already ran two times.\n        do {\n            indicesResponse = client().admin().indices().prepareStats(\"test\").execute().actionGet();\n            if (indicesResponse.getTotal().getPercolate().getTimeInMillis() > 0) {\n                moreThanOneMs = true;\n                break;\n            }\n\n            logger.info(\"--> {}th percolate request\", counter);\n            response = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(response.getMatches(), arrayWithSize(1));\n            assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n        } while (++counter <= 1000);\n        assertTrue(\"Something is off, we should have spent at least 1ms on percolating...\", moreThanOneMs);\n\n        long percolateSumTime = 0;\n        nodesResponse = client().admin().cluster().prepareNodesStats().execute().actionGet();\n        for (NodeStats nodeStats : nodesResponse) {\n            percolateCount += nodeStats.getIndices().getPercolate().getCount();\n            percolateSumTime += nodeStats.getIndices().getPercolate().getTimeInMillis();\n        }\n        assertThat(percolateSumTime, greaterThan(0l));\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void removedQuery(HashedBytesRef id, Query query) {\n        numberOfQueries.dec();\n        memorySizeInBytes.dec(computeSizeInMemory(id, query));\n    }","id":36342,"modified_method":"public void removedQuery(HashedBytesRef id, Query query) {\n        numberOfQueries.dec();\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void addedQuery(HashedBytesRef id, Query previousQuery, Query newQuery) {\n        if (previousQuery != null) {\n            memorySizeInBytes.dec(computeSizeInMemory(id, previousQuery));\n        } else {\n            numberOfQueries.inc();\n        }\n        memorySizeInBytes.inc(computeSizeInMemory(id, newQuery));\n    }","id":36343,"modified_method":"public void addedQuery(HashedBytesRef id, Query previousQuery, Query newQuery) {\n        numberOfQueries.inc();\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * @return The current metrics\n     */\n    public PercolateStats stats() {\n        return new PercolateStats(percolateMetric.count(), TimeUnit.NANOSECONDS.toMillis(percolateMetric.sum()), currentMetric.count(), memorySizeInBytes.count(), numberOfQueries.count());\n    }","id":36344,"modified_method":"/**\n     * @return The current metrics\n     */\n    public PercolateStats stats() {\n        return new PercolateStats(percolateMetric.count(), TimeUnit.NANOSECONDS.toMillis(percolateMetric.sum()), currentMetric.count(), -1, numberOfQueries.count());\n    }","commit_id":"6f8f773f8c9f0d2edae7a9eb05409104daa9844a","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n  @SuppressWarnings({\"unchecked\"})\n  public void readExternal(final Element element) throws InvalidDataException {\n    final List<Element> modules = (List<Element>)element.getChildren(ELEMENT);\n    LOG.assertTrue(modules.size() <= 1);\n    if (modules.size() == 1) {\n      final Element module = modules.get(0);\n      final String moduleName = module.getAttributeValue(ATTRIBUTE);  //we are unable to set 'null' module from 'not null' one\n      if (moduleName != null && moduleName.length() > 0){\n        myModuleName = moduleName;\n      }\n    }\n  }","id":36345,"modified_method":"@Override\n  @SuppressWarnings({\"unchecked\"})\n  public void readExternal(@NotNull Element element) {\n    final List<Element> modules = element.getChildren(ELEMENT);\n    LOG.assertTrue(modules.size() <= 1);\n    if (modules.size() == 1) {\n      // we are unable to set 'null' module from 'not null' one\n      String moduleName = modules.get(0).getAttributeValue(ATTRIBUTE);\n      if (!StringUtil.isEmpty(moduleName)) {\n        myModuleName = moduleName;\n      }\n    }\n  }","commit_id":"d5fbcc7e163c24b6be01ca67f075004fc3948cb0","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void init() {\n    if (getModuleName().trim().length() > 0) return;\n    final Module[] modules = getModuleManager().getModules();\n    if (modules.length > 0){\n      setModule(modules[0]);\n    }\n  }","id":36346,"modified_method":"public void init() {\n    if (StringUtil.isEmptyOrSpaces(getModuleName())) {\n      Module[] modules = getModuleManager().getModules();\n      if (modules.length > 0) {\n        setModule(modules[0]);\n      }\n    }\n  }","commit_id":"d5fbcc7e163c24b6be01ca67f075004fc3948cb0","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void writeExternal(final Element parent) throws WriteExternalException {\n    final Element element = new Element(ELEMENT);\n    element.setAttribute(ATTRIBUTE, getModuleName());\n    parent.addContent(element);\n  }","id":36347,"modified_method":"@Override\n  public void writeExternal(@NotNull Element parent) {\n    parent.addContent(new Element(ELEMENT).setAttribute(ATTRIBUTE, getModuleName()));\n  }","commit_id":"d5fbcc7e163c24b6be01ca67f075004fc3948cb0","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void apply() throws ConfigurationException {\n    final CompilerProjectExtension compilerProjectExtension = CompilerProjectExtension.getInstance(myProject);\n\n    if (myProjectName != null && myProjectName.getText().trim().length() == 0) {\n      throw new ConfigurationException(\"Please, specify project name!\");\n    }\n\n    ApplicationManager.getApplication().runWriteAction(new Runnable() {\n      public void run() {\n        // set the output path first so that handlers of RootsChanged event sent after JDK is set\n        // would see the updated path\n        String canonicalPath = myProjectCompilerOutput.getText();\n        if (canonicalPath != null && canonicalPath.length() > 0) {\n          try {\n            canonicalPath = FileUtil.resolveShortWindowsName(canonicalPath);\n          }\n          catch (IOException e) {\n            //file doesn't exist yet\n          }\n          canonicalPath = FileUtil.toSystemIndependentName(canonicalPath);\n          compilerProjectExtension.setCompilerOutputUrl(VfsUtil.pathToUrl(canonicalPath));\n        }\n        else {\n          compilerProjectExtension.setCompilerOutputPointer(null);\n        }\n\n        final LanguageLevel newLevel = (LanguageLevel)myLanguageLevelCombo.getSelectedItem();\n        LanguageLevelProjectExtension.getInstance(myProject).setLanguageLevel(newLevel);\n        myProjectJdkConfigurable.apply();\n\n        if (myProjectName != null) {\n          ((ProjectEx)myProject).setProjectName(myProjectName.getText().trim());\n          if (myDetailsComponent != null) myDetailsComponent.setText(getBannerSlogan());\n        }\n      }\n    });\n  }","id":36348,"modified_method":"public void apply() throws ConfigurationException {\n    final CompilerProjectExtension compilerProjectExtension = CompilerProjectExtension.getInstance(myProject);\n    assert compilerProjectExtension != null : myProject;\n\n    if (myProjectName != null && StringUtil.isEmptyOrSpaces(myProjectName.getText())) {\n      throw new ConfigurationException(\"Please, specify project name!\");\n    }\n\n    ApplicationManager.getApplication().runWriteAction(new Runnable() {\n      public void run() {\n        // set the output path first so that handlers of RootsChanged event sent after JDK is set\n        // would see the updated path\n        String canonicalPath = myProjectCompilerOutput.getText();\n        if (canonicalPath != null && canonicalPath.length() > 0) {\n          try {\n            canonicalPath = FileUtil.resolveShortWindowsName(canonicalPath);\n          }\n          catch (IOException e) {\n            //file doesn't exist yet\n          }\n          canonicalPath = FileUtil.toSystemIndependentName(canonicalPath);\n          compilerProjectExtension.setCompilerOutputUrl(VfsUtil.pathToUrl(canonicalPath));\n        }\n        else {\n          compilerProjectExtension.setCompilerOutputPointer(null);\n        }\n\n        final LanguageLevel newLevel = (LanguageLevel)myLanguageLevelCombo.getSelectedItem();\n        LanguageLevelProjectExtension.getInstance(myProject).setLanguageLevel(newLevel);\n        myProjectJdkConfigurable.apply();\n\n        if (myProjectName != null) {\n          ((ProjectEx)myProject).setProjectName(myProjectName.getText().trim());\n          if (myDetailsComponent != null) myDetailsComponent.setText(getBannerSlogan());\n        }\n      }\n    });\n  }","commit_id":"f03dface4aceb423412ae2b2d6d195094d0df359","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void dispose() {\n    if (disposed) {\n      throw new MyException(\"Punching the dead horse.\\nurl=\"+toString(), getUserData(CREATE_TRACE), getUserData(KILL_TRACE));\n    }\n    if (--useCount == 0) {\n      if (TRACE_CREATION) {\n        putUserData(KILL_TRACE, new Throwable());\n      }\n      String url = getUrlNoUpdate();\n      disposed = true;\n      ((VirtualFilePointerManagerImpl)VirtualFilePointerManager.getInstance()).clearPointerCaches(url, myListener);\n    }\n  }","id":36349,"modified_method":"@Override\n  public void dispose() {\n    if (disposed) {\n      throw new MyException(\"Punching the dead horse.\\nURL=\" + toString(), getUserData(CREATE_TRACE), getUserData(KILL_TRACE));\n    }\n    if (--useCount == 0) {\n      if (TRACE_CREATION) {\n        putUserData(KILL_TRACE, new Throwable());\n      }\n      String url = getUrlNoUpdate();\n      disposed = true;\n      ((VirtualFilePointerManagerImpl)VirtualFilePointerManager.getInstance()).clearPointerCaches(url, myListener);\n    }\n  }","commit_id":"f03dface4aceb423412ae2b2d6d195094d0df359","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public Object deserialize(Object o, @NotNull Object... nodes) {\n    Collection result;\n\n    if (getTagName(o) != null) {\n      assert nodes.length == 1;\n      Element e = (Element)nodes[0];\n\n      result = createCollection(e.getName());\n      final Content[] childElements = JDOMUtil.getContent(e);\n      for (final Content n : childElements) {\n        if (XmlSerializerImpl.isIgnoredNode(n)) continue;\n        final Binding elementBinding = getElementBinding(n);\n        Object v = elementBinding.deserialize(o, n);\n        //noinspection unchecked\n        result.add(v);\n      }\n    }\n    else {\n      result = new ArrayList();\n      for (Object node : nodes) {\n        if (XmlSerializerImpl.isIgnoredNode(node)) continue;\n        final Binding elementBinding = getElementBinding(node);\n        Object v = elementBinding.deserialize(o, node);\n        //noinspection unchecked\n        result.add(v);\n      }\n    }\n\n\n    return processResult(result, o);\n  }","id":36350,"modified_method":"@Override\n  public Object deserialize(Object o, @NotNull Object... nodes) {\n    Collection result;\n    if (getTagName(o) != null) {\n      assert nodes.length == 1;\n      Element e = (Element)nodes[0];\n      result = createCollection(e.getName());\n      List<Content> content = e.getContent();\n      //noinspection ForLoopReplaceableByForEach\n      for (int i = 0, size = content.size(); i < size; i++) {\n        Content child = content.get(i);\n        if (!XmlSerializerImpl.isIgnoredNode(child)) {\n          //noinspection unchecked\n          result.add(getElementBinding(child).deserialize(o, child));\n        }\n      }\n    }\n    else {\n      result = new SmartList();\n      for (Object node : nodes) {\n        if (!XmlSerializerImpl.isIgnoredNode(node)) {\n          //noinspection unchecked\n          result.add(getElementBinding(node).deserialize(o, node));\n        }\n      }\n    }\n    return processResult(result, o);\n  }","commit_id":"23393bd8e00a13565743bdcadf33eb0832ef6871","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  @SuppressWarnings({\"unchecked\"})\n  public static <T> T deserialize(Element element, Class<T> aClass) throws XmlSerializationException {\n    try {\n      return (T)XmlSerializerImpl.getBinding(aClass).deserialize(null, element);\n    }\n    catch (XmlSerializationException e) {\n      throw e;\n    }\n    catch (Exception e) {\n      throw new XmlSerializationException(e);\n    }\n  }","id":36351,"modified_method":"@Nullable\n  @SuppressWarnings({\"unchecked\"})\n  public static <T> T deserialize(Element element, Class<T> aClass) throws XmlSerializationException {\n    try {\n      return (T)XmlSerializerImpl.getBinding(aClass).deserialize(null, element);\n    }\n    catch (XmlSerializationException e) {\n      throw e;\n    }\n    catch (Exception e) {\n      throw new XmlSerializationException(\"Cannot deserialize class \" + aClass.getName(), e);\n    }\n  }","commit_id":"23393bd8e00a13565743bdcadf33eb0832ef6871","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean isIgnoredNode(final Object child) {\n    if (child instanceof Text && ((Text)child).getValue().trim().isEmpty()) {\n      return true;\n    }\n    if (child instanceof Comment) {\n      return true;\n    }\n    if (child instanceof Attribute) {\n      Attribute attr = (Attribute)child;\n      final String namespaceURI = attr.getNamespaceURI();\n      if (namespaceURI != null && !namespaceURI.isEmpty()) return true;\n    }\n\n    return false;\n  }","id":36352,"modified_method":"public static boolean isIgnoredNode(final Object child) {\n    if (child instanceof Text && StringUtil.isEmptyOrSpaces(((Text)child).getValue())) {\n      return true;\n    }\n    if (child instanceof Comment) {\n      return true;\n    }\n    if (child instanceof Attribute) {\n      if (!StringUtil.isEmpty(((Attribute)child).getNamespaceURI())) {\n        return true;\n      }\n    }\n    return false;\n  }","commit_id":"23393bd8e00a13565743bdcadf33eb0832ef6871","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n     * @see org.apache.maven.reporting.AbstractMavenReport#executeReport(java.util.Locale)\n     */\n    protected void executeReport( Locale locale )\n        throws MavenReportException\n    {\n        ArtifactHandler artifactHandler = project.getArtifact().getArtifactHandler();\n        if ( !\"java\".equals( artifactHandler.getLanguage() ) )\n        {\n            getLog().info( \"Not executing Javadoc as the project is not a Java classpath-capable package\" );\n            return;\n        }\n\n        Model model = getProject().getModel();\n\n        StringBuffer options = new StringBuffer();\n        StringBuffer classpath = new StringBuffer();\n\n        if ( !StringUtils.isEmpty( this.locale ) )\n        {\n            options.append( \"-locale \" );\n            options.append( quotedArgument( this.locale ) );\n            options.append( \" \" );\n        }\n\n        try\n        {\n            for ( Iterator i = getProject().getCompileClasspathElements().iterator(); i.hasNext(); )\n            {\n                classpath.append( (String) i.next() );\n\n                if ( i.hasNext() )\n                {\n                    classpath.append( PATH_SEPARATOR );\n                }\n            }\n        }\n        catch ( DependencyResolutionRequiredException e )\n        {\n            throw new MavenReportException( \"Error in plugin descriptor - compile dependencies were not resolved\", e );\n        }\n\n        if ( classpath.length() > 0 )\n        {\n            options.append( \"-classpath \" );\n            options.append( quotedPathArgument( classpath.toString() ) );\n        }\n\n        char FILE_SEPARATOR = System.getProperty( \"file.separator\" ).charAt( 0 );\n        String[] excludePackages = {};\n        if ( excludePackageNames != null )\n        {\n            excludePackages = excludePackageNames.split( \"[ ,:;]\" );\n        }\n        for ( int i = 0; i < excludePackages.length; i++ )\n        {\n            excludePackages[i] = excludePackages[i].replace( '.', FILE_SEPARATOR );\n        }\n\n        StringBuffer sourcePath = new StringBuffer();\n        StringBuffer files = new StringBuffer();\n        for ( Iterator i = getProject().getCompileSourceRoots().iterator(); i.hasNext(); )\n        {\n            String sourceDirectory = (String) i.next();\n            String[] fileList = FileUtils.getFilesFromExtension( sourceDirectory, new String[] { \"java\" } );\n            if ( fileList != null && fileList.length != 0 )\n            {\n                for ( int j = 0; j < fileList.length; j++ )\n                {\n                    boolean include = true;\n                    for ( int k = 0; k < excludePackages.length && include; k++ )\n                    {\n                        if ( fileList[j].startsWith( sourceDirectory + FILE_SEPARATOR + excludePackages[k] ) )\n                        {\n                            include = false;\n                        }\n                    }\n                    if ( include )\n                    {\n                        files.append( quotedPathArgument( fileList[j] ) );\n                        files.append( \"\\n\" );\n                    }\n                }\n            }\n\n            sourcePath.append( sourceDirectory );\n\n            if ( i.hasNext() )\n            {\n                sourcePath.append( PATH_SEPARATOR );\n            }\n        }\n\n        if ( files.length() == 0 )\n        {\n            return;\n        }\n\n        File javadocDirectory = getReportOutputDirectory();\n\n        if ( !javadocDirectory.getAbsolutePath().equals( getOutputDirectory() ) )\n        {\n            // we're in site-embedded report mode, so Doxia has set the\n            // reportOutputDirectory to the basedir of the site.\n            // Append 'apidocs'.\n            javadocDirectory = new File( javadocDirectory, \"apidocs\" );\n        }\n        javadocDirectory.mkdirs();\n\n        File file = new File( javadocDirectory, \"files\" );\n        file.deleteOnExit();\n        try\n        {\n            FileUtils.fileWrite( file.getAbsolutePath(), files.toString() );\n        }\n        catch ( IOException e )\n        {\n            throw new MavenReportException( \"Unable to write temporary file for command execution\", e );\n        }\n\n        try\n        {\n            // Copy default style sheet\n            copyDefaultStylesheet( javadocDirectory );\n        }\n        catch ( IOException e )\n        {\n            throw new MavenReportException( \"Unable to copy default stylesheet\", e );\n        }\n\n        Commandline cmd = new Commandline();\n\n        if ( !StringUtils.isEmpty( maxmemory ) )\n        {\n            // Allow '128' or '128m'\n            if ( NumberUtils.isDigits( maxmemory ) )\n            {\n                cmd.createArgument().setValue( \"-J-Xmx\" + maxmemory + \"m\" );\n            }\n            else\n            {\n                if ( ( NumberUtils.isDigits( maxmemory.substring( 0, maxmemory.length() - 1 ) ) )\n                    && ( maxmemory.toLowerCase().endsWith( \"m\" ) ) )\n                {\n                    cmd.createArgument().setValue( \"-J-Xmx\" + maxmemory );\n                }\n                else\n                {\n                    getLog().error( \"The maxmemory '\" + maxmemory + \"' is not a valid number. Ignore this option.\" );\n                }\n            }\n        }\n\n        if ( !StringUtils.isEmpty( minmemory ) )\n        {\n            // Allow '128' or '128m'\n            if ( NumberUtils.isDigits( minmemory ) )\n            {\n                cmd.createArgument().setValue( \"-J-Xms\" + minmemory + \"m\" );\n            }\n            else\n            {\n                if ( ( NumberUtils.isDigits( minmemory.substring( 0, minmemory.length() - 1 ) ) )\n                    && ( minmemory.toLowerCase().endsWith( \"m\" ) ) )\n                {\n                    cmd.createArgument().setValue( \"-J-Xms\" + minmemory );\n                }\n                else\n                {\n                    getLog().error( \"The minmemory '\" + minmemory + \"' is not a valid number. Ignore this option.\" );\n                }\n            }\n        }\n\n        List arguments = new ArrayList();\n\n        cmd.setWorkingDirectory( javadocDirectory.getAbsolutePath() );\n        cmd.setExecutable( getJavadocPath() );\n\n        // General javadoc arguments\n        addArgIf( arguments, breakiterator, \"-breakiterator\", 1.4f );\n        if ( !StringUtils.isEmpty( doclet ) )\n        {\n            addArgIfNotEmpty( arguments, \"-doclet\", quotedArgument( doclet ) );\n\n            if ( docletArtifact != null ) {\n                Artifact artifact = factory.createArtifact( docletArtifact.getGroupId(),\n                    docletArtifact.getArtifactId(), docletArtifact.getVersion(), \"compile\", \"jar\" );\n                try {\n                    resolver.resolve( artifact, remoteRepositories, localRepository );\n                    docletPath = artifact.getFile().getAbsolutePath();\n                } catch ( ArtifactResolutionException e ) {\n                    throw new MavenReportException( \"Unable to resolve artifact.\", e );\n                } catch (ArtifactNotFoundException e) {\n                    throw new MavenReportException( \"Unable to find artifact.\", e );\n                }\n            }\n\n            addArgIfNotEmpty( arguments, \"-docletpath\", quotedPathArgument( docletPath ) );\n        }\n        addArgIfNotEmpty( arguments, \"-encoding\", quotedArgument( encoding ) );\n        addArgIfNotEmpty( arguments, \"-extdirs\", quotedPathArgument( extdirs ) );\n\n        if ( old && SystemUtils.isJavaVersionAtLeast( 1.4f ) )\n        {\n            getLog().warn( \"Javadoc 1.4 doesn't support the -1.1 switch anymore. Ignore this option.\" );\n        }\n        else\n        {\n            addArgIf( arguments, old, \"-1.1\" );\n        }\n\n        final int LEVEL_PUBLIC = 1;\n        final int LEVEL_PROTECTED = 2;\n        final int LEVEL_PACKAGE = 3;\n        final int LEVEL_PRIVATE = 4;\n        int accessLevel = 0;\n        if ( \"public\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PUBLIC;\n        }\n        else if ( \"protected\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PROTECTED;\n        }\n        else if ( \"package\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PACKAGE;\n        }\n        else if ( \"private\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PRIVATE;\n        }\n        else\n        {\n            getLog().error( \"Unrecognized access level to show '\" + show + \"'. Defaulting to protected.\" );\n            accessLevel = LEVEL_PROTECTED;\n        }\n\n        addArgIfNotEmpty( arguments, \"-overview\", quotedPathArgument( overview ) );\n        addArgIf( arguments, accessLevel == LEVEL_PUBLIC, \"-public\" );\n        addArgIf( arguments, accessLevel == LEVEL_PROTECTED, \"-protected\" );\n        addArgIf( arguments, accessLevel == LEVEL_PACKAGE, \"-package\" );\n        addArgIf( arguments, accessLevel == LEVEL_PRIVATE, \"-private\" );\n        addArgIf( arguments, quiet, \"-quiet\", 1.4f );\n        addArgIfNotEmpty( arguments, \"-source\", quotedArgument( source ), 1.4f );\n        addArgIf( arguments, verbose, \"-verbose\" );\n        addArgIfNotEmpty( arguments, null, additionalparam );\n        addArgIfNotEmpty( arguments, \"-sourcepath\", quotedPathArgument( sourcePath.toString() ) );\n\n        // javadoc arguments for default doclet\n        if ( StringUtils.isEmpty( doclet ) )\n        {\n            int actualYear = Calendar.getInstance().get( Calendar.YEAR );\n            String year = String.valueOf( actualYear );\n\n            bottom = StringUtils.replace( bottom, \"{currentYear}\", year );\n\n            if ( model != null && model.getInceptionYear() != null )\n            {\n                if ( model.getInceptionYear().equals( year ) )\n                {\n                    bottom = StringUtils.replace( bottom, \"{inceptionYear}-\", \"\" );\n                }\n                else\n                {\n                    bottom = StringUtils.replace( bottom, \"{inceptionYear}\", model.getInceptionYear() );\n                }\n            }\n\n            if ( StringUtils.isEmpty( stylesheetfile ) )\n            {\n                stylesheetfile = javadocDirectory + File.separator + DEFAULT_CSS_NAME;\n            }\n            // End Specify default values\n\n            addArgIf( arguments, author, \"-author\" );\n            addArgIfNotEmpty( arguments, \"-bottom\", quotedArgument( bottom ) );\n            addArgIf( arguments, breakiterator, \"-breakiterator\", 1.4f );\n            addArgIfNotEmpty( arguments, \"-charset\", quotedArgument( charset ) );\n            addArgIfNotEmpty( arguments, \"-d\", quotedPathArgument( javadocDirectory.toString() ) );\n            addArgIf( arguments, docfilessubdirs, \"-docfilessubdirs\", 1.4f );\n            addArgIfNotEmpty( arguments, \"-docencoding\", quotedArgument( docencoding ) );\n            addArgIfNotEmpty( arguments, \"-doctitle\", quotedArgument( doctitle ) );\n            addArgIfNotEmpty( arguments, \"-excludedocfilessubdir\", quotedPathArgument( excludedocfilessubdir ), 1.4f );\n            addArgIfNotEmpty( arguments, \"-footer\", quotedArgument( footer ) );\n            for ( int i = 0; i < groups.length; i++ )\n            {\n                if ( ( groups[i] == null ) || ( StringUtils.isEmpty( groups[i].getTitle() ) )\n                    || ( StringUtils.isEmpty( groups[i].getPackages() ) ) )\n                {\n                    getLog().info( \"A group option is empty. Ignore this option.\" );\n                    continue;\n                }\n                addArgIfNotEmpty( arguments, \"-group\", quotedArgument( groups[i].getTitle() ) + \" \"\n                    + quotedArgument( groups[i].getPackages() ), true );\n            }\n            addArgIfNotEmpty( arguments, \"-header\", quotedArgument( header ) );\n            addArgIfNotEmpty( arguments, \"-helpfile\", quotedPathArgument( helpfile ) );\n\n            if ( !isOffline )\n            {\n                addLinkArguments( arguments );\n                addLinkofflineArguments( arguments );\n                addArgIf( arguments, linksource, \"-linksource\", 1.4f );\n            }\n\n            addArgIf( arguments, nodeprecated, \"-nodeprecated\" );\n            addArgIf( arguments, nodeprecatedlist, \"-nodeprecatedlist\" );\n            addArgIf( arguments, nocomment, \"-nocomment\", 1.4f );\n            addArgIf( arguments, nohelp, \"-nohelp\" );\n            addArgIf( arguments, noindex, \"-noindex\" );\n            addArgIf( arguments, nonavbar, \"-nonavbar\" );\n            addArgIfNotEmpty( arguments, \"-noqualifier\", quotedArgument( noqualifier ), 1.4f );\n            addArgIf( arguments, nosince, \"-nosince\" );\n            addArgIf( arguments, notree, \"-notree\" );\n            addArgIf( arguments, serialwarn, \"-serialwarn\" );\n            addArgIf( arguments, splitindex, \"-splitindex\" );\n            addArgIfNotEmpty( arguments, \"-stylesheetfile\", quotedPathArgument( stylesheetfile ) );\n\n            addArgIfNotEmpty( arguments, \"-taglet\", quotedArgument( taglet ), 1.4f );\n            addArgIfNotEmpty( arguments, \"-tagletpath\", quotedPathArgument( tagletpath ), 1.4f );\n\n            for ( int i = 0; i < tags.length; i++ )\n            {\n                if ( ( tags[i] == null ) || ( StringUtils.isEmpty( tags[i].getName() ) )\n                    || ( StringUtils.isEmpty( tags[i].getPlacement() ) ) )\n                {\n                    getLog().info( \"A tag option is empty. Ignore this option.\" );\n                    continue;\n                }\n                String value = \"\\\"\" + tags[i].getName() + \":\" + tags[i].getPlacement();\n                if ( !StringUtils.isEmpty( tags[i].getHead() ) )\n                {\n                    value += \":\" + quotedArgument( tags[i].getHead() );\n                }\n                value+=\"\\\"\";\n                addArgIfNotEmpty( arguments, \"-tag\", value, 1.4f, false );\n            }\n\n            addArgIf( arguments, use, \"-use\" );\n            addArgIf( arguments, version, \"-version\" );\n            addArgIfNotEmpty( arguments, \"-windowtitle\", quotedArgument( windowtitle ) );\n        }\n\n        if ( options.length() > 0 )\n        {\n            File optionsFile = new File( javadocDirectory, \"options\" );\n            for ( Iterator it = arguments.iterator(); it.hasNext(); )\n            {\n                options.append( \" \" );\n                options.append( (String) it.next() );\n            }\n            try\n            {\n                FileUtils.fileWrite( optionsFile.getAbsolutePath(), options.toString() );\n            }\n            catch ( IOException e )\n            {\n                throw new MavenReportException( \"Unable to write temporary file for command execution\", e );\n            }\n            cmd.createArgument().setValue( \"@options\" );\n            if ( !getLog().isDebugEnabled() )\n            {\n                optionsFile.deleteOnExit();\n            }\n        }\n\n        cmd.createArgument().setValue( \"@files\" );\n\n        getLog().debug( Commandline.toString( cmd.getCommandline() ) );\n\n        CommandLineUtils.StringStreamConsumer err = new CommandLineUtils.StringStreamConsumer();\n        try\n        {\n            int exitCode = CommandLineUtils.executeCommandLine( cmd, new DefaultConsumer(), err );\n\n            if ( exitCode != 0 )\n            {\n                throw new MavenReportException( \"Exit code: \" + exitCode + \" - \" + err.getOutput() );\n            }\n        }\n        catch ( CommandLineException e )\n        {\n            throw new MavenReportException( \"Unable to execute javadoc command\", e );\n        }\n    }","id":36353,"modified_method":"/**\n     * @see org.apache.maven.reporting.AbstractMavenReport#executeReport(java.util.Locale)\n     */\n    protected void executeReport( Locale locale )\n        throws MavenReportException\n    {\n        ArtifactHandler artifactHandler = project.getArtifact().getArtifactHandler();\n        if ( !\"java\".equals( artifactHandler.getLanguage() ) )\n        {\n            getLog().info( \"Not executing Javadoc as the project is not a Java classpath-capable package\" );\n            return;\n        }\n\n        Model model = getProject().getModel();\n\n        StringBuffer options = new StringBuffer();\n        StringBuffer classpath = new StringBuffer();\n\n        if ( !StringUtils.isEmpty( this.locale ) )\n        {\n            options.append( \"-locale \" );\n            options.append( quotedArgument( this.locale ) );\n            options.append( \" \" );\n        }\n\n        try\n        {\n            for ( Iterator i = getProject().getCompileClasspathElements().iterator(); i.hasNext(); )\n            {\n                classpath.append( (String) i.next() );\n\n                if ( i.hasNext() )\n                {\n                    classpath.append( PATH_SEPARATOR );\n                }\n            }\n        }\n        catch ( DependencyResolutionRequiredException e )\n        {\n            throw new MavenReportException( \"Error in plugin descriptor - compile dependencies were not resolved\", e );\n        }\n\n        if ( classpath.length() > 0 )\n        {\n            options.append( \"-classpath \" );\n            options.append( quotedPathArgument( classpath.toString() ) );\n        }\n\n        char FILE_SEPARATOR = System.getProperty( \"file.separator\" ).charAt( 0 );\n        String[] excludePackages = {};\n        if ( excludePackageNames != null )\n        {\n            excludePackages = excludePackageNames.split( \"[ ,:;]\" );\n        }\n        for ( int i = 0; i < excludePackages.length; i++ )\n        {\n            excludePackages[i] = excludePackages[i].replace( '.', FILE_SEPARATOR );\n        }\n\n        StringBuffer sourcePath = new StringBuffer();\n        StringBuffer files = new StringBuffer();\n        for ( Iterator i = getProject().getCompileSourceRoots().iterator(); i.hasNext(); )\n        {\n            String sourceDirectory = (String) i.next();\n            String[] fileList = FileUtils.getFilesFromExtension( sourceDirectory, new String[] { \"java\" } );\n            if ( fileList != null && fileList.length != 0 )\n            {\n                for ( int j = 0; j < fileList.length; j++ )\n                {\n                    boolean include = true;\n                    for ( int k = 0; k < excludePackages.length && include; k++ )\n                    {\n                        if ( fileList[j].startsWith( sourceDirectory + FILE_SEPARATOR + excludePackages[k] ) )\n                        {\n                            include = false;\n                        }\n                    }\n                    if ( include )\n                    {\n                        files.append( quotedPathArgument( fileList[j] ) );\n                        files.append( \"\\n\" );\n                    }\n                }\n            }\n\n            sourcePath.append( sourceDirectory );\n\n            if ( i.hasNext() )\n            {\n                sourcePath.append( PATH_SEPARATOR );\n            }\n        }\n\n        if ( files.length() == 0 )\n        {\n            return;\n        }\n                \n        File javadocDirectory = new File( getOutputDirectory() );\n        javadocDirectory.mkdirs();\n\n        File file = new File( javadocDirectory, \"files\" );\n        file.deleteOnExit();\n        try\n        {\n            FileUtils.fileWrite( file.getAbsolutePath(), files.toString() );\n        }\n        catch ( IOException e )\n        {\n            throw new MavenReportException( \"Unable to write temporary file for command execution\", e );\n        }\n\n        try\n        {\n            // Copy default style sheet\n            copyDefaultStylesheet( javadocDirectory );\n        }\n        catch ( IOException e )\n        {\n            throw new MavenReportException( \"Unable to copy default stylesheet\", e );\n        }\n\n        Commandline cmd = new Commandline();\n\n        if ( !StringUtils.isEmpty( maxmemory ) )\n        {\n            // Allow '128' or '128m'\n            if ( NumberUtils.isDigits( maxmemory ) )\n            {\n                cmd.createArgument().setValue( \"-J-Xmx\" + maxmemory + \"m\" );\n            }\n            else\n            {\n                if ( ( NumberUtils.isDigits( maxmemory.substring( 0, maxmemory.length() - 1 ) ) )\n                    && ( maxmemory.toLowerCase().endsWith( \"m\" ) ) )\n                {\n                    cmd.createArgument().setValue( \"-J-Xmx\" + maxmemory );\n                }\n                else\n                {\n                    getLog().error( \"The maxmemory '\" + maxmemory + \"' is not a valid number. Ignore this option.\" );\n                }\n            }\n        }\n\n        if ( !StringUtils.isEmpty( minmemory ) )\n        {\n            // Allow '128' or '128m'\n            if ( NumberUtils.isDigits( minmemory ) )\n            {\n                cmd.createArgument().setValue( \"-J-Xms\" + minmemory + \"m\" );\n            }\n            else\n            {\n                if ( ( NumberUtils.isDigits( minmemory.substring( 0, minmemory.length() - 1 ) ) )\n                    && ( minmemory.toLowerCase().endsWith( \"m\" ) ) )\n                {\n                    cmd.createArgument().setValue( \"-J-Xms\" + minmemory );\n                }\n                else\n                {\n                    getLog().error( \"The minmemory '\" + minmemory + \"' is not a valid number. Ignore this option.\" );\n                }\n            }\n        }\n\n        List arguments = new ArrayList();\n\n        cmd.setWorkingDirectory( javadocDirectory.getAbsolutePath() );\n        cmd.setExecutable( getJavadocPath() );\n\n        // General javadoc arguments\n        addArgIf( arguments, breakiterator, \"-breakiterator\", 1.4f );\n        if ( !StringUtils.isEmpty( doclet ) )\n        {\n            addArgIfNotEmpty( arguments, \"-doclet\", quotedArgument( doclet ) );\n\n            if ( docletArtifact != null ) {\n                Artifact artifact = factory.createArtifact( docletArtifact.getGroupId(),\n                    docletArtifact.getArtifactId(), docletArtifact.getVersion(), \"compile\", \"jar\" );\n                try {\n                    resolver.resolve( artifact, remoteRepositories, localRepository );\n                    docletPath = artifact.getFile().getAbsolutePath();\n                } catch ( ArtifactResolutionException e ) {\n                    throw new MavenReportException( \"Unable to resolve artifact.\", e );\n                } catch (ArtifactNotFoundException e) {\n                    throw new MavenReportException( \"Unable to find artifact.\", e );\n                }\n            }\n\n            addArgIfNotEmpty( arguments, \"-docletpath\", quotedPathArgument( docletPath ) );\n        }\n        addArgIfNotEmpty( arguments, \"-encoding\", quotedArgument( encoding ) );\n        addArgIfNotEmpty( arguments, \"-extdirs\", quotedPathArgument( extdirs ) );\n\n        if ( old && SystemUtils.isJavaVersionAtLeast( 1.4f ) )\n        {\n            getLog().warn( \"Javadoc 1.4 doesn't support the -1.1 switch anymore. Ignore this option.\" );\n        }\n        else\n        {\n            addArgIf( arguments, old, \"-1.1\" );\n        }\n\n        final int LEVEL_PUBLIC = 1;\n        final int LEVEL_PROTECTED = 2;\n        final int LEVEL_PACKAGE = 3;\n        final int LEVEL_PRIVATE = 4;\n        int accessLevel = 0;\n        if ( \"public\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PUBLIC;\n        }\n        else if ( \"protected\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PROTECTED;\n        }\n        else if ( \"package\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PACKAGE;\n        }\n        else if ( \"private\".equalsIgnoreCase( show ) )\n        {\n            accessLevel = LEVEL_PRIVATE;\n        }\n        else\n        {\n            getLog().error( \"Unrecognized access level to show '\" + show + \"'. Defaulting to protected.\" );\n            accessLevel = LEVEL_PROTECTED;\n        }\n\n        addArgIfNotEmpty( arguments, \"-overview\", quotedPathArgument( overview ) );\n        addArgIf( arguments, accessLevel == LEVEL_PUBLIC, \"-public\" );\n        addArgIf( arguments, accessLevel == LEVEL_PROTECTED, \"-protected\" );\n        addArgIf( arguments, accessLevel == LEVEL_PACKAGE, \"-package\" );\n        addArgIf( arguments, accessLevel == LEVEL_PRIVATE, \"-private\" );\n        addArgIf( arguments, quiet, \"-quiet\", 1.4f );\n        addArgIfNotEmpty( arguments, \"-source\", quotedArgument( source ), 1.4f );\n        addArgIf( arguments, verbose, \"-verbose\" );\n        addArgIfNotEmpty( arguments, null, additionalparam );\n        addArgIfNotEmpty( arguments, \"-sourcepath\", quotedPathArgument( sourcePath.toString() ) );\n\n        // javadoc arguments for default doclet\n        if ( StringUtils.isEmpty( doclet ) )\n        {\n            int actualYear = Calendar.getInstance().get( Calendar.YEAR );\n            String year = String.valueOf( actualYear );\n\n            bottom = StringUtils.replace( bottom, \"{currentYear}\", year );\n\n            if ( model != null && model.getInceptionYear() != null )\n            {\n                if ( model.getInceptionYear().equals( year ) )\n                {\n                    bottom = StringUtils.replace( bottom, \"{inceptionYear}-\", \"\" );\n                }\n                else\n                {\n                    bottom = StringUtils.replace( bottom, \"{inceptionYear}\", model.getInceptionYear() );\n                }\n            }\n\n            if ( StringUtils.isEmpty( stylesheetfile ) )\n            {\n                stylesheetfile = javadocDirectory + File.separator + DEFAULT_CSS_NAME;\n            }\n            // End Specify default values\n\n            addArgIf( arguments, author, \"-author\" );\n            addArgIfNotEmpty( arguments, \"-bottom\", quotedArgument( bottom ) );\n            addArgIf( arguments, breakiterator, \"-breakiterator\", 1.4f );\n            addArgIfNotEmpty( arguments, \"-charset\", quotedArgument( charset ) );\n            addArgIfNotEmpty( arguments, \"-d\", quotedPathArgument( javadocDirectory.toString() ) );\n            addArgIf( arguments, docfilessubdirs, \"-docfilessubdirs\", 1.4f );\n            addArgIfNotEmpty( arguments, \"-docencoding\", quotedArgument( docencoding ) );\n            addArgIfNotEmpty( arguments, \"-doctitle\", quotedArgument( doctitle ) );\n            addArgIfNotEmpty( arguments, \"-excludedocfilessubdir\", quotedPathArgument( excludedocfilessubdir ), 1.4f );\n            addArgIfNotEmpty( arguments, \"-footer\", quotedArgument( footer ) );\n            for ( int i = 0; i < groups.length; i++ )\n            {\n                if ( ( groups[i] == null ) || ( StringUtils.isEmpty( groups[i].getTitle() ) )\n                    || ( StringUtils.isEmpty( groups[i].getPackages() ) ) )\n                {\n                    getLog().info( \"A group option is empty. Ignore this option.\" );\n                    continue;\n                }\n                addArgIfNotEmpty( arguments, \"-group\", quotedArgument( groups[i].getTitle() ) + \" \"\n                    + quotedArgument( groups[i].getPackages() ), true );\n            }\n            addArgIfNotEmpty( arguments, \"-header\", quotedArgument( header ) );\n            addArgIfNotEmpty( arguments, \"-helpfile\", quotedPathArgument( helpfile ) );\n\n            if ( !isOffline )\n            {\n                addLinkArguments( arguments );\n                addLinkofflineArguments( arguments );\n                addArgIf( arguments, linksource, \"-linksource\", 1.4f );\n            }\n\n            addArgIf( arguments, nodeprecated, \"-nodeprecated\" );\n            addArgIf( arguments, nodeprecatedlist, \"-nodeprecatedlist\" );\n            addArgIf( arguments, nocomment, \"-nocomment\", 1.4f );\n            addArgIf( arguments, nohelp, \"-nohelp\" );\n            addArgIf( arguments, noindex, \"-noindex\" );\n            addArgIf( arguments, nonavbar, \"-nonavbar\" );\n            addArgIfNotEmpty( arguments, \"-noqualifier\", quotedArgument( noqualifier ), 1.4f );\n            addArgIf( arguments, nosince, \"-nosince\" );\n            addArgIf( arguments, notree, \"-notree\" );\n            addArgIf( arguments, serialwarn, \"-serialwarn\" );\n            addArgIf( arguments, splitindex, \"-splitindex\" );\n            addArgIfNotEmpty( arguments, \"-stylesheetfile\", quotedPathArgument( stylesheetfile ) );\n\n            addArgIfNotEmpty( arguments, \"-taglet\", quotedArgument( taglet ), 1.4f );\n            addArgIfNotEmpty( arguments, \"-tagletpath\", quotedPathArgument( tagletpath ), 1.4f );\n\n            for ( int i = 0; i < tags.length; i++ )\n            {\n                if ( ( tags[i] == null ) || ( StringUtils.isEmpty( tags[i].getName() ) )\n                    || ( StringUtils.isEmpty( tags[i].getPlacement() ) ) )\n                {\n                    getLog().info( \"A tag option is empty. Ignore this option.\" );\n                    continue;\n                }\n                String value = \"\\\"\" + tags[i].getName() + \":\" + tags[i].getPlacement();\n                if ( !StringUtils.isEmpty( tags[i].getHead() ) )\n                {\n                    value += \":\" + quotedArgument( tags[i].getHead() );\n                }\n                value+=\"\\\"\";\n                addArgIfNotEmpty( arguments, \"-tag\", value, 1.4f, false );\n            }\n\n            addArgIf( arguments, use, \"-use\" );\n            addArgIf( arguments, version, \"-version\" );\n            addArgIfNotEmpty( arguments, \"-windowtitle\", quotedArgument( windowtitle ) );\n        }\n\n        if ( options.length() > 0 )\n        {\n            File optionsFile = new File( javadocDirectory, \"options\" );\n            for ( Iterator it = arguments.iterator(); it.hasNext(); )\n            {\n                options.append( \" \" );\n                options.append( (String) it.next() );\n            }\n            try\n            {\n                FileUtils.fileWrite( optionsFile.getAbsolutePath(), options.toString() );\n            }\n            catch ( IOException e )\n            {\n                throw new MavenReportException( \"Unable to write temporary file for command execution\", e );\n            }\n            cmd.createArgument().setValue( \"@options\" );\n            if ( !getLog().isDebugEnabled() )\n            {\n                optionsFile.deleteOnExit();\n            }\n        }\n\n        cmd.createArgument().setValue( \"@files\" );\n\n        getLog().debug( Commandline.toString( cmd.getCommandline() ) );\n\n        CommandLineUtils.StringStreamConsumer err = new CommandLineUtils.StringStreamConsumer();\n        try\n        {\n            int exitCode = CommandLineUtils.executeCommandLine( cmd, new DefaultConsumer(), err );\n\n            if ( exitCode != 0 )\n            {\n                throw new MavenReportException( \"Exit code: \" + exitCode + \" - \" + err.getOutput() );\n            }\n        }\n        catch ( CommandLineException e )\n        {\n            throw new MavenReportException( \"Unable to execute javadoc command\", e );\n        }\n    }","commit_id":"25615ae95278bcbcb7c792e41ed7278f2b0f9929","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * Create and set the classloader that is needed for creating the java sources from wsdl\n     * \n     * @param project\n     * @param useCompileClasspath\n     * @param classesDir\n     */\n    public Set<String> switchClassLoader(MavenProject project,\n                                         boolean useCompileClasspath,\n                                         File classesDir) {\n        List<URL> urlList = new ArrayList<URL>();\n        StringBuilder buf = new StringBuilder();\n        Set<String> ret = new LinkedHashSet<String>();\n        \n        try {\n            urlList.add(classesDir.toURI().toURL());\n            if (!useCompileClasspath) {\n                urlList.add(new File(project.getBuild().getOutputDirectory()).toURI().toURL());\n            }\n        } catch (MalformedURLException e) {\n            // ignore\n        }\n\n        buf.append(classesDir.getAbsolutePath());\n        ret.add(classesDir.getAbsolutePath());\n        buf.append(File.pathSeparatorChar);\n        if (!useCompileClasspath) {\n            buf.append(project.getBuild().getOutputDirectory());\n            ret.add(project.getBuild().getOutputDirectory());\n            buf.append(File.pathSeparatorChar);\n        }\n        List<?> artifacts = useCompileClasspath ? project.getCompileArtifacts() : project.getTestArtifacts();\n        for (Artifact a : CastUtils.cast(artifacts, Artifact.class)) {\n            try {\n                if (a.getFile() != null && a.getFile().exists()) {\n                    urlList.add(a.getFile().toURI().toURL());\n                    buf.append(a.getFile().getAbsolutePath());\n                    ret.add(a.getFile().getAbsolutePath());\n                    buf.append(File.pathSeparatorChar);\n                    // System.out.println(\"     \" +\n                    // a.getFile().getAbsolutePath());\n                }\n            } catch (MalformedURLException e) {\n                // ignore\n            }\n        }\n\n        origContextClassloader = Thread.currentThread().getContextClassLoader();\n        URLClassLoader loader = new URLClassLoader(urlList.toArray(new URL[urlList.size()]),\n                                                   origContextClassloader);\n        String newCp = buf.toString();\n\n        log.debug(\"Classpath: \" + urlList.toString());\n\n        origProps = new HashMap<Object, Object>(System.getProperties());\n\n        origClassPath = System.getProperty(\"java.class.path\");\n\n        Thread.currentThread().setContextClassLoader(loader);\n        System.setProperty(\"java.class.path\", newCp);\n        return ret;\n    }","id":36354,"modified_method":"/**\n     * Create and set the classloader that is needed for creating the java sources from wsdl\n     * \n     * @param project\n     * @param useCompileClasspath\n     * @param classesDir\n     */\n    public Set<URI> switchClassLoader(MavenProject project,\n                                         boolean useCompileClasspath,\n                                         File classesDir) {\n        List<URL> urlList = new ArrayList<URL>();\n        StringBuilder buf = new StringBuilder();\n        Set<URI> ret = new LinkedHashSet<URI>();\n        \n        try {\n            urlList.add(classesDir.toURI().toURL());\n            if (!useCompileClasspath) {\n                urlList.add(new File(project.getBuild().getOutputDirectory()).toURI().toURL());\n            }\n        } catch (MalformedURLException e) {\n            // ignore\n        }\n\n        buf.append(classesDir.getAbsolutePath());\n        ret.add(classesDir.toURI());\n        buf.append(File.pathSeparatorChar);\n        if (!useCompileClasspath) {\n            buf.append(project.getBuild().getOutputDirectory());\n            ret.add(new File(project.getBuild().getOutputDirectory()).toURI());\n            buf.append(File.pathSeparatorChar);\n        }\n        List<?> artifacts = useCompileClasspath ? project.getCompileArtifacts() : project.getTestArtifacts();\n        for (Artifact a : CastUtils.cast(artifacts, Artifact.class)) {\n            try {\n                if (a.getFile() != null && a.getFile().exists()) {\n                    urlList.add(a.getFile().toURI().toURL());\n                    buf.append(a.getFile().getAbsolutePath());\n                    ret.add(a.getFile().toURI());\n                    buf.append(File.pathSeparatorChar);\n                    // System.out.println(\"     \" +\n                    // a.getFile().getAbsolutePath());\n                }\n            } catch (MalformedURLException e) {\n                // ignore\n            }\n        }\n\n        origContextClassloader = Thread.currentThread().getContextClassLoader();\n        URLClassLoader loader = new URLClassLoader(urlList.toArray(new URL[urlList.size()]),\n                                                   origContextClassloader);\n        String newCp = buf.toString();\n\n        log.debug(\"Classpath: \" + urlList.toString());\n\n        origProps = new HashMap<Object, Object>(System.getProperties());\n\n        origClassPath = System.getProperty(\"java.class.path\");\n\n        Thread.currentThread().setContextClassLoader(loader);\n        System.setProperty(\"java.class.path\", newCp);\n        return ret;\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"private void forkOnce(Set<String> classPath, List<WsdlOption> effectiveWsdlOptions) \n        throws MojoExecutionException {\n        List<WsdlOption> toDo = new LinkedList<WsdlOption>();\n        List<List<String>> wargs = new LinkedList<List<String>>();\n        for (WsdlOption wsdlOption : effectiveWsdlOptions) {\n            File outputDirFile = wsdlOption.getOutputDir();\n            outputDirFile.mkdirs();\n            URI basedir = project.getBasedir().toURI();\n            URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n            File doneFile = getDoneFile(basedir, wsdlURI);\n\n            if (!shouldRun(wsdlOption, doneFile, wsdlURI)) {\n                continue;\n            }\n            doneFile.delete();\n            \n            toDo.add(wsdlOption);\n            \n            wargs.add(wsdlOption.generateCommandLine(outputDirFile, basedir, wsdlURI, getLog()\n                                                               .isDebugEnabled()));\n        }\n        if (wargs.isEmpty()) {\n            return;\n        }\n        \n        Set<String> artifactsPath = new LinkedHashSet<String>();\n        for (Artifact a : pluginArtifacts) {\n            File file = a.getFile();\n            if (file == null) {\n                throw new MojoExecutionException(\"Unable to find \" + file + \" for artifact \"\n                                                 + a.getGroupId() + \":\" + a.getArtifactId()\n                                                 + \":\" + a.getVersion());\n            }\n            artifactsPath.add(file.getPath());\n        }\n        addPluginArtifact(artifactsPath);\n        artifactsPath.addAll(classPath);\n        \n        String cp = StringUtils.join(artifactsPath.iterator(), File.pathSeparator);\n        \n        String args[] = createForkOnceArgs(wargs);\n        runForked(cp, ForkOnceWSDL2Java.class, args);\n        \n        for (WsdlOption wsdlOption : toDo) {\n            File dirs[] = wsdlOption.getDeleteDirs();\n            if (dirs != null) {\n                for (int idx = 0; idx < dirs.length; ++idx) {\n                    deleteDir(dirs[idx]);\n                }\n            }\n            URI basedir = project.getBasedir().toURI();\n            URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n            File doneFile = getDoneFile(basedir, wsdlURI);\n            try {\n                doneFile.createNewFile();\n            } catch (Throwable e) {\n                getLog().warn(\"Could not create marker file \" + doneFile.getAbsolutePath());\n                getLog().debug(e);\n            }\n        }\n    }","id":36355,"modified_method":"private void forkOnce(Set<URI> classPath, List<WsdlOption> effectiveWsdlOptions) \n        throws MojoExecutionException {\n        List<WsdlOption> toDo = new LinkedList<WsdlOption>();\n        List<List<String>> wargs = new LinkedList<List<String>>();\n        for (WsdlOption wsdlOption : effectiveWsdlOptions) {\n            File outputDirFile = wsdlOption.getOutputDir();\n            outputDirFile.mkdirs();\n            URI basedir = project.getBasedir().toURI();\n            URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n            File doneFile = getDoneFile(basedir, wsdlURI);\n\n            if (!shouldRun(wsdlOption, doneFile, wsdlURI)) {\n                continue;\n            }\n            doneFile.delete();\n            \n            toDo.add(wsdlOption);\n            \n            wargs.add(wsdlOption.generateCommandLine(outputDirFile, basedir, wsdlURI, getLog()\n                                                               .isDebugEnabled()));\n        }\n        if (wargs.isEmpty()) {\n            return;\n        }\n        \n        Set<URI> artifactsPath = new LinkedHashSet<URI>();\n        for (Artifact a : pluginArtifacts) {\n            File file = a.getFile();\n            if (file == null) {\n                throw new MojoExecutionException(\"Unable to find \" + file + \" for artifact \"\n                                                 + a.getGroupId() + \":\" + a.getArtifactId()\n                                                 + \":\" + a.getVersion());\n            }\n            artifactsPath.add(file.toURI());\n        }\n        addPluginArtifact(artifactsPath);\n        artifactsPath.addAll(classPath);\n        \n        String args[] = createForkOnceArgs(wargs);\n        runForked(artifactsPath, ForkOnceWSDL2Java.class, args);\n        \n        for (WsdlOption wsdlOption : toDo) {\n            File dirs[] = wsdlOption.getDeleteDirs();\n            if (dirs != null) {\n                for (int idx = 0; idx < dirs.length; ++idx) {\n                    deleteDir(dirs[idx]);\n                }\n            }\n            URI basedir = project.getBasedir().toURI();\n            URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n            File doneFile = getDoneFile(basedir, wsdlURI);\n            try {\n                doneFile.createNewFile();\n            } catch (Throwable e) {\n                getLog().warn(\"Could not create marker file \" + doneFile.getAbsolutePath());\n                getLog().debug(e);\n            }\n        }\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"private Bus callWsdl2Java(WsdlOption wsdlOption, \n                              Bus bus,\n                              Set<String> classPath) throws MojoExecutionException {\n        File outputDirFile = wsdlOption.getOutputDir();\n        outputDirFile.mkdirs();\n        URI basedir = project.getBasedir().toURI();\n        URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n        File doneFile = getDoneFile(basedir, wsdlURI);\n\n        if (!shouldRun(wsdlOption, doneFile, wsdlURI)) {\n            return bus;\n        }\n        doneFile.delete();\n\n        List<String> list = wsdlOption.generateCommandLine(outputDirFile, basedir, wsdlURI, getLog()\n                                                           .isDebugEnabled());\n        String[] args = (String[])list.toArray(new String[list.size()]);\n        getLog().debug(\"Calling wsdl2java with args: \" + Arrays.toString(args));\n        \n        if (!\"false\".equals(fork)) {\n            Set<String> artifactsPath = new LinkedHashSet<String>();\n            for (Artifact a : pluginArtifacts) {\n                File file = a.getFile();\n                if (file == null) {\n                    throw new MojoExecutionException(\"Unable to find \" + file + \" for artifact \"\n                                                     + a.getGroupId() + \":\" + a.getArtifactId()\n                                                     + \":\" + a.getVersion());\n                }\n                artifactsPath.add(file.getPath());\n            }\n            addPluginArtifact(artifactsPath);\n            artifactsPath.addAll(classPath);\n            String cp = StringUtils.join(artifactsPath.iterator(), File.pathSeparator);\n            \n            runForked(cp, WSDLToJava.class, args);\n\n        } else {\n            if (bus == null) {\n                bus = BusFactory.newInstance().createBus();\n                BusFactory.setThreadDefaultBus(bus);\n            }\n            try {\n                new WSDLToJava(args).run(new ToolContext());\n            } catch (Throwable e) {\n                getLog().debug(e);\n                throw new MojoExecutionException(e.getMessage(), e);\n            }  \n        }\n        \n\n        try {\n            doneFile.createNewFile();\n        } catch (Throwable e) {\n            getLog().warn(\"Could not create marker file \" + doneFile.getAbsolutePath());\n            getLog().debug(e);\n        }\n        return bus;\n    }","id":36356,"modified_method":"private Bus callWsdl2Java(WsdlOption wsdlOption, \n                              Bus bus,\n                              Set<URI> classPath) throws MojoExecutionException {\n        File outputDirFile = wsdlOption.getOutputDir();\n        outputDirFile.mkdirs();\n        URI basedir = project.getBasedir().toURI();\n        URI wsdlURI = wsdlOption.getWsdlURI(basedir);\n        File doneFile = getDoneFile(basedir, wsdlURI);\n\n        if (!shouldRun(wsdlOption, doneFile, wsdlURI)) {\n            return bus;\n        }\n        doneFile.delete();\n\n        List<String> list = wsdlOption.generateCommandLine(outputDirFile, basedir, wsdlURI, getLog()\n                                                           .isDebugEnabled());\n        String[] args = (String[])list.toArray(new String[list.size()]);\n        getLog().debug(\"Calling wsdl2java with args: \" + Arrays.toString(args));\n        \n        if (!\"false\".equals(fork)) {\n            Set<URI> artifactsPath = new LinkedHashSet<URI>();\n            for (Artifact a : pluginArtifacts) {\n                File file = a.getFile();\n                if (file == null) {\n                    throw new MojoExecutionException(\"Unable to find \" + file + \" for artifact \"\n                                                     + a.getGroupId() + \":\" + a.getArtifactId()\n                                                     + \":\" + a.getVersion());\n                }\n                artifactsPath.add(file.toURI());\n            }\n            addPluginArtifact(artifactsPath);\n            artifactsPath.addAll(classPath);\n            \n            runForked(artifactsPath, WSDLToJava.class, args);\n\n        } else {\n            if (bus == null) {\n                bus = BusFactory.newInstance().createBus();\n                BusFactory.setThreadDefaultBus(bus);\n            }\n            try {\n                new WSDLToJava(args).run(new ToolContext());\n            } catch (Throwable e) {\n                getLog().debug(e);\n                throw new MojoExecutionException(e.getMessage(), e);\n            }  \n        }\n        \n\n        try {\n            doneFile.createNewFile();\n        } catch (Throwable e) {\n            getLog().warn(\"Could not create marker file \" + doneFile.getAbsolutePath());\n            getLog().debug(e);\n        }\n        return bus;\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"public void execute() throws MojoExecutionException {\n        if (includes == null) {\n            includes = new String[] {\n                \"*.wsdl\"\n            };\n        }\n        defaultOptions.addDefaultBindingFileIfExists(project.getBasedir());\n        File classesDir = new File(classesDirectory);\n        classesDir.mkdirs();\n        markerDirectory.mkdirs();\n\n        List<WsdlOption> effectiveWsdlOptions = createWsdlOptionsFromScansAndExplicitWsdlOptions();\n\n        if (effectiveWsdlOptions.size() == 0) {\n            getLog().info(\"Nothing to generate\");\n            return;\n        }\n\n        ClassLoaderSwitcher classLoaderSwitcher = new ClassLoaderSwitcher(getLog());\n        boolean result = true;\n\n        Bus bus = null;\n        try {\n            Set<String> cp = classLoaderSwitcher.switchClassLoader(project, useCompileClasspath, classesDir);\n\n            if (\"once\".equals(fork) || \"true\".equals(fork)) {\n                forkOnce(cp, effectiveWsdlOptions);\n            } else {\n                for (WsdlOption o : effectiveWsdlOptions) {\n                    bus = callWsdl2Java(o, bus, cp);\n    \n                    File dirs[] = o.getDeleteDirs();\n                    if (dirs != null) {\n                        for (int idx = 0; idx < dirs.length; ++idx) {\n                            result = result && deleteDir(dirs[idx]);\n                        }\n                    }\n                }\n            }\n        } finally {\n            // cleanup as much as we can.\n            if (bus != null) {\n                bus.shutdown(true);\n            }\n            classLoaderSwitcher.restoreClassLoader();\n        }\n        if (project != null && sourceRoot != null && sourceRoot.exists()) {\n            project.addCompileSourceRoot(sourceRoot.getAbsolutePath());\n        }\n        if (project != null && testSourceRoot != null && testSourceRoot.exists()) {\n            project.addTestCompileSourceRoot(testSourceRoot.getAbsolutePath());\n        }\n\n        System.gc();\n    }","id":36357,"modified_method":"public void execute() throws MojoExecutionException {\n        if (includes == null) {\n            includes = new String[] {\n                \"*.wsdl\"\n            };\n        }\n        defaultOptions.addDefaultBindingFileIfExists(project.getBasedir());\n        File classesDir = new File(classesDirectory);\n        classesDir.mkdirs();\n        markerDirectory.mkdirs();\n\n        List<WsdlOption> effectiveWsdlOptions = createWsdlOptionsFromScansAndExplicitWsdlOptions();\n\n        if (effectiveWsdlOptions.size() == 0) {\n            getLog().info(\"Nothing to generate\");\n            return;\n        }\n\n        ClassLoaderSwitcher classLoaderSwitcher = new ClassLoaderSwitcher(getLog());\n        boolean result = true;\n\n        Bus bus = null;\n        try {\n            Set<URI> cp = classLoaderSwitcher.switchClassLoader(project, useCompileClasspath, classesDir);\n\n            if (\"once\".equals(fork) || \"true\".equals(fork)) {\n                forkOnce(cp, effectiveWsdlOptions);\n            } else {\n                for (WsdlOption o : effectiveWsdlOptions) {\n                    bus = callWsdl2Java(o, bus, cp);\n    \n                    File dirs[] = o.getDeleteDirs();\n                    if (dirs != null) {\n                        for (int idx = 0; idx < dirs.length; ++idx) {\n                            result = result && deleteDir(dirs[idx]);\n                        }\n                    }\n                }\n            }\n        } finally {\n            // cleanup as much as we can.\n            if (bus != null) {\n                bus.shutdown(true);\n            }\n            classLoaderSwitcher.restoreClassLoader();\n        }\n        if (project != null && sourceRoot != null && sourceRoot.exists()) {\n            project.addCompileSourceRoot(sourceRoot.getAbsolutePath());\n        }\n        if (project != null && testSourceRoot != null && testSourceRoot.exists()) {\n            project.addTestCompileSourceRoot(testSourceRoot.getAbsolutePath());\n        }\n\n        System.gc();\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"private void runForked(String classPath, Class cls, String[] args) throws MojoExecutionException {\n        getLog().info(\"Running wsdl2java in fork mode...\");\n\n        Commandline cmd = new Commandline();\n        cmd.getShell().setQuotedArgumentsEnabled(false); // for JVM args\n        cmd.setWorkingDirectory(project.getBuild().getDirectory());\n        try {\n            cmd.setExecutable(getJavaExecutable().getAbsolutePath());\n        } catch (IOException e) {\n            getLog().debug(e);\n            throw new MojoExecutionException(e.getMessage(), e);\n        }\n        cmd.createArg().setValue(\"-cp\");\n        cmd.createArg().setValue(classPath);\n        cmd.createArg().setLine(additionalJvmArgs);\n        cmd.createArg().setValue(cls.getName());\n        cmd.addArguments(args);\n\n        CommandLineUtils.StringStreamConsumer err = new CommandLineUtils.StringStreamConsumer();\n        CommandLineUtils.StringStreamConsumer out = new CommandLineUtils.StringStreamConsumer();\n\n        int exitCode;\n        try {\n            exitCode = CommandLineUtils.executeCommandLine(cmd, out, err);\n        } catch (CommandLineException e) {\n            getLog().debug(e);\n            throw new MojoExecutionException(e.getMessage(), e);\n        }\n\n        String output = StringUtils.isEmpty(out.getOutput()) ? null : '\\n' + out.getOutput().trim();\n\n        String cmdLine = CommandLineUtils.toString(cmd.getCommandline());\n\n        if (exitCode != 0) {\n            if (StringUtils.isNotEmpty(output)) {\n                getLog().info(output);\n            }\n\n            StringBuffer msg = new StringBuffer(\"\\nExit code: \");\n            msg.append(exitCode);\n            if (StringUtils.isNotEmpty(err.getOutput())) {\n                msg.append(\" - \").append(err.getOutput());\n            }\n            msg.append('\\n');\n            msg.append(\"Command line was: \").append(cmdLine).append('\\n').append('\\n');\n\n            throw new MojoExecutionException(msg.toString());\n        }\n\n        if (StringUtils.isNotEmpty(err.getOutput()) && err.getOutput().contains(\"WSDL2Java Error\")) {\n            StringBuffer msg = new StringBuffer();\n            msg.append(err.getOutput());\n            msg.append('\\n');\n            msg.append(\"Command line was: \").append(cmdLine).append('\\n').append('\\n');\n            throw new MojoExecutionException(msg.toString());\n        }\n\n    }","id":36358,"modified_method":"private void runForked(Set<URI> classPath, Class cls, String[] args) throws MojoExecutionException {\n        getLog().info(\"Running wsdl2java in fork mode...\");\n\n        Commandline cmd = new Commandline();\n        cmd.getShell().setQuotedArgumentsEnabled(false); // for JVM args\n        cmd.setWorkingDirectory(project.getBuild().getDirectory());\n        try {\n            cmd.setExecutable(getJavaExecutable().getAbsolutePath());\n        } catch (IOException e) {\n            getLog().debug(e);\n            throw new MojoExecutionException(e.getMessage(), e);\n        }\n\n        cmd.createArg().setLine(additionalJvmArgs);\n\n        try {\n            File file = FileUtils.createTempFile(\"cxf-codegen\", \".jar\");\n\n            JarArchiver jar = new JarArchiver();\n            jar.setDestFile(file.getAbsoluteFile());\n            \n            Manifest manifest = new Manifest();\n            Attribute attr = new Attribute();\n            attr.setName(\"Class-Path\");\n            attr.setValue(StringUtils.join(classPath.iterator(), \" \"));\n            manifest.getMainSection().addConfiguredAttribute(attr);\n            \n            attr = new Attribute();\n            attr.setName(\"Main-Class\");\n            attr.setValue(cls.getName());\n            manifest.getMainSection().addConfiguredAttribute(attr);\n\n            jar.addConfiguredManifest(manifest);\n            jar.createArchive();\n            \n            cmd.createArg().setValue(\"-jar\");\n            cmd.createArg().setValue(file.getAbsolutePath());\n\n            \n        } catch (Exception e1) {\n            throw new MojoExecutionException(\"Could not create runtime jar\", e1);\n        }\n        cmd.addArguments(args);\n        \n\n        CommandLineUtils.StringStreamConsumer err = new CommandLineUtils.StringStreamConsumer();\n        CommandLineUtils.StringStreamConsumer out = new CommandLineUtils.StringStreamConsumer();\n\n        int exitCode;\n        try {\n            exitCode = CommandLineUtils.executeCommandLine(cmd, out, err);\n        } catch (CommandLineException e) {\n            getLog().debug(e);\n            throw new MojoExecutionException(e.getMessage(), e);\n        }\n\n        String output = StringUtils.isEmpty(out.getOutput()) ? null : '\\n' + out.getOutput().trim();\n\n        String cmdLine = CommandLineUtils.toString(cmd.getCommandline());\n\n        if (exitCode != 0) {\n            if (StringUtils.isNotEmpty(output)) {\n                getLog().info(output);\n            }\n\n            StringBuffer msg = new StringBuffer(\"\\nExit code: \");\n            msg.append(exitCode);\n            if (StringUtils.isNotEmpty(err.getOutput())) {\n                msg.append(\" - \").append(err.getOutput());\n            }\n            msg.append('\\n');\n            msg.append(\"Command line was: \").append(cmdLine).append('\\n').append('\\n');\n\n            throw new MojoExecutionException(msg.toString());\n        }\n\n        if (StringUtils.isNotEmpty(err.getOutput()) && err.getOutput().contains(\"WSDL2Java Error\")) {\n            StringBuffer msg = new StringBuffer();\n            msg.append(err.getOutput());\n            msg.append('\\n');\n            msg.append(\"Command line was: \").append(cmdLine).append('\\n').append('\\n');\n            throw new MojoExecutionException(msg.toString());\n        }\n\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"private void addPluginArtifact(Set<String> artifactsPath) {\n        //for Maven 2.x, the actual artifact isn't in the list....  need to try and find it\n        URL url = getClass().getResource(getClass().getSimpleName() + \".class\");\n        \n        try {\n            URI uri = url.toURI();\n            if (\"jar\".equals(uri.getScheme())) {\n                String s = uri.getSchemeSpecificPart();\n                if (s.contains(\"!\")) {\n                    s = s.substring(0, s.indexOf('!'));\n                    uri = new URI(s);\n                }\n            }\n            if (uri.getSchemeSpecificPart().endsWith(\".class\")) {\n                String s = uri.toString();\n                s = s.substring(0, s.length() - 6 - getClass().getName().length());\n                uri = new URI(s);\n            }\n            \n            File file = new File(uri);\n            if (file.exists()) {\n                artifactsPath.add(file.getPath());\n            }\n        } catch (Exception ex) {\n            //ex.printStackTrace();\n        }\n\n    }","id":36359,"modified_method":"private void addPluginArtifact(Set<URI> artifactsPath) {\n        //for Maven 2.x, the actual artifact isn't in the list....  need to try and find it\n        URL url = getClass().getResource(getClass().getSimpleName() + \".class\");\n        \n        try {\n            URI uri = url.toURI();\n            if (\"jar\".equals(uri.getScheme())) {\n                String s = uri.getSchemeSpecificPart();\n                if (s.contains(\"!\")) {\n                    s = s.substring(0, s.indexOf('!'));\n                    uri = new URI(s);\n                }\n            }\n            if (uri.getSchemeSpecificPart().endsWith(\".class\")) {\n                String s = uri.toString();\n                s = s.substring(0, s.length() - 6 - getClass().getName().length());\n                uri = new URI(s);\n            }\n            \n            File file = new File(uri);\n            if (file.exists()) {\n                artifactsPath.add(file.toURI());\n            }\n        } catch (Exception ex) {\n            //ex.printStackTrace();\n        }\n\n    }","commit_id":"55d0441f2c6a7163ce712686289b46218bbe9c0a","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Returns the EJB Jar file to generate, based on an optional classifier.\n     *\n     * @param basedir    the output directory\n     * @param finalName  the name of the ear file\n     * @param classifier an optional classifier\n     * @return the EJB file to generate\n     */\n    private static File getEJBJarFile( String basedir, String finalName, String classifier )\n    {\n        if ( classifier == null )\n        {\n            classifier = \"\";\n        }\n        else if ( classifier.trim().length() > 0 && !classifier.startsWith( \"-\" ) )\n        {\n            classifier = \"-\" + classifier;\n        }\n\n        return new File( basedir, finalName + classifier + \".jar\" );\n    }","id":36360,"modified_method":"/**\n     * Returns the EJB Jar file to generate, based on an optional classifier.\n     *\n     * @param basedir    the output directory\n     * @param finalName  the name of the ear file\n     * @param classifier an optional classifier\n     * @return the EJB file to generate\n     */\n    private static File getEJBJarFile( File basedir, String finalName, String classifier )\n    {\n        if ( classifier == null )\n        {\n            classifier = \"\";\n        }\n        else if ( classifier.trim().length() > 0 && !classifier.startsWith( \"-\" ) )\n        {\n            classifier = \"-\" + classifier;\n        }\n\n        return new File( basedir, finalName + classifier + \".jar\" );\n    }","commit_id":"5e6de2ee47c7d4c1ad2160dcd418a9611d26f250","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * Generates an EJB jar and optionally an ejb-client jar.\n     *\n     * @todo Add license files in META-INF directory.\n     */\n    public void execute()\n        throws MojoExecutionException\n    {\n        if ( getLog().isInfoEnabled() )\n        {\n            getLog().info( \"Building EJB \" + jarName + \" with EJB version \" + ejbVersion );\n        }\n\n        File jarFile = getEJBJarFile( basedir, jarName, classifier );\n\n        MavenArchiver archiver = new MavenArchiver();\n\n        archiver.setArchiver( jarArchiver );\n\n        archiver.setOutputFile( jarFile );\n\n        File deploymentDescriptor = new File( outputDirectory, EJB_JAR_XML );\n\n        /* test EJB version compliance */\n        if ( !ejbVersion.matches( \"\\\\A[2-3]\\\\.[0-9]\\\\z\" ) )\n        {\n            throw new MojoExecutionException(\n                \"ejbVersion is not valid: \" + ejbVersion + \". Must be 2.x or 3.x (where x is a digit)\" );\n        }\n\n        if ( ejbVersion.matches( \"\\\\A2\\\\.[0-9]\\\\z\" ) && !deploymentDescriptor.exists() )\n        {\n            throw new MojoExecutionException(\n                \"Error assembling EJB: \" + EJB_JAR_XML + \" is required for ejbVersion 2.x\" );\n        }\n\n        try\n        {\n            String[] mainJarExcludes = DEFAULT_EXCLUDES;\n\n            if ( excludes != null && !excludes.isEmpty() ) {\n                mainJarExcludes = (String[]) excludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            archiver.getArchiver().addDirectory( new File( outputDirectory ), DEFAULT_INCLUDES, mainJarExcludes );\n\n            if ( deploymentDescriptor.exists() )\n            {\n                archiver.getArchiver().addFile( deploymentDescriptor, EJB_JAR_XML );\n            }\n\n            // create archive\n            archiver.createArchive( project, archive );\n        }\n        catch ( ArchiverException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( ManifestException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( DependencyResolutionRequiredException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n\n        // Handle the classifier if necessary\n        if ( classifier != null )\n        {\n            projectHelper.attachArtifact( project, \"ejb\", classifier, jarFile );\n        }\n        else\n        {\n            project.getArtifact().setFile( jarFile );\n        }\n\n        if ( generateClient )\n        {\n            String clientJarName = jarName;\n            if ( classifier != null )\n            {\n                clientJarName += \"-\" + classifier;\n            }\n\n            getLog().info( \"Building EJB client \" + clientJarName + \"-client\" );\n\n            String[] excludes = DEFAULT_CLIENT_EXCLUDES;\n            String[] includes = DEFAULT_INCLUDES;\n\n            if ( clientIncludes != null && !clientIncludes.isEmpty() )\n            {\n                includes = (String[]) clientIncludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            if ( clientExcludes != null && !clientExcludes.isEmpty() )\n            {\n                excludes = (String[]) clientExcludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            File clientJarFile = new File( basedir, clientJarName + \"-client.jar\" );\n\n            MavenArchiver clientArchiver = new MavenArchiver();\n\n            clientArchiver.setArchiver( clientJarArchiver );\n\n            clientArchiver.setOutputFile( clientJarFile );\n\n            try\n            {\n                clientArchiver.getArchiver().addDirectory( new File( outputDirectory ), includes, excludes );\n\n                // create archive\n                clientArchiver.createArchive( project, archive );\n\n            }\n            catch ( ArchiverException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( ManifestException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( DependencyResolutionRequiredException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n\n            // TODO: shouldn't need classifer\n            if ( classifier != null )\n            {\n                projectHelper.attachArtifact( project, \"ejb-client\", classifier + \"-client\", clientJarFile );\n            }\n            else\n            {\n                projectHelper.attachArtifact( project, \"ejb-client\", \"client\", clientJarFile );\n            }\n        }\n    }","id":36361,"modified_method":"/**\n     * Generates an EJB jar and optionally an ejb-client jar.\n     *\n     * @todo Add license files in META-INF directory.\n     */\n    public void execute()\n        throws MojoExecutionException\n    {\n        if ( getLog().isInfoEnabled() )\n        {\n            getLog().info( \"Building EJB \" + jarName + \" with EJB version \" + ejbVersion );\n        }\n\n        File jarFile = getEJBJarFile( basedir, jarName, classifier );\n\n        MavenArchiver archiver = new MavenArchiver();\n\n        archiver.setArchiver( jarArchiver );\n\n        archiver.setOutputFile( jarFile );\n\n        File deploymentDescriptor = new File( outputDirectory, EJB_JAR_XML );\n\n        /* test EJB version compliance */\n        if ( !ejbVersion.matches( \"\\\\A[2-3]\\\\.[0-9]\\\\z\" ) )\n        {\n            throw new MojoExecutionException(\n                \"ejbVersion is not valid: \" + ejbVersion + \". Must be 2.x or 3.x (where x is a digit)\" );\n        }\n\n        if ( ejbVersion.matches( \"\\\\A2\\\\.[0-9]\\\\z\" ) && !deploymentDescriptor.exists() )\n        {\n            throw new MojoExecutionException(\n                \"Error assembling EJB: \" + EJB_JAR_XML + \" is required for ejbVersion 2.x\" );\n        }\n\n        try\n        {\n            String[] mainJarExcludes = DEFAULT_EXCLUDES;\n\n            if ( excludes != null && !excludes.isEmpty() ) {\n                mainJarExcludes = (String[]) excludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            archiver.getArchiver().addDirectory( outputDirectory, DEFAULT_INCLUDES, mainJarExcludes );\n\n            if ( deploymentDescriptor.exists() )\n            {\n                archiver.getArchiver().addFile( deploymentDescriptor, EJB_JAR_XML );\n            }\n\n            // create archive\n            archiver.createArchive( project, archive );\n        }\n        catch ( ArchiverException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( ManifestException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n        catch ( DependencyResolutionRequiredException e )\n        {\n            throw new MojoExecutionException( \"There was a problem creating the EJB archive: \" + e.getMessage(), e );\n        }\n\n        // Handle the classifier if necessary\n        if ( classifier != null )\n        {\n            projectHelper.attachArtifact( project, \"ejb\", classifier, jarFile );\n        }\n        else\n        {\n            project.getArtifact().setFile( jarFile );\n        }\n\n        if ( generateClient )\n        {\n            String clientJarName = jarName;\n            if ( classifier != null )\n            {\n                clientJarName += \"-\" + classifier;\n            }\n\n            getLog().info( \"Building EJB client \" + clientJarName + \"-client\" );\n\n            String[] excludes = DEFAULT_CLIENT_EXCLUDES;\n            String[] includes = DEFAULT_INCLUDES;\n\n            if ( clientIncludes != null && !clientIncludes.isEmpty() )\n            {\n                includes = (String[]) clientIncludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            if ( clientExcludes != null && !clientExcludes.isEmpty() )\n            {\n                excludes = (String[]) clientExcludes.toArray( EMPTY_STRING_ARRAY );\n            }\n\n            File clientJarFile = new File( basedir, clientJarName + \"-client.jar\" );\n\n            MavenArchiver clientArchiver = new MavenArchiver();\n\n            clientArchiver.setArchiver( clientJarArchiver );\n\n            clientArchiver.setOutputFile( clientJarFile );\n\n            try\n            {\n                clientArchiver.getArchiver().addDirectory( outputDirectory, includes, excludes );\n\n                // create archive\n                clientArchiver.createArchive( project, archive );\n\n            }\n            catch ( ArchiverException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( ManifestException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n            catch ( DependencyResolutionRequiredException e )\n            {\n                throw new MojoExecutionException(\n                    \"There was a problem creating the EJB client archive: \" + e.getMessage(), e );\n            }\n\n            // TODO: shouldn't need classifer\n            if ( classifier != null )\n            {\n                projectHelper.attachArtifact( project, \"ejb-client\", classifier + \"-client\", clientJarFile );\n            }\n            else\n            {\n                projectHelper.attachArtifact( project, \"ejb-client\", \"client\", clientJarFile );\n            }\n        }\n    }","commit_id":"5e6de2ee47c7d4c1ad2160dcd418a9611d26f250","url":"https://github.com/apache/maven-plugins"},{"original_method":"protected EjbMojo lookupMojoWithSettings( final MavenProject project, LinkedList clientIncludes,\n                                              LinkedList clientExcludes, LinkedList excludes )\n        throws Exception\n    {\n        final EjbMojo mojo = lookupMojo();\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"basedir\", project.getBuild().getDirectory() );\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\n        setVariableValueToObject( mojo, \"jarName\", DEFAULT_JAR_NAME );\n        setVariableValueToObject( mojo, \"clientExcludes\", clientExcludes );\n        setVariableValueToObject( mojo, \"clientIncludes\", clientIncludes );\n        setVariableValueToObject( mojo, \"excludes\", excludes );\n\n        return mojo;\n    }","id":36362,"modified_method":"protected EjbMojo lookupMojoWithSettings( final MavenProject project, LinkedList clientIncludes,\n                                              LinkedList clientExcludes, LinkedList excludes )\n        throws Exception\n    {\n        final EjbMojo mojo = lookupMojo();\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"basedir\", new File( project.getBuild().getDirectory() ) );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"jarName\", DEFAULT_JAR_NAME );\n        setVariableValueToObject( mojo, \"clientExcludes\", clientExcludes );\n        setVariableValueToObject( mojo, \"clientIncludes\", clientIncludes );\n        setVariableValueToObject( mojo, \"excludes\", excludes );\n\n        return mojo;\n    }","commit_id":"5e6de2ee47c7d4c1ad2160dcd418a9611d26f250","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void populateFile( File file, int type )\n    {\n        FileOutputStream outputStream;\n        String data = data = (String) dataMap.get( file.getName() );\n\n        if ( ( data != null ) && file.exists() )\n        {\n            try\n            {\n                outputStream = new FileOutputStream( file );\n                outputStream.write( data.getBytes() );\n                outputStream.flush();\n                outputStream.close();\n            }\n            catch ( IOException ex )\n            {\n                // TODO: handle exception here\n            }\n        }\n    }","id":36363,"modified_method":"private void populateFile( File file, int type )\n    {\n        FileOutputStream outputStream;\n        String data = (String) dataMap.get( file.getName() );\n\n        if ( ( data != null ) && file.exists() )\n        {\n            try\n            {\n                outputStream = new FileOutputStream( file );\n                outputStream.write( data.getBytes() );\n                outputStream.flush();\n                outputStream.close();\n            }\n            catch ( IOException ex )\n            {\n                // TODO: handle exception here\n            }\n        }\n    }","commit_id":"5e6de2ee47c7d4c1ad2160dcd418a9611d26f250","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * Execute the eclipse:eclipse goal on a test project and verify generated files.\n     * @param projectName project directory\n     * @param outputDir output dir (if null it's the same as the project)\n     * @throws Exception any exception generated during test\n     */\n    protected void testProject( String projectName, File outputDir )\n        throws Exception\n    {\n        File basedir = getTestFile( \"src/test/projects/\" + projectName );\n\n        MavenProjectBuilder builder = (MavenProjectBuilder) lookup( MavenProjectBuilder.ROLE );\n\n        EclipsePlugin plugin = new EclipsePlugin();\n\n        File repo = getTestFile( \"src/test/repository\" );\n\n        ArtifactRepositoryLayout localRepositoryLayout = (ArtifactRepositoryLayout) lookup(\n                                                                                            ArtifactRepositoryLayout.ROLE,\n                                                                                            \"legacy\" );\n\n        ArtifactRepository localRepository = new DefaultArtifactRepository( \"local\",\n                                                                            \"file://\" + repo.getAbsolutePath(),\n                                                                            localRepositoryLayout );\n\n        MavenProject project = builder.buildWithDependencies( new File( basedir, \"pom.xml\" ), localRepository, null );\n\n        File projectOutputDir = basedir;\n\n        if ( outputDir == null )\n        {\n            outputDir = basedir;\n        }\n        else\n        {\n            outputDir.mkdirs();\n\n            projectOutputDir = new File( outputDir, project.getArtifactId() );\n        }\n\n        // Shouldn't PlexusTestCase at least offer a predefined log instance?\n        //  if ( log.isDebugEnabled() )\n        //  {\n        //    log.debug( \"basedir: \" + basedir + \"\\noutputdir: \" + outputDir + \"\\nprojectOutputDir: \" + projectOutputDir );\n        //  }\n\n        plugin.setOutputDir( outputDir );\n\n        for ( Iterator it = project.getArtifacts().iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            artifact.setFile( new File( localRepository.getBasedir(), localRepository.pathOf( artifact ) ) );\n        }\n\n        plugin.setProject( project );\n        plugin.setOutputDirectory( project.getBuild().getOutputDirectory() );\n\n        plugin.setLocalRepository( localRepository );\n\n        plugin.setArtifactFactory( (ArtifactFactory) lookup( ArtifactFactory.ROLE ) );\n        plugin.setArtifactResolver( (ArtifactResolver) lookup( ArtifactResolver.ROLE ) );\n        plugin.setRemoteArtifactRepositories( new ArrayList( 0 ) );\n\n        List projectNatures = new ArrayList();\n        projectNatures.add( \"org.eclipse.jdt.core.javanature\" );\n        plugin.setProjectnatures( projectNatures );\n\n        List buildcommands = new ArrayList();\n        buildcommands.add( \"org.eclipse.jdt.core.javabuilder\" );\n        plugin.setBuildcommands( buildcommands );\n\n        plugin.setClasspathContainers( new ArrayList() );\n\n        plugin.setDownloadSources( true );\n\n        plugin.setWtpversion( \"R7\" );\n\n        plugin.execute();\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"project\" ), new File( projectOutputDir,\n                                                                                                  \".project\" ) );\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"classpath\" ), new File( projectOutputDir,\n                                                                                                    \".classpath\" ) );\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"wtpmodules\" ), new File( projectOutputDir,\n                                                                                                     \".wtpmodules\" ) );\n\n        if ( new File( basedir, \"settings\" ).exists() )\n        {\n            assertFileEquals( localRepository.getBasedir(), new File( basedir, \"settings\" ),\n                              new File( basedir, \".settings/org.eclipse.jdt.core.prefs\" ) );\n        }\n    }","id":36364,"modified_method":"/**\n     * Execute the eclipse:eclipse goal on a test project and verify generated files.\n     * @param projectName project directory\n     * @param outputDir output dir (if null it's the same as the project)\n     * @throws Exception any exception generated during test\n     */\n    protected void testProject( String projectName, File outputDir )\n        throws Exception\n    {\n        File basedir = getTestFile( \"src/test/projects/\" + projectName );\n\n        MavenProjectBuilder builder = (MavenProjectBuilder) lookup( MavenProjectBuilder.ROLE );\n\n        EclipsePlugin plugin = new EclipsePlugin();\n\n        File repo = getTestFile( \"src/test/repository\" );\n\n        ArtifactRepositoryLayout localRepositoryLayout = (ArtifactRepositoryLayout) lookup(\n                                                                                            ArtifactRepositoryLayout.ROLE,\n                                                                                            \"legacy\" );\n\n        ArtifactRepository localRepository = new DefaultArtifactRepository( \"local\", \"file://\"\n            + repo.getCanonicalPath(), localRepositoryLayout );\n\n        MavenProject project = builder.buildWithDependencies( new File( basedir, \"pom.xml\" ), localRepository, null );\n\n        File projectOutputDir = basedir;\n\n        if ( outputDir == null )\n        {\n            outputDir = basedir;\n        }\n        else\n        {\n            outputDir.mkdirs();\n\n            projectOutputDir = new File( outputDir, project.getArtifactId() );\n        }\n\n        // Shouldn't PlexusTestCase at least offer a predefined log instance?\n        //  if ( log.isDebugEnabled() )\n        //  {\n        //    log.debug( \"basedir: \" + basedir + \"\\noutputdir: \" + outputDir + \"\\nprojectOutputDir: \" + projectOutputDir );\n        //  }\n\n        plugin.setOutputDir( outputDir );\n\n        for ( Iterator it = project.getArtifacts().iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            artifact.setFile( new File( localRepository.getBasedir(), localRepository.pathOf( artifact ) ) );\n        }\n\n        plugin.setProject( project );\n        plugin.setOutputDirectory( project.getBuild().getOutputDirectory() );\n\n        plugin.setLocalRepository( localRepository );\n\n        plugin.setArtifactFactory( (ArtifactFactory) lookup( ArtifactFactory.ROLE ) );\n        plugin.setArtifactResolver( (ArtifactResolver) lookup( ArtifactResolver.ROLE ) );\n        plugin.setRemoteArtifactRepositories( new ArrayList( 0 ) );\n\n        List projectNatures = new ArrayList();\n        projectNatures.add( \"org.eclipse.jdt.core.javanature\" );\n        plugin.setProjectnatures( projectNatures );\n\n        List buildcommands = new ArrayList();\n        buildcommands.add( \"org.eclipse.jdt.core.javabuilder\" );\n        plugin.setBuildcommands( buildcommands );\n\n        plugin.setClasspathContainers( new ArrayList() );\n\n        plugin.setDownloadSources( true );\n\n        plugin.setWtpversion( \"R7\" );\n\n        plugin.execute();\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"project\" ), new File( projectOutputDir,\n                                                                                                  \".project\" ) );\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"classpath\" ), new File( projectOutputDir,\n                                                                                                    \".classpath\" ) );\n\n        assertFileEquals( localRepository.getBasedir(), new File( basedir, \"wtpmodules\" ), new File( projectOutputDir,\n                                                                                                     \".wtpmodules\" ) );\n\n        if ( new File( basedir, \"settings\" ).exists() )\n        {\n            assertFileEquals( localRepository.getBasedir(), new File( basedir, \"settings\" ),\n                              new File( basedir, \".settings/org.eclipse.jdt.core.prefs\" ) );\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"protected void assertFileEquals( String mavenRepo, File expectedFile, File actualFile )\n        throws IOException\n    {\n        List expectedLines = getLines( mavenRepo, expectedFile );\n\n        List actualLines = getLines( mavenRepo, actualFile );\n\n        String basedir = getBasedir().replace( '\\\\', '/' );\n\n        for ( int i = 0; i < expectedLines.size(); i++ )\n        {\n            String expected = expectedLines.get( i ).toString();\n\n            // replace some vars in the expected line, to account\n            // for absolute paths that are different on each installation.\n\n            expected = StringUtils.replace( expected, \"${basedir}\", basedir );\n\n            if ( actualLines.size() <= i )\n            {\n                fail( \"Too few lines in the actual file. Was \" + actualLines.size() + \", expected: \"\n                    + expectedLines.size() );\n            }\n\n            String actual = actualLines.get( i ).toString();\n\n            if ( expected.startsWith( \"#\" ) && actual.startsWith( \"#\" ) )\n            {\n                //ignore comments, for settings file\n                continue;\n            }\n\n            assertEquals( \"Checking line #\" + ( i + 1 ), expected, actual );\n        }\n\n        assertTrue( \"Unequal number of lines.\", expectedLines.size() == actualLines.size() );\n    }","id":36365,"modified_method":"protected void assertFileEquals( String mavenRepo, File expectedFile, File actualFile )\n        throws IOException\n    {\n        List expectedLines = getLines( mavenRepo, expectedFile );\n        List actualLines = getLines( mavenRepo, actualFile );\n        String filename = actualFile.getName();\n\n        String basedir = new File( getBasedir() ).getCanonicalPath().replace( '\\\\', '/' );\n\n        for ( int i = 0; i < expectedLines.size(); i++ )\n        {\n            String expected = expectedLines.get( i ).toString();\n\n            // replace some vars in the expected line, to account\n            // for absolute paths that are different on each installation.\n            expected = StringUtils.replace( expected, \"${basedir}\", basedir );\n\n            if ( actualLines.size() <= i )\n            {\n                fail( \"Too few lines in the actual file. Was \" + actualLines.size() + \", expected: \"\n                    + expectedLines.size() );\n            }\n\n            String actual = actualLines.get( i ).toString();\n\n            if ( expected.startsWith( \"#\" ) && actual.startsWith( \"#\" ) )\n            {\n                //ignore comments, for settings file\n                continue;\n            }\n\n            assertEquals( \"Checking \" + filename + \", line #\" + ( i + 1 ), expected, actual );\n        }\n\n        assertTrue( \"Unequal number of lines.\", expectedLines.size() == actualLines.size() );\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public void execute()\n        throws MojoExecutionException\n    {\n\n        File workDir = new File( workspace, \".metadata/.plugins/org.eclipse.core.runtime/.settings\" ); //$NON-NLS-1$\n        workDir.mkdirs();\n\n        Properties props = new Properties();\n\n        File f = new File( workDir.getAbsolutePath(), \"org.eclipse.jdt.core.prefs\" ); //$NON-NLS-1$\n\n        // preserve old settings\n        if ( f.exists() )\n        {\n            try\n            {\n                props.load( new FileInputStream( f ) );\n            }\n            catch ( FileNotFoundException e )\n            {\n                throw new MojoExecutionException( Messages\n                    .getString( \"EclipsePlugin.cantreadfile\", f.getAbsolutePath() ), e ); //$NON-NLS-1$\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException( Messages\n                    .getString( \"EclipsePlugin.cantreadfile\", f.getAbsolutePath() ), e ); //$NON-NLS-1$\n            }\n        }\n\n        props.put( \"org.eclipse.jdt.core.classpathVariable.M2_REPO\", //$NON-NLS-1$\n                   StringUtils.replace( localRepository.getBasedir(), \":\", \"\\\\:\" ) ); //$NON-NLS-1$  //$NON-NLS-2$\n\n        try\n        {\n            OutputStream os = new FileOutputStream( f );\n            props.store( os, null );\n            os.close();\n        }\n        catch ( IOException ioe )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantwritetofile\", //$NON-NLS-1$\n                                                                  f.getAbsolutePath() ) );\n        }\n    }","id":36366,"modified_method":"public void execute()\n        throws MojoExecutionException\n    {\n\n        File workDir = new File( workspace, \".metadata/.plugins/org.eclipse.core.runtime/.settings\" ); //$NON-NLS-1$\n        workDir.mkdirs();\n\n        Properties props = new Properties();\n\n        File f = new File( workDir, \"org.eclipse.jdt.core.prefs\" ); //$NON-NLS-1$\n\n        // preserve old settings\n        if ( f.exists() )\n        {\n            try\n            {\n                props.load( new FileInputStream( f ) );\n            }\n            catch ( FileNotFoundException e )\n            {\n                throw new MojoExecutionException( Messages\n                    .getString( \"EclipsePlugin.cantreadfile\", f.getAbsolutePath() ), e ); //$NON-NLS-1$\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException( Messages\n                    .getString( \"EclipsePlugin.cantreadfile\", f.getAbsolutePath() ), e ); //$NON-NLS-1$\n            }\n        }\n\n        props.put( \"org.eclipse.jdt.core.classpathVariable.M2_REPO\", //$NON-NLS-1$\n                   StringUtils.replace( localRepository.getBasedir(), \":\", \"\\\\:\" ) ); //$NON-NLS-1$  //$NON-NLS-2$\n\n        try\n        {\n            OutputStream os = new FileOutputStream( f );\n            props.store( os, null );\n            os.close();\n        }\n        catch ( IOException ioe )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantwritetofile\", //$NON-NLS-1$\n                                                                  f.getAbsolutePath() ) );\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void addDependency( XMLWriter writer, Artifact artifact, List referencedReactorArtifacts,\n                               ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                               ArtifactFactory artifactFactory, List remoteArtifactRepositories )\n        throws MojoExecutionException\n    {\n\n        String path;\n        String kind;\n        String sourcepath = null;\n\n        if ( referencedReactorArtifacts.contains( artifact ) )\n        {\n            path = \"/\" + artifact.getArtifactId(); //$NON-NLS-1$\n            kind = \"src\"; //$NON-NLS-1$\n        }\n        else\n        {\n            File artifactPath = artifact.getFile();\n\n            if ( artifactPath == null )\n            {\n                log.error( Messages.getString( \"EclipsePlugin.artifactpathisnull\", artifact.getId() ) ); //$NON-NLS-1$\n                return;\n            }\n\n            if ( Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n            {\n                try\n                {\n                    path = StringUtils.replace( artifactPath.getCanonicalPath(), \"\\\\\", \"/\" );\n                }\n                catch ( IOException e )\n                {\n                    String message = Messages.getString( \"EclipsePlugin.cantcanonicalize\", artifactPath );\n\n                    throw new MojoExecutionException( message, e );\n                }\n\n                if ( log.isDebugEnabled() )\n                {\n                    log.debug( Messages.getString( \"EclipsePlugin.artifactissystemscoped\", //$NON-NLS-1$\n                                                   new Object[] { artifact.getArtifactId(), path } ) );\n                }\n\n                missingSourceArtifacts.add( artifact );\n\n                //                log.info( Messages.getString( \"EclipseClasspathWriter.sourcesnotavailable\", //$NON-NLS-1$\n                //                                              artifact.getArtifactId() ) );\n\n                kind = \"lib\"; //$NON-NLS-1$\n            }\n            else\n            {\n                File localRepositoryFile = new File( localRepository.getBasedir() );\n\n                String fullPath = artifactPath.getPath();\n\n                path = \"M2_REPO/\" //$NON-NLS-1$\n                    + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, fullPath, false );\n\n                Artifact sourceArtifact = retrieveSourceArtifact( artifact, remoteArtifactRepositories,\n                                                                  localRepository, artifactResolver, artifactFactory,\n                                                                  downloadSources );\n\n                if ( !sourceArtifact.isResolved() )\n                {\n\n                    missingSourceArtifacts.add( artifact );\n\n                    //                    if ( downloadSources )\n                    //                    {\n                    //                        log.info( Messages.getString( \"EclipseClasspathWriter.sourcesnotavailable\", //$NON-NLS-1$\n                    //                                                      sourceArtifact.getId() ) );\n                    //                    }\n                    //                    else\n                    //                    {\n                    //                        log.info( Messages.getString( \"EclipseClasspathWriter.sourcesnotdownloaded\", //$NON-NLS-1$\n                    //                                                      sourceArtifact.getId() ) );\n                    //                    }\n                }\n                else\n                {\n                    if ( log.isDebugEnabled() )\n                    {\n                        log.debug( Messages.getString( \"EclipseClasspathWriter.sourcesavailable\", //$NON-NLS-1$\n                                                       new Object[] {\n                                                           sourceArtifact.getId(),\n                                                           sourceArtifact.getFile().getAbsolutePath() } ) );\n                    }\n\n                    sourcepath = \"M2_REPO/\" //$NON-NLS-1$\n                        + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, sourceArtifact.getFile()\n                            .getAbsolutePath(), false );\n\n                }\n\n                kind = \"var\"; //$NON-NLS-1$\n            }\n\n        }\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", kind ); //$NON-NLS-1$\n        writer.addAttribute( \"path\", path ); //$NON-NLS-1$\n\n        if ( sourcepath != null )\n        {\n            writer.addAttribute( \"sourcepath\", sourcepath ); //$NON-NLS-1$\n        }\n\n        writer.endElement();\n\n    }","id":36367,"modified_method":"private void addDependency( XMLWriter writer, Artifact artifact, List referencedReactorArtifacts,\n                               ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                               ArtifactFactory artifactFactory, List remoteArtifactRepositories, File projectBaseDir )\n        throws MojoExecutionException\n    {\n\n        String path;\n        String kind;\n        String sourcepath = null;\n\n        if ( referencedReactorArtifacts.contains( artifact ) )\n        {\n            path = \"/\" + artifact.getArtifactId(); //$NON-NLS-1$\n            kind = \"src\"; //$NON-NLS-1$\n        }\n        else\n        {\n            File artifactPath = artifact.getFile();\n\n            if ( artifactPath == null )\n            {\n                log.error( Messages.getString( \"EclipsePlugin.artifactpathisnull\", artifact.getId() ) ); //$NON-NLS-1$\n                return;\n            }\n\n            if ( Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n            {\n                path = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, artifactPath, true );\n\n                if ( log.isDebugEnabled() )\n                {\n                    log.debug( Messages.getString( \"EclipsePlugin.artifactissystemscoped\", //$NON-NLS-1$\n                                                   new Object[] { artifact.getArtifactId(), path } ) );\n                }\n\n                missingSourceArtifacts.add( artifact );\n\n                kind = \"lib\"; //$NON-NLS-1$\n            }\n            else\n            {\n                File localRepositoryFile = new File( localRepository.getBasedir() );\n\n                String fullPath = artifactPath.getPath();\n\n                path = \"M2_REPO/\" //$NON-NLS-1$\n                    + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, new File( fullPath ), false );\n\n                Artifact sourceArtifact = retrieveSourceArtifact( artifact, remoteArtifactRepositories,\n                                                                  localRepository, artifactResolver, artifactFactory,\n                                                                  downloadSources );\n\n                if ( !sourceArtifact.isResolved() )\n                {\n                    missingSourceArtifacts.add( artifact );\n                }\n                else\n                {\n                    if ( log.isDebugEnabled() )\n                    {\n                        log.debug( Messages.getString( \"EclipseClasspathWriter.sourcesavailable\", //$NON-NLS-1$\n                                                       new Object[] {\n                                                           sourceArtifact.getId(),\n                                                           sourceArtifact.getFile().getAbsolutePath() } ) );\n                    }\n\n                    sourcepath = \"M2_REPO/\" //$NON-NLS-1$\n                        + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, sourceArtifact.getFile(), false );\n\n                }\n\n                kind = \"var\"; //$NON-NLS-1$\n            }\n\n        }\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", kind ); //$NON-NLS-1$\n        writer.addAttribute( \"path\", path ); //$NON-NLS-1$\n\n        if ( sourcepath != null )\n        {\n            writer.addAttribute( \"sourcepath\", sourcepath ); //$NON-NLS-1$\n        }\n\n        writer.endElement();\n\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * @param outputDirectory TODO\n     * @todo the list of needed parameters is really long, maybe this should become a Plexus component\n     */\n    protected void write( File projectBaseDir, File basedir, MavenProject project, List referencedReactorArtifacts,\n                         EclipseSourceDir[] sourceDirs, List classpathContainers, ArtifactRepository localRepository,\n                         ArtifactResolver artifactResolver, ArtifactFactory artifactFactory,\n                         List remoteArtifactRepositories, boolean downloadSources, String outputDirectory )\n        throws MojoExecutionException\n    {\n\n        this.downloadSources = downloadSources;\n\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( basedir, \".classpath\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"classpath\" ); //$NON-NLS-1$\n\n        // ----------------------------------------------------------------------\n        // Source roots and resources\n        // ----------------------------------------------------------------------\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n\n            writer.addAttribute( \"kind\", \"src\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", dir.getPath() ); //$NON-NLS-1$\n            if ( dir.getOutput() != null )\n            {\n                writer.addAttribute( \"output\", dir.getOutput() ); //$NON-NLS-1$\n            }\n\n            writer.endElement();\n\n        }\n\n        // ----------------------------------------------------------------------\n        // The default output\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"output\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, //$NON-NLS-1$  \n                                                                             outputDirectory, false ) );\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // The JRE reference\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", \"org.eclipse.jdt.launching.JRE_CONTAINER\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // The dependencies\n        // ----------------------------------------------------------------------\n\n        List artifacts = project.getTestArtifacts();\n\n        EclipseUtils.fixMissingOptionalArtifacts( artifacts, project.getDependencyArtifacts(), localRepository,\n                                                  artifactResolver, remoteArtifactRepositories, log );\n\n        EclipseUtils.fixSystemScopeArtifacts( artifacts, project.getDependencies() );\n\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            if ( artifact.getArtifactHandler().isAddedToClasspath() )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository, artifactResolver,\n                               artifactFactory, remoteArtifactRepositories );\n            }\n        }\n\n        // ----------------------------------------------------------------------\n        // Additional container classpath entries\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = classpathContainers.iterator(); it.hasNext(); )\n        {\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n            writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", (String) it.next() ); //$NON-NLS-1$\n            writer.endElement(); // name\n        }\n\n        writer.endElement();\n\n        IOUtil.close( w );\n\n        reportMissingSources();\n    }","id":36368,"modified_method":"/**\n     * @param outputDirectory TODO\n     * @todo the list of needed parameters is really long, maybe this should become a Plexus component\n     */\n    protected void write( File projectBaseDir, File basedir, MavenProject project, List referencedReactorArtifacts,\n                         EclipseSourceDir[] sourceDirs, List classpathContainers, ArtifactRepository localRepository,\n                         ArtifactResolver artifactResolver, ArtifactFactory artifactFactory,\n                         List remoteArtifactRepositories, boolean downloadSources, String outputDirectory )\n        throws MojoExecutionException\n    {\n\n        this.downloadSources = downloadSources;\n\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( basedir, \".classpath\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"classpath\" ); //$NON-NLS-1$\n\n        // ----------------------------------------------------------------------\n        // Source roots and resources\n        // ----------------------------------------------------------------------\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n\n            writer.addAttribute( \"kind\", \"src\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", dir.getPath() ); //$NON-NLS-1$\n            if ( dir.getOutput() != null )\n            {\n                writer.addAttribute( \"output\", dir.getOutput() ); //$NON-NLS-1$\n            }\n\n            writer.endElement();\n\n        }\n\n        // ----------------------------------------------------------------------\n        // The default output\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"output\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, //$NON-NLS-1$  \n                                                                             new File( outputDirectory ), false ) );\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // The JRE reference\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", \"org.eclipse.jdt.launching.JRE_CONTAINER\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // The dependencies\n        // ----------------------------------------------------------------------\n\n        List artifacts = project.getTestArtifacts();\n\n        EclipseUtils.fixMissingOptionalArtifacts( artifacts, project.getDependencyArtifacts(), localRepository,\n                                                  artifactResolver, remoteArtifactRepositories, log );\n\n        EclipseUtils.fixSystemScopeArtifacts( artifacts, project.getDependencies() );\n\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            if ( artifact.getArtifactHandler().isAddedToClasspath() )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository, artifactResolver,\n                               artifactFactory, remoteArtifactRepositories, projectBaseDir );\n            }\n        }\n\n        // ----------------------------------------------------------------------\n        // Additional container classpath entries\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = classpathContainers.iterator(); it.hasNext(); )\n        {\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n            writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", (String) it.next() ); //$NON-NLS-1$\n            writer.endElement(); // name\n        }\n\n        writer.endElement();\n\n        IOUtil.close( w );\n\n        reportMissingSources();\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * Convenience method to create a m2 command line from a given working directory.\n     *\n     * @param workingDir a not null working directory.\n     * @return the m2 command line\n     * @throws Exception any exception caught is thrown during tests\n     */\n    protected Commandline createMaven2CommandLine( File workingDir )\n        throws Exception\n    {\n\n        assertNotNull( \"workingDir can't be null\", workingDir );\n        assertTrue( \"workingDir must exist\", workingDir.exists() );\n\n        // read default settings and extract local repository path\n        MavenSettingsBuilder settingsBuilder = (MavenSettingsBuilder) lookup( MavenSettingsBuilder.ROLE );\n        Settings defaultSettings = settingsBuilder.buildSettings();\n\n        String settingsPath = createTestSettings( defaultSettings );\n\n        Commandline cmd = new Commandline();\n\n        cmd.setWorkingDirectory( workingDir.getAbsolutePath() );\n\n        cmd.setExecutable( \"mvn\" );\n        cmd.createArgument().setValue( \"-s\" + settingsPath );\n        cmd.createArgument().setValue( \"-e\" );\n\n        cmd.createArgument().setValue( \"eclipse:clean\" );\n        cmd.createArgument().setValue( \"eclipse:eclipse\" );\n\n        return cmd;\n    }","id":36369,"modified_method":"/**\n     * Convenience method to create a m2 command line from a given working directory.\n     *\n     * @param workingDir a not null working directory.\n     * @return the m2 command line\n     * @throws Exception any exception caught is thrown during tests\n     */\n    protected Commandline createMaven2CommandLine( File workingDir )\n        throws Exception\n    {\n\n        assertNotNull( \"workingDir can't be null\", workingDir );\n        assertTrue( \"workingDir must exist\", workingDir.exists() );\n\n        // read default settings and extract local repository path\n        MavenSettingsBuilder settingsBuilder = (MavenSettingsBuilder) lookup( MavenSettingsBuilder.ROLE );\n        Settings defaultSettings = settingsBuilder.buildSettings();\n\n        String settingsPath = createTestSettings( defaultSettings );\n\n        Commandline cmd = new Commandline();\n\n        cmd.setWorkingDirectory( workingDir.getCanonicalPath() );\n\n        cmd.setExecutable( \"mvn\" );\n        cmd.createArgument().setValue( \"-s\" + settingsPath );\n        cmd.createArgument().setValue( \"-e\" );\n\n        cmd.createArgument().setValue( \"eclipse:clean\" );\n        cmd.createArgument().setValue( \"eclipse:eclipse\" );\n\n        return cmd;\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public void testModule2Wtpmodules()\n        throws Exception\n    {\n        InputStream fis = new FileInputStream( new File( basedir, \"module-2/.wtpmodules\" ) );\n        String wtpmodules = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies: include only runtime (also optional) dependencies\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/direct-test\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-sysdep\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/direct-provided\" );\n\n        // referenced project: only runtime deps\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/module-1\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/refproject-compile\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/refproject-sysdep\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-provided\" );\n    }","id":36370,"modified_method":"public void testModule2Wtpmodules()\n        throws Exception\n    {\n        InputStream fis = new FileInputStream( new File( basedir, \"module-2/.wtpmodules\" ) );\n        String wtpmodules = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies: include only runtime (also optional) dependencies\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/direct-test\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-sysdep\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/direct-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/direct-provided\" );\n\n        // referenced project: only runtime deps\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/module-1\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/refproject-compile\" );\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"refproject-sysdep\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/refproject-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-direct-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid wtpmodules\", wtpmodules, \"/deps-refproject-provided\" );\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private String createTestSettings( Settings defaultSettings )\n        throws IOException\n    {\n        // prepare a temporary settings.xml\n        File settings = File.createTempFile( \"settings\", \".xml\" );\n        settings.deleteOnExit();\n        Writer w = new FileWriter( settings );\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n        writer.startElement( \"settings\" );\n\n        // keep default local repository\n        writer.startElement( \"localRepository\" );\n        writer.writeText( defaultSettings.getLocalRepository() );\n        writer.endElement();\n\n        writer.startElement( \"interactiveMode\" );\n        writer.writeText( \"false\" );\n        writer.endElement();\n\n        writer.startElement( \"mirrors\" );\n        writer.startElement( \"mirror\" );\n\n        // add a file mirror, so that dependencies are loaded from the plugin directory\n        writer.startElement( \"id\" );\n        writer.writeText( \"localtest\" );\n        writer.endElement();\n        writer.startElement( \"url\" );\n        writer.writeText( \"file://\" + getBasedir().replace( '\\\\', '/' ) + \"/src/test/m2repo\" );\n        writer.endElement();\n        writer.startElement( \"mirrorOf\" );\n        writer.writeText( \"central\" );\n        writer.endElement();\n\n        writer.endElement();\n        writer.endElement();\n\n        writer.endElement();\n        IOUtil.close( w );\n        settings.deleteOnExit();\n\n        return settings.getAbsolutePath();\n    }","id":36371,"modified_method":"private String createTestSettings( Settings defaultSettings )\n        throws IOException\n    {\n        // prepare a temporary settings.xml\n        File settings = File.createTempFile( \"settings\", \".xml\" );\n        settings.deleteOnExit();\n        Writer w = new FileWriter( settings );\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n        writer.startElement( \"settings\" );\n\n        // keep default local repository\n        writer.startElement( \"localRepository\" );\n        writer.writeText( defaultSettings.getLocalRepository() );\n        writer.endElement();\n\n        writer.startElement( \"interactiveMode\" );\n        writer.writeText( \"false\" );\n        writer.endElement();\n\n        writer.startElement( \"mirrors\" );\n        writer.startElement( \"mirror\" );\n\n        // add a file mirror, so that dependencies are loaded from the plugin directory\n        writer.startElement( \"id\" );\n        writer.writeText( \"localtest\" );\n        writer.endElement();\n        writer.startElement( \"url\" );\n        writer.writeText( \"file://\" + getBasedir().replace( '\\\\', '/' ) + \"/src/test/m2repo\" );\n        writer.endElement();\n        writer.startElement( \"mirrorOf\" );\n        writer.writeText( \"central\" );\n        writer.endElement();\n\n        writer.endElement();\n        writer.endElement();\n\n        writer.endElement();\n        IOUtil.close( w );\n        settings.deleteOnExit();\n\n        return settings.getCanonicalPath();\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public void testModule1Classpath()\n        throws Exception\n    {\n\n        InputStream fis = new FileInputStream( new File( basedir, \"module-1/.classpath\" ) );\n        String classpath = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies, include all\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-compile\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-sysdep\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-test\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-optional\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-provided\" );\n\n        // transitive dependencies\n        assertContains( \"Invalid classpath\", classpath, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-provided\" );\n\n    }","id":36372,"modified_method":"public void testModule1Classpath()\n        throws Exception\n    {\n\n        InputStream fis = new FileInputStream( new File( basedir, \"module-1/.classpath\" ) );\n        String classpath = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies, include all\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-compile\" );\n        assertContains( \"Invalid classpath\", classpath, \"refproject-sysdep\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-test\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-optional\" );\n        assertContains( \"Invalid classpath\", classpath, \"/refproject-provided\" );\n\n        // transitive dependencies\n        assertContains( \"Invalid classpath\", classpath, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-provided\" );\n\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public void testModule2Classpath()\n        throws Exception\n    {\n        InputStream fis = new FileInputStream( new File( basedir, \"module-2/.classpath\" ) );\n        String classpath = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies: include all\n        assertContains( \"Invalid classpath\", classpath, \"/direct-compile\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-test\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-sysdep\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-optional\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-provided\" );\n\n        // referenced project: not required, but it's not a problem to have them included\n        assertContains( \"Invalid classpath\", classpath, \"/module-1\" );\n        // assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-compile\" );\n        // assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-sysdep\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid classpath\", classpath, \"/deps-direct-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-optional\" );\n        // @todo should this be included? see MNG-514\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid classpath\", classpath, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-provided\" );\n    }","id":36373,"modified_method":"public void testModule2Classpath()\n        throws Exception\n    {\n        InputStream fis = new FileInputStream( new File( basedir, \"module-2/.classpath\" ) );\n        String classpath = IOUtil.toString( fis );\n        IOUtil.close( fis );\n\n        // direct dependencies: include all\n        assertContains( \"Invalid classpath\", classpath, \"/direct-compile\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-test\" );\n        assertContains( \"Invalid classpath\", classpath, \"direct-sysdep\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-optional\" );\n        assertContains( \"Invalid classpath\", classpath, \"/direct-provided\" );\n\n        // referenced project: not required, but it's not a problem to have them included\n        assertContains( \"Invalid classpath\", classpath, \"/module-1\" );\n        // assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-compile\" );\n        // assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-sysdep\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/refproject-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid classpath\", classpath, \"/deps-direct-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-optional\" );\n        // @todo should this be included? see MNG-514\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-direct-provided\" );\n\n        // transitive dependencies from referenced projects\n        assertContains( \"Invalid classpath\", classpath, \"/deps-refproject-compile\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-test\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-optional\" );\n        assertDoesNotContain( \"Invalid classpath\", classpath, \"/deps-refproject-provided\" );\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void addResourceLinks( XMLWriter writer, File projectBaseDir, File basedir, List sourceRoots )\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n            String resourceDir = ( (Resource) it.next() ).getDirectory();\n\n            if ( new File( resourceDir ).isDirectory() )\n            {\n                writer.startElement( \"link\" ); //$NON-NLS-1$\n\n                writer.startElement( \"name\" ); //$NON-NLS-1$\n                writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, resourceDir, true ) );\n                writer.endElement(); // name\n\n                writer.startElement( \"type\" ); //$NON-NLS-1$\n                writer.writeText( \"2\" ); //$NON-NLS-1$\n                writer.endElement(); // type\n\n                writer.startElement( \"location\" ); //$NON-NLS-1$\n                writer.writeText( resourceDir.replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n                writer.endElement(); // location\n\n                writer.endElement(); // link\n            }\n        }\n    }","id":36374,"modified_method":"private void addResourceLinks( XMLWriter writer, File projectBaseDir, File basedir, List sourceRoots )\n        throws MojoExecutionException\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n            String resourceDirString = ( (Resource) it.next() ).getDirectory();\n            File resourceDir = new File( resourceDirString );\n\n            if ( resourceDir.isDirectory() )\n            {\n                writer.startElement( \"link\" ); //$NON-NLS-1$\n\n                writer.startElement( \"name\" ); //$NON-NLS-1$\n                writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, resourceDir, true ) );\n                writer.endElement(); // name\n\n                writer.startElement( \"type\" ); //$NON-NLS-1$\n                writer.writeText( \"2\" ); //$NON-NLS-1$\n                writer.endElement(); // type\n\n                writer.startElement( \"location\" ); //$NON-NLS-1$\n                try\n                {\n                    writer.writeText( resourceDir.getCanonicalPath().replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n                }\n                catch ( IOException e )\n                {\n                    throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantcanonicalize\", resourceDir\n                        .getAbsolutePath() ), e );\n                }\n                writer.endElement(); // location\n\n                writer.endElement(); // link\n            }\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void addSourceLinks( XMLWriter writer, File projectBaseDir, File basedir, List sourceRoots )\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n            String sourceRoot = (String) it.next();\n\n            if ( new File( sourceRoot ).isDirectory() )\n            {\n                writer.startElement( \"link\" ); //$NON-NLS-1$\n\n                writer.startElement( \"name\" ); //$NON-NLS-1$\n                writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, sourceRoot, true ) );\n                writer.endElement(); // name\n\n                writer.startElement( \"type\" ); //$NON-NLS-1$\n                writer.writeText( \"2\" ); //$NON-NLS-1$\n                writer.endElement(); // type\n\n                writer.startElement( \"location\" ); //$NON-NLS-1$\n                writer.writeText( sourceRoot.replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n                writer.endElement(); // location\n\n                writer.endElement(); // link\n            }\n        }\n    }","id":36375,"modified_method":"private void addSourceLinks( XMLWriter writer, File projectBaseDir, File basedir, List sourceRoots )\n        throws MojoExecutionException\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n            String sourceRootString = (String) it.next();\n            File sourceRoot = new File( sourceRootString );\n\n            if ( sourceRoot.isDirectory() )\n            {\n                writer.startElement( \"link\" ); //$NON-NLS-1$\n\n                writer.startElement( \"name\" ); //$NON-NLS-1$\n                writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, sourceRoot, true ) );\n                writer.endElement(); // name\n\n                writer.startElement( \"type\" ); //$NON-NLS-1$\n                writer.writeText( \"2\" ); //$NON-NLS-1$\n                writer.endElement(); // type\n\n                writer.startElement( \"location\" ); //$NON-NLS-1$\n                try\n                {\n                    writer.writeText( sourceRoot.getCanonicalPath().replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n                }\n                catch ( IOException e )\n                {\n                    throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantcanonicalize\", sourceRoot\n                        .getAbsolutePath() ), e );\n                }\n\n                writer.endElement(); // location\n\n                writer.endElement(); // link\n            }\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void addFileLink( XMLWriter writer, File projectBaseDir, File basedir, File file )\n    {\n        if ( file.isFile() )\n        {\n            writer.startElement( \"link\" ); //$NON-NLS-1$\n\n            writer.startElement( \"name\" ); //$NON-NLS-1$\n            writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, file.toString(), true ) );\n            writer.endElement(); // name\n\n            writer.startElement( \"type\" ); //$NON-NLS-1$\n            writer.writeText( \"1\" ); //$NON-NLS-1$\n            writer.endElement(); // type\n\n            writer.startElement( \"location\" ); //$NON-NLS-1$\n            writer.writeText( file.toString().replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.endElement(); // location\n\n            writer.endElement(); // link\n        }\n        else\n        {\n            log.warn( Messages.getString( \"EclipseProjectWriter.notafile\", file ) ); //$NON-NLS-1$\n        }\n    }","id":36376,"modified_method":"private void addFileLink( XMLWriter writer, File projectBaseDir, File basedir, File file )\n        throws MojoExecutionException\n    {\n        if ( file.isFile() )\n        {\n            writer.startElement( \"link\" ); //$NON-NLS-1$\n\n            writer.startElement( \"name\" ); //$NON-NLS-1$\n            writer.writeText( EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, file, true ) );\n            writer.endElement(); // name\n\n            writer.startElement( \"type\" ); //$NON-NLS-1$\n            writer.writeText( \"1\" ); //$NON-NLS-1$\n            writer.endElement(); // type\n\n            writer.startElement( \"location\" ); //$NON-NLS-1$\n            try\n            {\n                writer.writeText( file.getCanonicalPath().replaceAll( \"\\\\\\\\\", \"/\" ) ); //$NON-NLS-1$ //$NON-NLS-2$\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantcanonicalize\", file\n                    .getAbsolutePath() ), e );\n            }\n            writer.endElement(); // location\n\n            writer.endElement(); // link\n        }\n        else\n        {\n            log.warn( Messages.getString( \"EclipseProjectWriter.notafile\", file ) ); //$NON-NLS-1$\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"protected void write( File projectBaseDir, File outputDir, MavenProject project )\n        throws MojoExecutionException\n    {\n\n        // check if it's necessary to create project specific settings\n        Properties coreSettings = new Properties();\n\n        String source = EclipseUtils.getPluginSetting( project, \"maven-compiler-plugin\", \"source\",\n                                                       null ); //$NON-NLS-1$ //$NON-NLS-2$\n        String target = EclipseUtils.getPluginSetting( project, \"maven-compiler-plugin\", \"target\",\n                                                       null ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        if ( source != null && !\"1.3\".equals( source ) ) //$NON-NLS-1$\n        {\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.source\", source ); //$NON-NLS-1$\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.compliance\", source ); //$NON-NLS-1$\n        }\n\n        if ( target != null && !\"1.2\".equals( target ) ) //$NON-NLS-1$\n        {\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.codegen.targetPlatform\", target ); //$NON-NLS-1$\n        }\n              \n        // write the settings, if needed\n        if ( !coreSettings.isEmpty() )\n        {\n            File settingsDir = new File( outputDir, \"/.settings\" ); //$NON-NLS-1$\n                                  \n            settingsDir.mkdirs();\n\n            coreSettings.put( \"eclipse.preferences.version\", \"1\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            try\n            {\n                File oldCoreSettingsFile;\n                \n                File coreSettingsFile = new File( settingsDir, \"org.eclipse.jdt.core.prefs\" ); //$NON-NLS-1$\n                \n                if( coreSettingsFile.exists() )\n                {\n                    oldCoreSettingsFile = coreSettingsFile;\n                    \n                    Properties props = new Properties();\n                    \n                    props.load( new FileInputStream( oldCoreSettingsFile ) );\n                    \n                    if( !props.equals( coreSettings ) )\n                    {\n                        coreSettings.store( new FileOutputStream( coreSettingsFile ), null );\n                    }\n                }\n                else\n                {\n                    coreSettings.store( new FileOutputStream( coreSettingsFile ), null );\n\n                    log.info( Messages.getString( \"EclipseSettingsWriter.wrotesettings\", //$NON-NLS-1$\n                                                  coreSettingsFile.getAbsolutePath() ) );\n                }\n            }\n            catch ( FileNotFoundException e )\n            {\n                throw new MojoExecutionException( Messages.getString( \"EclipseSettingsWriter.cannotcreatesettings\" ),\n                                                  e ); //$NON-NLS-1$\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException( Messages.getString( \"EclipseSettingsWriter.errorwritingsettings\" ),\n                                                  e ); //$NON-NLS-1$\n            }\n        }\n        else\n        {\n            log.info( Messages.getString( \"EclipseSettingsWriter.usingdefaults\" ) ); //$NON-NLS-1$\n        }\n    }","id":36377,"modified_method":"protected void write( File projectBaseDir, File outputDir, MavenProject project )\n        throws MojoExecutionException\n    {\n\n        // check if it's necessary to create project specific settings\n        Properties coreSettings = new Properties();\n\n        String source = EclipseUtils.getPluginSetting( project, \"maven-compiler-plugin\", \"source\",\n                                                       null ); //$NON-NLS-1$ //$NON-NLS-2$\n        String target = EclipseUtils.getPluginSetting( project, \"maven-compiler-plugin\", \"target\",\n                                                       null ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        if ( source != null && !\"1.3\".equals( source ) ) //$NON-NLS-1$\n        {\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.source\", source ); //$NON-NLS-1$\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.compliance\", source ); //$NON-NLS-1$\n        }\n\n        if ( target != null && !\"1.2\".equals( target ) ) //$NON-NLS-1$\n        {\n            coreSettings.put( \"org.eclipse.jdt.core.compiler.codegen.targetPlatform\", target ); //$NON-NLS-1$\n        }\n              \n        // write the settings, if needed\n        if ( !coreSettings.isEmpty() )\n        {\n            File settingsDir = new File( outputDir, \"/.settings\" ); //$NON-NLS-1$\n                                  \n            settingsDir.mkdirs();\n\n            coreSettings.put( \"eclipse.preferences.version\", \"1\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            try\n            {\n                File oldCoreSettingsFile;\n                \n                File coreSettingsFile = new File( settingsDir, \"org.eclipse.jdt.core.prefs\" ); //$NON-NLS-1$\n                \n                if( coreSettingsFile.exists() )\n                {\n                    oldCoreSettingsFile = coreSettingsFile;\n                    \n                    Properties props = new Properties();\n                    \n                    props.load( new FileInputStream( oldCoreSettingsFile ) );\n                    \n                    if( !props.equals( coreSettings ) )\n                    {\n                        coreSettings.store( new FileOutputStream( coreSettingsFile ), null );\n                    }\n                }\n                else\n                {\n                    coreSettings.store( new FileOutputStream( coreSettingsFile ), null );\n\n                    log.info( Messages.getString( \"EclipseSettingsWriter.wrotesettings\", //$NON-NLS-1$\n                                                  coreSettingsFile.getCanonicalPath() ) );\n                }\n            }\n            catch ( FileNotFoundException e )\n            {\n                throw new MojoExecutionException( Messages.getString( \"EclipseSettingsWriter.cannotcreatesettings\" ),\n                                                  e ); //$NON-NLS-1$\n            }\n            catch ( IOException e )\n            {\n                throw new MojoExecutionException( Messages.getString( \"EclipseSettingsWriter.errorwritingsettings\" ),\n                                                  e ); //$NON-NLS-1$\n            }\n        }\n        else\n        {\n            log.info( Messages.getString( \"EclipseSettingsWriter.usingdefaults\" ) ); //$NON-NLS-1$\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private static void extractSourceDirs( Set directories, List sourceRoots, File basedir, File projectBaseDir,\n                                          boolean test, String output )\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n            String sourceRoot = (String) it.next();\n\n            if ( new File( sourceRoot ).isDirectory() )\n            {\n                sourceRoot = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, sourceRoot, !projectBaseDir\n                    .equals( basedir ) );\n\n                directories.add( new EclipseSourceDir( sourceRoot, output, test, null, null ) );\n            }\n        }\n    }","id":36378,"modified_method":"private static void extractSourceDirs( Set directories, List sourceRoots, File basedir, File projectBaseDir,\n                                          boolean test, String output )\n        throws MojoExecutionException\n    {\n        for ( Iterator it = sourceRoots.iterator(); it.hasNext(); )\n        {\n\n            File sourceRootFile = new File( (String) it.next() );\n\n            if ( sourceRootFile.isDirectory() )\n            {\n                String sourceRoot = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, sourceRootFile,\n                                                                            !projectBaseDir.equals( basedir ) );\n\n                directories.add( new EclipseSourceDir( sourceRoot, output, test, null, null ) );\n            }\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public static EclipseSourceDir[] buildDirectoryList( MavenProject project, File basedir, Log log,\n                                                        String outputDirectory )\n    {\n        File projectBaseDir = project.getFile().getParentFile();\n\n        // avoid duplicated entries\n        Set directories = new TreeSet();\n\n        EclipseUtils.extractSourceDirs( directories, project.getCompileSourceRoots(), basedir, projectBaseDir, false,\n                                        null );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getResources(), project, basedir,\n                                          projectBaseDir, false, null, log );\n\n        // If using the standard output location, don't mix the test output into it.\n        String testOutput = outputDirectory.equals( project.getBuild().getOutputDirectory() ) ? EclipseUtils\n            .toRelativeAndFixSeparator( projectBaseDir, project.getBuild().getTestOutputDirectory(), false ) : null;\n\n        EclipseUtils.extractSourceDirs( directories, project.getTestCompileSourceRoots(), basedir, projectBaseDir,\n                                        true, testOutput );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getTestResources(), project, basedir,\n                                          projectBaseDir, true, testOutput, log );\n\n        return (EclipseSourceDir[]) directories.toArray( new EclipseSourceDir[directories.size()] );\n    }","id":36379,"modified_method":"public static EclipseSourceDir[] buildDirectoryList( MavenProject project, File basedir, Log log,\n                                                        String outputDirectory )\n        throws MojoExecutionException\n    {\n        File projectBaseDir = project.getFile().getParentFile();\n\n        // avoid duplicated entries\n        Set directories = new TreeSet();\n\n        EclipseUtils.extractSourceDirs( directories, project.getCompileSourceRoots(), basedir, projectBaseDir, false,\n                                        null );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getResources(), project, basedir,\n                                          projectBaseDir, false, null, log );\n\n        // If using the standard output location, don't mix the test output into it.\n        String testOutput = outputDirectory.equals( project.getBuild().getOutputDirectory() ) ? EclipseUtils\n            .toRelativeAndFixSeparator( projectBaseDir, new File( project.getBuild().getTestOutputDirectory() ), false )\n                                                                                             : null;\n\n        EclipseUtils.extractSourceDirs( directories, project.getTestCompileSourceRoots(), basedir, projectBaseDir,\n                                        true, testOutput );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getTestResources(), project, basedir,\n                                          projectBaseDir, true, testOutput, log );\n\n        return (EclipseSourceDir[]) directories.toArray( new EclipseSourceDir[directories.size()] );\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private static void extractResourceDirs( Set directories, List resources, MavenProject project, File basedir,\n                                            File projectBaseDir, boolean test, String output, Log log )\n    {\n        for ( Iterator it = resources.iterator(); it.hasNext(); )\n        {\n\n            Resource resource = (Resource) it.next();\n            String includePattern = null;\n            String excludePattern = null;\n\n            if ( resource.getIncludes().size() != 0 )\n            {\n                // @todo includePattern = ?\n                log.warn( Messages.getString( \"EclipsePlugin.includenotsupported\" ) ); //$NON-NLS-1$\n            }\n\n            if ( resource.getExcludes().size() != 0 )\n            {\n                // @todo excludePattern = ?\n                log.warn( Messages.getString( \"EclipsePlugin.excludenotsupported\" ) ); //$NON-NLS-1$\n            }\n\n            //          Example of setting include/exclude patterns for future reference.\n            //\n            //          TODO: figure out how to merge if the same dir is specified twice\n            //          with different in/exclude patterns. We can't write them now,\n            //                      since only the the first one would be included.\n            //\n            //          if ( resource.getIncludes().size() != 0 )\n            //          {\n            //              writer.addAttribute(\n            //                      \"including\", StringUtils.join( resource.getIncludes().iterator(), \"|\" )\n            //                      );\n            //          }\n            //\n            //          if ( resource.getExcludes().size() != 0 )\n            //          {\n            //              writer.addAttribute(\n            //                      \"excluding\", StringUtils.join( resource.getExcludes().iterator(), \"|\" )\n            //              );\n            //          }\n\n            if ( !StringUtils.isEmpty( resource.getTargetPath() ) )\n            {\n                output = resource.getTargetPath();\n            }\n\n            File resourceDirectory = new File( resource.getDirectory() );\n\n            if ( !resourceDirectory.exists() || !resourceDirectory.isDirectory() )\n            {\n                continue;\n            }\n\n            String resourceDir = resource.getDirectory();\n            resourceDir = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, resourceDir, !projectBaseDir\n                .equals( basedir ) );\n\n            if ( output != null )\n            {\n                output = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, output, false );\n            }\n\n            directories.add( new EclipseSourceDir( resourceDir, output, test, includePattern, excludePattern ) );\n        }\n    }","id":36380,"modified_method":"private static void extractResourceDirs( Set directories, List resources, MavenProject project, File basedir,\n                                            File projectBaseDir, boolean test, String output, Log log )\n        throws MojoExecutionException\n    {\n        for ( Iterator it = resources.iterator(); it.hasNext(); )\n        {\n            Resource resource = (Resource) it.next();\n            String includePattern = null;\n            String excludePattern = null;\n\n            if ( resource.getIncludes().size() != 0 )\n            {\n                // @todo includePattern = ?\n                log.warn( Messages.getString( \"EclipsePlugin.includenotsupported\" ) ); //$NON-NLS-1$\n            }\n\n            if ( resource.getExcludes().size() != 0 )\n            {\n                // @todo excludePattern = ?\n                log.warn( Messages.getString( \"EclipsePlugin.excludenotsupported\" ) ); //$NON-NLS-1$\n            }\n\n            //          Example of setting include/exclude patterns for future reference.\n            //\n            //          TODO: figure out how to merge if the same dir is specified twice\n            //          with different in/exclude patterns. We can't write them now,\n            //                      since only the the first one would be included.\n            //\n            //          if ( resource.getIncludes().size() != 0 )\n            //          {\n            //              writer.addAttribute(\n            //                      \"including\", StringUtils.join( resource.getIncludes().iterator(), \"|\" )\n            //                      );\n            //          }\n            //\n            //          if ( resource.getExcludes().size() != 0 )\n            //          {\n            //              writer.addAttribute(\n            //                      \"excluding\", StringUtils.join( resource.getExcludes().iterator(), \"|\" )\n            //              );\n            //          }\n\n            if ( !StringUtils.isEmpty( resource.getTargetPath() ) )\n            {\n                output = resource.getTargetPath();\n            }\n\n            File resourceDirectory = new File( resource.getDirectory() );\n\n            if ( !resourceDirectory.exists() || !resourceDirectory.isDirectory() )\n            {\n                continue;\n            }\n\n            String resourceDir = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, resourceDirectory,\n                                                                         !projectBaseDir.equals( basedir ) );\n\n            if ( output != null )\n            {\n                File outputFile = new File( projectBaseDir, output );\n                // create output dir if it doesn't exist\n                outputFile.mkdirs();\n                output = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, outputFile, false );\n            }\n\n            directories.add( new EclipseSourceDir( resourceDir, output, test, includePattern, excludePattern ) );\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public static String toRelativeAndFixSeparator( File basedir, String absolutePath, boolean replaceSlashes )\n    {\n        String relative;\n\n        if ( absolutePath.equals( basedir.getAbsolutePath() ) )\n        {\n            relative = \".\";\n        }\n        else if ( absolutePath.startsWith( basedir.getAbsolutePath() ) )\n        {\n            relative = absolutePath.substring( basedir.getAbsolutePath().length() + 1 );\n        }\n        else\n        {\n            relative = absolutePath;\n        }\n\n        relative = StringUtils.replace( relative, \"\\\\\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        if ( replaceSlashes )\n        {\n            relative = StringUtils.replace( relative, \"/\", \"-\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        }\n\n        return relative;\n    }","id":36381,"modified_method":"public static String toRelativeAndFixSeparator( File basedir, File fileToAdd, boolean replaceSlashes )\n        throws MojoExecutionException\n    {\n        String basedirpath;\n        String absolutePath;\n\n        try\n        {\n            basedirpath = basedir.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantcanonicalize\", basedir\n                .getAbsolutePath() ), e );\n        }\n\n        try\n        {\n            absolutePath = fileToAdd.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.cantcanonicalize\", fileToAdd\n                .getAbsolutePath() ), e );\n        }\n\n        String relative;\n\n        if ( absolutePath.equals( basedirpath ) )\n        {\n            relative = \".\";\n        }\n        else if ( absolutePath.startsWith( basedirpath ) )\n        {\n            relative = absolutePath.substring( basedirpath.length() + 1 );\n        }\n        else\n        {\n            relative = absolutePath;\n        }\n\n        relative = StringUtils.replace( relative, \"\\\\\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        if ( replaceSlashes )\n        {\n            relative = StringUtils.replace( relative, \"/\", \"-\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        }\n\n        return relative;\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void writeWarOrEarResources( XMLWriter writer, MavenProject project, List referencedReactorArtifacts,\n                                        ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                                        List remoteArtifactRepositories )\n    {\n        Set artifacts = project.getArtifacts();\n\n        EclipseUtils.fixMissingOptionalArtifacts( artifacts, project.getDependencyArtifacts(), localRepository,\n                                                  artifactResolver, remoteArtifactRepositories, log );\n\n        EclipseUtils.fixSystemScopeArtifacts( artifacts, project.getDependencies() );\n\n        ScopeArtifactFilter scopeFilter = new ScopeArtifactFilter( Artifact.SCOPE_RUNTIME );\n\n        // dependencies\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            String type = artifact.getType();\n\n            // NB war is needed for ear projects, we suppose nobody adds a war dependency to a war/jar project\n            if ( ( scopeFilter.include( artifact ) || Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n                && ( \"jar\".equals( type ) || \"ejb\".equals( type ) || \"ejb-client\".equals( type ) || \"war\".equals( type ) ) )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository );\n            }\n        }\n    }","id":36382,"modified_method":"private void writeWarOrEarResources( XMLWriter writer, MavenProject project, List referencedReactorArtifacts,\n                                        ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                                        List remoteArtifactRepositories )\n        throws MojoExecutionException\n    {\n        Set artifacts = project.getArtifacts();\n\n        EclipseUtils.fixMissingOptionalArtifacts( artifacts, project.getDependencyArtifacts(), localRepository,\n                                                  artifactResolver, remoteArtifactRepositories, log );\n\n        EclipseUtils.fixSystemScopeArtifacts( artifacts, project.getDependencies() );\n\n        ScopeArtifactFilter scopeFilter = new ScopeArtifactFilter( Artifact.SCOPE_RUNTIME );\n\n        // dependencies\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            String type = artifact.getType();\n\n            // NB war is needed for ear projects, we suppose nobody adds a war dependency to a war/jar project\n            if ( ( scopeFilter.include( artifact ) || Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n                && ( \"jar\".equals( type ) || \"ejb\".equals( type ) || \"ejb-client\".equals( type ) || \"war\".equals( type ) ) )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository, project.getBasedir() );\n            }\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\n     * @param project\n     * @param writer\n     * @param packaging\n     */\n    private void writeModuleTypeAccordingToPackaging( MavenProject project, XMLWriter writer, String packaging )\n    {\n        if ( \"war\".equals( packaging ) ) //$NON-NLS-1$\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.web\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n\n            // defaults to 2.4, try to detect real version from dependencies\n            String servletVersion = \"2.4\"; //$NON-NLS-1$\n\n            for ( Iterator it = project.getArtifacts().iterator(); it.hasNext(); )\n            {\n                Artifact artifact = (Artifact) it.next();\n                if ( \"servlet-api\".equals( artifact.getArtifactId() ) //$NON-NLS-1$\n                    || \"servletapi\".equals( artifact.getArtifactId() ) // $NON-NLS-1$\n                    || \"geronimo-spec-servlet\".equals( artifact.getArtifactId() ) ) //$NON-NLS-1$\n                {\n                    servletVersion = StringUtils.substring( artifact.getVersion(), 0, 3 );\n                }\n                else if ( \"geronimo-spec-j2ee\".equals( artifact.getArtifactId() ) ) // $NON-NLS-1$\n                {\n                    String j2eeMinorVersion = StringUtils.substring( artifact.getVersion(), 2, 3 );\n                    servletVersion = \"2.\" + j2eeMinorVersion;\n                }\n            }\n\n            writer.writeText( servletVersion );\n            writer.endElement();\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"context-root\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", project.getArtifactId() ); //$NON-NLS-1$\n            writer.endElement();\n        }\n        else if ( \"ejb\".equals( packaging ) ) //$NON-NLS-1$\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.ejb\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n            writer.writeText( \"2.1\" ); //$NON-NLS-1$\n            // @todo this is the default, find real ejb version from dependencies\n            writer.endElement();\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"java-output-path\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", \"/\" + //$NON-NLS-1$ //$NON-NLS-2$\n                EclipseUtils.toRelativeAndFixSeparator( project.getBasedir(), project.getBuild().getOutputDirectory(),\n                                                        false ) );\n            writer.endElement();\n        }\n        else if ( \"ear\".equals( packaging ) )\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.ear\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n            writer.writeText( \"1.3\" ); //$NON-NLS-1$\n            // @todo 1.3 is the default\n            writer.endElement();\n        }\n        else\n        {\n            // jar\n            writer.addAttribute( \"module-type-id\", \"jst.utility\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"java-output-path\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", \"/\" + //$NON-NLS-1$ //$NON-NLS-2$\n                EclipseUtils.toRelativeAndFixSeparator( project.getBasedir(), project.getBuild().getOutputDirectory(),\n                                                        false ) );\n            writer.endElement();\n        }\n    }","id":36383,"modified_method":"/**\n     * @param project\n     * @param writer\n     * @param packaging\n     * @throws MojoExecutionException \n     */\n    private void writeModuleTypeAccordingToPackaging( MavenProject project, XMLWriter writer, String packaging )\n        throws MojoExecutionException\n    {\n        if ( \"war\".equals( packaging ) ) //$NON-NLS-1$\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.web\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n\n            // defaults to 2.4, try to detect real version from dependencies\n            String servletVersion = \"2.4\"; //$NON-NLS-1$\n\n            for ( Iterator it = project.getArtifacts().iterator(); it.hasNext(); )\n            {\n                Artifact artifact = (Artifact) it.next();\n                if ( \"servlet-api\".equals( artifact.getArtifactId() ) //$NON-NLS-1$\n                    || \"servletapi\".equals( artifact.getArtifactId() ) // $NON-NLS-1$\n                    || \"geronimo-spec-servlet\".equals( artifact.getArtifactId() ) ) //$NON-NLS-1$\n                {\n                    servletVersion = StringUtils.substring( artifact.getVersion(), 0, 3 );\n                }\n                else if ( \"geronimo-spec-j2ee\".equals( artifact.getArtifactId() ) ) // $NON-NLS-1$\n                {\n                    String j2eeMinorVersion = StringUtils.substring( artifact.getVersion(), 2, 3 );\n                    servletVersion = \"2.\" + j2eeMinorVersion;\n                }\n            }\n\n            writer.writeText( servletVersion );\n            writer.endElement();\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"context-root\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", project.getArtifactId() ); //$NON-NLS-1$\n            writer.endElement();\n        }\n        else if ( \"ejb\".equals( packaging ) ) //$NON-NLS-1$\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.ejb\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n            writer.writeText( \"2.1\" ); //$NON-NLS-1$\n            // @todo this is the default, find real ejb version from dependencies\n            writer.endElement();\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"java-output-path\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", \"/\" + //$NON-NLS-1$ //$NON-NLS-2$\n                EclipseUtils.toRelativeAndFixSeparator( project.getBasedir(), new File( project.getBuild()\n                    .getOutputDirectory() ), false ) );\n            writer.endElement();\n        }\n        else if ( \"ear\".equals( packaging ) )\n        {\n            writer.addAttribute( \"module-type-id\", \"jst.ear\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"version\" ); //$NON-NLS-1$\n            writer.writeText( \"1.3\" ); //$NON-NLS-1$\n            // @todo 1.3 is the default\n            writer.endElement();\n        }\n        else\n        {\n            // jar\n            writer.addAttribute( \"module-type-id\", \"jst.utility\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n            writer.startElement( \"property\" ); //$NON-NLS-1$\n            writer.addAttribute( \"name\", \"java-output-path\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"value\", \"/\" + //$NON-NLS-1$ //$NON-NLS-2$\n                EclipseUtils.toRelativeAndFixSeparator( project.getBasedir(), new File( project.getBuild()\n                    .getOutputDirectory() ), false ) );\n            writer.endElement();\n        }\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"private void addDependency( XMLWriter writer, Artifact artifact, List referencedReactorProjects,\n                               ArtifactRepository localRepository )\n    {\n        String handle;\n\n        if ( referencedReactorProjects.contains( artifact ) )\n        {\n            //  <dependent-module deploy-path=\"/WEB-INF/lib\" handle=\"module:/resource/artifactid/artifactid\">\n            //    <dependency-type>uses<\/dependency-type>\n            //  <\/dependent-module>\n\n            handle = \"module:/resource/\" + artifact.getArtifactId() + \"/\" + artifact.getArtifactId(); //$NON-NLS-1$ //$NON-NLS-2$\n        }\n        else\n        {\n            // <dependent-module deploy-path=\"/WEB-INF/lib\" handle=\"module:/classpath/var/M2_REPO/cl/cl/2.1/cl-2.1.jar\">\n            //    <dependency-type>uses<\/dependency-type>\n            // <\/dependent-module>\n\n            File artifactPath = artifact.getFile();\n\n            if ( artifactPath == null )\n            {\n                log.error( Messages.getString( \"EclipsePlugin.artifactpathisnull\", artifact.getId() ) ); //$NON-NLS-1$\n                return;\n            }\n\n            String fullPath = artifactPath.getPath();\n\n            if ( Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n            {\n                handle = \"module:/classpath/lib/\" //$NON-NLS-1$\n                    + StringUtils.replace( fullPath, \"\\\\\", \"/\" );\n            }\n            else\n            {\n                File localRepositoryFile = new File( localRepository.getBasedir() );\n\n                handle = \"module:/classpath/var/M2_REPO/\" //$NON-NLS-1$\n                    + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, fullPath, false );\n            }\n        }\n\n        writer.startElement( \"dependent-module\" ); //$NON-NLS-1$\n\n        writer.addAttribute( \"deploy-path\", \"/WEB-INF/lib\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"handle\", handle ); //$NON-NLS-1$\n\n        writer.startElement( \"dependency-type\" ); //$NON-NLS-1$\n        writer.writeText( \"uses\" ); //$NON-NLS-1$\n        writer.endElement();\n\n        writer.endElement();\n    }","id":36384,"modified_method":"private void addDependency( XMLWriter writer, Artifact artifact, List referencedReactorProjects,\n                               ArtifactRepository localRepository, File basedir )\n        throws MojoExecutionException\n    {\n        String handle;\n\n        if ( referencedReactorProjects.contains( artifact ) )\n        {\n            //  <dependent-module deploy-path=\"/WEB-INF/lib\" handle=\"module:/resource/artifactid/artifactid\">\n            //    <dependency-type>uses<\/dependency-type>\n            //  <\/dependent-module>\n\n            handle = \"module:/resource/\" + artifact.getArtifactId() + \"/\" + artifact.getArtifactId(); //$NON-NLS-1$ //$NON-NLS-2$\n        }\n        else\n        {\n            // <dependent-module deploy-path=\"/WEB-INF/lib\" handle=\"module:/classpath/var/M2_REPO/cl/cl/2.1/cl-2.1.jar\">\n            //    <dependency-type>uses<\/dependency-type>\n            // <\/dependent-module>\n\n            File artifactPath = artifact.getFile();\n\n            if ( artifactPath == null )\n            {\n                log.error( Messages.getString( \"EclipsePlugin.artifactpathisnull\", artifact.getId() ) ); //$NON-NLS-1$\n                return;\n            }\n\n            String fullPath = artifactPath.getPath();\n            File repoFile = new File( fullPath );\n\n            if ( Artifact.SCOPE_SYSTEM.equals( artifact.getScope() ) )\n            {\n                handle = \"module:/classpath/lib/\" //$NON-NLS-1$\n                    + EclipseUtils.toRelativeAndFixSeparator( basedir, repoFile, true );\n            }\n            else\n            {\n                File localRepositoryFile = new File( localRepository.getBasedir() );\n\n                handle = \"module:/classpath/var/M2_REPO/\" //$NON-NLS-1$\n                    + EclipseUtils.toRelativeAndFixSeparator( localRepositoryFile, repoFile, false );\n            }\n        }\n\n        writer.startElement( \"dependent-module\" ); //$NON-NLS-1$\n\n        writer.addAttribute( \"deploy-path\", \"/WEB-INF/lib\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"handle\", handle ); //$NON-NLS-1$\n\n        writer.startElement( \"dependency-type\" ); //$NON-NLS-1$\n        writer.writeText( \"uses\" ); //$NON-NLS-1$\n        writer.endElement();\n\n        writer.endElement();\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"protected void write( File basedir, MavenProject project, List referencedReactorArtifacts,\n                         EclipseSourceDir[] sourceDirs, ArtifactRepository localRepository,\n                         ArtifactResolver artifactResolver, List remoteArtifactRepositories )\n        throws MojoExecutionException\n    {\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( basedir, \".wtpmodules\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"project-modules\" ); //$NON-NLS-1$\n        writer.addAttribute( \"id\", \"moduleCoreId\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        writer.startElement( \"wb-module\" ); //$NON-NLS-1$\n        writer.addAttribute( \"deploy-name\", project.getArtifactId() ); //$NON-NLS-1$\n\n        String packaging = project.getPackaging();\n\n        writer.startElement( \"module-type\" ); //$NON-NLS-1$\n        writeModuleTypeAccordingToPackaging( project, writer, packaging );\n        writer.endElement(); // module-type\n\n        // source and resource paths.\n        // deploy-path is \"/\" for utility and ejb projects, \"/WEB-INF/classes\" for webapps\n\n        String target = \"/\"; //$NON-NLS-1$\n        if ( \"war\".equals( project.getPackaging() ) ) //$NON-NLS-1$\n        {\n            String warSourceDirectory = EclipseUtils.getPluginSetting( project, \"maven-war-plugin\", //$NON-NLS-1$\n                                                                       \"warSourceDirectory\", //$NON-NLS-1$\n                                                                       \"/src/main/webapp\" ); //$NON-NLS-1$\n\n            writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n            writer.addAttribute( \"deploy-path\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"source-path\", //$NON-NLS-1$\n                                 EclipseUtils.toRelativeAndFixSeparator( basedir, warSourceDirectory, false ) );\n            writer.endElement();\n\n            writeWarOrEarResources( writer, project, referencedReactorArtifacts, localRepository, artifactResolver,\n                                    remoteArtifactRepositories );\n\n            target = \"/WEB-INF/classes\"; //$NON-NLS-1$\n        }\n        else if ( \"ear\".equals( project.getPackaging() ) ) //$NON-NLS-1$\n        {\n            writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n            writer.addAttribute( \"deploy-path\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"source-path\", //$NON-NLS-1$\n                                 EclipseUtils.toRelativeAndFixSeparator( basedir, \"/\", false ) );\n            writer.endElement();\n\n            writeWarOrEarResources( writer, project, referencedReactorArtifacts, localRepository, artifactResolver,\n                                    remoteArtifactRepositories );\n        }\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n            // test src/resources are not added to wtpmodules\n            if ( !dir.isTest() )\n            {\n                //  <wb-resource deploy-path=\"/\" source-path=\"/src/java\" />\n                writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n                writer.addAttribute( \"deploy-path\", target ); //$NON-NLS-1$\n                writer.addAttribute( \"source-path\", dir.getPath() ); //$NON-NLS-1$\n                writer.endElement();\n            }\n        }\n\n        writer.endElement(); // wb-module\n        writer.endElement(); // project-modules\n\n        IOUtil.close( w );\n    }","id":36385,"modified_method":"protected void write( File basedir, MavenProject project, List referencedReactorArtifacts,\n                         EclipseSourceDir[] sourceDirs, ArtifactRepository localRepository,\n                         ArtifactResolver artifactResolver, List remoteArtifactRepositories )\n        throws MojoExecutionException\n    {\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( basedir, \".wtpmodules\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"project-modules\" ); //$NON-NLS-1$\n        writer.addAttribute( \"id\", \"moduleCoreId\" ); //$NON-NLS-1$ //$NON-NLS-2$\n\n        writer.startElement( \"wb-module\" ); //$NON-NLS-1$\n        writer.addAttribute( \"deploy-name\", project.getArtifactId() ); //$NON-NLS-1$\n\n        String packaging = project.getPackaging();\n\n        writer.startElement( \"module-type\" ); //$NON-NLS-1$\n        writeModuleTypeAccordingToPackaging( project, writer, packaging );\n        writer.endElement(); // module-type\n\n        // source and resource paths.\n        // deploy-path is \"/\" for utility and ejb projects, \"/WEB-INF/classes\" for webapps\n\n        String target = \"/\"; //$NON-NLS-1$\n        if ( \"war\".equals( project.getPackaging() ) ) //$NON-NLS-1$\n        {\n            String warSourceDirectory = EclipseUtils.getPluginSetting( project, \"maven-war-plugin\", //$NON-NLS-1$\n                                                                       \"warSourceDirectory\", //$NON-NLS-1$\n                                                                       \"/src/main/webapp\" ); //$NON-NLS-1$\n\n            writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n            writer.addAttribute( \"deploy-path\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"source-path\", //$NON-NLS-1$\n                                 \"/\"\n                                     + EclipseUtils.toRelativeAndFixSeparator( basedir, new File( basedir,\n                                                                                                  warSourceDirectory ),\n                                                                               false ) );\n            writer.endElement();\n\n            writeWarOrEarResources( writer, project, referencedReactorArtifacts, localRepository, artifactResolver,\n                                    remoteArtifactRepositories );\n\n            target = \"/WEB-INF/classes\"; //$NON-NLS-1$\n        }\n        else if ( \"ear\".equals( project.getPackaging() ) ) //$NON-NLS-1$\n        {\n            writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n            writer.addAttribute( \"deploy-path\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"source-path\", \"/\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.endElement();\n\n            writeWarOrEarResources( writer, project, referencedReactorArtifacts, localRepository, artifactResolver,\n                                    remoteArtifactRepositories );\n        }\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n            // test src/resources are not added to wtpmodules\n            if ( !dir.isTest() )\n            {\n                //  <wb-resource deploy-path=\"/\" source-path=\"/src/java\" />\n                writer.startElement( \"wb-resource\" ); //$NON-NLS-1$\n                writer.addAttribute( \"deploy-path\", target ); //$NON-NLS-1$\n                writer.addAttribute( \"source-path\", dir.getPath() ); //$NON-NLS-1$\n                writer.endElement();\n            }\n        }\n\n        writer.endElement(); // wb-module\n        writer.endElement(); // project-modules\n\n        IOUtil.close( w );\n    }","commit_id":"0ad10d875b9e32b46760793c84a40db11a2ab262","url":"https://github.com/apache/maven-plugins"},{"original_method":"public String getTestSourceDirectory()\n    {\n        return build.getTestSourceDirectory();\n    }","id":36386,"modified_method":"public String getTestSourceDirectory()\n    {\n        String path = build.getDirectory();\n        File file = new File( build.getTestSourceDirectory() );\n        try\n        {\n            path = file.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            handleCanonicalException( path, e );\n        }\n        return path;\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public BuildOverlay( Build build )\n    {\n        if ( build == null )\n        {\n            this.build = new Build();\n            \n            this.resources = new ArrayList();\n            \n            this.testResources = new ArrayList();\n        }\n        else\n        {\n            this.build = build;\n            \n            this.resources = new ArrayList( build.getResources() );\n            \n            this.testResources = new ArrayList( build.getTestResources() );\n        }\n    }","id":36387,"modified_method":"public BuildOverlay( Build build )\n    {\n        if ( build == null )\n        {\n            this.build = new Build();\n\n            resources = new ArrayList();\n\n            testResources = new ArrayList();\n        }\n        else\n        {\n            this.build = build;\n\n            resources = new ArrayList( build.getResources() );\n\n            testResources = new ArrayList( build.getTestResources() );\n        }\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public String getDirectory()\n    {\n        return build.getDirectory();\n    }","id":36388,"modified_method":"public String getDirectory()\n    {\n        String path = build.getDirectory();\n        File file = new File( build.getDirectory() );\n        try\n        {\n            path = file.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            handleCanonicalException( path, e );\n        }\n        return path;\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public String getScriptSourceDirectory()\n    {\n        return build.getScriptSourceDirectory();\n    }","id":36389,"modified_method":"public String getScriptSourceDirectory()\n    {\n        String path = build.getDirectory();\n        File file = new File( build.getScriptSourceDirectory() );\n        try\n        {\n            path = file.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            handleCanonicalException( path, e );\n        }\n        return path;\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public String getOutputDirectory()\n    {\n        return build.getOutputDirectory();\n    }","id":36390,"modified_method":"public String getOutputDirectory()\n    {\n        String path = build.getDirectory();\n        File file = new File( build.getOutputDirectory() );\n        try\n        {\n            path = file.getCanonicalPath();\n        }\n        catch ( IOException e )\n        {\n            handleCanonicalException( path, e );\n        }\n        return path;\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public void testTwoExpressions()\n        throws Exception\n    {\n        Build build = new Build();\n        build.setDirectory( \"expected-directory\" );\n        build.setFinalName( \"expected-finalName\" );\n\n        Model model = new Model();\n        model.setBuild( build );\n\n        ExpressionEvaluator expressionEvaluator =\n            createExpressionEvaluator( new MavenProject( model ), null, new Properties() );\n\n        Object value = expressionEvaluator.evaluate( \"${project.build.directory}/${project.build.finalName}\" );\n\n        assertEquals( \"expected-directory/expected-finalName\", value );\n    }","id":36391,"modified_method":"public void testTwoExpressions()\n        throws Exception\n    {\n        Build build = new Build();\n        build.setDirectory( \"expected-directory\" );\n        build.setFinalName( \"expected-finalName\" );\n\n        Model model = new Model();\n        model.setBuild( build );\n\n        ExpressionEvaluator expressionEvaluator =\n            createExpressionEvaluator( new MavenProject( model ), null, new Properties() );\n\n        Object value = expressionEvaluator.evaluate( \"${project.build.directory}/${project.build.finalName}\" );\n\n        assertEquals( new File( \"expected-directory/expected-finalName\" ).getCanonicalPath(), value );\n    }","commit_id":"6d3984551c58dac13301965f71ffbc5c7ca18be1","url":"https://github.com/apache/maven"},{"original_method":"public void write( File projectBaseDir, List referencedReactorArtifacts, EclipseSourceDir[] sourceDirs,\n                      List classpathContainers, ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                      ArtifactFactory artifactFactory, String buildOutputDirectory )\n        throws MojoExecutionException\n    {\n\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( eclipseProjectDir, \".classpath\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"classpath\" ); //$NON-NLS-1$\n\n        // ----------------------------------------------------------------------\n        // Source roots and resources\n        // ----------------------------------------------------------------------\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n\n            writer.addAttribute( \"kind\", \"src\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", dir.getPath() ); //$NON-NLS-1$\n            if ( dir.getOutput() != null )\n            {\n                writer.addAttribute( \"output\", dir.getOutput() ); //$NON-NLS-1$\n            }\n\n            writer.endElement();\n\n        }\n\n        // ----------------------------------------------------------------------\n        // The default output\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"output\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, //$NON-NLS-1$  \n                                                                             new File( buildOutputDirectory ), false ) );\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // Container classpath entries\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = classpathContainers.iterator(); it.hasNext(); )\n        {\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n            writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", (String) it.next() ); //$NON-NLS-1$\n            writer.endElement(); // name\n        }\n\n        // ----------------------------------------------------------------------\n        // The dependencies\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            if ( artifact.getArtifactHandler().isAddedToClasspath() )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository, artifactResolver,\n                               artifactFactory, projectBaseDir );\n            }\n        }\n\n        writer.endElement();\n\n        IOUtil.close( w );\n\n    }","id":36392,"modified_method":"public void write( File projectBaseDir, List referencedReactorArtifacts, EclipseSourceDir[] sourceDirs,\n                      List classpathContainers, ArtifactRepository localRepository, ArtifactResolver artifactResolver,\n                      ArtifactFactory artifactFactory, File buildOutputDirectory )\n        throws MojoExecutionException\n    {\n\n        FileWriter w;\n\n        try\n        {\n            w = new FileWriter( new File( eclipseProjectDir, \".classpath\" ) ); //$NON-NLS-1$\n        }\n        catch ( IOException ex )\n        {\n            throw new MojoExecutionException( Messages.getString( \"EclipsePlugin.erroropeningfile\" ), ex ); //$NON-NLS-1$\n        }\n\n        XMLWriter writer = new PrettyPrintXMLWriter( w );\n\n        writer.startElement( \"classpath\" ); //$NON-NLS-1$\n\n        // ----------------------------------------------------------------------\n        // Source roots and resources\n        // ----------------------------------------------------------------------\n\n        for ( int j = 0; j < sourceDirs.length; j++ )\n        {\n            EclipseSourceDir dir = sourceDirs[j];\n\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n\n            writer.addAttribute( \"kind\", \"src\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", dir.getPath() ); //$NON-NLS-1$\n            if ( dir.getOutput() != null )\n            {\n                writer.addAttribute( \"output\", dir.getOutput() ); //$NON-NLS-1$\n            }\n\n            writer.endElement();\n\n        }\n\n        // ----------------------------------------------------------------------\n        // The default output\n        // ----------------------------------------------------------------------\n\n        writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n        writer.addAttribute( \"kind\", \"output\" ); //$NON-NLS-1$ //$NON-NLS-2$\n        writer.addAttribute( \"path\", //$NON-NLS-1$ \n                             EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, buildOutputDirectory, false ) );\n        writer.endElement();\n\n        // ----------------------------------------------------------------------\n        // Container classpath entries\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = classpathContainers.iterator(); it.hasNext(); )\n        {\n            writer.startElement( \"classpathentry\" ); //$NON-NLS-1$\n            writer.addAttribute( \"kind\", \"con\" ); //$NON-NLS-1$ //$NON-NLS-2$\n            writer.addAttribute( \"path\", (String) it.next() ); //$NON-NLS-1$\n            writer.endElement(); // name\n        }\n\n        // ----------------------------------------------------------------------\n        // The dependencies\n        // ----------------------------------------------------------------------\n\n        for ( Iterator it = artifacts.iterator(); it.hasNext(); )\n        {\n            Artifact artifact = (Artifact) it.next();\n            if ( artifact.getArtifactHandler().isAddedToClasspath() )\n            {\n                addDependency( writer, artifact, referencedReactorArtifacts, localRepository, artifactResolver,\n                               artifactFactory, projectBaseDir );\n            }\n        }\n\n        writer.endElement();\n\n        IOUtil.close( w );\n\n    }","commit_id":"1ce6d01ae4dd1d995ddfd06176cdc5248fa282b9","url":"https://github.com/apache/maven-plugins"},{"original_method":"public static EclipseSourceDir[] buildDirectoryList( MavenProject project, File basedir, Log log,\n                                                        String outputDirectory )\n        throws MojoExecutionException\n    {\n        File projectBaseDir = project.getFile().getParentFile();\n\n        // avoid duplicated entries\n        Set directories = new TreeSet();\n\n        EclipseUtils.extractSourceDirs( directories, project.getCompileSourceRoots(), basedir, projectBaseDir, false,\n                                        null );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getResources(), project, basedir,\n                                          projectBaseDir, false, null, log );\n\n        // If using the standard output location, don't mix the test output into it.\n        String testOutput = outputDirectory.equals( project.getBuild().getOutputDirectory() ) ? EclipseUtils\n            .toRelativeAndFixSeparator( projectBaseDir, new File( project.getBuild().getTestOutputDirectory() ), false )\n                                                                                             : null;\n\n        EclipseUtils.extractSourceDirs( directories, project.getTestCompileSourceRoots(), basedir, projectBaseDir,\n                                        true, testOutput );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getTestResources(), project, basedir,\n                                          projectBaseDir, true, testOutput, log );\n\n        return (EclipseSourceDir[]) directories.toArray( new EclipseSourceDir[directories.size()] );\n    }","id":36393,"modified_method":"public static EclipseSourceDir[] buildDirectoryList( MavenProject project, File basedir, Log log,\n                                                        File buildOutputDirectory )\n        throws MojoExecutionException\n    {\n        File projectBaseDir = project.getFile().getParentFile();\n\n        // avoid duplicated entries\n        Set directories = new TreeSet();\n\n        EclipseUtils.extractSourceDirs( directories, project.getCompileSourceRoots(), basedir, projectBaseDir, false,\n                                        null );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getResources(), project, basedir,\n                                          projectBaseDir, false, null, log );\n\n        // If using the standard output location, don't mix the test output into it.\n        String testOutput = null;\n        boolean useFixedOutputDir = !buildOutputDirectory.equals( new File( project.getBuild().getOutputDirectory() ) );\n        if ( !useFixedOutputDir )\n        {\n            testOutput = EclipseUtils.toRelativeAndFixSeparator( projectBaseDir, new File( project.getBuild()\n                .getTestOutputDirectory() ), false );\n        }\n\n        EclipseUtils.extractSourceDirs( directories, project.getTestCompileSourceRoots(), basedir, projectBaseDir,\n                                        true, testOutput );\n\n        EclipseUtils.extractResourceDirs( directories, project.getBuild().getTestResources(), project, basedir,\n                                          projectBaseDir, true, testOutput, log );\n\n        return (EclipseSourceDir[]) directories.toArray( new EclipseSourceDir[directories.size()] );\n    }","commit_id":"1ce6d01ae4dd1d995ddfd06176cdc5248fa282b9","url":"https://github.com/apache/maven-plugins"},{"original_method":"protected void copyResources( List resources, String outputDirectory )\n        throws MojoExecutionException\n    {\n        initializeFiltering();\n\n        if ( encoding == null || encoding.length() < 1 )\n        {\n            getLog().info( \"Using default encoding to copy filtered resources.\" );\n        }\n        else\n        {\n            getLog().info( \"Using '\" + encoding + \"' to copy filtered resources.\" );\n        }\n        \n        for ( Iterator i = resources.iterator(); i.hasNext(); )\n        {\n            Resource resource = (Resource) i.next();\n\n            String targetPath = resource.getTargetPath();\n\n            File resourceDirectory = new File( resource.getDirectory() );\n            if ( !resourceDirectory.isAbsolute() )\n            {\n                resourceDirectory = new File( project.getBasedir(), resourceDirectory.getPath() );\n            }\n\n            if ( !resourceDirectory.exists() )\n            {\n                getLog().info( \"Resource directory does not exist: \" + resourceDirectory );\n                continue;\n            }\n\n            // this part is required in case the user specified \"../something\" as destination\n            // see MNG-1345\n            File outputDir = new File( outputDirectory );\n            if ( !outputDir.exists() )\n            {\n                if ( !outputDir.mkdirs() )\n                {\n                    throw new MojoExecutionException( \"Cannot create resource output directory: \" + outputDir );\n                }\n            }\n\n            DirectoryScanner scanner = new DirectoryScanner();\n\n            scanner.setBasedir( resourceDirectory );\n            if ( resource.getIncludes() != null && !resource.getIncludes().isEmpty() )\n            {\n                scanner.setIncludes( (String[]) resource.getIncludes().toArray( EMPTY_STRING_ARRAY ) );\n            }\n            else\n            {\n                scanner.setIncludes( DEFAULT_INCLUDES );\n            }\n\n            if ( resource.getExcludes() != null && !resource.getExcludes().isEmpty() )\n            {\n                scanner.setExcludes( (String[]) resource.getExcludes().toArray( EMPTY_STRING_ARRAY ) );\n            }\n\n            scanner.addDefaultExcludes();\n            scanner.scan();\n\n            List includedFiles = Arrays.asList( scanner.getIncludedFiles() );\n\n            getLog().info( \"Copying \" + includedFiles.size() + \" resource\"\n                + ( includedFiles.size() > 1 ? \"s\" : \"\" )\n                + ( targetPath == null ? \"\" : \" to \" + targetPath ) );\n\n            for ( Iterator j = includedFiles.iterator(); j.hasNext(); )\n            {\n                String name = (String) j.next();\n\n                String destination = name;\n\n                if ( targetPath != null )\n                {\n                    destination = targetPath + \"/\" + name;\n                }\n\n                File source = new File( resourceDirectory, name );\n\n                File destinationFile = new File( outputDirectory, destination );\n\n                if ( !destinationFile.getParentFile().exists() )\n                {\n                    destinationFile.getParentFile().mkdirs();\n                }\n\n                try\n                {\n                    copyFile( source, destinationFile, resource.isFiltering() );\n                }\n                catch ( IOException e )\n                {\n                    throw new MojoExecutionException( \"Error copying resource \" + source, e );\n                }\n            }\n        }\n    }","id":36394,"modified_method":"protected void copyResources( List resources, File outputDirectory )\n        throws MojoExecutionException\n    {\n        initializeFiltering();\n\n        if ( encoding == null || encoding.length() < 1 )\n        {\n            getLog().info( \"Using default encoding to copy filtered resources.\" );\n        }\n        else\n        {\n            getLog().info( \"Using '\" + encoding + \"' to copy filtered resources.\" );\n        }\n        \n        for ( Iterator i = resources.iterator(); i.hasNext(); )\n        {\n            Resource resource = (Resource) i.next();\n\n            String targetPath = resource.getTargetPath();\n\n            File resourceDirectory = new File( resource.getDirectory() );\n            if ( !resourceDirectory.isAbsolute() )\n            {\n                resourceDirectory = new File( project.getBasedir(), resourceDirectory.getPath() );\n            }\n\n            if ( !resourceDirectory.exists() )\n            {\n                getLog().info( \"Resource directory does not exist: \" + resourceDirectory );\n                continue;\n            }\n\n            // this part is required in case the user specified \"../something\" as destination\n            // see MNG-1345\n            if ( !outputDirectory.exists() )\n            {\n                if ( !outputDirectory.mkdirs() )\n                {\n                    throw new MojoExecutionException( \"Cannot create resource output directory: \" + outputDirectory );\n                }\n            }\n\n            DirectoryScanner scanner = new DirectoryScanner();\n\n            scanner.setBasedir( resourceDirectory );\n            if ( resource.getIncludes() != null && !resource.getIncludes().isEmpty() )\n            {\n                scanner.setIncludes( (String[]) resource.getIncludes().toArray( EMPTY_STRING_ARRAY ) );\n            }\n            else\n            {\n                scanner.setIncludes( DEFAULT_INCLUDES );\n            }\n\n            if ( resource.getExcludes() != null && !resource.getExcludes().isEmpty() )\n            {\n                scanner.setExcludes( (String[]) resource.getExcludes().toArray( EMPTY_STRING_ARRAY ) );\n            }\n\n            scanner.addDefaultExcludes();\n            scanner.scan();\n\n            List includedFiles = Arrays.asList( scanner.getIncludedFiles() );\n\n            getLog().info( \"Copying \" + includedFiles.size() + \" resource\"\n                + ( includedFiles.size() > 1 ? \"s\" : \"\" )\n                + ( targetPath == null ? \"\" : \" to \" + targetPath ) );\n\n            for ( Iterator j = includedFiles.iterator(); j.hasNext(); )\n            {\n                String name = (String) j.next();\n\n                String destination = name;\n\n                if ( targetPath != null )\n                {\n                    destination = targetPath + \"/\" + name;\n                }\n\n                File source = new File( resourceDirectory, name );\n\n                File destinationFile = new File( outputDirectory, destination );\n\n                if ( !destinationFile.getParentFile().exists() )\n                {\n                    destinationFile.getParentFile().mkdirs();\n                }\n\n                try\n                {\n                    copyFile( source, destinationFile, resource.isFiltering() );\n                }\n                catch ( IOException e )\n                {\n                    throw new MojoExecutionException( \"Error copying resource \" + source, e );\n                }\n            }\n        }\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceEncoding()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"encoding\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.txt\" );\r\n        project.setResourceFiltering( 0, true );\r\n        project.setupBuildEnvironment();\r\n\r\n        setVariableValueToObject( mojo, \"encoding\", \"UTF-8\" );\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\r\n    }","id":36395,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceEncoding()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"encoding\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.txt\" );\n        project.setResourceFiltering( 0, true );\n        project.setupBuildEnvironment();\n\n        setVariableValueToObject( mojo, \"encoding\", \"UTF-8\" );\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testPropertyFiles_Filtering()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourcePropertyFiles_Filtering\" );\r\n        List resources = project.getBuild().getResources();\r\n        LinkedList filterList = new LinkedList();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.properties\", \"current working directory=${dir}\" );\r\n        project.addFile( \"filter.properties\", \"dir:testdir\" );\r\n        project.setResourceFiltering( 0, true );\r\n        project.setupBuildEnvironment();\r\n        filterList.add( project.getResourcesDirectory() + \"filter.properties\" );\r\n\r\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", filterList );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n        String checkString = \"current working directory=testdir\";\r\n\r\n        assertContent( resourcesDir + \"/file4.properties\", checkString );\r\n    }","id":36396,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testPropertyFiles_Filtering()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourcePropertyFiles_Filtering\" );\n        List resources = project.getBuild().getResources();\n        LinkedList filterList = new LinkedList();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.properties\", \"current working directory=${dir}\" );\n        project.addFile( \"filter.properties\", \"dir:testdir\" );\n        project.setResourceFiltering( 0, true );\n        project.setupBuildEnvironment();\n        filterList.add( project.getResourcesDirectory() + \"filter.properties\" );\n\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", filterList );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n        String checkString = \"current working directory=testdir\";\n\n        assertContent( resourcesDir + \"/file4.properties\", checkString );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceSystemProperties_Filtering()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceSystemProperties_Filtering\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.txt\", \"current working directory = ${user.dir}\" );\r\n        project.setResourceFiltering( 0, true );\r\n        project.setupBuildEnvironment();\r\n\r\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n        String checkString = \"current working directory = \" + (String) System.getProperty( \"user.dir\" );\r\n\r\n        assertContent( resourcesDir + \"/file4.txt\", checkString );\r\n    }","id":36397,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceSystemProperties_Filtering()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceSystemProperties_Filtering\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.txt\", \"current working directory = ${user.dir}\" );\n        project.setResourceFiltering( 0, true );\n        project.setupBuildEnvironment();\n\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n        String checkString = \"current working directory = \" + (String) System.getProperty( \"user.dir\" );\n\n        assertContent( resourcesDir + \"/file4.txt\", checkString );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testProjectProperty_Filtering_PropertyDestination()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project =\r\n            new MavenProjectResourcesStub( \"resourcePojectProperty_Filtering_PropertyDestination\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.properties\", \"current working directory=${description}\" );\r\n        project.setResourceFiltering( 0, true );\r\n        project.setupBuildEnvironment();\r\n\r\n        // setup dummy property\r\n        project.setDescription( \"c:\\\\\\\\org\\\\apache\\\\test\" );\r\n\r\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n        String checkString = \"current working directory=c\\\\:\\\\\\\\\\\\\\\\org\\\\\\\\apache\\\\\\\\test\";\r\n\r\n        assertContent( resourcesDir + \"/file4.properties\", checkString );\r\n    }","id":36398,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testProjectProperty_Filtering_PropertyDestination()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project =\n            new MavenProjectResourcesStub( \"resourcePojectProperty_Filtering_PropertyDestination\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.properties\", \"current working directory=${description}\" );\n        project.setResourceFiltering( 0, true );\n        project.setupBuildEnvironment();\n\n        // setup dummy property\n        project.setDescription( \"c:\\\\\\\\org\\\\apache\\\\test\" );\n\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n        String checkString = \"current working directory=c\\\\:\\\\\\\\\\\\\\\\org\\\\\\\\apache\\\\\\\\test\";\n\n        assertContent( resourcesDir + \"/file4.properties\", checkString );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceInclude()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceInclude\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file1.include\" );\r\n        project.addFile( \"file2.exclude\" );\r\n        project.addFile( \"file3.nottest\" );\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file1.include\" );\r\n        project.addFile( \"package/file2.exclude\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"package/file4.txt\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"notpackage/file2.exclude\" );\r\n        project.addFile( \"notpackage/file3.nottest\" );\r\n        project.addFile( \"notpackage/file4.txt\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"package/nottest/file2.txt\" );\r\n        project.addFile( \"notpackage/test/file1.txt\" );\r\n        project.addFile( \"notpackage/nottest/file.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        project.addInclude( \"*.include\" );\r\n        project.addInclude( \"**/test\" );\r\n        project.addInclude( \"**/test/file*\" );\r\n        project.addInclude( \"**/package/*.include\" );\r\n\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file1.include\" ) );\r\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\r\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/nottest/file.txt\" ) );\r\n    }","id":36399,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceInclude()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceInclude\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file1.include\" );\n        project.addFile( \"file2.exclude\" );\n        project.addFile( \"file3.nottest\" );\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file1.include\" );\n        project.addFile( \"package/file2.exclude\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"package/file4.txt\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"notpackage/file2.exclude\" );\n        project.addFile( \"notpackage/file3.nottest\" );\n        project.addFile( \"notpackage/file4.txt\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"package/nottest/file2.txt\" );\n        project.addFile( \"notpackage/test/file1.txt\" );\n        project.addFile( \"notpackage/nottest/file.txt\" );\n        project.setupBuildEnvironment();\n\n        project.addInclude( \"*.include\" );\n        project.addInclude( \"**/test\" );\n        project.addInclude( \"**/test/file*\" );\n        project.addInclude( \"**/package/*.include\" );\n\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file1.include\" ) );\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/nottest/file.txt\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceDirectoryStructure_RelativePath()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceDirectoryStructure_RelativePath\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.setOutputDirectory( \"../relative_dir\" );\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"notpackage/test/file2.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file3.nottest\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/test\" ) );\r\n    }","id":36400,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceDirectoryStructure_RelativePath()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceDirectoryStructure_RelativePath\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.setOutputDirectory( \"../relative_dir\" );\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"notpackage/test/file2.txt\" );\n        project.setupBuildEnvironment();\n\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file3.nottest\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/test\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceProjectProperties_Filtering()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceProjectProperties_Filtering\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.txt\", \"current working directory = ${user.dir}\" );\r\n        project.setResourceFiltering( 0, true );\r\n        project.addProperty( \"user.dir\", \"FPJ kami!!!\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n        String checkString = \"current working directory = FPJ kami!!!\";\r\n\r\n        assertContent( resourcesDir + \"/file4.txt\", checkString );\r\n    }","id":36401,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceProjectProperties_Filtering()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceProjectProperties_Filtering\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.txt\", \"current working directory = ${user.dir}\" );\n        project.setResourceFiltering( 0, true );\n        project.addProperty( \"user.dir\", \"FPJ kami!!!\" );\n        project.setupBuildEnvironment();\n\n        //setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n        String checkString = \"current working directory = FPJ kami!!!\";\n\n        assertContent( resourcesDir + \"/file4.txt\", checkString );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceDirectoryStructure()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceDirectoryStructure\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"notpackage/test/file2.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file3.nottest\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/test\" ) );\r\n    }","id":36402,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceDirectoryStructure()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceDirectoryStructure\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"notpackage/test/file2.txt\" );\n        project.setupBuildEnvironment();\n\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file4.txt\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file3.nottest\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/notpackage/test\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceTargetPath()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceTargetPath\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.setTargetPath( \"org/apache/maven/plugin/test\" );\r\n\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"notpackage/test/file2.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/file4.txt\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/package/file3.nottest\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/notpackage/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/notpackage/test\" ) );\r\n    }","id":36403,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceTargetPath()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceTargetPath\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.setTargetPath( \"org/apache/maven/plugin/test\" );\n\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"notpackage/test/file2.txt\" );\n        project.setupBuildEnvironment();\n\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/file4.txt\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/package/file3.nottest\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/notpackage/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/org/apache/maven/plugin/test/notpackage/test\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testResourceExclude()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceExclude\" );\r\n        List resources = project.getBuild().getResources();\r\n        ;\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file1.include\" );\r\n        project.addFile( \"file2.exclude\" );\r\n        project.addFile( \"file3.nottest\" );\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file1.include\" );\r\n        project.addFile( \"package/file2.exclude\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"package/file4.txt\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"notpackage/file2.exclude\" );\r\n        project.addFile( \"notpackage/file3.nottest\" );\r\n        project.addFile( \"notpackage/file4.txt\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"package/nottest/file2.txt\" );\r\n        project.addFile( \"notpackage/test/file1.txt\" );\r\n        project.addFile( \"notpackage/nottest/file.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        project.addExclude( \"**/*.exclude\" );\r\n        project.addExclude( \"**/nottest*\" );\r\n        project.addExclude( \"**/notest\" );\r\n        project.addExclude( \"**/notpackage*\" );\r\n        project.addExclude( \"**/notpackage*/**\" );\r\n\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resourcesDir = project.getOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file1.include\" ) );\r\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\r\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/nottest/file.txt\" ) );\r\n    }","id":36404,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testResourceExclude()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        ResourcesMojo mojo = (ResourcesMojo) lookupMojo( \"resources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"resourceExclude\" );\n        List resources = project.getBuild().getResources();\n        ;\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file1.include\" );\n        project.addFile( \"file2.exclude\" );\n        project.addFile( \"file3.nottest\" );\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file1.include\" );\n        project.addFile( \"package/file2.exclude\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"package/file4.txt\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"notpackage/file2.exclude\" );\n        project.addFile( \"notpackage/file3.nottest\" );\n        project.addFile( \"notpackage/file4.txt\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"package/nottest/file2.txt\" );\n        project.addFile( \"notpackage/test/file1.txt\" );\n        project.addFile( \"notpackage/nottest/file.txt\" );\n        project.setupBuildEnvironment();\n\n        project.addExclude( \"**/*.exclude\" );\n        project.addExclude( \"**/nottest*\" );\n        project.addExclude( \"**/notest\" );\n        project.addExclude( \"**/notpackage*\" );\n        project.addExclude( \"**/notpackage*/**\" );\n\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resourcesDir = project.getOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resourcesDir + \"/package/file1.include\" ) );\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/file1.include\" ) );\n        assertFalse( FileUtils.fileExists( resourcesDir + \"/notpackage/nottest/file.txt\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * Validates that a Filter token containing a project property will be\r\n     * resolved before the Filter is applied to the resources.\r\n     * \r\n     * @throws Exception\r\n     */\r\n    public void testPropertyFiles_Filtering_TokensInFilters() \r\n        throws Exception\r\n    {\r\n        final File testPom = new File(getBasedir(), defaultPomFilePath);\r\n        final ResourcesMojo mojo = (ResourcesMojo) lookupMojo(\"resources\", testPom);\r\n        final MavenProjectResourcesStub project = new MavenProjectResourcesStub(\r\n                \"resourcePropertyFiles_Filtering_TokensInFilters\");\r\n        final List resources = project.getBuild().getResources();\r\n        final LinkedList filterList = new LinkedList();\r\n\r\n        assertNotNull(mojo);\r\n\r\n        project.addFile(\"file4.properties\", \"current working directory=${filter.token}\");\r\n        project.addFile(\"filter.properties\", \"filter.token=${pom-property}\");\r\n        project.setResourceFiltering(0, true);\r\n        project.addProperty(\"pom-property\", \"foobar\");\r\n        project.setupBuildEnvironment();\r\n        filterList.add(project.getResourcesDirectory() + \"filter.properties\");\r\n\r\n        // setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\r\n        setVariableValueToObject(mojo, \"project\", project);\r\n        setVariableValueToObject(mojo, \"resources\", resources);\r\n        setVariableValueToObject(mojo, \"outputDirectory\", project.getBuild().getOutputDirectory());\r\n        setVariableValueToObject(mojo, \"filters\", filterList);\r\n        mojo.execute();\r\n        final String resourcesDir = project.getOutputDirectory();\r\n        final String checkString = \"current working directory=foobar\";\r\n\r\n        assertContent(resourcesDir + \"/file4.properties\", checkString);\r\n    }","id":36405,"modified_method":"/**\n     * Validates that a Filter token containing a project property will be\n     * resolved before the Filter is applied to the resources.\n     * \n     * @throws Exception\n     */\n    public void testPropertyFiles_Filtering_TokensInFilters() \n        throws Exception\n    {\n        final File testPom = new File(getBasedir(), defaultPomFilePath);\n        final ResourcesMojo mojo = (ResourcesMojo) lookupMojo(\"resources\", testPom);\n        final MavenProjectResourcesStub project = new MavenProjectResourcesStub(\n                \"resourcePropertyFiles_Filtering_TokensInFilters\");\n        final List resources = project.getBuild().getResources();\n        final LinkedList filterList = new LinkedList();\n\n        assertNotNull(mojo);\n\n        project.addFile(\"file4.properties\", \"current working directory=${filter.token}\");\n        project.addFile(\"filter.properties\", \"filter.token=${pom-property}\");\n        project.setResourceFiltering(0, true);\n        project.addProperty(\"pom-property\", \"foobar\");\n        project.setupBuildEnvironment();\n        filterList.add(project.getResourcesDirectory() + \"filter.properties\");\n\n        // setVariableValueToObject(mojo,\"encoding\",\"UTF-8\");\n        setVariableValueToObject(mojo, \"project\", project);\n        setVariableValueToObject(mojo, \"resources\", resources);\n        setVariableValueToObject(mojo, \"outputDirectory\", new File( project.getBuild().getOutputDirectory() ) );\n        setVariableValueToObject(mojo, \"filters\", filterList);\n        mojo.execute();\n        final String resourcesDir = project.getOutputDirectory();\n        final String checkString = \"current working directory=foobar\";\n\n        assertContent(resourcesDir + \"/file4.properties\", checkString);\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"/**\r\n     * @throws Exception\r\n     */\r\n    public void testTestResourceDirectoryCreation()\r\n        throws Exception\r\n    {\r\n        File testPom = new File( getBasedir(), defaultPomFilePath );\r\n        TestResourcesMojo mojo = (TestResourcesMojo) lookupMojo( \"testResources\", testPom );\r\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"testResourceDirectoryStructure\" );\r\n        List resources = project.getBuild().getResources();\r\n\r\n        assertNotNull( mojo );\r\n\r\n        project.addFile( \"file4.txt\" );\r\n        project.addFile( \"package/file3.nottest\" );\r\n        project.addFile( \"notpackage/file1.include\" );\r\n        project.addFile( \"package/test/file1.txt\" );\r\n        project.addFile( \"notpackage/test/file2.txt\" );\r\n        project.setupBuildEnvironment();\r\n\r\n        setVariableValueToObject( mojo, \"project\", project );\r\n        setVariableValueToObject( mojo, \"resources\", resources );\r\n        setVariableValueToObject( mojo, \"outputDirectory\", project.getBuild().getTestOutputDirectory() );\r\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\r\n        mojo.execute();\r\n\r\n        String resorucesDir = project.getTestOutputDirectory();\r\n\r\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/file4.txt\" ) );\r\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/package/file3.nottest\" ) );\r\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/notpackage/file1.include\" ) );\r\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/package/test\" ) );\r\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/notpackage/test\" ) );\r\n    }","id":36406,"modified_method":"/**\n     * @throws Exception\n     */\n    public void testTestResourceDirectoryCreation()\n        throws Exception\n    {\n        File testPom = new File( getBasedir(), defaultPomFilePath );\n        TestResourcesMojo mojo = (TestResourcesMojo) lookupMojo( \"testResources\", testPom );\n        MavenProjectResourcesStub project = new MavenProjectResourcesStub( \"testResourceDirectoryStructure\" );\n        List resources = project.getBuild().getResources();\n\n        assertNotNull( mojo );\n\n        project.addFile( \"file4.txt\" );\n        project.addFile( \"package/file3.nottest\" );\n        project.addFile( \"notpackage/file1.include\" );\n        project.addFile( \"package/test/file1.txt\" );\n        project.addFile( \"notpackage/test/file2.txt\" );\n        project.setupBuildEnvironment();\n\n        setVariableValueToObject( mojo, \"project\", project );\n        setVariableValueToObject( mojo, \"resources\", resources );\n        setVariableValueToObject( mojo, \"outputDirectory\", new File( project.getBuild().getTestOutputDirectory() ) );\n        setVariableValueToObject( mojo, \"filters\", new LinkedList() );\n        mojo.execute();\n\n        String resorucesDir = project.getTestOutputDirectory();\n\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/file4.txt\" ) );\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/package/file3.nottest\" ) );\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/notpackage/file1.include\" ) );\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/package/test\" ) );\n        assertTrue( FileUtils.fileExists( resorucesDir + \"/notpackage/test\" ) );\n    }","commit_id":"7b3df59dc4a6718b5e4de19f8f00c126b47a1cc5","url":"https://github.com/apache/maven-plugins"},{"original_method":"@Override\n    @SuppressWarnings(\"unchecked\")\n    protected DaemonForkOptions toDaemonOptions(RoutesCompileSpec spec) {\n        List<String> routesPackages = Arrays.asList(\"play.router\", \"scala.collection\", \"scala.collection.mutable\", \"scala.util.matching\");\n        return new DaemonForkOptions(null, null, Collections.EMPTY_LIST, compilerClasspath, routesPackages);\n    }","id":36407,"modified_method":"@Override\n    @SuppressWarnings(\"unchecked\")\n    protected DaemonForkOptions toDaemonOptions(VersionedRoutesCompileSpec spec) {\n        List<String> routesPackages = Arrays.asList(\"play.router\", \"scala.collection\", \"scala.collection.mutable\", \"scala.util.matching\");\n        return new DaemonForkOptions(null, null, Collections.EMPTY_LIST, compilerClasspath, routesPackages);\n    }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"public <T extends CompileSpec> Compiler<T> newCompiler(T spec) {\n            if (spec instanceof TwirlCompileSpec) {\n                TwirlCompileSpec twirlCompileSpec = (TwirlCompileSpec)spec;\n                VersionedTwirlCompileSpec versionedSpec = TwirlCompileSpecFactory.create(twirlCompileSpec, targetPlatform);\n                Dependency compilerDependency = dependencyHandler.create(versionedSpec.getDependencyNotation());\n\n                Configuration templateCompilerClasspath = configurationContainer.detachedConfiguration(compilerDependency);\n                DaemonTwirlCompiler compiler = new DaemonTwirlCompiler(fileResolver.resolve(\".\"), templateCompilerClasspath.getFiles(), new TwirlCompiler(), compilerDaemonManager, new BaseForkOptions());\n                @SuppressWarnings(\"unchecked\") Compiler<T> twirlCompileSpecCompiler = (Compiler<T>) new MappingSpecCompiler<TwirlCompileSpec, VersionedTwirlCompileSpec>(compiler, WrapUtil.toMap(twirlCompileSpec, versionedSpec));\n                return twirlCompileSpecCompiler;\n            }\n            return null;\n        }","id":36408,"modified_method":"public <T extends CompileSpec> Compiler<T> newCompiler(T spec) {\n            if (spec instanceof TwirlCompileSpec) {\n                TwirlCompileSpec twirlCompileSpec = (TwirlCompileSpec)spec;\n                VersionedTwirlCompileSpec versionedSpec = TwirlCompileSpecFactory.create(twirlCompileSpec, targetPlatform);\n                Dependency compilerDependency = dependencyHandler.create(versionedSpec.getDependencyNotation());\n                Configuration templateCompilerClasspath = configurationContainer.detachedConfiguration(compilerDependency);\n\n                DaemonTwirlCompiler compiler = new DaemonTwirlCompiler(fileResolver.resolve(\".\"), templateCompilerClasspath.getFiles(), new TwirlCompiler(), compilerDaemonManager, new BaseForkOptions());\n                @SuppressWarnings(\"unchecked\") Compiler<T> twirlCompileSpecCompiler = (Compiler<T>) new MappingSpecCompiler<TwirlCompileSpec, VersionedTwirlCompileSpec>(compiler, WrapUtil.toMap(twirlCompileSpec, versionedSpec));\n                return twirlCompileSpecCompiler;\n            }\n            if(spec instanceof RoutesCompileSpec){\n                RoutesCompileSpec routesCompileSpec = (RoutesCompileSpec)spec;\n\n                VersionedRoutesCompileSpec versionedSpec = RoutesCompileSpecFactory.create(routesCompileSpec, false, targetPlatform);\n                Dependency compilerDependency = dependencyHandler.create(versionedSpec.getDependencyNotation());\n                Configuration routesCompilerClasspath = configurationContainer.detachedConfiguration(compilerDependency);\n\n                DaemonRoutesCompiler compiler = new DaemonRoutesCompiler(fileResolver.resolve(\".\"), new RoutesCompiler(), compilerDaemonManager, routesCompilerClasspath.getFiles());\n                @SuppressWarnings(\"unchecked\") Compiler<T> routesSpecCompiler = (Compiler<T>) new MappingSpecCompiler<RoutesCompileSpec, VersionedRoutesCompileSpec>(compiler, WrapUtil.toMap(routesCompileSpec, versionedSpec));\n                return routesSpecCompiler;\n            }\n\n            return null;\n        }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"public void apply(final ProjectInternal project) {\n        project.apply(WrapUtil.toMap(\"type\", ScalaBasePlugin.class));\n        this.project = project;\n        setupRoutesCompilation();\n        setupPlayAppClasspath();\n    }","id":36409,"modified_method":"public void apply(final ProjectInternal project) {\n        project.apply(WrapUtil.toMap(\"type\", ScalaBasePlugin.class));\n        this.project = project;\n        setupPlayAppClasspath();\n    }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"/**\n     * Returns the version used for the Play Routes compiler.\n     *\n     * @return The version of the Play Routes compiler.\n     */\n    public String getRoutesCompilerVersion() {\n        return routesCompilerVersion;\n    }","id":36410,"modified_method":"private Compiler<RoutesCompileSpec> getCompiler(RoutesCompileSpec spec) {\n        if (compiler == null) {\n            ToolProvider select = ((PlayToolChainInternal) getToolChain()).select(platform);\n            compiler = select.newCompiler(spec);\n        }\n        return compiler;\n    }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"@TaskAction\n    void compile() {\n        if(compiler==null){\n            compiler = new CleaningPlayToolCompiler<RoutesCompileSpec>(getCompiler(), getOutputs());\n        }\n\n        RoutesCompilerVersion version = RoutesCompilerVersion.parse(getRoutesCompilerVersion());\n        RoutesCompileSpec spec = RoutesCompileSpecFactory.create(getSource().getFiles(), getOutputDirectory(), getAdditionalImports(), isNamespaceReverseRouter(), isJavaProject(), version);\n        compiler.execute(spec);\n    }","id":36411,"modified_method":"@TaskAction\n    void compile() {\n        RoutesCompileSpec spec = new DefaultRoutesCompileSpec(getSource().getFiles(), getOutputDirectory(), getAdditionalImports(), isNamespaceReverseRouter(), getForkOptions(), isJavaProject());\n        if (compiler == null) {\n            compiler = new CleaningPlayToolCompiler<RoutesCompileSpec>(getCompiler(spec), getOutputs());\n        }\n        compiler.execute(spec);\n    }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"public WorkResult execute(RoutesCompileSpec spec) {\n        boolean didWork = false;\n\n        try {\n            ClassLoader cl = getClass().getClassLoader();\n            Iterable<File> sources = spec.getSources();\n            Function<Object[], Object> compile = spec.getCompileMethod(cl);\n            for (File sourceFile : sources) {\n                Object ret = compile.apply(spec.createCompileParameters(cl, sourceFile));\n                if (ret != null && ret instanceof Boolean) {\n                    didWork = (Boolean) ret || didWork;\n                } else {\n                    didWork = true; //assume we did some work\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(\"Error invoking the Play routes compiler.\", e);\n        }\n\n        return new SimpleWorkResult(didWork);\n    }","id":36412,"modified_method":"public WorkResult execute(VersionedRoutesCompileSpec spec) {\n        boolean didWork = false;\n        try {\n            ClassLoader cl = getClass().getClassLoader();\n            Iterable<File> sources = spec.getSources();\n            Function<Object[], Object> compile = spec.getCompileMethod(cl);\n            for (File sourceFile : sources) {\n                Object ret = compile.apply(spec.createCompileParameters(cl, sourceFile));\n                if (ret != null && ret instanceof Boolean) {\n                    didWork = (Boolean) ret || didWork;\n                } else {\n                    didWork = true; //assume we did some work\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(\"Error invoking the Play routes compiler.\", e);\n        }\n\n        return new SimpleWorkResult(didWork);\n    }","commit_id":"e820a140969368e01b42c513235bd8713640cfce","url":"https://github.com/gradle/gradle"},{"original_method":"/**\n     * Update the Maven project resources if not target/classes (or the\n     * configured build output directory) is used for output\n     */\n    private boolean updateProjectResources() {\n        final String classesDir = this.project.getBuild().getOutputDirectory().replace(File.separatorChar, '/');\n        final String ourRsrcPath = this.outputDirectory.getAbsolutePath().replace(File.separatorChar, '/');\n        if ( !classesDir.equals(ourRsrcPath) ) {\n            // now add the descriptor directory to the maven resources\n            boolean found = false;\n            @SuppressWarnings(\"unchecked\")\n            final Iterator<Resource> rsrcIterator = this.project.getResources().iterator();\n            while (!found && rsrcIterator.hasNext()) {\n                final Resource rsrc = rsrcIterator.next();\n                found = rsrc.getDirectory().replace(File.separatorChar, '/').equals(ourRsrcPath);\n            }\n            if (!found) {\n                final Resource resource = new Resource();\n                resource.setDirectory(this.outputDirectory.getAbsolutePath());\n                this.project.addResource(resource);\n            }\n            return true;\n        }\n        return false;\n    }","id":36413,"modified_method":"/**\n     * Update the Maven project resources if not target/classes (or the\n     * configured build output directory) is used for output\n     */\n    private boolean updateProjectResources() {\n        final String classesDir = new File(this.project.getBuild().getOutputDirectory()).getAbsolutePath().replace(File.separatorChar, '/');\n        final String ourRsrcPath = this.outputDirectory.getAbsolutePath().replace(File.separatorChar, '/');\n        if ( !classesDir.equals(ourRsrcPath) ) {\n            // now add the descriptor directory to the maven resources\n            boolean found = false;\n            @SuppressWarnings(\"unchecked\")\n            final Iterator<Resource> rsrcIterator = this.project.getResources().iterator();\n            while (!found && rsrcIterator.hasNext()) {\n                final Resource rsrc = rsrcIterator.next();\n                found = new File(rsrc.getDirectory()).getAbsolutePath().replace(File.separatorChar, '/').equals(ourRsrcPath);\n            }\n            if (!found) {\n                final Resource resource = new Resource();\n                resource.setDirectory(this.outputDirectory.getAbsolutePath());\n                this.project.addResource(resource);\n            }\n            return true;\n        }\n        return false;\n    }","commit_id":"235900c4dfdddf9f93eb21ddbeca8799a8a1551a","url":"https://github.com/apache/felix"},{"original_method":"public void onMergedPartitionLevelDeletion(DeletionTime mergedDeletion, DeletionTime[] versions)\n            {\n                for (int i = 0; i < versions.length; i++)\n                {\n                    if (mergedDeletion.supersedes(versions[i]))\n                        update(i).addPartitionDeletion(mergedDeletion);\n                }\n            }","id":36414,"modified_method":"public void onMergedPartitionLevelDeletion(DeletionTime mergedDeletion, DeletionTime[] versions)\n            {\n                this.partitionLevelDeletion = mergedDeletion;\n                for (int i = 0; i < versions.length; i++)\n                {\n                    if (mergedDeletion.supersedes(versions[i]))\n                        update(i).addPartitionDeletion(mergedDeletion);\n                }\n            }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"public void onMergedRangeTombstoneMarkers(RangeTombstoneMarker merged, RangeTombstoneMarker[] versions)\n            {\n                for (int i = 0; i < versions.length; i++)\n                {\n                    RangeTombstoneMarker marker = versions[i];\n                    // Note that boundaries are both close and open, so it's not one or the other\n                    if (merged.isClose(isReversed) && markerOpen[i] != null)\n                    {\n                        Slice.Bound open = markerOpen[i];\n                        Slice.Bound close = merged.closeBound(isReversed);\n                        update(i).add(new RangeTombstone(Slice.make(isReversed ? close : open, isReversed ? open : close), markerTime[i]));\n                    }\n                    if (merged.isOpen(isReversed) && (marker == null || merged.openDeletionTime(isReversed).supersedes(marker.openDeletionTime(isReversed))))\n                    {\n                        markerOpen[i] = merged.openBound(isReversed);\n                        markerTime[i] = merged.openDeletionTime(isReversed);\n                    }\n                }\n            }","id":36415,"modified_method":"public void onMergedRangeTombstoneMarkers(RangeTombstoneMarker merged, RangeTombstoneMarker[] versions)\n            {\n                // The current deletion as of dealing with this marker.\n                DeletionTime currentDeletion = currentDeletion();\n\n                for (int i = 0; i < versions.length; i++)\n                {\n                    RangeTombstoneMarker marker = versions[i];\n\n                    // Update what the source now thinks is the current deletion\n                    if (marker != null)\n                        sourceDeletionTime[i] = marker.isOpen(isReversed) ? marker.openDeletionTime(isReversed) : null;\n\n                    // If merged == null, some of the source is opening or closing a marker\n                    if (merged == null)\n                    {\n                        // but if it's not this source, move to the next one\n                        if (marker == null)\n                            continue;\n\n                        // We have a close and/or open marker for a source, with nothing corresponding in merged.\n                        // Because merged is a superset, this imply that we have a current deletion (being it due to an\n                        // early opening in merged or a partition level deletion) and that this deletion will still be\n                        // active after that point. Further whatever deletion was open or is open by this marker on the\n                        // source, that deletion cannot supersedes the current one.\n                        //\n                        // What we want to know here is if the source deletion and merged deletion was or will be equal,\n                        // because in that case we don't want to include any repair for the source, and otherwise we do.\n                        //\n                        // Note further that if the marker is a boundary, as both side of that boundary will have a\n                        // different deletion time, only one side might be equal to the merged deletion. This means we\n                        // can only be in one of 2 cases:\n                        //   1) the source was up-to-date on deletion up to that point (markerToRepair[i] == null), and then\n                        //      it won't be from that point on.\n                        //   2) the source wasn't up-to-date on deletion up to that point (markerToRepair[i] != null), and\n                        //      it may now be (if it isn't we just have nothing to do for that marker).\n                        assert !currentDeletion.isLive();\n\n                        if (markerToRepair[i] == null)\n                        {\n                            // Since there is an ongoing merged deletion, the only way we don't have an open repair for\n                            // this source is that it had a range open with the same deletion as current and it's\n                            // closing it. This imply we need to open a deletion for the source from that point.\n                            assert marker.isClose(isReversed) && currentDeletion.equals(marker.closeDeletionTime(isReversed));\n                            assert !marker.isOpen(isReversed) || currentDeletion.supersedes(marker.openDeletionTime(isReversed));\n                            markerToRepair[i] = marker.closeBound(isReversed).invert();\n                        }\n                        // In case 2) above, we only have something to do if the source is up-to-date after that point\n                        else if (marker.isOpen(isReversed) && currentDeletion.equals(marker.openDeletionTime(isReversed)))\n                        {\n                            closeOpenMarker(i, marker.openBound(isReversed).invert());\n                        }\n                    }\n                    else\n                    {\n                        // We have a change of current deletion in merged (potentially to/from no deletion at all).\n\n                        if (merged.isClose(isReversed))\n                        {\n                            // We're closing the merged range. If we've marked the source as needing to be repaired for\n                            // that range, close and add it to the repair to be sent.\n                            if (markerToRepair[i] != null)\n                                closeOpenMarker(i, merged.closeBound(isReversed));\n\n                        }\n\n                        if (merged.isOpen(isReversed))\n                        {\n                            // If we're opening a new merged range (or just switching deletion), then unless the source\n                            // is up to date on that deletion (note that we've updated what the source deleteion is\n                            // above), we'll have to sent the range to the source.\n                            DeletionTime newDeletion = merged.openDeletionTime(isReversed);\n                            DeletionTime sourceDeletion = sourceDeletionTime[i];\n                            if (!newDeletion.equals(sourceDeletion))\n                                markerToRepair[i] = merged.openBound(isReversed);\n                        }\n                    }\n                }\n\n                if (merged != null)\n                    mergedDeletionTime = merged.isOpen(isReversed) ? merged.openDeletionTime(isReversed) : null;\n            }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"private void assertRepairContainsDeletions(MessageOut<Mutation> message,\n                                               DeletionTime deletionTime,\n                                               RangeTombstone...rangeTombstones)\n    {\n        PartitionUpdate update = ((Mutation)message.payload).getPartitionUpdates().iterator().next();\n        DeletionInfo deletionInfo = update.deletionInfo();\n        if (deletionTime != null)\n            assertEquals(deletionTime, deletionInfo.getPartitionDeletion());\n\n        assertEquals(rangeTombstones.length, deletionInfo.rangeCount());\n        Iterator<RangeTombstone> ranges = deletionInfo.rangeIterator(false);\n        int i = 0;\n        while (ranges.hasNext())\n        {\n            assertEquals(ranges.next(), rangeTombstones[i++]);\n        }\n    }","id":36416,"modified_method":"private void assertRepairContainsDeletions(MessageOut<Mutation> message,\n                                               DeletionTime deletionTime,\n                                               RangeTombstone...rangeTombstones)\n    {\n        PartitionUpdate update = ((Mutation)message.payload).getPartitionUpdates().iterator().next();\n        DeletionInfo deletionInfo = update.deletionInfo();\n        if (deletionTime != null)\n            assertEquals(deletionTime, deletionInfo.getPartitionDeletion());\n\n        assertEquals(rangeTombstones.length, deletionInfo.rangeCount());\n        Iterator<RangeTombstone> ranges = deletionInfo.rangeIterator(false);\n        int i = 0;\n        while (ranges.hasNext())\n        {\n            RangeTombstone expected = rangeTombstones[i++];\n            RangeTombstone actual = ranges.next();\n            String msg = String.format(\"Expected %s, but got %s\", expected.toString(cfm.comparator), actual.toString(cfm.comparator));\n            assertEquals(msg, expected, actual);\n        }\n    }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"private RangeTombstone tombstone(Object start, Object end, long markedForDeleteAt, int localDeletionTime)\n    {\n        return new RangeTombstone(Slice.make(cfm.comparator.make(start), cfm.comparator.make(end)),\n                                  new DeletionTime(markedForDeleteAt, localDeletionTime));\n    }","id":36417,"modified_method":"private RangeTombstone tombstone(Object start, Object end, long markedForDeleteAt, int localDeletionTime)\n    {\n        return tombstone(start, true, end, true, markedForDeleteAt, localDeletionTime);\n    }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"public void onMergedPartitionLevelDeletion(DeletionTime mergedDeletion, DeletionTime[] versions);","id":36418,"modified_method":"/**\n         * Called once for the merged partition.\n         *\n         * @param mergedDeletion the partition level deletion for the merged partition. Implementors can test if the\n         * merged partition actually has a partition level deletion or not by calling {@code mergedDeletion.isLive()}.\n         * @param versions the partition level deletion for the sources of the merge. Elements of the array will never\n         * be null, but be \"live\".\n         **/\n        public void onMergedPartitionLevelDeletion(DeletionTime mergedDeletion, DeletionTime[] versions);","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"public void onMergedRangeTombstoneMarkers(RangeTombstoneMarker merged, RangeTombstoneMarker[] versions);","id":36419,"modified_method":"/**\n         * Called once for every range tombstone marker participating in the merge.\n         * <p>\n         * Note that this is called for every \"clustering position\" where at least one of the source merged has a range\n         * tombstone marker.\n         *\n         * @param merged the marker in the merged output. This can be {@code null} if there is no such marker, which\n         * means that at least one source has a marker in {@code versions} but the merged out has nothing corresponding\n         * (this basically mean the merged output has a currently open deletion that shadows whatever marker the source\n         * had).\n         * @param versions the marker for each source merged. This can be {@code null} for some source if that source\n         * has not such marker.\n         */\n        public void onMergedRangeTombstoneMarkers(RangeTombstoneMarker merged, RangeTombstoneMarker[] versions);","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"protected Unfiltered getReduced()\n            {\n                if (nextKind == Unfiltered.Kind.ROW)\n                {\n                    Row merged = rowMerger.merge(markerMerger.activeDeletion());\n                    if (listener != null)\n                        listener.onMergedRows(merged == null ? BTreeRow.emptyRow(rowMerger.mergedClustering()) : merged, rowMerger.mergedRows());\n                    return merged;\n                }\n                else\n                {\n                    RangeTombstoneMarker merged = markerMerger.merge();\n                    if (merged != null && listener != null)\n                        listener.onMergedRangeTombstoneMarkers(merged, markerMerger.mergedMarkers());\n                    return merged;\n                }\n            }","id":36420,"modified_method":"protected Unfiltered getReduced()\n            {\n                if (nextKind == Unfiltered.Kind.ROW)\n                {\n                    Row merged = rowMerger.merge(markerMerger.activeDeletion());\n                    if (listener != null)\n                        listener.onMergedRows(merged == null ? BTreeRow.emptyRow(rowMerger.mergedClustering()) : merged, rowMerger.mergedRows());\n                    return merged;\n                }\n                else\n                {\n                    RangeTombstoneMarker merged = markerMerger.merge();\n                    if (listener != null)\n                        listener.onMergedRangeTombstoneMarkers(merged, markerMerger.mergedMarkers());\n                    return merged;\n                }\n            }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"public void onMergedRows(Row merged, Row[] versions);","id":36421,"modified_method":"/**\n         * Called once for every row participating in the merge.\n         * <p>\n         * Note that this is called for every clustering where at least one of the source merged has a row. In\n         * particular, this may be called in cases where there is no row in the merged output (if a source has a row\n         * that is shadowed by another source range tombstone or partition level deletion).\n         *\n         * @param merged the result of the merge. This cannot be {@code null} but can be empty, in which case this is a\n         * placeholder for when at least one source has a row, but that row is shadowed in the merged output.\n         * @param versions for each source, the row in that source corresponding to {@code merged}. This can be\n         * {@code null} for some sources if the source has not such row.\n         */\n        public void onMergedRows(Row merged, Row[] versions);","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"@SuppressWarnings(\"resource\") // We're not really creating any resource here\n        private static DeletionTime collectPartitionLevelDeletion(List<UnfilteredRowIterator> iterators, MergeListener listener)\n        {\n            DeletionTime[] versions = listener == null ? null : new DeletionTime[iterators.size()];\n\n            DeletionTime delTime = DeletionTime.LIVE;\n            for (int i = 0; i < iterators.size(); i++)\n            {\n                UnfilteredRowIterator iter = iterators.get(i);\n                DeletionTime iterDeletion = iter.partitionLevelDeletion();\n                if (listener != null)\n                    versions[i] = iterDeletion;\n                if (!delTime.supersedes(iterDeletion))\n                    delTime = iterDeletion;\n            }\n            if (listener != null && !delTime.isLive())\n                listener.onMergedPartitionLevelDeletion(delTime, versions);\n            return delTime;\n        }","id":36422,"modified_method":"@SuppressWarnings(\"resource\") // We're not really creating any resource here\n        private static DeletionTime collectPartitionLevelDeletion(List<UnfilteredRowIterator> iterators, MergeListener listener)\n        {\n            DeletionTime[] versions = listener == null ? null : new DeletionTime[iterators.size()];\n\n            DeletionTime delTime = DeletionTime.LIVE;\n            for (int i = 0; i < iterators.size(); i++)\n            {\n                UnfilteredRowIterator iter = iterators.get(i);\n                DeletionTime iterDeletion = iter.partitionLevelDeletion();\n                if (listener != null)\n                    versions[i] = iterDeletion;\n                if (!delTime.supersedes(iterDeletion))\n                    delTime = iterDeletion;\n            }\n            if (listener != null)\n                listener.onMergedPartitionLevelDeletion(delTime, versions);\n            return delTime;\n        }","commit_id":"3f9b9ffe6b83987f7a1feb9a1d269e0f7c112161","url":"https://github.com/apache/cassandra"},{"original_method":"private void pushResource(String pushResource)\n        {\n            short version = stream.getSession().getVersion();\n            Fields.Field scheme = requestHeaders.get(HTTPSPDYHeader.SCHEME.name(version));\n            Fields.Field host = requestHeaders.get(HTTPSPDYHeader.HOST.name(version));\n            Fields.Field uri = requestHeaders.get(HTTPSPDYHeader.URI.name(version));\n            Fields pushHeaders = createPushHeaders(scheme, host, pushResource);\n            final Fields pushRequestHeaders = createRequestHeaders(scheme, host, uri, pushResource);\n\n            // TODO: handle the timeout better\n            stream.push(new PushInfo(0, TimeUnit.MILLISECONDS, pushHeaders, false), new Promise.Adapter<Stream>()\n            {\n                @Override\n                public void succeeded(Stream pushStream)\n                {\n                    queue.offer(new PushResource(pushStream, pushRequestHeaders));\n                    sendNextResourceData();\n                }\n            });\n        }","id":36423,"modified_method":"private void pushResource(String pushResource)\n        {\n            short version = stream.getSession().getVersion();\n            Fields.Field scheme = requestHeaders.get(HTTPSPDYHeader.SCHEME.name(version));\n            Fields.Field host = requestHeaders.get(HTTPSPDYHeader.HOST.name(version));\n            Fields.Field uri = requestHeaders.get(HTTPSPDYHeader.URI.name(version));\n            Fields pushHeaders = createPushHeaders(scheme, host, pushResource);\n            final Fields pushRequestHeaders = createRequestHeaders(scheme, host, uri, pushResource);\n\n            stream.push(new PushInfo(pushHeaders, false),\n                    new Promise.Adapter<Stream>()\n            {\n                @Override\n                public void succeeded(Stream pushStream)\n                {\n                    queue.offer(new PushResource(pushStream, pushRequestHeaders));\n                    sendNextResourceData();\n                }\n            });\n        }","commit_id":"f62cec561bcbc4297faad16859fd252c4325a21c","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public PushSynInfo(int associatedStreamId, PushInfo pushInfo){\n        super(pushInfo.getHeaders(), pushInfo.isClose());\n        this.associatedStreamId = associatedStreamId;\n    }","id":36424,"modified_method":"public PushSynInfo(int associatedStreamId, PushInfo pushInfo){\n        super(pushInfo.getTimeout(), pushInfo.getUnit(), pushInfo.getHeaders(), pushInfo.isClose(), (byte)0);\n        this.associatedStreamId = associatedStreamId;\n    }","commit_id":"f62cec561bcbc4297faad16859fd252c4325a21c","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private boolean isPushResource(String url, Headers responseHeaders)\n    {\n        // TODO\n        return false;\n    }","id":36425,"modified_method":"private boolean isPushResource(String url, Headers responseHeaders)\n    {\n        for (Pattern pushRegexp : pushRegexps)\n        {\n            if (pushRegexp.matcher(url).matches())\n                return true;\n        }\n        return false;\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private void buildMetadata(String url, String referrer)\n    {\n        Set<String> pushResources = Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());\n        Set<String> existing = resources.putIfAbsent(referrer, pushResources);\n        if (existing != null)\n            pushResources = existing;\n        pushResources.add(url);\n    }","id":36426,"modified_method":"private void buildMetadata(String origin, String url, String referrer)\n    {\n        if (referrer.startsWith(origin) || isPushOriginAllowed(origin))\n        {\n            Set<String> pushResources = resources.get(referrer);\n            if (pushResources == null)\n            {\n                pushResources = Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());\n                Set<String> existing = resources.putIfAbsent(referrer, pushResources);\n                if (existing != null)\n                    pushResources = existing;\n            }\n            pushResources.add(url);\n            logger.debug(\"Built push metadata for {}: {}\", referrer, pushResources);\n        }\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private Set<String> pushResources(String url)\n    {\n        Set<String> pushResources = resources.get(url);\n        if (pushResources == null)\n            return Collections.emptySet();\n        return Collections.unmodifiableSet(pushResources);\n    }","id":36427,"modified_method":"private Set<String> pushResources(String absoluteURL)\n    {\n        Set<String> pushResources = resources.get(absoluteURL);\n        if (pushResources == null)\n            return Collections.emptySet();\n        return Collections.unmodifiableSet(pushResources);\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private boolean isMainResource(String url, Headers responseHeaders)\n    {\n        // TODO\n        return false;\n    }","id":36428,"modified_method":"private boolean isMainResource(String url, Headers responseHeaders)\n    {\n        return !isPushResource(url, responseHeaders);\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n    public Set<String> apply(Stream stream, Headers requestHeaders, Headers responseHeaders)\n    {\n        String url = requestHeaders.get(\"url\").value();\n        if (!hasQueryString(url))\n        {\n            if (isMainResource(url, responseHeaders))\n            {\n                return pushResources(url);\n            }\n            else if (isPushResource(url, responseHeaders))\n            {\n                String referrer = requestHeaders.get(\"referer\").value();\n                Set<String> pushResources = resources.get(referrer);\n                if (pushResources == null || !pushResources.contains(url))\n                {\n                    buildMetadata(url, referrer);\n                }\n                else\n                {\n                    return pushResources(url);\n                }\n            }\n        }\n        return Collections.emptySet();\n    }","id":36429,"modified_method":"@Override\n    public Set<String> apply(Stream stream, Headers requestHeaders, Headers responseHeaders)\n    {\n        Set<String> result = Collections.emptySet();\n        String scheme = requestHeaders.get(\"scheme\").value();\n        String host = requestHeaders.get(\"host\").value();\n        String origin = new StringBuilder(scheme).append(\"://\").append(host).toString();\n        String url = requestHeaders.get(\"url\").value();\n        String absoluteURL = new StringBuilder(origin).append(url).toString();\n        logger.debug(\"Applying push strategy for {}\", absoluteURL);\n        if (isValidMethod(requestHeaders.get(\"method\").value()))\n        {\n            if (isMainResource(url, responseHeaders))\n            {\n                result = pushResources(absoluteURL);\n            }\n            else if (isPushResource(url, responseHeaders))\n            {\n                Headers.Header referrerHeader = requestHeaders.get(\"referer\");\n                if (referrerHeader != null)\n                {\n                    String referrer = referrerHeader.value();\n                    Set<String> pushResources = resources.get(referrer);\n                    if (pushResources == null || !pushResources.contains(url))\n                        buildMetadata(origin, url, referrer);\n                    else\n                        result = pushResources(absoluteURL);\n                }\n            }\n        }\n        logger.debug(\"Push resources for {}: {}\", absoluteURL, result);\n        return result;\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private void respond(Stream stream, int status)\n    {\n        Headers headers = new Headers();\n        headers.put(\"status\", String.valueOf(status));\n        headers.put(\"version\", \"HTTP/1.1\");\n        stream.reply(new ReplyInfo(headers, true));\n    }","id":36430,"modified_method":"private void respond(Stream stream, int status)\n    {\n        if (stream.isUnidirectional())\n        {\n            stream.getSession().rst(new RstInfo(stream.getId(), StreamStatus.INTERNAL_ERROR));\n        }\n        else\n        {\n            Headers headers = new Headers();\n            headers.put(\"status\", String.valueOf(status));\n            headers.put(\"version\", \"HTTP/1.1\");\n            stream.reply(new ReplyInfo(headers, true));\n        }\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public void endRequest()\n    {\n        post(new Runnable()\n        {\n            public void run()\n            {\n                if (state == State.HEADERS)\n                {\n                    updateState(State.HEADERS_COMPLETE);\n                    handle();\n                }\n                updateState(State.FINAL);\n                handle();\n            }\n        });\n    }","id":36431,"modified_method":"public void endRequest()\n    {\n        post(new Runnable()\n        {\n            public void run()\n            {\n                performEndRequest();\n            }\n        });\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public void beginRequest(final Headers headers)\n    {\n        this.headers = headers.isEmpty() ? null : headers;\n        post(new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                if (!headers.isEmpty())\n                    updateState(State.REQUEST);\n                handle();\n            }\n        });\n    }","id":36432,"modified_method":"public void beginRequest(final Headers headers, final boolean endRequest)\n    {\n        this.headers = headers.isEmpty() ? null : headers;\n        post(new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                if (!headers.isEmpty())\n                    updateState(State.REQUEST);\n                handle();\n                if (endRequest)\n                    performEndRequest();\n            }\n        });\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"protected void reply(Stream stream, ReplyInfo replyInfo)\n    {\n        if (!stream.isUnidirectional())\n            stream.reply(replyInfo);\n        if (replyInfo.getHeaders().get(\"status\").value().startsWith(\"200\") && !stream.isClosed())\n        {\n            // We have a 200 OK with some content to send\n            Set<String> pushResources = pushStrategy.apply(stream, this.headers, replyInfo.getHeaders());\n            for (String url : pushResources)\n            {\n                final Headers pushHeaders = new Headers();\n                pushHeaders.put(\"method\", \"GET\");\n                pushHeaders.put(\"url\", url);\n                pushHeaders.put(\"version\", \"HTTP/1.1\");\n                Headers.Header acceptEncoding = headers.get(\"accept-encoding\");\n                if (acceptEncoding != null)\n                    pushHeaders.put(acceptEncoding);\n                stream.syn(new SynInfo(pushHeaders, false), getMaxIdleTime(), TimeUnit.MILLISECONDS, new Handler.Adapter<Stream>()\n                {\n                    @Override\n                    public void completed(Stream pushStream)\n                    {\n                        Synchronous pushConnection = new Synchronous(getConnector(), getEndPoint(), getServer(), connection, pushStrategy, pushStream);\n                        pushConnection.beginRequest(pushHeaders);\n                        pushConnection.endRequest();\n                    }\n                });\n            }\n        }\n    }","id":36433,"modified_method":"protected void reply(Stream stream, ReplyInfo replyInfo)\n    {\n        if (!stream.isUnidirectional())\n            stream.reply(replyInfo);\n        if (replyInfo.getHeaders().get(\"status\").value().startsWith(\"200\") && !stream.isClosed())\n        {\n            // We have a 200 OK with some content to send\n\n            Headers.Header scheme = headers.get(\"scheme\");\n            Headers.Header host = headers.get(\"host\");\n            Headers.Header url = headers.get(\"url\");\n            Set<String> pushResources = pushStrategy.apply(stream, this.headers, replyInfo.getHeaders());\n            String referrer = new StringBuilder(scheme.value()).append(\"://\").append(host.value()).append(url.value()).toString();\n            for (String pushURL : pushResources)\n            {\n                final Headers pushHeaders = new Headers();\n                pushHeaders.put(\"method\", \"GET\");\n                pushHeaders.put(\"url\", pushURL);\n                pushHeaders.put(\"version\", \"HTTP/1.1\");\n                pushHeaders.put(scheme);\n                pushHeaders.put(host);\n                pushHeaders.put(\"referer\", referrer);\n                // Remember support for gzip encoding\n                pushHeaders.put(headers.get(\"accept-encoding\"));\n                stream.syn(new SynInfo(pushHeaders, false), getMaxIdleTime(), TimeUnit.MILLISECONDS, new Handler.Adapter<Stream>()\n                {\n                    @Override\n                    public void completed(Stream pushStream)\n                    {\n                        Synchronous pushConnection = new Synchronous(getConnector(), getEndPoint(), getServer(), connection, pushStrategy, pushStream);\n                        pushConnection.beginRequest(pushHeaders, true);\n                    }\n                });\n            }\n        }\n    }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n        public StreamFrameListener onSyn(final Stream stream, SynInfo synInfo)\n        {\n            // Every time we have a SYN, it maps to a HTTP request.\n            // We can have multiple concurrent SYNs on the same connection,\n            // and this is very different from HTTP, where only one request/response\n            // cycle is processed at a time, so we need to fake an http connection\n            // for each SYN in order to run concurrently.\n\n            logger.debug(\"Received {} on {}\", synInfo, stream);\n\n            HTTPSPDYAsyncEndPoint asyncEndPoint = new HTTPSPDYAsyncEndPoint(endPoint, stream);\n            ServerHTTPSPDYAsyncConnection connection = new ServerHTTPSPDYAsyncConnection(connector,\n                    asyncEndPoint, connector.getServer(), (SPDYAsyncConnection)endPoint.getConnection(),\n                    pushStrategy, stream);\n            asyncEndPoint.setConnection(connection);\n            stream.setAttribute(CONNECTION_ATTRIBUTE, connection);\n\n            Headers headers = synInfo.getHeaders();\n            connection.beginRequest(headers);\n\n            if (headers.isEmpty())\n            {\n                // If the SYN has no headers, they may come later in a HEADERS frame\n                return this;\n            }\n            else\n            {\n                if (synInfo.isClose())\n                {\n                    connection.endRequest();\n                    return null;\n                }\n                else\n                {\n                    return this;\n                }\n            }\n        }","id":36434,"modified_method":"@Override\n        public StreamFrameListener onSyn(final Stream stream, SynInfo synInfo)\n        {\n            // Every time we have a SYN, it maps to a HTTP request.\n            // We can have multiple concurrent SYNs on the same connection,\n            // and this is very different from HTTP, where only one request/response\n            // cycle is processed at a time, so we need to fake an http connection\n            // for each SYN in order to run concurrently.\n\n            logger.debug(\"Received {} on {}\", synInfo, stream);\n\n            HTTPSPDYAsyncEndPoint asyncEndPoint = new HTTPSPDYAsyncEndPoint(endPoint, stream);\n            ServerHTTPSPDYAsyncConnection connection = new ServerHTTPSPDYAsyncConnection(connector,\n                    asyncEndPoint, connector.getServer(), (SPDYAsyncConnection)endPoint.getConnection(),\n                    pushStrategy, stream);\n            asyncEndPoint.setConnection(connection);\n            stream.setAttribute(CONNECTION_ATTRIBUTE, connection);\n\n            Headers headers = synInfo.getHeaders();\n            connection.beginRequest(headers, synInfo.isClose());\n\n            if (headers.isEmpty())\n            {\n                // If the SYN has no headers, they may come later in a HEADERS frame\n                return this;\n            }\n            else\n            {\n                if (synInfo.isClose())\n                    return null;\n                else\n                    return this;\n            }\n        }","commit_id":"14f80912523f6581055c2a3007eb6baacbb5bb9e","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public XXFormsDialogControl(XFormsContainingDocument containingDocument, XFormsControl parent, Element element, String name, String effectiveId) {\n        super(containingDocument, parent, element, name, effectiveId);\n        this.level = element.attributeValue(\"level\");\n        if (this.level == null)\n            this.level = \"modal\";\n        this.close = !\"false\".equals(element.attributeValue(\"close\"));\n    }","id":36435,"modified_method":"public XXFormsDialogControl(XFormsContainingDocument containingDocument, XFormsControl parent, Element element, String name, String effectiveId) {\n        super(containingDocument, parent, element, name, effectiveId);\n        this.level = element.attributeValue(\"level\");\n        if (this.level == null)\n            this.level = \"modal\";\n        this.close = !\"false\".equals(element.attributeValue(\"close\"));\n        this.draggable = !\"false\".equals(element.attributeValue(\"draggable\"));\n    }","commit_id":"4c99ed0a9c07d06fd4eec863afd26d33d79502e4","url":"https://github.com/orbeon/orbeon-forms"},{"original_method":"public void start(String uri, String localname, String qName, Attributes attributes) throws SAXException {\n\n        effectiveDialogId = handlerContext.getEffectiveId(attributes);\n\n        // Find classes to add\n        final StringBuffer classes = new StringBuffer(\"xforms-dialog xforms-initially-hidden\");\n        if (!handlerContext.isGenerateTemplate()) {// NOTE: xxforms:dialog cannot be in a template\n            dialogXFormsControl = ((XXFormsDialogControl) containingDocument.getObjectById(handlerContext.getPipelineContext(), effectiveDialogId));\n            classes.append(\" xforms-dialog-\");\n            classes.append(dialogXFormsControl.getLevel());\n            classes.append(\" xforms-dialog-\");\n            classes.append(dialogXFormsControl.isClose() ? \"close\" : \"no-close\");\n        }\n\n        // Start main xhtml:div\n        final String xhtmlPrefix = handlerContext.findXHTMLPrefix();\n        final String divQName = XMLUtils.buildQName(xhtmlPrefix, \"div\");\n        final ContentHandler contentHandler = handlerContext.getController().getOutput();\n        contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, getAttributes(attributes, classes.toString(), effectiveDialogId));\n\n        // Child xhtml:div for label\n        final String labelValue = handlerContext.isGenerateTemplate() ? null : dialogXFormsControl.getLabel();\n        if (labelValue != null) {\n            reusableAttributes.clear();\n            reusableAttributes.addAttribute(\"\", \"class\", \"class\", ContentHandlerHelper.CDATA, \"hd\");\n            contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, reusableAttributes);\n            contentHandler.characters(labelValue.toCharArray(), 0, labelValue.length());\n            contentHandler.endElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName);\n        }\n\n        // Child xhtml:div for body\n        reusableAttributes.clear();\n        reusableAttributes.addAttribute(\"\", \"class\", \"class\", ContentHandlerHelper.CDATA, \"bd\");\n        contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, reusableAttributes);\n    }","id":36436,"modified_method":"public void start(String uri, String localname, String qName, Attributes attributes) throws SAXException {\n\n        effectiveDialogId = handlerContext.getEffectiveId(attributes);\n\n        // Find classes to add\n        final StringBuffer classes = new StringBuffer(\"xforms-dialog xforms-initially-hidden\");\n        if (!handlerContext.isGenerateTemplate()) {// NOTE: xxforms:dialog cannot be in a template\n            dialogXFormsControl = ((XXFormsDialogControl) containingDocument.getObjectById(handlerContext.getPipelineContext(), effectiveDialogId));\n            classes.append(\" xforms-dialog-\");\n            classes.append(dialogXFormsControl.getLevel());\n            classes.append(\" xforms-dialog-close-\");\n            classes.append(Boolean.toString(dialogXFormsControl.isClose()));\n            classes.append(\" xforms-dialog-draggable-\");\n            classes.append(Boolean.toString(dialogXFormsControl.isDraggable()));\n        }\n\n        // Start main xhtml:div\n        final String xhtmlPrefix = handlerContext.findXHTMLPrefix();\n        final String divQName = XMLUtils.buildQName(xhtmlPrefix, \"div\");\n        final ContentHandler contentHandler = handlerContext.getController().getOutput();\n        contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, getAttributes(attributes, classes.toString(), effectiveDialogId));\n\n        // Child xhtml:div for label\n        final String labelValue = handlerContext.isGenerateTemplate() ? null : dialogXFormsControl.getLabel();\n        if (labelValue != null) {\n            reusableAttributes.clear();\n            reusableAttributes.addAttribute(\"\", \"class\", \"class\", ContentHandlerHelper.CDATA, \"hd\");\n            contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, reusableAttributes);\n            contentHandler.characters(labelValue.toCharArray(), 0, labelValue.length());\n            contentHandler.endElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName);\n        }\n\n        // Child xhtml:div for body\n        reusableAttributes.clear();\n        reusableAttributes.addAttribute(\"\", \"class\", \"class\", ContentHandlerHelper.CDATA, \"bd\");\n        contentHandler.startElement(XMLConstants.XHTML_NAMESPACE_URI, \"div\", divQName, reusableAttributes);\n    }","commit_id":"4c99ed0a9c07d06fd4eec863afd26d33d79502e4","url":"https://github.com/orbeon/orbeon-forms"},{"original_method":"@Override\n\tprotected final MarkupElement onComponentTag(ComponentTag tag) throws ParseException\n\t{\n\t\t// Whatever there is left in the markup, ignore it\n\t\tif (ignoreTheRest == true)\n\t\t{\n\t\t\treturn tag;\n\t\t}\n\n\t\t// if it is <head> or <\/head>\n\t\tif (HEAD.equalsIgnoreCase(tag.getName()))\n\t\t{\n\t\t\tif (tag.getNamespace() == null)\n\t\t\t{\n\t\t\t\t// we found <head>\n\t\t\t\tif (tag.isClose())\n\t\t\t\t{\n\t\t\t\t\tfoundHead = true;\n\t\t\t\t}\n\t\t\t\telse if (tag.getId() == null)\n\t\t\t\t{\n\t\t\t\t\ttag.setId(HEADER_ID);\n\t\t\t\t\ttag.setAutoComponentTag(true);\n\t\t\t\t\ttag.setModified(true);\n\t\t\t\t}\n\n\t\t\t\treturn tag;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// we found <wicket:head>\n\t\t\t\tfoundHead = true;\n\t\t\t}\n\t\t}\n\t\telse if (BODY.equalsIgnoreCase(tag.getName()) && (tag.getNamespace() == null))\n\t\t{\n\t\t\t// We found <body>\n\t\t\tif (foundHead == false)\n\t\t\t{\n\t\t\t\tinsertHeadTag();\n\t\t\t}\n\n\t\t\t// <head> must always be before <body>\n\t\t\tignoreTheRest = true;\n\t\t\treturn tag;\n\t\t}\n\n\t\treturn tag;\n\t}","id":36437,"modified_method":"@Override\n\tprotected final MarkupElement onComponentTag(ComponentTag tag) throws ParseException\n\t{\n\t\t// Whatever there is left in the markup, ignore it\n\t\tif (ignoreTheRest == true)\n\t\t{\n\t\t\treturn tag;\n\t\t}\n\n\t\t// if it is <head> or <\/head>\n\t\tif (HEAD.equalsIgnoreCase(tag.getName()))\n\t\t{\n\t\t\tif (tag.getNamespace() == null)\n\t\t\t{\n\t\t\t\t// we found <head>\n\t\t\t\tif (tag.isOpen())\n\t\t\t\t{\n\t\t\t\t\tfoundHead = true;\n\n\t\t\t\t\tif (tag.getId() == null)\n\t\t\t\t\t{\n\t\t\t\t\t\ttag.setId(HEADER_ID);\n\t\t\t\t\t\ttag.setAutoComponentTag(true);\n\t\t\t\t\t\ttag.setModified(true);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (tag.isClose())\n\t\t\t\t{\n\t\t\t\t\tfoundClosingHead = true;\n\t\t\t\t}\n\n\t\t\t\treturn tag;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// we found <wicket:head>\n\t\t\t\tfoundHead = true;\n\t\t\t\tfoundClosingHead = true;\n\t\t\t}\n\t\t}\n\t\telse if (BODY.equalsIgnoreCase(tag.getName()) && (tag.getNamespace() == null))\n\t\t{\n\t\t\t// WICKET-4511: We found <body> inside <head> tag. Markup is not valid!\n\t\t\tif (foundHead && !foundClosingHead)\n\t\t\t{\n\t\t\t\tthrow new MarkupException(new MarkupStream(markup),\n\t\t\t\t\t\"Invalid page markup. Tag <BODY> found inside <HEAD>\");\n\t\t\t}\n\n\t\t\t// We found <body>\n\t\t\tif (foundHead == false)\n\t\t\t{\n\t\t\t\tinsertHeadTag();\n\t\t\t}\n\n\t\t\t// <head> must always be before <body>\n\t\t\tignoreTheRest = true;\n\t\t\treturn tag;\n\t\t}\n\n\t\treturn tag;\n\t}","commit_id":"4ee5ad1fbd7e7e9b3c0935f9b07e1350ecefd1cb","url":"https://github.com/apache/wicket"},{"original_method":"private void endRequest()\n        {\n            // TODO: hasBody is unused, persistent is false in spdy\n            getEventHandler().headerComplete(false, false);\n            // TODO: contentLength is unused\n            getEventHandler().messageComplete(-1);\n            //TODO: is this the way to go?\n            handle();\n        }","id":36438,"modified_method":"public void endRequest()\n        {\n            post(new Runnable()\n            {\n                public void run()\n                {\n                    performEndRequest();\n                }\n            });\n        }","commit_id":"aa22952368532b04565c411d8eecc30d306c73c4","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n        public StreamFrameListener onSyn(final Stream stream, SynInfo synInfo)\n        {\n            // Every time we have a SYN, it maps to a HTTP request.\n            // We can have multiple concurrent SYNs on the same connection,\n            // and this is very different from HTTP, where only one request/response\n            // cycle is processed at a time, so we need to fake an http connection\n            // for each SYN in order to run concurrently.\n\n            logger.debug(\"Received {} on {}\", synInfo, stream);\n\n            HTTPChannelOverSPDY channel = new HTTPChannelOverSPDY(connector.getServer(), endPoint.getConnection(),\n                    stream);\n            stream.setAttribute(CHANNEL_ATTRIBUTE, channel);\n\n            Headers headers = synInfo.getHeaders();\n\n            if (headers.isEmpty())\n            {\n                // If the SYN has no headers, they may come later in a HEADERS frame\n                return this;\n            }\n\n            channel.beginRequest(headers);\n\n            if (synInfo.isClose())\n            {\n                channel.endRequest();\n                return null;\n            }\n            else\n                return this;\n        }","id":36439,"modified_method":"@Override\n        public StreamFrameListener onSyn(final Stream stream, SynInfo synInfo)\n        {\n            // Every time we have a SYN, it maps to a HTTP request.\n            // We can have multiple concurrent SYNs on the same connection,\n            // and this is very different from HTTP, where only one request/response\n            // cycle is processed at a time, so we need to fake an http connection\n            // for each SYN in order to run concurrently.\n\n            logger.debug(\"Received {} on {}\", synInfo, stream);\n\n            HTTPChannelOverSPDY channel = new HTTPChannelOverSPDY(connector.getServer(), endPoint.getConnection(),\n                    stream);\n            stream.setAttribute(CHANNEL_ATTRIBUTE, channel);\n            Headers headers = synInfo.getHeaders();\n\n            if (headers.isEmpty())\n            {\n                // If the SYN has no headers, they may come later in a HEADERS frame\n                return this;\n            }\n            //TODO: beginRequest does two things, startRequest and close...should be doing one only?!\n            channel.beginRequest(headers, synInfo.isClose());\n\n            if (synInfo.isClose())\n                return null;\n            else\n                return this;\n        }","commit_id":"aa22952368532b04565c411d8eecc30d306c73c4","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private void beginRequest(Headers headers)\n        {\n            this.headers = headers;\n            Headers.Header method = headers.get(HTTPSPDYHeader.METHOD.name(getVersion()));\n            Headers.Header uri = headers.get(HTTPSPDYHeader.URI.name(getVersion()));\n            Headers.Header version = headers.get(HTTPSPDYHeader.VERSION.name(getVersion()));\n\n            if (method == null || uri == null || version == null)\n                throw new IllegalStateException(\"400\"); // TODO: replace with HttpException equivalent\n            //                throw new HttpException(HttpStatus.BAD_REQUEST_400);\n\n            HttpMethod httpMethod = HttpMethod.fromString(method.value());\n            HttpVersion httpVersion = HttpVersion.fromString(version.value());\n            String uriString = uri.value();\n\n            logger.debug(\"HTTP > {} {} {}\", httpMethod, uriString, httpVersion);\n            //TODO: why pass httpMethod and httpMethod.asString() ?\n            getEventHandler().startRequest(httpMethod, httpMethod.asString(), uriString, httpVersion);\n\n            Headers.Header schemeHeader = headers.get(HTTPSPDYHeader.SCHEME.name(getVersion()));\n            //            if (schemeHeader != null)  //TODO: thomas\n            //                _request.setScheme(schemeHeader.value());\n\n            for (Headers.Header header : headers)\n            {\n                String name = header.name();\n                HttpHeader httpHeader = null;\n\n                // Skip special SPDY headers, unless it's the \"host\" header\n                HTTPSPDYHeader specialHeader = HTTPSPDYHeader.from(getVersion(), name);\n                if (specialHeader != null)\n                {\n                    if (specialHeader == HTTPSPDYHeader.HOST)\n                    {\n                        httpHeader = HttpHeader.HOST;\n                        name = \"host\";\n                    }\n                    else\n                        continue;\n                }\n\n                switch (name)\n                {\n                    case \"connection\":\n                    case \"keep-alive\":\n                    case \"proxy-connection\":\n                    case \"transfer-encoding\":\n                    {\n                        // Spec says to ignore these headers\n                        continue;\n                    }\n                    default:\n                    {\n                        // Spec says headers must be single valued\n                        String value = header.value();\n                        logger.debug(\"HTTP > {}: {}\", name, value);\n                        //TODO: Is it safe to pass a null HttpHeader here?\n                        getEventHandler().parsedHeader(httpHeader, name, value);\n                        break;\n                    }\n                }\n            }\n        }","id":36440,"modified_method":"public void beginRequest(final Headers headers, final boolean endRequest)\n        {\n            this.headers = headers.isEmpty() ? null : headers;\n            post(new Runnable()\n            {\n                @Override\n                public void run()\n                {\n                    if (!headers.isEmpty())\n                        updateState(State.REQUEST);\n                    handle();\n                    if (endRequest)\n                        performEndRequest();\n                }\n            });\n        }","commit_id":"aa22952368532b04565c411d8eecc30d306c73c4","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n        public void onHeaders(Stream stream, HeadersInfo headersInfo)\n        {\n            logger.debug(\"Received {} on {}\", headersInfo, stream);\n            HTTPChannelOverSPDY channel = (HTTPChannelOverSPDY)stream.getAttribute(CHANNEL_ATTRIBUTE);\n            HttpChannel.EventHandler eventHandler = channel.getEventHandler();\n\n            for (Headers.Header header : headersInfo.getHeaders())\n            {\n                String name = header.name();\n\n                // Skip special SPDY headers, unless it's the \"host\" header\n                HTTPSPDYHeader specialHeader = HTTPSPDYHeader.from(getVersion(), name);\n                if (specialHeader != null)\n                {\n                    if (specialHeader == HTTPSPDYHeader.HOST)\n                        name = \"host\";\n                    else\n                        continue;\n                }\n\n                switch (name)\n                {\n                    case \"connection\":\n                    case \"keep-alive\":\n                    case \"proxy-connection\":\n                    case \"transfer-encoding\":\n                    {\n                        // Spec says to ignore these headers\n                        continue;\n                    }\n                    default:\n                    {\n                        HttpHeader httpHeader = HttpHeader.valueOf(header.name());\n                        // Spec says headers must be single valued\n                        String value = header.value();\n                        logger.debug(\"HTTP > {}: {}\", name, value);\n                        //TODO: move stuff to HttpOverSPDYChannel?\n                        eventHandler.parsedHeader(httpHeader, header.name(), value);\n                    }\n                }\n            }\n\n            if (headersInfo.isClose())\n                channel.endRequest();\n        }","id":36441,"modified_method":"@Override\n        public void onHeaders(Stream stream, HeadersInfo headersInfo)\n        {\n            logger.debug(\"Received {} on {}\", headersInfo, stream);\n            HTTPChannelOverSPDY channel = (HTTPChannelOverSPDY)stream.getAttribute(CHANNEL_ATTRIBUTE);\n            channel.parseHeaders(headersInfo.getHeaders());\n\n            if (headersInfo.isClose())\n                channel.endRequest();\n        }","commit_id":"aa22952368532b04565c411d8eecc30d306c73c4","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n        protected void completeResponse() throws IOException\n        {\n            logger.debug(\"completeResponse\");\n            getEventHandler().commit();\n            Response response = getResponse();\n            logger.debug(\"completed\");\n            Headers headers = new Headers();\n            headers.put(HTTPSPDYHeader.VERSION.name(getVersion()), HttpVersion.HTTP_1_1.asString());\n            StringBuilder status = new StringBuilder().append(response.getStatus());\n            String reason = response.getReason();\n            if (reason != null)\n                status.append(\" \").append(reason.toString());\n            headers.put(HTTPSPDYHeader.STATUS.name(getVersion()), status.toString());\n            logger.debug(\"HTTP < {} {}\", HttpVersion.HTTP_1_1, status);\n\n            HttpFields httpFields = response.getHttpFields();\n            if (httpFields != null)\n            {\n                for (HttpFields.Field httpField : httpFields)\n                {\n                    String name = httpField.getName().toLowerCase();\n                    String value = httpField.getValue();\n                    headers.put(name, value);\n                    logger.debug(\"HTTP < {}: {}\", name, value);\n                }\n            }\n\n            // We have to query the HttpGenerator and its buffers to know\n            // whether there is content buffered and update the generator state\n            reply(stream, new ReplyInfo(headers, response.getContentCount() < 1));\n\n            //TODO: sent content\n        }","id":36442,"modified_method":"@Override\n        protected void completeResponse() throws IOException\n        {\n            logger.debug(\"completeResponse\");\n            getEventHandler().commit();\n            Response response = getResponse();\n            Headers headers = new Headers();\n            headers.put(HTTPSPDYHeader.VERSION.name(getVersion()), HttpVersion.HTTP_1_1.asString());\n            StringBuilder status = new StringBuilder().append(response.getStatus());\n            String reason = response.getReason();\n            if (reason != null)\n                status.append(\" \").append(reason.toString());\n            headers.put(HTTPSPDYHeader.STATUS.name(getVersion()), status.toString());\n            logger.debug(\"HTTP < {} {}\", HttpVersion.HTTP_1_1, status);\n\n            HttpFields httpFields = response.getHttpFields();\n            if (httpFields != null)\n            {\n                for (HttpFields.Field httpField : httpFields)\n                {\n                    String name = httpField.getName().toLowerCase();\n                    String value = httpField.getValue();\n                    headers.put(name, value);\n                    logger.debug(\"HTTP < {}: {}\", name, value);\n                }\n            }\n\n            // We have to query the HttpGenerator and its buffers to know\n            // whether there is content buffered and update the generator state\n            reply(stream, new ReplyInfo(headers, response.getContentCount() < 1));\n\n            //TODO: sent content\n        }","commit_id":"aa22952368532b04565c411d8eecc30d306c73c4","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override public void compute2() {\n      System.out.println(\"ddply on group \"+Arrays.toString(_ds)+\" rows=\"+_fr.numRows()+\", env=\"+_env+\", op=\"+_op);\n      \n      // Clone a private copy of the environment for local execution\n      _env = _env.capture(true);\n\n      _env.push(_op);\n      _env.push(_fr);\n      _op.apply(_env,2/*1-arg function*/);\n      System.out.println(\"ddply on group \"+Arrays.toString(_ds)+\", env=\"+_env);\n      \n      _fr.delete();\n      _fr = null;\n      _ds = null;\n      _op = null;\n      _env= null;\n      tryComplete();\n    }","id":36443,"modified_method":"@Override public void compute2() {\n      Env shared_env = UKV.get(_envkey);\n      // Clone a private copy of the environment for local execution\n      Env env = shared_env.capture(true);\n      ASTOp op = env.fcn(-1);\n\n      System.out.println(\"ddply on group \"+Arrays.toString(_ds)+\" rows=\"+_fr.numRows()+\", env=\"+env+\", op=\"+op);\n      env.push(op);\n      env.push(_fr);\n      op.apply(env,2/*1-arg function*/);\n      System.out.println(\"ddply on group \"+Arrays.toString(_ds)+\", env=\"+env);\n      \n      _fr.delete();\n      _fr = null;\n      _ds = null;\n      _envkey= null;\n      tryComplete();\n    }","commit_id":"a0786f0d4eadfb2c84805915ca98b11a4c117429","url":"https://github.com/h2oai/h2o-2"},{"original_method":"RemoteExec( double ds[], Frame fr, ASTOp op, Env env ) { _ds=ds; _fr=fr; _op=op; _env=env; }","id":36444,"modified_method":"RemoteExec( double ds[], Frame fr, Key envkey ) { _ds=ds; _fr=fr; _envkey=envkey; }","commit_id":"a0786f0d4eadfb2c84805915ca98b11a4c117429","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override void apply(Env env, int argcnt) {\n    // Peek everything from the stack\n    // Function to execute on the groups\n    final ASTOp op = env.fcn(-1); // ary->dblary: subRxC -> 1xN\n    \n    Frame fr = env.ary(-3);    // The Frame to work on\n    final int ncols = fr.numCols();\n\n    // Either a single column, or a collection of columns to group on.\n    int cols[];\n    if( !env.isAry(-2) ) {      // Single column?\n      if( Double.isNaN(env.dbl(-2)) ) throw new IllegalArgumentException(\"NA not a valid column\");\n      cols = new int[]{(int)env.dbl(-2)-1};\n    } else {                    // Else a collection of columns?\n      Frame cs = env.ary(-2);\n      if( cs.numCols() !=  1  ) throw new IllegalArgumentException(\"Only one column-of-columns for column selection\");\n      if( cs.numRows() > 1000 ) throw new IllegalArgumentException(\"Too many columns selected\");\n      cols = new int[(int)cs.numRows()];\n      Vec vec = cs.vecs()[0];\n      for( int i=0; i<cols.length; i++ ) \n        if( vec.isNA(i) ) throw new IllegalArgumentException(\"NA not a valid column\");\n        else cols[i] = (int)vec.at8(i)-1;\n    }\n    // Another check for sane columns\n    for( int c : cols )\n      if( c < 0 || c >= fr.numCols() )\n        throw new IllegalArgumentException(\"Column \"+(c+1)+\" out of range for frame columns \"+fr.numCols());\n\n    // Was pondering a SIMD-like execution model, running the fcn \"once\" - but\n    // in parallel for all groups.  But this isn't going to work: each fcn\n    // execution will take different control paths.  Also the functions side-\n    // effects' must only happen once, and they will make multiple passes over\n    // the Frame passed in.  \n    //\n    // GroupIDs' can vary from 1 group to 1-per-row.  Are formed by the cross-\n    // product of the selection cols.  Will be hashed to find Group - NBHML\n    // mapping row-contents to group.  Index is a sample row.  NBHML per-node,\n    // plus roll-ups.  Result/Value is Group structure pointing to NewChunks\n    // holding row indices.  \n\n    // Pass 1: Find Groups.\n    // Build a NBHSet of unique double[]'s holding selection cols.\n    // These are the unique groups, found per-node, rolled-up globally\n    // Record the rows belonging to each group, locally.\n    ddplyPass1 p1 = new ddplyPass1(cols).doAll(fr);\n\n    // Pass 2: Build Groups.\n    // Wrap Vec headers around all the local row-counts.\n    ddplyPass2 p2 = new ddplyPass2(p1).invokeOnAllNodes();\n    // vecs[] iteration order exactly matches p1._grpoups.keySet()\n    Vec vecs[] = p2.close();\n    \n    // Pass 3: Send Groups 'round the cluster\n    // Single-threaded per-group work.\n    // Send each group to some remote node for execution\n    int csz = H2O.CLOUD.size();\n    Futures fs = new Futures();\n    int grpnum=0; // vecs[] iteration order exactly matches p1._groups.keySet()\n    for( Group g : p1._groups.keySet() ) {\n      // vecs[] iteration order exactly matches p1._grpoups.keySet()\n      Vec rows = vecs[grpnum++]; // Rows for this Vec\n      Vec[] data = fr.vecs();    // Full data columns\n      Vec[] gvecs = new Vec[data.length];\n      Key[] keys = rows.group().addVecs(data.length);\n      for( int c=0; c<data.length; c++ )\n        gvecs[c] = new SubsetVec(rows._key,data[c]._key,keys[c],rows._espc);\n      Frame fg = new Frame(fr._names,gvecs);\n      // Non-blocking, send a group to a remote node for execution\n      fs.add(RPC.call(H2O.CLOUD._memary[g.hashCode()%csz],new RemoteExec(g._ds,fg,op,env)));\n    }\n    fs.blockForPending();\n\n    for( Vec v : vecs ) UKV.remove(v._key);\n\n    env.pop(4);\n    // Push empty frame for debugging\n    env.push(new Frame(new String[0],new Vec[0]));\n  }","id":36445,"modified_method":"@Override void apply(Env env, int argcnt) {\n    // Peek everything from the stack\n    // Function to execute on the groups\n    final ASTOp op = env.fcn(-1); // ary->dblary: subRxC -> 1xN\n    \n    Frame fr = env.ary(-3);    // The Frame to work on\n    final int ncols = fr.numCols();\n\n    // Either a single column, or a collection of columns to group on.\n    int cols[];\n    if( !env.isAry(-2) ) {      // Single column?\n      if( Double.isNaN(env.dbl(-2)) ) throw new IllegalArgumentException(\"NA not a valid column\");\n      cols = new int[]{(int)env.dbl(-2)-1};\n    } else {                    // Else a collection of columns?\n      Frame cs = env.ary(-2);\n      if( cs.numCols() !=  1  ) throw new IllegalArgumentException(\"Only one column-of-columns for column selection\");\n      if( cs.numRows() > 1000 ) throw new IllegalArgumentException(\"Too many columns selected\");\n      cols = new int[(int)cs.numRows()];\n      Vec vec = cs.vecs()[0];\n      for( int i=0; i<cols.length; i++ ) \n        if( vec.isNA(i) ) throw new IllegalArgumentException(\"NA not a valid column\");\n        else cols[i] = (int)vec.at8(i)-1;\n    }\n    // Another check for sane columns\n    for( int c : cols )\n      if( c < 0 || c >= fr.numCols() )\n        throw new IllegalArgumentException(\"Column \"+(c+1)+\" out of range for frame columns \"+fr.numCols());\n\n    // Was pondering a SIMD-like execution model, running the fcn \"once\" - but\n    // in parallel for all groups.  But this isn't going to work: each fcn\n    // execution will take different control paths.  Also the functions side-\n    // effects' must only happen once, and they will make multiple passes over\n    // the Frame passed in.  \n    //\n    // GroupIDs' can vary from 1 group to 1-per-row.  Are formed by the cross-\n    // product of the selection cols.  Will be hashed to find Group - NBHML\n    // mapping row-contents to group.  Index is a sample row.  NBHML per-node,\n    // plus roll-ups.  Result/Value is Group structure pointing to NewChunks\n    // holding row indices.  \n\n    // Pass 1: Find Groups.\n    // Build a NBHSet of unique double[]'s holding selection cols.\n    // These are the unique groups, found per-node, rolled-up globally\n    // Record the rows belonging to each group, locally.\n    ddplyPass1 p1 = new ddplyPass1(cols).doAll(fr);\n\n    // Pass 2: Build Groups.\n    // Wrap Vec headers around all the local row-counts.\n    ddplyPass2 p2 = new ddplyPass2(p1).invokeOnAllNodes();\n    // vecs[] iteration order exactly matches p1._grpoups.keySet()\n    Vec vecs[] = p2.close();\n    // Push the execution env around the cluster\n    Key envkey = Key.make();\n    UKV.put(envkey,env);\n    \n    // Pass 3: Send Groups 'round the cluster\n    // Single-threaded per-group work.\n    // Send each group to some remote node for execution\n    int csz = H2O.CLOUD.size();\n    Futures fs = new Futures();\n    int grpnum=0; // vecs[] iteration order exactly matches p1._groups.keySet()\n    for( Group g : p1._groups.keySet() ) {\n      // vecs[] iteration order exactly matches p1._grpoups.keySet()\n      Vec rows = vecs[grpnum++]; // Rows for this Vec\n      Vec[] data = fr.vecs();    // Full data columns\n      Vec[] gvecs = new Vec[data.length];\n      Key[] keys = rows.group().addVecs(data.length);\n      for( int c=0; c<data.length; c++ )\n        gvecs[c] = new SubsetVec(rows._key,data[c]._key,keys[c],rows._espc);\n      Frame fg = new Frame(fr._names,gvecs);\n      // Non-blocking, send a group to a remote node for execution\n      fs.add(RPC.call(H2O.CLOUD._memary[g.hashCode()%csz],new RemoteExec(g._ds,fg,envkey)));\n    }\n    fs.blockForPending();\n\n    // Delete the group row vecs\n    for( Vec v : vecs ) UKV.remove(v._key);\n\n    env.pop(4);\n    // Push empty frame for debugging\n    env.push(new Frame(new String[0],new Vec[0]));\n  }","commit_id":"a0786f0d4eadfb2c84805915ca98b11a4c117429","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override\n\tpublic boolean isFilterEnabled() {\n\t\tif (!super.isFilterEnabled()) {\n\t\t\treturn false;\n\t\t}\n\n\t\tif (!_monitoringPortalRequest) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t}","id":36446,"modified_method":"@Override\n\tpublic boolean isFilterEnabled() {\n\t\tif (!super.isFilterEnabled()) {\n\t\t\treturn false;\n\t\t}\n\n\t\tif (!_monitoringPortalRequest &&\n\t\t\t!MonitoringPortlet.isMonitoringPortletActionRequest() &&\n\t\t\t!MonitoringPortlet.isMonitoringPortletEventRequest() &&\n\t\t\t!MonitoringPortlet.isMonitoringPortletRenderRequest() &&\n\t\t\t!MonitoringPortlet.isMonitoringPortletResourceRequest() &&\n\t\t\t!ServiceMonitorAdvice.isActive()) {\n\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t}","commit_id":"afba7a9876c981a00497150b2c158eac5e99e58b","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tprotected void processFilter(\n\t\t\tHttpServletRequest request, HttpServletResponse response,\n\t\t\tFilterChain filterChain)\n\t\tthrows IOException, ServletException {\n\n\t\tlong companyId = PortalUtil.getCompanyId(request);\n\n\t\tPortalRequestDataSample portalRequestDataSample =\n\t\t\tnew PortalRequestDataSample(\n\t\t\t\tcompanyId, request.getRemoteUser(), request.getRequestURI(),\n\t\t\t\trequest.getRequestURL().toString());\n\n\t\ttry {\n\t\t\tportalRequestDataSample.prepare();\n\n\t\t\tprocessFilter(\n\t\t\t\tMonitoringFilter.class, request, response, filterChain);\n\n\t\t\tportalRequestDataSample.capture(RequestStatus.SUCCESS);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tportalRequestDataSample.capture(RequestStatus.ERROR);\n\n\t\t\tif (e instanceof IOException) {\n\t\t\t\tthrow (IOException)e;\n\t\t\t}\n\t\t\telse if (e instanceof ServletException) {\n\t\t\t\tthrow (ServletException)e;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new ServletException(\"Unable to execute request\", e);\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tMessageBusUtil.sendMessage(\n\t\t\t\tDestinationNames.MONITORING, portalRequestDataSample);\n\n\t\t\tDataSampleThreadLocal.addDataSample(portalRequestDataSample);\n\t\t}\n\t}","id":36447,"modified_method":"@Override\n\tprotected void processFilter(\n\t\t\tHttpServletRequest request, HttpServletResponse response,\n\t\t\tFilterChain filterChain)\n\t\tthrows IOException, ServletException {\n\n\t\tlong companyId = PortalUtil.getCompanyId(request);\n\n\t\tPortalRequestDataSample portalRequestDataSample = null;\n\n\t\tif (_monitoringPortalRequest) {\n\n\t\t\tString requestURLString = StringPool.BLANK;\n\n\t\t\tif (request.getRequestURL() != null) {\n\t\t\t\trequestURLString = request.getRequestURL().toString();\n\t\t\t}\n\n\t\t\tportalRequestDataSample = new PortalRequestDataSample(\n\t\t\t\tcompanyId, request.getRemoteUser(), request.getRequestURI(),\n\t\t\t\trequestURLString);\n\t\t}\n\n\t\ttry {\n\t\t\tif (portalRequestDataSample != null) {\n\t\t\t\tportalRequestDataSample.prepare();\n\t\t\t}\n\n\t\t\tprocessFilter(\n\t\t\t\tMonitoringFilter.class, request, response, filterChain);\n\n\t\t\tif (portalRequestDataSample != null) {\n\t\t\t\tportalRequestDataSample.capture(RequestStatus.SUCCESS);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tif (portalRequestDataSample != null) {\n\t\t\t\tportalRequestDataSample.capture(RequestStatus.ERROR);\n\t\t\t}\n\n\t\t\tif (e instanceof IOException) {\n\t\t\t\tthrow (IOException)e;\n\t\t\t}\n\t\t\telse if (e instanceof ServletException) {\n\t\t\t\tthrow (ServletException)e;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new ServletException(\"Unable to execute request\", e);\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tif (portalRequestDataSample != null) {\n\t\t\t\tDataSampleThreadLocal.addDataSample(portalRequestDataSample);\n\t\t\t}\n\n\t\t\tMessageBusUtil.sendMessage(\n\t\t\t\tDestinationNames.MONITORING,\n\t\t\t\tDataSampleThreadLocal.getDataSamples());\n\t\t}\n\t}","commit_id":"afba7a9876c981a00497150b2c158eac5e99e58b","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tprotected void doReceive(Message message) throws Exception {\n\t\tDataSample dataSample = (DataSample)message.getPayload();\n\n\t\tif (dataSample != null) {\n\t\t\t_dataSampleProcessor.processDataSample(dataSample);\n\t\t}\n\t}","id":36448,"modified_method":"@Override\n\tprotected void doReceive(Message message) throws Exception {\n\t\tList<DataSample> dataSamples = (List<DataSample>)message.getPayload();\n\n\t\tif ((dataSamples != null) && !dataSamples.isEmpty()) {\n\t\t\tfor (DataSample dataSample : dataSamples) {\n\t\t\t\t_dataSampleProcessor.processDataSample(dataSample);\n\t\t\t}\n\t\t}\n\t}","commit_id":"afba7a9876c981a00497150b2c158eac5e99e58b","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n    protected void addSourceSetsBlock(@NotNull GroovyFile file) {\n        GrClosableBlock androidBlock = getAndroidBlock(file);\n        addLastExpressionInBlockIfNeeded(SOURCE_SET, getSourceSetsBlock(androidBlock));\n    }","id":36449,"modified_method":"@Override\n    protected boolean addSourceSetsBlock(@NotNull GroovyFile file) {\n        GrClosableBlock androidBlock = getAndroidBlock(file);\n        return addLastExpressionInBlockIfNeeded(SOURCE_SET, getSourceSetsBlock(androidBlock));\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    protected boolean addElementsToFile(@NotNull GroovyFile groovyFile, boolean isTopLevelProjectFile, @NotNull String version) {\n        if (isTopLevelProjectFile) {\n            addElementsToProjectFile(groovyFile, version);\n        }\n        else {\n            addElementsToModuleFile(groovyFile, version);\n        }\n        return true;\n    }","id":36450,"modified_method":"@Override\n    protected boolean addElementsToFile(@NotNull GroovyFile groovyFile, boolean isTopLevelProjectFile, @NotNull String version) {\n        if (isTopLevelProjectFile) {\n            return addElementsToProjectFile(groovyFile, version);\n        }\n        else {\n            return addElementsToModuleFile(groovyFile, version);\n        }\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    protected boolean addElementsToFile(@NotNull GroovyFile groovyFile, boolean isTopLevelProjectFile, @NotNull String version) {\n        if (!isTopLevelProjectFile) {\n            addElementsToProjectFile(groovyFile, version);\n            addElementsToModuleFile(groovyFile, version);\n            return true;\n        }\n        return false;\n    }","id":36451,"modified_method":"@Override\n    protected boolean addElementsToFile(@NotNull GroovyFile groovyFile, boolean isTopLevelProjectFile, @NotNull String version) {\n        if (!isTopLevelProjectFile) {\n            boolean wasModified = addElementsToProjectFile(groovyFile, version);\n            wasModified |= addElementsToModuleFile(groovyFile, version);\n            return wasModified;\n        }\n        return false;\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    protected void addSourceSetsBlock(@NotNull GroovyFile file) {\n        GrClosableBlock sourceSetBlock = getSourceSetsBlock(file);\n        addLastExpressionInBlockIfNeeded(SOURCE_SET, sourceSetBlock);\n    }","id":36452,"modified_method":"@Override\n    protected boolean addSourceSetsBlock(@NotNull GroovyFile file) {\n        GrClosableBlock sourceSetBlock = getSourceSetsBlock(file);\n        return addLastExpressionInBlockIfNeeded(SOURCE_SET, sourceSetBlock);\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected static void addElementsToProjectFile(@NotNull GroovyFile file, @NotNull String version) {\n        GrClosableBlock buildScriptBlock = getBuildScriptBlock(file);\n        addFirstExpressionInBlockIfNeeded(VERSION.replace(VERSION_TEMPLATE, version), buildScriptBlock);\n\n        GrClosableBlock buildScriptRepositoriesBlock = getBuildScriptRepositoriesBlock(file);\n        if (isSnapshot(version)) {\n            addLastExpressionInBlockIfNeeded(SNAPSHOT_REPOSITORY, buildScriptRepositoriesBlock);\n        }\n        else if (!isRepositoryConfigured(buildScriptRepositoriesBlock)) {\n            addLastExpressionInBlockIfNeeded(MAVEN_CENTRAL, buildScriptRepositoriesBlock);\n        }\n\n        GrClosableBlock buildScriptDependenciesBlock = getBuildScriptDependenciesBlock(file);\n        addLastExpressionInBlockIfNeeded(CLASSPATH, buildScriptDependenciesBlock);\n    }","id":36453,"modified_method":"protected static boolean addElementsToProjectFile(@NotNull GroovyFile file, @NotNull String version) {\n        boolean wasModified;\n\n        GrClosableBlock buildScriptBlock = getBuildScriptBlock(file);\n        wasModified = addFirstExpressionInBlockIfNeeded(VERSION.replace(VERSION_TEMPLATE, version), buildScriptBlock);\n\n        GrClosableBlock buildScriptRepositoriesBlock = getBuildScriptRepositoriesBlock(file);\n        if (isSnapshot(version)) {\n            wasModified |= addLastExpressionInBlockIfNeeded(SNAPSHOT_REPOSITORY, buildScriptRepositoriesBlock);\n        }\n        else if (!isRepositoryConfigured(buildScriptRepositoriesBlock)) {\n            wasModified |= addLastExpressionInBlockIfNeeded(MAVEN_CENTRAL, buildScriptRepositoriesBlock);\n        }\n\n        GrClosableBlock buildScriptDependenciesBlock = getBuildScriptDependenciesBlock(file);\n        wasModified |= addLastExpressionInBlockIfNeeded(CLASSPATH, buildScriptDependenciesBlock);\n\n        return wasModified;\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block, boolean isFirst) {\n        if (block.getText().contains(text)) return;\n        GrExpression newStatement = GroovyPsiElementFactory.getInstance(block.getProject()).createExpressionFromText(text);\n        CodeStyleManager.getInstance(block.getProject()).reformat(newStatement);\n        GrStatement[] statements = block.getStatements();\n        if (!isFirst && statements.length > 0) {\n            GrStatement lastStatement = statements[statements.length - 1];\n            if (lastStatement != null) {\n                block.addAfter(newStatement, lastStatement);\n            }\n        }\n        else {\n            PsiElement firstChild = block.getFirstChild();\n            if (firstChild != null) {\n                block.addAfter(newStatement, firstChild);\n            }\n        }\n    }","id":36454,"modified_method":"private static boolean addExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block, boolean isFirst, boolean forceInsert) {\n        if (!forceInsert && block.getText().contains(text)) return false;\n        GrExpression newStatement = GroovyPsiElementFactory.getInstance(block.getProject()).createExpressionFromText(text);\n        CodeStyleManager.getInstance(block.getProject()).reformat(newStatement);\n        GrStatement[] statements = block.getStatements();\n        if (!isFirst && statements.length > 0) {\n            GrStatement lastStatement = statements[statements.length - 1];\n            if (lastStatement != null) {\n                block.addAfter(newStatement, lastStatement);\n            }\n        }\n        else {\n            PsiElement firstChild = block.getFirstChild();\n            if (firstChild != null) {\n                block.addAfter(newStatement, firstChild);\n            }\n        }\n        return true;\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addFirstExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block) {\n        addExpressionInBlockIfNeeded(text, block, true);\n    }","id":36455,"modified_method":"private static boolean addFirstExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block) {\n        return addExpressionInBlockIfNeeded(text, block, true, false);\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected static void addLastExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block) {\n        addExpressionInBlockIfNeeded(text, block, false);\n    }","id":36456,"modified_method":"protected static boolean addLastExpressionInBlockIfNeeded(@NotNull String text, @NotNull GrClosableBlock block) {\n        return addExpressionInBlockIfNeeded(text, block, false, false);\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected boolean changeGradleFile(\n            @NotNull final GroovyFile groovyFile,\n            final boolean isTopLevelProjectFile,\n            @NotNull final String version,\n            @NotNull NotificationMessageCollector collector\n    ) {\n        final boolean[] isModified = {false};\n        new WriteCommandAction(groovyFile.getProject()) {\n            @Override\n            protected void run(@NotNull Result result) {\n                isModified[0] = addElementsToFile(groovyFile, isTopLevelProjectFile, version);\n\n                CodeInsightUtilCore.forcePsiPostprocessAndRestoreElement(groovyFile);\n            }\n        }.execute();\n\n        VirtualFile virtualFile = groovyFile.getVirtualFile();\n        if (virtualFile != null) {\n            collector.addMessage(virtualFile.getPath() + \" was modified\");\n        }\n        return isModified[0];\n    }","id":36457,"modified_method":"protected boolean changeGradleFile(\n            @NotNull final GroovyFile groovyFile,\n            final boolean isTopLevelProjectFile,\n            @NotNull final String version,\n            @NotNull NotificationMessageCollector collector\n    ) {\n        final boolean[] isModified = {false};\n        new WriteCommandAction(groovyFile.getProject()) {\n            @Override\n            protected void run(@NotNull Result result) {\n                isModified[0] = addElementsToFile(groovyFile, isTopLevelProjectFile, version);\n\n                CodeInsightUtilCore.forcePsiPostprocessAndRestoreElement(groovyFile);\n            }\n        }.execute();\n\n        VirtualFile virtualFile = groovyFile.getVirtualFile();\n        if (virtualFile != null && isModified[0]) {\n            collector.addMessage(virtualFile.getPath() + \" was modified\");\n        }\n        return isModified[0];\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected abstract void addSourceSetsBlock(@NotNull GroovyFile file);","id":36458,"modified_method":"protected abstract boolean addSourceSetsBlock(@NotNull GroovyFile file);","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected void addElementsToModuleFile(@NotNull GroovyFile file, @NotNull String version) {\n        if (!file.getText().contains(getApplyPluginDirective())) {\n            GrExpression apply = GroovyPsiElementFactory.getInstance(file.getProject()).createExpressionFromText(getApplyPluginDirective());\n            GrApplicationStatement applyStatement = getApplyStatement(file);\n            if (applyStatement != null) {\n                file.addAfter(apply, applyStatement);\n            }\n            else {\n                GrClosableBlock buildScript = getBlockByName(file, \"buildscript\");\n                if (buildScript != null) {\n                    file.addAfter(apply, buildScript.getParent());\n                }\n                else {\n                    GrStatement[] statements = file.getStatements();\n                    if (statements.length > 0) {\n                        file.addAfter(apply, statements[statements.length - 1]);\n                    }\n                    else {\n                        file.addAfter(apply, file.getFirstChild());\n                    }\n                }\n            }\n        }\n\n        GrClosableBlock repositoriesBlock = getRepositoriesBlock(file);\n        if (isSnapshot(version)) {\n            addLastExpressionInBlockIfNeeded(SNAPSHOT_REPOSITORY, repositoriesBlock);\n        }\n        else if (!isRepositoryConfigured(repositoriesBlock)) {\n            addLastExpressionInBlockIfNeeded(MAVEN_CENTRAL, repositoriesBlock);\n        }\n\n        GrClosableBlock dependenciesBlock = getDependenciesBlock(file);\n        addLastExpressionInBlockIfNeeded(LIBRARY, dependenciesBlock);\n\n        addSourceSetsBlock(file);\n    }","id":36459,"modified_method":"protected boolean addElementsToModuleFile(@NotNull GroovyFile file, @NotNull String version) {\n        boolean wasModified = false;\n\n        if (!file.getText().contains(getApplyPluginDirective())) {\n            GrExpression apply = GroovyPsiElementFactory.getInstance(file.getProject()).createExpressionFromText(getApplyPluginDirective());\n            GrApplicationStatement applyStatement = getApplyStatement(file);\n            if (applyStatement != null) {\n                file.addAfter(apply, applyStatement);\n                wasModified = true;\n            }\n            else {\n                GrClosableBlock buildScript = getBlockByName(file, \"buildscript\");\n                if (buildScript != null) {\n                    file.addAfter(apply, buildScript.getParent());\n                    wasModified = true;\n                }\n                else {\n                    GrStatement[] statements = file.getStatements();\n                    if (statements.length > 0) {\n                        file.addAfter(apply, statements[statements.length - 1]);\n                    }\n                    else {\n                        file.addAfter(apply, file.getFirstChild());\n                    }\n                    wasModified = true;\n                }\n            }\n        }\n\n        GrClosableBlock repositoriesBlock = getRepositoriesBlock(file);\n        if (isSnapshot(version)) {\n            wasModified |= addLastExpressionInBlockIfNeeded(SNAPSHOT_REPOSITORY, repositoriesBlock);\n        }\n        else if (!isRepositoryConfigured(repositoriesBlock)) {\n            wasModified |= addLastExpressionInBlockIfNeeded(MAVEN_CENTRAL, repositoriesBlock);\n        }\n\n        GrClosableBlock dependenciesBlock = getDependenciesBlock(file);\n        Module module = FileIndexFacade.getInstance(file.getProject()).getModuleForFile(file.getVirtualFile());\n        wasModified |= addExpressionInBlockIfNeeded(LIBRARY, dependenciesBlock, false, !ConfigureKotlinInProjectUtilsKt.hasKotlinRuntimeInScope(module));\n\n        wasModified |= addSourceSetsBlock(file);\n\n        return wasModified;\n    }","commit_id":"e31202ff7c4c27d9251078e2d8b1bac5fbe9a555","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Test public void compare() throws Exception {\n\n    // Testing different things\n    // Note: Microsoft reference implementation is only for Tanh + MSE, rectifier and MCE are implemented by 0xdata (trivial).\n    // Note: Initial weight distributions are copied, but what is tested is the stability behavior.\n    NeuralNet.Activation[] activations = { NeuralNet.Activation.Tanh, NeuralNet.Activation.Rectifier };\n    Loss[] losses = { NeuralNet.Loss.MeanSquare, NeuralNet.Loss.CrossEntropy };\n    NeuralNet.InitialWeightDistribution[] dists = {\n            NeuralNet.InitialWeightDistribution.Normal,\n            NeuralNet.InitialWeightDistribution.Uniform,\n            NeuralNet.InitialWeightDistribution.UniformAdaptive };\n    float[] initial_weight_scales = { 0.001f, 1.538f };\n\n    for (NeuralNet.Activation activation : activations) {\n      for (Loss loss : losses) {\n        for (NeuralNet.InitialWeightDistribution dist : dists) {\n          for (float scale : initial_weight_scales) {\n\n            Log.info(\"Testing \" + activation.name() + \" activation function with \" + loss.name() + \" loss function\");\n            Log.info(\"Testing \" + dist.name() + \" distribution with \" + scale + \" scale\");\n\n            NeuralNetMLPReference ref = new NeuralNetMLPReference();\n            ref.init(activation);\n\n            // Parse Iris and shuffle the same way as ref\n            Key file = NFSFileVec.make(new File(PATH));\n            Key pars = Key.make();\n            Frame frame = ParseDataset2.parse(pars, new Key[] { file });\n            UKV.remove(file);\n\n            double[][] rows = new double[(int) frame.numRows()][frame.numCols()];\n            for( int c = 0; c < frame.numCols(); c++ )\n              for( int r = 0; r < frame.numRows(); r++ )\n                rows[r][c] = frame.vecs()[c].at(r);\n\n            MersenneTwisterRNG rand = new MersenneTwisterRNG(MersenneTwisterRNG.SEEDS);\n//            Random rand = getRNG(); //TODO: why does this fail??\n            for( int i = rows.length - 1; i >= 0; i-- ) {\n              int shuffle = rand.nextInt(i + 1);\n              double[] row = rows[shuffle];\n              rows[shuffle] = rows[i];\n              rows[i] = row;\n            }\n\n            int limit = (int) frame.numRows() * 80 / 100;\n            _train = frame(null, Utils.subarray(rows, 0, limit));\n            _test = frame(null, Utils.subarray(rows, limit, (int) frame.numRows() - limit));\n            UKV.remove(pars);\n\n            Vec[] data = Utils.remove(_train.vecs(), _train.vecs().length - 1);\n            Vec labels = _train.vecs()[_train.vecs().length - 1];\n\n            NeuralNet p = new NeuralNet();\n            p.rate = 0.01f;\n            p.epochs = 1000;\n            p.activation = activation;\n            p.max_w2 = Float.MAX_VALUE;\n            p.rate = 0.01f;\n            p.epochs = 1000;\n            p.activation = activation;\n            p.max_w2 = Float.MAX_VALUE;\n            p.input_dropout_ratio = 0;\n            p.rate_annealing = 0;\n            p.l1 = 0;\n            p.l2 = 0;\n            p.momentum_start = 0;\n            p.momentum_ramp = 0;\n            p.momentum_stable = 0;\n            p.initial_weight_distribution = dist;\n            p.initial_weight_scale = scale;\n\n            Layer[] ls = new Layer[3];\n            ls[0] = new VecsInput(data, null);\n            if (activation == NeuralNet.Activation.Tanh) {\n              ls[1] = new Tanh(7);\n            }\n            else if (activation == NeuralNet.Activation.Rectifier) {\n              ls[1] = new Rectifier(7);\n            }\n            ls[2] = new VecSoftmax(labels, null, loss);\n\n            for( int i = 0; i < ls.length; i++ ) {\n              ls[i].init(ls, i, p);\n            }\n\n            // use the same random weights for the reference implementation\n            Layer l = ls[1];\n            for( int o = 0; o < l._a.length; o++ ) {\n              for( int i = 0; i < l._previous._a.length; i++ )\n                ref._nn.ihWeights[i][o] = l._w[o * l._previous._a.length + i];\n              ref._nn.hBiases[o] = l._b[o];\n            }\n            l = ls[2];\n            for( int o = 0; o < l._a.length; o++ ) {\n              for( int i = 0; i < l._previous._a.length; i++ )\n                ref._nn.hoWeights[i][o] = l._w[o * l._previous._a.length + i];\n              ref._nn.oBiases[o] = l._b[o];\n            }\n\n            // Reference\n            ref.train((int)p.epochs, (float)p.rate, loss);\n\n            // H2O\n            Trainer.Direct trainer = new Trainer.Direct(ls, p.epochs, null);\n            trainer.run();\n\n            // Make sure outputs are equal\n            float epsilon = 1e-4f;\n            for( int o = 0; o < ls[2]._a.length; o++ ) {\n              float a = ref._nn.outputs[o];\n              float b = ls[2]._a[o];\n              Assert.assertEquals(a, b, epsilon);\n            }\n\n            // Make sure weights are equal\n            l = ls[1];\n            for( int o = 0; o < l._a.length; o++ ) {\n              for( int i = 0; i < l._previous._a.length; i++ ) {\n                float a = ref._nn.ihWeights[i][o];\n                float b = l._w[o * l._previous._a.length + i];\n                Assert.assertEquals(a, b, epsilon);\n              }\n            }\n\n            // Make sure errors are equal\n            NeuralNet.Errors train = NeuralNet.eval(ls, 0, null);\n            data = Utils.remove(_test.vecs(), _test.vecs().length - 1);\n            labels = _test.vecs()[_test.vecs().length - 1];\n            VecsInput input = (VecsInput) ls[0];\n            input.vecs = data;\n            input._len = data[0].length();\n            ((VecSoftmax) ls[2]).vec = labels;\n            NeuralNet.Errors test = NeuralNet.eval(ls, 0, null);\n            float trainAcc = ref._nn.Accuracy(ref._trainData);\n            Assert.assertEquals(trainAcc, train.classification, epsilon);\n            float testAcc = ref._nn.Accuracy(ref._testData);\n            Assert.assertEquals(testAcc, test.classification, epsilon);\n\n            Log.info(\"H2O and Reference equal, train: \" + train + \", test: \" + test);\n\n            for( int i = 0; i < ls.length; i++ )\n              ls[i].close();\n            _train.remove();\n            _test.remove();\n          }\n        }\n      }\n    }\n  }","id":36460,"modified_method":"@Test public void compare() throws Exception {\n\n    // Testing different things\n    // Note: Microsoft reference implementation is only for Tanh + MSE, rectifier and MCE are implemented by 0xdata (trivial).\n    // Note: Initial weight distributions are copied, but what is tested is the stability behavior.\n    NeuralNet.Activation[] activations = { NeuralNet.Activation.Tanh, NeuralNet.Activation.Rectifier };\n    Loss[] losses = { NeuralNet.Loss.MeanSquare, NeuralNet.Loss.CrossEntropy };\n    NeuralNet.InitialWeightDistribution[] dists = {\n            NeuralNet.InitialWeightDistribution.Normal,\n            //NeuralNet.InitialWeightDistribution.Uniform,\n            NeuralNet.InitialWeightDistribution.UniformAdaptive };\n    float[] initial_weight_scales = { 0.02f, 1.538f };\n    double[] holdout_ratios = { 0.8 };\n\n    for (NeuralNet.Activation activation : activations) {\n      for (Loss loss : losses) {\n        for (NeuralNet.InitialWeightDistribution dist : dists) {\n          for (float scale : initial_weight_scales) {\n            for (double holdout_ratio : holdout_ratios) {\n\n              Log.info(\"Testing \" + activation.name() + \" activation function with \" + loss.name() + \" loss function\");\n              Log.info(\"Testing \" + dist.name() + \" distribution with \" + scale + \" scale\");\n              Log.info(\"Testing holdout ratio \" + holdout_ratio);\n\n              NeuralNetMLPReference ref = new NeuralNetMLPReference();\n\n              final long seed = 0xDEADBEEF;\n              Log.info(\"Using seed \" + seed);\n              ref.init(activation, water.util.Utils.getDeterRNG(seed), holdout_ratio);\n\n              // Parse Iris and shuffle the same way as ref\n              Key file = NFSFileVec.make(new File(PATH));\n              Key pars = Key.make();\n              Frame frame = ParseDataset2.parse(pars, new Key[] { file });\n              UKV.remove(file);\n\n              double[][] rows = new double[(int) frame.numRows()][frame.numCols()];\n              for( int c = 0; c < frame.numCols(); c++ )\n                for( int r = 0; r < frame.numRows(); r++ )\n                  rows[r][c] = frame.vecs()[c].at(r);\n\n              Random rand = water.util.Utils.getDeterRNG(seed);\n              for( int i = rows.length - 1; i >= 0; i-- ) {\n                int shuffle = rand.nextInt(i + 1);\n                double[] row = rows[shuffle];\n                rows[shuffle] = rows[i];\n                rows[i] = row;\n              }\n\n              int limit = (int) (frame.numRows() * holdout_ratio);\n              _train = frame(null, Utils.subarray(rows, 0, limit));\n              _test = frame(null, Utils.subarray(rows, limit, (int) frame.numRows() - limit));\n              UKV.remove(pars);\n\n              Vec[] data = Utils.remove(_train.vecs(), _train.vecs().length - 1);\n              Vec labels = _train.vecs()[_train.vecs().length - 1];\n\n              NeuralNet p = new NeuralNet();\n              p.rate = 0.01f;\n              p.epochs = 1000;\n              p.activation = activation;\n              p.max_w2 = Float.MAX_VALUE;\n              p.rate = 0.01f;\n              p.epochs = 1000;\n              p.activation = activation;\n              p.max_w2 = Float.MAX_VALUE;\n              p.input_dropout_ratio = 0;\n              p.rate_annealing = 0;\n              p.l1 = 0;\n              p.l2 = 0;\n              p.momentum_start = 0;\n              p.momentum_ramp = 0;\n              p.momentum_stable = 0;\n              p.initial_weight_distribution = dist;\n              p.initial_weight_scale = scale;\n\n              Layer[] ls = new Layer[3];\n              ls[0] = new VecsInput(data, null);\n              if (activation == NeuralNet.Activation.Tanh) {\n                ls[1] = new Tanh(7);\n              }\n              else if (activation == NeuralNet.Activation.Rectifier) {\n                ls[1] = new Rectifier(7);\n              }\n              ls[2] = new VecSoftmax(labels, null, loss);\n\n              for( int i = 0; i < ls.length; i++ ) {\n                ls[i].init(ls, i, p);\n              }\n\n              // use the same random weights for the reference implementation\n              Layer l = ls[1];\n              for( int o = 0; o < l._a.length; o++ ) {\n                for( int i = 0; i < l._previous._a.length; i++ )\n                  ref._nn.ihWeights[i][o] = l._w[o * l._previous._a.length + i];\n                ref._nn.hBiases[o] = l._b[o];\n              }\n              l = ls[2];\n              for( int o = 0; o < l._a.length; o++ ) {\n                for( int i = 0; i < l._previous._a.length; i++ )\n                  ref._nn.hoWeights[i][o] = l._w[o * l._previous._a.length + i];\n                ref._nn.oBiases[o] = l._b[o];\n              }\n\n              // Reference\n              ref.train((int)p.epochs, (float)p.rate, loss);\n\n              // H2O\n              Trainer.Direct trainer = new Trainer.Direct(ls, p.epochs, null);\n              trainer.run();\n\n              float epsilon = 1e-4f;\n              for( int o = 0; o < ls[2]._a.length; o++ ) {\n                float a = ref._nn.outputs[o];\n                float b = ls[2]._a[o];\n                Assert.assertEquals(a, b, epsilon); //absolute error\n                if (a != b) Assert.assertTrue(Math.abs(a-b)/Math.max(a,b) < 10*epsilon); //relative error\n              }\n\n              // Make sure weights are equal\n              l = ls[1];\n              for( int o = 0; o < l._a.length; o++ ) {\n                for( int i = 0; i < l._previous._a.length; i++ ) {\n                  float a = ref._nn.ihWeights[i][o];\n                  float b = l._w[o * l._previous._a.length + i];\n                  Assert.assertEquals(a, b, epsilon); //absolute error\n                  if (a != b) Assert.assertTrue(Math.abs(a-b)/Math.max(a,b) < 10*epsilon); //relative error\n                }\n              }\n\n              // Make sure errors are equal\n              NeuralNet.Errors train = NeuralNet.eval(ls, 0, null);\n              data = Utils.remove(_test.vecs(), _test.vecs().length - 1);\n              labels = _test.vecs()[_test.vecs().length - 1];\n              VecsInput input = (VecsInput) ls[0];\n              input.vecs = data;\n              input._len = data[0].length();\n              ((VecSoftmax) ls[2]).vec = labels;\n              NeuralNet.Errors test = NeuralNet.eval(ls, 0, null);\n              float trainAcc = ref._nn.Accuracy(ref._trainData);\n              Assert.assertEquals(trainAcc, train.classification, epsilon);\n              float testAcc = ref._nn.Accuracy(ref._testData);\n              Assert.assertEquals(testAcc, test.classification, epsilon);\n\n              Log.info(\"H2O and Reference equal, train: \" + train + \", test: \" + test);\n\n              for( int i = 0; i < ls.length; i++ )\n                ls[i].close();\n              _train.remove();\n              _test.remove();\n            }\n          }\n        }\n      }\n    }\n  }","commit_id":"78af2fd57ee994749a916df77708e621d2036e56","url":"https://github.com/h2oai/h2o-2"},{"original_method":"static void shuffle(int[] sequence) {\n      MersenneTwisterRNG rand = new MersenneTwisterRNG(MersenneTwisterRNG.SEEDS);\n      for( int i = sequence.length - 1; i >= 0; i-- ) {\n        int r = rand.nextInt(i + 1);\n        int tmp = sequence[r];\n        sequence[r] = sequence[i];\n        sequence[i] = tmp;\n      }\n    }","id":36461,"modified_method":"static void shuffle(int[] sequence, Random rand) {\n      for( int i = sequence.length - 1; i >= 0; i-- ) {\n        int r = rand.nextInt(i + 1);\n        int tmp = sequence[r];\n        sequence[r] = sequence[i];\n        sequence[i] = tmp;\n      }\n    }","commit_id":"78af2fd57ee994749a916df77708e621d2036e56","url":"https://github.com/h2oai/h2o-2"},{"original_method":"void init(NeuralNet.Activation activation) {\n    double[][] ds = new double[150][];\n    int r = 0;\n    ds[r++] = new double[] { 5.1, 3.5, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.7, 3.2, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.1, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.6, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.9, 1.7, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.4, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.4, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 2.9, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.7, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.4, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3, 1.4, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 4.3, 3, 1.1, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.8, 4, 1.2, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.7, 4.4, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.9, 1.3, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.5, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.7, 3.8, 1.7, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.5, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.4, 1.7, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.7, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.6, 1, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.3, 1.7, 0.5, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.4, 1.9, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.4, 1.6, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 3.5, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 3.4, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.7, 3.2, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.1, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.4, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 4.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.5, 4.2, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.2, 1.2, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.5, 3.5, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 3, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.4, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.5, 1.3, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 4.5, 2.3, 1.3, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 3.2, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.5, 1.6, 0.6, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.9, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.2, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.3, 3.7, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.3, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 7, 3.2, 4.7, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.4, 3.2, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 4.9, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.3, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.5, 2.8, 4.6, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.8, 4.5, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 3.3, 4.7, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 4.9, 2.4, 3.3, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.6, 2.9, 4.6, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.2, 2.7, 3.9, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5, 2, 3.5, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.9, 3, 4.2, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.2, 4, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.9, 4.7, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.9, 3.6, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 4.4, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 3, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 4.1, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.2, 2.2, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.5, 3.9, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.9, 3.2, 4.8, 1.8, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.8, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 2.5, 4.9, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.8, 4.7, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6.4, 2.9, 4.3, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.6, 3, 4.4, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.8, 2.8, 4.8, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3, 5, 1.7, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.9, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.6, 3.5, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.4, 3.8, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.4, 3.7, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 3.9, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.7, 5.1, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 5.4, 3, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 3.4, 4.5, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 4.7, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 2.3, 4.4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 3, 4.1, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.5, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.6, 4.4, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 3, 4.6, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.6, 4, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 5, 2.3, 3.3, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.7, 4.2, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 3, 4.2, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.9, 4.2, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.2, 2.9, 4.3, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.1, 2.5, 3, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.8, 4.1, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 3.3, 6, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 5.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 7.1, 3, 5.9, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.9, 5.6, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.8, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.6, 3, 6.6, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 4.9, 2.5, 4.5, 1.7, 1, 0, 0 };\n    ds[r++] = new double[] { 7.3, 2.9, 6.3, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 2.5, 5.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3.6, 6.1, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3.2, 5.1, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.7, 5.3, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.8, 3, 5.5, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 5.7, 2.5, 5, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.8, 5.1, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 3.2, 5.3, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.5, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 3.8, 6.7, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 2.6, 6.9, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6, 2.2, 5, 1.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.2, 5.7, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.6, 2.8, 4.9, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 2.8, 6.7, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.7, 4.9, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.3, 5.7, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3.2, 6, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.2, 2.8, 4.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.1, 3, 4.9, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.8, 5.6, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3, 5.8, 1.6, 1, 0, 0 };\n    ds[r++] = new double[] { 7.4, 2.8, 6.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 7.9, 3.8, 6.4, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.8, 5.6, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.8, 5.1, 1.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.1, 2.6, 5.6, 1.4, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 3, 6.1, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 3.4, 5.6, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 3.1, 5.5, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6, 3, 4.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 5.4, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 5.6, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 5.1, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 5.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.8, 3.2, 5.9, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.3, 5.7, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3, 5.2, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.5, 5, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.2, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.2, 3.4, 5.4, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.9, 3, 5.1, 1.8, 1, 0, 0 };\n\n    float[][] allData = new float[ds.length][ds[0].length];\n    for( int j = 0; j < allData.length; j++ ) {\n      for( int i = 0; i < allData[j].length; i++ )\n        allData[j][i] = (float) ds[j][i];\n\n      allData[j][4] = (float) ds[j][6];\n      allData[j][5] = (float) ds[j][5];\n      allData[j][6] = (float) ds[j][4];\n    }\n\n    int trainRows = (int) (allData.length * 0.80);\n    int testRows = allData.length - trainRows;\n    _trainData = new float[trainRows][];\n    _testData = new float[testRows][];\n    MakeTrainTest(allData, _trainData, _testData);\n\n    // Normalize all data using train stats\n    for( int i = 0; i < 4; i++ ) {\n      double mean = 0;\n      for( int n = 0; n < _trainData.length; n++ )\n        mean += _trainData[n][i];\n      mean /= _trainData.length;\n\n      double sigma = 0;\n      for( int n = 0; n < _trainData.length; n++ ) {\n        double d = _trainData[n][i] - mean;\n        sigma += d * d;\n      }\n      sigma = Math.sqrt(sigma / (_trainData.length - 1));\n      for( int n = 0; n < _trainData.length; n++ ) {\n        _trainData[n][i] -= mean;\n        _trainData[n][i] /= sigma;\n      }\n      for( int n = 0; n < _testData.length; n++ ) {\n        _testData[n][i] -= mean;\n        _testData[n][i] /= sigma;\n      }\n    }\n\n    int numInput = 4;\n    int numHidden = 7;\n    int numOutput = 3;\n    _nn = new NeuralNetwork(activation, numInput, numHidden, numOutput);\n    _nn.InitializeWeights();\n  }","id":36462,"modified_method":"void init(NeuralNet.Activation activation, Random rand, double holdout_ratio) {\n    double[][] ds = new double[150][];\n    int r = 0;\n    ds[r++] = new double[] { 5.1, 3.5, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.7, 3.2, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.1, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.6, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.9, 1.7, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.4, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.4, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 2.9, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.7, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.4, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3, 1.4, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 4.3, 3, 1.1, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.8, 4, 1.2, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.7, 4.4, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.9, 1.3, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.5, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.7, 3.8, 1.7, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.5, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.4, 1.7, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.7, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.6, 1, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.3, 1.7, 0.5, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.4, 1.9, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.4, 1.6, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 3.5, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 3.4, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.7, 3.2, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3.1, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.4, 3.4, 1.5, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 5.2, 4.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5.5, 4.2, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.2, 1.2, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.5, 3.5, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.9, 3.1, 1.5, 0.1, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 3, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.4, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.5, 1.3, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 4.5, 2.3, 1.3, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 4.4, 3.2, 1.3, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.5, 1.6, 0.6, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.9, 0.4, 0, 0, 1 };\n    ds[r++] = new double[] { 4.8, 3, 1.4, 0.3, 0, 0, 1 };\n    ds[r++] = new double[] { 5.1, 3.8, 1.6, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 4.6, 3.2, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5.3, 3.7, 1.5, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 5, 3.3, 1.4, 0.2, 0, 0, 1 };\n    ds[r++] = new double[] { 7, 3.2, 4.7, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.4, 3.2, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 4.9, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.3, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.5, 2.8, 4.6, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.8, 4.5, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 3.3, 4.7, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 4.9, 2.4, 3.3, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.6, 2.9, 4.6, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.2, 2.7, 3.9, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5, 2, 3.5, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.9, 3, 4.2, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.2, 4, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.9, 4.7, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.9, 3.6, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 4.4, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 3, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 4.1, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 6.2, 2.2, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.5, 3.9, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.9, 3.2, 4.8, 1.8, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.8, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 2.5, 4.9, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 2.8, 4.7, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6.4, 2.9, 4.3, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.6, 3, 4.4, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.8, 2.8, 4.8, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3, 5, 1.7, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.9, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.6, 3.5, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.4, 3.8, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.4, 3.7, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 3.9, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 2.7, 5.1, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 5.4, 3, 4.5, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6, 3.4, 4.5, 1.6, 0, 1, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 4.7, 1.5, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 2.3, 4.4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 3, 4.1, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.5, 4, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.5, 2.6, 4.4, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 6.1, 3, 4.6, 1.4, 0, 1, 0 };\n    ds[r++] = new double[] { 5.8, 2.6, 4, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 5, 2.3, 3.3, 1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.6, 2.7, 4.2, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 3, 4.2, 1.2, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.9, 4.2, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.2, 2.9, 4.3, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 5.1, 2.5, 3, 1.1, 0, 1, 0 };\n    ds[r++] = new double[] { 5.7, 2.8, 4.1, 1.3, 0, 1, 0 };\n    ds[r++] = new double[] { 6.3, 3.3, 6, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 5.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 7.1, 3, 5.9, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.9, 5.6, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.8, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.6, 3, 6.6, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 4.9, 2.5, 4.5, 1.7, 1, 0, 0 };\n    ds[r++] = new double[] { 7.3, 2.9, 6.3, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 2.5, 5.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3.6, 6.1, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3.2, 5.1, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.7, 5.3, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.8, 3, 5.5, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 5.7, 2.5, 5, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.8, 5.1, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 3.2, 5.3, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.5, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 3.8, 6.7, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 2.6, 6.9, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6, 2.2, 5, 1.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.2, 5.7, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.6, 2.8, 4.9, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 2.8, 6.7, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.7, 4.9, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.3, 5.7, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3.2, 6, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.2, 2.8, 4.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.1, 3, 4.9, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.8, 5.6, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 7.2, 3, 5.8, 1.6, 1, 0, 0 };\n    ds[r++] = new double[] { 7.4, 2.8, 6.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 7.9, 3.8, 6.4, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 2.8, 5.6, 2.2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.8, 5.1, 1.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.1, 2.6, 5.6, 1.4, 1, 0, 0 };\n    ds[r++] = new double[] { 7.7, 3, 6.1, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 3.4, 5.6, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.4, 3.1, 5.5, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6, 3, 4.8, 1.8, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 5.4, 2.1, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.1, 5.6, 2.4, 1, 0, 0 };\n    ds[r++] = new double[] { 6.9, 3.1, 5.1, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.8, 2.7, 5.1, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.8, 3.2, 5.9, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3.3, 5.7, 2.5, 1, 0, 0 };\n    ds[r++] = new double[] { 6.7, 3, 5.2, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 6.3, 2.5, 5, 1.9, 1, 0, 0 };\n    ds[r++] = new double[] { 6.5, 3, 5.2, 2, 1, 0, 0 };\n    ds[r++] = new double[] { 6.2, 3.4, 5.4, 2.3, 1, 0, 0 };\n    ds[r++] = new double[] { 5.9, 3, 5.1, 1.8, 1, 0, 0 };\n\n    float[][] allData = new float[ds.length][ds[0].length];\n    for( int j = 0; j < allData.length; j++ ) {\n      for( int i = 0; i < allData[j].length; i++ )\n        allData[j][i] = (float) ds[j][i];\n\n      allData[j][4] = (float) ds[j][6];\n      allData[j][5] = (float) ds[j][5];\n      allData[j][6] = (float) ds[j][4];\n    }\n\n    int trainRows = (int) (allData.length * holdout_ratio);\n    int testRows = allData.length - trainRows;\n    _trainData = new float[trainRows][];\n    _testData = new float[testRows][];\n    MakeTrainTest(allData, _trainData, _testData, rand);\n\n    // Normalize all data using train stats\n    for( int i = 0; i < 4; i++ ) {\n      double mean = 0;\n      for( int n = 0; n < _trainData.length; n++ )\n        mean += _trainData[n][i];\n      mean /= _trainData.length;\n\n      double sigma = 0;\n      for( int n = 0; n < _trainData.length; n++ ) {\n        double d = _trainData[n][i] - mean;\n        sigma += d * d;\n      }\n      sigma = Math.sqrt(sigma / (_trainData.length - 1));\n      for( int n = 0; n < _trainData.length; n++ ) {\n        _trainData[n][i] -= mean;\n        _trainData[n][i] /= sigma;\n      }\n      for( int n = 0; n < _testData.length; n++ ) {\n        _testData[n][i] -= mean;\n        _testData[n][i] /= sigma;\n      }\n    }\n\n    int numInput = 4;\n    int numHidden = 7;\n    int numOutput = 3;\n    _nn = new NeuralNetwork(activation, numInput, numHidden, numOutput);\n    _nn.InitializeWeights();\n  }","commit_id":"78af2fd57ee994749a916df77708e621d2036e56","url":"https://github.com/h2oai/h2o-2"},{"original_method":"void MakeTrainTest(float[][] allData, float[][] trainData, float[][] testData) {\n    // split allData into 80% trainData and 20% testData\n    int numCols = allData[0].length;\n\n    int[] shuffle = new int[allData.length]; // create a random sequence of indexes\n    for( int i = 0; i < shuffle.length; ++i )\n      shuffle[i] = i;\n    NeuralNetwork.shuffle(shuffle);\n\n    int si = 0; // index into sequence[]\n    int j = 0; // index into trainData or testData\n\n    for( ; si < trainData.length; ++si ) // first rows to train data\n    {\n      trainData[j] = new float[numCols];\n      int idx = shuffle[si];\n      System.arraycopy(allData[idx], 0, trainData[j], 0, numCols);\n      ++j;\n    }\n\n    j = 0; // reset to start of test data\n    for( ; si < allData.length; ++si ) // remainder to test data\n    {\n      testData[j] = new float[numCols];\n      int idx = shuffle[si];\n      System.arraycopy(allData[idx], 0, testData[j], 0, numCols);\n      ++j;\n    }\n  }","id":36463,"modified_method":"void MakeTrainTest(float[][] allData, float[][] trainData, float[][] testData, Random rand) {\n    // split allData into 80% trainData and 20% testData\n    int numCols = allData[0].length;\n\n    int[] shuffle = new int[allData.length]; // create a random sequence of indexes\n    for( int i = 0; i < shuffle.length; ++i )\n      shuffle[i] = i;\n    NeuralNetwork.shuffle(shuffle, rand);\n\n    int si = 0; // index into sequence[]\n    int j = 0; // index into trainData or testData\n\n    for( ; si < trainData.length; ++si ) // first rows to train data\n    {\n      trainData[j] = new float[numCols];\n      int idx = shuffle[si];\n      System.arraycopy(allData[idx], 0, trainData[j], 0, numCols);\n      ++j;\n    }\n\n    j = 0; // reset to start of test data\n    for( ; si < allData.length; ++si ) // remainder to test data\n    {\n      testData[j] = new float[numCols];\n      int idx = shuffle[si];\n      System.arraycopy(allData[idx], 0, testData[j], 0, numCols);\n      ++j;\n    }\n  }","commit_id":"78af2fd57ee994749a916df77708e621d2036e56","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public NNModel buildModel(NNModel model) {\n    logStart();\n    lock();\n    Log.info(\"Number of chunks of the training data: \" + source.anyVec().nChunks());\n    if (validation != null)\n      Log.info(\"Number of chunks of the validation data: \" + validation.anyVec().nChunks());\n    if (model == null) model = UKV.get(dest());\n\n    final long model_size = model.model_info().size();\n    Log.info(\"Number of model parameters (weights/biases): \" + String.format(\"%,d\", model_size));\n    Log.info(\"Memory usage of the model: \" + String.format(\"%.2f\", (double)model_size*Float.SIZE / (1<<23)) + \" MB.\");\n\n    model.delete_and_lock(self()); //claim ownership of the model\n\n    final Frame[] valid_adapted = validation == null ? null : model.adapt(validation, false);\n    Frame train = _dinfo._adaptedFrame;\n    Frame valid = validation == null ? null : valid_adapted[0];\n\n    // Optionally downsample data for scoring\n    Frame trainScoreFrame = sampleFrame(train, score_training_samples, seed);\n    Frame validScoreFrame = sampleFrame(valid, score_validation_samples, seed+1);\n\n    if (sync_samples > train.numRows()) {\n      Log.warn(\"Setting sync_samples (\" + sync_samples\n              + \") to the number of rows of the training data (\" + (sync_samples=train.numRows()) + \").\");\n    }\n    // determines the number of rows processed during NNTask, affects synchronization (happens at the end of each NNTask)\n    final float sync_fraction = sync_samples == 0l ? 1.0f : (float)sync_samples / train.numRows();\n\n    Log.info(\"Starting to train the Neural Net model.\");\n    long timeStart = System.currentTimeMillis();\n    //main loop\n    do {\n//      shuffle();\n      NNTask nntask = new NNTask(_dinfo, model.model_info(), true, sync_fraction, shuffle_training_data).doAll(train);\n      model.set_model_info(nntask.model_info());\n    } while (model.doDiagnostics(trainScoreFrame, validScoreFrame, timeStart, self()));\n\n    model.unlock(self()); //release model ownership\n\n    //delete temporary frames\n    if (validScoreFrame != null && validScoreFrame != valid) validScoreFrame.delete();\n    if (trainScoreFrame != null && trainScoreFrame != train) trainScoreFrame.delete();\n    if (validation != null) valid_adapted[1].delete(); //just deleted the adapted frames for validation\n//    if (_newsource != null && _newsource != source) _newsource.delete();\n\n    unlock();\n    delete();\n\n    Log.info(\"Finished training the Neural Net model.\");\n    return model;\n  }","id":36464,"modified_method":"public final NNModel buildModel(NNModel model) {\n    lock_data();\n    logStart();\n    Log.info(\"Number of chunks of the training data: \" + source.anyVec().nChunks());\n    if (validation != null)\n      Log.info(\"Number of chunks of the validation data: \" + validation.anyVec().nChunks());\n    if (model == null) {\n      model = UKV.get(dest());\n    }\n    model.write_lock(self());\n    Log.info(\"Initial model:\\n\" + model.model_info());\n\n    final long model_size = model.model_info().size();\n    Log.info(\"Number of model parameters (weights/biases): \" + String.format(\"%,d\", model_size));\n    Log.info(\"Memory usage of the model: \" + String.format(\"%.2f\", (double)model_size*Float.SIZE / (1<<23)) + \" MB.\");\n\n    final Frame train = model.model_info().data_info()._adaptedFrame;\n    Frame trainScoreFrame = sampleFrame(train, score_training_samples, seed);\n\n    Frame[] valid_adapted = null;\n    Frame valid = null;\n    Frame validScoreFrame = null;\n    if (validation != null) {\n      valid_adapted = model.adapt(validation, false);\n      valid = valid_adapted[0];\n      validScoreFrame = valid != validation ? sampleFrame(valid, score_validation_samples, seed+1) : null;\n    }\n\n    if (sync_samples > train.numRows()) {\n      Log.warn(\"Setting sync_samples (\" + sync_samples\n              + \") to the number of rows of the training data (\" + (sync_samples=train.numRows()) + \").\");\n    }\n    // determines the number of rows processed during NNTask, affects synchronization (happens at the end of each NNTask)\n    final float sync_fraction = sync_samples == 0l ? 1.0f : (float)sync_samples / train.numRows();\n\n    Log.info(\"Starting to train the Neural Net model.\");\n    long timeStart = System.currentTimeMillis();\n\n    //main loop\n    do model.set_model_info(new NNTask(model.model_info(), true /*train*/, sync_fraction).doAll(train).model_info());\n    while (model.doDiagnostics(trainScoreFrame, validScoreFrame, timeStart, self()));\n    model.unlock(self());\n\n    //clean up\n    if (validScoreFrame != null && validScoreFrame != valid) validScoreFrame.delete();\n    if (trainScoreFrame != null && trainScoreFrame != train) trainScoreFrame.delete();\n    if (validation != null) valid_adapted[1].delete(); //just deleted the adapted frames for validation\n//    if (_newsource != null && _newsource != source) _newsource.delete();\n    unlock_data();\n    Log.info(\"Finished training the Neural Net model.\");\n    return model;\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override public JobState exec() {\n    buildModel(initModel());\n    return JobState.DONE;\n  }","id":36465,"modified_method":"@Override public JobState exec() {\n    buildModel(initModel());\n    delete();\n    return JobState.DONE;\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public NNModel initModel() {\n    checkParams();\n    lock();\n    if (_dinfo == null)\n      _dinfo = new FrameTask.DataInfo(FrameTask.DataInfo.prepareFrame(source, response, ignored_cols, classification, ignore_const_cols), 1, true, !classification);\n    NNModel model = new NNModel(dest(), self(), source._key, _dinfo, this);\n    model.model_info().initializeMembers();\n    //Log.info(\"Initial model:\\n\" + model.model_info());\n    unlock();\n    return model;\n  }","id":36466,"modified_method":"public final NNModel initModel() {\n    checkParams();\n    lock_data();\n    final Frame train = FrameTask.DataInfo.prepareFrame(source, response, ignored_cols, classification, ignore_const_cols);\n    final DataInfo dinfo = new FrameTask.DataInfo(train, 1, true, !classification);\n    final NNModel model = new NNModel(dest(), self(), source._key, dinfo, this);\n    unlock_data();\n    model.model_info().initializeMembers();\n    return model;\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private void unlock() {\n    source.unlock(self());\n    if( validation != null && !source._key.equals(validation._key) )\n      validation.unlock(self());\n  }","id":36467,"modified_method":"private void unlock_data() {\n    source.unlock(self());\n    if( validation != null && !source._key.equals(validation._key) )\n      validation.unlock(self());\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private void delete() {\n    if (_fakejob) UKV.remove(job_key);\n    remove();\n  }","id":36468,"modified_method":"public void delete() {\n    if (_fakejob) UKV.remove(job_key);\n    remove();\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public boolean generateHTML(String title, StringBuilder sb) {\n    if (_key == null) {\n      DocGen.HTML.title(sb, \"No model yet\");\n      return true;\n    }\n\n    final String mse_format = \"%g\";\n    final String cross_entropy_format = \"%2.6f\";\n\n    DocGen.HTML.title(sb, title);\n    DocGen.HTML.paragraph(sb, \"Model type: \" + (model_info().parameters.classification ? \" Classification\" : \" Regression\"));\n    DocGen.HTML.paragraph(sb, \"Model Key: \" + _key);\n    DocGen.HTML.paragraph(sb, \"Job Key: \" + jobKey);\n    Inspect2 is2 = new Inspect2();\n    DocGen.HTML.paragraph(sb, \"Training Data Key: \" + _dataKey);\n    if (model_info.parameters.validation != null) {\n      DocGen.HTML.paragraph(sb, \"Validation Data Key: \" + model_info.parameters.validation._key);\n    }\n    DocGen.HTML.paragraph(sb, \"Number of model parameters (weights/biases): \" + String.format(\"%,d\", model_info().size()));\n\n    model_info.job().toHTML(sb);\n    sb.append(\"<div class='alert'>Actions: \"\n            + (Job.isRunning(jobKey) ? Cancel.link(jobKey, \"Cancel job\") + \", \" : \"\")\n            + is2.link(\"Inspect training data\", _dataKey) + \", \"\n            + (model_info().parameters.validation != null ? (is2.link(\"Inspect validation data\", model_info().parameters.validation._key) + \", \") : \"\")\n            + water.api.Predict.link(_key, \"Score on dataset\") + \", \" +\n            NN.link(_dataKey, \"Compute new model\") + \"<\/div>\");\n\n    // stats for training and validation\n    final Errors error = errors[errors.length - 1];\n    assert(error != null);\n\n    if (errors.length > 1) {\n      if (isClassifier()) {\n        // Plot training error\n        float[] err = new float[errors.length];\n        float[] samples = new float[errors.length];\n        for (int i=0; i<err.length; ++i) {\n          err[i] = (float)errors[i].train_err;\n          samples[i] = errors[i].training_samples;\n        }\n        new D3Plot(samples, err, \"training samples\", \"classification error\",\n                \"Classification Error on Training Set\").generate(sb);\n\n        // Plot validation error\n        if (model_info.parameters.validation != null) {\n          for (int i=0; i<err.length; ++i) {\n            err[i] = (float)errors[i].valid_err;\n          }\n          new D3Plot(samples, err, \"training samples\", \"classification error\",\n                  \"Classification Error on Validation Set\").generate(sb);\n        }\n      } else {\n        // Plot training MSE\n        float[] err = new float[errors.length-1];\n        float[] samples = new float[errors.length-1];\n        for (int i=0; i<err.length; ++i) {\n          err[i] = (float)errors[i+1].train_mse;\n          samples[i] = errors[i+1].training_samples;\n        }\n        new D3Plot(samples, err, \"training samples\", \"MSE\",\n                \"Regression Error on Training Set\").generate(sb);\n\n        // Plot validation MSE\n        if (model_info.parameters.validation != null) {\n          for (int i=0; i<err.length; ++i) {\n            err[i] = (float)errors[i+1].valid_mse;\n          }\n          new D3Plot(samples, err, \"training samples\", \"MSE\",\n                  \"Regression Error on Validation Set\").generate(sb);\n        }\n      }\n    }\n\n    DocGen.HTML.section(sb, \"Predicting: \" + responseName());\n    if (isClassifier()) {\n      DocGen.HTML.section(sb, \"Training classification error: \" + formatPct(error.train_err));\n//      DocGen.HTML.section(sb, \"Training cross entropy: \" + String.format(cross_entropy_format, error.train_mce));\n      if(error.validation) {\n        DocGen.HTML.section(sb, \"Validation classification error: \" + formatPct(error.valid_err));\n//        DocGen.HTML.section(sb, \"Validation mean cross entropy: \" + String.format(cross_entropy_format, error.valid_mce));\n      }\n    } else {\n      DocGen.HTML.section(sb, \"Training mean squared error: \" + String.format(mse_format, error.train_mse));\n      if(error.validation) {\n        DocGen.HTML.section(sb, \"Validation mean squared error: \" + String.format(mse_format, error.valid_mse));\n      }\n    }\n    if (error.training_time_ms > 0)\n      DocGen.HTML.section(sb, \"Training speed: \" + error.training_samples * 1000 / error.training_time_ms + \" samples/s\");\n    if (model_info.parameters != null && model_info.parameters.diagnostics) {\n      DocGen.HTML.section(sb, \"Status of Neuron Layers\");\n      sb.append(\"<table class='table table-striped table-bordered table-condensed'>\");\n      sb.append(\"<tr>\");\n      sb.append(\"<th>\").append(\"#\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Units\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Type\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Dropout\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Rate\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"L1\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"L2\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Momentum\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Weight (Mean, RMS)\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Bias (Mean, RMS)\").append(\"<\/th>\");\n      sb.append(\"<\/tr>\");\n      Neurons[] neurons = NNTask.makeNeuronsForTesting(model_info()); //link the weights to the neurons, for easy access\n      for (int i=0; i<neurons.length; ++i) {\n        sb.append(\"<tr>\");\n        sb.append(\"<td>\").append(\"<b>\").append(i+1).append(\"<\/b>\").append(\"<\/td>\");\n        sb.append(\"<td>\").append(\"<b>\").append(neurons[i].units).append(\"<\/b>\").append(\"<\/td>\");\n        sb.append(\"<td>\").append(neurons[i].getClass().getSimpleName()).append(\"<\/td>\");\n\n        if (i == 0) {\n          sb.append(\"<td>\");\n          sb.append(formatPct(neurons[i].params.input_dropout_ratio));\n          sb.append(\"<\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          continue;\n        }\n        else if (i < neurons.length-1) {\n          sb.append(\"<td>\");\n          sb.append( neurons[i] instanceof Neurons.TanhDropout\n                  || neurons[i] instanceof Neurons.RectifierDropout\n                  || neurons[i] instanceof Neurons.MaxoutDropout ? \"50%\" : \"0%\");\n          sb.append(\"<\/td>\");\n        } else {\n          sb.append(\"<td><\/td>\");\n        }\n\n        sb.append(\"<td>\").append(String.format(\"%.5g\", neurons[i].rate(error.training_samples))).append(\"<\/td>\");\n       sb.append(\"<td>\").append(neurons[i].params.l1).append(\"<\/td>\");\n        sb.append(\"<td>\").append(neurons[i].params.l2).append(\"<\/td>\");\n        final String format = \"%g\";\n        sb.append(\"<td>\").append(String.format(\"%.5f\", neurons[i].momentum(error.training_samples))).append(\"<\/td>\");\n        sb.append(\"<td>(\").append(String.format(format, model_info.mean_weight[i])).\n                append(\", \").append(String.format(format, model_info.rms_weight[i])).append(\")<\/td>\");\n        sb.append(\"<td>(\").append(String.format(format, model_info.mean_bias[i])).\n                append(\", \").append(String.format(format, model_info.rms_bias[i])).append(\")<\/td>\");\n        sb.append(\"<\/tr>\");\n      }\n      sb.append(\"<\/table>\");\n    }\n    if (model_info.unstable()) {\n      final String msg = \"Job was aborted due to observed numerical instability (exponential growth).\"\n              + \" Try a bounded activation function or regularization with L1, L2 or max_w2 and/or use a smaller learning rate or faster annealing.\";\n      DocGen.HTML.section(sb, \"=======================================================================================\");\n      DocGen.HTML.section(sb, msg);\n      DocGen.HTML.section(sb, \"=======================================================================================\");\n    }\n    long score_valid = error.score_validation_samples;\n    long score_train = error.score_training_samples;\n    final boolean fulltrain = score_train==0 || score_train == model_info().data_info()._adaptedFrame.numRows();\n    final boolean fullvalid = score_valid==0 || score_valid == model_info().get_params().validation.numRows();\n    if (isClassifier()) {\n      final String cmTitle = \"Confusion Matrix on \" + (error.validation ?\n              \"Validation Data\" + (fullvalid ? \"\" : \" (\" + score_valid + \" samples)\")\n              : \"Training Data\" + (fulltrain ? \"\" : \" (\" + score_train + \" samples)\"));\n      DocGen.HTML.section(sb, cmTitle);\n      if (error.train_confusion_matrix != null) {\n        if (error.train_confusion_matrix.cm != null && error.train_confusion_matrix.cm.length < 100) {\n          if (error.validation && error.valid_confusion_matrix != null && error.valid_confusion_matrix.cm != null) error.valid_confusion_matrix.toHTML(sb);\n          else if (error.train_confusion_matrix != null) error.train_confusion_matrix.toHTML(sb);\n        } else {\n          sb.append(\"<h5>Not shown here (too large).<\/h5>\");\n        }\n      }\n      else sb.append(\"<h5>Not yet computed.<\/h5>\");\n    }\n\n    sb.append(\"<h3>\" + \"Progress\" + \"<\/h3>\");\n    sb.append(\"<h4>\" + \"Epochs: \" + String.format(\"%.3f\", epoch_counter) + \"<\/h4>\");\n\n    String training = \"Number of training set samples for scoring: \" + (fulltrain ? \"all \" + model_info().data_info()._adaptedFrame.numRows() : score_train);\n    if (score_train > 0) {\n      if (score_train < 1000 && model_info().data_info()._adaptedFrame.numRows() >= 1000) training += \" (low, scoring might be inaccurate -> consider increasing this number in the expert mode)\";\n      if (score_train > 100000) training += \" (large, scoring can be slow -> consider reducing this number in the expert mode or scoring manually)\";\n    }\n    DocGen.HTML.section(sb, training);\n    if (error.validation) {\n      String validation = \"Number of validation set samples for scoring: \" + (fullvalid ? \"all \" + model_info().get_params().validation.numRows() : score_valid);\n      if (score_valid > 0) {\n        if (score_valid < 1000 && model_info().get_params().validation.numRows() >= 1000) validation += \" (low, scoring might be inaccurate -> consider increasing this number in the expert mode)\";\n        if (score_valid > 100000) validation += \" (large, scoring can be slow -> consider reducing this number in the expert mode or scoring manually)\";\n      }\n      DocGen.HTML.section(sb, validation);\n    }\n\n//    String training = \"Number of training set samples for scoring: \" + error.score_training;\n    if (error.validation) {\n//      String validation = \"Number of validation set samples for scoring: \" + error.score_validation;\n    }\n    sb.append(\"<table class='table table-striped table-bordered table-condensed'>\");\n    sb.append(\"<tr>\");\n    sb.append(\"<th>Training Time<\/th>\");\n    sb.append(\"<th>Training Epochs<\/th>\");\n    sb.append(\"<th>Training Samples<\/th>\");\n    if (isClassifier()) {\n//      sb.append(\"<th>Training MCE<\/th>\");\n      sb.append(\"<th>Training Error<\/th>\");\n    } else {\n      sb.append(\"<th>Training MSE<\/th>\");\n    }\n    if (error.validation) {\n      if (isClassifier()) {\n//      sb.append(\"<th>Validation MCE<\/th>\");\n        sb.append(\"<th>Validation Error<\/th>\");\n      } else {\n        sb.append(\"<th>Validation MSE<\/th>\");\n      }\n    }\n    sb.append(\"<\/tr>\");\n    for( int i = errors.length - 1; i >= 0; i-- ) {\n      final Errors e = errors[i];\n      sb.append(\"<tr>\");\n      sb.append(\"<td>\" + PrettyPrint.msecs(e.training_time_ms, true) + \"<\/td>\");\n      sb.append(\"<td>\" + String.format(\"%g\", e.epoch_counter) + \"<\/td>\");\n      sb.append(\"<td>\" + String.format(\"%,d\", e.training_samples) + \"<\/td>\");\n      if (isClassifier()) {\n//        sb.append(\"<td>\" + String.format(cross_entropy_format, e.train_mce) + \"<\/td>\");\n        sb.append(\"<td>\" + formatPct(e.train_err) + \"<\/td>\");\n      } else {\n        sb.append(\"<td>\" + String.format(mse_format, e.train_mse) + \"<\/td>\");\n      }\n      if(e.validation) {\n        if (isClassifier()) {\n//          sb.append(\"<td>\" + String.format(cross_entropy_format, e.valid_mce) + \"<\/td>\");\n          sb.append(\"<td>\" + formatPct(e.valid_err) + \"<\/td>\");\n        } else {\n          sb.append(\"<td>\" + String.format(mse_format, e.valid_mse) + \"<\/td>\");\n        }\n      }\n      sb.append(\"<\/tr>\");\n    }\n    sb.append(\"<\/table>\");\n    return true;\n  }","id":36469,"modified_method":"public boolean generateHTML(String title, StringBuilder sb) {\n    if (_key == null) {\n      DocGen.HTML.title(sb, \"No model yet\");\n      return true;\n    }\n\n    final String mse_format = \"%g\";\n    final String cross_entropy_format = \"%2.6f\";\n\n    DocGen.HTML.title(sb, title);\n    DocGen.HTML.paragraph(sb, \"Model type: \" + (model_info().parameters.classification ? \" Classification\" : \" Regression\"));\n    DocGen.HTML.paragraph(sb, \"Model Key: \" + _key);\n    DocGen.HTML.paragraph(sb, \"Job Key: \" + jobKey);\n    Inspect2 is2 = new Inspect2();\n    DocGen.HTML.paragraph(sb, \"Training Data Key: \" + _dataKey);\n    if (model_info.parameters.validation != null) {\n      DocGen.HTML.paragraph(sb, \"Validation Data Key: \" + model_info.parameters.validation._key);\n    }\n    DocGen.HTML.paragraph(sb, \"Number of model parameters (weights/biases): \" + String.format(\"%,d\", model_info().size()));\n\n    model_info.job().toHTML(sb);\n    sb.append(\"<div class='alert'>Actions: \"\n            + (Job.isRunning(jobKey) ? Cancel.link(jobKey, \"Cancel job\") + \", \" : \"\")\n            + is2.link(\"Inspect training data\", _dataKey) + \", \"\n            + (model_info().parameters.validation != null ? (is2.link(\"Inspect validation data\", model_info().parameters.validation._key) + \", \") : \"\")\n            + water.api.Predict.link(_key, \"Score on dataset\") + \", \" +\n            NN.link(_dataKey, \"Compute new model\") + \"<\/div>\");\n\n    // stats for training and validation\n    final Errors error = errors[errors.length - 1];\n    assert(error != null);\n\n    if (errors.length > 1) {\n      if (isClassifier()) {\n        // Plot training error\n        float[] err = new float[errors.length];\n        float[] samples = new float[errors.length];\n        for (int i=0; i<err.length; ++i) {\n          err[i] = (float)errors[i].train_err;\n          samples[i] = errors[i].training_samples;\n        }\n        new D3Plot(samples, err, \"training samples\", \"classification error\",\n                \"Classification Error on Training Set\").generate(sb);\n\n        // Plot validation error\n        if (model_info.parameters.validation != null) {\n          for (int i=0; i<err.length; ++i) {\n            err[i] = (float)errors[i].valid_err;\n          }\n          new D3Plot(samples, err, \"training samples\", \"classification error\",\n                  \"Classification Error on Validation Set\").generate(sb);\n        }\n      } else {\n        // Plot training MSE\n        float[] err = new float[errors.length-1];\n        float[] samples = new float[errors.length-1];\n        for (int i=0; i<err.length; ++i) {\n          err[i] = (float)errors[i+1].train_mse;\n          samples[i] = errors[i+1].training_samples;\n        }\n        new D3Plot(samples, err, \"training samples\", \"MSE\",\n                \"Regression Error on Training Set\").generate(sb);\n\n        // Plot validation MSE\n        if (model_info.parameters.validation != null) {\n          for (int i=0; i<err.length; ++i) {\n            err[i] = (float)errors[i+1].valid_mse;\n          }\n          new D3Plot(samples, err, \"training samples\", \"MSE\",\n                  \"Regression Error on Validation Set\").generate(sb);\n        }\n      }\n    }\n\n    DocGen.HTML.section(sb, \"Predicting: \" + responseName());\n    if (isClassifier()) {\n      DocGen.HTML.section(sb, \"Training classification error: \" + formatPct(error.train_err));\n//      DocGen.HTML.section(sb, \"Training cross entropy: \" + String.format(cross_entropy_format, error.train_mce));\n      if(error.validation) {\n        DocGen.HTML.section(sb, \"Validation classification error: \" + formatPct(error.valid_err));\n//        DocGen.HTML.section(sb, \"Validation mean cross entropy: \" + String.format(cross_entropy_format, error.valid_mce));\n      }\n    } else {\n      DocGen.HTML.section(sb, \"Training mean squared error: \" + String.format(mse_format, error.train_mse));\n      if(error.validation) {\n        DocGen.HTML.section(sb, \"Validation mean squared error: \" + String.format(mse_format, error.valid_mse));\n      }\n    }\n    if (error.training_time_ms > 0)\n      DocGen.HTML.section(sb, \"Training speed: \" + error.training_samples * 1000 / error.training_time_ms + \" samples/s\");\n    if (model_info.parameters != null && model_info.parameters.diagnostics) {\n      DocGen.HTML.section(sb, \"Status of Neuron Layers\");\n      sb.append(\"<table class='table table-striped table-bordered table-condensed'>\");\n      sb.append(\"<tr>\");\n      sb.append(\"<th>\").append(\"#\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Units\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Type\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Dropout\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Rate\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"L1\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"L2\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Momentum\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Weight (Mean, RMS)\").append(\"<\/th>\");\n      sb.append(\"<th>\").append(\"Bias (Mean, RMS)\").append(\"<\/th>\");\n      sb.append(\"<\/tr>\");\n      Neurons[] neurons = NNTask.makeNeuronsForTesting(model_info()); //link the weights to the neurons, for easy access\n      for (int i=0; i<neurons.length; ++i) {\n        sb.append(\"<tr>\");\n        sb.append(\"<td>\").append(\"<b>\").append(i+1).append(\"<\/b>\").append(\"<\/td>\");\n        sb.append(\"<td>\").append(\"<b>\").append(neurons[i].units).append(\"<\/b>\").append(\"<\/td>\");\n        sb.append(\"<td>\").append(neurons[i].getClass().getSimpleName()).append(\"<\/td>\");\n\n        if (i == 0) {\n          sb.append(\"<td>\");\n          sb.append(formatPct(neurons[i].params.input_dropout_ratio));\n          sb.append(\"<\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          sb.append(\"<td><\/td>\");\n          continue;\n        }\n        else if (i < neurons.length-1) {\n          sb.append(\"<td>\");\n          sb.append( neurons[i] instanceof Neurons.TanhDropout\n                  || neurons[i] instanceof Neurons.RectifierDropout\n                  || neurons[i] instanceof Neurons.MaxoutDropout ? \"50%\" : \"0%\");\n          sb.append(\"<\/td>\");\n        } else {\n          sb.append(\"<td><\/td>\");\n        }\n\n        sb.append(\"<td>\").append(String.format(\"%.5g\", neurons[i].rate(error.training_samples))).append(\"<\/td>\");\n       sb.append(\"<td>\").append(neurons[i].params.l1).append(\"<\/td>\");\n        sb.append(\"<td>\").append(neurons[i].params.l2).append(\"<\/td>\");\n        final String format = \"%g\";\n        sb.append(\"<td>\").append(String.format(\"%.5f\", neurons[i].momentum(error.training_samples))).append(\"<\/td>\");\n        sb.append(\"<td>(\").append(String.format(format, model_info.mean_weight[i])).\n                append(\", \").append(String.format(format, model_info.rms_weight[i])).append(\")<\/td>\");\n        sb.append(\"<td>(\").append(String.format(format, model_info.mean_bias[i])).\n                append(\", \").append(String.format(format, model_info.rms_bias[i])).append(\")<\/td>\");\n        sb.append(\"<\/tr>\");\n      }\n      sb.append(\"<\/table>\");\n    }\n    if (model_info.unstable()) {\n      final String msg = \"Job was aborted due to observed numerical instability (exponential growth).\"\n              + \" Try a bounded activation function or regularization with L1, L2 or max_w2 and/or use a smaller learning rate or faster annealing.\";\n      DocGen.HTML.section(sb, \"=======================================================================================\");\n      DocGen.HTML.section(sb, msg);\n      DocGen.HTML.section(sb, \"=======================================================================================\");\n    }\n    long score_valid = error.score_validation_samples;\n    long score_train = error.score_training_samples;\n    final boolean fulltrain = score_train==0 || score_train == model_info().data_info()._adaptedFrame.numRows();\n    final boolean fullvalid = score_valid==0 || score_valid == model_info().get_params().validation.numRows();\n    if (isClassifier()) {\n      final String cmTitle = \"Confusion Matrix on \" + (error.validation ?\n              \"Validation Data\" + (fullvalid ? \"\" : \" (\" + score_valid + \" samples)\")\n              : \"Training Data\" + (fulltrain ? \"\" : \" (\" + score_train + \" samples)\"));\n      DocGen.HTML.section(sb, cmTitle);\n      if (error.train_confusion_matrix != null) {\n        if (error.train_confusion_matrix.cm != null && error.train_confusion_matrix.cm.length < 100) {\n          if (error.validation && error.valid_confusion_matrix != null && error.valid_confusion_matrix.cm != null) error.valid_confusion_matrix.toHTML(sb);\n          else if (error.train_confusion_matrix != null) error.train_confusion_matrix.toHTML(sb);\n        } else {\n          sb.append(\"<h5>Not shown here (too large).<\/h5>\");\n        }\n      }\n      else sb.append(\"<h5>Not yet computed.<\/h5>\");\n    }\n\n    sb.append(\"<h3>\" + \"Progress\" + \"<\/h3>\");\n    sb.append(\"<h4>\" + \"Epochs: \" + String.format(\"%.3f\", epoch_counter) + \"<\/h4>\");\n\n    final long pts = fulltrain ? model_info().data_info()._adaptedFrame.numRows() : score_train;\n    String training = \"Number of training set samples for scoring: \" + (fulltrain ? \"all \" : \"\") + pts;\n    if (pts < 1000 && model_info().data_info()._adaptedFrame.numRows() >= 1000) training += \" (low, scoring might be inaccurate -> consider increasing this number in the expert mode)\";\n    if (pts > 100000) training += \" (large, scoring can be slow -> consider reducing this number in the expert mode or scoring manually)\";\n    DocGen.HTML.section(sb, training);\n    if (error.validation) {\n      final long ptsv = fullvalid ? model_info().get_params().validation.numRows() : score_valid;\n      String validation = \"Number of validation set samples for scoring: \" + (fullvalid ? \"all \" : \"\") + pts;\n      if (ptsv < 1000 && model_info().get_params().validation.numRows() >= 1000) validation += \" (low, scoring might be inaccurate -> consider increasing this number in the expert mode)\";\n      if (ptsv > 100000) validation += \" (large, scoring can be slow -> consider reducing this number in the expert mode or scoring manually)\";\n      DocGen.HTML.section(sb, validation);\n    }\n\n//    String training = \"Number of training set samples for scoring: \" + error.score_training;\n    if (error.validation) {\n//      String validation = \"Number of validation set samples for scoring: \" + error.score_validation;\n    }\n    sb.append(\"<table class='table table-striped table-bordered table-condensed'>\");\n    sb.append(\"<tr>\");\n    sb.append(\"<th>Training Time<\/th>\");\n    sb.append(\"<th>Training Epochs<\/th>\");\n    sb.append(\"<th>Training Samples<\/th>\");\n    if (isClassifier()) {\n//      sb.append(\"<th>Training MCE<\/th>\");\n      sb.append(\"<th>Training Error<\/th>\");\n    } else {\n      sb.append(\"<th>Training MSE<\/th>\");\n    }\n    if (error.validation) {\n      if (isClassifier()) {\n//      sb.append(\"<th>Validation MCE<\/th>\");\n        sb.append(\"<th>Validation Error<\/th>\");\n      } else {\n        sb.append(\"<th>Validation MSE<\/th>\");\n      }\n    }\n    sb.append(\"<\/tr>\");\n    for( int i = errors.length - 1; i >= 0; i-- ) {\n      final Errors e = errors[i];\n      sb.append(\"<tr>\");\n      sb.append(\"<td>\" + PrettyPrint.msecs(e.training_time_ms, true) + \"<\/td>\");\n      sb.append(\"<td>\" + String.format(\"%g\", e.epoch_counter) + \"<\/td>\");\n      sb.append(\"<td>\" + String.format(\"%,d\", e.training_samples) + \"<\/td>\");\n      if (isClassifier()) {\n//        sb.append(\"<td>\" + String.format(cross_entropy_format, e.train_mce) + \"<\/td>\");\n        sb.append(\"<td>\" + formatPct(e.train_err) + \"<\/td>\");\n      } else {\n        sb.append(\"<td>\" + String.format(mse_format, e.train_mse) + \"<\/td>\");\n      }\n      if(e.validation) {\n        if (isClassifier()) {\n//          sb.append(\"<td>\" + String.format(cross_entropy_format, e.valid_mce) + \"<\/td>\");\n          sb.append(\"<td>\" + formatPct(e.valid_err) + \"<\/td>\");\n        } else {\n          sb.append(\"<td>\" + String.format(mse_format, e.valid_mse) + \"<\/td>\");\n        }\n      }\n      sb.append(\"<\/tr>\");\n    }\n    sb.append(\"<\/table>\");\n    return true;\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"/**\n   *\n   * @param ftrain potentially downsampled training data for scoring\n   * @param ftest  potentially downsampled validation data for scoring\n   * @param timeStart start time in milliseconds, used to report training speed\n   * @param dest_key where to store the model with the diagnostics in it\n   * @return true if model building is ongoing\n   */\n  boolean doDiagnostics(Frame ftrain, Frame ftest, long timeStart, Key dest_key) {\n    epoch_counter = (float)model_info().get_processed_total()/model_info().data_info._adaptedFrame.numRows();\n    run_time = (System.currentTimeMillis()-start_time);\n    boolean keep_running = (epoch_counter < model_info().parameters.epochs);\n    _now = System.currentTimeMillis();\n    final long sinceLastScore = _now-_timeLastScoreStart;\n    final long sinceLastPrint = _now-_timeLastPrintStart;\n    final long samples = model_info().get_processed_total();\n    if (sinceLastPrint > model_info().parameters.score_interval*1000) {\n      _timeLastPrintStart = _now;\n      if (!model_info().get_params().quiet_mode)\n        Log.info(\"Training time: \" + PrettyPrint.msecs(_now - start_time, true)\n                + \" processed \" + samples + \" samples\" + \" (\" + String.format(\"%.3f\", epoch_counter) + \" epochs).\"\n                + \" Speed: \" + String.format(\"%.3f\", (double)samples/((_now - start_time)/1000.)) + \" samples/sec.\");\n    }\n    // this is potentially slow - only do every so often\n    if( !keep_running || sinceLastScore > model_info().parameters.score_interval*1000) {\n      final boolean printme = !model_info().get_params().quiet_mode;\n      if (printme) Log.info(\"Scoring the model.\");\n      _timeLastScoreStart = _now;\n      // compute errors\n      Errors err = new Errors();\n      err.classification = isClassifier();\n      assert(err.classification == model_info().get_params().classification);\n      err.training_time_ms = _now - timeStart;\n      err.epoch_counter = epoch_counter;\n      err.validation = ftest != null;\n      err.training_samples = model_info().get_processed_total();\n      err.score_training_samples = ftrain.numRows();\n      err.train_confusion_matrix = new ConfusionMatrix();\n      final double trainErr = calcError(ftrain, \"Error on training data:\", printme, err.train_confusion_matrix);\n      if (err.classification) err.train_err = trainErr;\n      else err.train_mse = trainErr;\n\n      if (err.validation) {\n        err.score_validation_samples = ftest.numRows();\n        err.valid_confusion_matrix = new ConfusionMatrix();\n        final double validErr = calcError(ftest, \"Error on validation data:\", printme, err.valid_confusion_matrix);\n        if (err.classification) err.valid_err = validErr;\n        else err.valid_mse = validErr;\n      }\n      // enlarge the error array by one, push latest score back\n      if (errors == null) {\n         errors = new Errors[]{err};\n      } else {\n        Errors[] err2 = new Errors[errors.length+1];\n        System.arraycopy(errors, 0, err2, 0, errors.length);\n        err2[err2.length-1] = err;\n        errors = err2;\n      }\n      if (printme) {\n        // print the freshly scored model to ASCII\n        for (String s : toString().split(\"\\n\")) Log.info(s);\n        Log.info(\"Scoring time: \" + PrettyPrint.msecs(System.currentTimeMillis() - _now, true));\n      }\n    }\n    if (model_info().unstable()) {\n      Log.err(\"Canceling job since the model is unstable (exponential growth observed).\");\n      Log.err(\"Try a bounded activation function or regularization with L1, L2 or max_w2 and/or use a smaller learning rate or faster annealing.\");\n      keep_running = false;\n    } else if (ftest == null &&\n            (model_info().get_params().classification && errors[errors.length-1].train_err <= model_info().get_params().classification_stop)\n        || (!model_info().get_params().classification && errors[errors.length-1].train_mse <= model_info().get_params().regression_stop)\n            ) {\n      Log.info(\"Achieved 100% modeling accuracy on the training data. We are done here.\");\n      keep_running = false;\n    } else if (ftest != null &&\n            (model_info().get_params().classification && errors[errors.length-1].valid_err <= model_info().get_params().classification_stop)\n        || (!model_info().get_params().classification && errors[errors.length-1].valid_mse <= model_info().get_params().regression_stop)\n            ) {\n      Log.info(\"Achieved 100% modeling accuracy on the validation data. We are done here.\");\n      keep_running = false;\n    }\n    update(dest_key); //update model in UKV\n//    System.out.println(this);\n    return keep_running;\n  }","id":36470,"modified_method":"/**\n   *\n   * @param ftrain potentially downsampled training data for scoring\n   * @param ftest  potentially downsampled validation data for scoring\n   * @param timeStart start time in milliseconds, used to report training speed\n   * @param job_key key of the owning job\n   * @return true if model building is ongoing\n   */\n  boolean doDiagnostics(Frame ftrain, Frame ftest, long timeStart, Key job_key) {\n    epoch_counter = (float)model_info().get_processed_total()/model_info().data_info._adaptedFrame.numRows();\n    run_time = (System.currentTimeMillis()-start_time);\n    boolean keep_running = (epoch_counter < model_info().parameters.epochs);\n    _now = System.currentTimeMillis();\n    final long sinceLastScore = _now-_timeLastScoreStart;\n    final long sinceLastPrint = _now-_timeLastPrintStart;\n    final long samples = model_info().get_processed_total();\n    if (sinceLastPrint > model_info().parameters.score_interval*1000) {\n      _timeLastPrintStart = _now;\n      if (!model_info().get_params().quiet_mode)\n        Log.info(\"Training time: \" + PrettyPrint.msecs(_now - start_time, true)\n                + \" processed \" + samples + \" samples\" + \" (\" + String.format(\"%.3f\", epoch_counter) + \" epochs).\"\n                + \" Speed: \" + String.format(\"%.3f\", (double)samples/((_now - start_time)/1000.)) + \" samples/sec.\");\n    }\n    // this is potentially slow - only do every so often\n    if( !keep_running || sinceLastScore > model_info().parameters.score_interval*1000) {\n      final boolean printme = !model_info().get_params().quiet_mode;\n      if (printme) Log.info(\"Scoring the model.\");\n      _timeLastScoreStart = _now;\n      // compute errors\n      Errors err = new Errors();\n      err.classification = isClassifier();\n      assert(err.classification == model_info().get_params().classification);\n      err.training_time_ms = _now - timeStart;\n      err.epoch_counter = epoch_counter;\n      err.validation = ftest != null;\n      err.training_samples = model_info().get_processed_total();\n      err.score_training_samples = ftrain.numRows();\n      err.train_confusion_matrix = new ConfusionMatrix();\n      final double trainErr = calcError(ftrain, \"Error on training data:\", printme, err.train_confusion_matrix);\n      if (err.classification) err.train_err = trainErr;\n      else err.train_mse = trainErr;\n\n      if (err.validation) {\n        err.score_validation_samples = ftest.numRows();\n        err.valid_confusion_matrix = new ConfusionMatrix();\n        final double validErr = calcError(ftest, \"Error on validation data:\", printme, err.valid_confusion_matrix);\n        if (err.classification) err.valid_err = validErr;\n        else err.valid_mse = validErr;\n      }\n      // enlarge the error array by one, push latest score back\n      if (errors == null) {\n         errors = new Errors[]{err};\n      } else {\n        Errors[] err2 = new Errors[errors.length+1];\n        System.arraycopy(errors, 0, err2, 0, errors.length);\n        err2[err2.length-1] = err;\n        errors = err2;\n      }\n      if (printme) {\n        // print the freshly scored model to ASCII\n        for (String s : toString().split(\"\\n\")) Log.info(s);\n        Log.info(\"Scoring time: \" + PrettyPrint.msecs(System.currentTimeMillis() - _now, true));\n      }\n    }\n    if (model_info().unstable()) {\n      Log.err(\"Canceling job since the model is unstable (exponential growth observed).\");\n      Log.err(\"Try a bounded activation function or regularization with L1, L2 or max_w2 and/or use a smaller learning rate or faster annealing.\");\n      keep_running = false;\n    } else if (ftest == null &&\n            (model_info().get_params().classification && errors[errors.length-1].train_err <= model_info().get_params().classification_stop)\n        || (!model_info().get_params().classification && errors[errors.length-1].train_mse <= model_info().get_params().regression_stop)\n            ) {\n      Log.info(\"Achieved 100% modeling accuracy on the training data. We are done here.\");\n      keep_running = false;\n    } else if (ftest != null &&\n            (model_info().get_params().classification && errors[errors.length-1].valid_err <= model_info().get_params().classification_stop)\n        || (!model_info().get_params().classification && errors[errors.length-1].valid_mse <= model_info().get_params().regression_stop)\n            ) {\n      Log.info(\"Achieved 100% modeling accuracy on the validation data. We are done here.\");\n      keep_running = false;\n    }\n    update(job_key);\n//    System.out.println(this);\n    return keep_running;\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public NNTask(DataInfo dinfo, NNModel.NNModelInfo input, boolean training, float fraction, boolean shuffle){this(dinfo,input,training,fraction,shuffle,null);}","id":36471,"modified_method":"public NNTask(NNModel.NNModelInfo input, boolean training, float fraction){this(input,training,fraction,null);}","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private NNTask(DataInfo dinfo, NNModel.NNModelInfo input, boolean training, float fraction, boolean shuffle, H2OCountedCompleter cmp){\n    super(input.job(),dinfo,cmp);\n    _training=training;\n    _input=input;\n    _useFraction=fraction;\n    _seed=_input.get_params().seed;\n    _shuffle = shuffle;\n    assert(_output == null);\n  }","id":36472,"modified_method":"private NNTask(NNModel.NNModelInfo input, boolean training, float fraction, H2OCountedCompleter cmp){\n    super(input.job(),input.data_info(),cmp);\n    _training=training;\n    _input=input;\n    _useFraction=fraction;\n    _seed=_input.get_params().seed;\n    _shuffle = _input.get_params().shuffle_training_data;\n    assert(_output == null);\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public NNModel.NNModelInfo model_info() { return _output; }","id":36473,"modified_method":"final public NNModel.NNModelInfo model_info() { return _output; }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Test public void compare() throws Exception {\n\n    for (int repeat = 0; repeat < 1; ++repeat) {\n      // Testing different things\n      // Note: Microsoft reference implementation is only for Tanh + MSE, rectifier and MCE are implemented by 0xdata (trivial).\n      // Note: Initial weight distributions are copied, but what is tested is the stability behavior.\n\n      NN.Activation[] activations = { NN.Activation.Tanh, NN.Activation.Rectifier };\n      NN.Loss[] losses = { NN.Loss.MeanSquare, NN.Loss.CrossEntropy };\n      NN.InitialWeightDistribution[] dists = {\n//              NN.InitialWeightDistribution.Normal,\n//              NN.InitialWeightDistribution.Uniform,\n              NN.InitialWeightDistribution.UniformAdaptive\n      };\n      double[] initial_weight_scales = { 1e-4 + new Random().nextDouble() };\n      double[] holdout_ratios = { 0.1 + new Random().nextDouble() * 0.8 };\n      double[] momenta = { new Random().nextDouble() * 0.99 };\n      int[] hiddens = { 1, new Random().nextInt(50) };\n      int[] epochs = { 1, new Random().nextInt(50) };\n      double[] rates = { 0.01, 1e-5 + new Random().nextDouble() * .1 };\n\n      int num_runs = 0;\n      for (NN.Activation activation : activations) {\n        for (NN.Loss loss : losses) {\n          for (NN.InitialWeightDistribution dist : dists) {\n            for (double scale : initial_weight_scales) {\n              for (double holdout_ratio : holdout_ratios) {\n                for (double momentum : momenta) {\n                  for (int hidden : hiddens) {\n                    for (int epoch : epochs) {\n                      for (double rate : rates) {\n                        long seed = new Random().nextLong();\n                        Log.info(\"\");\n                        Log.info(\"STARTING.\");\n                        Log.info(\"Running with \" + activation.name() + \" activation function and \" + loss.name() + \" loss function.\");\n                        Log.info(\"Initialization with \" + dist.name() + \" distribution and \" + scale + \" scale, holdout ratio \" + holdout_ratio);\n                        Log.info(\"Using \" + hidden + \" hidden layers and momentum: \" + momentum);\n                        Log.info(\"Using seed \" + seed);\n\n                        Key file = NFSFileVec.make(find_test_file(PATH));\n                        Frame frame = ParseDataset2.parse(Key.make(\"iris_nn2\"), new Key[] { file });\n\n                        Frame fr = null;\n                        NN p;\n                        Random rand;\n\n                        int trial = 0;\n                        FrameTask.DataInfo dinfo;\n                        do {\n                          Log.info(\"Trial #\" + ++trial);\n                          if (_train != null) _train.delete();\n                          if (_test != null) _test.delete();\n                          if (fr != null) fr.delete();\n\n                          rand = Utils.getDeterRNG(seed);\n\n                          double[][] rows = new double[(int) frame.numRows()][frame.numCols()];\n                          String[] names = new String[frame.numCols()];\n                          for( int c = 0; c < frame.numCols(); c++ ) {\n                            names[c] = \"ColumnName\" + c;\n                            for( int r = 0; r < frame.numRows(); r++ )\n                              rows[r][c] = frame.vecs()[c].at(r);\n                          }\n\n                          for( int i = rows.length - 1; i >= 0; i-- ) {\n                            int shuffle = rand.nextInt(i + 1);\n                            double[] row = rows[shuffle];\n                            rows[shuffle] = rows[i];\n                            rows[i] = row;\n                          }\n\n                          int limit = (int) (frame.numRows() * holdout_ratio);\n                          _train = frame(names, Utils.subarray(rows, 0, limit));\n                          _test = frame(names, Utils.subarray(rows, limit, (int) frame.numRows() - limit));\n\n                          p = new NN();\n                          p.source = _train;\n                          p.response = _train.lastVec();\n                          p.ignored_cols = null;\n                          p.ignore_const_cols = true;\n                          fr = FrameTask.DataInfo.prepareFrame(p.source, p.response, p.ignored_cols, true, p.ignore_const_cols);\n                          dinfo = new FrameTask.DataInfo(fr, 1, true);\n                        }\n                        // must have all output classes in training data (since that's what the reference implementation has hardcoded)\n                        while (dinfo._adaptedFrame.lastVec().domain().length < 3);\n\n                        // use the same seed for the reference implementation\n                        NeuralNetMLPReference2 ref = new NeuralNetMLPReference2();\n                        ref.init(activation, Utils.getDeterRNG(seed), holdout_ratio, hidden);\n\n                        p.seed = seed;\n                        p.hidden = new int[]{hidden};\n                        p.rate = rate / (1 - momentum); //adapt to (1-m) correction that's done inside (only for constant momentum!)\n                        p.activation = activation;\n                        p.max_w2 = Double.MAX_VALUE;\n                        p.epochs = epoch;\n                        p.input_dropout_ratio = 0;\n                        p.rate_annealing = 0; //do not change - not implemented in reference\n                        p.l1 = 0;\n                        p.loss = loss;\n                        p.l2 = 0;\n                        p.momentum_stable = momentum; //reference only supports constant momentum\n                        p.momentum_start = p.momentum_stable; //do not change - not implemented in reference\n                        p.momentum_ramp = 0; //do not change - not implemented in reference\n                        p.initial_weight_distribution = dist;\n                        p.initial_weight_scale = scale;\n                        p.classification = true;\n                        p.diagnostics = true;\n                        p.validation = null;\n                        p.quiet_mode = true;\n                        p.fast_mode = false; //to be the same as reference\n//                      p.fast_mode = true; //to be the same as old NeuralNet code\n                        p.nesterov_accelerated_gradient = false; //to be the same as reference\n//                        p.nesterov_accelerated_gradient = true; //to be the same as old NeuralNet code\n                        p.sync_samples = 100000; //sync once per period\n                        p.ignore_const_cols = false;\n                        p.shuffle_training_data = false;\n                        p.classification_stop = -1; //don't stop early -> need to compare against reference, which doesn't stop either\n                        NNModel mymodel = p.initModel(); //randomize weights, but don't start training yet\n\n                        Neurons[] neurons = NNTask.makeNeuronsForTraining(mymodel.model_info());\n\n                        // use the same random weights for the reference implementation\n                        Neurons l = neurons[1];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n//                          System.out.println(\"initial weight[\" + o + \"]=\" + l._w[o * l._previous._a.length + i]);\n                            ref._nn.ihWeights[i][o] = l._w[o * l._previous._a.length + i];\n                          }\n                          ref._nn.hBiases[o] = l._b[o];\n//                        System.out.println(\"initial bias[\" + o + \"]=\" + l._b[o]);\n                        }\n                        l = neurons[2];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n//                          System.out.println(\"initial weight[\" + o + \"]=\" + l._w[o * l._previous._a.length + i]);\n                            ref._nn.hoWeights[i][o] = l._w[o * l._previous._a.length + i];\n                          }\n                          ref._nn.oBiases[o] = l._b[o];\n//                        System.out.println(\"initial bias[\" + o + \"]=\" + l._b[o]);\n                        }\n\n                        // Train the Reference\n                        ref.train((int)p.epochs, rate, p.momentum_stable, loss);\n\n                        // Train H2O\n                        mymodel = p.buildModel(mymodel);\n\n                        /**\n                         * Tolerances (super tight -> expect the same double/float precision math inside both algos)\n                         */\n                        final double abseps = 1e-13;\n                        final double releps = 1e-13;\n\n                        /**\n                         * Compare weights and biases in hidden layer\n                         */\n                        neurons = NNTask.makeNeuronsForTesting(mymodel.model_info()); //link the weights to the neurons, for easy access\n                        l = neurons[1];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n                            double a = ref._nn.ihWeights[i][o];\n                            double b = l._w[o * l._previous._a.length + i];\n                            compareVal(a, b, abseps, releps);\n//                          System.out.println(\"weight[\" + o + \"]=\" + b);\n                          }\n                          double ba = ref._nn.hBiases[o];\n                          double bb = l._b[o];\n                          compareVal(ba, bb, abseps, releps);\n                        }\n                        Log.info(\"Weights and biases for hidden layer: PASS\");\n\n                        /**\n                         * Compare weights and biases for output layer\n                         */\n                        l = neurons[2];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n                            double a = ref._nn.hoWeights[i][o];\n                            double b = l._w[o * l._previous._a.length + i];\n                            compareVal(a, b, abseps, releps);\n                          }\n                          double ba = ref._nn.oBiases[o];\n                          double bb = l._b[o];\n                          compareVal(ba, bb, abseps, releps);\n                        }\n                        Log.info(\"Weights and biases for output layer: PASS\");\n\n                        /**\n                         * Compare predictions\n                         * Note: Reference and H2O each do their internal data normalization,\n                         * so we must use their \"own\" test data, which is assumed to be created correctly.\n                         */\n                        // H2O predictions\n                        Frame fpreds = mymodel.score(_test); //[0] is label, [1]...[4] are the probabilities\n\n                        for (int i=0; i<_test.numRows(); ++i) {\n                          // Reference predictions\n                          double[] xValues = new double[neurons[0]._a.length];\n                          System.arraycopy(ref._testData[i], 0, xValues, 0, xValues.length);\n                          double[] ref_preds = ref._nn.ComputeOutputs(xValues);\n\n                          // find the label\n                          // do the same as H2O here (compare float values and break ties based on row number)\n                          float[] preds = new float[ref_preds.length+1];\n                          for (int j=0; j<ref_preds.length; ++j) preds[j+1] = (float)ref_preds[j];\n                          preds[0] = Model.getPrediction(preds, i);\n\n                          // compare predicted label\n                          Assert.assertTrue(preds[0] == (int) fpreds.vecs()[0].at(i));\n                          // compare predicted probabilities\n                          for (int j=0; j<ref_preds.length; ++j) {\n                            compareVal((float)(ref_preds[j]), fpreds.vecs()[1+j].at(i), abseps, releps);\n                          }\n                        }\n                        fpreds.delete();\n                        Log.info(\"Predicted values: PASS\");\n\n                        /**\n                         * Compare (self-reported) scoring\n                         */\n                        final double trainErr = ref._nn.Accuracy(ref._trainData);\n                        final double testErr = ref._nn.Accuracy(ref._testData);\n                        final double myTrainErr = mymodel.calcError(_train, \"Final training error:\", true, null);\n                        final double myTestErr = mymodel.calcError(_test,  \"Final testing error:\",  true, null);\n                        Log.info(\"H2O  training error : \" + myTrainErr*100 + \"%, test error: \" + myTestErr*100 + \"%\");\n                        Log.info(\"REF  training error : \" + trainErr*100 + \"%, test error: \" + testErr*100 + \"%\");\n                        compareVal(trainErr, myTrainErr, abseps, releps);\n                        compareVal(testErr,  myTestErr,  abseps, releps);\n                        Log.info(\"Scoring: PASS\");\n\n                        // cleanup\n                        mymodel.delete();\n                        _train.delete();\n                        _test.delete();\n                        frame.delete();\n                        fr.delete();\n\n                        num_runs++;\n                        Log.info(\"Parameters combination \" + num_runs + \": PASS\");\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }","id":36474,"modified_method":"@Test public void compare() throws Exception {\n\n    for (int repeat = 0; repeat < 1; ++repeat) {\n      // Testing different things\n      // Note: Microsoft reference implementation is only for Tanh + MSE, rectifier and MCE are implemented by 0xdata (trivial).\n      // Note: Initial weight distributions are copied, but what is tested is the stability behavior.\n\n      NN.Activation[] activations = { NN.Activation.Tanh, NN.Activation.Rectifier };\n      NN.Loss[] losses = { NN.Loss.MeanSquare, NN.Loss.CrossEntropy };\n      NN.InitialWeightDistribution[] dists = {\n//              NN.InitialWeightDistribution.Normal,\n//              NN.InitialWeightDistribution.Uniform,\n              NN.InitialWeightDistribution.UniformAdaptive\n      };\n      double[] initial_weight_scales = { 1e-4 + new Random().nextDouble() };\n      double[] holdout_ratios = { 0.1 + new Random().nextDouble() * 0.8 };\n      double[] momenta = { new Random().nextDouble() * 0.99 };\n      int[] hiddens = { 1, new Random().nextInt(50) };\n      int[] epochs = { 1, new Random().nextInt(50) };\n      double[] rates = { 0.01, 1e-5 + new Random().nextDouble() * .1 };\n\n      int num_runs = 0;\n      for (NN.Activation activation : activations) {\n        for (NN.Loss loss : losses) {\n          for (NN.InitialWeightDistribution dist : dists) {\n            for (double scale : initial_weight_scales) {\n              for (double holdout_ratio : holdout_ratios) {\n                for (double momentum : momenta) {\n                  for (int hidden : hiddens) {\n                    for (int epoch : epochs) {\n                      for (double rate : rates) {\n                        long seed = new Random().nextLong();\n                        Log.info(\"\");\n                        Log.info(\"STARTING.\");\n                        Log.info(\"Running with \" + activation.name() + \" activation function and \" + loss.name() + \" loss function.\");\n                        Log.info(\"Initialization with \" + dist.name() + \" distribution and \" + scale + \" scale, holdout ratio \" + holdout_ratio);\n                        Log.info(\"Using \" + hidden + \" hidden layers and momentum: \" + momentum);\n                        Log.info(\"Using seed \" + seed);\n\n                        Key file = NFSFileVec.make(find_test_file(PATH));\n                        Frame frame = ParseDataset2.parse(Key.make(\"iris_nn2\"), new Key[] { file });\n\n                        Frame fr = null;\n                        NN p;\n                        Random rand;\n\n                        int trial = 0;\n                        FrameTask.DataInfo dinfo;\n                        do {\n                          Log.info(\"Trial #\" + ++trial);\n                          if (_train != null) _train.delete();\n                          if (_test != null) _test.delete();\n                          if (fr != null) fr.delete();\n\n                          rand = Utils.getDeterRNG(seed);\n\n                          double[][] rows = new double[(int) frame.numRows()][frame.numCols()];\n                          String[] names = new String[frame.numCols()];\n                          for( int c = 0; c < frame.numCols(); c++ ) {\n                            names[c] = \"ColumnName\" + c;\n                            for( int r = 0; r < frame.numRows(); r++ )\n                              rows[r][c] = frame.vecs()[c].at(r);\n                          }\n\n                          for( int i = rows.length - 1; i >= 0; i-- ) {\n                            int shuffle = rand.nextInt(i + 1);\n                            double[] row = rows[shuffle];\n                            rows[shuffle] = rows[i];\n                            rows[i] = row;\n                          }\n\n                          int limit = (int) (frame.numRows() * holdout_ratio);\n                          _train = frame(names, Utils.subarray(rows, 0, limit));\n                          _test = frame(names, Utils.subarray(rows, limit, (int) frame.numRows() - limit));\n\n                          p = new NN();\n                          p.source = _train;\n                          p.response = _train.lastVec();\n                          p.ignored_cols = null;\n                          p.ignore_const_cols = true;\n                          fr = FrameTask.DataInfo.prepareFrame(p.source, p.response, p.ignored_cols, true, p.ignore_const_cols);\n                          dinfo = new FrameTask.DataInfo(fr, 1, true);\n                        }\n                        // must have all output classes in training data (since that's what the reference implementation has hardcoded)\n                        while (dinfo._adaptedFrame.lastVec().domain().length < 3);\n\n                        // use the same seed for the reference implementation\n                        NeuralNetMLPReference2 ref = new NeuralNetMLPReference2();\n                        ref.init(activation, Utils.getDeterRNG(seed), holdout_ratio, hidden);\n\n                        p.seed = seed;\n                        p.hidden = new int[]{hidden};\n                        p.rate = rate / (1 - momentum); //adapt to (1-m) correction that's done inside (only for constant momentum!)\n                        p.activation = activation;\n                        p.max_w2 = Double.MAX_VALUE;\n                        p.epochs = epoch;\n                        p.input_dropout_ratio = 0;\n                        p.rate_annealing = 0; //do not change - not implemented in reference\n                        p.l1 = 0;\n                        p.loss = loss;\n                        p.l2 = 0;\n                        p.momentum_stable = momentum; //reference only supports constant momentum\n                        p.momentum_start = p.momentum_stable; //do not change - not implemented in reference\n                        p.momentum_ramp = 0; //do not change - not implemented in reference\n                        p.initial_weight_distribution = dist;\n                        p.initial_weight_scale = scale;\n                        p.classification = true;\n                        p.diagnostics = true;\n                        p.validation = null;\n                        p.quiet_mode = true;\n                        p.fast_mode = false; //to be the same as reference\n//                      p.fast_mode = true; //to be the same as old NeuralNet code\n                        p.nesterov_accelerated_gradient = false; //to be the same as reference\n//                        p.nesterov_accelerated_gradient = true; //to be the same as old NeuralNet code\n                        p.sync_samples = 100000; //sync once per period\n                        p.ignore_const_cols = false;\n                        p.shuffle_training_data = false;\n                        p.classification_stop = -1; //don't stop early -> need to compare against reference, which doesn't stop either\n                        NNModel mymodel = p.initModel(); //randomize weights, but don't start training yet\n\n                        Neurons[] neurons = NNTask.makeNeuronsForTraining(mymodel.model_info());\n\n                        // use the same random weights for the reference implementation\n                        Neurons l = neurons[1];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n//                          System.out.println(\"initial weight[\" + o + \"]=\" + l._w[o * l._previous._a.length + i]);\n                            ref._nn.ihWeights[i][o] = l._w[o * l._previous._a.length + i];\n                          }\n                          ref._nn.hBiases[o] = l._b[o];\n//                        System.out.println(\"initial bias[\" + o + \"]=\" + l._b[o]);\n                        }\n                        l = neurons[2];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n//                          System.out.println(\"initial weight[\" + o + \"]=\" + l._w[o * l._previous._a.length + i]);\n                            ref._nn.hoWeights[i][o] = l._w[o * l._previous._a.length + i];\n                          }\n                          ref._nn.oBiases[o] = l._b[o];\n//                        System.out.println(\"initial bias[\" + o + \"]=\" + l._b[o]);\n                        }\n\n                        // Train the Reference\n                        ref.train((int)p.epochs, rate, p.momentum_stable, loss);\n\n                        // Train H2O\n                        mymodel = p.buildModel(mymodel);\n\n                        /**\n                         * Tolerances (super tight -> expect the same double/float precision math inside both algos)\n                         */\n                        final double abseps = 1e-13;\n                        final double releps = 1e-13;\n\n                        /**\n                         * Compare weights and biases in hidden layer\n                         */\n                        neurons = NNTask.makeNeuronsForTesting(mymodel.model_info()); //link the weights to the neurons, for easy access\n                        l = neurons[1];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n                            double a = ref._nn.ihWeights[i][o];\n                            double b = l._w[o * l._previous._a.length + i];\n                            compareVal(a, b, abseps, releps);\n//                          System.out.println(\"weight[\" + o + \"]=\" + b);\n                          }\n                          double ba = ref._nn.hBiases[o];\n                          double bb = l._b[o];\n                          compareVal(ba, bb, abseps, releps);\n                        }\n                        Log.info(\"Weights and biases for hidden layer: PASS\");\n\n                        /**\n                         * Compare weights and biases for output layer\n                         */\n                        l = neurons[2];\n                        for( int o = 0; o < l._a.length; o++ ) {\n                          for( int i = 0; i < l._previous._a.length; i++ ) {\n                            double a = ref._nn.hoWeights[i][o];\n                            double b = l._w[o * l._previous._a.length + i];\n                            compareVal(a, b, abseps, releps);\n                          }\n                          double ba = ref._nn.oBiases[o];\n                          double bb = l._b[o];\n                          compareVal(ba, bb, abseps, releps);\n                        }\n                        Log.info(\"Weights and biases for output layer: PASS\");\n\n                        /**\n                         * Compare predictions\n                         * Note: Reference and H2O each do their internal data normalization,\n                         * so we must use their \"own\" test data, which is assumed to be created correctly.\n                         */\n                        // H2O predictions\n                        Frame fpreds = mymodel.score(_test); //[0] is label, [1]...[4] are the probabilities\n\n                        for (int i=0; i<_test.numRows(); ++i) {\n                          // Reference predictions\n                          double[] xValues = new double[neurons[0]._a.length];\n                          System.arraycopy(ref._testData[i], 0, xValues, 0, xValues.length);\n                          double[] ref_preds = ref._nn.ComputeOutputs(xValues);\n\n                          // find the label\n                          // do the same as H2O here (compare float values and break ties based on row number)\n                          float[] preds = new float[ref_preds.length+1];\n                          for (int j=0; j<ref_preds.length; ++j) preds[j+1] = (float)ref_preds[j];\n                          preds[0] = Model.getPrediction(preds, i);\n\n                          // compare predicted label\n                          Assert.assertTrue(preds[0] == (int) fpreds.vecs()[0].at(i));\n                          // compare predicted probabilities\n                          for (int j=0; j<ref_preds.length; ++j) {\n                            compareVal((float)(ref_preds[j]), fpreds.vecs()[1+j].at(i), abseps, releps);\n                          }\n                        }\n                        fpreds.delete();\n                        Log.info(\"Predicted values: PASS\");\n\n                        /**\n                         * Compare (self-reported) scoring\n                         */\n                        final double trainErr = ref._nn.Accuracy(ref._trainData);\n                        final double testErr = ref._nn.Accuracy(ref._testData);\n                        final double myTrainErr = mymodel.calcError(_train, \"Final training error:\", true, null);\n                        final double myTestErr = mymodel.calcError(_test,  \"Final testing error:\",  true, null);\n                        Log.info(\"H2O  training error : \" + myTrainErr*100 + \"%, test error: \" + myTestErr*100 + \"%\");\n                        Log.info(\"REF  training error : \" + trainErr*100 + \"%, test error: \" + testErr*100 + \"%\");\n                        compareVal(trainErr, myTrainErr, abseps, releps);\n                        compareVal(testErr,  myTestErr,  abseps, releps);\n                        Log.info(\"Scoring: PASS\");\n\n                        // cleanup\n                        mymodel.delete();\n                        _train.delete();\n                        _test.delete();\n                        frame.delete();\n                        fr.delete();\n                        p.delete();\n\n                        num_runs++;\n                        Log.info(\"Parameters combination \" + num_runs + \": PASS\");\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }","commit_id":"e3c8e64992d6af7076017cc2d378002be35d6268","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public void testPlistConstructor() {\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Company.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = NSPropertyListSerialization.dictionaryWithPathURL(entityUrl);\n\n\t\tAssert.assertNotNull(new ERXEntity(plist, model));\n\t}","id":36475,"modified_method":"public void testPlistConstructor() {\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Company.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = (NSDictionary)NSPropertyListSerialization.propertyListWithPathURL(entityUrl);\n\n\t\tAssert.assertNotNull(new ERXEntity(plist, model));\n\t}","commit_id":"e31249b407a32d1f3818e8b29d2a08c38483a802","url":"https://github.com/wocommunity/wonder"},{"original_method":"public void testHasExternalName() {\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Company.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = NSPropertyListSerialization.dictionaryWithPathURL(entityUrl);\n\n\t\tERXEntity erxentity = new ERXEntity(plist, model);\n\n\t\tAssert.assertTrue(erxentity.hasExternalName());\n\t}","id":36476,"modified_method":"public void testHasExternalName() {\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Company.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = (NSDictionary)NSPropertyListSerialization.propertyListWithPathURL(entityUrl);\n\n\t\tERXEntity erxentity = new ERXEntity(plist, model);\n\n\t\tAssert.assertTrue(erxentity.hasExternalName());\n\t}","commit_id":"e31249b407a32d1f3818e8b29d2a08c38483a802","url":"https://github.com/wocommunity/wonder"},{"original_method":"public void testSetClassDescription() {\n\n\t\tEOEntity entity1 = EOModelGroup.defaultGroup().entityNamed(\"Company\");\n\t\tEOClassDescription desc = entity1.classDescriptionForInstances();\n\n\t\tAssert.assertNotNull(desc);\n\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Employee.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = NSPropertyListSerialization.dictionaryWithPathURL(entityUrl);\n\n\t\tERXEntity entity2 = new ERXEntity(plist, model);\n\n\t\t// Using a mis-matched EOClassDescription here, but doing that on purpose so we can verify the superclass did not just ignore the set.\n\t\t//\n\t\tentity2.setClassDescription(desc);\n\n\t\tAssert.assertTrue(ERExtensionsTest.equalsForEOAccessObjects(desc, entity2.classDescriptionForInstances()));\n\t}","id":36477,"modified_method":"public void testSetClassDescription() {\n\n\t\tEOEntity entity1 = EOModelGroup.defaultGroup().entityNamed(\"Company\");\n\t\tEOClassDescription desc = entity1.classDescriptionForInstances();\n\n\t\tAssert.assertNotNull(desc);\n\n\t\tURL entityUrl = null;        \t\n\t\ttry {\n\t\t\tentityUrl = new java.net.URL(model.pathURL()+\"/Employee.plist\");\n\t\t} catch (java.net.MalformedURLException e) { throw new IllegalArgumentException(e.getMessage()); }\n\n\t\tNSDictionary plist = (NSDictionary)NSPropertyListSerialization.propertyListWithPathURL(entityUrl);\n\n\t\tERXEntity entity2 = new ERXEntity(plist, model);\n\n\t\t// Using a mis-matched EOClassDescription here, but doing that on purpose so we can verify the superclass did not just ignore the set.\n\t\t//\n\t\tentity2.setClassDescription(desc);\n\n\t\tAssert.assertTrue(ERExtensionsTest.equalsForEOAccessObjects(desc, entity2.classDescriptionForInstances()));\n\t}","commit_id":"e31249b407a32d1f3818e8b29d2a08c38483a802","url":"https://github.com/wocommunity/wonder"},{"original_method":"@SuppressWarnings(\"deprecation\")\n\tpublic void testIncrementAcrossDST() {\n\n        // Set up values used throughout this test.\n        //\n        NSTimeZone tz = null;\n        NSTimestamp ts1, ts2;\n        NSTimestampFormatter  formatter = null;\n        StringBuffer dt = null;\n        java.text.FieldPosition fp = new java.text.FieldPosition(0);\n\n        NSDictionary data = NSPropertyListSerialization.dictionaryWithPathURL(ERXFileUtilities.pathURLForResourceNamed(\"dates.plist\", null, null));\n\n        Enumeration dsts = ((NSArray)data.objectForKey(\"daylightSavingTimeTransitions\")).objectEnumerator();\n\n        while (dsts.hasMoreElements()) {\n            NSDictionary dst = (NSDictionary)dsts.nextElement();\n\n            // System.out.println(\"dst: \"+dst);\n\n            int year = ERXValueUtilities.intValue(dst.objectForKey(\"year\"));\n            int month = ERXValueUtilities.intValue(dst.objectForKey(\"month\"));\n            int day = ERXValueUtilities.intValue(dst.objectForKey(\"day\"));\n            tz = NSTimeZone.timeZoneWithName((String)dst.objectForKey(\"tz\"), false);\n\n            formatter = new NSTimestampFormatter(\"%Y %b %d %H:%M:%S %z\");\n            formatter.setDefaultFormatTimeZone(tz);\n\n            String before = (String)dst.objectForKey(\"before\");\n            String after = (String)dst.objectForKey(\"after\");\n\n            ts1 = new NSTimestamp(year, month, day, 1, 59, 59, tz);\n            dt = new StringBuffer();\n            formatter.format(ts1, dt, fp);\n            // System.out.println(\"before: expected = \\\"\"+before+\"\\\", found = \\\"\"+dt+\"\\\"\");\n            Assert.assertEquals(before, dt.toString());\n\n            ts2 = ts1.timestampByAddingGregorianUnits(0,0,0,0,0,2);\n            dt = new StringBuffer();\n            formatter.format(ts2, dt, fp);\n            // System.out.println(\"after: expected = \\\"\"+after+\"\\\", found = \\\"\"+dt+\"\\\"\");\n            Assert.assertEquals(after, dt.toString());\n        }\n    }","id":36478,"modified_method":"@SuppressWarnings(\"deprecation\")\n\tpublic void testIncrementAcrossDST() {\n\n        // Set up values used throughout this test.\n        //\n        NSTimeZone tz = null;\n        NSTimestamp ts1, ts2;\n        NSTimestampFormatter  formatter = null;\n        StringBuffer dt = null;\n        java.text.FieldPosition fp = new java.text.FieldPosition(0);\n\n        NSDictionary data = (NSDictionary)NSPropertyListSerialization.propertyListWithPathURL(ERXFileUtilities.pathURLForResourceNamed(\"dates.plist\", null, null));\n\n        Enumeration dsts = ((NSArray)data.objectForKey(\"daylightSavingTimeTransitions\")).objectEnumerator();\n\n        while (dsts.hasMoreElements()) {\n            NSDictionary dst = (NSDictionary)dsts.nextElement();\n\n            // System.out.println(\"dst: \"+dst);\n\n            int year = ERXValueUtilities.intValue(dst.objectForKey(\"year\"));\n            int month = ERXValueUtilities.intValue(dst.objectForKey(\"month\"));\n            int day = ERXValueUtilities.intValue(dst.objectForKey(\"day\"));\n            tz = NSTimeZone.timeZoneWithName((String)dst.objectForKey(\"tz\"), false);\n\n            formatter = new NSTimestampFormatter(\"%Y %b %d %H:%M:%S %z\");\n            formatter.setDefaultFormatTimeZone(tz);\n\n            String before = (String)dst.objectForKey(\"before\");\n            String after = (String)dst.objectForKey(\"after\");\n\n            ts1 = new NSTimestamp(year, month, day, 1, 59, 59, tz);\n            dt = new StringBuffer();\n            formatter.format(ts1, dt, fp);\n            // System.out.println(\"before: expected = \\\"\"+before+\"\\\", found = \\\"\"+dt+\"\\\"\");\n            Assert.assertEquals(before, dt.toString());\n\n            ts2 = ts1.timestampByAddingGregorianUnits(0,0,0,0,0,2);\n            dt = new StringBuffer();\n            formatter.format(ts2, dt, fp);\n            // System.out.println(\"after: expected = \\\"\"+after+\"\\\", found = \\\"\"+dt+\"\\\"\");\n            Assert.assertEquals(after, dt.toString());\n        }\n    }","commit_id":"e31249b407a32d1f3818e8b29d2a08c38483a802","url":"https://github.com/wocommunity/wonder"},{"original_method":"@SuppressWarnings(\"deprecation\")\n\tpublic void testFirstDaysOfYears() {\n        NSDictionary data = NSPropertyListSerialization.dictionaryWithPathURL(ERXFileUtilities.pathURLForResourceNamed(\"dates.plist\", null, null));\n\n        NSDictionary daysDict = (NSDictionary)data.objectForKey(\"firstDayForYears\");\n      \n        Enumeration days = daysDict.allKeys().objectEnumerator();\n        while (days.hasMoreElements()) {\n            String key = (String)days.nextElement();\n            int year = -1;\n            try {\n                year = (new Integer(key)).intValue();\n            } catch (java.lang.NumberFormatException nfe) { }\n            String dayName = (String)daysDict.objectForKey(key);\n            Assert.assertEquals(day(dayName), (new NSTimestamp(year, JAN, 1, 0, 0, 0, NSTimeZone.getGMT())).dayOfWeek());\n        } \n    }","id":36479,"modified_method":"@SuppressWarnings(\"deprecation\")\n\tpublic void testFirstDaysOfYears() {\n        NSDictionary data = (NSDictionary)NSPropertyListSerialization.propertyListWithPathURL(ERXFileUtilities.pathURLForResourceNamed(\"dates.plist\", null, null));\n\n        NSDictionary daysDict = (NSDictionary)data.objectForKey(\"firstDayForYears\");\n      \n        Enumeration days = daysDict.allKeys().objectEnumerator();\n        while (days.hasMoreElements()) {\n            String key = (String)days.nextElement();\n            int year = -1;\n            try {\n                year = (new Integer(key)).intValue();\n            } catch (java.lang.NumberFormatException nfe) { }\n            String dayName = (String)daysDict.objectForKey(key);\n            Assert.assertEquals(day(dayName), (new NSTimestamp(year, JAN, 1, 0, 0, 0, NSTimeZone.getGMT())).dayOfWeek());\n        } \n    }","commit_id":"e31249b407a32d1f3818e8b29d2a08c38483a802","url":"https://github.com/wocommunity/wonder"},{"original_method":"private synchronized void checkConceptIsLoaded(final String fqName) {\n    if (structureDescriptors.containsKey(fqName) || conceptsInLoading.contains(fqName)) {\n      return;\n    }\n\n    conceptsInLoading.add(fqName);\n\n    languageToConcepts.putValue(NameUtil.namespaceFromConceptFQName(fqName), fqName);\n\n    ModelAccess.instance().runReadAction(new Runnable() {\n      @Override\n      public void run() {\n        LanguageRuntime languageRuntime = LanguageRegistry.getInstance().getLanguage(NameUtil.namespaceFromConceptFQName(fqName));\n        structureDescriptors.put(fqName, languageRuntime.getStructureAspect().getDescriptor(fqName));\n        behaviorDescriptors.put(fqName, languageRuntime.getBehaviorAspect().getDescriptor(fqName));\n        constraintsDescriptors.put(fqName, languageRuntime.getConstraintsAspect().getDescriptor(fqName));\n      }\n    });\n\n    conceptsInLoading.remove(fqName);\n  }","id":36480,"modified_method":"private synchronized void checkConceptIsLoaded(final String fqName) {\n    if (structureDescriptors.containsKey(fqName) || conceptsInLoading.contains(fqName)) {\n      return;\n    }\n\n    conceptsInLoading.add(fqName);\n\n    languageToConcepts.putValue(NameUtil.namespaceFromConceptFQName(fqName), fqName);\n\n//    ModelAccess.instance().runReadAction(new Runnable() {\n//      @Override\n//      public void run() {\n    LanguageRuntime languageRuntime = LanguageRegistry.getInstance().getLanguage(NameUtil.namespaceFromConceptFQName(fqName));\n\n    if (languageRuntime != null) {\n      structureDescriptors.put(fqName, languageRuntime.getStructureAspect().getDescriptor(fqName));\n      behaviorDescriptors.put(fqName, languageRuntime.getBehaviorAspect().getDescriptor(fqName));\n      constraintsDescriptors.put(fqName, languageRuntime.getConstraintsAspect().getDescriptor(fqName));\n    }\n//      }\n//    });\n\n    conceptsInLoading.remove(fqName);\n  }","commit_id":"4ce7d7b0bafc304315c697a55d3c95b12bb2283b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static Set<String> getAncestorsNames(final String conceptFqName) {\n    return ConceptRegistry.getInstance().getStructureDescriptor(conceptFqName).getAncestorsNames();\n  }","id":36481,"modified_method":"public static Set<String> getAncestorsNames(final String conceptFqName) {\n    return ConceptRegistry.getInstance().getConceptDescriptor(conceptFqName).structure().getAncestorsNames();\n  }","commit_id":"4ce7d7b0bafc304315c697a55d3c95b12bb2283b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<String> getParentsNames(String conceptFqName) {\n    return ConceptRegistry.getInstance().getStructureDescriptor(conceptFqName).getParentsNames();\n  }","id":36482,"modified_method":"public static List<String> getParentsNames(String conceptFqName) {\n    return ConceptRegistry.getInstance().getConceptDescriptor(conceptFqName).structure().getParentsNames();\n  }","commit_id":"4ce7d7b0bafc304315c697a55d3c95b12bb2283b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static boolean isAssignable(String fromConceptFqName, String toConceptFqName) {\n    return ConceptRegistry.getInstance().getStructureDescriptor(fromConceptFqName).isAssignableTo(toConceptFqName);\n  }","id":36483,"modified_method":"public static boolean isAssignable(String fromConceptFqName, String toConceptFqName) {\n    return ConceptRegistry.getInstance().getConceptDescriptor(fromConceptFqName).structure().isAssignableTo(toConceptFqName);\n  }","commit_id":"4ce7d7b0bafc304315c697a55d3c95b12bb2283b","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Nullable\n  public LanguageRuntime getLanguage(String namespace) {\n    ModelAccess.assertLegalRead();\n\n    return myLanguages.get(namespace);\n  }","id":36484,"modified_method":"@Nullable\n  public LanguageRuntime getLanguage(String namespace) {\n//    ModelAccess.assertLegalRead();\n\n    return myLanguages.get(namespace);\n  }","commit_id":"4ce7d7b0bafc304315c697a55d3c95b12bb2283b","url":"https://github.com/JetBrains/MPS"},{"original_method":"public CustomMembersGenerator(GroovyClassDescriptor descriptor) {\n    myDescriptor = descriptor;\n    myProject = descriptor.getProject();\n    myTypeText = descriptor.getTypeText();\n    final PsiType type = descriptor.getPsiType();\n    if (type instanceof PsiClassType) {\n      final PsiClass psiClass = ((PsiClassType)type).resolve();\n      if (psiClass != null) {\n        myQualifiedName = psiClass.getQualifiedName();\n      } else {\n        myQualifiedName = null;\n      }\n    } else {\n      myQualifiedName = null;\n    }\n  }","id":36485,"modified_method":"public CustomMembersGenerator(GroovyClassDescriptor descriptor) {\n    myDescriptor = descriptor;\n    myProject = descriptor.getProject();\n    final PsiType type = descriptor.getPsiType();\n    if (type instanceof PsiClassType) {\n      final PsiClass psiClass = ((PsiClassType)type).resolve();\n      if (psiClass != null) {\n        myQualifiedName = psiClass.getQualifiedName();\n      } else {\n        myQualifiedName = null;\n      }\n    } else {\n      myQualifiedName = null;\n    }\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  public PsiType getClassType() {\n    final PsiElementFactory factory = JavaPsiFacade.getElementFactory(myProject);\n    try {\n      return factory.createTypeFromText(myTypeText, getPlace());\n    }\n    catch (IncorrectOperationException e) {\n      final PsiClass psiClass = getPsiClass();\n      if (psiClass != null) return factory.createType(psiClass);\n    }\n    return null;\n  }","id":36486,"modified_method":"@Nullable\n  public PsiClass getClassType() {\n    return getPsiClass();\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void processDynamicElements(@NotNull PsiType qualifierType,\n                                     PsiScopeProcessor processor,\n                                     PsiElement place,\n                                     ResolveState state) {\n    final DynamicManager manager = DynamicManager.getInstance(place.getProject());\n    for (String qName : ResolveUtil.getAllSuperTypes(qualifierType, place).keySet()) {\n      for (PsiMethod method : manager.getMethods(qName)) {\n        if (!ResolveUtil.processElement(processor, method, state)) return;\n      }\n\n      for (PsiVariable var : manager.getProperties(qName)) {\n        if (!ResolveUtil.processElement(processor, var, state)) return;\n      }\n    }\n  }","id":36487,"modified_method":"@Override\n  public void processDynamicElements(@NotNull PsiType qualifierType,\n                                     PsiScopeProcessor processor,\n                                     PsiElement place,\n                                     ResolveState state) {\n    final DynamicManager manager = DynamicManager.getInstance(place.getProject());\n    for (String qName : ResolveUtil.getAllSuperTypes(qualifierType, place.getProject()).keySet()) {\n      for (PsiMethod method : manager.getMethods(qName)) {\n        if (!ResolveUtil.processElement(processor, method, state)) return;\n      }\n\n      for (PsiVariable var : manager.getProperties(qName)) {\n        if (!ResolveUtil.processElement(processor, var, state)) return;\n      }\n    }\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void processDynamicElements(@NotNull PsiType qualifierType,\n                                     PsiScopeProcessor processor,\n                                     PsiElement place,\n                                     ResolveState state) {\n    if (ResolveUtil.isInheritor(qualifierType, \"groovy.util.AntBuilder\", place)) {\n      processAntTasks(processor, place, state);\n      return;\n    }\n\n    if (!(place instanceof GrReferenceExpression) || ((GrReferenceExpression)place).isQualified()) {\n      return;\n    }\n\n    GrClosableBlock closure = PsiTreeUtil.getContextOfType(place, GrClosableBlock.class, true);\n    if (closure == null) {\n      return;\n    }\n\n    boolean antTasksProcessed = false;\n    while (closure != null) {\n      final PsiElement parent = closure.getParent();\n      if (parent instanceof GrMethodCall) {\n        final PsiMethod method = ((GrMethodCall)parent).resolveMethod();\n        if (method instanceof AntBuilderMethod) {\n          antTasksProcessed = true;\n          if (!processAntTasks(processor, place, state)) {\n            return;\n          }\n          if (!((AntBuilderMethod)method).processNestedElements(processor)) {\n            return;\n          }\n          break;\n        }\n      }\n\n      closure = PsiTreeUtil.getContextOfType(closure, GrClosableBlock.class, true);\n    }\n\n    // ------- gant-specific\n\n    PsiFile file = place.getContainingFile();\n    if (!GantUtils.isGantScriptFile(file)) {\n      return;\n    }\n\n    for (GrArgumentLabel label : GantUtils.getScriptTargets((GroovyFile)file)) {\n      final String targetName = label.getName();\n      if (targetName != null) {\n        final PsiNamedElement variable = new LightVariableBuilder(targetName, GrClosableBlock.GROOVY_LANG_CLOSURE, label).\n          setBaseIcon(GantIcons.GANT_TARGET);\n        if (!ResolveUtil.processElement(processor, variable, state)) {\n          return;\n        }\n      }\n    }\n\n    if (!antTasksProcessed) {\n      processAntTasks(processor, place, state);\n    }\n\n  }","id":36488,"modified_method":"@Override\n  public void processDynamicElements(@NotNull PsiType qualifierType,\n                                     PsiScopeProcessor processor,\n                                     PsiElement place,\n                                     ResolveState state) {\n    if (ResolveUtil.isInheritor(qualifierType, \"groovy.util.AntBuilder\", place.getProject())) {\n      processAntTasks(processor, place, state);\n      return;\n    }\n\n    if (!(place instanceof GrReferenceExpression) || ((GrReferenceExpression)place).isQualified()) {\n      return;\n    }\n\n    GrClosableBlock closure = PsiTreeUtil.getContextOfType(place, GrClosableBlock.class, true);\n    if (closure == null) {\n      return;\n    }\n\n    boolean antTasksProcessed = false;\n    while (closure != null) {\n      final PsiElement parent = closure.getParent();\n      if (parent instanceof GrMethodCall) {\n        final PsiMethod method = ((GrMethodCall)parent).resolveMethod();\n        if (method instanceof AntBuilderMethod) {\n          antTasksProcessed = true;\n          if (!processAntTasks(processor, place, state)) {\n            return;\n          }\n          if (!((AntBuilderMethod)method).processNestedElements(processor)) {\n            return;\n          }\n          break;\n        }\n      }\n\n      closure = PsiTreeUtil.getContextOfType(closure, GrClosableBlock.class, true);\n    }\n\n    // ------- gant-specific\n\n    PsiFile file = place.getContainingFile();\n    if (!GantUtils.isGantScriptFile(file)) {\n      return;\n    }\n\n    for (GrArgumentLabel label : GantUtils.getScriptTargets((GroovyFile)file)) {\n      final String targetName = label.getName();\n      if (targetName != null) {\n        final PsiNamedElement variable = new LightVariableBuilder(targetName, GrClosableBlock.GROOVY_LANG_CLOSURE, label).\n          setBaseIcon(GantIcons.GANT_TARGET);\n        if (!ResolveUtil.processElement(processor, variable, state)) {\n          return;\n        }\n      }\n    }\n\n    if (!antTasksProcessed) {\n      processAntTasks(processor, place, state);\n    }\n\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean handleDslError(Throwable e) {\n    if (project.isDisposed() || ApplicationManager.getApplication().isUnitTestMode()) {\n      LOG.error(e);\n      return true;\n    }\n    GroovyDslFileIndex.invokeDslErrorPopup(e, project, file);\n    return false;\n  }","id":36489,"modified_method":"private boolean handleDslError(Throwable e) {\n    LOG.error(e);\n    if (project.isDisposed() || ApplicationManager.getApplication().isUnitTestMode()) {\n      return true;\n    }\n    GroovyDslFileIndex.invokeDslErrorPopup(e, project, file);\n    return false;\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GroovyPsiManager(Project project) {\n    myProject = project;\n    myCache = ContainerUtil.findInstance(project.getExtensions(PsiShortNamesCache.EP_NAME), GroovyShortNamesCache.class);\n\n    ((PsiManagerEx)PsiManager.getInstance(myProject)).registerRunnableToRunOnAnyChange(new Runnable() {\n      public void run() {\n        dropTypesCache();\n      }\n    });\n\n    myTypeInferenceHelper = new TypeInferenceHelper(myProject);\n\n    myProject.getMessageBus().connect().subscribe(ProjectTopics.PROJECT_ROOTS, new ModuleRootListener() {\n      public void beforeRootsChange(ModuleRootEvent event) {\n      }\n\n      public void rootsChanged(ModuleRootEvent event) {\n        dropTypesCache();\n        myRebuildGdkPending = true;\n      }\n    });\n  }","id":36490,"modified_method":"public GroovyPsiManager(Project project) {\n    myProject = project;\n    myCache = ContainerUtil.findInstance(project.getExtensions(PsiShortNamesCache.EP_NAME), GroovyShortNamesCache.class);\n\n    ((PsiManagerEx)PsiManager.getInstance(myProject)).registerRunnableToRunOnAnyChange(new Runnable() {\n      public void run() {\n        dropTypesCache();\n      }\n    });\n\n    myTypeInferenceHelper = new TypeInferenceHelper(myProject);\n\n    myProject.getMessageBus().connect().subscribe(ProjectTopics.PROJECT_ROOTS, new ModuleRootListener() {\n      public void beforeRootsChange(ModuleRootEvent event) {\n      }\n\n      public void rootsChanged(ModuleRootEvent event) {\n        dropTypesCache();\n      }\n    });\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean isInheritor(PsiType type, @NotNull String baseClass, PsiElement place) {\n    return getAllSuperTypes(type, place).keySet().contains(baseClass);\n  }","id":36491,"modified_method":"public static boolean isInheritor(PsiType type, @NotNull String baseClass, Project project) {\n    return getAllSuperTypes(type, project).keySet().contains(baseClass);\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static Map<String, PsiType> getAllSuperTypes(PsiType base, final PsiElement place) {\n    final Project project = place.getProject();\n    final Map<String, Map<String, PsiType>> cache =\n      CachedValuesManager.getManager(project).getCachedValue(project, new CachedValueProvider<Map<String, Map<String, PsiType>>>() {\n        @Override\n        public Result<Map<String, Map<String, PsiType>>> compute() {\n          final Map<String, Map<String, PsiType>> result = new ConcurrentHashMap<String, Map<String, PsiType>>();\n          return Result.create(result, PsiModificationTracker.JAVA_STRUCTURE_MODIFICATION_COUNT, ProjectRootManager.getInstance(project));\n        }\n      });\n\n    final PsiClass cls = PsiUtil.resolveClassInType(base);\n    //noinspection ConstantConditions\n    String key = cls instanceof PsiTypeParameter ? cls.getName() + cls.getSuperClass().getName() : rawCanonicalText(base);\n    Map<String, PsiType> result = cache.get(key);\n    if (result == null) {\n      result = new HashMap<String, PsiType>();\n      collectSuperTypes(base, result, project);\n      cache.put(key, result);\n    }\n    return result;\n  }","id":36492,"modified_method":"public static Map<String, PsiType> getAllSuperTypes(PsiType base, final Project project) {\n    final Map<String, Map<String, PsiType>> cache =\n      CachedValuesManager.getManager(project).getCachedValue(project, new CachedValueProvider<Map<String, Map<String, PsiType>>>() {\n        @Override\n        public Result<Map<String, Map<String, PsiType>>> compute() {\n          final Map<String, Map<String, PsiType>> result = new ConcurrentHashMap<String, Map<String, PsiType>>();\n          return Result.create(result, PsiModificationTracker.JAVA_STRUCTURE_MODIFICATION_COUNT, ProjectRootManager.getInstance(project));\n        }\n      });\n\n    final PsiClass cls = PsiUtil.resolveClassInType(base);\n    //noinspection ConstantConditions\n    String key = cls instanceof PsiTypeParameter ? cls.getName() + cls.getSuperClass().getName() : rawCanonicalText(base);\n    Map<String, PsiType> result = cache.get(key);\n    if (result == null) {\n      result = new HashMap<String, PsiType>();\n      collectSuperTypes(base, result, project);\n      cache.put(key, result);\n    }\n    return result;\n  }","commit_id":"ddd0df0f0b55c99e6430c4ce76641679e889cc44","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean isValid() {\n      return getPsiClass() != null;\n    }","id":36493,"modified_method":"public boolean isValid() {\n      PsiClass psiClass = getPsiClass();\n      return psiClass != null && psiClass.isValid();\n    }","commit_id":"4826465b86d77e1cee16ebcac9f9c6193b55408b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void scrollToSelectedElementInner() {\n    try {\n      PsiDocumentManager.getInstance(myProject).commitAllDocuments();\n      final Object currentEditorElement = myTreeModel.getCurrentEditorElement();\n      if (currentEditorElement != null) {\n        select(currentEditorElement, false);\n      }\n    }\n    catch (IndexNotReadyException ignore) {\n    }\n  }","id":36494,"modified_method":"private void scrollToSelectedElementInner() {\n    PsiDocumentManager.getInstance(myProject).performWhenAllCommitted(() -> {\n      try {\n        final Object currentEditorElement = myTreeModel.getCurrentEditorElement();\n        if (currentEditorElement != null) {\n          select(currentEditorElement, false);\n        }\n      }\n      catch (IndexNotReadyException ignore) {\n      }\n    });\n  }","commit_id":"8ad96210438b024eae400487937eb1ea2c795749","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"void execute(@NotNull BrowseMode browseMode) {\n      myBrowseMode = browseMode;\n\n      Document document = myEditor.getDocument();\n      final PsiFile file = PsiDocumentManager.getInstance(myProject).getPsiFile(document);\n      if (file == null) return;\n      PsiDocumentManager.getInstance(myProject).commitAllDocuments();\n\n      if (EditorUtil.inVirtualSpace(myEditor, myPosition)) {\n        disposeHighlighter();\n        return;\n      }\n\n      final int offset = myEditor.logicalPositionToOffset(myPosition);\n\n      int selStart = myEditor.getSelectionModel().getSelectionStart();\n      int selEnd = myEditor.getSelectionModel().getSelectionEnd();\n\n      if (offset >= selStart && offset < selEnd) return;\n\n      ProgressIndicatorUtils.scheduleWithWriteActionPriority(myProgress, new ReadTask() {\n        @Nullable\n        @Override\n        public Continuation performInReadAction(@NotNull ProgressIndicator indicator) throws ProcessCanceledException {\n          return doExecute(file, offset);\n        }\n\n        @Override\n        public void onCanceled(@NotNull ProgressIndicator indicator) {\n          LOG.debug(\"Highlighting was cancelled\");\n        }\n      });\n    }","id":36495,"modified_method":"void execute(@NotNull BrowseMode browseMode) {\n      myBrowseMode = browseMode;\n\n      Document document = myEditor.getDocument();\n      final PsiFile file = PsiDocumentManager.getInstance(myProject).getPsiFile(document);\n      if (file == null) return;\n\n      if (EditorUtil.inVirtualSpace(myEditor, myPosition)) {\n        disposeHighlighter();\n        return;\n      }\n\n      final int offset = myEditor.logicalPositionToOffset(myPosition);\n\n      int selStart = myEditor.getSelectionModel().getSelectionStart();\n      int selEnd = myEditor.getSelectionModel().getSelectionEnd();\n\n      if (offset >= selStart && offset < selEnd) return;\n\n      PsiDocumentManager.getInstance(myProject).performWhenAllCommitted(\n        () -> ProgressIndicatorUtils.scheduleWithWriteActionPriority(myProgress, new ReadTask() {\n          @Nullable\n          @Override\n          public Continuation performInReadAction(@NotNull ProgressIndicator indicator) throws ProcessCanceledException {\n            return doExecute(file, offset);\n          }\n\n          @Override\n          public void onCanceled(@NotNull ProgressIndicator indicator) {\n            LOG.debug(\"Highlighting was cancelled\");\n          }\n        }));\n    }","commit_id":"f3eb8cd7bf6aa528fdc03ecc05a9654026514ca9","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    public void visibilityChanged() {\n      if (myProject.isOpen()) {\n        PsiDocumentManager.getInstance(myProject).commitAllDocuments();\n        myTodoTreeBuilder.setUpdatable(isShowing());\n      }\n    }","id":36496,"modified_method":"@Override\n    public void visibilityChanged() {\n      if (myProject.isOpen()) {\n        PsiDocumentManager.getInstance(myProject).performWhenAllCommitted(\n          () -> myTodoTreeBuilder.setUpdatable(isShowing()));\n      }\n    }","commit_id":"3dff55951297ca752159f13e2f9a12295b9182ea","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean parseOption(String[] args) throws ParseException, IOException {\n    if (args.length == 0) {\n      return true; // no args will process with default values.\n    }\n    CommandLineParser parser = new GnuParser();\n    CommandLine cmd = parser.parse(options, args);\n    if (cmd.hasOption(\"h\")) {\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"HFileV1Detector\", options, true);\n      System.out\n          .println(\"In case no option is provided, it processes hbase.rootdir using 10 threads.\");\n      System.out.println(\"Example:\");\n      System.out.println(\" To detect any HFileV1 in a given hbase installation '/myhbase':\");\n      System.out.println(\" $ $HBASE_HOME/bin/hbase \" + this.getClass().getName() + \" -p /myhbase\");\n      System.out.println();\n      return false;\n    }\n\n    if (cmd.hasOption(\"p\")) {\n      dirToProcess = new Path(cmd.getOptionValue(\"p\"));\n    }\n    try {\n      if (cmd.hasOption(\"n\")) {\n        int n = Integer.parseInt(cmd.getOptionValue(\"n\"));\n        if (n < 0 || n > 100) {\n          System.out.println(\"Please use a positive number <= 100 for number of threads.\"\n              + \" Continuing with default value \" + DEFAULT_NUM_OF_THREADS);\n          return true;\n        }\n        numOfThreads = n;\n      }\n    } catch (NumberFormatException nfe) {\n      System.err.println(\"Please select a valid number for threads\");\n      return false;\n    }\n    return true;\n  }","id":36497,"modified_method":"private boolean parseOption(String[] args) throws ParseException, IOException {\n    if (args.length == 0) {\n      return true; // no args will process with default values.\n    }\n    CommandLineParser parser = new GnuParser();\n    CommandLine cmd = parser.parse(options, args);\n    if (cmd.hasOption(\"h\")) {\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"HFileV1Detector\", options, true);\n      System.out\n          .println(\"In case no option is provided, it processes hbase.rootdir using 10 threads.\");\n      System.out.println(\"Example:\");\n      System.out.println(\" To detect any HFileV1 in a given hbase installation '/myhbase':\");\n      System.out.println(\" $ $HBASE_HOME/bin/hbase \" + this.getClass().getName() + \" -p /myhbase\");\n      System.out.println();\n      return false;\n    }\n\n    if (cmd.hasOption(\"p\")) {\n      this.targetDirPath = new Path(FSUtils.getRootDir(getConf()), cmd.getOptionValue(\"p\"));\n    }\n    try {\n      if (cmd.hasOption(\"n\")) {\n        int n = Integer.parseInt(cmd.getOptionValue(\"n\"));\n        if (n < 0 || n > 100) {\n          LOG.warn(\"Please use a positive number <= 100 for number of threads.\"\n              + \" Continuing with default value \" + DEFAULT_NUM_OF_THREADS);\n          return true;\n        }\n        this.numOfThreads = n;\n      }\n    } catch (NumberFormatException nfe) {\n      LOG.error(\"Please select a valid number for threads\");\n      return false;\n    }\n    return true;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n  public int run(String args[]) throws IOException, ParseException {\n    fs = FileSystem.get(getConf());\n    numOfThreads = DEFAULT_NUM_OF_THREADS;\n    dirToProcess = FSUtils.getRootDir(getConf());\n    if (!parseOption(args)) {\n      System.exit(1);\n    }\n    ExecutorService exec = Executors.newFixedThreadPool(numOfThreads);\n    Set<Path> regionsWithHFileV1;\n    try {\n      regionsWithHFileV1 = checkForV1Files(dirToProcess, exec);\n      printHRegionsWithHFileV1(regionsWithHFileV1);\n      printAllHFileV1();\n      printCorruptedHFiles();\n      if (hFileV1Set.isEmpty() && corruptedHFiles.isEmpty()) {\n        // all clear.\n        System.out.println(\"No HFile V1 Found\");\n      }\n    } catch (Exception e) {\n      System.err.println(e);\n      return 1;\n    } finally {\n      exec.shutdown();\n      fs.close();\n    }\n    return 0;\n  }","id":36498,"modified_method":"/**\n   * Checks for HFileV1.\n   * @return 0 when no HFileV1 is present.\n   *         1 when a HFileV1 is present or, when there is a file with corrupt major version\n   *          (neither V1 nor V2).\n   *        -1 in case of any error/exception\n   */\n  @Override\n  public int run(String args[]) throws IOException, ParseException {\n    FSUtils.setFsDefault(getConf(), new Path(FSUtils.getRootDir(getConf()).toUri()));\n    fs = FileSystem.get(getConf());\n    numOfThreads = DEFAULT_NUM_OF_THREADS;\n    targetDirPath = FSUtils.getRootDir(getConf());\n    if (!parseOption(args)) {\n      System.exit(-1);\n    }\n    this.exec = Executors.newFixedThreadPool(numOfThreads);\n    try {\n      return processResult(checkForV1Files(targetDirPath));\n    } catch (Exception e) {\n      LOG.error(e);\n    } finally {\n      exec.shutdown();\n      fs.close();\n    }\n    return -1;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Takes a directory path, and lists out any HFileV1, if present.\n   * @param targetDir directory to start looking for HFilev1.\n   * @param exec\n   * @return set of Regions that have HFileV1\n   * @throws IOException\n   */\n  private Set<Path> checkForV1Files(Path targetDir, final ExecutorService exec) throws IOException {\n    if (isTableDir(fs, targetDir)) {\n      return processTable(targetDir, exec);\n    }\n    // user has passed a hbase installation directory.\n    if (!fs.exists(targetDir)) {\n      throw new IOException(\"The given path does not exist: \" + targetDir);\n    }\n    Set<Path> regionsWithHFileV1 = new HashSet<Path>();\n    FileStatus[] fsStats = fs.listStatus(targetDir);\n    for (FileStatus fsStat : fsStats) {\n      if (isTableDir(fs, fsStat.getPath())) {\n        // look for regions and find out any v1 file.\n        regionsWithHFileV1.addAll(processTable(fsStat.getPath(), exec));\n      } else {\n        LOG.info(\"Ignoring path: \" + fsStat.getPath());\n      }\n    }\n    return regionsWithHFileV1;\n  }","id":36499,"modified_method":"/**\n   * Takes a directory path, and lists out any HFileV1, if present.\n   * @param targetDir directory to start looking for HFilev1.\n   * @return set of Regions that have HFileV1\n   * @throws IOException\n   */\n  private Set<Path> checkForV1Files(Path targetDir) throws IOException {\n    LOG.info(\"Target dir is: \" + targetDir);\n    if (!fs.exists(targetDir)) {\n      throw new IOException(\"The given path does not exist: \" + targetDir);\n    }\n    if (isTableDir(fs, targetDir)) {\n      processedTables.add(targetDir);\n      return processTable(targetDir);\n    }\n    Set<Path> regionsWithHFileV1 = new HashSet<Path>();\n    FileStatus[] fsStats = fs.listStatus(targetDir);\n    for (FileStatus fsStat : fsStats) {\n      if (isTableDir(fs, fsStat.getPath()) && !isRootTable(fsStat.getPath())) {\n        processedTables.add(fsStat.getPath());\n        // look for regions and find out any v1 file.\n        regionsWithHFileV1.addAll(processTable(fsStat.getPath()));\n      } else {\n        LOG.info(\"Ignoring path: \" + fsStat.getPath());\n      }\n    }\n    return regionsWithHFileV1;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"private static boolean isTableDir(final FileSystem fs, final Path path) throws IOException {\n    return FSTableDescriptors.getTableInfoPath(fs, path) != null;\n  }","id":36500,"modified_method":"private static boolean isTableDir(final FileSystem fs, final Path path) throws IOException {\n    // check for old format, of having /table/.tableinfo; .META. doesn't has .tableinfo,\n    // include it.\n    return (FSTableDescriptors.getTableInfoPath(fs, path) != null || FSTableDescriptors\n        .getCurrentTableInfoStatus(fs, path, false) != null) || path.toString().endsWith(\".META.\");\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Find out the regions in the table which has an HFile v1 in it.\n   * @param tableDir\n   * @param exec\n   * @return the set of regions containing HFile v1.\n   * @throws IOException\n   */\n  private Set<Path> processTable(Path tableDir, final ExecutorService exec) throws IOException {\n    // list out the regions and then process each file in it.\n    LOG.info(\"processing table: \" + tableDir);\n    List<Future<Path>> regionLevelResults = new ArrayList<Future<Path>>();\n    Set<Path> regionsWithHFileV1 = new HashSet<Path>();\n\n    FileStatus[] fsStats = fs.listStatus(tableDir);\n    for (FileStatus fsStat : fsStats) {\n      // process each region\n      if (isRegionDir(fs, fsStat.getPath())) {\n        regionLevelResults.add(processRegion(fsStat.getPath(), exec));\n      }\n    }\n    for (Future<Path> f : regionLevelResults) {\n      try {\n        if (f.get() != null) {\n          regionsWithHFileV1.add(f.get());\n        }\n      } catch (InterruptedException e) {\n        System.err.println(e);\n      } catch (ExecutionException e) {\n        System.err.println(e); // might be a bad hfile. We print it at the end.\n      }\n    }\n    return regionsWithHFileV1;\n  }","id":36501,"modified_method":"/**\n   * Find out regions in the table which have HFileV1.\n   * @param tableDir\n   * @return the set of regions containing HFile v1.\n   * @throws IOException\n   */\n  private Set<Path> processTable(Path tableDir) throws IOException {\n    // list out the regions and then process each file in it.\n    LOG.debug(\"processing table: \" + tableDir);\n    List<Future<Path>> regionLevelResults = new ArrayList<Future<Path>>();\n    Set<Path> regionsWithHFileV1 = new HashSet<Path>();\n\n    FileStatus[] fsStats = fs.listStatus(tableDir);\n    for (FileStatus fsStat : fsStats) {\n      // process each region\n      if (isRegionDir(fs, fsStat.getPath())) {\n        regionLevelResults.add(processRegion(fsStat.getPath()));\n      }\n    }\n    for (Future<Path> f : regionLevelResults) {\n      try {\n        if (f.get() != null) {\n          regionsWithHFileV1.add(f.get());\n        }\n      } catch (InterruptedException e) {\n        LOG.error(e);\n      } catch (ExecutionException e) {\n        LOG.error(e); // might be a bad hfile. We print it at the end.\n      }\n    }\n    return regionsWithHFileV1;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Each region is processed by a separate handler. If a HRegion has a hfileV1, its path is\n   * returned as the future result, otherwise, a null value is returned.\n   * @param regionDir Region to process.\n   * @param exec\n   * @return corresponding Future object.\n   */\n  private Future<Path> processRegion(final Path regionDir, final ExecutorService exec) {\n    LOG.info(\"processing region: \" + regionDir);\n    Callable<Path> regionCallable = new Callable<Path>() {\n      @Override\n      public Path call() throws Exception {\n        for (Path familyDir : FSUtils.getFamilyDirs(fs, regionDir)) {\n          FileStatus[] storeFiles = FSUtils.listStatus(fs, familyDir);\n          if (storeFiles == null || storeFiles.length == 0) continue;\n          for (FileStatus storeFile : storeFiles) {\n            Path storeFilePath = storeFile.getPath();\n            FSDataInputStream fsdis = null;\n            long lenToRead = 0;\n            try {\n              // check whether this path is a reference.\n              if (StoreFileInfo.isReference(storeFilePath)) continue;\n              // check whether this path is a HFileLink.\n              else if (HFileLink.isHFileLink(storeFilePath)) {\n                HFileLink fileLink = new HFileLink(getConf(), storeFilePath);\n                fsdis = fileLink.open(fs);\n                lenToRead = fileLink.getFileStatus(fs).getLen();\n              } else {\n                // a regular hfile\n                fsdis = fs.open(storeFilePath);\n                lenToRead = storeFile.getLen();\n              }\n              FixedFileTrailer trailer = FixedFileTrailer.readFromStream(fsdis, lenToRead);\n              int version = trailer.getMajorVersion();\n              if (version == 1) {\n                hFileV1Set.add(storeFilePath);\n                // return this region path, as it needs to be compacted.\n                return regionDir;\n              }\n            } catch (Exception iae) {\n              corruptedHFiles.add(storeFilePath);\n            } finally {\n              if (fsdis != null) fsdis.close();\n            }\n          }\n        }\n        return null;\n      }\n    };\n    Future<Path> f = exec.submit(regionCallable);\n    return f;\n  }","id":36502,"modified_method":"/**\n   * Each region is processed by a separate handler. If a HRegion has a hfileV1, its path is\n   * returned as the future result, otherwise, a null value is returned.\n   * @param regionDir Region to process.\n   * @return corresponding Future object.\n   */\n  private Future<Path> processRegion(final Path regionDir) {\n    LOG.debug(\"processing region: \" + regionDir);\n    Callable<Path> regionCallable = new Callable<Path>() {\n      @Override\n      public Path call() throws Exception {\n        for (Path familyDir : FSUtils.getFamilyDirs(fs, regionDir)) {\n          FileStatus[] storeFiles = FSUtils.listStatus(fs, familyDir);\n          if (storeFiles == null || storeFiles.length == 0) continue;\n          for (FileStatus storeFile : storeFiles) {\n            Path storeFilePath = storeFile.getPath();\n            FSDataInputStream fsdis = null;\n            long lenToRead = 0;\n            try {\n              // check whether this path is a reference.\n              if (StoreFileInfo.isReference(storeFilePath)) continue;\n              // check whether this path is a HFileLink.\n              else if (HFileLink.isHFileLink(storeFilePath)) {\n                HFileLink fileLink = new HFileLink(getConf(), storeFilePath);\n                fsdis = fileLink.open(fs);\n                lenToRead = fileLink.getFileStatus(fs).getLen();\n              } else {\n                // a regular hfile\n                fsdis = fs.open(storeFilePath);\n                lenToRead = storeFile.getLen();\n              }\n              int majorVersion = computeMajorVersion(fsdis, lenToRead);\n              if (majorVersion == 1) {\n                hFileV1Set.add(storeFilePath);\n                // return this region path, as it needs to be compacted.\n                return regionDir;\n              }\n              if (majorVersion > 2 || majorVersion < 1) throw new IllegalArgumentException(\n                  \"Incorrect major version: \" + majorVersion);\n            } catch (Exception iae) {\n              corruptedHFiles.add(storeFilePath);\n              LOG.error(\"Got exception while reading trailer for file: \"+ storeFilePath, iae);\n            } finally {\n              if (fsdis != null) fsdis.close();\n            }\n          }\n        }\n        return null;\n      }\n\n      private int computeMajorVersion(FSDataInputStream istream, long fileSize)\n       throws IOException {\n        //read up the last int of the file. Major version is in the last 3 bytes.\n        long seekPoint = fileSize - Bytes.SIZEOF_INT;\n        if (seekPoint < 0)\n          throw new IllegalArgumentException(\"File too small, no major version found\");\n\n        // Read the version from the last int of the file.\n        istream.seek(seekPoint);\n        int version = istream.readInt();\n        // Extract and return the major version\n        return version & 0x00ffffff;\n      }\n    };\n    Future<Path> f = exec.submit(regionCallable);\n    return f;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"public void init() throws IOException {\n    this.rootDir = FSUtils.getRootDir(conf);\n    this.fs = FileSystem.get(conf);\n    Path tmpDataDir = new Path(rootDir, TMP_DATA_DIR);\n    sysNsDir = new Path(tmpDataDir, NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR);\n    defNsDir = new Path(tmpDataDir, NamespaceDescriptor.DEFAULT_NAMESPACE_NAME_STR);\n    baseDirs = new Path[]{rootDir,\n        new Path(rootDir, HConstants.HFILE_ARCHIVE_DIRECTORY),\n        new Path(rootDir, HConstants.HBASE_TEMP_DIRECTORY)};\n    backupDir = new Path(rootDir, HConstants.MIGRATION_NAME);\n  }","id":36503,"modified_method":"public void init() throws IOException {\n    this.rootDir = FSUtils.getRootDir(conf);\n    FSUtils.setFsDefault(getConf(), rootDir);\n    this.fs = FileSystem.get(conf);\n    Path tmpDataDir = new Path(rootDir, TMP_DATA_DIR);\n    sysNsDir = new Path(tmpDataDir, NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR);\n    defNsDir = new Path(tmpDataDir, NamespaceDescriptor.DEFAULT_NAMESPACE_NAME_STR);\n    baseDirs = new Path[]{rootDir,\n        new Path(rootDir, HConstants.HFILE_ARCHIVE_DIRECTORY),\n        new Path(rootDir, HConstants.HBASE_TEMP_DIRECTORY)};\n    backupDir = new Path(rootDir, HConstants.MIGRATION_NAME);\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"private static File untar(final File testdir) throws IOException {\n    // Find the src data under src/test/data\n    final String datafile = \"TestNamespaceUpgrade\";\n    File srcTarFile = new File(\n      System.getProperty(\"project.build.testSourceDirectory\", \"src/test\") +\n      File.separator + \"data\" + File.separator + datafile + \".tgz\");\n    File homedir = new File(testdir.toString());\n    File tgtUntarDir = new File(homedir, \"hbase\");\n    if (tgtUntarDir.exists()) {\n      if (!FileUtil.fullyDelete(tgtUntarDir)) {\n        throw new IOException(\"Failed delete of \" + tgtUntarDir.toString());\n      }\n    }\n    if (!srcTarFile.exists()) {\n      throw new IOException(srcTarFile+\" does not exist\");\n    }\n    LOG.info(\"Untarring \" + srcTarFile + \" into \" + homedir.toString());\n    FileUtil.unTar(srcTarFile, homedir);\n    Assert.assertTrue(tgtUntarDir.exists());\n    return tgtUntarDir;\n  }","id":36504,"modified_method":"static File untar(final File testdir) throws IOException {\n    // Find the src data under src/test/data\n    final String datafile = \"TestNamespaceUpgrade\";\n    File srcTarFile = new File(\n      System.getProperty(\"project.build.testSourceDirectory\", \"src/test\") +\n      File.separator + \"data\" + File.separator + datafile + \".tgz\");\n    File homedir = new File(testdir.toString());\n    File tgtUntarDir = new File(homedir, \"hbase\");\n    if (tgtUntarDir.exists()) {\n      if (!FileUtil.fullyDelete(tgtUntarDir)) {\n        throw new IOException(\"Failed delete of \" + tgtUntarDir.toString());\n      }\n    }\n    if (!srcTarFile.exists()) {\n      throw new IOException(srcTarFile+\" does not exist\");\n    }\n    LOG.info(\"Untarring \" + srcTarFile + \" into \" + homedir.toString());\n    FileUtil.unTar(srcTarFile, homedir);\n    Assert.assertTrue(tgtUntarDir.exists());\n    return tgtUntarDir;\n  }","commit_id":"08247bfe76d98cbeb83060e2d6e4d78dd2cb0f9d","url":"https://github.com/apache/hbase"},{"original_method":"public static BuildFactory newInstanceFactory(final StartParameter startParameter) {\n        if (customFactory != null) {\n            return customFactory.newInstanceFactory(startParameter);\n        }\n        return new BuildFactory() {\n            public Build newInstance(String inMemoryScriptText, File buildResolverDir) {\n                DefaultDependencyManagerFactory dependencyManagerFactory = new DefaultDependencyManagerFactory();\n                ImportsReader importsReader = new ImportsReader(startParameter.getDefaultImportsFile());\n                DefaultScriptProcessor scriptProcessor = new DefaultScriptProcessor(new DefaultScriptHandler());\n                Dag tasksGraph = new Dag();\n                Build build =  new Build(\n                        new RootFinder(),\n                        new SettingsProcessor(\n                                new DefaultSettingsScriptMetaData(),\n                                scriptProcessor,\n                                importsReader,\n                                new SettingsFactory(),\n                                dependencyManagerFactory,\n                                null,\n                                buildResolverDir),\n                        new ProjectsLoader(\n                                new ProjectFactory(\n                                        new TaskFactory(tasksGraph),\n                                        dependencyManagerFactory,\n                                        new BuildScriptProcessor(\n                                                scriptProcessor,\n                                                new DefaultProjectScriptMetaData(),\n                                                importsReader,\n                                                inMemoryScriptText,\n                                                startParameter.getCacheUsage()),\n                                        new PluginRegistry(\n                                                startParameter.getPluginPropertiesFile()),\n                                        startParameter.getBuildFileName(),\n                                        new ProjectRegistry())\n\n                        ),\n                        new BuildConfigurer(\n                                new ProjectDependencies2TaskResolver(),\n                                new ProjectTasksPrettyPrinter()),\n                        new BuildExecuter(tasksGraph\n                        ));\n                if (buildResolverDir == null) {\n                    build.addBuildListener(new DefaultBuildListener());\n                }\n                return build;\n            }\n        };\n    }","id":36505,"modified_method":"public static BuildFactory newInstanceFactory(final StartParameter startParameter) {\n        if (customFactory != null) {\n            return customFactory.newInstanceFactory(startParameter);\n        }\n        return new BuildFactory() {\n            public Build newInstance(String inMemoryScriptText, File buildResolverDir) {\n                DefaultDependencyManagerFactory dependencyManagerFactory = new DefaultDependencyManagerFactory();\n                ImportsReader importsReader = new ImportsReader(startParameter.getDefaultImportsFile());\n                IScriptProcessor scriptProcessor = new DefaultScriptProcessor(new DefaultScriptHandler(), startParameter.getCacheUsage());\n                Dag tasksGraph = new Dag();\n                Build build =  new Build(\n                        new RootFinder(),\n                        new SettingsProcessor(\n                                new DefaultSettingsScriptMetaData(),\n                                scriptProcessor,\n                                importsReader,\n                                new SettingsFactory(),\n                                dependencyManagerFactory,\n                                null,\n                                buildResolverDir),\n                        new ProjectsLoader(\n                                new ProjectFactory(\n                                        new TaskFactory(tasksGraph),\n                                        dependencyManagerFactory,\n                                        new BuildScriptProcessor(\n                                                scriptProcessor,\n                                                new DefaultProjectScriptMetaData(),\n                                                importsReader,\n                                                inMemoryScriptText\n                                        ),\n                                        new PluginRegistry(\n                                                startParameter.getPluginPropertiesFile()),\n                                        startParameter.getBuildFileName(),\n                                        new ProjectRegistry())\n\n                        ),\n                        new BuildConfigurer(\n                                new ProjectDependencies2TaskResolver(),\n                                new ProjectTasksPrettyPrinter()),\n                        new BuildExecuter(tasksGraph\n                        ));\n                if (buildResolverDir == null) {\n                    build.addBuildListener(new DefaultBuildListener());\n                }\n                return build;\n            }\n        };\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"public Script createScript(AbstractProject project) {\n        String imports = importsReader.getImports(project.getRootDir());\n        Script projectScript;\n        if (GUtil.isTrue(inMemoryScriptText)) {\n            projectScript = scriptProcessor.createScriptFromText(inMemoryScriptText, imports, project.getBuildFileCacheName(),\n                    project.getBuildScriptClassLoader(), ProjectScript.class);\n        } else {\n            projectScript = scriptProcessor.createScriptFromFile(\n                    cacheDir(project),\n                    buildFile(project),\n                    imports,\n                    cacheUsage,\n                    project.getBuildScriptClassLoader(),\n                    ProjectScript.class);\n        }\n        projectScriptMetaData.applyMetaData(projectScript, project);\n        return projectScript;\n    }","id":36506,"modified_method":"public Script createScript(AbstractProject project) {\n        Script projectScript;\n        if (GUtil.isTrue(inMemoryScriptText)) {\n            ScriptSource source = new StringScriptSource(\"embedded build script\", inMemoryScriptText, project.getRootDir(), importsReader);\n            projectScript = scriptProcessor.createScript(source, project.getBuildScriptClassLoader(), ProjectScript.class);\n        } else {\n            ScriptSource source = new FileScriptSource(\"build file\", buildFile(project), importsReader);\n            projectScript = scriptProcessor.createScript(source, project.getBuildScriptClassLoader(), ProjectScript.class);\n        }\n        projectScriptMetaData.applyMetaData(projectScript, project);\n        return projectScript;\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"public BuildScriptProcessor(IScriptProcessor scriptProcessor, IProjectScriptMetaData projectScriptMetaData,\n                                ImportsReader importsReader, String inMemoryScriptText, CacheUsage cacheUsage) {\n        this.scriptProcessor = scriptProcessor;\n        this.projectScriptMetaData = projectScriptMetaData;\n        this.importsReader = importsReader;\n        this.inMemoryScriptText = inMemoryScriptText;\n        this.cacheUsage = cacheUsage;\n    }","id":36507,"modified_method":"public BuildScriptProcessor(IScriptProcessor scriptProcessor, IProjectScriptMetaData projectScriptMetaData,\n                                ImportsReader importsReader, String inMemoryScriptText) {\n        this.scriptProcessor = scriptProcessor;\n        this.projectScriptMetaData = projectScriptMetaData;\n        this.importsReader = importsReader;\n        this.inMemoryScriptText = inMemoryScriptText;\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testCreateScriptWithInMemoryTextSet() {\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, TEST_SCRIPT_TEXT, expectedCacheUsage);\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getRootDir();\n                will(returnValue(testProjectDir.getParentFile()));\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                allowing(testProject).getBuildFileCacheName();\n                will(returnValue(TEST_BUILD_FILE_SCRIPT_NAME));\n                allowing(importsReaderMock).getImports(testProjectDir.getParentFile());\n                will(returnValue(TEST_IMPORTS));\n                one(scriptProcessorMock).createScriptFromText(\n                        TEST_SCRIPT_TEXT,\n                        TEST_IMPORTS,\n                        TEST_BUILD_FILE_SCRIPT_NAME,\n                        expectedClassloader,\n                        ProjectScript.class);\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData((ProjectScript) expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","id":36508,"modified_method":"@Test\n    public void testCreateScriptWithInMemoryTextSet() {\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, TEST_SCRIPT_TEXT);\n        final File rootDir = testProjectDir.getParentFile();\n        final ScriptSource expectedScriptSource = new StringScriptSource(\"embedded build script\", TEST_SCRIPT_TEXT, rootDir, importsReaderMock);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getRootDir();\n                will(returnValue(rootDir));\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                one(scriptProcessorMock).createScript(\n                        with(reflectionEquals(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testCreateScriptWithInMemoryTextNotSet() {\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getRootDir();\n                will(returnValue(testProjectDir.getParentFile()));\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                allowing(testProject).getProjectDir();\n                will(returnValue(testProjectDir));\n                allowing(testProject).getBuildFileName();\n                will(returnValue(TEST_BUILD_FILE_NAME));\n                allowing(importsReaderMock).getImports(testProjectDir.getParentFile());\n                will(returnValue(TEST_IMPORTS));\n                one(scriptProcessorMock).createScriptFromFile(\n                        new File(testProjectDir, Project.CACHE_DIR_NAME),\n                        testBuildScriptFile,\n                        TEST_IMPORTS,\n                        CacheUsage.ON,\n                        expectedClassloader,\n                        ProjectScript.class);\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData((ProjectScript) expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","id":36509,"modified_method":"@Test\n    public void testCreateScriptWithInMemoryTextNotSet() {\n        final ScriptSource expectedScriptSource = new FileScriptSource(\"build file\", testBuildScriptFile, importsReaderMock);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                allowing(testProject).getProjectDir();\n                will(returnValue(testProjectDir));\n                allowing(testProject).getBuildFileName();\n                will(returnValue(TEST_BUILD_FILE_NAME));\n                one(scriptProcessorMock).createScript(\n                        with(reflectionEquals(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Before\n    public void setUp() {\n        context.setImposteriser(ClassImposteriser.INSTANCE);\n        testProjectDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testBuildScriptFile = new File(testProjectDir, TEST_BUILD_FILE_NAME);\n        testProject = context.mock(DefaultProject.class);\n        importsReaderMock = context.mock(ImportsReader.class);\n        scriptProcessorMock = context.mock(IScriptProcessor.class);\n        expectedClassloader = new URLClassLoader(new URL[0]);\n        projectScriptMetaDataMock = context.mock(IProjectScriptMetaData.class);\n        expectedScript = new ProjectScript() {\n            public Object run() {\n                return null; \n            }\n        };\n        expectedCacheUsage = CacheUsage.ON;\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, null, expectedCacheUsage);\n    }","id":36510,"modified_method":"@Before\n    public void setUp() {\n        context.setImposteriser(ClassImposteriser.INSTANCE);\n        testProjectDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testBuildScriptFile = new File(testProjectDir, TEST_BUILD_FILE_NAME);\n        testProject = context.mock(DefaultProject.class);\n        importsReaderMock = context.mock(ImportsReader.class);\n        scriptProcessorMock = context.mock(IScriptProcessor.class);\n        expectedClassloader = new URLClassLoader(new URL[0]);\n        projectScriptMetaDataMock = context.mock(IProjectScriptMetaData.class);\n        expectedScript = new ProjectScript() {\n            public Object run() {\n                return null; \n            }\n        };\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, null);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testInit() {\n        assertSame(scriptProcessorMock, buildScriptProcessor.getScriptProcessor());\n        assertSame(projectScriptMetaDataMock, buildScriptProcessor.getProjectScriptMetaData());\n        assertSame(importsReaderMock, buildScriptProcessor.getImportsReader());\n        assertSame(expectedCacheUsage, buildScriptProcessor.getCacheUsage());\n        assertNull(buildScriptProcessor.getInMemoryScriptText());\n    }","id":36511,"modified_method":"@Test\n    public void testInit() {\n        assertSame(scriptProcessorMock, buildScriptProcessor.getScriptProcessor());\n        assertSame(projectScriptMetaDataMock, buildScriptProcessor.getProjectScriptMetaData());\n        assertSame(importsReaderMock, buildScriptProcessor.getImportsReader());\n        assertNull(buildScriptProcessor.getInMemoryScriptText());\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"private void evaluateScript(Script script) {\n        assertTrue(expectedScriptClass.isInstance(script));\n        script.run();\n        assertEquals(TEST_EXPECTED_SYSTEMPROP_VALUE, System.getProperty(TEST_EXPECTED_SYSTEMPROP_KEY));\n    }","id":36512,"modified_method":"private void evaluateScript(Script script) {\n        assertTrue(expectedScriptClass.isInstance(script));\n        assertEquals(script.getClass().getSimpleName(), TEST_SCRIPT_NAME);\n        System.setProperty(TEST_EXPECTED_SYSTEMPROP_KEY, \"not the expected value\");\n        script.run();\n        assertEquals(TEST_EXPECTED_SYSTEMPROP_VALUE, System.getProperty(TEST_EXPECTED_SYSTEMPROP_KEY));\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"public Script createScriptFromText(String scriptText, String scriptAttachement,\n                               String scriptName, ClassLoader classLoader, Class scriptBaseClass) {\n        return scriptHandler.createScript(concatenate(scriptText, scriptAttachement), classLoader,\n                    scriptName, scriptBaseClass);\n    }","id":36513,"modified_method":"public Script createScript(ScriptSource source, ClassLoader classLoader, Class scriptBaseClass) {\n        File sourceFile = source.getSourceFile();\n        if (isCacheable(sourceFile)) {\n            return loadViaCache(source, classLoader, scriptBaseClass);\n        }\n        return loadWithoutCache(source, classLoader, scriptBaseClass);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"public DefaultScriptProcessor(IScriptHandler scriptHandler) {\n        this.scriptHandler = scriptHandler;\n    }","id":36514,"modified_method":"public DefaultScriptProcessor(IScriptHandler scriptHandler, CacheUsage cacheUsage) {\n        this.scriptHandler = scriptHandler;\n        this.cacheUsage = cacheUsage;\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithExistingCachedBuildFile() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                one(scriptHandlerMock).loadFromCache(testScriptFile.lastModified(), testClassLoader, TEST_SCRIPT_NAME, testCacheDir);\n                will(returnValue(expectedScript));\n            }\n        });\n\n        assertSame(expectedScript, scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, TEST_SCRIPT_ATACHEMENT,\n                CacheUsage.ON, testClassLoader, expectedScriptBaseClass));\n    }","id":36515,"modified_method":"@Test\n    public void testWithExistingCachedSourceFile() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                allowing(source).getSourceFile();\n                will(returnValue(testScriptFile));\n\n                allowing(source).getClassName();\n                will(returnValue(TEST_SCRIPT_NAME));\n\n                one(scriptHandlerMock).loadFromCache(testScriptFile.lastModified(), testClassLoader, TEST_SCRIPT_NAME, testCacheDir);\n                will(returnValue(expectedScript));\n            }\n        });\n\n        assertSame(expectedScript, scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass));\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithNonExistingBuildFile() {\n        assertTrue(scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, \"\", CacheUsage.ON, testClassLoader, expectedScriptBaseClass) instanceof EmptyScript);\n    }","id":36516,"modified_method":"@Test\n    public void testWithNonExistingSourceFileAndNoText() {\n        context.checking(new Expectations(){{\n            allowing(source).getSourceFile();\n            will(returnValue(testScriptFile));\n            allowing(source).getText();\n            will(returnValue(null));\n        }});\n\n        assertTrue(scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass) instanceof EmptyScript);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Before\n    public void setUp() {\n        scriptHandlerMock = context.mock(IScriptHandler.class);\n        testClassLoader = new URLClassLoader(new URL[0]);\n        testScriptFileDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testScriptFile = new File(testScriptFileDir, TEST_BUILD_FILE_NAME);\n        testCacheDir = new File(\"scriptCacheDir\");\n        expectedScript = HelperUtil.createTestScript();\n        context.checking(new Expectations() {\n            {\n            }\n        });\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock);\n    }","id":36517,"modified_method":"@Before\n    public void setUp() {\n        scriptHandlerMock = context.mock(IScriptHandler.class);\n        testClassLoader = new URLClassLoader(new URL[0]);\n        testScriptFileDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testScriptFile = new File(testScriptFileDir, TEST_BUILD_FILE_NAME);\n        testCacheDir = new File(testScriptFileDir, Project.CACHE_DIR_NAME);\n        expectedScript = HelperUtil.createTestScript();\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.ON);\n        source = context.mock(ScriptSource.class);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithExistingBuildFileAndCacheOff() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                one(scriptHandlerMock).createScript(\n                        TEST_SCRIPT_TEXT + System.getProperty(\"line.separator\") + TEST_SCRIPT_ATACHEMENT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        expectedScriptBaseClass);\n                will(returnValue(expectedScript));\n            }\n        });\n        assertSame(expectedScript, scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, TEST_SCRIPT_ATACHEMENT,\n                CacheUsage.OFF, testClassLoader, expectedScriptBaseClass));\n    }","id":36518,"modified_method":"@Test\n    public void testWithExistingSourceFileAndCacheOff() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                allowing(source).getSourceFile();\n                will(returnValue(testScriptFile));\n\n                allowing(source).getText();\n                will(returnValue(TEST_SCRIPT_TEXT));\n\n                allowing(source).getClassName();\n                will(returnValue(TEST_SCRIPT_NAME));\n\n                one(scriptHandlerMock).createScript(\n                        TEST_SCRIPT_TEXT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        expectedScriptBaseClass);\n                will(returnValue(expectedScript));\n            }\n        });\n\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.OFF);\n        assertSame(expectedScript, scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass));\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithExistingBuildFileAndRebuildCache() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                one(scriptHandlerMock).writeToCache(\n                        TEST_SCRIPT_TEXT + System.getProperty(\"line.separator\") + TEST_SCRIPT_ATACHEMENT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        testCacheDir,\n                        expectedScriptBaseClass\n                ); will(returnValue(expectedScript));\n            }\n        });\n\n        assertSame(expectedScript, scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, TEST_SCRIPT_ATACHEMENT,\n                CacheUsage.REBUILD, testClassLoader, expectedScriptBaseClass));\n    }","id":36519,"modified_method":"@Test\n    public void testWithExistingBuildFileAndRebuildCache() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                allowing(source).getSourceFile();\n                will(returnValue(testScriptFile));\n\n                allowing(source).getText();\n                will(returnValue(TEST_SCRIPT_TEXT));\n\n                allowing(source).getClassName();\n                will(returnValue(TEST_SCRIPT_NAME));\n\n                one(scriptHandlerMock).writeToCache(\n                        TEST_SCRIPT_TEXT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        testCacheDir,\n                        expectedScriptBaseClass\n                ); will(returnValue(expectedScript));\n            }\n        });\n\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.REBUILD);\n        assertSame(expectedScript, scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass));\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithNonExistingBuildFileAndCacheOff() {\n        assertTrue(scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, \"\", CacheUsage.OFF, testClassLoader, expectedScriptBaseClass) instanceof EmptyScript);\n    }","id":36520,"modified_method":"@Test\n    public void testWithNonExistingSourceFileAndCacheOff() {\n        context.checking(new Expectations() {\n            {\n                allowing(source).getSourceFile();\n                will(returnValue(testScriptFile));\n\n                allowing(source).getText();\n                will(returnValue(\"\"));\n            }\n        });\n\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.OFF);\n        assertTrue(scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass) instanceof EmptyScript);\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWithNonCachedExistingBuildFile() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                one(scriptHandlerMock).loadFromCache(testScriptFile.lastModified(), testClassLoader, TEST_SCRIPT_NAME, testCacheDir);\n                will(returnValue(null));\n                one(scriptHandlerMock).writeToCache(\n                        TEST_SCRIPT_TEXT + System.getProperty(\"line.separator\") + TEST_SCRIPT_ATACHEMENT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        testCacheDir,\n                        expectedScriptBaseClass\n                );\n                will(returnValue(expectedScript));\n            }\n        });\n        assertSame(expectedScript, scriptProcessor.createScriptFromFile(testCacheDir, testScriptFile, TEST_SCRIPT_ATACHEMENT,\n                CacheUsage.ON, testClassLoader, expectedScriptBaseClass));\n    }","id":36521,"modified_method":"@Test\n    public void testWithNonCachedExistingSourceFile() {\n        createBuildScriptFile();\n        context.checking(new Expectations() {\n            {\n                allowing(source).getSourceFile();\n                will(returnValue(testScriptFile));\n\n                allowing(source).getText();\n                will(returnValue(TEST_SCRIPT_TEXT));\n\n                allowing(source).getClassName();\n                will(returnValue(TEST_SCRIPT_NAME));\n\n                one(scriptHandlerMock).loadFromCache(testScriptFile.lastModified(), testClassLoader, TEST_SCRIPT_NAME, testCacheDir);\n                will(returnValue(null));\n\n                one(scriptHandlerMock).writeToCache(\n                        TEST_SCRIPT_TEXT,\n                        testClassLoader,\n                        TEST_SCRIPT_NAME,\n                        testCacheDir,\n                        expectedScriptBaseClass\n                );\n                will(returnValue(expectedScript));\n            }\n        });\n        assertSame(expectedScript, scriptProcessor.createScript(source, testClassLoader, expectedScriptBaseClass));\n    }","commit_id":"bcb3e697881c82f0656be750e7f4039449650508","url":"https://github.com/gradle/gradle"},{"original_method":"private DefaultSettings initWithCurrentDirAsRoot(StartParameter startParameter) {\n        StartParameter startParameterArg = StartParameter.newInstance(startParameter);\n        startParameterArg.setSearchUpwards(false);\n        rootFinder.find(startParameter);\n        setSystemProperties(startParameter.getSystemPropertiesArgs(), rootFinder);\n        DefaultSettings settings = settingsProcessor.createBasicSettings(rootFinder, startParameter);\n        return settings;\n    }","id":36522,"modified_method":"private DefaultSettings initWithCurrentDirAsRoot(StartParameter startParameter) {\n        startParameter.setSearchUpwards(false);\n        rootFinder.find(startParameter);\n        setSystemProperties(startParameter.getSystemPropertiesArgs(), rootFinder);\n        return settingsProcessor.createBasicSettings(rootFinder, startParameter);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"private DefaultSettings init(StartParameter startParameter) {\n        rootFinder.find(startParameter);\n        setSystemProperties(startParameter.getSystemPropertiesArgs(), rootFinder);\n        DefaultSettings settings = settingsProcessor.process(rootFinder, startParameter);\n        return settings;\n    }","id":36523,"modified_method":"private DefaultSettings init(StartParameter startParameter) {\n        rootFinder.find(startParameter);\n        setSystemProperties(startParameter.getSystemPropertiesArgs(), rootFinder);\n        return settingsProcessor.process(rootFinder, startParameter);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public Script createScript(AbstractProject project) {\n        Script projectScript;\n        if (GUtil.isTrue(inMemoryScriptText)) {\n            ScriptSource source = new StringScriptSource(\"embedded build script\", inMemoryScriptText, project.getRootDir(), importsReader);\n            projectScript = scriptProcessor.createScript(source, project.getBuildScriptClassLoader(), ProjectScript.class);\n        } else {\n            ScriptSource source = new FileScriptSource(\"build file\", buildFile(project), importsReader);\n            projectScript = scriptProcessor.createScript(source, project.getBuildScriptClassLoader(), ProjectScript.class);\n        }\n        projectScriptMetaData.applyMetaData(projectScript, project);\n        return projectScript;\n    }","id":36524,"modified_method":"public Script createScript(AbstractProject project) {\n        ScriptSource source;\n        if (GUtil.isTrue(inMemoryScriptText)) {\n            source = new StringScriptSource(\"embedded build script\", inMemoryScriptText);\n        } else {\n            source = new FileScriptSource(\"build file\", buildFile(project));\n        }\n        source = new ImportsScriptSource(source, importsReader, project.getRootDir());\n        Script projectScript = scriptProcessor.createScript(source, project.getBuildScriptClassLoader(), ProjectScript.class);\n        projectScriptMetaData.applyMetaData(projectScript, project);\n        return projectScript;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testCreateScriptWithInMemoryTextSet() {\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, TEST_SCRIPT_TEXT);\n        final File rootDir = testProjectDir.getParentFile();\n        final ScriptSource expectedScriptSource = new StringScriptSource(\"embedded build script\", TEST_SCRIPT_TEXT, rootDir, importsReaderMock);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getRootDir();\n                will(returnValue(rootDir));\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                one(scriptProcessorMock).createScript(\n                        with(reflectionEquals(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","id":36525,"modified_method":"@Test\n    public void testCreateScriptWithInMemoryTextSet() {\n        buildScriptProcessor = new BuildScriptProcessor(scriptProcessorMock, projectScriptMetaDataMock,\n                importsReaderMock, TEST_SCRIPT_TEXT);\n        final File rootDir = testProjectDir.getParentFile();\n        final ScriptSource expectedScriptSource = new StringScriptSource(\"embedded build script\", TEST_SCRIPT_TEXT);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getRootDir();\n                will(returnValue(rootDir));\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                one(scriptProcessorMock).createScript(\n                        with(new ScriptSourceMatcher(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testCreateScriptWithInMemoryTextNotSet() {\n        final ScriptSource expectedScriptSource = new FileScriptSource(\"build file\", testBuildScriptFile, importsReaderMock);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                allowing(testProject).getProjectDir();\n                will(returnValue(testProjectDir));\n                allowing(testProject).getBuildFileName();\n                will(returnValue(TEST_BUILD_FILE_NAME));\n                one(scriptProcessorMock).createScript(\n                        with(reflectionEquals(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","id":36526,"modified_method":"@Test\n    public void testCreateScriptWithInMemoryTextNotSet() {\n        final ScriptSource expectedScriptSource = new FileScriptSource(\"build file\", testBuildScriptFile);\n\n        context.checking(new Expectations() {\n            {\n                allowing(testProject).getBuildScriptClassLoader();\n                will(returnValue(expectedClassloader));\n                allowing(testProject).getRootDir();\n                will(returnValue(testProjectDir));\n                allowing(testProject).getProjectDir();\n                will(returnValue(testProjectDir));\n                allowing(testProject).getBuildFileName();\n                will(returnValue(TEST_BUILD_FILE_NAME));\n                one(scriptProcessorMock).createScript(\n                        with(new ScriptSourceMatcher(expectedScriptSource)),\n                        with(same(expectedClassloader)),\n                        with(equal(ProjectScript.class)));\n                will(returnValue(expectedScript));\n                one(projectScriptMetaDataMock).applyMetaData(expectedScript, testProject);\n            }\n        });\n        buildScriptProcessor.createScript(testProject);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public Script writeToCache(String scriptText, ClassLoader classLoader, String scriptName, File cacheDirParent, Class scriptBaseClass) {\n        Clock clock = new Clock();\n        File cacheDir = new File(cacheDirParent, scriptName);\n        GFileUtils.deleteDirectory(cacheDir);\n        cacheDir.mkdirs();\n        CompilerConfiguration configuration = createBaseCompilerConfiguration(scriptBaseClass);\n        configuration.setTargetDirectory(cacheDir);\n        CompilationUnit unit = new CompilationUnit(configuration, null, new GroovyClassLoader(classLoader));\n        unit.addSource(scriptName, new ByteArrayInputStream(scriptText.getBytes()));\n        try {\n            unit.compile();\n        } catch (CompilationFailedException e) {\n            throw new GradleScriptException(e, scriptName);\n        }\n        logger.info(\"Timing: Writing script to cache at {} took: {}\", cacheDir.getAbsolutePath(), clock.getTime());\n        return loadFromCache(0, classLoader, scriptName, cacheDirParent);\n    }","id":36527,"modified_method":"public Script writeToCache(String scriptText, ClassLoader classLoader, String scriptName, File scriptCacheDir, Class scriptBaseClass) {\n        Clock clock = new Clock();\n        GFileUtils.deleteDirectory(scriptCacheDir);\n        scriptCacheDir.mkdirs();\n        CompilerConfiguration configuration = createBaseCompilerConfiguration(scriptBaseClass);\n        configuration.setTargetDirectory(scriptCacheDir);\n        CompilationUnit unit = new CompilationUnit(configuration, null, new GroovyClassLoader(classLoader));\n        unit.addSource(scriptName, new ByteArrayInputStream(scriptText.getBytes()));\n        try {\n            unit.compile();\n        } catch (CompilationFailedException e) {\n            throw new GradleScriptException(e, scriptName);\n        }\n        logger.info(\"Timing: Writing script to cache at {} took: {}\", scriptCacheDir.getAbsolutePath(), clock.getTime());\n        return loadFromCache(0, classLoader, scriptName, scriptCacheDir);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public Script loadFromCache(long lastModified, ClassLoader classLoader, String scriptName, File cacheDirParent) {\n        if (cacheFile(cacheDirParent, scriptName).lastModified() < lastModified) {\n            return null;\n        }\n        Clock clock = new Clock();\n        Script script;\n        try {\n            URLClassLoader urlClassLoader = new URLClassLoader(WrapUtil.toArray(new File(cacheDirParent, scriptName).toURI().toURL()),\n                    classLoader);\n            script = (Script) urlClassLoader.loadClass(scriptName).newInstance();\n        } catch (ClassNotFoundException e) {\n            logger.debug(\"Class not in cache: \", e);\n            return null;\n        } catch (Exception e) {\n            throw new GradleException(e);\n        }\n        logger.info(\"Timing: Loading script from cache took: {}\", clock.getTime());\n        return script;\n    }","id":36528,"modified_method":"public Script loadFromCache(long lastModified, ClassLoader classLoader, String scriptName, File scriptCacheDir) {\n        if (scriptCacheDir.lastModified() < lastModified) {\n            return null;\n        }\n        Clock clock = new Clock();\n        Script script;\n        try {\n            URLClassLoader urlClassLoader = new URLClassLoader(WrapUtil.toArray(scriptCacheDir.toURI().toURL()),\n                    classLoader);\n            script = (Script) urlClassLoader.loadClass(scriptName).newInstance();\n        } catch (ClassNotFoundException e) {\n            logger.debug(\"Class not in cache: \", e);\n            return null;\n        } catch (Exception e) {\n            throw new GradleException(e);\n        }\n        logger.info(\"Timing: Loading script from cache took: {}\", clock.getTime());\n        return script;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Before\n    public void setUp() throws IOException, ClassNotFoundException {\n        testProjectDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        classLoader = new InputStreamClassLoader();\n        InputStream inputStream = this.getClass().getResourceAsStream(\"/org/gradle/api/ClasspathTester.dat\");\n        classLoader.loadClass(\"org.gradle.api.ClasspathTester\", inputStream);\n        scriptHandler = new DefaultScriptHandler();\n        cacheDir = new File(testProjectDir, Project.CACHE_DIR_NAME);\n        scriptCacheDir = new File(cacheDir, TEST_SCRIPT_NAME);\n        cachedFile = new File(scriptCacheDir, TEST_SCRIPT_NAME + \".class\");\n        testScript = \"System.setProperty('\" + TEST_EXPECTED_SYSTEMPROP_KEY + \"', '\" + TEST_EXPECTED_SYSTEMPROP_VALUE + \"')\";\n        expectedScriptClass = TestBaseScript.class;\n    }","id":36529,"modified_method":"@Before\n    public void setUp() throws IOException, ClassNotFoundException {\n        testProjectDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        classLoader = new InputStreamClassLoader();\n        InputStream inputStream = this.getClass().getResourceAsStream(\"/org/gradle/api/ClasspathTester.dat\");\n        classLoader.loadClass(\"org.gradle.api.ClasspathTester\", inputStream);\n        scriptHandler = new DefaultScriptHandler();\n        scriptCacheDir = new File(testProjectDir, \"cache\");\n        cachedFile = new File(scriptCacheDir, TEST_SCRIPT_NAME + \".class\");\n        testScript = \"System.setProperty('\" + TEST_EXPECTED_SYSTEMPROP_KEY + \"', '\" + TEST_EXPECTED_SYSTEMPROP_VALUE + \"')\";\n        expectedScriptClass = TestBaseScript.class;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test public void testLoadFromCacheWithNonCachedBuildFile() {\n        assertNull(scriptHandler.loadFromCache(0, classLoader, TEST_SCRIPT_NAME, cacheDir));\n    }","id":36530,"modified_method":"@Test public void testLoadFromCacheWithNonCachedBuildFile() {\n        assertNull(scriptHandler.loadFromCache(0, classLoader, TEST_SCRIPT_NAME, scriptCacheDir));\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test(expected = GradleScriptException.class) public void testWriteToCacheWithException() {\n        Script script = scriptHandler.writeToCache(\"new HHHHJSJSJ jsj\", classLoader, TEST_SCRIPT_NAME, cacheDir, expectedScriptClass);\n    }","id":36531,"modified_method":"@Test(expected = GradleScriptException.class) public void testWriteToCacheWithException() {\n        Script script = scriptHandler.writeToCache(\"new HHHHJSJSJ jsj\", classLoader, TEST_SCRIPT_NAME, scriptCacheDir, expectedScriptClass);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test public void testLoadFromCacheWithStaleCache() {\n        scriptHandler.writeToCache(testScript, classLoader, TEST_SCRIPT_NAME, cacheDir, expectedScriptClass);\n        cachedFile.setLastModified(0);\n        assertNull(scriptHandler.loadFromCache(100000, classLoader, TEST_SCRIPT_NAME, cacheDir));\n    }","id":36532,"modified_method":"@Test public void testLoadFromCacheWithStaleCache() {\n        scriptHandler.writeToCache(testScript, classLoader, TEST_SCRIPT_NAME, scriptCacheDir, expectedScriptClass);\n        scriptCacheDir.setLastModified(0);\n        assertNull(scriptHandler.loadFromCache(100000, classLoader, TEST_SCRIPT_NAME, scriptCacheDir));\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void testWriteToCacheAndLoadFromCache() {\n        Script script = scriptHandler.writeToCache(testScript, classLoader, TEST_SCRIPT_NAME, cacheDir, expectedScriptClass);\n        checkCacheDestination();\n        evaluateScript(script);\n        evaluateScript(scriptHandler.loadFromCache(0, classLoader, TEST_SCRIPT_NAME, cacheDir));\n    }","id":36533,"modified_method":"@Test\n    public void testWriteToCacheAndLoadFromCache() {\n        Script script = scriptHandler.writeToCache(testScript, classLoader, TEST_SCRIPT_NAME, scriptCacheDir, expectedScriptClass);\n        checkCacheDestination();\n        evaluateScript(script);\n        evaluateScript(scriptHandler.loadFromCache(0, classLoader, TEST_SCRIPT_NAME, scriptCacheDir));\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"private void checkCacheDestination() {\n        assert scriptCacheDir.isDirectory();\n        assert cachedFile.isFile();\n    }","id":36534,"modified_method":"private void checkCacheDestination() {\n        assertTrue(scriptCacheDir.isDirectory());\n        assertTrue(cachedFile.isFile());\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"private Script loadViaCache(ScriptSource source, ClassLoader classLoader, Class scriptBaseClass) {\n        File sourceFile = source.getSourceFile();\n        File cacheDir = new File(sourceFile.getParentFile(), Project.CACHE_DIR_NAME);\n        String cacheFileName = source.getClassName();\n        if (cacheUsage == CacheUsage.ON) {\n            Script cachedScript = scriptHandler.loadFromCache(sourceFile.lastModified(), classLoader, cacheFileName, cacheDir);\n            if (cachedScript != null) {\n                return cachedScript;\n            }\n        }\n        return scriptHandler.writeToCache(source.getText(), classLoader, cacheFileName, cacheDir, scriptBaseClass);\n    }","id":36535,"modified_method":"private Script loadViaCache(ScriptSource source, ClassLoader classLoader, Class scriptBaseClass) {\n        File sourceFile = source.getSourceFile();\n        File cacheDir = new File(sourceFile.getParentFile(), Project.CACHE_DIR_NAME);\n        File scriptCacheDir = new File(cacheDir, sourceFile.getName());\n        String scriptClassName = source.getClassName();\n        if (cacheUsage == CacheUsage.ON) {\n            Script cachedScript = scriptHandler.loadFromCache(sourceFile.lastModified(), classLoader, scriptClassName, scriptCacheDir);\n            if (cachedScript != null) {\n                return cachedScript;\n            }\n        }\n        return scriptHandler.writeToCache(source.getText(), classLoader, scriptClassName, scriptCacheDir, scriptBaseClass);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"private Script loadWithoutCache(ScriptSource source, ClassLoader classLoader, Class scriptBaseClass) {\n        String text = source.getText();\n        if (!GUtil.isTrue(text)) {\n            return returnEmptyScript();\n        }\n\n        return scriptHandler.createScript(text, classLoader, source.getClassName(), scriptBaseClass);\n    }","id":36536,"modified_method":"private Script loadWithoutCache(ScriptSource source, ClassLoader classLoader, Class scriptBaseClass) {\n        String text = source.getText();\n        if (!GUtil.isTrue(text)) {\n            logger.info(String.format(\"%s is not available. Using an empty script!\", StringUtils.capitalize(source.getDescription())));\n            return new EmptyScript();\n        }\n\n        return scriptHandler.createScript(text, classLoader, source.getClassName(), scriptBaseClass);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Before\n    public void setUp() {\n        scriptHandlerMock = context.mock(IScriptHandler.class);\n        testClassLoader = new URLClassLoader(new URL[0]);\n        testScriptFileDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testScriptFile = new File(testScriptFileDir, TEST_BUILD_FILE_NAME);\n        testCacheDir = new File(testScriptFileDir, Project.CACHE_DIR_NAME);\n        expectedScript = HelperUtil.createTestScript();\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.ON);\n        source = context.mock(ScriptSource.class);\n    }","id":36537,"modified_method":"@Before\n    public void setUp() {\n        scriptHandlerMock = context.mock(IScriptHandler.class);\n        testClassLoader = new URLClassLoader(new URL[0]);\n        testScriptFileDir = HelperUtil.makeNewTestDir(\"projectdir\");\n        testScriptFile = new File(testScriptFileDir, TEST_BUILD_FILE_NAME);\n        testCacheDir = new File(new File(testScriptFileDir, Project.CACHE_DIR_NAME), TEST_BUILD_FILE_NAME);\n        expectedScript = HelperUtil.createTestScript();\n        scriptProcessor = new DefaultScriptProcessor(scriptHandlerMock, CacheUsage.ON);\n        source = context.mock(ScriptSource.class);\n\n        context.checking(new Expectations(){{\n            allowing(source).getDescription();\n            will(returnValue(\"[script source]\"));\n        }});\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public String getText() {\n        if (!sourceFile.exists()) {\n            return null;\n        }\n        String imports = importsReader.getImports(sourceFile.getParentFile());\n        String scriptContent = GFileUtils.readFileToString(sourceFile);\n        return imports + '\\n' + scriptContent;\n    }","id":36538,"modified_method":"public String getText() {\n        if (!sourceFile.exists()) {\n            return null;\n        }\n        return GFileUtils.readFileToString(sourceFile);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public FileScriptSource(String description, File sourceFile, ImportsReader importsReader) {\n        this.description = description;\n        this.sourceFile = sourceFile;\n        this.importsReader = importsReader;\n    }","id":36539,"modified_method":"public FileScriptSource(String description, File sourceFile) {\n        this.description = description;\n        this.sourceFile = sourceFile;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Before\n    public void setUp() {\n        context.setImposteriser(ClassImposteriser.INSTANCE);\n        importsReader = context.mock(ImportsReader.class);\n        testDir = HelperUtil.makeNewTestDir();\n        scriptFile = new File(testDir, \"build.script\");\n        source = new FileScriptSource(\"<file-type>\", scriptFile, importsReader);\n    }","id":36540,"modified_method":"@Before\n    public void setUp() {\n        testDir = HelperUtil.makeNewTestDir();\n        scriptFile = new File(testDir, \"build.script\");\n        source = new FileScriptSource(\"<file-type>\", scriptFile);\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void encodesScriptFileBaseNameToClassName() {\n        assertThat(source.getClassName(), equalTo(\"build_script\"));\n\n        source = new FileScriptSource(\"<file-type>\", new File(testDir, \"name with-some^reserved\\nchars\"), importsReader);\n        assertThat(source.getClassName(), equalTo(\"name_with_some_reserved_chars\"));\n\n        source = new FileScriptSource(\"<file-type>\", new File(testDir, \"123\"), importsReader);\n        assertThat(source.getClassName(), equalTo(\"_123\"));\n    }","id":36541,"modified_method":"@Test\n    public void encodesScriptFileBaseNameToClassName() {\n        assertThat(source.getClassName(), equalTo(\"build_script\"));\n\n        source = new FileScriptSource(\"<file-type>\", new File(testDir, \"name with-some^reserved\\nchars\"));\n        assertThat(source.getClassName(), equalTo(\"name_with_some_reserved_chars\"));\n\n        source = new FileScriptSource(\"<file-type>\", new File(testDir, \"123\"));\n        assertThat(source.getClassName(), equalTo(\"_123\"));\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void loadsScriptFileContentAndPrependsImports() throws IOException {\n        FileUtils.writeStringToFile(scriptFile, \"<content>\");\n\n        context.checking(new Expectations(){{\n            one(importsReader).getImports(testDir);\n            will(returnValue(\"<imports>\"));\n        }});\n\n        assertThat(source.getText(), equalTo(\"<imports>\\n<content>\"));\n    }","id":36542,"modified_method":"@Test\n    public void loadsScriptFileContentWhenFileExists() throws IOException {\n        FileUtils.writeStringToFile(scriptFile, \"<content>\");\n        assertThat(source.getText(), equalTo(\"<content>\"));\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public StringScriptSource(String description, String content, File rootDir, ImportsReader importsReader) {\n        this.description = description;\n        this.content = content;\n        this.rootDir = rootDir;\n        this.importsReader = importsReader;\n    }","id":36543,"modified_method":"public StringScriptSource(String description, String content) {\n        this.description = description;\n        this.content = content;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public String getText() {\n        if (!GUtil.isTrue(content)) {\n            return null;\n        }\n        return importsReader.getImports(rootDir) + '\\n' + content;\n    }","id":36544,"modified_method":"public String getText() {\n        if (!GUtil.isTrue(content)) {\n            return null;\n        }\n        return content;\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"@Test\n    public void hasNoContentWhenScriptContentIsEmpty() {\n        StringScriptSource source = new StringScriptSource(\"<description>\", \"\", rootDir, importsReader);\n\n        assertThat(source.getText(), nullValue());\n    }","id":36545,"modified_method":"@Test\n    public void hasNoContentWhenScriptContentIsEmpty() {\n        StringScriptSource source = new StringScriptSource(\"<description>\", \"\");\n        assertThat(source.getText(), nullValue());\n    }","commit_id":"70d657f281844008dc569d66583659ef9e198cfd","url":"https://github.com/gradle/gradle"},{"original_method":"public SNode newEntry(ExportLabelContext labelContext, SNode exportLabel, SModel exports, SModel outputModel) {\n    SNode rv = SModelOperations.createNewNode(exports, null, SNodeOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, \"jetbrains.mps.lang.generator.structure.ExportEntry\")));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9c8ecccL, \"outputModel\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9c8b6d3L, \"jetbrains.mps.lang.generator.structure.ModelIdentity\").getDeclarationNode()), \"call_create_9032177546942789358\", new Object[]{exports, outputModel}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b63027L, \"inputNode\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b5e358L, \"jetbrains.mps.lang.generator.structure.NodeIdentity\").getDeclarationNode()), \"call_create_9032177546941796951\", new Object[]{exports, labelContext.getInput()}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b63029L, \"outputNode\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b5e358L, \"jetbrains.mps.lang.generator.structure.NodeIdentity\").getDeclarationNode()), \"call_create_9032177546941796951\", new Object[]{exports, labelContext.getOutput()}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b6302cL, \"dataKeeper\"), labelContext.getKeeper());\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getReferenceLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b71703L, \"label\"), exportLabel);\n    return rv;\n  }","id":36546,"modified_method":"public SNode newEntry(ExportLabelContext labelContext, SNode exportLabel, SModel exports, SModel outputModel) {\n    SNode rv = SModelOperations.createNewNode(exports, null, SNodeOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, \"jetbrains.mps.lang.generator.structure.ExportEntry\")));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9c8ecccL, \"outputModel\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9c8b6d3L, \"jetbrains.mps.lang.generator.structure.ModelIdentity\")), \"call_create_9032177546942789358\", new Object[]{exports, outputModel}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b63027L, \"inputNode\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b5e358L, \"jetbrains.mps.lang.generator.structure.NodeIdentity\")), \"call_create_9032177546941796951\", new Object[]{exports, labelContext.getInput()}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b63029L, \"outputNode\"), BehaviorReflection.invokeNonVirtualStatic((Class<SNode>) ((Class) Object.class), SNodeOperations.asSConcept(MetaAdapterFactory.getInterfaceConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b5e358L, \"jetbrains.mps.lang.generator.structure.NodeIdentity\")), \"call_create_9032177546941796951\", new Object[]{exports, labelContext.getOutput()}));\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b6302cL, \"dataKeeper\"), labelContext.getKeeper());\n    SLinkOperations.setTarget(rv, MetaAdapterFactory.getReferenceLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7d58bd9fd9b3d34dL, 0x7d58bd9fd9b71703L, \"label\"), exportLabel);\n    return rv;\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SNode> getTemplateFragments(@NotNull SNode template) {\n    List<SNode> templateFragments = new ArrayList<SNode>();\n    LinkedList<SNode> queue = new LinkedList<SNode>();\n    queue.addFirst(template);\n    final SNode conceptTemplateFragment = MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xff1b29b76cL, \"jetbrains.mps.lang.generator.structure.TemplateFragment\").getDeclarationNode();\n    while (!(queue.isEmpty())) {\n      SNode subnode = queue.removeFirst();\n      // do not look for TemplateFragments in subnode's children as TFs couldn't be nested \n      boolean tfFound = false;\n      for (SNode attr : SLinkOperations.getChildren(subnode, MetaAdapterFactory.getContainmentLink(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x47bf8397520e5942L, \"smodelAttribute\"))) {\n        if (SNodeOperations.getConceptDeclaration(attr) == conceptTemplateFragment) {\n          templateFragments.add((SNode) attr);\n          tfFound = true;\n          break;\n        }\n      }\n      if (!(tfFound)) {\n        queue.addAll(SNodeOperations.getChildren(subnode));\n      }\n    }\n    return templateFragments;\n  }","id":36547,"modified_method":"public static List<SNode> getTemplateFragments(@NotNull SNode template) {\n    List<SNode> templateFragments = new ArrayList<SNode>();\n    LinkedList<SNode> queue = new LinkedList<SNode>();\n    queue.addFirst(template);\n    final SAbstractConcept conceptTemplateFragment = MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xff1b29b76cL, \"jetbrains.mps.lang.generator.structure.TemplateFragment\");\n    while (!(queue.isEmpty())) {\n      SNode subnode = queue.removeFirst();\n      // do not look for TemplateFragments in subnode's children as TFs couldn't be nested \n      boolean tfFound = false;\n      for (SNode attr : SLinkOperations.getChildren(subnode, MetaAdapterFactory.getContainmentLink(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x47bf8397520e5942L, \"smodelAttribute\"))) {\n        if (SConceptOperations.isExactly(SNodeOperations.asSConcept(SNodeOperations.getConcept(attr)), SNodeOperations.asSConcept(conceptTemplateFragment))) {\n          templateFragments.add((SNode) attr);\n          tfFound = true;\n          break;\n        }\n      }\n      if (!(tfFound)) {\n        queue.addAll(SNodeOperations.getChildren(subnode));\n      }\n    }\n    return templateFragments;\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void scan() {\n    for (SNode root : myTemplateModel.getRootNodes()) {\n      if (safeIsInstanceOf(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xff0bea0475L, \"jetbrains.mps.lang.generator.structure.MappingConfiguration\").getDeclarationNode())) {\n        scanControlNode(root);\n      } else if (safeIsInstanceOf(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x10313ed7688L, \"jetbrains.mps.lang.generator.structure.TemplateSwitch\").getDeclarationNode())) {\n        scanControlNode(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x10313ed7688L, \"jetbrains.mps.lang.generator.structure.TemplateSwitch\")));\n      } else if (safeIsInstanceOf(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, \"jetbrains.mps.lang.generator.structure.TemplateDeclaration\").getDeclarationNode())) {\n        scanTemplateContextNode(SLinkOperations.getTarget(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, \"jetbrains.mps.lang.generator.structure.TemplateDeclaration\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, 0xfe43de823bL, \"contentNode\")));\n        for (SNode n : SLinkOperations.getChildren(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, \"jetbrains.mps.lang.generator.structure.TemplateDeclaration\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0xda3dc6e5137e9b1L, 0xda3dc6e5137ea56L, \"parameter\"))) {\n          scanControlNode(n);\n        }\n      } else if (safeIsInstanceOf(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1165958fcd6L, \"jetbrains.mps.lang.generator.structure.MappingScript\").getDeclarationNode())) {\n        scanQueryNode(SLinkOperations.getTarget(SLinkOperations.getTarget(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1165958fcd6L, \"jetbrains.mps.lang.generator.structure.MappingScript\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1165958fcd6L, 0x116596b2f70L, \"codeBlock\")), MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x108bbca0f48L, 0x108bbd29b4aL, \"body\")));\n      } else {\n        if ((safeNodeAttribute(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x11017244494L, \"jetbrains.mps.lang.generator.structure.RootTemplateAnnotation\").getDeclarationNode()) != null)) {\n          scanTemplateNode(root);\n        }\n      }\n    }\n    SetSequence.fromSet(myTargetLanguages).removeElement(\"jetbrains.mps.lang.generator\");\n    if (myTemplateModel.getRootNodes().iterator().hasNext()) {\n      SetSequence.fromSet(myQueryLanguages).addElement(\"jetbrains.mps.lang.generator\");\n    }\n  }","id":36548,"modified_method":"public void scan() {\n    for (SNode root : myTemplateModel.getRootNodes()) {\n      if (safeIsInstanceOf(root, RuleUtil.concept_MappingConfiguration)) {\n        scanControlNode(root);\n      } else if (safeIsInstanceOf(root, RuleUtil.concept_TemplateSwitch)) {\n        scanControlNode(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x10313ed7688L, \"jetbrains.mps.lang.generator.structure.TemplateSwitch\")));\n      } else if (safeIsInstanceOf(root, RuleUtil.concept_TemplateDeclaration)) {\n        scanTemplateContextNode(SLinkOperations.getTarget(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, \"jetbrains.mps.lang.generator.structure.TemplateDeclaration\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, 0xfe43de823bL, \"contentNode\")));\n        for (SNode n : SLinkOperations.getChildren(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0xfe43cb41d0L, \"jetbrains.mps.lang.generator.structure.TemplateDeclaration\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0xda3dc6e5137e9b1L, 0xda3dc6e5137ea56L, \"parameter\"))) {\n          scanControlNode(n);\n        }\n      } else if (safeIsInstanceOf(root, RuleUtil.concept_MappingScript)) {\n        scanQueryNode(SLinkOperations.getTarget(SLinkOperations.getTarget(SNodeOperations.cast(root, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1165958fcd6L, \"jetbrains.mps.lang.generator.structure.MappingScript\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1165958fcd6L, 0x116596b2f70L, \"codeBlock\")), MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x108bbca0f48L, 0x108bbd29b4aL, \"body\")));\n      } else {\n        if ((safeNodeAttribute(root, RuleUtil.concept_RootTemplateAnnotation) != null)) {\n          scanTemplateNode(root);\n        }\n      }\n    }\n    SetSequence.fromSet(myTargetLanguages).removeElement(\"jetbrains.mps.lang.generator\");\n    if (myTemplateModel.getRootNodes().iterator().hasNext()) {\n      SetSequence.fromSet(myQueryLanguages).addElement(\"jetbrains.mps.lang.generator\");\n    }\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void scanTemplateContextNode(SNode node) {\n    if ((node == null)) {\n      return;\n    }\n    if ((safeNodeAttribute(node, concept_TemplateFragment) != null)) {\n      scanTemplateNode(node);\n      return;\n    }\n    for (SNode n : node.getChildren()) {\n      scanTemplateContextNode(n);\n    }\n  }","id":36549,"modified_method":"private void scanTemplateContextNode(SNode node) {\n    if ((node == null)) {\n      return;\n    }\n    if ((safeNodeAttribute(node, RuleUtil.concept_TemplateFragment) != null)) {\n      scanTemplateNode(node);\n      return;\n    }\n    for (SNode n : node.getChildren()) {\n      scanTemplateContextNode(n);\n    }\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static boolean eq_8grp5z_a0a3a02(Object a, Object b) {\n    return (a != null ? a.equals(b) : a == b);\n  }","id":36550,"modified_method":"private static boolean eq_8grp5z_a0a3a11(Object a, Object b) {\n    return (a != null ? a.equals(b) : a == b);\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"private boolean safeIsInstanceOf(SNode node, SNode concept) {\n    // as this class executed before ALL generation process we cannot use isInstanceOf operation here \n    // so isInstanceOf limited only to generator language concepts \n    // todo: extending generator macroses impossible anymore, is it ok? \n    if (node != null && eq_8grp5z_a0a3a02(node.getConcept().getLanguage().getQualifiedName(), \"jetbrains.mps.lang.generator\")) {\n      return SNodeOperations.isInstanceOf(node, SNodeOperations.asSConcept(concept));\n    } else {\n      return false;\n    }\n  }","id":36551,"modified_method":"private boolean safeIsInstanceOf(SNode node, SAbstractConcept concept) {\n    // as this class executed before ALL generation process we cannot use isInstanceOf operation here \n    // so isInstanceOf limited only to generator language concepts \n    // todo: extending generator macroses impossible anymore, is it ok? \n    if (node != null && eq_8grp5z_a0a3a11(node.getConcept().getLanguage().getQualifiedName(), \"jetbrains.mps.lang.generator\")) {\n      return SNodeOperations.isInstanceOf(node, SNodeOperations.asSConcept(concept));\n    } else {\n      return false;\n    }\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected void scanTemplateNode(SNode node) {\n    if ((node == null)) {\n      return;\n    }\n    SetSequence.fromSet(myTargetLanguages).addElement(node.getConcept().getLanguage().getQualifiedName());\n    for (SNode n : node.getChildren()) {\n      if (safeIsInstanceOf(n, concept_IfMacro)) {\n        if (SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x1163aea5803L, \"alternativeConsequence\")) != null) {\n          scanControlNode(SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x1163aea5803L, \"alternativeConsequence\")));\n        }\n        scanQueryNode(SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x10feeff8ac3L, \"conditionFunction\")));\n      } else if (safeIsInstanceOf(n, concept_NodeMacro) || safeIsInstanceOf(n, concept_RootTemplateAnnotation) || safeIsInstanceOf(n, concept_PropertyMacro) || safeIsInstanceOf(n, concept_ReferenceMacro) || safeIsInstanceOf(n, concept_TemplateFragment)) {\n        scanQueryNode(n);\n      } else {\n        scanTemplateNode(n);\n      }\n    }\n  }","id":36552,"modified_method":"protected void scanTemplateNode(SNode node) {\n    if ((node == null)) {\n      return;\n    }\n    SetSequence.fromSet(myTargetLanguages).addElement(node.getConcept().getLanguage().getQualifiedName());\n    for (SNode n : node.getChildren()) {\n      if (safeIsInstanceOf(n, RuleUtil.concept_IfMacro)) {\n        if (SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x1163aea5803L, \"alternativeConsequence\")) != null) {\n          scanControlNode(SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x1163aea5803L, \"alternativeConsequence\")));\n        }\n        scanQueryNode(SLinkOperations.getTarget(SNodeOperations.cast(n, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, \"jetbrains.mps.lang.generator.structure.IfMacro\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x1047c1472deL, 0x10feeff8ac3L, \"conditionFunction\")));\n      } else if (safeIsInstanceOf(n, RuleUtil.concept_NodeMacro) || safeIsInstanceOf(n, RuleUtil.concept_RootTemplateAnnotation) || safeIsInstanceOf(n, RuleUtil.concept_PropertyMacro) || safeIsInstanceOf(n, RuleUtil.concept_ReferenceMacro) || safeIsInstanceOf(n, RuleUtil.concept_TemplateFragment)) {\n        scanQueryNode(n);\n      } else {\n        scanTemplateNode(n);\n      }\n    }\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"private SNode safeNodeAttribute(SNode node, final SNode attribute) {\n    // todo: basically for this we need everything castable to BaseConcept \n    return ListSequence.fromList(SLinkOperations.getChildren(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, \"jetbrains.mps.lang.core.structure.BaseConcept\")), MetaAdapterFactory.getContainmentLink(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x47bf8397520e5942L, \"smodelAttribute\"))).findFirst(new IWhereFilter<SNode>() {\n      public boolean accept(SNode it) {\n        return safeIsInstanceOf(it, attribute);\n      }\n    });\n  }","id":36553,"modified_method":"private SNode safeNodeAttribute(SNode node, final SAbstractConcept attribute) {\n    // todo: basically for this we need everything castable to BaseConcept \n    return ListSequence.fromList(SLinkOperations.getChildren(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, \"jetbrains.mps.lang.core.structure.BaseConcept\")), MetaAdapterFactory.getContainmentLink(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x47bf8397520e5942L, \"smodelAttribute\"))).findFirst(new IWhereFilter<SNode>() {\n      public boolean accept(SNode it) {\n        return safeIsInstanceOf(it, attribute);\n      }\n    });\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void scanControlNode(SNode node) {\n    if (safeIsInstanceOf(node, concept_rc_InlineTemplateWithContext)) {\n      scanTemplateContextNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7b85dded0be53d6cL, \"jetbrains.mps.lang.generator.structure.InlineTemplateWithContext_RuleConsequence\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7b85dded0be53d6cL, 0x7b85dded0be53d6fL, \"contentNode\")));\n    } else if (safeIsInstanceOf(node, concept_rc_InlineTemplate)) {\n      scanTemplateNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x112103dd1e8L, \"jetbrains.mps.lang.generator.structure.InlineTemplate_RuleConsequence\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x112103dd1e8L, 0x112103ebf76L, \"templateNode\")));\n    } else if (safeIsInstanceOf(node, concept_rule_PatternReduction)) {\n      // ignore pattern \n      SetSequence.fromSet(myQueryLanguages).addElement(\"jetbrains.mps.lang.pattern\");\n      scanControlNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, \"jetbrains.mps.lang.generator.structure.PatternReduction_MappingRule\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, 0x190d31fe6a12ebb8L, \"ruleConsequence\")));\n      scanQueryNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, \"jetbrains.mps.lang.generator.structure.PatternReduction_MappingRule\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, 0x190d31fe6a12ebb5L, \"conditionFunction\")));\n    } else {\n      if (\"jetbrains.mps.lang.generator\".equals(node.getConcept().getLanguage().getQualifiedName())) {\n        for (SNode child : node.getChildren()) {\n          scanControlNode(child);\n        }\n      } else {\n        scanQueryNode(node);\n      }\n    }\n  }","id":36554,"modified_method":"private void scanControlNode(SNode node) {\n    if (safeIsInstanceOf(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7b85dded0be53d6cL, \"jetbrains.mps.lang.generator.structure.InlineTemplateWithContext_RuleConsequence\"))) {\n      scanTemplateContextNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7b85dded0be53d6cL, \"jetbrains.mps.lang.generator.structure.InlineTemplateWithContext_RuleConsequence\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x7b85dded0be53d6cL, 0x7b85dded0be53d6fL, \"contentNode\")));\n    } else if (safeIsInstanceOf(node, RuleUtil.concept_InlineTemplate_RuleConsequence)) {\n      scanTemplateNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x112103dd1e8L, \"jetbrains.mps.lang.generator.structure.InlineTemplate_RuleConsequence\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x112103dd1e8L, 0x112103ebf76L, \"templateNode\")));\n    } else if (safeIsInstanceOf(node, RuleUtil.concept_PatternReduction_MappingRule)) {\n      // ignore pattern \n      SetSequence.fromSet(myQueryLanguages).addElement(\"jetbrains.mps.lang.pattern\");\n      scanControlNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, \"jetbrains.mps.lang.generator.structure.PatternReduction_MappingRule\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, 0x190d31fe6a12ebb8L, \"ruleConsequence\")));\n      scanQueryNode(SLinkOperations.getTarget(SNodeOperations.cast(node, MetaAdapterFactory.getConcept(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, \"jetbrains.mps.lang.generator.structure.PatternReduction_MappingRule\")), MetaAdapterFactory.getContainmentLink(0xb401a68083254110L, 0x8fd384331ff25befL, 0x190d31fe6a12ebb4L, 0x190d31fe6a12ebb5L, \"conditionFunction\")));\n    } else {\n      if (\"jetbrains.mps.lang.generator\".equals(node.getConcept().getLanguage().getQualifiedName())) {\n        for (SNode child : node.getChildren()) {\n          scanControlNode(child);\n        }\n      } else {\n        scanQueryNode(node);\n      }\n    }\n  }","commit_id":"87e64aa295a916a227d336e50b10f1c2edf38926","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void concept_hierarchy2(SModel model) {\n    List<SNode> subConcepts = SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, \"jetbrains.mps.baseLanguage.structure.BinaryOperation\").getDeclarationNode(), model);\n    SNode n = null;\n    List<SNode> subConcepts1 = SConceptOperations.getAllSubConcepts(SNodeOperations.getConceptDeclaration(n), model);\n  }","id":36555,"modified_method":"public void concept_hierarchy2(SModel model) {\n    List<SAbstractConcept> subConcepts = SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, \"jetbrains.mps.baseLanguage.structure.BinaryOperation\"), model);\n    SNode n = null;\n    List<SAbstractConcept> subConcepts1 = SConceptOperations.getAllSubConcepts(SNodeOperations.getConcept(n), model);\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void handleAction_impl(SNode parameterObject, SNode node, SModel model, IOperationContext operationContext, EditorContext editorContext) {\n      SNodeOperations.replaceWithAnother(node, SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept(parameterObject), SLinkOperations.getTarget(node, MetaAdapterFactory.getContainmentLink(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e6443a20L, 0x64b1e972e6443a22L, \"expr\"))));\n    }","id":36556,"modified_method":"public void handleAction_impl(SAbstractConcept parameterObject, SNode node, SModel model, IOperationContext operationContext, EditorContext editorContext) {\n      SNodeOperations.replaceWithAnother(node, SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept(parameterObject), SLinkOperations.getTarget(node, MetaAdapterFactory.getContainmentLink(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e6443a20L, 0x64b1e972e6443a22L, \"expr\"))));\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected void handleAction(Object parameterObject, SNode node, SModel model, IOperationContext operationContext, EditorContext editorContext) {\n      this.handleAction_impl((SNode) parameterObject, node, model, operationContext, editorContext);\n    }","id":36557,"modified_method":"protected void handleAction(Object parameterObject, SNode node, SModel model, IOperationContext operationContext, EditorContext editorContext) {\n      this.handleAction_impl((SAbstractConcept) parameterObject, node, model, operationContext, editorContext);\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public List<?> createParameterObjects(SNode node, IOperationContext operationContext, EditorContext editorContext) {\n      List<SNode> result = ListSequence.fromList(new ArrayList<SNode>());\n      for (SNode a : ListSequence.fromList(SConceptOperations.getAllSubConcepts(ListSequence.fromList(ExponentialOperation__BehaviorDescriptor.getAllowedSubstituends_id2D1PBM_bxH0.invoke(SNodeOperations.asSConcept(SNodeOperations.getConceptDeclaration(node)))).first(), SNodeOperations.getModel(node)))) {\n        if (!(SPropertyOperations.getBoolean(a, MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0x403a32c5772c7ec2L, \"abstract\"))) && SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(a), MetaAdapterFactory.getConcept(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e6443a20L, \"jetbrains.mps.baseLanguage.math.structure.ExponentialOperation\"))) {\n          ListSequence.fromList(result).addElement(SNodeOperations.castConcept(a, MetaAdapterFactory.getConcept(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e6443a20L, \"jetbrains.mps.baseLanguage.math.structure.ExponentialOperation\")));\n        }\n      }\n      return result;\n    }","id":36558,"modified_method":"public List<?> createParameterObjects(SNode node, IOperationContext operationContext, EditorContext editorContext) {\n      List<SAbstractConcept> result = ListSequence.fromList(new ArrayList<SAbstractConcept>());\n      for (SAbstractConcept a : ListSequence.fromList(SConceptOperations.getAllSubConcepts(SNodeOperations.asSConcept(ListSequence.fromList(ExponentialOperation__BehaviorDescriptor.getAllowedSubstituends_id2D1PBM_bxH0.invoke(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)))).first()), SNodeOperations.getModel(node)))) {\n        if (!(a.isAbstract()) && SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(a), MetaAdapterFactory.getConcept(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e6443a20L, \"jetbrains.mps.baseLanguage.math.structure.ExponentialOperation\"))) {\n          ListSequence.fromList(result).addElement((SAbstractConcept) a);\n        }\n      }\n      return result;\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"private EditorCell createReadOnlyModelAccessor_spngij_b0(final EditorContext editorContext, final SNode node) {\n    EditorCell_Property editorCell = EditorCell_Property.create(editorContext, new ModelAccessor() {\n      public String getText() {\n        return (String) ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept(SNodeOperations.getConceptDeclaration(node)));\n      }\n      public void setText(String s) {\n      }\n      public boolean isValidText(String s) {\n        return EqualUtil.equals(s, getText());\n      }\n    }, node);\n    editorCell.setAction(CellActionType.DELETE, EmptyCellAction.getInstance());\n    editorCell.setAction(CellActionType.BACKSPACE, EmptyCellAction.getInstance());\n    editorCell.setSubstituteInfo(new CompositeSubstituteInfo(editorContext, new BasicCellContext(node), new SubstituteInfoPartExt[]{new ExponentOperation_Component.ExponentialOperation_generic_cellMenu_spngij_a0b0()}));\n    editorCell.setCellId(\"ReadOnlyModelAccessor_spngij_b0\");\n    Style style = new StyleImpl();\n    style.set(StyleAttributes.SCRIPT_KIND, 0, ScriptKind.SUPERSCRIPT);\n    editorCell.getStyle().putAll(style);\n    deleteUpperIndex.setCellActions(editorCell, node, editorContext);\n    return editorCell;\n  }","id":36559,"modified_method":"private EditorCell createReadOnlyModelAccessor_spngij_b0(final EditorContext editorContext, final SNode node) {\n    EditorCell_Property editorCell = EditorCell_Property.create(editorContext, new ModelAccessor() {\n      public String getText() {\n        return (String) ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept(SNodeOperations.getConcept(node)));\n      }\n      public void setText(String s) {\n      }\n      public boolean isValidText(String s) {\n        return EqualUtil.equals(s, getText());\n      }\n    }, node);\n    editorCell.setAction(CellActionType.DELETE, EmptyCellAction.getInstance());\n    editorCell.setAction(CellActionType.BACKSPACE, EmptyCellAction.getInstance());\n    editorCell.setSubstituteInfo(new CompositeSubstituteInfo(editorContext, new BasicCellContext(node), new SubstituteInfoPartExt[]{new ExponentOperation_Component.ExponentialOperation_generic_cellMenu_spngij_a0b0()}));\n    editorCell.setCellId(\"ReadOnlyModelAccessor_spngij_b0\");\n    Style style = new StyleImpl();\n    style.set(StyleAttributes.SCRIPT_KIND, 0, ScriptKind.SUPERSCRIPT);\n    editorCell.getStyle().putAll(style);\n    deleteUpperIndex.setCellActions(editorCell, node, editorContext);\n    return editorCell;\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public String getMatchingText(Object parameterObject) {\n      return this.getMatchingText_internal((SNode) parameterObject);\n    }","id":36560,"modified_method":"public String getMatchingText(Object parameterObject) {\n      return this.getMatchingText_internal((SAbstractConcept) parameterObject);\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public String getDescriptionText_internal(SNode parameterObject) {\n      return SPropertyOperations.getString(parameterObject, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x10d34f97574L, \"shortDescription\"));\n    }","id":36561,"modified_method":"public String getDescriptionText_internal(SAbstractConcept parameterObject) {\n      return SConceptOperations.shortDescription(parameterObject);\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public String getDescriptionText(Object parameterObject) {\n      return this.getDescriptionText_internal((SNode) parameterObject);\n    }","id":36562,"modified_method":"public String getDescriptionText(Object parameterObject) {\n      return this.getDescriptionText_internal((SAbstractConcept) parameterObject);\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public String getMatchingText_internal(SNode parameterObject) {\n      return (String) ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept(parameterObject));\n    }","id":36563,"modified_method":"public String getMatchingText_internal(SAbstractConcept parameterObject) {\n      return (String) ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept(parameterObject));\n    }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"static void doExecute_id2SpVAIqougW(@NotNull SNode __thisNode__, ConsoleContext context, ConsoleStream console) {\n    if ((SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")) == null)) {\n      Iterable<SNode> constructions = ListSequence.fromList(SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getInterfaceConcept(0x1a8554c4eb8443baL, 0x8c346f0d90c6e75aL, 0x690b986730edd07L, \"jetbrains.mps.lang.smodel.query.structure.HelpProvider\").getDeclarationNode(), ((BaseConsoleTab) context.getOutputWindow()).getConsoleModel())).where(new IWhereFilter<SNode>() {\n        public boolean accept(SNode it) {\n          return SNodeOperations.isInstanceOf(SNodeOperations.asNode(it), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979ba0450L, \"jetbrains.mps.lang.structure.structure.ConceptDeclaration\")) && (boolean) AbstractConceptDeclaration__BehaviorDescriptor.isDefaultSubstitutable_id6spw4TQeyqh.invoke(SNodeOperations.asNode(it));\n        }\n      }).sort(new ISelector<SNode, String>() {\n        public String select(SNode it) {\n          return (String) HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(it));\n        }\n      }, true).alsoSort(new ISelector<SNode, String>() {\n        public String select(SNode it) {\n          return (String) HelpProvider__BehaviorDescriptor.getKind_id64VftqEenf4.invoke(SNodeOperations.asSConcept(it));\n        }\n      }, true).alsoSort(new ISelector<SNode, String>() {\n        public String select(SNode it) {\n          return SPropertyOperations.getString(it, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"));\n        }\n      }, true);\n      Deque<SNode> groupedConstructions = LinkedListSequence.fromLinkedListNew(new LinkedList<SNode>());\n      for (SNode e : Sequence.fromIterable(constructions)) {\n        if (HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(e)) != check_x46ur7_a0a0c0a0a(LinkedListSequence.fromLinkedListNew(groupedConstructions).last())) {\n          LinkedListSequence.fromLinkedListNew(groupedConstructions).addElement(null);\n        }\n        LinkedListSequence.fromLinkedListNew(groupedConstructions).addElement(e);\n      }\n      List<List<String>> resultList = ListSequence.fromListWithValues(new ArrayList<List<String>>(), LinkedListSequence.fromLinkedListNew(groupedConstructions).select(new ISelector<SNode, IListSequence<String>>() {\n        public IListSequence<String> select(SNode it) {\n          try {\n            return ListSequence.fromListAndArray(new ArrayList<String>(), HelpProvider__BehaviorDescriptor.getShortDisplayString_id64VftqEenfn.invoke(SNodeOperations.asSConcept(it)), HelpProvider__BehaviorDescriptor.getShortHelp_idqgIopNa9Hb.invoke(SNodeOperations.asSConcept(it)));\n          } catch (RuntimeException e) {\n            if (LOG.isEnabledFor(Level.WARN)) {\n              LOG.warn(\"Concept \" + INamedConcept__BehaviorDescriptor.getFqName_idhEwIO9y.invoke(SNodeOperations.asNode(it)) + \" implements ConsoleHelpProvider but does not implement getHelp() method\", e);\n            }\n            try {\n              return ListSequence.fromListAndArray(new ArrayList<String>(), HelpProvider__BehaviorDescriptor.getShortDisplayString_id64VftqEenfn.invoke(SNodeOperations.asSConcept(it)), \"\");\n            } catch (RuntimeException e1) {\n              return ListSequence.fromListAndArray(new ArrayList<String>(), SPropertyOperations.getString(it, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\")), \"\");\n            }\n          }\n        }\n      }));\n      List<Integer> maxLens = ListSequence.fromList(new LinkedList<Integer>());\n      for (int i = 0; i < ListSequence.fromList(resultList).select(new ISelector<List<String>, Integer>() {\n        public Integer select(List<String> it) {\n          return ListSequence.fromList(it).count();\n        }\n      }).foldRight(0, new IRightCombinator<Integer, Integer>() {\n        public Integer combine(Integer it, Integer s) {\n          return Math.max(s, it);\n        }\n      }); i++) {\n        int maxLength = 0;\n        for (List<String> row : ListSequence.fromList(resultList)) {\n          int length = check_x46ur7_a0a0b0f0a0a(ListSequence.fromList(row).getElement(i));\n          if (length > maxLength) {\n            maxLength = length;\n          }\n        }\n        ListSequence.fromList(maxLens).addElement(maxLength);\n      }\n\n      StringBuilder output = new StringBuilder();\n      for (List<String> row : ListSequence.fromList(resultList)) {\n        for (int i = 0; i < ListSequence.fromList(maxLens).count(); i++) {\n          output.append((ListSequence.fromList(row).getElement(i) == null ? \"\" : ListSequence.fromList(row).getElement(i)));\n          if (i < ListSequence.fromList(maxLens).count() - 1) {\n            for (int j = check_x46ur7_a0a0b0a0i0a0a(ListSequence.fromList(row).getElement(i)); j < ListSequence.fromList(maxLens).getElement(i) + 2; j++) {\n              output.append(\" \");\n            }\n          }\n        }\n        output.append(\"\\n\");\n      }\n      console.addText(\"Constructions available in console:\\n\\n\");\n      console.addText(output.toString());\n    } else if ((boolean) AbstractConceptDeclaration__BehaviorDescriptor.isSubconceptOf_id73yVtVlWOga.invoke(SLinkOperations.getTarget(SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")), MetaAdapterFactory.getReferenceLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x60279080c2f3b209L, 0x60279080c2f3f8d6L, \"command\")), SNodeOperations.getNode(\"r:935ba0ee-7291-4caa-a807-d76e8fc69391(jetbrains.mps.lang.smodel.query.structure)\", \"473081947981012231\"))) {\n      String helpPage;\n      try {\n        SNode chp = (SNode) (SNode) SLinkOperations.getTarget(SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")), MetaAdapterFactory.getReferenceLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x60279080c2f3b209L, 0x60279080c2f3f8d6L, \"command\"));\n        helpPage = HelpProvider__BehaviorDescriptor.getHelpPage_id64VftqEen2L.invoke(SNodeOperations.asSConcept(chp));\n        String helpHead = HelpProvider__BehaviorDescriptor.getDisplayString_id5YxQmqOFZEf.invoke(SNodeOperations.asSConcept(chp)) + \" : \" + HelpProvider__BehaviorDescriptor.getKind_id64VftqEenf4.invoke(SNodeOperations.asSConcept(chp)) + \"\\n\" + HelpProvider__BehaviorDescriptor.getShortHelp_idqgIopNa9Hb.invoke(SNodeOperations.asSConcept(chp));\n        if ((helpPage != null && helpPage.length() > 0)) {\n          console.addText(helpHead + \"\\n\\n\" + helpPage);\n        } else {\n          console.addText(helpHead);\n        }\n      } catch (RuntimeException ignored) {\n      }\n    }\n  }","id":36564,"modified_method":"static void doExecute_id2SpVAIqougW(@NotNull SNode __thisNode__, ConsoleContext context, ConsoleStream console) {\n    if ((SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")) == null)) {\n      Iterable<SAbstractConcept> constructions = ListSequence.fromList(SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getInterfaceConcept(0x1a8554c4eb8443baL, 0x8c346f0d90c6e75aL, 0x690b986730edd07L, \"jetbrains.mps.lang.smodel.query.structure.HelpProvider\"), context.getOutputWindow().getConsoleModel())).where(new IWhereFilter<SAbstractConcept>() {\n        public boolean accept(SAbstractConcept it) {\n          return SNodeOperations.isInstanceOf(SNodeOperations.asNode(it), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979ba0450L, \"jetbrains.mps.lang.structure.structure.ConceptDeclaration\")) && (boolean) AbstractConceptDeclaration__BehaviorDescriptor.isDefaultSubstitutable_id6spw4TQeyqh.invoke(SNodeOperations.asNode(it));\n        }\n      }).sort(new ISelector<SAbstractConcept, String>() {\n        public String select(SAbstractConcept it) {\n          return (String) HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(it));\n        }\n      }, true).alsoSort(new ISelector<SAbstractConcept, String>() {\n        public String select(SAbstractConcept it) {\n          return (String) HelpProvider__BehaviorDescriptor.getKind_id64VftqEenf4.invoke(SNodeOperations.asSConcept(it));\n        }\n      }, true).alsoSort(new ISelector<SAbstractConcept, String>() {\n        public String select(SAbstractConcept it) {\n          return it.getName();\n        }\n      }, true);\n      Deque<SAbstractConcept> groupedConstructions = LinkedListSequence.fromLinkedListNew(new LinkedList<SAbstractConcept>());\n      for (SAbstractConcept e : Sequence.fromIterable(constructions)) {\n        if (HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(e)) != check_x46ur7_a0a0c0a0a(LinkedListSequence.fromLinkedListNew(groupedConstructions).last())) {\n          LinkedListSequence.fromLinkedListNew(groupedConstructions).addElement(null);\n        }\n        LinkedListSequence.fromLinkedListNew(groupedConstructions).addElement(e);\n      }\n      List<List<String>> resultList = ListSequence.fromListWithValues(new ArrayList<List<String>>(), LinkedListSequence.fromLinkedListNew(groupedConstructions).select(new ISelector<SAbstractConcept, IListSequence<String>>() {\n        public IListSequence<String> select(SAbstractConcept it) {\n          try {\n            return ListSequence.fromListAndArray(new ArrayList<String>(), HelpProvider__BehaviorDescriptor.getShortDisplayString_id64VftqEenfn.invoke(SNodeOperations.asSConcept(it)), HelpProvider__BehaviorDescriptor.getShortHelp_idqgIopNa9Hb.invoke(SNodeOperations.asSConcept(it)));\n          } catch (RuntimeException e) {\n            if (LOG.isEnabledFor(Level.WARN)) {\n              LOG.warn(\"Concept \" + INamedConcept__BehaviorDescriptor.getFqName_idhEwIO9y.invoke(SNodeOperations.asNode(it)) + \" implements ConsoleHelpProvider but does not implement getHelp() method\", e);\n            }\n            try {\n              return ListSequence.fromListAndArray(new ArrayList<String>(), HelpProvider__BehaviorDescriptor.getShortDisplayString_id64VftqEenfn.invoke(SNodeOperations.asSConcept(it)), \"\");\n            } catch (RuntimeException e1) {\n              return ListSequence.fromListAndArray(new ArrayList<String>(), it.getName(), \"\");\n            }\n          }\n        }\n      }));\n      List<Integer> maxLens = ListSequence.fromList(new LinkedList<Integer>());\n      for (int i = 0; i < ListSequence.fromList(resultList).select(new ISelector<List<String>, Integer>() {\n        public Integer select(List<String> it) {\n          return ListSequence.fromList(it).count();\n        }\n      }).foldRight(0, new IRightCombinator<Integer, Integer>() {\n        public Integer combine(Integer it, Integer s) {\n          return Math.max(s, it);\n        }\n      }); i++) {\n        int maxLength = 0;\n        for (List<String> row : ListSequence.fromList(resultList)) {\n          int length = check_x46ur7_a0a0b0f0a0a(ListSequence.fromList(row).getElement(i));\n          if (length > maxLength) {\n            maxLength = length;\n          }\n        }\n        ListSequence.fromList(maxLens).addElement(maxLength);\n      }\n\n      StringBuilder output = new StringBuilder();\n      for (List<String> row : ListSequence.fromList(resultList)) {\n        for (int i = 0; i < ListSequence.fromList(maxLens).count(); i++) {\n          output.append((ListSequence.fromList(row).getElement(i) == null ? \"\" : ListSequence.fromList(row).getElement(i)));\n          if (i < ListSequence.fromList(maxLens).count() - 1) {\n            for (int j = check_x46ur7_a0a0b0a0i0a0a(ListSequence.fromList(row).getElement(i)); j < ListSequence.fromList(maxLens).getElement(i) + 2; j++) {\n              output.append(\" \");\n            }\n          }\n        }\n        output.append(\"\\n\");\n      }\n      console.addText(\"Constructions available in console:\\n\\n\");\n      console.addText(output.toString());\n    } else if ((boolean) AbstractConceptDeclaration__BehaviorDescriptor.isSubconceptOf_id73yVtVlWOga.invoke(SLinkOperations.getTarget(SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")), MetaAdapterFactory.getReferenceLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x60279080c2f3b209L, 0x60279080c2f3f8d6L, \"command\")), SNodeOperations.getNode(\"r:935ba0ee-7291-4caa-a807-d76e8fc69391(jetbrains.mps.lang.smodel.query.structure)\", \"473081947981012231\"))) {\n      String helpPage;\n      try {\n        SAbstractConcept chp = (SAbstractConcept) SNodeOperations.asSConcept(SLinkOperations.getTarget(SLinkOperations.getTarget(__thisNode__, MetaAdapterFactory.getContainmentLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x690b986730a1f80L, 0x60279080c2f4192bL, \"target\")), MetaAdapterFactory.getReferenceLink(0xde1ad86d6e504a02L, 0xb306d4d17f64c375L, 0x60279080c2f3b209L, 0x60279080c2f3f8d6L, \"command\")));\n        helpPage = HelpProvider__BehaviorDescriptor.getHelpPage_id64VftqEen2L.invoke(SNodeOperations.asSConcept(chp));\n        String helpHead = HelpProvider__BehaviorDescriptor.getDisplayString_id5YxQmqOFZEf.invoke(SNodeOperations.asSConcept(chp)) + \" : \" + HelpProvider__BehaviorDescriptor.getKind_id64VftqEenf4.invoke(SNodeOperations.asSConcept(chp)) + \"\\n\" + HelpProvider__BehaviorDescriptor.getShortHelp_idqgIopNa9Hb.invoke(SNodeOperations.asSConcept(chp));\n        if ((helpPage != null && helpPage.length() > 0)) {\n          console.addText(helpHead + \"\\n\\n\" + helpPage);\n        } else {\n          console.addText(helpHead);\n        }\n      } catch (RuntimeException ignored) {\n      }\n    }\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static String check_x46ur7_a0a0c0a0a(SNode checkedDotOperand) {\n    if (null != checkedDotOperand) {\n      return HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(checkedDotOperand));\n    }\n    return null;\n  }","id":36565,"modified_method":"private static String check_x46ur7_a0a0c0a0a(SAbstractConcept checkedDotOperand) {\n    if (null != checkedDotOperand) {\n      return HelpProvider__BehaviorDescriptor.getGroup_id60B$833p9Uj.invoke(SNodeOperations.asSConcept(checkedDotOperand));\n    }\n    return null;\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SubstituteAction> sideTransform_ActionsFactory_Regexp_1177531335474(final IOperationContext operationContext, final SideTransformActionsBuilderContext _context) {\n    List<SubstituteAction> result = ListSequence.fromList(new ArrayList<SubstituteAction>());\n    {\n      Iterable<SNode> parameterObjects = new Computable<Iterable<SNode>>() {\n        public Iterable<SNode> compute() {\n          final List<SNode> excludeList = ListSequence.fromListAndArray(new ArrayList<SNode>(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, \"jetbrains.mps.baseLanguage.regexp.structure.BinaryRegexp\").getDeclarationNode(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c678adL, \"jetbrains.mps.baseLanguage.regexp.structure.UnaryRegexp\").getDeclarationNode(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11178fa2a18L, \"jetbrains.mps.baseLanguage.regexp.structure.PredefinedSymbolClassRegexp\").getDeclarationNode(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x1117f58ea2aL, \"jetbrains.mps.baseLanguage.regexp.structure.RegexpDeclarationReferenceRegexp\").getDeclarationNode(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x1118e0a1c55L, \"jetbrains.mps.baseLanguage.regexp.structure.MatchVariableReferenceRegexp\").getDeclarationNode());\n          List<SNode> regexps = SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), _context.getModel());\n          return ListSequence.fromList(regexps).where(new IWhereFilter<SNode>() {\n            public boolean accept(SNode it) {\n              for (SNode exclude : ListSequence.fromList(excludeList)) {\n                if (SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(it), SNodeOperations.asSConcept(exclude))) {\n                  return false;\n                }\n              }\n              return true;\n            }\n          }).toListSequence();\n        }\n      }.compute();\n      if (parameterObjects != null) {\n        for (final SNode item : parameterObjects) {\n          ListSequence.fromList(result).addElement(new AbstractSideTransformHintSubstituteAction(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), item, _context.getSourceNode()) {\n            public SNode doSubstitute(@Nullable final EditorContext editorContext, String pattern) {\n              SNode newRegexp = SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept((item)), null);\n              SNode result = SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174bc30e7L, \"jetbrains.mps.baseLanguage.regexp.structure.SeqRegexp\")), null);\n              SNodeOperations.replaceWithAnother(_context.getSourceNode(), result);\n              SLinkOperations.setTarget(result, MetaAdapterFactory.getContainmentLink(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, 0x11174c59241L, \"left\"), _context.getSourceNode());\n              SLinkOperations.setTarget(result, MetaAdapterFactory.getContainmentLink(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, 0x11174c5a26fL, \"right\"), newRegexp);\n              return newRegexp;\n            }\n            @Override\n            protected boolean isEnabled() {\n              SNode sourceNode = getSourceNode();\n              SNode parent = SNodeOperations.getParent(sourceNode);\n              SNode containingLink = SNodeOperations.getContainingLinkDeclaration(sourceNode);\n              return parent == null || containingLink == null || (ModelConstraints.canBeParent(parent, MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), containingLink, null, null) && ModelConstraints.canBeAncestor(parent, null, MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), null));\n            }\n          });\n        }\n      }\n    }\n    return result;\n  }","id":36566,"modified_method":"public static List<SubstituteAction> sideTransform_ActionsFactory_Regexp_1177531335474(final IOperationContext operationContext, final SideTransformActionsBuilderContext _context) {\n    List<SubstituteAction> result = ListSequence.fromList(new ArrayList<SubstituteAction>());\n    {\n      Iterable<SAbstractConcept> parameterObjects = new Computable<Iterable<SAbstractConcept>>() {\n        public Iterable<SAbstractConcept> compute() {\n          final List<SAbstractConcept> excludeList = ListSequence.fromListAndArray(new ArrayList<SAbstractConcept>(), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, \"jetbrains.mps.baseLanguage.regexp.structure.BinaryRegexp\"), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c678adL, \"jetbrains.mps.baseLanguage.regexp.structure.UnaryRegexp\"), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11178fa2a18L, \"jetbrains.mps.baseLanguage.regexp.structure.PredefinedSymbolClassRegexp\"), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x1117f58ea2aL, \"jetbrains.mps.baseLanguage.regexp.structure.RegexpDeclarationReferenceRegexp\"), MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x1118e0a1c55L, \"jetbrains.mps.baseLanguage.regexp.structure.MatchVariableReferenceRegexp\"));\n          List<SAbstractConcept> regexps = SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\"), _context.getModel());\n          return ListSequence.fromList(regexps).where(new IWhereFilter<SAbstractConcept>() {\n            public boolean accept(SAbstractConcept it) {\n              for (SAbstractConcept exclude : ListSequence.fromList(excludeList)) {\n                if (SConceptOperations.isSubConceptOf(SNodeOperations.asSConcept(it), SNodeOperations.asSConcept(exclude))) {\n                  return false;\n                }\n              }\n              return true;\n            }\n          }).toListSequence();\n        }\n      }.compute();\n      if (parameterObjects != null) {\n        for (final SAbstractConcept item : parameterObjects) {\n          ListSequence.fromList(result).addElement(new AbstractSideTransformHintSubstituteAction(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), item, _context.getSourceNode()) {\n            public SNode doSubstitute(@Nullable final EditorContext editorContext, String pattern) {\n              SNode newRegexp = SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept((item)), null);\n              SNode result = SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept(MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174bc30e7L, \"jetbrains.mps.baseLanguage.regexp.structure.SeqRegexp\")), null);\n              SNodeOperations.replaceWithAnother(_context.getSourceNode(), result);\n              SLinkOperations.setTarget(result, MetaAdapterFactory.getContainmentLink(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, 0x11174c59241L, \"left\"), _context.getSourceNode());\n              SLinkOperations.setTarget(result, MetaAdapterFactory.getContainmentLink(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174c56bf9L, 0x11174c5a26fL, \"right\"), newRegexp);\n              return newRegexp;\n            }\n            @Override\n            protected boolean isEnabled() {\n              SNode sourceNode = getSourceNode();\n              SNode parent = SNodeOperations.getParent(sourceNode);\n              SNode containingLink = SNodeOperations.getContainingLinkDeclaration(sourceNode);\n              return parent == null || containingLink == null || (ModelConstraints.canBeParent(parent, MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), containingLink, null, null) && ModelConstraints.canBeAncestor(parent, null, MetaAdapterFactory.getConcept(0xdaafa647f1f74b0bL, 0xb09669cd7c8408c0L, 0x11174a06efdL, \"jetbrains.mps.baseLanguage.regexp.structure.Regexp\").getDeclarationNode(), null));\n            }\n          });\n        }\n      }\n    }\n    return result;\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static List<SubstituteAction> sideTransform_ActionsFactory_Expression_7255837154369265165(final IOperationContext operationContext, final SideTransformActionsBuilderContext _context) {\n    List<SubstituteAction> result = ListSequence.fromList(new ArrayList<SubstituteAction>());\n    {\n      Iterable<SNode> parameterObjects = new Computable<Iterable<SNode>>() {\n        public Iterable<SNode> compute() {\n          List<SNode> result = ListSequence.fromList(new ArrayList<SNode>());\n          for (SNode a : ListSequence.fromList(SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e647ad7dL, \"jetbrains.mps.baseLanguage.math.structure.MatrixExponentialOperation\").getDeclarationNode(), _context.getModel()))) {\n            if (!(SPropertyOperations.getBoolean(a, MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0x403a32c5772c7ec2L, \"abstract\")))) {\n              ListSequence.fromList(result).addElement(a);\n            }\n          }\n          return result;\n        }\n      }.compute();\n      if (parameterObjects != null) {\n        for (final SNode item : parameterObjects) {\n          ListSequence.fromList(result).addElement(new AbstractSideTransformHintSubstituteAction(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), item, _context.getSourceNode()) {\n            public SNode doSubstitute(@Nullable final EditorContext editorContext, String pattern) {\n              return SNodeOperations.replaceWithAnother(_context.getSourceNode(), SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept((item)), _context.getSourceNode()));\n            }\n            public String getMatchingText(String pattern) {\n              return \"^\" + ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept((item)));\n            }\n            public String getVisibleMatchingText(String pattern) {\n              return getMatchingText(pattern);\n            }\n            public String getDescriptionText(String pattern) {\n              return SPropertyOperations.getString((item), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x10802efe25aL, 0x10d34f97574L, \"shortDescription\"));\n            }\n            @Override\n            protected boolean isEnabled() {\n              SNode sourceNode = getSourceNode();\n              SNode parent = SNodeOperations.getParent(sourceNode);\n              SNode containingLink = SNodeOperations.getContainingLinkDeclaration(sourceNode);\n              return parent == null || containingLink == null || (ModelConstraints.canBeParent(parent, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), containingLink, null, null) && ModelConstraints.canBeAncestor(parent, null, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), null));\n            }\n          });\n        }\n      }\n    }\n    return result;\n  }","id":36567,"modified_method":"public static List<SubstituteAction> sideTransform_ActionsFactory_Expression_7255837154369265165(final IOperationContext operationContext, final SideTransformActionsBuilderContext _context) {\n    List<SubstituteAction> result = ListSequence.fromList(new ArrayList<SubstituteAction>());\n    {\n      Iterable<SAbstractConcept> parameterObjects = new Computable<Iterable<SAbstractConcept>>() {\n        public Iterable<SAbstractConcept> compute() {\n          List<SAbstractConcept> result = ListSequence.fromList(new ArrayList<SAbstractConcept>());\n          for (SAbstractConcept a : ListSequence.fromList(SConceptOperations.getAllSubConcepts(MetaAdapterFactory.getConcept(0x3304fc6e7c6b401eL, 0xa016b944934bb21fL, 0x64b1e972e647ad7dL, \"jetbrains.mps.baseLanguage.math.structure.MatrixExponentialOperation\"), _context.getModel()))) {\n            if (!(a.isAbstract())) {\n              ListSequence.fromList(result).addElement(a);\n            }\n          }\n          return result;\n        }\n      }.compute();\n      if (parameterObjects != null) {\n        for (final SAbstractConcept item : parameterObjects) {\n          ListSequence.fromList(result).addElement(new AbstractSideTransformHintSubstituteAction(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), item, _context.getSourceNode()) {\n            public SNode doSubstitute(@Nullable final EditorContext editorContext, String pattern) {\n              return SNodeOperations.replaceWithAnother(_context.getSourceNode(), SNodeFactoryOperations.createNewNode(SNodeFactoryOperations.asInstanceConcept((item)), _context.getSourceNode()));\n            }\n            public String getMatchingText(String pattern) {\n              return \"^\" + ExponentialOperation__BehaviorDescriptor.getOperationSymbol_id1653mnvAgnB.invoke(SNodeOperations.asSConcept((item)));\n            }\n            public String getVisibleMatchingText(String pattern) {\n              return getMatchingText(pattern);\n            }\n            public String getDescriptionText(String pattern) {\n              return SConceptOperations.shortDescription((item));\n            }\n            @Override\n            protected boolean isEnabled() {\n              SNode sourceNode = getSourceNode();\n              SNode parent = SNodeOperations.getParent(sourceNode);\n              SNode containingLink = SNodeOperations.getContainingLinkDeclaration(sourceNode);\n              return parent == null || containingLink == null || (ModelConstraints.canBeParent(parent, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), containingLink, null, null) && ModelConstraints.canBeAncestor(parent, null, MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37f506fL, \"jetbrains.mps.baseLanguage.structure.Expression\").getDeclarationNode(), null));\n            }\n          });\n        }\n      }\n    }\n    return result;\n  }","commit_id":"aa75ebdfe5a9684b290475c10d3eedafc7dd703d","url":"https://github.com/JetBrains/MPS"},{"original_method":"public ClusterAllocationExplanation(ShardId shard, boolean primary, @Nullable String assignedNodeId,\n                                        UnassignedInfo unassignedInfo, Map<DiscoveryNode, Decision> nodeToDecision,\n                                        Map<DiscoveryNode, Float> nodeToWeight, long remainingDelayNanos,\n                                        List<IndicesShardStoresResponse.StoreStatus> shardStores, Set<String> activeAllocationIds) {\n        this.shard = shard;\n        this.primary = primary;\n        this.assignedNodeId = assignedNodeId;\n        this.unassignedInfo = unassignedInfo;\n        this.remainingDelayNanos = remainingDelayNanos;\n        this.activeAllocationIds = activeAllocationIds;\n        final Map<DiscoveryNode, Decision> nodeDecisions = nodeToDecision == null ? Collections.emptyMap() : nodeToDecision;\n        final Map<DiscoveryNode, Float> nodeWeights = nodeToWeight == null ? Collections.emptyMap() : nodeToWeight;\n        assert nodeDecisions.size() == nodeWeights.size() : \"decision and weight list should be the same size\";\n        final Map<DiscoveryNode, IndicesShardStoresResponse.StoreStatus> storeStatuses = calculateStoreStatuses(shardStores);\n\n        this.nodeExplanations = new HashMap<>(nodeDecisions.size());\n        for (Map.Entry<DiscoveryNode, Decision> entry : nodeDecisions.entrySet()) {\n            final DiscoveryNode node = entry.getKey();\n            final Decision decision = entry.getValue();\n            final NodeExplanation nodeExplanation = calculateNodeExplanation(node, decision, nodeWeights.get(node),\n                    storeStatuses.get(node), assignedNodeId, activeAllocationIds);\n            nodeExplanations.put(node, nodeExplanation);\n        }\n    }","id":36568,"modified_method":"public ClusterAllocationExplanation(ShardId shard, boolean primary, @Nullable String assignedNodeId, long remainingDelayMillis,\n                                        UnassignedInfo unassignedInfo, Map<DiscoveryNode, NodeExplanation> nodeExplanations) {\n        this.shard = shard;\n        this.primary = primary;\n        this.assignedNodeId = assignedNodeId;\n        this.unassignedInfo = unassignedInfo;\n        this.remainingDelayMillis = remainingDelayMillis;\n        this.nodeExplanations = nodeExplanations;\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(); {\n            builder.startObject(\"shard\"); {\n                builder.field(\"index\", shard.getIndexName());\n                builder.field(\"index_uuid\", shard.getIndex().getUUID());\n                builder.field(\"id\", shard.getId());\n                builder.field(\"primary\", primary);\n            }\n            builder.endObject(); // end shard\n            builder.field(\"assigned\", this.assignedNodeId != null);\n            // If assigned, show the node id of the node it's assigned to\n            if (assignedNodeId != null) {\n                builder.field(\"assigned_node_id\", this.assignedNodeId);\n            }\n            // If we have unassigned info, show that\n            if (unassignedInfo != null) {\n                unassignedInfo.toXContent(builder, params);\n                long delay = unassignedInfo.getLastComputedLeftDelayNanos();\n                builder.field(\"allocation_delay\", TimeValue.timeValueNanos(delay));\n                builder.field(\"allocation_delay_ms\", TimeValue.timeValueNanos(delay).millis());\n                builder.field(\"remaining_delay\", TimeValue.timeValueNanos(remainingDelayNanos));\n                builder.field(\"remaining_delay_ms\", TimeValue.timeValueNanos(remainingDelayNanos).millis());\n            }\n            builder.startObject(\"nodes\");\n            for (NodeExplanation explanation : nodeExplanations.values()) {\n                explanation.toXContent(builder, params);\n            }\n            builder.endObject(); // end nodes\n        }\n        builder.endObject(); // end wrapping object\n        return builder;\n    }","id":36569,"modified_method":"public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(); {\n            builder.startObject(\"shard\"); {\n                builder.field(\"index\", shard.getIndexName());\n                builder.field(\"index_uuid\", shard.getIndex().getUUID());\n                builder.field(\"id\", shard.getId());\n                builder.field(\"primary\", primary);\n            }\n            builder.endObject(); // end shard\n            builder.field(\"assigned\", this.assignedNodeId != null);\n            // If assigned, show the node id of the node it's assigned to\n            if (assignedNodeId != null) {\n                builder.field(\"assigned_node_id\", this.assignedNodeId);\n            }\n            // If we have unassigned info, show that\n            if (unassignedInfo != null) {\n                unassignedInfo.toXContent(builder, params);\n                long delay = unassignedInfo.getLastComputedLeftDelayNanos();\n                builder.timeValueField(\"allocation_delay_ms\", \"allocation_delay\", TimeValue.timeValueNanos(delay));\n                builder.timeValueField(\"remaining_delay_ms\", \"remaining_delay\", TimeValue.timeValueMillis(remainingDelayMillis));\n            }\n            builder.startObject(\"nodes\");\n            for (NodeExplanation explanation : nodeExplanations.values()) {\n                explanation.toXContent(builder, params);\n            }\n            builder.endObject(); // end nodes\n        }\n        builder.endObject(); // end wrapping object\n        return builder;\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/** Return the remaining allocation delay for this shard in nanoseconds */\n    public long getRemainingDelayNanos() {\n        return this.remainingDelayNanos;\n    }","id":36570,"modified_method":"/** Return the remaining allocation delay for this shard in nanoseconds */\n    public long getRemainingDelayMillis() {\n        return this.remainingDelayMillis;\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public ClusterAllocationExplanation(StreamInput in) throws IOException {\n        this.shard = ShardId.readShardId(in);\n        this.primary = in.readBoolean();\n        this.assignedNodeId = in.readOptionalString();\n        this.unassignedInfo = in.readOptionalWriteable(UnassignedInfo::new);\n        this.remainingDelayNanos = in.readVLong();\n\n        int allocIdSize = in.readVInt();\n        Set<String> activeIds = new HashSet<>(allocIdSize);\n        for (int i = 0; i < allocIdSize; i++) {\n            activeIds.add(in.readString());\n        }\n        this.activeAllocationIds = activeIds;\n\n        int mapSize = in.readVInt();\n        Map<DiscoveryNode, NodeExplanation> nodeToExplanation = new HashMap<>(mapSize);\n        for (int i = 0; i < mapSize; i++) {\n            NodeExplanation nodeExplanation = new NodeExplanation(in);\n            nodeToExplanation.put(nodeExplanation.getNode(), nodeExplanation);\n        }\n        this.nodeExplanations = nodeToExplanation;\n    }","id":36571,"modified_method":"public ClusterAllocationExplanation(StreamInput in) throws IOException {\n        this.shard = ShardId.readShardId(in);\n        this.primary = in.readBoolean();\n        this.assignedNodeId = in.readOptionalString();\n        this.unassignedInfo = in.readOptionalWriteable(UnassignedInfo::new);\n        this.remainingDelayMillis = in.readVLong();\n\n        int mapSize = in.readVInt();\n        Map<DiscoveryNode, NodeExplanation> nodeToExplanation = new HashMap<>(mapSize);\n        for (int i = 0; i < mapSize; i++) {\n            NodeExplanation nodeExplanation = new NodeExplanation(in);\n            nodeToExplanation.put(nodeExplanation.getNode(), nodeExplanation);\n        }\n        this.nodeExplanations = nodeToExplanation;\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        this.getShard().writeTo(out);\n        out.writeBoolean(this.isPrimary());\n        out.writeOptionalString(this.getAssignedNodeId());\n        out.writeOptionalWriteable(this.getUnassignedInfo());\n        out.writeVLong(remainingDelayNanos);\n        out.writeVInt(activeAllocationIds.size());\n        for (String id : activeAllocationIds) {\n            out.writeString(id);\n        }\n\n        out.writeVInt(this.nodeExplanations.size());\n        for (NodeExplanation explanation : this.nodeExplanations.values()) {\n            explanation.writeTo(out);\n        }\n    }","id":36572,"modified_method":"@Override\n    public void writeTo(StreamOutput out) throws IOException {\n        this.getShard().writeTo(out);\n        out.writeBoolean(this.isPrimary());\n        out.writeOptionalString(this.getAssignedNodeId());\n        out.writeOptionalWriteable(this.getUnassignedInfo());\n        out.writeVLong(remainingDelayMillis);\n\n        out.writeVInt(this.nodeExplanations.size());\n        for (NodeExplanation explanation : this.nodeExplanations.values()) {\n            explanation.writeTo(out);\n        }\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * For the given {@code ShardRouting}, return the explanation of the allocation for that shard on all nodes. If {@code\n     * includeYesDecisions} is true, returns all decisions, otherwise returns only 'NO' and 'THROTTLE' decisions.\n     */\n    public static ClusterAllocationExplanation explainShard(ShardRouting shard, RoutingAllocation allocation, RoutingNodes routingNodes,\n                                                            boolean includeYesDecisions, ShardsAllocator shardAllocator,\n                                                            List<IndicesShardStoresResponse.StoreStatus> shardStores) {\n        // don't short circuit deciders, we want a full explanation\n        allocation.debugDecision(true);\n        // get the existing unassigned info if available\n        UnassignedInfo ui = shard.unassignedInfo();\n\n        RoutingNodesIterator iter = routingNodes.nodes();\n        Map<DiscoveryNode, Decision> nodeToDecision = new HashMap<>();\n        while (iter.hasNext()) {\n            RoutingNode node = iter.next();\n            DiscoveryNode discoNode = node.node();\n            if (discoNode.isDataNode()) {\n                Decision d = tryShardOnNode(shard, node, allocation, includeYesDecisions);\n                nodeToDecision.put(discoNode, d);\n            }\n        }\n        long remainingDelayNanos = 0;\n        final MetaData metadata = allocation.metaData();\n        final IndexMetaData indexMetaData = metadata.index(shard.index());\n        if (ui != null) {\n            final Settings indexSettings = indexMetaData.getSettings();\n            remainingDelayNanos = ui.getRemainingDelay(System.nanoTime(), metadata.settings(), indexSettings);\n        }\n        return new ClusterAllocationExplanation(shard.shardId(), shard.primary(), shard.currentNodeId(), ui, nodeToDecision,\n                shardAllocator.weighShard(allocation, shard), remainingDelayNanos, shardStores,\n                indexMetaData.activeAllocationIds(shard.getId()));\n    }","id":36573,"modified_method":"/**\n     * For the given {@code ShardRouting}, return the explanation of the allocation for that shard on all nodes. If {@code\n     * includeYesDecisions} is true, returns all decisions, otherwise returns only 'NO' and 'THROTTLE' decisions.\n     */\n    public static ClusterAllocationExplanation explainShard(ShardRouting shard, RoutingAllocation allocation, RoutingNodes routingNodes,\n                                                            boolean includeYesDecisions, ShardsAllocator shardAllocator,\n                                                            List<IndicesShardStoresResponse.StoreStatus> shardStores) {\n        // don't short circuit deciders, we want a full explanation\n        allocation.debugDecision(true);\n        // get the existing unassigned info if available\n        UnassignedInfo ui = shard.unassignedInfo();\n\n        RoutingNodesIterator iter = routingNodes.nodes();\n        Map<DiscoveryNode, Decision> nodeToDecision = new HashMap<>();\n        while (iter.hasNext()) {\n            RoutingNode node = iter.next();\n            DiscoveryNode discoNode = node.node();\n            if (discoNode.isDataNode()) {\n                Decision d = tryShardOnNode(shard, node, allocation, includeYesDecisions);\n                nodeToDecision.put(discoNode, d);\n            }\n        }\n        long remainingDelayMillis = 0;\n        final MetaData metadata = allocation.metaData();\n        final IndexMetaData indexMetaData = metadata.index(shard.index());\n        if (ui != null) {\n            final Settings indexSettings = indexMetaData.getSettings();\n            long remainingDelayNanos = ui.getRemainingDelay(System.nanoTime(), metadata.settings(), indexSettings);\n            remainingDelayMillis = TimeValue.timeValueNanos(remainingDelayNanos).millis();\n        }\n\n        // Calculate weights for each of the nodes\n        Map<DiscoveryNode, Float> weights = shardAllocator.weighShard(allocation, shard);\n\n        Map<DiscoveryNode, IndicesShardStoresResponse.StoreStatus> nodeToStatus = new HashMap<>(shardStores.size());\n        for (IndicesShardStoresResponse.StoreStatus status : shardStores) {\n            nodeToStatus.put(status.getNode(), status);\n        }\n\n        Map<DiscoveryNode, NodeExplanation> explanations = new HashMap<>(shardStores.size());\n        for (Map.Entry<DiscoveryNode, Decision> entry : nodeToDecision.entrySet()) {\n            DiscoveryNode node = entry.getKey();\n            Decision decision = entry.getValue();\n            Float weight = weights.get(node);\n            IndicesShardStoresResponse.StoreStatus storeStatus = nodeToStatus.get(node);\n            NodeExplanation nodeExplanation = calculateNodeExplanation(shard, indexMetaData, node, decision, weight,\n                    storeStatus, shard.currentNodeId(), indexMetaData.activeAllocationIds(shard.getId()));\n            explanations.put(node, nodeExplanation);\n        }\n        return new ClusterAllocationExplanation(shard.shardId(), shard.primary(),\n                shard.currentNodeId(), remainingDelayMillis, ui, explanations);\n    }","commit_id":"49c310691ced7da02b3c6adaaebcc52814976099","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public static ShardRouting randomChange(ShardRouting shardRouting, String[] nodes) {\n        switch (randomInt(2)) {\n            case 0:\n                if (shardRouting.unassigned() == false) {\n                    shardRouting = shardRouting.moveToUnassigned(new UnassignedInfo(randomReason(), randomAsciiOfLength(10)));\n                } else if (shardRouting.unassignedInfo() != null) {\n                    shardRouting = shardRouting.updateUnassignedInfo(new UnassignedInfo(randomReason(), randomAsciiOfLength(10)));\n                }\n                break;\n            case 1:\n                if (shardRouting.unassigned()) {\n                    shardRouting = shardRouting.initialize(randomFrom(nodes), null, -1);\n                }\n                break;\n            case 2:\n                if (shardRouting.initializing()) {\n                    shardRouting = shardRouting.moveToStarted();\n                }\n                break;\n        }\n        return shardRouting;\n    }","id":36574,"modified_method":"public static ShardRouting randomChange(ShardRouting shardRouting, String[] nodes) {\n        switch (randomInt(2)) {\n            case 0:\n                if (shardRouting.unassigned() == false && shardRouting.primary() == false) {\n                    shardRouting = shardRouting.moveToUnassigned(new UnassignedInfo(randomReason(), randomAsciiOfLength(10)));\n                } else if (shardRouting.unassignedInfo() != null) {\n                    shardRouting = shardRouting.updateUnassignedInfo(new UnassignedInfo(randomReason(), randomAsciiOfLength(10)));\n                }\n                break;\n            case 1:\n                if (shardRouting.unassigned()) {\n                    shardRouting = shardRouting.initialize(randomFrom(nodes), null, -1);\n                }\n                break;\n            case 2:\n                if (shardRouting.initializing()) {\n                    shardRouting = shardRouting.moveToStarted();\n                }\n                break;\n        }\n        return shardRouting;\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void addRecovery(ShardRouting routing) {\n        addRecovery(routing, true, null);\n    }","id":36575,"modified_method":"private void addRecovery(ShardRouting routing) {\n        updateRecoveryCounts(routing, true, findAssignedPrimaryIfPeerRecovery(routing));\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void removeRecovery(ShardRouting routing) {\n        addRecovery(routing, false, null);\n    }","id":36576,"modified_method":"private void removeRecovery(ShardRouting routing) {\n        updateRecoveryCounts(routing, false, findAssignedPrimaryIfPeerRecovery(routing));\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Calculates RoutingNodes statistics by iterating over all {@link ShardRouting}s\n     * in the cluster to ensure the book-keeping is correct.\n     * For performance reasons, this should only be called from asserts\n     *\n     * @return this method always returns <code>true<\/code> or throws an assertion error. If assertion are not enabled\n     *         this method does nothing.\n     */\n    public static boolean assertShardStats(RoutingNodes routingNodes) {\n        boolean run = false;\n        assert (run = true); // only run if assertions are enabled!\n        if (!run) {\n            return true;\n        }\n        int unassignedPrimaryCount = 0;\n        int unassignedIgnoredPrimaryCount = 0;\n        int inactivePrimaryCount = 0;\n        int inactiveShardCount = 0;\n        int relocating = 0;\n        Map<Index, Integer> indicesAndShards = new HashMap<>();\n        for (RoutingNode node : routingNodes) {\n            for (ShardRouting shard : node) {\n                if (shard.initializing() && shard.relocatingNodeId() == null) {\n                    inactiveShardCount++;\n                    if (shard.primary()) {\n                        inactivePrimaryCount++;\n                    }\n                }\n                if (shard.relocating()) {\n                    relocating++;\n                }\n                Integer i = indicesAndShards.get(shard.index());\n                if (i == null) {\n                    i = shard.id();\n                }\n                indicesAndShards.put(shard.index(), Math.max(i, shard.id()));\n            }\n        }\n        // Assert that the active shard routing are identical.\n        Set<Map.Entry<Index, Integer>> entries = indicesAndShards.entrySet();\n        final List<ShardRouting> shards = new ArrayList<>();\n        for (Map.Entry<Index, Integer> e : entries) {\n            Index index = e.getKey();\n            for (int i = 0; i < e.getValue(); i++) {\n                for (RoutingNode routingNode : routingNodes) {\n                    for (ShardRouting shardRouting : routingNode) {\n                        if (shardRouting.index().equals(index) && shardRouting.id() == i) {\n                            shards.add(shardRouting);\n                        }\n                    }\n                }\n                List<ShardRouting> mutableShardRoutings = routingNodes.assignedShards(new ShardId(index, i));\n                assert mutableShardRoutings.size() == shards.size();\n                for (ShardRouting r : mutableShardRoutings) {\n                    assert shards.contains(r);\n                    shards.remove(r);\n                }\n                assert shards.isEmpty();\n            }\n        }\n\n        for (ShardRouting shard : routingNodes.unassigned()) {\n            if (shard.primary()) {\n                unassignedPrimaryCount++;\n            }\n        }\n\n        for (ShardRouting shard : routingNodes.unassigned().ignored()) {\n            if (shard.primary()) {\n                unassignedIgnoredPrimaryCount++;\n            }\n        }\n\n        for (Map.Entry<String, Recoveries> recoveries : routingNodes.recoveriesPerNode.entrySet()) {\n            String node = recoveries.getKey();\n            final Recoveries value = recoveries.getValue();\n            int incoming = 0;\n            int outgoing = 0;\n            RoutingNode routingNode = routingNodes.nodesToShards.get(node);\n            if (routingNode != null) { // node might have dropped out of the cluster\n                for (ShardRouting routing : routingNode) {\n                    if (routing.initializing()) {\n                        incoming++;\n                    } else if (routing.relocating()) {\n                        outgoing++;\n                    }\n                    if (routing.primary() && (routing.initializing() && routing.relocatingNodeId() != null) == false) { // we don't count the initialization end of the primary relocation\n                        List<ShardRouting> shardRoutings = routingNodes.assignedShards.get(routing.shardId());\n                        for (ShardRouting assigned : shardRoutings) {\n                            if (assigned.primary() == false && assigned.initializing() && assigned.relocatingNodeId() == null) {\n                                outgoing++;\n                            }\n                        }\n                    }\n                }\n            }\n            assert incoming == value.incoming : incoming + \" != \" + value.incoming;\n            assert outgoing == value.outgoing : outgoing + \" != \" + value.outgoing + \" node: \" + routingNode;\n        }\n\n\n        assert unassignedPrimaryCount == routingNodes.unassignedShards.getNumPrimaries() :\n                \"Unassigned primaries is [\" + unassignedPrimaryCount + \"] but RoutingNodes returned unassigned primaries [\" + routingNodes.unassigned().getNumPrimaries() + \"]\";\n        assert unassignedIgnoredPrimaryCount == routingNodes.unassignedShards.getNumIgnoredPrimaries() :\n                \"Unassigned ignored primaries is [\" + unassignedIgnoredPrimaryCount + \"] but RoutingNodes returned unassigned ignored primaries [\" + routingNodes.unassigned().getNumIgnoredPrimaries() + \"]\";\n        assert inactivePrimaryCount == routingNodes.inactivePrimaryCount :\n                \"Inactive Primary count [\" + inactivePrimaryCount + \"] but RoutingNodes returned inactive primaries [\" + routingNodes.inactivePrimaryCount + \"]\";\n        assert inactiveShardCount == routingNodes.inactiveShardCount :\n                \"Inactive Shard count [\" + inactiveShardCount + \"] but RoutingNodes returned inactive shards [\" + routingNodes.inactiveShardCount + \"]\";\n        assert routingNodes.getRelocatingShardCount() == relocating : \"Relocating shards mismatch [\" + routingNodes.getRelocatingShardCount() + \"] but expected [\" + relocating + \"]\";\n        return true;\n    }","id":36577,"modified_method":"/**\n     * Calculates RoutingNodes statistics by iterating over all {@link ShardRouting}s\n     * in the cluster to ensure the book-keeping is correct.\n     * For performance reasons, this should only be called from asserts\n     *\n     * @return this method always returns <code>true<\/code> or throws an assertion error. If assertion are not enabled\n     *         this method does nothing.\n     */\n    public static boolean assertShardStats(RoutingNodes routingNodes) {\n        boolean run = false;\n        assert (run = true); // only run if assertions are enabled!\n        if (!run) {\n            return true;\n        }\n        int unassignedPrimaryCount = 0;\n        int unassignedIgnoredPrimaryCount = 0;\n        int inactivePrimaryCount = 0;\n        int inactiveShardCount = 0;\n        int relocating = 0;\n        Map<Index, Integer> indicesAndShards = new HashMap<>();\n        for (RoutingNode node : routingNodes) {\n            for (ShardRouting shard : node) {\n                if (shard.initializing() && shard.relocatingNodeId() == null) {\n                    inactiveShardCount++;\n                    if (shard.primary()) {\n                        inactivePrimaryCount++;\n                    }\n                }\n                if (shard.relocating()) {\n                    relocating++;\n                }\n                Integer i = indicesAndShards.get(shard.index());\n                if (i == null) {\n                    i = shard.id();\n                }\n                indicesAndShards.put(shard.index(), Math.max(i, shard.id()));\n            }\n        }\n        // Assert that the active shard routing are identical.\n        Set<Map.Entry<Index, Integer>> entries = indicesAndShards.entrySet();\n        final List<ShardRouting> shards = new ArrayList<>();\n        for (Map.Entry<Index, Integer> e : entries) {\n            Index index = e.getKey();\n            for (int i = 0; i < e.getValue(); i++) {\n                for (RoutingNode routingNode : routingNodes) {\n                    for (ShardRouting shardRouting : routingNode) {\n                        if (shardRouting.index().equals(index) && shardRouting.id() == i) {\n                            shards.add(shardRouting);\n                        }\n                    }\n                }\n                List<ShardRouting> mutableShardRoutings = routingNodes.assignedShards(new ShardId(index, i));\n                assert mutableShardRoutings.size() == shards.size();\n                for (ShardRouting r : mutableShardRoutings) {\n                    assert shards.contains(r);\n                    shards.remove(r);\n                }\n                assert shards.isEmpty();\n            }\n        }\n\n        for (ShardRouting shard : routingNodes.unassigned()) {\n            if (shard.primary()) {\n                unassignedPrimaryCount++;\n            }\n        }\n\n        for (ShardRouting shard : routingNodes.unassigned().ignored()) {\n            if (shard.primary()) {\n                unassignedIgnoredPrimaryCount++;\n            }\n        }\n\n        for (Map.Entry<String, Recoveries> recoveries : routingNodes.recoveriesPerNode.entrySet()) {\n            String node = recoveries.getKey();\n            final Recoveries value = recoveries.getValue();\n            int incoming = 0;\n            int outgoing = 0;\n            RoutingNode routingNode = routingNodes.nodesToShards.get(node);\n            if (routingNode != null) { // node might have dropped out of the cluster\n                for (ShardRouting routing : routingNode) {\n                    if (routing.initializing()) {\n                        incoming++;\n                    }\n                    if (routing.primary() && routing.isPeerRecovery() == false) {\n                        for (ShardRouting assigned : routingNodes.assignedShards.get(routing.shardId())) {\n                            if (assigned.isPeerRecovery()) {\n                                outgoing++;\n                            }\n                        }\n                    }\n                }\n            }\n            assert incoming == value.incoming : incoming + \" != \" + value.incoming + \" node: \" + routingNode;\n            assert outgoing == value.outgoing : outgoing + \" != \" + value.outgoing + \" node: \" + routingNode;\n        }\n\n\n        assert unassignedPrimaryCount == routingNodes.unassignedShards.getNumPrimaries() :\n                \"Unassigned primaries is [\" + unassignedPrimaryCount + \"] but RoutingNodes returned unassigned primaries [\" + routingNodes.unassigned().getNumPrimaries() + \"]\";\n        assert unassignedIgnoredPrimaryCount == routingNodes.unassignedShards.getNumIgnoredPrimaries() :\n                \"Unassigned ignored primaries is [\" + unassignedIgnoredPrimaryCount + \"] but RoutingNodes returned unassigned ignored primaries [\" + routingNodes.unassigned().getNumIgnoredPrimaries() + \"]\";\n        assert inactivePrimaryCount == routingNodes.inactivePrimaryCount :\n                \"Inactive Primary count [\" + inactivePrimaryCount + \"] but RoutingNodes returned inactive primaries [\" + routingNodes.inactivePrimaryCount + \"]\";\n        assert inactiveShardCount == routingNodes.inactiveShardCount :\n                \"Inactive Shard count [\" + inactiveShardCount + \"] but RoutingNodes returned inactive shards [\" + routingNodes.inactiveShardCount + \"]\";\n        assert routingNodes.getRelocatingShardCount() == relocating : \"Relocating shards mismatch [\" + routingNodes.getRelocatingShardCount() + \"] but expected [\" + relocating + \"]\";\n        return true;\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void addRecovery(final ShardRouting routing, final boolean increment, final RoutingTable routingTable) {\n        final int howMany = increment ? 1 : -1;\n        assert routing.initializing() : \"routing must be initializing: \" + routing;\n        Recoveries.getOrAdd(recoveriesPerNode, routing.currentNodeId()).addIncoming(howMany);\n        final String sourceNodeId;\n        if (routing.relocatingNodeId() != null) { // this is a relocation-target\n            sourceNodeId = routing.relocatingNodeId();\n            if (routing.primary() && increment == false) { // primary is done relocating\n                int numRecoveringReplicas = 0;\n                for (ShardRouting assigned : assignedShards(routing.shardId())) {\n                    if (assigned.primary() == false && assigned.initializing() && assigned.relocatingNodeId() == null) {\n                        numRecoveringReplicas++;\n                    }\n                }\n                // we transfer the recoveries to the relocated primary\n                recoveriesPerNode.get(sourceNodeId).addOutgoing(-numRecoveringReplicas);\n                recoveriesPerNode.get(routing.currentNodeId()).addOutgoing(numRecoveringReplicas);\n            }\n        } else if (routing.primary() == false) { // primary without relocationID is initial recovery\n            ShardRouting primary = findPrimary(routing);\n            if (primary == null && routingTable != null) {\n                primary = routingTable.index(routing.index().getName()).shard(routing.shardId().id()).primary;\n            } else if (primary == null) {\n                throw new IllegalStateException(\"replica is initializing but primary is unassigned\");\n            }\n            sourceNodeId = primary.currentNodeId();\n        } else {\n            sourceNodeId = null;\n        }\n        if (sourceNodeId != null) {\n            Recoveries.getOrAdd(recoveriesPerNode, sourceNodeId).addOutgoing(howMany);\n        }\n    }","id":36578,"modified_method":"private void updateRecoveryCounts(final ShardRouting routing, final boolean increment, @Nullable final ShardRouting primary) {\n        final int howMany = increment ? 1 : -1;\n        assert routing.initializing() : \"routing must be initializing: \" + routing;\n        // TODO: check primary == null || primary.active() after all tests properly add ReplicaAfterPrimaryActiveAllocationDecider\n        assert primary == null || primary.assignedToNode() :\n            \"shard is initializing but its primary is not assigned to a node\";\n\n        Recoveries.getOrAdd(recoveriesPerNode, routing.currentNodeId()).addIncoming(howMany);\n\n        if (routing.isPeerRecovery()) {\n            // add/remove corresponding outgoing recovery on node with primary shard\n            if (primary == null) {\n                throw new IllegalStateException(\"shard is peer recovering but primary is unassigned\");\n            }\n            Recoveries.getOrAdd(recoveriesPerNode, primary.currentNodeId()).addOutgoing(howMany);\n\n            if (increment == false && routing.primary() && routing.relocatingNodeId() != null) {\n                // primary is done relocating, move non-primary recoveries from old primary to new primary\n                int numRecoveringReplicas = 0;\n                for (ShardRouting assigned : assignedShards(routing.shardId())) {\n                    if (assigned.primary() == false && assigned.isPeerRecovery()) {\n                        numRecoveringReplicas++;\n                    }\n                }\n                recoveriesPerNode.get(routing.relocatingNodeId()).addOutgoing(-numRecoveringReplicas);\n                recoveriesPerNode.get(routing.currentNodeId()).addOutgoing(numRecoveringReplicas);\n            }\n        }\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void addInitialRecovery(ShardRouting routing, RoutingTable routingTable) {\n        addRecovery(routing, true, routingTable);\n    }","id":36579,"modified_method":"private void addInitialRecovery(ShardRouting routing, ShardRouting initialPrimaryShard) {\n        updateRecoveryCounts(routing, true, initialPrimaryShard);\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private ShardRouting findPrimary(ShardRouting routing) {\n        List<ShardRouting> shardRoutings = assignedShards.get(routing.shardId());\n        ShardRouting primary = null;\n        if (shardRoutings != null) {\n            for (ShardRouting shardRouting : shardRoutings) {\n                if (shardRouting.primary()) {\n                    if (shardRouting.active()) {\n                        return shardRouting;\n                    } else if (primary == null) {\n                        primary = shardRouting;\n                    } else if (primary.relocatingNodeId() != null) {\n                        primary = shardRouting;\n                    }\n                }\n            }\n        }\n        return primary;\n    }","id":36580,"modified_method":"@Nullable\n    private ShardRouting findAssignedPrimaryIfPeerRecovery(ShardRouting routing) {\n        ShardRouting primary = null;\n        if (routing.isPeerRecovery()) {\n            List<ShardRouting> shardRoutings = assignedShards.get(routing.shardId());\n            if (shardRoutings != null) {\n                for (ShardRouting shardRouting : shardRoutings) {\n                    if (shardRouting.primary()) {\n                        if (shardRouting.active()) {\n                            return shardRouting;\n                        } else if (primary == null) {\n                            primary = shardRouting;\n                        } else if (primary.relocatingNodeId() != null) {\n                            primary = shardRouting;\n                        }\n                    }\n                }\n            }\n        }\n        return primary;\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public RoutingNodes(ClusterState clusterState, boolean readOnly) {\n        this.readOnly = readOnly;\n        final RoutingTable routingTable = clusterState.routingTable();\n\n        Map<String, LinkedHashMap<ShardId, ShardRouting>> nodesToShards = new HashMap<>();\n        // fill in the nodeToShards with the \"live\" nodes\n        for (ObjectCursor<DiscoveryNode> cursor : clusterState.nodes().getDataNodes().values()) {\n            nodesToShards.put(cursor.value.getId(), new LinkedHashMap<>()); // LinkedHashMap to preserve order\n        }\n\n        // fill in the inverse of node -> shards allocated\n        // also fill replicaSet information\n        for (ObjectCursor<IndexRoutingTable> indexRoutingTable : routingTable.indicesRouting().values()) {\n            for (IndexShardRoutingTable indexShard : indexRoutingTable.value) {\n                assert indexShard.primary != null;\n                for (ShardRouting shard : indexShard) {\n                    // to get all the shards belonging to an index, including the replicas,\n                    // we define a replica set and keep track of it. A replica set is identified\n                    // by the ShardId, as this is common for primary and replicas.\n                    // A replica Set might have one (and not more) replicas with the state of RELOCATING.\n                    if (shard.assignedToNode()) {\n                        Map<ShardId, ShardRouting> entries = nodesToShards.computeIfAbsent(shard.currentNodeId(),\n                            k -> new LinkedHashMap<>()); // LinkedHashMap to preserve order\n                        ShardRouting previousValue = entries.put(shard.shardId(), shard);\n                        if (previousValue != null) {\n                            throw new IllegalArgumentException(\"Cannot have two different shards with same shard id on same node\");\n                        }\n                        assignedShardsAdd(shard);\n                        if (shard.relocating()) {\n                            relocatingShards++;\n                            entries = nodesToShards.computeIfAbsent(shard.relocatingNodeId(),\n                                k -> new LinkedHashMap<>()); // LinkedHashMap to preserve order\n                            // add the counterpart shard with relocatingNodeId reflecting the source from which\n                            // it's relocating from.\n                            ShardRouting targetShardRouting = shard.buildTargetRelocatingShard();\n                            addInitialRecovery(targetShardRouting, routingTable);\n                            previousValue = entries.put(targetShardRouting.shardId(), targetShardRouting);\n                            if (previousValue != null) {\n                                throw new IllegalArgumentException(\"Cannot have two different shards with same shard id on same node\");\n                            }\n                            assignedShardsAdd(targetShardRouting);\n                        } else if (shard.active() == false) { // shards that are initializing without being relocated\n                            if (shard.primary()) {\n                                inactivePrimaryCount++;\n                            }\n                            inactiveShardCount++;\n                            addInitialRecovery(shard, routingTable);\n                        }\n                    } else {\n                        unassignedShards.add(shard);\n                    }\n                }\n            }\n        }\n        for (Map.Entry<String, LinkedHashMap<ShardId, ShardRouting>> entry : nodesToShards.entrySet()) {\n            String nodeId = entry.getKey();\n            this.nodesToShards.put(nodeId, new RoutingNode(nodeId, clusterState.nodes().get(nodeId), entry.getValue()));\n        }\n    }","id":36581,"modified_method":"public RoutingNodes(ClusterState clusterState, boolean readOnly) {\n        this.readOnly = readOnly;\n        final RoutingTable routingTable = clusterState.routingTable();\n\n        Map<String, LinkedHashMap<ShardId, ShardRouting>> nodesToShards = new HashMap<>();\n        // fill in the nodeToShards with the \"live\" nodes\n        for (ObjectCursor<DiscoveryNode> cursor : clusterState.nodes().getDataNodes().values()) {\n            nodesToShards.put(cursor.value.getId(), new LinkedHashMap<>()); // LinkedHashMap to preserve order\n        }\n\n        // fill in the inverse of node -> shards allocated\n        // also fill replicaSet information\n        for (ObjectCursor<IndexRoutingTable> indexRoutingTable : routingTable.indicesRouting().values()) {\n            for (IndexShardRoutingTable indexShard : indexRoutingTable.value) {\n                assert indexShard.primary != null;\n                for (ShardRouting shard : indexShard) {\n                    // to get all the shards belonging to an index, including the replicas,\n                    // we define a replica set and keep track of it. A replica set is identified\n                    // by the ShardId, as this is common for primary and replicas.\n                    // A replica Set might have one (and not more) replicas with the state of RELOCATING.\n                    if (shard.assignedToNode()) {\n                        Map<ShardId, ShardRouting> entries = nodesToShards.computeIfAbsent(shard.currentNodeId(),\n                            k -> new LinkedHashMap<>()); // LinkedHashMap to preserve order\n                        ShardRouting previousValue = entries.put(shard.shardId(), shard);\n                        if (previousValue != null) {\n                            throw new IllegalArgumentException(\"Cannot have two different shards with same shard id on same node\");\n                        }\n                        assignedShardsAdd(shard);\n                        if (shard.relocating()) {\n                            relocatingShards++;\n                            entries = nodesToShards.computeIfAbsent(shard.relocatingNodeId(),\n                                k -> new LinkedHashMap<>()); // LinkedHashMap to preserve order\n                            // add the counterpart shard with relocatingNodeId reflecting the source from which\n                            // it's relocating from.\n                            ShardRouting targetShardRouting = shard.buildTargetRelocatingShard();\n                            addInitialRecovery(targetShardRouting, indexShard.primary);\n                            previousValue = entries.put(targetShardRouting.shardId(), targetShardRouting);\n                            if (previousValue != null) {\n                                throw new IllegalArgumentException(\"Cannot have two different shards with same shard id on same node\");\n                            }\n                            assignedShardsAdd(targetShardRouting);\n                        } else if (shard.initializing()) {\n                            if (shard.primary()) {\n                                inactivePrimaryCount++;\n                            }\n                            inactiveShardCount++;\n                            addInitialRecovery(shard, indexShard.primary);\n                        }\n                    } else {\n                        unassignedShards.add(shard);\n                    }\n                }\n            }\n        }\n        for (Map.Entry<String, LinkedHashMap<ShardId, ShardRouting>> entry : nodesToShards.entrySet()) {\n            String nodeId = entry.getKey();\n            this.nodesToShards.put(nodeId, new RoutingNode(nodeId, clusterState.nodes().get(nodeId), entry.getValue()));\n        }\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Removes relocation source of an initializing non-primary shard. This allows the replica shard to continue recovery from\n     * the primary even though its non-primary relocation source has failed.\n     */\n    public ShardRouting removeRelocationSource(ShardRouting shard) {\n        assert shard.isRelocationTarget() : \"only relocation target shards can have their relocation source removed (\" + shard + \")\";\n        ensureMutable();\n        ShardRouting relocationMarkerRemoved = shard.removeRelocationSource();\n        updateAssigned(shard, relocationMarkerRemoved);\n        inactiveShardCount++; // relocation targets are not counted as inactive shards whereas initializing shards are\n        Recoveries.getOrAdd(recoveriesPerNode, shard.relocatingNodeId()).addOutgoing(-1);\n        return relocationMarkerRemoved;\n    }","id":36582,"modified_method":"/**\n     * Removes relocation source of an initializing non-primary shard. This allows the replica shard to continue recovery from\n     * the primary even though its non-primary relocation source has failed.\n     */\n    public ShardRouting removeRelocationSource(ShardRouting shard) {\n        assert shard.isRelocationTarget() : \"only relocation target shards can have their relocation source removed (\" + shard + \")\";\n        ensureMutable();\n        ShardRouting relocationMarkerRemoved = shard.removeRelocationSource();\n        updateAssigned(shard, relocationMarkerRemoved);\n        inactiveShardCount++; // relocation targets are not counted as inactive shards whereas initializing shards are\n        return relocationMarkerRemoved;\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n        if (shardRouting.primary()) {\n            assert shardRouting.unassigned() || shardRouting.active();\n            if (shardRouting.unassigned()) {\n                // primary is unassigned, means we are going to do recovery from gateway\n                // count *just the primary* currently doing recovery on the node and check against concurrent_recoveries\n                int primariesInRecovery = 0;\n                for (ShardRouting shard : node) {\n                    // when a primary shard is INITIALIZING, it can be because of *initial recovery* or *relocation from another node*\n                    // we only count initial recoveries here, so we need to make sure that relocating node is null\n                    if (shard.initializing() && shard.primary() && shard.relocatingNodeId() == null) {\n                        primariesInRecovery++;\n                    }\n                }\n                if (primariesInRecovery >= primariesInitialRecoveries) {\n                    return allocation.decision(Decision.THROTTLE, NAME, \"too many primaries are currently recovering [%d], limit: [%d]\",\n                            primariesInRecovery, primariesInitialRecoveries);\n                } else {\n                    return allocation.decision(Decision.YES, NAME, \"below primary recovery limit of [%d]\", primariesInitialRecoveries);\n                }\n            }\n        }\n        // TODO should we allow shards not allocated post API to always allocate?\n        // either primary or replica doing recovery (from peer shard)\n\n        // count the number of recoveries on the node, its for both target (INITIALIZING) and source (RELOCATING)\n        return canAllocate(node, allocation);\n    }","id":36583,"modified_method":"@Override\n    public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n        if (shardRouting.primary() && shardRouting.unassigned()) {\n            assert initializingShard(shardRouting, node.nodeId()).isPeerRecovery() == false;\n            // primary is unassigned, means we are going to do recovery from store, snapshot or local shards\n            // count *just the primaries* currently doing recovery on the node and check against primariesInitialRecoveries\n\n            int primariesInRecovery = 0;\n            for (ShardRouting shard : node) {\n                // when a primary shard is INITIALIZING, it can be because of *initial recovery* or *relocation from another node*\n                // we only count initial recoveries here, so we need to make sure that relocating node is null\n                if (shard.initializing() && shard.primary() && shard.relocatingNodeId() == null) {\n                    primariesInRecovery++;\n                }\n            }\n            if (primariesInRecovery >= primariesInitialRecoveries) {\n                // TODO: Should index creation not be throttled for primary shards?\n                return allocation.decision(THROTTLE, NAME, \"too many primaries are currently recovering [%d], limit: [%d]\",\n                    primariesInRecovery, primariesInitialRecoveries);\n            } else {\n                return allocation.decision(YES, NAME, \"below primary recovery limit of [%d]\", primariesInitialRecoveries);\n            }\n        } else {\n            // Peer recovery\n            assert initializingShard(shardRouting, node.nodeId()).isPeerRecovery();\n\n            // Allocating a shard to this node will increase the incoming recoveries\n            int currentInRecoveries = allocation.routingNodes().getIncomingRecoveries(node.nodeId());\n            if (currentInRecoveries >= concurrentIncomingRecoveries) {\n                return allocation.decision(THROTTLE, NAME, \"too many incoming shards are currently recovering [%d], limit: [%d]\",\n                    currentInRecoveries, concurrentIncomingRecoveries);\n            } else {\n                // search for corresponding recovery source (= primary shard) and check number of outgoing recoveries on that node\n                ShardRouting primaryShard = allocation.routingNodes().activePrimary(shardRouting.shardId());\n                if (primaryShard == null) {\n                    return allocation.decision(Decision.NO, NAME, \"primary shard for this replica is not yet active\");\n                }\n                int primaryNodeOutRecoveries = allocation.routingNodes().getOutgoingRecoveries(primaryShard.currentNodeId());\n                if (primaryNodeOutRecoveries >= concurrentOutgoingRecoveries) {\n                    return allocation.decision(THROTTLE, NAME, \"too many outgoing shards are currently recovering [%d], limit: [%d]\",\n                        primaryNodeOutRecoveries, concurrentOutgoingRecoveries);\n                } else {\n                    return allocation.decision(YES, NAME, \"below shard recovery limit of outgoing: [%d < %d] incoming: [%d < %d]\",\n                        primaryNodeOutRecoveries,\n                        concurrentOutgoingRecoveries,\n                        currentInRecoveries,\n                        concurrentIncomingRecoveries);\n                }\n            }\n        }\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testOutgoingThrottlesAllocaiton() {\n        Settings settings = Settings.builder()\n            .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 1)\n            .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 1)\n            .put(\"cluster.routing.allocation.cluster_concurrent_rebalance\", 1)\n            .build();\n        AllocationService strategy = createAllocationService(settings);\n\n        MetaData metaData = MetaData.builder()\n            .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(0))\n            .build();\n\n        RoutingTable routingTable = RoutingTable.builder()\n            .addAsNew(metaData.index(\"test\"))\n            .build();\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\")).put(newNode(\"node2\")).put(newNode(\"node3\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node3\"), 0);\n\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node3\"), 0);\n\n        RoutingAllocation.Result reroute = strategy.reroute(clusterState, new AllocationCommands(new MoveAllocationCommand(\"test\", clusterState.getRoutingNodes().node(\"node1\").iterator().next().shardId().id(), \"node1\", \"node2\")), false, false);\n        assertEquals(reroute.explanations().explanations().size(), 1);\n        assertEquals(reroute.explanations().explanations().get(0).decisions().type(), Decision.Type.YES);\n        routingTable = reroute.routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node3\"), 0);\n\n        // outgoing throttles\n        reroute = strategy.reroute(clusterState, new AllocationCommands(new MoveAllocationCommand(\"test\", clusterState.getRoutingNodes().node(\"node3\").iterator().next().shardId().id(), \"node3\", \"node1\")), true, false);\n        assertEquals(reroute.explanations().explanations().size(), 1);\n        assertEquals(reroute.explanations().explanations().get(0).decisions().type(), Decision.Type.THROTTLE);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node3\"), 0);\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n        // incoming throttles\n        reroute = strategy.reroute(clusterState, new AllocationCommands(new MoveAllocationCommand(\"test\", clusterState.getRoutingNodes().node(\"node3\").iterator().next().shardId().id(), \"node3\", \"node2\")), true, false);\n        assertEquals(reroute.explanations().explanations().size(), 1);\n        assertEquals(reroute.explanations().explanations().get(0).decisions().type(), Decision.Type.THROTTLE);\n\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node3\"), 0);\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n    }","id":36584,"modified_method":"public void testOutgoingThrottlesAllocation() {\n        AllocationService strategy = createAllocationService(Settings.builder()\n            .put(\"cluster.routing.allocation.node_concurrent_outgoing_recoveries\", 1)\n            .build());\n\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n            .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(2))\n            .build();\n\n        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(\"test\"));\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 1 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(2));\n\n        logger.info(\"start initializing\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(2));\n\n        logger.info(\"start one more node, first non-primary should start being allocated\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node2\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(1));\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n\n        logger.info(\"start initializing non-primary\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(1));\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 0);\n\n        logger.info(\"start one more node, initializing second non-primary\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node3\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n\n        logger.info(\"start one more node\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node4\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n\n        logger.info(\"move started non-primary to new node\");\n        RoutingAllocation.Result reroute = strategy.reroute(clusterState, new AllocationCommands(\n            new MoveAllocationCommand(\"test\", 0, \"node2\", \"node4\")), true, false);\n        assertEquals(reroute.explanations().explanations().size(), 1);\n        assertEquals(reroute.explanations().explanations().get(0).decisions().type(), Decision.Type.THROTTLE);\n        // even though it is throttled, move command still forces allocation\n\n        clusterState = ClusterState.builder(clusterState).routingResult(reroute).build();\n        routingTable = clusterState.routingTable();\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 2);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node2\"), 0);\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testThrottleIncomingAndOutgoing() {\n        Settings settings = Settings.builder()\n            .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 5)\n            .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 5)\n            .put(\"cluster.routing.allocation.cluster_concurrent_rebalance\", 5)\n            .build();\n        AllocationService strategy = createAllocationService(settings);\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n            .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(9).numberOfReplicas(0))\n            .build();\n\n        RoutingTable routingTable = RoutingTable.builder()\n            .addAsNew(metaData.index(\"test\"))\n            .build();\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 5 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(4));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 5);\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(4));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        logger.info(\"start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node2\")).put(newNode(\"node3\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(4));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 3);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 2);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 5);\n\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        logger.info(\"start the relocating shards, one more shard should relocate away from node1\");\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n    }","id":36585,"modified_method":"public void testThrottleIncomingAndOutgoing() {\n        Settings settings = Settings.builder()\n            .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 5)\n            .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 5)\n            .put(\"cluster.routing.allocation.cluster_concurrent_rebalance\", 5)\n            .build();\n        AllocationService strategy = createAllocationService(settings);\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n            .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(9).numberOfReplicas(0))\n            .build();\n\n        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(\"test\"));\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 5 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(4));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 5);\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(4));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        logger.info(\"start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node2\")).put(newNode(\"node3\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(4));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 3);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 2);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 5);\n\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        logger.info(\"start the relocating shards, one more shard should relocate away from node1\");\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));\n        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node2\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node3\"), 1);\n        assertEquals(clusterState.getRoutingNodes().getIncomingRecoveries(\"node1\"), 0);\n        assertEquals(clusterState.getRoutingNodes().getOutgoingRecoveries(\"node1\"), 1);\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testPrimaryRecoveryThrottling() {\n        AllocationService strategy = createAllocationService(Settings.builder()\n                .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 3)\n                .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 3)\n                .build());\n\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n                .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(10).numberOfReplicas(1))\n                .build();\n\n        RoutingTable routingTable = RoutingTable.builder()\n                .addAsNew(metaData.index(\"test\"))\n                .build();\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 3 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(17));\n\n        logger.info(\"start initializing, another 3 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(14));\n\n        logger.info(\"start initializing, another 3 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(6));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(11));\n\n        logger.info(\"start initializing, another 1 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(9));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));\n    }","id":36586,"modified_method":"public void testPrimaryRecoveryThrottling() {\n        AllocationService strategy = createAllocationService(Settings.builder()\n                .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 3)\n                .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 3)\n                .build());\n\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n                .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(10).numberOfReplicas(1))\n                .build();\n\n        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(\"test\"));\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 3 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(17));\n\n        logger.info(\"start initializing, another 3 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(14));\n\n        logger.info(\"start initializing, another 3 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(6));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(11));\n\n        logger.info(\"start initializing, another 1 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(9));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testReplicaAndPrimaryRecoveryThrottling() {\n        AllocationService strategy = createAllocationService(Settings.builder()\n                .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 3)\n                .put(\"cluster.routing.allocation.concurrent_source_recoveries\", 3)\n                .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 3)\n                .build());\n\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n                .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))\n                .build();\n\n        RoutingTable routingTable = RoutingTable.builder()\n                .addAsNew(metaData.index(\"test\"))\n                .build();\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 3 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(7));\n\n        logger.info(\"start initializing, another 2 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));\n\n        logger.info(\"start another node, replicas should start being allocated\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node2\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(2));\n\n        logger.info(\"start initializing replicas\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n        logger.info(\"start initializing replicas, all should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n    }","id":36587,"modified_method":"public void testReplicaAndPrimaryRecoveryThrottling() {\n        AllocationService strategy = createAllocationService(Settings.builder()\n                .put(\"cluster.routing.allocation.node_concurrent_recoveries\", 3)\n                .put(\"cluster.routing.allocation.concurrent_source_recoveries\", 3)\n                .put(\"cluster.routing.allocation.node_initial_primaries_recoveries\", 3)\n                .build());\n\n        logger.info(\"Building initial routing table\");\n\n        MetaData metaData = MetaData.builder()\n                .put(IndexMetaData.builder(\"test\").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))\n                .build();\n\n        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(\"test\"));\n\n        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();\n\n        logger.info(\"start one node, do reroute, only 3 should initialize\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode(\"node1\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(7));\n\n        logger.info(\"start initializing, another 2 should initialize\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));\n\n        logger.info(\"start initializing, all primaries should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));\n\n        logger.info(\"start another node, replicas should start being allocated\");\n        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).put(newNode(\"node2\"))).build();\n        routingTable = strategy.reroute(clusterState, \"reroute\").routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(2));\n\n        logger.info(\"start initializing replicas\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n\n        logger.info(\"start initializing replicas, all should be started\");\n        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();\n        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();\n\n        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));\n        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));\n        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));\n    }","commit_id":"24a7b7224bd834eb57d1026ceb0c455b8c48a206","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n        String sourceNodeId = shardRouting.currentNodeId();\n        /* if sourceNodeId is not null we do a relocation and just check the version of the node\n         * that we are currently allocate on. If not we are initializing and recover from primary.*/\n        if (sourceNodeId == null) { // we allocate - check primary\n            if (shardRouting.primary()) {\n                // we are the primary we can allocate wherever\n                return allocation.decision(Decision.YES, NAME, \"primary shard can be allocated anywhere\");\n            }\n            final ShardRouting primary = allocation.routingNodes().activePrimary(shardRouting);\n            if (primary == null) { // we have a primary - it's a start ;)\n                return allocation.decision(Decision.YES, NAME, \"no active primary shard yet\");\n            }\n            sourceNodeId = primary.currentNodeId();\n        }\n        return isVersionCompatible(allocation.routingNodes(), sourceNodeId, node, allocation);\n\n    }","id":36588,"modified_method":"@Override\n    public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n        if (shardRouting.primary()) {\n            if (shardRouting.currentNodeId() == null) {\n                // fresh primary, we can allocate wherever\n                return allocation.decision(Decision.YES, NAME, \"primary shard can be allocated anywhere\");\n            } else {\n                // relocating primary, only migrate to newer host\n                return isVersionCompatible(allocation.routingNodes(), shardRouting.currentNodeId(), node, allocation);\n            }\n        } else {\n            final ShardRouting primary = allocation.routingNodes().activePrimary(shardRouting);\n            // check that active primary has a newer version so that peer recovery works\n            if (primary != null) {\n                return isVersionCompatible(allocation.routingNodes(), primary.currentNodeId(), node, allocation);\n            } else {\n                // ReplicaAfterPrimaryActiveAllocationDecider should prevent this case from occurring\n                return allocation.decision(Decision.YES, NAME, \"no active primary shard yet\");\n            }\n        }\n    }","commit_id":"55cc88e1ae9360e9400cd1075306c2c5d94a81ba","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private final void assertRecoveryNodeVersions(RoutingNodes routingNodes) {\n        logger.trace(\"RoutingNodes: {}\", routingNodes.prettyPrint());\n\n        List<ShardRouting> mutableShardRoutings = routingNodes.shardsWithState(ShardRoutingState.RELOCATING);\n        for (ShardRouting r : mutableShardRoutings) {\n            String toId = r.relocatingNodeId();\n            String fromId = r.currentNodeId();\n            assertThat(fromId, notNullValue());\n            assertThat(toId, notNullValue());\n            logger.trace(\"From: \" + fromId + \" with Version: \" + routingNodes.node(fromId).node().version() + \" to: \" + toId + \" with Version: \" + routingNodes.node(toId).node().version());\n            assertTrue(routingNodes.node(toId).node().version().onOrAfter(routingNodes.node(fromId).node().version()));\n        }\n\n        mutableShardRoutings = routingNodes.shardsWithState(ShardRoutingState.INITIALIZING);\n        for (ShardRouting r : mutableShardRoutings) {\n            if (r.initializing() && r.relocatingNodeId() == null && !r.primary()) {\n                ShardRouting primary = routingNodes.activePrimary(r);\n                assertThat(primary, notNullValue());\n                String fromId = primary.currentNodeId();\n                String toId = r.currentNodeId();\n                logger.trace(\"From: \" + fromId + \" with Version: \" + routingNodes.node(fromId).node().version() + \" to: \" + toId + \" with Version: \" + routingNodes.node(toId).node().version());\n                assertTrue(routingNodes.node(toId).node().version().onOrAfter(routingNodes.node(fromId).node().version()));\n            }\n        }\n\n\n    }","id":36589,"modified_method":"private final void assertRecoveryNodeVersions(RoutingNodes routingNodes) {\n        logger.trace(\"RoutingNodes: {}\", routingNodes.prettyPrint());\n\n        List<ShardRouting> mutableShardRoutings = routingNodes.shardsWithState(ShardRoutingState.RELOCATING);\n        for (ShardRouting r : mutableShardRoutings) {\n            if (r.primary()) {\n                String toId = r.relocatingNodeId();\n                String fromId = r.currentNodeId();\n                assertThat(fromId, notNullValue());\n                assertThat(toId, notNullValue());\n                logger.trace(\"From: \" + fromId + \" with Version: \" + routingNodes.node(fromId).node().version() + \" to: \" + toId + \" with Version: \" + routingNodes.node(toId).node().version());\n                assertTrue(routingNodes.node(toId).node().version().onOrAfter(routingNodes.node(fromId).node().version()));\n            } else {\n                ShardRouting primary = routingNodes.activePrimary(r);\n                assertThat(primary, notNullValue());\n                String fromId = primary.currentNodeId();\n                String toId = r.relocatingNodeId();\n                logger.error(\"From: \" + fromId + \" with Version: \" + routingNodes.node(fromId).node().version() + \" to: \" + toId + \" with Version: \" + routingNodes.node(toId).node().version());\n                logger.error(routingNodes.prettyPrint());\n                assertTrue(routingNodes.node(toId).node().version().onOrAfter(routingNodes.node(fromId).node().version()));\n            }\n        }\n\n        mutableShardRoutings = routingNodes.shardsWithState(ShardRoutingState.INITIALIZING);\n        for (ShardRouting r : mutableShardRoutings) {\n            if (!r.primary()) {\n                ShardRouting primary = routingNodes.activePrimary(r);\n                assertThat(primary, notNullValue());\n                String fromId = primary.currentNodeId();\n                String toId = r.currentNodeId();\n                logger.trace(\"From: \" + fromId + \" with Version: \" + routingNodes.node(fromId).node().version() + \" to: \" + toId + \" with Version: \" + routingNodes.node(toId).node().version());\n                assertTrue(routingNodes.node(toId).node().version().onOrAfter(routingNodes.node(fromId).node().version()));\n            }\n        }\n\n\n    }","commit_id":"55cc88e1ae9360e9400cd1075306c2c5d94a81ba","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Updates the enabled/diabled status of all elements of the current page.<p>\n     */\n    public void actionUpdateElements() {\n        try {\n            List elementList = computeElements();\n            CmsFile file = getCms().readFile(this.getParamTempfile());\n            CmsXmlPage page = CmsXmlPage.read(getCms(), file);\n            boolean foundMandatory = false;\n            m_changeElement = \"\";\n            Iterator i = elementList.iterator();\n            while (i.hasNext()) {\n                // get the current list element\n                CmsDialogElement element = (CmsDialogElement)i.next();               \n                if (element.isMandantory() \n                || \"true\".equals(getJsp().getRequest().getParameter(PREFIX_PARAM_BODY + element.getName()))) {\n                    if (!element.isExisting()) {\n                        // create element in order to enable it properly \n                        page.addElement(element.getName(), getElementLocale());\n                    }\n                    page.setEnabled(element.getName(), getElementLocale(), true);\n                    if (element.isMandantory() && !foundMandatory) {\n                        m_changeElement = element.getName();\n                        foundMandatory = true;\n                    }\n                } else {\n                    if (element.isExisting()) {\n                        // must set enabled to true or check for contains always fails\n                        page.setEnabled(element.getName(), getElementLocale(), true);\n                        // disable element if it is already existing\n                        if (! element.isTemplateElement() \n                        && \"\".equals(page.getContent(getCms(), element.getName(), getElementLocale()))) {\n                            // element is not defined in template, empty and disabled - remove it\n                            page.removeElement(element.getName(), getElementLocale());\n                        } else {\n                            page.setEnabled(element.getName(), getElementLocale(), false);\n                        }\n                    }                    \n                }\n            }\n            // write the temporary file\n            // odd behaviour,  getCms().writeFile(page.write(file)); does not work here\n            file = page.write(file);\n            getCms().writeFile(file);\n            // set the javascript functions which should be executed\n            if (page.isEnabled(getParamElementname(), getElementLocale())) {\n                m_changeElement = getParamElementname();\n            } else if (!foundMandatory) {\n                if (elementList.size() > 0) {\n                    m_changeElement = ((CmsDialogElement)elementList.get(0)).getName();                    \n                }\n            }                       \n        } catch (CmsException e) {\n            // show error dialog\n            setParamErrorstack(e.getStackTraceAsString());\n            setParamMessage(key(\"error.message.editor.elements\"));\n            String reason = key(\"error.reason.editor.elements\") + \"<br>\\n\" + key(\"error.suggestion.editor.elements\") + \"\\n\";\n            setParamReasonSuggestion(reason);\n            // save initialized instance of this class in request attribute for included sub-elements\n            getJsp().getRequest().setAttribute(C_SESSION_WORKPLACE_CLASS, this);\n            try {\n                getJsp().include(C_FILE_DIALOG_SCREEN_ERROR); \n            } catch (Exception exc) {\n                // ignore this exception\n            }\n        }\n    }","id":36590,"modified_method":"/**\n     * Updates the enabled/diabled status of all elements of the current page.<p>\n     */\n    public void actionUpdateElements() {\n        try {\n            List elementList = computeElements();\n            CmsFile file = getCms().readFile(this.getParamTempfile());\n            CmsXmlPage page = CmsXmlPage.read(getCms(), file);\n            boolean foundMandatory = false;\n            m_changeElement = \"\";\n            Iterator i = elementList.iterator();\n            while (i.hasNext()) {\n                // get the current list element\n                CmsDialogElement element = (CmsDialogElement)i.next();               \n                if (element.isMandantory() \n                || \"true\".equals(getJsp().getRequest().getParameter(PREFIX_PARAM_BODY + element.getName()))) {\n                    if (!element.isExisting()) {\n                        // create element in order to enable it properly \n                        page.addElement(element.getName(), getElementLocale());\n                    }\n                    page.setEnabled(element.getName(), getElementLocale(), true);\n                    if (element.isMandantory() && !foundMandatory) {\n                        m_changeElement = element.getName();\n                        foundMandatory = true;\n                    }\n                } else {\n                    if (element.isExisting()) {\n                        // must set enabled to true or check for contains always fails\n                        page.setEnabled(element.getName(), getElementLocale(), true);\n                        // disable element if it is already existing\n                        if (\"\".equals(page.getContent(getCms(), element.getName(), getElementLocale()))) {\n                            // element is not defined in template, empty and disabled - remove it\n                            page.removeElement(element.getName(), getElementLocale());\n                        } else {\n                            page.setEnabled(element.getName(), getElementLocale(), false);\n                        }\n                    }                    \n                }\n            }\n            // write the temporary file\n            // odd behaviour,  getCms().writeFile(page.write(file)); does not work here\n            file = page.write(file);\n            getCms().writeFile(file);\n            // set the javascript functions which should be executed\n            if (page.isEnabled(getParamElementname(), getElementLocale())) {\n                m_changeElement = getParamElementname();\n            } else if (!foundMandatory) {\n                if (elementList.size() > 0) {\n                    m_changeElement = ((CmsDialogElement)elementList.get(0)).getName();                    \n                }\n            }                       \n        } catch (CmsException e) {\n            // show error dialog\n            setParamErrorstack(e.getStackTraceAsString());\n            setParamMessage(key(\"error.message.editor.elements\"));\n            String reason = key(\"error.reason.editor.elements\") + \"<br>\\n\" + key(\"error.suggestion.editor.elements\") + \"\\n\";\n            setParamReasonSuggestion(reason);\n            // save initialized instance of this class in request attribute for included sub-elements\n            getJsp().getRequest().setAttribute(C_SESSION_WORKPLACE_CLASS, this);\n            try {\n                getJsp().include(C_FILE_DIALOG_SCREEN_ERROR); \n            } catch (Exception exc) {\n                // ignore this exception\n            }\n        }\n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Removes a bookmark with a given key.<p>\n     * \n     * @param name the name of the element\n     * @param locale the locale of the element\n     * @return the element removed from the bookmarks or null\n     */\n    protected Element removeBookmark(String name, Locale locale) {\n        if (locale != null) {\n            return (Element)m_bookmarks.remove(locale.toString() + \"|\" + name);\n        } else {\n            return (Element)m_bookmarks.remove(name);\n        }\n    }","id":36591,"modified_method":"/**\n     * Removes a bookmark with a given key.<p>\n     * \n     * @param name the name of the element\n     * @param locale the locale of the element\n     * @return the element removed from the bookmarks or null\n     */\n    protected Element removeBookmark(String name, Locale locale) {\n        if (locale != null) {\n            return (Element)m_bookmarks.remove(locale.toString() + \"|\" + name);\n        } else {\n            int warning = 0;\n            return (Element)m_bookmarks.remove(name);\n        }\n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Adds a bookmark for the given element.<p>\n     * \n     * @param name the name of the element\n     * @param locale the locale of the element\n     * @param element the element to bookmark\n     */\n    protected void setBookmark(String name, Locale locale, Element element) {        \n        if (locale != null) {\n            m_locales.add(locale);\n            m_bookmarks.put(locale.toString() + \"|\" + name, element);\n        } else {\n            m_bookmarks.put(name, element);\n        }\n    }","id":36592,"modified_method":"/**\n     * Adds a bookmark for the given element.<p>\n     * \n     * @param name the name of the element\n     * @param locale the locale of the element\n     * @param element the element to bookmark\n     */\n    protected void setBookmark(String name, Locale locale, boolean enabled, Element element) {        \n        if (locale != null) {\n            m_locales.add(locale);\n            m_bookmarks.put(locale.toString() + \"|\" + name, element);\n            if (enabled) {\n                Object o = m_elementLocales.get(name);\n                if (o != null) {\n                    Set set = (Set)o;\n                    set.add(locale);\n                } else {\n                    Set set = new HashSet();\n                    set.add(locale);\n                    m_elementLocales.put(name, set);\n                }\n            }\n        } else {\n            int warning = 0;\n            m_bookmarks.put(name, element);\n        }\n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Initializes the bookmarks according to the named elements in the document.<p>\n     */\n    protected void initBookmarks() {\n\n        m_bookmarks = new HashMap();\n        m_locales = new HashSet();\n        \n        for (Iterator i = m_document.getRootElement().element(C_NODE_ELEMENTS).elementIterator(C_NODE_ELEMENT); i.hasNext();) {\n   \n            Element elem = (Element)i.next();\n            try {\n                String elementName = elem.attribute(C_ATTRIBUTE_NAME).getValue();\n                String elementLang = elem.attribute(C_ATTRIBUTE_LANGUAGE).getValue();\n                setBookmark(elementName, CmsLocaleManager.getLocale(elementLang), elem);              \n            } catch (NullPointerException e) {\n                OpenCms.getLog(this).error(\"Error while initalizing xmlPage bookmarks\", e);                \n            }    \n        }\n    }","id":36593,"modified_method":"/**\n     * Initializes the bookmarks according to the named elements in the document.<p>\n     */\n    protected void initBookmarks() {\n\n        m_bookmarks = new HashMap();\n        m_locales = new HashSet();\n        m_elementLocales = new HashMap();\n        \n        for (Iterator i = m_document.getRootElement().element(C_NODE_ELEMENTS).elementIterator(C_NODE_ELEMENT); i.hasNext();) {\n   \n            Element elem = (Element)i.next();\n            try {\n                String elementName = elem.attributeValue(C_ATTRIBUTE_NAME);\n                String elementLang = elem.attributeValue(C_ATTRIBUTE_LANGUAGE);\n                String elementEnabled = elem.attributeValue(C_ATTRIBUTE_ENABLED);\n                boolean enabled = (elementEnabled==null)?true:Boolean.valueOf(elementEnabled).booleanValue();\n                setBookmark(elementName, CmsLocaleManager.getLocale(elementLang), enabled, elem);              \n            } catch (NullPointerException e) {\n                OpenCms.getLog(this).error(\"Error while initalizing xmlPage bookmarks\", e);                \n            }    \n        }\n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Adds a new empty element with the given name and language.<p>\n     *  \n     * @param name name of the element, must be unique\n     * @param locale locale of the element\n     */\n    public void addElement(String name, Locale locale) {\n        Element elements = m_document.getRootElement().element(C_NODE_ELEMENTS);        \n        Element element = elements.addElement(C_NODE_ELEMENT)\n              .addAttribute(C_ATTRIBUTE_NAME, name)\n              .addAttribute(C_ATTRIBUTE_LANGUAGE, locale.toString());       \n        element.addElement(C_NODE_LINKS);\n        element.addElement(C_NODE_CONTENT);\n        setBookmark(name, locale, element);\n    }","id":36594,"modified_method":"/**\n     * Adds a new empty element with the given name and language.<p>\n     *  \n     * @param name name of the element, must be unique\n     * @param locale locale of the element\n     */\n    public void addElement(String name, Locale locale) {\n        Element elements = m_document.getRootElement().element(C_NODE_ELEMENTS);        \n        Element element = elements.addElement(C_NODE_ELEMENT)\n              .addAttribute(C_ATTRIBUTE_NAME, name)\n              .addAttribute(C_ATTRIBUTE_LANGUAGE, locale.toString());       \n        element.addElement(C_NODE_LINKS);\n        element.addElement(C_NODE_CONTENT);\n        setBookmark(name, locale, true, element);\n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * @see org.opencms.loader.I_CmsResourceLoader#service(org.opencms.file.CmsObject, org.opencms.file.CmsResource, javax.servlet.ServletRequest, javax.servlet.ServletResponse)\n     */\n    public void service(CmsObject cms, CmsResource resource, ServletRequest req, ServletResponse res) \n    throws IOException, CmsException {\n        \n        // get the absolute path of the resource\n        String absolutePath = cms.readAbsolutePath(resource);\n        \n        // get the requested page\n        CmsXmlPage page = (CmsXmlPage)req.getAttribute(absolutePath);\n            \n        if (page == null) {      \n            // make sure a page is only read once (not every time for each element)\n            page = CmsXmlPage.read(cms, CmsFile.upgrade(resource, cms));\n            req.setAttribute(absolutePath, page);\n        }        \n        \n        // get the element selector\n        String elementName = req.getParameter(I_CmsConstants.C_PARAMETER_ELEMENT);\n        \n        // check the current locales\n        Locale locale = OpenCms.getLocaleManager().getBestMatchingLocale(cms.getRequestContext().getLocale(), OpenCms.getLocaleManager().getDefaultLocales(cms, absolutePath), page.getLocales());\n        \n        // get the appropriate content and convert it to bytes\n        byte[] result = page.getContent(cms, elementName, locale).getBytes(page.getEncoding()); \n        \n        // append the result to the output stream\n        if (result != null) {\n            res.getOutputStream().write(result);\n        }        \n    }","id":36595,"modified_method":"/**\n     * @see org.opencms.loader.I_CmsResourceLoader#service(org.opencms.file.CmsObject, org.opencms.file.CmsResource, javax.servlet.ServletRequest, javax.servlet.ServletResponse)\n     */\n    public void service(CmsObject cms, CmsResource resource, ServletRequest req, ServletResponse res) \n    throws IOException, CmsException {\n        \n        // get the absolute path of the resource\n        String absolutePath = cms.readAbsolutePath(resource);\n        \n        // get the requested page\n        CmsXmlPage page = (CmsXmlPage)req.getAttribute(absolutePath);\n            \n        if (page == null) {      \n            // make sure a page is only read once (not every time for each element)\n            page = CmsXmlPage.read(cms, CmsFile.upgrade(resource, cms));\n            req.setAttribute(absolutePath, page);\n        }        \n        \n        // get the element selector\n        String elementName = req.getParameter(I_CmsConstants.C_PARAMETER_ELEMENT);\n        \n        // check the current locales\n        Locale locale = OpenCms.getLocaleManager().getBestMatchingLocale(cms.getRequestContext().getLocale(), OpenCms.getLocaleManager().getDefaultLocales(cms, absolutePath), page.getLocales(elementName));\n        \n        // get the appropriate content and convert it to bytes\n        byte[] result = page.getContent(cms, elementName, locale).getBytes(page.getEncoding()); \n        \n        // append the result to the output stream\n        if (result != null) {\n            res.getOutputStream().write(result);\n        }        \n    }","commit_id":"9d6a06977987d6e053924ebb108109b891123150","url":"https://github.com/alkacon/opencms-core"},{"original_method":"protected void validateLiferayPluginPackageXMLFile(File xmlFile)\n\t\tthrows Exception {\n\n\t\tAssert.assertTrue(\n\t\t\t\"liferay-plugin-package.xml must be created.\", xmlFile.exists());\n\n\t\tString liferayPluginPackageXML = FileUtil.read(xmlFile);\n\n\t\tAssert.assertNotNull(\n\t\t\t\"XML file content must not be null.\", liferayPluginPackageXML);\n\n\t\tDocument document = SAXReaderUtil.read(liferayPluginPackageXML, true);\n\n\t\tElement rootElement = document.getRootElement();\n\n\t\tElement element = rootElement.element(\"name\");\n\n\t\tAssert.assertNotNull(\"Name element missing.\", element);\n\n\t\telement = rootElement.element(\"tags\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"short-description\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertEquals(\"Test\", element.getTextTrim());\n\n\t\telement = rootElement.element(\"page-url\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"author\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"liferay-versions\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\t}","id":36596,"modified_method":"protected void validateLiferayPluginPackageXMLFile(File xmlFile)\n\t\tthrows Exception {\n\n\t\tAssert.assertTrue(xmlFile.exists());\n\n\t\tString liferayPluginPackageXML = FileUtil.read(xmlFile);\n\n\t\tAssert.assertNotNull(liferayPluginPackageXML);\n\n\t\tDocument document = SAXReaderUtil.read(liferayPluginPackageXML, true);\n\n\t\tElement rootElement = document.getRootElement();\n\n\t\tElement element = rootElement.element(\"name\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\telement = rootElement.element(\"tags\");\n\n\t\tAssert.assertNotNull(element);\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"short-description\");\n\n\t\tAssert.assertNotNull(element);\n\t\tAssert.assertEquals(\"Test\", element.getTextTrim());\n\n\t\telement = rootElement.element(\"page-url\");\n\n\t\tAssert.assertNotNull(element);\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"author\");\n\n\t\tAssert.assertNotNull(element);\n\t\tAssert.assertNotNull(element.getTextTrim());\n\n\t\telement = rootElement.element(\"liferay-versions\");\n\n\t\tAssert.assertNotNull(element);\n\t\tAssert.assertNotNull(element.getTextTrim());\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public File getWebInfFolder() {\n\t\treturn new File(WEB_INF_FOLDER);\n\t}","id":36597,"modified_method":"protected File getWebInfDir() {\n\t\treturn new File(getRootDir(), \"WEB-INF\");\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Properties getLiferayPluginPackageProperties()\n\t\tthrows IOException {\n\n\t\tInputStream inputStream = new FileInputStream(\n\t\t\tWEB_INF_FOLDER + \"/liferay-plugin-package.properties\");\n\n\t\tString stringProperties = StringUtil.read(inputStream);\n\n\t\tProperties properties = PropertiesUtil.load(stringProperties);\n\n\t\tAssert.assertFalse(\n\t\t\t\"Test properties have not been loaded properly.\",\n\t\t\tproperties.isEmpty());\n\n\t\treturn properties;\n\t}","id":36598,"modified_method":"protected Properties getLiferayPluginPackageProperties()\n\t\tthrows IOException {\n\n\t\tInputStream inputStream = new FileInputStream(\n\t\t\tnew File(getWebInfDir(), \"liferay-plugin-package.properties\"));\n\n\t\tProperties properties = PropertiesUtil.load(\n\t\t\tStringUtil.read(inputStream));\n\n\t\tAssert.assertFalse(properties.isEmpty());\n\n\t\treturn properties;\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void validateLiferayLookAndFeelXMLFile(File xmlFile)\n\t\tthrows Exception {\n\n\t\tAssert.assertTrue(\n\t\t\t\"liferay-look-and-feel.xml must be created.\", xmlFile.exists());\n\n\t\tString liferayLookAndFeelXML = FileUtil.read(xmlFile);\n\n\t\tAssert.assertNotNull(\n\t\t\t\"XML file content must not be null.\", liferayLookAndFeelXML);\n\n\t\tDocument document = SAXReaderUtil.read(liferayLookAndFeelXML, true);\n\n\t\tElement rootElement = document.getRootElement();\n\n\t\tElement element = rootElement.element(\"theme\");\n\n\t\tString value = element.attribute(\"name\").getValue();\n\n\t\tAssert.assertEquals(\"Test Theme EE\", value);\n\n\t\tvalue = element.attribute(\"id\").getValue();\n\n\t\tAssert.assertNotNull(value);\n\n\t\telement = rootElement.element(\"compatibility\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\t}","id":36599,"modified_method":"protected void validateLiferayLookAndFeelXMLFile(File xmlFile)\n\t\tthrows Exception {\n\n\t\tAssert.assertTrue(xmlFile.exists());\n\n\t\tString liferayLookAndFeelXML = FileUtil.read(xmlFile);\n\n\t\tAssert.assertNotNull(liferayLookAndFeelXML);\n\n\t\tDocument document = SAXReaderUtil.read(liferayLookAndFeelXML, true);\n\n\t\tElement rootElement = document.getRootElement();\n\n\t\tElement element = rootElement.element(\"theme\");\n\n\t\tString value = element.attributeValue(\"name\");\n\n\t\tAssert.assertEquals(\"Test Theme\", value);\n\n\t\tvalue = element.attributeValue(\"id\");\n\n\t\tAssert.assertNotNull(value);\n\n\t\telement = rootElement.element(\"compatibility\");\n\n\t\tAssert.assertNotNull(element);\n\n\t\tAssert.assertNotNull(element.getTextTrim());\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Map<String, String> processPluginPackageProperties()\n\t\tthrows Exception {\n\n\t\tString displayName = \"test-theme\";\n\n\t\tProperties properties = getLiferayPluginPackageProperties();\n\n\t\tPluginPackage pluginPackage =\n\t\t\tPluginPackageUtil.readPluginPackageProperties(\n\t\t\t\tdisplayName, properties);\n\n\t\tAssert.assertNotNull(pluginPackage);\n\n\t\tAssert.assertEquals(\"Test Theme EE\", pluginPackage.getName());\n\n\t\tDeployer themeDeployer = getDeployer();\n\n\t\tMap<String, String> filterMap =\n\t\t\tthemeDeployer.processPluginPackageProperties(\n\t\t\t\tgetRootDeploymentFolder(), displayName, pluginPackage);\n\n\t\tAssert.assertNotNull(\"FilterMap must not be null.\", filterMap);\n\n\t\tAssert.assertFalse(\"FilterMap must not be empty.\", filterMap.isEmpty());\n\n\t\treturn filterMap;\n\t}","id":36600,"modified_method":"protected Map<String, String> processPluginPackageProperties()\n\t\tthrows Exception {\n\n\t\tString displayName = \"test-theme\";\n\t\tProperties properties = getLiferayPluginPackageProperties();\n\n\t\tPluginPackage pluginPackage =\n\t\t\tPluginPackageUtil.readPluginPackageProperties(\n\t\t\t\tdisplayName, properties);\n\n\t\tAssert.assertNotNull(pluginPackage);\n\t\tAssert.assertEquals(\"Test Theme\", pluginPackage.getName());\n\n\t\tDeployer deployer = getDeployer();\n\n\t\tMap<String, String> filterMap = deployer.processPluginPackageProperties(\n\t\t\tgetRootDir(), displayName, pluginPackage);\n\n\t\tAssert.assertNotNull(filterMap);\n\t\tAssert.assertFalse(filterMap.isEmpty());\n\n\t\treturn filterMap;\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Test\n\tpublic void testProcessPluginPackageProperties() throws Exception {\n\n\t\tMap<String, String> filterMap = processPluginPackageProperties();\n\n\t\tAssert.assertNotNull(\"FilterMap must not be null.\", filterMap);\n\n\t\tAssert.assertFalse(\"FilterMap must not be empty.\", filterMap.isEmpty());\n\n\t\tFile xmlFile = new File(\n\t\t\tgetWebInfFolder(), \"liferay-plugin-package.xml\");\n\n\t\tvalidateLiferayPluginPackageXMLFile(xmlFile);\n\n\t\txmlFile = new File(getWebInfFolder(),\"liferay-look-and-feel.xml\");\n\n\t\tvalidateLiferayLookAndFeelXMLFile(xmlFile);\n\t}","id":36601,"modified_method":"@Test\n\tpublic void testProcessPluginPackageProperties() throws Exception {\n\t\tprocessPluginPackageProperties();\n\n\t\tFile xmlFile = new File(getWebInfDir(), \"liferay-plugin-package.xml\");\n\n\t\tvalidateLiferayPluginPackageXMLFile(xmlFile);\n\n\t\txmlFile = new File(getWebInfDir(),\"liferay-look-and-feel.xml\");\n\n\t\tvalidateLiferayLookAndFeelXMLFile(xmlFile);\n\t}","commit_id":"e98dfc90669fc996b05e7af1def570a6e34b1784","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\treturn Flags.isPublic(modifiers);\n\t\t}","id":36602,"modified_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\tif (isInternalClass(simpleTypeName, enclosingTypeNames)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn Flags.isPublic(modifiers);\n\t\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\treturn !Flags.isAbstract(modifiers) && !Flags.isInterface(modifiers);\n\t\t}","id":36603,"modified_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\tif (isInternalClass(simpleTypeName, enclosingTypeNames)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn !Flags.isAbstract(modifiers) && !Flags.isInterface(modifiers);\n\t\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\treturn true;\n\t\t}","id":36604,"modified_method":"public boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\tif (isInternalClass(simpleTypeName, enclosingTypeNames)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn true;\n\t\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeImport_ImportedType(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, Xtend2Package.Literals.XTEND_IMPORT__IMPORTED_TYPE, true,\n\t\t\t\tgetQualifiedNameValueConverter(), new ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.TYPE;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","id":36605,"modified_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeImport_ImportedType(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, Xtend2Package.Literals.XTEND_IMPORT__IMPORTED_TYPE, true,\n\t\t\t\tgetQualifiedNameValueConverter(), new TypeMatchFilters.All(IJavaSearchConstants.TYPE), acceptor);\n\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeClass_Extends(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, XbasePackage.Literals.XTYPE_LITERAL__TYPE, true, getQualifiedNameValueConverter(),\n\t\t\t\tnew ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.CLASS;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\treturn !Flags.isFinal(modifiers);\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","id":36606,"modified_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeClass_Extends(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, XbasePackage.Literals.XTYPE_LITERAL__TYPE, true, getQualifiedNameValueConverter(),\n\t\t\t\tnew ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.CLASS;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\tif (TypeMatchFilters.isInternalClass(simpleTypeName, enclosingTypeNames))\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\treturn !Flags.isFinal(modifiers);\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic void completeClass_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor);\n\t\tsuper.completeClass_Members(model, assignment, context, acceptor);\n\t}","id":36607,"modified_method":"@Override\n\tpublic void completeClass_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tif (\"\".equals(context.getPrefix()) && context.getLastCompleteNode().getTotalEndOffset() < context.getOffset())\n\t\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor);\n\t\tsuper.completeClass_Members(model, assignment, context, acceptor);\n\t}","commit_id":"152aac827f648bd749123844d16e24062fdca77b","url":"https://github.com/eclipse/xtext"},{"original_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeClass_Extends(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, XbasePackage.Literals.XTYPE_LITERAL__TYPE, true, getQualifiedNameValueConverter(),\n\t\t\t\tnew ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.CLASS;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\treturn !Flags.isFinal(modifiers);\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","id":36608,"modified_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeClass_Extends(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, XbasePackage.Literals.XTYPE_LITERAL__TYPE, true, getQualifiedNameValueConverter(),\n\t\t\t\tnew ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.CLASS;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\tif (TypeMatchFilters.isInternalClass(simpleTypeName, enclosingTypeNames))\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\treturn !Flags.isFinal(modifiers);\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","commit_id":"2c4a80f0e21a6cd8d29a331ecd3a9e56c06dafad","url":"https://github.com/eclipse/xtext"},{"original_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeImport_ImportedType(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, Xtend2Package.Literals.XTEND_IMPORT__IMPORTED_TYPE, true,\n\t\t\t\tgetQualifiedNameValueConverter(), new ITypesProposalProvider.Filter() {\n\t\t\t\t\tpublic int getSearchFor() {\n\t\t\t\t\t\treturn IJavaSearchConstants.TYPE;\n\t\t\t\t\t}\n\n\t\t\t\t\tpublic boolean accept(int modifiers, char[] packageName, char[] simpleTypeName,\n\t\t\t\t\t\t\tchar[][] enclosingTypeNames, String path) {\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}, acceptor);\n\t}","id":36609,"modified_method":"@SuppressWarnings(\"restriction\")\n\t@Override\n\tpublic void completeImport_ImportedType(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tcompleteJavaTypes(context, Xtend2Package.Literals.XTEND_IMPORT__IMPORTED_TYPE, true,\n\t\t\t\tgetQualifiedNameValueConverter(), new TypeMatchFilters.All(IJavaSearchConstants.TYPE), acceptor);\n\t}","commit_id":"2c4a80f0e21a6cd8d29a331ecd3a9e56c06dafad","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic void completeClass_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor);\n\t\tsuper.completeClass_Members(model, assignment, context, acceptor);\n\t}","id":36610,"modified_method":"@Override\n\tpublic void completeClass_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tif (\"\".equals(context.getPrefix()) && context.getLastCompleteNode().getTotalEndOffset() < context.getOffset())\n\t\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor);\n\t\tsuper.completeClass_Members(model, assignment, context, acceptor);\n\t}","commit_id":"2c4a80f0e21a6cd8d29a331ecd3a9e56c06dafad","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic void completeType_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tif (model instanceof XtendClass) {\n\t\t\tINode node = context.getCurrentNode();\n\t\t\tEObject eObject = NodeModelUtils.findActualSemanticObjectFor(node);\n\t\t\tif (!(eObject instanceof AnonymousClass))\n\t\t\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor, getConflictHelper());\n\t\t}\n\t\tsuper.completeType_Members(model, assignment, context, acceptor);\n\t}","id":36611,"modified_method":"@Override\n\tpublic void completeType_Members(EObject model, Assignment assignment, ContentAssistContext context,\n\t\t\tICompletionProposalAcceptor acceptor) {\n\t\tif (model instanceof XtendClass) {\n\t\t\tINode node = context.getCurrentNode();\n\t\t\tEObject eObject = NodeModelUtils.findActualSemanticObjectFor(node);\n\t\t\tif (!(eObject instanceof AnonymousClass)) {\n\t\t\t\t// due to some optimizations in the CA parser, we get some bogus context here and have to\n\t\t\t\t// double check that an override proposal would be valid at this location\n\t\t\t\t// see https://bugs.eclipse.org/bugs/show_bug.cgi?id=370955\n\t\t\t\tEObject prevModel = context.getPreviousModel();\n\t\t\t\tif (prevModel instanceof XExpression) {\n\t\t\t\t\tXtendMember containingMember = EcoreUtil2.getContainerOfType(prevModel, XtendMember.class);\n\t\t\t\t\tXBlockExpression blockExpression = EcoreUtil2.getContainerOfType(prevModel, XBlockExpression.class);\n\t\t\t\t\tif (blockExpression != null && blockExpression != prevModel) {\n\t\t\t\t\t\tif (EcoreUtil.isAncestor(containingMember, blockExpression)) { // still inside block\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\toverrideAssist.createOverrideProposals((XtendClass) model, context, acceptor, getConflictHelper());\n\t\t\t}\n\t\t}\n\t\tsuper.completeType_Members(model, assignment, context, acceptor);\n\t}","commit_id":"aca5ef3175207e4ff966b5e96565f5b6555f1926","url":"https://github.com/eclipse/xtext"},{"original_method":"private static boolean languageDialectChanged(final PsiFile newPsiFile) {\n    return ( newPsiFile.getLanguageDialect() != null && \n             newPsiFile.getLanguageDialect().getParserDefinition() != newPsiFile.getLanguage().getParserDefinition()\n           ) ||\n           ( newPsiFile.getLanguageDialect() == null &&\n             newPsiFile instanceof PsiFileBase &&\n             newPsiFile.getLanguage().getParserDefinition() == ((PsiFileBase)newPsiFile).getParserDefinition()\n           );\n  }","id":36612,"modified_method":"private static boolean languageDialectChanged(final PsiFile newPsiFile) {\n    return ( newPsiFile.getLanguageDialect() != null && \n             newPsiFile.getLanguageDialect().getParserDefinition().getClass() != newPsiFile.getLanguage().getParserDefinition().getClass()\n           ) ||\n           ( newPsiFile.getLanguageDialect() == null &&\n             newPsiFile instanceof PsiFileBase &&\n             newPsiFile.getLanguage().getParserDefinition().getClass() == ((PsiFileBase)newPsiFile).getParserDefinition().getClass()\n           );\n  }","commit_id":"912f58a3d026a5f976e7a5c5582ee2c70d08b821","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n     * {@inheritDoc}\n     */\n    protected ValidatorError processFormValues(HttpServletRequest request,\n            DynaActionForm form,\n            BaseKickstartCommand cmdIn) {\n\n        ValidatorError error = null;\n        KickstartEditCommand cmd = (KickstartEditCommand) cmdIn;\n        RequestContext ctx = new RequestContext(request);\n        KickstartBuilder builder = new KickstartBuilder(ctx.getLoggedInUser());\n        cmd.setComments(form.getString(COMMENTS));\n        try {\n\n\n            KickstartVirtualizationType vType =\n                KickstartFactory.lookupKickstartVirtualizationTypeByLabel(\n                    form.getString(VIRTUALIZATION_TYPE_LABEL));\n\n            Distro distro = CobblerProfileCommand.getCobblerDistroForVirtType(\n                    cmdIn.getKickstartData().getTree(), vType, ctx.getLoggedInUser());\n            if (distro == null) {\n                ValidatorException.raiseException(\"kickstart.cobbler.profile.invalidvirt\");\n            }\n\n\n            if (!cmdIn.getKickstartData().getLabel().equals(form.getString(LABEL))) {\n                builder.validateNewLabel(form.getString(LABEL));\n            }\n\n\n            cmd.setLabel(form.getString(LABEL));\n            cmd.setActive(new\n                    Boolean(BooleanUtils.toBoolean((Boolean) form.get(ACTIVE))));\n            cmd.setIsOrgDefault(new\n                    Boolean(BooleanUtils.toBoolean((Boolean) form.get(ORG_DEFAULT))));\n            cmd.getKickstartData().setPostLog(\n                    BooleanUtils.toBoolean((Boolean) form.get(POST_LOG)));\n            cmd.getKickstartData().setPreLog(\n                    BooleanUtils.toBoolean((Boolean) form.get(PRE_LOG)));\n            cmd.getKickstartData().setKsCfg(\n                    BooleanUtils.toBoolean((Boolean) form.get(KS_CFG)));\n\n            processCobblerFormValues(cmd.getKickstartData(), form, ctx.getLoggedInUser());\n\n            String virtTypeLabel = form.getString(VIRTUALIZATION_TYPE_LABEL);\n            KickstartVirtualizationType ksVirtType = KickstartFactory.\n                lookupKickstartVirtualizationTypeByLabel(virtTypeLabel);\n            if (ksVirtType == null) {\n                throw new InvalidVirtualizationTypeException(virtTypeLabel);\n            }\n            cmd.setVirtualizationType(ksVirtType);\n\n\n\n            return null;\n        }\n        catch (ValidatorException ve) {\n            return ve.getResult().getErrors().get(0);\n        }\n    }","id":36613,"modified_method":"/**\n     * {@inheritDoc}\n     */\n    protected ValidatorError processFormValues(HttpServletRequest request,\n            DynaActionForm form,\n            BaseKickstartCommand cmdIn) {\n\n        ValidatorError error = null;\n        KickstartEditCommand cmd = (KickstartEditCommand) cmdIn;\n        RequestContext ctx = new RequestContext(request);\n        KickstartBuilder builder = new KickstartBuilder(ctx.getLoggedInUser());\n        cmd.setComments(form.getString(COMMENTS));\n        try {\n\n\n            KickstartVirtualizationType vType =\n                KickstartFactory.lookupKickstartVirtualizationTypeByLabel(\n                    form.getString(VIRTUALIZATION_TYPE_LABEL));\n\n            Distro distro = CobblerProfileCommand.getCobblerDistroForVirtType(\n                    cmdIn.getKickstartData().getTree(), vType, ctx.getLoggedInUser());\n            if (distro == null) {\n                ValidatorException.raiseException(\"kickstart.cobbler.profile.invalidvirt\");\n            }\n\n\n            if (!cmdIn.getKickstartData().getLabel().equals(form.getString(LABEL))) {\n                builder.validateNewLabel(form.getString(LABEL));\n            }\n\n\n            cmd.setLabel(form.getString(LABEL));\n            cmd.setActive(Boolean.valueOf(\n                    BooleanUtils.toBoolean((Boolean) form.get(ACTIVE))));\n            cmd.setIsOrgDefault(Boolean.valueOf(\n                    BooleanUtils.toBoolean((Boolean) form.get(ORG_DEFAULT))));\n            cmd.getKickstartData().setPostLog(\n                    BooleanUtils.toBoolean((Boolean) form.get(POST_LOG)));\n            cmd.getKickstartData().setPreLog(\n                    BooleanUtils.toBoolean((Boolean) form.get(PRE_LOG)));\n            cmd.getKickstartData().setKsCfg(\n                    BooleanUtils.toBoolean((Boolean) form.get(KS_CFG)));\n\n            processCobblerFormValues(cmd.getKickstartData(), form, ctx.getLoggedInUser());\n\n            String virtTypeLabel = form.getString(VIRTUALIZATION_TYPE_LABEL);\n            KickstartVirtualizationType ksVirtType = KickstartFactory.\n                lookupKickstartVirtualizationTypeByLabel(virtTypeLabel);\n            if (ksVirtType == null) {\n                throw new InvalidVirtualizationTypeException(virtTypeLabel);\n            }\n            cmd.setVirtualizationType(ksVirtType);\n\n\n\n            return null;\n        }\n        catch (ValidatorException ve) {\n            return ve.getResult().getErrors().get(0);\n        }\n    }","commit_id":"db7b5b4c6c7f6fef57d64dc5072cc8bacbe1dfeb","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"private Boolean parseOptional(Element simpleType) {\n        Element child;\n        Boolean optional = Boolean.FALSE;\n        child = simpleType.getChild(\"optional\", schemaNamespace);\n        if (child != null) {\n            String value = child.getAttributeValue(\"value\");\n            if (value == null) {\n                // <optional/> consider as true\n                optional = Boolean.TRUE;\n            }\n            else {\n                optional = new Boolean(value);\n            }\n        }\n        return optional;\n    }","id":36614,"modified_method":"private Boolean parseOptional(Element simpleType) {\n        Element child;\n        Boolean optional = Boolean.FALSE;\n        child = simpleType.getChild(\"optional\", schemaNamespace);\n        if (child != null) {\n            String value = child.getAttributeValue(\"value\");\n            if (value == null) {\n                // <optional/> consider as true\n                optional = Boolean.TRUE;\n            }\n            else {\n                optional = Boolean.valueOf(value);\n            }\n        }\n        return optional;\n    }","commit_id":"db7b5b4c6c7f6fef57d64dc5072cc8bacbe1dfeb","url":"https://github.com/spacewalkproject/spacewalk"},{"original_method":"/**\n     * @see org.apache.sling.api.resource.ModifyingResourceProvider#create(org.apache.sling.api.resource.ResourceResolver, java.lang.String, java.util.Map)\n     */\n    public Resource create(final ResourceResolver resolver,\n            final String path,\n            final Map<String, Object> properties)\n    throws PersistenceException {\n        // check if the resource exists\n        final Resource mountResource = this.getResource(resolver, path);\n        if ( mountResource != null ) {\n            throw new PersistenceException(\"Resource at \" + path + \" already exists.\", null, path, null);\n        }\n        // creation of the root mount resource is not supported\n        final String relativePath = getRelativePath(path);\n        if ( relativePath == null || relativePath.length() == 0 ) {\n            throw new PersistenceException(\"Resource at \" + path + \" can't be created.\", null, path, null);\n        }\n\n        final ExtendedResourceHolder holder = this.getAllResources(resolver, path, relativePath);\n        // we only support modifications if there is more than one location merged\n        if ( holder.count < 2 ) {\n            throw new PersistenceException(\"Modifying is only supported with at least two potentially merged resources.\", null, path, null);\n        }\n        if ( holder.resources.size() == 0\n             || (holder.resources.size() < holder.count && !holder.resources.get(holder.resources.size() - 1).getPath().equals(holder.highestResourcePath) )) {\n            final String createPath = holder.highestResourcePath;\n            final Resource parentResource = ResourceUtil.getOrCreateResource(resolver, ResourceUtil.getParent(createPath), (String)null, null, false);\n            resolver.create(parentResource, ResourceUtil.getName(createPath), properties);\n        } else {\n            final Resource hidingResource = resolver.getResource(holder.highestResourcePath);\n            if ( hidingResource != null ) {\n                final ModifiableValueMap mvm = hidingResource.adaptTo(ModifiableValueMap.class);\n                mvm.remove(MergedResourceConstants.PN_HIDE_RESOURCE);\n                mvm.putAll(properties);\n            }\n            // TODO check parent hiding\n        }\n        return this.getResource(resolver, path);\n    }","id":36615,"modified_method":"@Override\n    public Resource create(final ResolveContext<Void> ctx, final String path, final Map<String, Object> properties) throws PersistenceException {\n        final ResourceResolver resolver = ctx.getResourceResolver();\n\n        // check if the resource exists\n        final Resource mountResource = this.getResource(ctx, path, null);\n        if ( mountResource != null ) {\n            throw new PersistenceException(\"Resource at \" + path + \" already exists.\", null, path, null);\n        }\n        // creation of the root mount resource is not supported\n        final String relativePath = getRelativePath(path);\n        if ( relativePath == null || relativePath.length() == 0 ) {\n            throw new PersistenceException(\"Resource at \" + path + \" can't be created.\", null, path, null);\n        }\n\n        final ExtendedResourceHolder holder = this.getAllResources(resolver, path, relativePath);\n        // we only support modifications if there is more than one location merged\n        if ( holder.count < 2 ) {\n            throw new PersistenceException(\"Modifying is only supported with at least two potentially merged resources.\", null, path, null);\n        }\n        if ( holder.resources.size() == 0\n             || (holder.resources.size() < holder.count && !holder.resources.get(holder.resources.size() - 1).getPath().equals(holder.highestResourcePath) )) {\n            final String createPath = holder.highestResourcePath;\n            final Resource parentResource = ResourceUtil.getOrCreateResource(resolver, ResourceUtil.getParent(createPath), (String)null, null, false);\n            resolver.create(parentResource, ResourceUtil.getName(createPath), properties);\n        } else {\n            final Resource hidingResource = resolver.getResource(holder.highestResourcePath);\n            if ( hidingResource != null ) {\n                final ModifiableValueMap mvm = hidingResource.adaptTo(ModifiableValueMap.class);\n                mvm.remove(MergedResourceConstants.PN_HIDE_RESOURCE);\n                mvm.putAll(properties);\n            }\n            // TODO check parent hiding\n        }\n        return this.getResource(ctx, path, null);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"/**\n     * Constructor\n     *\n     * @param resolver      Resource resolver\n     * @param mergeRootPath   Merge root path\n     * @param relativePath    Relative path\n     * @param mappedResources List of physical mapped resources' paths\n     */\n    MergedResource(final ResourceResolver resolver,\n                   final String mergeRootPath,\n                   final String relativePath,\n                   final List<Resource> mappedResources,\n                   final List<ValueMap> valueMaps) {\n        this.resolver = resolver;\n        this.path = (relativePath.length() == 0 ? mergeRootPath : mergeRootPath + \"/\" + relativePath);\n        this.properties = new DeepReadValueMapDecorator(this, new MergedValueMap(valueMaps));\n        // get resource type\n        final String slingPropRT = this.properties.get(ResourceResolver.PROPERTY_RESOURCE_TYPE, String.class);\n        String rt = slingPropRT;\n        if (rt == null) {\n            rt = relativePath.length() == 0 ? \"/\" : relativePath;\n        }\n        // use the resource type of the last resource in the set that provides one\n        for(final Resource rsrc : mappedResources) {\n            final String value = rsrc.getResourceType();\n            if ( value != null ) {\n                rt = value;\n            }\n        }\n        this.resourceType = rt;\n        if ( !rt.equals(slingPropRT) ) {\n            this.resourceSuperType = slingPropRT;\n        } else {\n            this.resourceSuperType = null;\n        }\n        metadata.put(MergedResourceConstants.METADATA_FLAG, true);\n        final String[] resourcePaths = new String[mappedResources.size()];\n        int i = 0;\n        for(final Resource rsrc : mappedResources) {\n            resourcePaths[i] = rsrc.getPath();\n            i++;\n        }\n        metadata.put(MergedResourceConstants.METADATA_RESOURCES, resourcePaths);\n    }","id":36616,"modified_method":"/**\n     * Constructor\n     *\n     * @param resolver      Resource resolver\n     * @param mergeRootPath   Merge root path\n     * @param relativePath    Relative path\n     * @param mappedResources List of physical mapped resources' paths\n     */\n    MergedResource(final ResourceResolver resolver,\n                   final String mergeRootPath,\n                   final String relativePath,\n                   final List<Resource> mappedResources,\n                   final List<ValueMap> valueMaps) {\n        this.resolver = resolver;\n        this.path = (relativePath.length() == 0 ? mergeRootPath : mergeRootPath + \"/\" + relativePath);\n        this.mappedResources = mappedResources;\n        this.properties = new DeepReadValueMapDecorator(this, new MergedValueMap(valueMaps));\n        // get resource type\n        final String slingPropRT = this.properties.get(ResourceResolver.PROPERTY_RESOURCE_TYPE, String.class);\n        String rt = slingPropRT;\n        if (rt == null) {\n            rt = relativePath.length() == 0 ? \"/\" : relativePath;\n        }\n        // use the resource type of the last resource in the set that provides one\n        for(final Resource rsrc : mappedResources) {\n            final String value = rsrc.getResourceType();\n            if ( value != null ) {\n                rt = value;\n            }\n        }\n        this.resourceType = rt;\n        if ( !rt.equals(slingPropRT) ) {\n            this.resourceSuperType = slingPropRT;\n        } else {\n            this.resourceSuperType = null;\n        }\n        metadata.put(MergedResourceConstants.METADATA_FLAG, true);\n        final String[] resourcePaths = new String[mappedResources.size()];\n        int i = 0;\n        for(final Resource rsrc : mappedResources) {\n            resourcePaths[i] = rsrc.getPath();\n            i++;\n        }\n        metadata.put(MergedResourceConstants.METADATA_RESOURCES, resourcePaths);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"public Object addingService(final ServiceReference reference) {\n        final MergedResourcePicker picker = (MergedResourcePicker) bundleContext.getService(reference);\n        if ( picker != null ) {\n            final String mergeRoot = PropertiesUtil.toString(reference.getProperty(MergedResourcePicker.MERGE_ROOT), null);\n            if (mergeRoot != null) {\n                final ResourceProviderFactory providerFactory = new MergingResourceProviderFactory(mergeRoot, picker,\n                        PropertiesUtil.toBoolean(reference.getProperty(MergedResourcePicker.READ_ONLY), true),\n                        PropertiesUtil.toBoolean(reference.getProperty(MergedResourcePicker.TRAVERSE_PARENT), false));\n                final Dictionary<Object, Object> props = new Hashtable<Object, Object>();\n                props.put(ResourceProvider.ROOTS, mergeRoot);\n                props.put(ResourceProvider.OWNS_ROOTS, true);\n\n                final Long key = (Long) reference.getProperty(Constants.SERVICE_ID);\n                final ServiceRegistration reg = bundleContext.registerService(ResourceProviderFactory.class.getName(), providerFactory, props);\n\n                serviceRegistrations.put(key, reg);\n\n            }\n            return picker;\n        }\n        return null;\n    }","id":36617,"modified_method":"public Object addingService(final ServiceReference reference) {\n        final MergedResourcePicker picker = (MergedResourcePicker) bundleContext.getService(reference);\n        if ( picker != null ) {\n            final String mergeRoot = PropertiesUtil.toString(reference.getProperty(MergedResourcePicker.MERGE_ROOT), null);\n            if (mergeRoot != null) {\n                boolean readOnly = PropertiesUtil.toBoolean(reference.getProperty(MergedResourcePicker.READ_ONLY), true);\n                boolean traverseParent = PropertiesUtil.toBoolean(reference.getProperty(MergedResourcePicker.TRAVERSE_PARENT), false);\n\n                MergingResourceProvider provider = readOnly ?\n                        new MergingResourceProvider(mergeRoot, picker, true, traverseParent) :\n                        new CRUDMergingResourceProvider(mergeRoot, picker, traverseParent);\n\n                final Dictionary<Object, Object> props = new Hashtable<Object, Object>();\n                props.put(ResourceProvider.PROPERTY_NAME, readOnly ? \"Merging\" : \"CRUDMerging\");\n                props.put(ResourceProvider.PROPERTY_ROOT, mergeRoot);\n                props.put(ResourceProvider.PROPERTY_MODIFIABLE, !readOnly);\n                props.put(ResourceProvider.PROPERTY_AUTHENTICATE, ResourceProvider.AUTHENTICATE_NO);\n\n                final Long key = (Long) reference.getProperty(Constants.SERVICE_ID);\n                final ServiceRegistration reg = bundleContext.registerService(ResourceProvider.class.getName(), provider, props);\n\n                serviceRegistrations.put(key, reg);\n            }\n            return picker;\n        }\n        return null;\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testResourceType() {\n        // a/2 defines the property and it's overlayed\n        final Resource rsrcA2 = this.provider.getResource(this.resolver, \"/merged/a/2\");\n        assertEquals(\"apps\", rsrcA2.getResourceType());\n\n        // a/12 doesn't define the property and it's overlayed\n        final Resource rsrcA1 = this.provider.getResource(this.resolver, \"/merged/a/1\");\n        assertEquals(\"a/1\", rsrcA1.getResourceType());\n\n    }","id":36618,"modified_method":"@Test public void testResourceType() {\n        // a/2 defines the property and it's overlayed\n        final Resource rsrcA2 = this.provider.getResource(ctx, \"/merged/a/2\", null);\n        assertEquals(\"apps\", rsrcA2.getResourceType());\n\n        // a/12 doesn't define the property and it's overlayed\n        final Resource rsrcA1 = this.provider.getResource(ctx, \"/merged/a/1\", null);\n        assertEquals(\"a/1\", rsrcA1.getResourceType());\n\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testSimpleCreateAndDelete() throws PersistenceException {\n        final String path = \"/merged/a/new\";\n        try {\n            final Resource rsrc = this.provider.create(this.resolver, path, Collections.singletonMap(\"foo\", (Object)\"bla\"));\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n            final ValueMap vm = ResourceUtil.getValueMap(rsrc);\n            assertEquals(\"bla\", vm.get(\"foo\"));\n\n            final Resource realResource = this.resolver.getResource(\"/apps/a/new\");\n            assertNotNull(realResource);\n            final ValueMap vmReal = ResourceUtil.getValueMap(realResource);\n            assertEquals(\"bla\", vmReal.get(\"foo\"));\n            assertNull(this.resolver.getResource(\"/libs/a/new\"));\n\n            this.provider.delete(this.resolver, path);\n            assertNull(this.provider.getResource(this.resolver, path));\n            assertNull(this.resolver.getResource(\"/libs/a/new\"));\n            assertNull(this.resolver.getResource(\"/apps/a/new\"));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","id":36619,"modified_method":"@Test public void testSimpleCreateAndDelete() throws PersistenceException {\n        final String path = \"/merged/a/new\";\n        try {\n            final Resource rsrc = this.provider.create(ctx, path, Collections.singletonMap(\"foo\", (Object)\"bla\"));\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n            final ValueMap vm = ResourceUtil.getValueMap(rsrc);\n            assertEquals(\"bla\", vm.get(\"foo\"));\n\n            final Resource realResource = this.resolver.getResource(\"/apps/a/new\");\n            assertNotNull(realResource);\n            final ValueMap vmReal = ResourceUtil.getValueMap(realResource);\n            assertEquals(\"bla\", vmReal.get(\"foo\"));\n            assertNull(this.resolver.getResource(\"/libs/a/new\"));\n\n            this.provider.delete(ctx, rsrc);\n            assertNull(this.provider.getResource(ctx, path, null));\n            assertNull(this.resolver.getResource(\"/libs/a/new\"));\n            assertNull(this.resolver.getResource(\"/apps/a/new\"));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testHideProperties() {\n        final Resource rsrcA4 = this.provider.getResource(this.resolver, \"/merged/a/4\");\n        final ValueMap vm = rsrcA4.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size());\n        assertEquals(\"1\", vm.get(\"d\"));\n        assertEquals(\"2\", vm.get(\"e\"));\n        assertEquals(\"x\", vm.get(\"b\"));\n    }","id":36620,"modified_method":"@Test public void testHideProperties() {\n        final Resource rsrcA4 = this.provider.getResource(ctx, \"/merged/a/4\", null);\n        final ValueMap vm = rsrcA4.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size());\n        assertEquals(\"1\", vm.get(\"d\"));\n        assertEquals(\"2\", vm.get(\"e\"));\n        assertEquals(\"x\", vm.get(\"b\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testClearProperties() {\n        final Resource rsrcA3 = this.provider.getResource(this.resolver, \"/merged/a/3\");\n        final ValueMap vm = rsrcA3.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(0, vm.size());\n    }","id":36621,"modified_method":"@Test public void testClearProperties() {\n        final Resource rsrcA3 = this.provider.getResource(ctx, \"/merged/a/3\", null);\n        final ValueMap vm = rsrcA3.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(0, vm.size());\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testDeleteByHidingAndCreate() throws PersistenceException {\n        final String path = \"/merged/deleteTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            assertNull(this.resolver.getResource(\"/apps/deleteTest\"));\n\n            final Resource rsrc = this.provider.getResource(this.resolver, path);\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n\n            this.provider.delete(this.resolver, path);\n            this.provider.create(this.resolver, path, Collections.singletonMap(\"foo\", (Object)\"bla\"));\n\n            assertNotNull(this.provider.getResource(this.resolver, path));\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            final Resource hidingRsrc = this.resolver.getResource(\"/apps/deleteTest\");\n            assertNotNull(hidingRsrc);\n            final ValueMap vm = hidingRsrc.getValueMap();\n            assertEquals(\"bla\", vm.get(\"foo\"));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","id":36622,"modified_method":"@Test public void testDeleteByHidingAndCreate() throws PersistenceException {\n        final String path = \"/merged/deleteTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            assertNull(this.resolver.getResource(\"/apps/deleteTest\"));\n\n            final Resource rsrc = this.provider.getResource(ctx, path, null);\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n\n            this.provider.delete(ctx, rsrc);\n            this.provider.create(ctx, path, Collections.singletonMap(\"foo\", (Object)\"bla\"));\n\n            assertNotNull(this.provider.getResource(ctx, path, null));\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            final Resource hidingRsrc = this.resolver.getResource(\"/apps/deleteTest\");\n            assertNotNull(hidingRsrc);\n            final ValueMap vm = hidingRsrc.getValueMap();\n            assertEquals(\"bla\", vm.get(\"foo\"));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testListSubChildren() {\n        final Resource rsrcY = this.provider.getResource(this.resolver, \"/merged/a/Y\");\n        assertNotNull(rsrcY);\n        final Iterator<Resource> i = this.provider.listChildren(rsrcY);\n        assertNotNull(i);\n        final List<String> names = new ArrayList<String>();\n        while ( i.hasNext() ) {\n            names.add(i.next().getName());\n        }\n        assertEquals(3, names.size());\n        assertTrue(names.contains(\"a\"));\n        assertTrue(names.contains(\"b\"));\n        assertTrue(names.contains(\"c\"));\n    }","id":36623,"modified_method":"@Test public void testListSubChildren() {\n        final Resource rsrcY = this.provider.getResource(ctx, \"/merged/a/Y\", null);\n        assertNotNull(rsrcY);\n        final Iterator<Resource> i = this.provider.listChildren(ctx, rsrcY);\n        assertNotNull(i);\n        final List<String> names = new ArrayList<String>();\n        while ( i.hasNext() ) {\n            names.add(i.next().getName());\n        }\n        assertEquals(3, names.size());\n        assertTrue(names.contains(\"a\"));\n        assertTrue(names.contains(\"b\"));\n        assertTrue(names.contains(\"c\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Before public void setup() throws Exception {\n        final MockResourceResolverFactoryOptions options = new MockResourceResolverFactoryOptions();\n        options.setSearchPaths(new String[] {\"/apps/\", \"/libs/\"});\n        final ResourceResolverFactory factory = new MockResourceResolverFactory(options);\n        this.resolver = factory.getResourceResolver(null);\n        MockHelper.create(this.resolver).resource(\"/apps\")\n                                          .resource(\"a\").p(MergedResourceConstants.PN_HIDE_CHILDREN, new String[] {\"Z\", \"x\", \"y\"})\n                                            .resource(\"1\").p(\"a\", \"1\").p(\"b\", \"2\")\n                                            .resource(\".2\").p(ResourceResolver.PROPERTY_RESOURCE_TYPE, \"apps\")\n                                            .resource(\".3\").p(\"e\", \"2\")\n                                                           .p(MergedResourceConstants.PN_HIDE_PROPERTIES, \"*\")\n                                                           .p(\"b\", \"x\")\n                                                           .p(\"d\", \"1\")\n                                            .resource(\".4\").p(\"e\", \"2\")\n                                                           .p(MergedResourceConstants.PN_HIDE_PROPERTIES, new String[] {\"a\", \"c\"})\n                                                           .p(\"b\", \"x\")\n                                                           .p(\"d\", \"1\")\n                                            .resource(\".X\")\n                                        .resource(\"/libs\")\n                                          .resource(\"deleteTest\")\n                                          .resource(\".mvmTest\").p(\"a\", \"1\").p(\"b\", \"2\")\n                                          .resource(\".a\")\n                                            .resource(\"1\").p(\"a\", \"5\").p(\"c\", \"2\")\n                                            .resource(\".2\").p(ResourceResolver.PROPERTY_RESOURCE_TYPE, \"libs\")\n                                            .resource(\".3\").p(\"a\", \"1\").p(\"b\", \"2\").p(\"c\", \"3\")\n                                            .resource(\".4\").p(\"a\", \"1\").p(\"b\", \"2\").p(\"c\", \"3\")\n                                            .resource(\".Y\")\n                                            .resource(\".Z\")\n                                          .resource(\"/libs/a/Y/a\")\n                                          .resource(\"/libs/a/Y/b\")\n                                          .resource(\"/libs/a/Y/c\")\n                                        .commit();\n\n        this.provider = new CRUDMergingResourceProvider(\"/merged\", new MergingResourcePicker(), false);\n    }","id":36624,"modified_method":"@Before public void setup() throws Exception {\n        final MockResourceResolverFactoryOptions options = new MockResourceResolverFactoryOptions();\n        options.setSearchPaths(new String[] {\"/apps/\", \"/libs/\"});\n        final ResourceResolverFactory factory = new MockResourceResolverFactory(options);\n        this.resolver = factory.getResourceResolver(null);\n        MockHelper.create(this.resolver).resource(\"/apps\")\n                                          .resource(\"a\").p(MergedResourceConstants.PN_HIDE_CHILDREN, new String[] {\"Z\", \"x\", \"y\"})\n                                            .resource(\"1\").p(\"a\", \"1\").p(\"b\", \"2\")\n                                            .resource(\".2\").p(ResourceResolver.PROPERTY_RESOURCE_TYPE, \"apps\")\n                                            .resource(\".3\").p(\"e\", \"2\")\n                                                           .p(MergedResourceConstants.PN_HIDE_PROPERTIES, \"*\")\n                                                           .p(\"b\", \"x\")\n                                                           .p(\"d\", \"1\")\n                                            .resource(\".4\").p(\"e\", \"2\")\n                                                           .p(MergedResourceConstants.PN_HIDE_PROPERTIES, new String[] {\"a\", \"c\"})\n                                                           .p(\"b\", \"x\")\n                                                           .p(\"d\", \"1\")\n                                            .resource(\".X\")\n                                          .resource(\"/apps/b\").resource(\"c\").resource(\"d\").resource(\"e\").resource(\"f\")\n                                        .resource(\"/libs\")\n                                          .resource(\"deleteTest\")\n                                          .resource(\".mvmTest\").p(\"a\", \"1\").p(\"b\", \"2\")\n                                          .resource(\".a\")\n                                            .resource(\"1\").p(\"a\", \"5\").p(\"c\", \"2\")\n                                            .resource(\".2\").p(ResourceResolver.PROPERTY_RESOURCE_TYPE, \"libs\")\n                                            .resource(\".3\").p(\"a\", \"1\").p(\"b\", \"2\").p(\"c\", \"3\")\n                                            .resource(\".4\").p(\"a\", \"1\").p(\"b\", \"2\").p(\"c\", \"3\")\n                                            .resource(\".Y\")\n                                            .resource(\".Z\")\n                                          .resource(\"/libs/a/Y/a\")\n                                          .resource(\"/libs/a/Y/b\")\n                                          .resource(\"/libs/a/Y/c\")\n                                          .resource(\"/libs/b\").resource(\"c\").resource(\"d\").resource(\"e\").resource(\"f\")\n                                        .commit();\n\n        this.provider = new CRUDMergingResourceProvider(\"/merged\", new MergingResourcePicker(), false);\n        this.ctx = new BasicResolveContext(resolver, Collections.<String, String>emptyMap(), null);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testDeleteByHiding() throws PersistenceException {\n        final String path = \"/merged/deleteTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            assertNull(this.resolver.getResource(\"/apps/deleteTest\"));\n\n            final Resource rsrc = this.provider.getResource(this.resolver, path);\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n\n            this.provider.delete(this.resolver, path);\n\n            assertNull(this.provider.getResource(this.resolver, path));\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            final Resource hidingRsrc = this.resolver.getResource(\"/apps/deleteTest\");\n            assertNotNull(hidingRsrc);\n            final ValueMap vm = hidingRsrc.getValueMap();\n            assertEquals(Boolean.TRUE, vm.get(MergedResourceConstants.PN_HIDE_RESOURCE));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","id":36625,"modified_method":"@Test public void testDeleteByHiding() throws PersistenceException {\n        final String path = \"/merged/deleteTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            assertNull(this.resolver.getResource(\"/apps/deleteTest\"));\n\n            final Resource rsrc = this.provider.getResource(ctx, path, null);\n            assertNotNull(rsrc);\n            assertEquals(path, rsrc.getPath());\n\n            this.provider.delete(ctx, rsrc);\n\n            assertNull(this.provider.getResource(ctx, path, null));\n            assertNotNull(this.resolver.getResource(\"/libs/deleteTest\"));\n            final Resource hidingRsrc = this.resolver.getResource(\"/apps/deleteTest\");\n            assertNotNull(hidingRsrc);\n            final ValueMap vm = hidingRsrc.getValueMap();\n            assertEquals(Boolean.TRUE, vm.get(MergedResourceConstants.PN_HIDE_RESOURCE));\n\n        } finally {\n            this.resolver.revert();\n        }\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testListChildren() {\n        final Resource rsrcA = this.provider.getResource(this.resolver, \"/merged/a\");\n        assertNotNull(rsrcA);\n        final Iterator<Resource> i = this.provider.listChildren(rsrcA);\n        assertNotNull(i);\n        final List<String> names = new ArrayList<String>();\n        while ( i.hasNext() ) {\n            names.add(i.next().getName());\n        }\n        assertEquals(6, names.size());\n        assertTrue(names.contains(\"1\"));\n        assertTrue(names.contains(\"2\"));\n        assertTrue(names.contains(\"3\"));\n        assertTrue(names.contains(\"4\"));\n        assertTrue(names.contains(\"Y\"));\n        assertTrue(names.contains(\"X\"));\n    }","id":36626,"modified_method":"@Test public void testListChildren() {\n        final Resource rsrcA = this.provider.getResource(ctx, \"/merged/a\", null);\n        assertNotNull(rsrcA);\n        final Iterator<Resource> i = this.provider.listChildren(ctx, rsrcA);\n        assertNotNull(i);\n        final List<String> names = new ArrayList<String>();\n        while ( i.hasNext() ) {\n            names.add(i.next().getName());\n        }\n        assertEquals(6, names.size());\n        assertTrue(names.contains(\"1\"));\n        assertTrue(names.contains(\"2\"));\n        assertTrue(names.contains(\"3\"));\n        assertTrue(names.contains(\"4\"));\n        assertTrue(names.contains(\"Y\"));\n        assertTrue(names.contains(\"X\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testHideChildren() {\n        // check preconditions in libs and apps\n        assertNotNull(this.resolver.getResource(\"/libs/a/Z\"));\n        assertNull(this.resolver.getResource(\"/libs/a/X\"));\n        assertNotNull(this.resolver.getResource(\"/libs/a/Y\"));\n        assertNull(this.resolver.getResource(\"/libs/a/x\"));\n        assertNull(this.resolver.getResource(\"/libs/a/y\"));\n        assertNull(this.resolver.getResource(\"/apps/a/Z\"));\n        assertNotNull(this.resolver.getResource(\"/apps/a/X\"));\n        assertNull(this.resolver.getResource(\"/apps/a/Y\"));\n        assertNull(this.resolver.getResource(\"/apps/a/x\"));\n        assertNull(this.resolver.getResource(\"/apps/a/y\"));\n\n        // now do the real checks\n        assertNull(this.provider.getResource(this.resolver, \"/merged/a/Z\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/merged/a/Y\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/merged/a/X\"));\n        assertNull(this.provider.getResource(this.resolver, \"/merged/a/x\"));\n        assertNull(this.provider.getResource(this.resolver, \"/merged/a/y\"));\n    }","id":36627,"modified_method":"@Test public void testHideChildren() {\n        // check preconditions in libs and apps\n        assertNotNull(this.resolver.getResource(\"/libs/a/Z\"));\n        assertNull(this.resolver.getResource(\"/libs/a/X\"));\n        assertNotNull(this.resolver.getResource(\"/libs/a/Y\"));\n        assertNull(this.resolver.getResource(\"/libs/a/x\"));\n        assertNull(this.resolver.getResource(\"/libs/a/y\"));\n        assertNull(this.resolver.getResource(\"/apps/a/Z\"));\n        assertNotNull(this.resolver.getResource(\"/apps/a/X\"));\n        assertNull(this.resolver.getResource(\"/apps/a/Y\"));\n        assertNull(this.resolver.getResource(\"/apps/a/x\"));\n        assertNull(this.resolver.getResource(\"/apps/a/y\"));\n\n        // now do the real checks\n        assertNull(this.provider.getResource(ctx, \"/merged/a/Z\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/merged/a/Y\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/merged/a/X\", null));\n        assertNull(this.provider.getResource(ctx, \"/merged/a/x\", null));\n        assertNull(this.provider.getResource(ctx, \"/merged/a/y\", null));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testModifiableValueMap() throws PersistenceException {\n        final String path = \"/merged/mvmTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/mvmTest\"));\n            assertNull(this.resolver.getResource(\"/apps/mvmTest\"));\n\n            final Resource rsrc = this.provider.getResource(this.resolver, path);\n            assertNotNull(rsrc);\n            final ValueMap beforeVM = rsrc.getValueMap();\n            assertEquals(\"1\", beforeVM.get(\"a\"));\n            assertEquals(\"2\", beforeVM.get(\"b\"));\n\n            final ModifiableValueMap mvm = rsrc.adaptTo(ModifiableValueMap.class);\n            assertNotNull(mvm);\n            assertEquals(\"1\", mvm.get(\"a\"));\n            assertEquals(\"2\", mvm.get(\"b\"));\n\n            mvm.put(\"c\", \"3\");\n            mvm.remove(\"a\");\n\n            assertNotNull(this.resolver.getResource(\"/libs/mvmTest\"));\n            assertNotNull(this.resolver.getResource(\"/apps/mvmTest\"));\n\n            final Resource rsrc2 = this.provider.getResource(this.resolver, path);\n            assertNotNull(rsrc2);\n            final ValueMap afterVM = rsrc2.getValueMap();\n            assertNull(afterVM.get(\"a\"));\n            assertEquals(\"2\", afterVM.get(\"b\"));\n            assertEquals(\"3\", afterVM.get(\"c\"));\n\n            final Resource rsrcL = this.resolver.getResource(\"/libs/mvmTest\");\n            assertEquals(\"1\", rsrcL.getValueMap().get(\"a\"));\n            assertEquals(\"2\", rsrcL.getValueMap().get(\"b\"));\n            assertNull(rsrcL.getValueMap().get(\"c\"));\n\n            final Resource rsrcA = this.resolver.getResource(\"/apps/mvmTest\");\n            assertNull(rsrcA.getValueMap().get(\"a\"));\n            assertNull(rsrcA.getValueMap().get(\"b\"));\n            assertEquals(\"3\", rsrcA.getValueMap().get(\"c\"));\n            final String[] hidden = rsrcA.getValueMap().get(MergedResourceConstants.PN_HIDE_PROPERTIES, String[].class);\n            assertNotNull(hidden);\n            assertEquals(1, hidden.length);\n            assertEquals(\"a\", hidden[0]);\n\n        } finally {\n            this.resolver.revert();\n        }\n\n    }","id":36628,"modified_method":"@Test public void testModifiableValueMap() throws PersistenceException {\n        final String path = \"/merged/mvmTest\";\n        try {\n            assertNotNull(this.resolver.getResource(\"/libs/mvmTest\"));\n            assertNull(this.resolver.getResource(\"/apps/mvmTest\"));\n\n            final Resource rsrc = this.provider.getResource(ctx, path, null);\n            assertNotNull(rsrc);\n            final ValueMap beforeVM = rsrc.getValueMap();\n            assertEquals(\"1\", beforeVM.get(\"a\"));\n            assertEquals(\"2\", beforeVM.get(\"b\"));\n\n            final ModifiableValueMap mvm = rsrc.adaptTo(ModifiableValueMap.class);\n            assertNotNull(mvm);\n            assertEquals(\"1\", mvm.get(\"a\"));\n            assertEquals(\"2\", mvm.get(\"b\"));\n\n            mvm.put(\"c\", \"3\");\n            mvm.remove(\"a\");\n\n            assertNotNull(this.resolver.getResource(\"/libs/mvmTest\"));\n            assertNotNull(this.resolver.getResource(\"/apps/mvmTest\"));\n\n            final Resource rsrc2 = this.provider.getResource(ctx, path, null);\n            assertNotNull(rsrc2);\n            final ValueMap afterVM = rsrc2.getValueMap();\n            assertNull(afterVM.get(\"a\"));\n            assertEquals(\"2\", afterVM.get(\"b\"));\n            assertEquals(\"3\", afterVM.get(\"c\"));\n\n            final Resource rsrcL = this.resolver.getResource(\"/libs/mvmTest\");\n            assertEquals(\"1\", rsrcL.getValueMap().get(\"a\"));\n            assertEquals(\"2\", rsrcL.getValueMap().get(\"b\"));\n            assertNull(rsrcL.getValueMap().get(\"c\"));\n\n            final Resource rsrcA = this.resolver.getResource(\"/apps/mvmTest\");\n            assertNull(rsrcA.getValueMap().get(\"a\"));\n            assertNull(rsrcA.getValueMap().get(\"b\"));\n            assertEquals(\"3\", rsrcA.getValueMap().get(\"c\"));\n            final String[] hidden = rsrcA.getValueMap().get(MergedResourceConstants.PN_HIDE_PROPERTIES, String[].class);\n            assertNotNull(hidden);\n            assertEquals(1, hidden.length);\n            assertEquals(\"a\", hidden[0]);\n\n        } finally {\n            this.resolver.revert();\n        }\n\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test public void testProperties() {\n        final Resource rsrcA1 = this.provider.getResource(this.resolver, \"/merged/a/1\");\n        final ValueMap vm = rsrcA1.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size());\n        assertEquals(\"1\", vm.get(\"a\"));\n        assertEquals(\"2\", vm.get(\"b\"));\n        assertEquals(\"2\", vm.get(\"c\"));\n    }","id":36629,"modified_method":"@Test public void testProperties() {\n        final Resource rsrcA1 = this.provider.getResource(ctx, \"/merged/a/1\", null);\n        final ValueMap vm = rsrcA1.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size());\n        assertEquals(\"1\", vm.get(\"a\"));\n        assertEquals(\"2\", vm.get(\"b\"));\n        assertEquals(\"2\", vm.get(\"c\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"public List<Resource> pickResources(final ResourceResolver resolver, final String relativePath) {\n        final List<Resource> resources = new ArrayList<Resource>();\n        final String[] searchPaths = resolver.getSearchPath();\n        for (int i = searchPaths.length - 1; i >= 0; i--) {\n            final String basePath = searchPaths[i];\n            final String fullPath = basePath + relativePath;\n            final Resource resource = resolver.getResource(fullPath);\n            if (resource != null) {\n                resources.add(resource);\n            } else {\n                resources.add(new NonExistingResource(resolver, fullPath));\n            }\n        }\n        return resources;\n    }","id":36630,"modified_method":"@Override\n    public List<Resource> pickResources(ResourceResolver resolver, String relativePath) {\n        return pickResources(resolver, relativePath, null);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"/**\n     * {@inheritDoc}\n     */\n    public Resource getResource(final ResourceResolver resolver, final String path) {\n        final String relativePath = getRelativePath(path);\n\n        if (relativePath != null) {\n            final ResourceHolder holder = new ResourceHolder(ResourceUtil.getName(path));\n\n            final Iterator<Resource> resources = picker.pickResources(resolver, relativePath).iterator();\n\n            if (!resources.hasNext()) {\n                return null;\n            }\n\n            boolean isUnderlying = true;\n            while (resources.hasNext()) {\n                final Resource resource = resources.next();\n\n                final boolean hidden;\n                if (isUnderlying) {\n                    hidden = false;\n                    isUnderlying = false;\n                } else {\n                    // check parent for hiding\n                    // SLING 3521 : if parent is not readable, nothing is hidden\n                    final Resource parent = resource.getParent();\n                    hidden = (parent == null ? false : new ParentHidingHandler(parent, this.traverseHierarchie).isHidden(holder.name));\n                }\n                if (hidden) {\n                    holder.resources.clear();\n                } else if (!ResourceUtil.isNonExistingResource(resource)) {\n                    holder.resources.add(resource);\n                }\n            }\n            return createMergedResource(resolver, relativePath, holder);\n        }\n\n        return null;\n    }","id":36631,"modified_method":"/**\n     * {@inheritDoc}\n     */\n    public Resource getResource(final ResolveContext<Void> ctx, final String path, final Resource parent) {\n        final String relativePath = getRelativePath(path);\n\n        if (relativePath != null) {\n            final ResourceHolder holder = new ResourceHolder(ResourceUtil.getName(path));\n\n            final ResourceResolver resolver = ctx.getResourceResolver();\n            final Iterator<Resource> resources = picker.pickResources(resolver, relativePath, parent).iterator();\n\n            if (!resources.hasNext()) {\n                return null;\n            }\n\n            boolean isUnderlying = true;\n            while (resources.hasNext()) {\n                final Resource resource = resources.next();\n\n                final boolean hidden;\n                if (isUnderlying) {\n                    hidden = false;\n                    isUnderlying = false;\n                } else {\n                    // check parent for hiding\n                    // SLING 3521 : if parent is not readable, nothing is hidden\n                    final Resource resourceParent = resource.getParent();\n                    hidden = resourceParent != null && new ParentHidingHandler(resourceParent, this.traverseHierarchie).isHidden(holder.name);\n\n                    // TODO Usually, the parent does not exist if the resource is a NonExistingResource. Ideally, this\n                    // common case should be optimised\n                }\n                if (hidden) {\n                    holder.resources.clear();\n                } else if (!ResourceUtil.isNonExistingResource(resource)) {\n                    holder.resources.add(resource);\n                }\n            }\n            return createMergedResource(resolver, relativePath, holder);\n        }\n\n        return null;\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"/**\n     * {@inheritDoc}\n     */\n    public Iterator<Resource> listChildren(Resource resource) {\n        final ResourceResolver resolver = resource.getResourceResolver();\n\n        final String relativePath = getRelativePath(resource.getPath());\n\n        if (relativePath != null) {\n            final List<ResourceHolder> candidates = new ArrayList<ResourceHolder>();\n\n            final Iterator<Resource> resources = picker.pickResources(resolver, relativePath).iterator();\n\n            boolean isUnderlying = true;\n            while (resources.hasNext()) {\n                Resource parentResource = resources.next();\n                final ParentHidingHandler handler = !isUnderlying ? new ParentHidingHandler(parentResource, this.traverseHierarchie) : null;\n                isUnderlying = false;\n\n                for (final Resource child : parentResource.getChildren()) {\n                    final String rsrcName = child.getName();\n                    ResourceHolder holder = null;\n                    for (final ResourceHolder current : candidates) {\n                        if (current.name.equals(rsrcName)) {\n                            holder = current;\n                            break;\n                        }\n                    }\n                    if (holder == null) {\n                        holder = new ResourceHolder(rsrcName);\n                        candidates.add(holder);\n                    }\n                    holder.resources.add(child);\n\n                    // Check if children need reordering\n                    int orderBeforeIndex = -1;\n                    final ValueMap vm = child.getValueMap();\n                    final String orderBefore = vm.get(MergedResourceConstants.PN_ORDER_BEFORE, String.class);\n                    if (orderBefore != null && !orderBefore.equals(rsrcName)) {\n                        // search entry\n                        int index = 0;\n                        while (index < candidates.size()) {\n                            final ResourceHolder current = candidates.get(index);\n                            if (current.name.equals(orderBefore)) {\n                                orderBeforeIndex = index;\n                                break;\n                            }\n                            index++;\n                        }\n                    }\n\n                    if (orderBeforeIndex > -1) {\n                        candidates.add(orderBeforeIndex, holder);\n                        candidates.remove(candidates.size() - 1);\n                    }\n                }\n                if (handler != null) {\n                    final Iterator<ResourceHolder> iter = candidates.iterator();\n                    while (iter.hasNext()) {\n                        final ResourceHolder holder = iter.next();\n                        if (handler.isHidden(holder.name)) {\n                            iter.remove();\n                        }\n                    }\n                }\n            }\n            final List<Resource> children = new ArrayList<Resource>();\n            for (final ResourceHolder holder : candidates) {\n                final Resource mergedResource = this.createMergedResource(resolver,\n                        (relativePath.length() == 0 ? holder.name : relativePath + '/' + holder.name), holder);\n                if (mergedResource != null) {\n                    children.add(mergedResource);\n                }\n            }\n            return children.iterator();\n        }\n\n        return null;\n    }","id":36632,"modified_method":"/**\n     * {@inheritDoc}\n     */\n    public Iterator<Resource> listChildren(final ResolveContext<Void> ctx, final Resource parent) {\n        final ResourceResolver resolver = parent.getResourceResolver();\n\n        final String relativePath = getRelativePath(parent.getPath());\n\n        if (relativePath != null) {\n            final List<ResourceHolder> candidates = new ArrayList<ResourceHolder>();\n\n            final Iterator<Resource> resources = picker.pickResources(resolver, relativePath, parent).iterator();\n\n            boolean isUnderlying = true;\n            while (resources.hasNext()) {\n                Resource parentResource = resources.next();\n                final ParentHidingHandler handler = !isUnderlying ? new ParentHidingHandler(parentResource, this.traverseHierarchie) : null;\n                isUnderlying = false;\n\n                for (final Resource child : parentResource.getChildren()) {\n                    final String rsrcName = child.getName();\n                    ResourceHolder holder = null;\n                    for (final ResourceHolder current : candidates) {\n                        if (current.name.equals(rsrcName)) {\n                            holder = current;\n                            break;\n                        }\n                    }\n                    if (holder == null) {\n                        holder = new ResourceHolder(rsrcName);\n                        candidates.add(holder);\n                    }\n                    holder.resources.add(child);\n\n                    // Check if children need reordering\n                    int orderBeforeIndex = -1;\n                    final ValueMap vm = child.getValueMap();\n                    final String orderBefore = vm.get(MergedResourceConstants.PN_ORDER_BEFORE, String.class);\n                    if (orderBefore != null && !orderBefore.equals(rsrcName)) {\n                        // search entry\n                        int index = 0;\n                        while (index < candidates.size()) {\n                            final ResourceHolder current = candidates.get(index);\n                            if (current.name.equals(orderBefore)) {\n                                orderBeforeIndex = index;\n                                break;\n                            }\n                            index++;\n                        }\n                    }\n\n                    if (orderBeforeIndex > -1) {\n                        candidates.add(orderBeforeIndex, holder);\n                        candidates.remove(candidates.size() - 1);\n                    }\n                }\n                if (handler != null) {\n                    final Iterator<ResourceHolder> iter = candidates.iterator();\n                    while (iter.hasNext()) {\n                        final ResourceHolder holder = iter.next();\n                        if (handler.isHidden(holder.name)) {\n                            iter.remove();\n                        }\n                    }\n                }\n            }\n            final List<Resource> children = new ArrayList<Resource>();\n            for (final ResourceHolder holder : candidates) {\n                final Resource mergedResource = this.createMergedResource(resolver,\n                        (relativePath.length() == 0 ? holder.name : relativePath + '/' + holder.name), holder);\n                if (mergedResource != null) {\n                    children.add(mergedResource);\n                }\n            }\n            return children.iterator();\n        }\n\n        return null;\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"public List<Resource> pickResources(ResourceResolver resolver, String relativePath) {\n        String absPath = \"/\" + relativePath;\n        final List<Resource> resources = new ArrayList<Resource>();\n        final Set<String> roots = new HashSet<String>();\n\n        Resource currentTarget = resolver.getResource(absPath);\n\n        if (currentTarget == null) {\n            currentTarget = new StubResource(resolver, absPath);\n        }\n\n        resources.add(currentTarget);\n\n        while (currentTarget != null) {\n            final InheritanceRootInfo info = new InheritanceRootInfo();\n            findInheritanceRoot(currentTarget, info);\n            if (info.resource == null) {\n                currentTarget = null;\n            } else {\n                final Resource inheritanceRootResource = info.resource;\n                final String pathRelativeToInheritanceRoot = info.getPathRelativeToInheritanceRoot();\n                final String superType = inheritanceRootResource.getResourceSuperType();\n\n                if (superType == null\n                       || roots.contains(inheritanceRootResource.getPath())) { // avoid inheritance loops\n                    currentTarget = null;\n                } else {\n                    final String superTypeChildPath = superType + pathRelativeToInheritanceRoot;\n                    final Resource superTypeResource = resolver.getResource(superTypeChildPath);\n                    if (superTypeResource != null) {\n                        currentTarget = superTypeResource;\n                    } else {\n                        currentTarget = new StubResource(resolver, superTypeChildPath);\n                    }\n                    resources.add(currentTarget);\n                    roots.add(inheritanceRootResource.getPath());\n                }\n            }\n        }\n\n        Collections.reverse(resources);\n\n        return resources;\n    }","id":36633,"modified_method":"@Override\n    public List<Resource> pickResources(ResourceResolver resolver, String relativePath) {\n        return pickResources(resolver, relativePath, null);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testOverridingOnTarget() {\n        final Resource rsrcA2 = this.provider.getResource(this.resolver, \"/override/apps/a/2\");\n        final ValueMap vm = rsrcA2.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size()); //3rd is resource:superType\n        assertEquals(\"1\", vm.get(\"a\"));\n        assertEquals(\"2\", vm.get(\"b\"));\n    }","id":36634,"modified_method":"@Test\n    public void testOverridingOnTarget() {\n        final Resource rsrcA2 = this.provider.getResource(ctx, \"/override/apps/a/2\", null);\n        final ValueMap vm = rsrcA2.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(3, vm.size()); //3rd is resource:superType\n        assertEquals(\"1\", vm.get(\"a\"));\n        assertEquals(\"2\", vm.get(\"b\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testInheritingFromGrandParent() {\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/3/a\"));\n        assertNull(this.provider.getResource(this.resolver, \"/override/apps/a/3/b\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/3/c\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/3/d\"));\n    }","id":36635,"modified_method":"@Test\n    public void testInheritingFromGrandParent() {\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/3/a\", null));\n        assertNull(this.provider.getResource(ctx, \"/override/apps/a/3/b\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/3/c\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/3/d\", null));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testHideChildrenFromGet() {\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/1/b/1\"));\n        assertNull(this.provider.getResource(this.resolver, \"/override/apps/a/2/b\"));\n        assertNull(this.provider.getResource(this.resolver, \"/override/apps/a/2/b/1\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/2/d/1/a\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/2/d/1/b\"));\n        assertNotNull(this.provider.getResource(this.resolver, \"/override/apps/a/2/d/1/b/1\"));\n    }","id":36636,"modified_method":"@Test\n    public void testHideChildrenFromGet() {\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/1/b/1\", null));\n        assertNull(this.provider.getResource(ctx, \"/override/apps/a/2/b\", null));\n        assertNull(this.provider.getResource(ctx, \"/override/apps/a/2/b/1\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/2/d/1/a\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/2/d/1/b\", null));\n        assertNotNull(this.provider.getResource(ctx, \"/override/apps/a/2/d/1/b/1\", null));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testOverriddenIncludesChildFromSuper() {\n        final Resource rsrcA2 = this.provider.getResource(this.resolver, \"/override/apps/a/2\");\n\n        Resource d = getChildResource(rsrcA2, \"d\");\n        assertNotNull(d);\n\n        Resource d1 = getChildResource(d, \"1\");\n        assertNotNull(d1);\n\n        Resource d1a = getChildResource(d1, \"a\");\n        assertNotNull(d1a);\n    }","id":36637,"modified_method":"@Test\n    public void testOverriddenIncludesChildFromSuper() {\n        final Resource rsrcA2 = this.provider.getResource(ctx, \"/override/apps/a/2\", null);\n\n        Resource d = getChildResource(rsrcA2, \"d\");\n        assertNotNull(d);\n\n        Resource d1 = getChildResource(d, \"1\");\n        assertNotNull(d1);\n\n        Resource d1a = getChildResource(d1, \"a\");\n        assertNotNull(d1a);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"private Resource getChildResource(Resource parent, String name) {\n        final Iterator<Resource> children = this.provider.listChildren(parent);\n        while (children.hasNext()) {\n            final Resource candidate = children.next();\n            if (candidate.getName().equals(name)) {\n               return candidate;\n            }\n        }\n        return null;\n    }","id":36638,"modified_method":"private Resource getChildResource(Resource parent, String name) {\n        final Iterator<Resource> children = this.provider.listChildren(ctx, parent);\n        while (children.hasNext()) {\n            final Resource candidate = children.next();\n            if (candidate.getName().equals(name)) {\n               return candidate;\n            }\n        }\n        return null;\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testLoopInInheritance() {\n        final Resource rsrcA4 = this.provider.getResource(this.resolver, \"/override/apps/a/4\");\n\n        Resource d = getChildResource(rsrcA4, \"d\");\n        assertNotNull(d);\n\n        final Resource z = this.provider.getResource(this.resolver, \"/override/apps/x/z\");\n        assertNotNull(z);\n    }","id":36639,"modified_method":"@Test\n    public void testLoopInInheritance() {\n        final Resource rsrcA4 = this.provider.getResource(ctx, \"/override/apps/a/4\", null);\n\n        Resource d = getChildResource(rsrcA4, \"d\");\n        assertNotNull(d);\n\n        final Resource z = this.provider.getResource(ctx, \"/override/apps/x/z\", null);\n        assertNotNull(z);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testOverridingViaParent() {\n        final Resource rsrcA2 = this.provider.getResource(this.resolver, \"/override/apps/a/2/c\");\n        final ValueMap vm = rsrcA2.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(2, vm.size());\n        assertEquals(\"c\", vm.get(\"1\"));\n        assertEquals(\"b\", vm.get(\"2\"));\n    }","id":36640,"modified_method":"@Test\n    public void testOverridingViaParent() {\n        final Resource rsrcA2 = this.provider.getResource(ctx, \"/override/apps/a/2/c\", null);\n        final ValueMap vm = rsrcA2.adaptTo(ValueMap.class);\n        assertNotNull(vm);\n        assertEquals(2, vm.size());\n        assertEquals(\"c\", vm.get(\"1\"));\n        assertEquals(\"b\", vm.get(\"2\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Test\n    public void testHideChildrenFromList() {\n        final Resource rsrcA2 = this.provider.getResource(this.resolver, \"/override/apps/a/2\");\n        final Iterator<Resource> children = this.provider.listChildren(rsrcA2);\n        final List<String> names = new ArrayList<String>();\n        while (children.hasNext()) {\n            names.add(children.next().getName());\n        }\n        assertTrue(names.contains(\"a\"));\n        assertFalse(names.contains(\"b\"));\n        assertTrue(names.contains(\"c\"));\n    }","id":36641,"modified_method":"@Test\n    public void testHideChildrenFromList() {\n        final Resource rsrcA2 = this.provider.getResource(ctx, \"/override/apps/a/2\", null);\n        final Iterator<Resource> children = this.provider.listChildren(ctx, rsrcA2);\n        final List<String> names = new ArrayList<String>();\n        while (children.hasNext()) {\n            names.add(children.next().getName());\n        }\n        assertTrue(names.contains(\"a\"));\n        assertFalse(names.contains(\"b\"));\n        assertTrue(names.contains(\"c\"));\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Before\n    public void setup() throws Exception {\n        final MockResourceResolverFactoryOptions options = new MockResourceResolverFactoryOptions();\n        options.setSearchPaths(new String[] {\"/apps\", \"/libs\"});\n        final ResourceResolverFactory factory = new MockResourceResolverFactory(options);\n        this.resolver = factory.getAdministrativeResourceResolver(null);\n        MockHelper.create(this.resolver)\n                    .resource(\"/apps\")\n                    .resource(\"a\")\n                    .resource(\"1\").p(\"a\", \"1\").p(\"b\", \"1\")\n                    .resource(\"a\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\".b\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"1\")\n                    .resource(\"/apps/a/1/d\").p(\"a\", \"1\").p(\"b\", \"2\")\n                    .resource(\"1\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"a\")\n                    .resource(\"/apps/a/1/d/1/b\")\n                    .resource(\"1\")\n                    .resource(\"/apps/a/1/c\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"/apps/a/2\").p(SUPER_TYPE, \"a/1\").p(\"b\", \"2\").p(MergedResourceConstants.PN_HIDE_CHILDREN, new String[] {\"b\"})\n                    .resource(\"c\").p(\"1\", \"c\")\n                    .resource(\"/apps/a/3\").p(SUPER_TYPE, \"a/2\")\n                    .resource(\"/apps/a/4\").p(SUPER_TYPE, \"/apps/a/4/b/4\")\n                    .resource(\"b\")\n                    .resource(\"4\")\n                    .resource(\"d\")\n                    .resource(\"/apps/x\").p(SUPER_TYPE, \"x/y\")\n                    .resource(\"y\")\n                    .resource(\"z\")\n                    .commit();\n\n        this.provider = new MergingResourceProvider(\"/override\", new OverridingResourcePicker(), false, true);\n    }","id":36642,"modified_method":"@Before\n    public void setup() throws Exception {\n        final MockResourceResolverFactoryOptions options = new MockResourceResolverFactoryOptions();\n        options.setSearchPaths(new String[] {\"/apps\", \"/libs\"});\n        final ResourceResolverFactory factory = new MockResourceResolverFactory(options);\n        this.resolver = factory.getAdministrativeResourceResolver(null);\n        MockHelper.create(this.resolver)\n                    .resource(\"/apps\")\n                    .resource(\"a\")\n                    .resource(\"1\").p(\"a\", \"1\").p(\"b\", \"1\")\n                    .resource(\"a\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\".b\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"1\")\n                    .resource(\"/apps/a/1/d\").p(\"a\", \"1\").p(\"b\", \"2\")\n                    .resource(\"1\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"a\")\n                    .resource(\"/apps/a/1/d/1/b\")\n                    .resource(\"1\")\n                    .resource(\"/apps/a/1/c\").p(\"1\", \"a\").p(\"2\", \"b\")\n                    .resource(\"/apps/a/2\").p(SUPER_TYPE, \"a/1\").p(\"b\", \"2\").p(MergedResourceConstants.PN_HIDE_CHILDREN, new String[] {\"b\"})\n                    .resource(\"c\").p(\"1\", \"c\")\n                    .resource(\"/apps/a/3\").p(SUPER_TYPE, \"a/2\")\n                    .resource(\"/apps/a/4\").p(SUPER_TYPE, \"/apps/a/4/b/4\")\n                    .resource(\"b\")\n                    .resource(\"4\")\n                    .resource(\"d\")\n                    .resource(\"/apps/x\").p(SUPER_TYPE, \"x/y\")\n                    .resource(\"y\")\n                    .resource(\"z\")\n                    .commit();\n\n        this.provider = new MergingResourceProvider(\"/override\", new OverridingResourcePicker(), false, true);\n        this.ctx = new BasicResolveContext(resolver, Collections.<String, String>emptyMap(), null);\n    }","commit_id":"0e1832cd1a63713a43e8091f63690d7a2df3516e","url":"https://github.com/apache/sling"},{"original_method":"@Override\n  public void beforeFileDeletion(VirtualFileEvent event) {\n    if (!event.isFromRefresh()) {\n      VfsUtilCore.visitChildrenRecursively(event.getFile(), new VirtualFileVisitor() {\n        @Override\n        public boolean visitFile(@NotNull VirtualFile file) {\n          Document document = getCachedDocument(file);\n          if (document != null) {\n            removeFromUnsaved(document);\n          }\n          return true;\n        }\n      });\n    }\n\n  }","id":36643,"modified_method":"@Override\n  public void beforeFileDeletion(VirtualFileEvent event) {\n    if (!event.isFromRefresh()) {\n      VirtualFile file = event.getFile();\n      if (file.getFileSystem() instanceof TempFileSystem) {\n        return; //hack: this fs fails in getChildren during beforeFileDeletion\n      }\n      VfsUtilCore.visitChildrenRecursively(file, new VirtualFileVisitor() {\n        @Override\n        public boolean visitFile(@NotNull VirtualFile file) {\n          Document document = getCachedDocument(file);\n          if (document != null) {\n            removeFromUnsaved(document);\n          }\n          return true;\n        }\n      });\n    }\n\n  }","commit_id":"28763c431a5ef436190b964e09cd7cf3388663eb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void collectSuitableFiles(@NotNull VirtualFile file) {\n    class CancelledException extends RuntimeException { }\n\n    try {\n      VfsUtilCore.visitChildrenRecursively(file, new VirtualFileVisitor() {\n        @Override\n        public boolean visitFile(@NotNull VirtualFile file) {\n          if (myProgressIndicator.isCanceled()) {\n            throw new CancelledException();\n          }\n          if (!myProcessedFiles.add(file)) {\n            return false;\n          }\n\n          if (file.isDirectory()) {\n            file.getChildren();  // initialize myChildren field to ensure that refresh will be really performed\n            file.refresh(false, false);\n          }\n          else {\n            final FileType fileType = file.getFileType();\n            if (myDetectorsByFileType.containsKey(fileType)) {\n              myProgressIndicator.setText2(file.getPresentableUrl());\n              try {\n                final FileContent fileContent = new FileContentImpl(file, file.contentsToByteArray(false));\n                for (FrameworkDetectorData detector : myDetectorsByFileType.get(fileType)) {\n                  if (detector.myFilePattern.accepts(fileContent)) {\n                    detector.mySuitableFiles.add(file);\n                  }\n                }\n              }\n              catch (IOException e) {\n                LOG.info(e);\n              }\n            }\n          }\n\n          return true;\n        }\n      });\n    }\n    catch (CancelledException ignored) { }\n  }","id":36644,"modified_method":"private void collectSuitableFiles(@NotNull VirtualFile file) {\n    try {\n      VfsUtilCore.visitChildrenRecursively(file, new VirtualFileVisitor() {\n        @Override\n        public boolean visitFile(@NotNull VirtualFile file) {\n          // Since this code is invoked from New Project Wizard it's very possible that VFS isn't loaded to memory yet, so we need to do it\n          // manually, otherwise refresh will do nothing\n          myProgressIndicator.checkCanceled();\n          return true;\n        }\n      });\n      file.refresh(false, true);\n\n      VfsUtilCore.visitChildrenRecursively(file, new VirtualFileVisitor() {\n        @Override\n        public boolean visitFile(@NotNull VirtualFile file) {\n          myProgressIndicator.checkCanceled();\n          if (!myProcessedFiles.add(file)) {\n            return false;\n          }\n\n          if (!file.isDirectory()) {\n            final FileType fileType = file.getFileType();\n            if (myDetectorsByFileType.containsKey(fileType)) {\n              myProgressIndicator.setText2(file.getPresentableUrl());\n              try {\n                final FileContent fileContent = new FileContentImpl(file, file.contentsToByteArray(false));\n                for (FrameworkDetectorData detector : myDetectorsByFileType.get(fileType)) {\n                  if (detector.myFilePattern.accepts(fileContent)) {\n                    detector.mySuitableFiles.add(file);\n                  }\n                }\n              }\n              catch (IOException e) {\n                LOG.info(e);\n              }\n            }\n          }\n\n          return true;\n        }\n      });\n    }\n    catch (ProcessCanceledException ignored) {\n    }\n  }","commit_id":"f858e8999ed0123dfc78b397f9bb1c3f0391a8d8","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void testNoErrorsInAlternativeSignatures() {\n        InjectorForJavaSemanticServices injector = new InjectorForJavaSemanticServices(getProject());\n\n        final BindingContext bindingContext = injector.getBindingTrace().getBindingContext();\n        JavaDescriptorResolver javaDescriptorResolver = injector.getJavaDescriptorResolver();\n\n        final Map<DeclarationDescriptor, List<String>> errors = Maps.newHashMap();\n\n        Iterable<FqName> affectedClasses = getAffectedClasses(kotlinAnnotationsRoot);\n        AlternativeSignatureErrorFindingVisitor visitor = new AlternativeSignatureErrorFindingVisitor(bindingContext, errors);\n        for (FqName javaClass : affectedClasses) {\n            ClassDescriptor topLevelClass = javaDescriptorResolver.resolveClass(javaClass);\n            NamespaceDescriptor topLevelNamespace = javaDescriptorResolver.resolveNamespace(javaClass);\n            if (topLevelClass == null) {\n                continue;\n            }\n\n            topLevelClass.acceptVoid(visitor);\n\n            if (topLevelNamespace != null) {\n                topLevelNamespace.acceptVoid(visitor);\n            }\n        }\n\n        if (!errors.isEmpty()) {\n            StringBuilder sb = new StringBuilder(\"Error(s) in JDK alternative signatures: \\n\");\n            for (Map.Entry<DeclarationDescriptor, List<String>> entry : errors.entrySet()) {\n                sb.append(DescriptorRenderer.TEXT.render(entry.getKey())).append(\" : \").append(entry.getValue()).append(\"\\n\");\n            }\n            fail(sb.toString());\n        }\n    }","id":36645,"modified_method":"public void testNoErrorsInAlternativeSignatures() {\n        List<FqName> affectedClasses = getAffectedClasses(\"file://jdk-annotations\");\n\n        final Map<String, List<String>> errors = Maps.newHashMap();\n\n        for (int chunkIndex = 0; chunkIndex < affectedClasses.size() / CLASSES_IN_CHUNK + 1; chunkIndex++) {\n            Disposable parentDisposable = CompileEnvironmentUtil.createMockDisposable();\n\n            try {\n                JetCoreEnvironment commonEnvironment = createEnvironment(parentDisposable);\n\n                InjectorForJavaSemanticServices injector = new InjectorForJavaSemanticServices(commonEnvironment.getProject());\n\n                BindingContext bindingContext = injector.getBindingTrace().getBindingContext();\n                JavaDescriptorResolver javaDescriptorResolver = injector.getJavaDescriptorResolver();\n\n                AlternativeSignatureErrorFindingVisitor visitor = new AlternativeSignatureErrorFindingVisitor(bindingContext, errors);\n\n                int chunkStart = chunkIndex * CLASSES_IN_CHUNK;\n                for (FqName javaClass : affectedClasses.subList(chunkStart, Math.min(chunkStart + CLASSES_IN_CHUNK, affectedClasses.size()))) {\n                    ClassDescriptor topLevelClass = javaDescriptorResolver.resolveClass(javaClass);\n                    NamespaceDescriptor topLevelNamespace = javaDescriptorResolver.resolveNamespace(javaClass);\n                    if (topLevelClass == null) {\n                        continue;\n                    }\n\n                    topLevelClass.acceptVoid(visitor);\n\n                    if (topLevelNamespace != null) {\n                        topLevelNamespace.acceptVoid(visitor);\n                    }\n                }\n            }\n            finally {\n                Disposer.dispose(parentDisposable);\n            }\n        }\n\n\n        if (!errors.isEmpty()) {\n            StringBuilder sb = new StringBuilder(\"Error(s) in JDK alternative signatures: \\n\");\n            for (Map.Entry<String, List<String>> entry : errors.entrySet()) {\n                sb.append(entry.getKey()).append(\" : \").append(entry.getValue()).append(\"\\n\");\n            }\n            fail(sb.toString());\n        }\n    }","commit_id":"77876f9a4445fa4da5b79ed73f74338add12f91b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    protected JetCoreEnvironment createEnvironment() {\n        return JetTestUtils.createEnvironmentWithJdkAndNullabilityAnnotationsFromIdea(\n                myTestRootDisposable, ConfigurationKind.JDK_AND_ANNOTATIONS, TestJdkKind.FULL_JDK);\n    }","id":36646,"modified_method":"private static JetCoreEnvironment createEnvironment(Disposable parentDisposable) {\n        return JetTestUtils.createEnvironmentWithJdkAndNullabilityAnnotationsFromIdea(\n                parentDisposable, ConfigurationKind.JDK_AND_ANNOTATIONS, TestJdkKind.FULL_JDK);\n    }","commit_id":"77876f9a4445fa4da5b79ed73f74338add12f91b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static Iterable<FqName> getAffectedClasses(final VirtualFile root) {\n        final Set<FqName> result = Sets.newLinkedHashSet();\n        VfsUtilCore.visitChildrenRecursively(root, new VirtualFileVisitor() {\n            @Override\n            public boolean visitFile(@NotNull VirtualFile file) {\n                if (ExternalAnnotationsManager.ANNOTATIONS_XML.equals(file.getName())) {\n                    try {\n                        String text = StreamUtil.readText(file.getInputStream());\n                        Matcher matcher = Pattern.compile(\"<item name=['\\\"]([\\\\w\\\\d\\\\.]+)[\\\\s'\\\"]\").matcher(text);\n                        while (matcher.find()) {\n                            result.add(new FqName(matcher.group(1)));\n                        }\n                    }\n                    catch (IOException e) {\n                        throw new RuntimeException(e);\n                    }\n                }\n                return true;\n            }\n        });\n        return result;\n    }","id":36647,"modified_method":"static List<FqName> getAffectedClasses(final String rootUrl) {\n        Disposable myDisposable = CompileEnvironmentUtil.createMockDisposable();\n\n        try {\n            createEnvironment(myDisposable);\n\n            VirtualFile root = VirtualFileManager.getInstance().findFileByUrl(rootUrl);\n            assert root != null;\n\n            final Set<FqName> result = Sets.newLinkedHashSet();\n            VfsUtilCore.visitChildrenRecursively(root, new VirtualFileVisitor() {\n                @Override\n                public boolean visitFile(@NotNull VirtualFile file) {\n                    if (ExternalAnnotationsManager.ANNOTATIONS_XML.equals(file.getName())) {\n                        try {\n                            String text = StreamUtil.readText(file.getInputStream());\n                            Matcher matcher = Pattern.compile(\"<item name=['\\\"]([\\\\w\\\\d\\\\.]+)[\\\\s'\\\"]\").matcher(text);\n                            while (matcher.find()) {\n                                result.add(new FqName(matcher.group(1)));\n                            }\n                        }\n                        catch (IOException e) {\n                            throw new RuntimeException(e);\n                        }\n                    }\n                    return true;\n                }\n            });\n\n            return Lists.newArrayList(result);\n        }\n        finally {\n            Disposer.dispose(myDisposable);\n        }\n\n    }","commit_id":"77876f9a4445fa4da5b79ed73f74338add12f91b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private Void visitDeclaration(@NotNull DeclarationDescriptor descriptor) {\n            List<String> errors = bindingContext.get(BindingContext.LOAD_FROM_JAVA_SIGNATURE_ERRORS, descriptor);\n            if (errors != null) {\n                this.errors.put(descriptor, errors);\n            }\n            return null;\n        }","id":36648,"modified_method":"private Void visitDeclaration(@NotNull DeclarationDescriptor descriptor) {\n            List<String> errors = bindingContext.get(BindingContext.LOAD_FROM_JAVA_SIGNATURE_ERRORS, descriptor);\n            if (errors != null) {\n                this.errors.put(DescriptorRenderer.TEXT.render(descriptor), errors);\n            }\n            return null;\n        }","commit_id":"77876f9a4445fa4da5b79ed73f74338add12f91b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public AlternativeSignatureErrorFindingVisitor(BindingContext bindingContext, Map<DeclarationDescriptor, List<String>> errors) {\n            this.bindingContext = bindingContext;\n            this.errors = errors;\n        }","id":36649,"modified_method":"public AlternativeSignatureErrorFindingVisitor(BindingContext bindingContext, Map<String, List<String>> errors) {\n            this.bindingContext = bindingContext;\n            this.errors = errors;\n        }","commit_id":"77876f9a4445fa4da5b79ed73f74338add12f91b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Test\n\tpublic void testThreadLastPostDate() throws Exception {\n\t\tMBMessage parentMessage = MBTestUtil.addMessage(_group.getGroupId());\n\n\t\tlong categoryId = parentMessage.getCategoryId();\n\t\tlong threadId = parentMessage.getThreadId();\n\t\tlong parentMessageId = parentMessage.getMessageId();\n\n\t\tThread.sleep(2000);\n\n\t\tMBMessage firstReply = MBTestUtil.addMessage(\n\t\t\t_group.getGroupId(), categoryId, threadId, parentMessageId);\n\n\t\tThread.sleep(2000);\n\n\t\tMBMessage secondReply = MBTestUtil.addMessage(\n\t\t\t_group.getGroupId(), categoryId, threadId, parentMessageId);\n\n\t\tMBMessageLocalServiceUtil.deleteMessage(secondReply.getMessageId());\n\n\t\tMBThread mbThread = parentMessage.getThread();\n\n\t\tDate mbThreadLastPost = mbThread.getLastPostDate();\n\t\tDate lastModifiedMessage = firstReply.getModifiedDate();\n\n\t\tAssert.assertTrue(\n\t\t\tmbThreadLastPost.getTime() ==\n\t\t\t\t(lastModifiedMessage.getTime() / 1000) * 1000);\n\t}","id":36650,"modified_method":"@Test\n\tpublic void testThreadLastPostDate() throws Exception {\n\t\tMBMessage parentMessage = MBTestUtil.addMessage(_group.getGroupId());\n\n\t\tThread.sleep(2000);\n\n\t\tMBMessage firstReplyMessage = MBTestUtil.addMessage(\n\t\t\t_group.getGroupId(), parentMessage.getCategoryId(),\n\t\t\tparentMessage.getThreadId(), parentMessage.getMessageId());\n\n\t\tThread.sleep(2000);\n\n\t\tMBMessage secondReplyMessage = MBTestUtil.addMessage(\n\t\t\t_group.getGroupId(), parentMessage.getCategoryId(),\n\t\t\tparentMessage.getThreadId(), parentMessage.getMessageId());\n\n\t\tMBMessageLocalServiceUtil.deleteMessage(\n\t\t\tsecondReplyMessage.getMessageId());\n\n\t\tDate lastMessageModifiedDate = firstReplyMessage.getModifiedDate();\n\n\t\tMBThread mbThread = parentMessage.getThread();\n\n\t\tDate mbThreadLastPostDate = mbThread.getLastPostDate();\n\n\t\tAssert.assertTrue(\n\t\t\tmbThreadLastPostDate.getTime() ==\n\t\t\t\t(lastMessageModifiedDate.getTime() / 1000) * 1000);\n\t}","commit_id":"0d6573110d4d0d37414aa58950b623ec1af304fa","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tpublic String getRestoreLink(PortletRequest portletRequest, long classPK)\n\t\tthrows PortalException, SystemException {\n\n\t\tMBThread thread = MBThreadLocalServiceUtil.getThread(classPK);\n\n\t\treturn MBUtil.getMBControlPanelLink(\n\t\t\tportletRequest, thread.getCategoryId());\n\t}","id":36651,"modified_method":"@Override\n\tpublic String getRestoreLink(PortletRequest portletRequest, long classPK)\n\t\tthrows PortalException, SystemException {\n\n\t\tMBThread thread = MBThreadLocalServiceUtil.getThread(classPK);\n\n\t\tString portletName = PortletKeys.MESSAGE_BOARDS;\n\n\t\tlong plid = PortalUtil.getPlidFromPortletId(\n\t\t\tthread.getGroupId(), PortletKeys.MESSAGE_BOARDS);\n\n\t\tif (plid == LayoutConstants.DEFAULT_PLID) {\n\t\t\tplid = PortalUtil.getControlPanelPlid(portletRequest);\n\n\t\t\tportletName = PortletKeys.MESSAGE_BOARDS_ADMIN;\n\t\t}\n\n\t\tPortletURL portletURL = PortletURLFactoryUtil.create(\n\t\t\tportletRequest, portletName, plid, PortletRequest.RENDER_PHASE);\n\n\t\tportletURL.setParameter(\"struts_action\", \"/message_boards_admin/view\");\n\t\tportletURL.setParameter(\n\t\t\t\"mbCategoryId\", String.valueOf(thread.getCategoryId()));\n\n\t\treturn portletURL.toString();\n\t}","commit_id":"5fe0583b3a9ebbc04730850c28a3b96f1b31b4b6","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public MBMessage addMessage(\n\t\t\tlong parentMessageId, String subject, String body, String format,\n\t\t\tList<ObjectValuePair<String, InputStream>> inputStreamOVPs,\n\t\t\tboolean anonymous, double priority, boolean allowPingbacks,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tMBMessage parentMessage = mbMessagePersistence.fetchByPrimaryKey(\n\t\t\tparentMessageId);\n\n\t\tlong categoryId = parentMessage.getCategoryId();\n\t\tlong groupId = parentMessage.getGroupId();\n\t\tlong threadId = parentMessage.getThreadId();\n\n\t\tcheckReplyToPermission(groupId, categoryId, parentMessageId);\n\n\t\tif (lockLocalService.isLocked(MBThread.class.getName(), threadId)) {\n\t\t\tthrow new LockedThreadException();\n\t\t}\n\n\t\tif (!MBCategoryPermission.contains(\n\t\t\t\tgetPermissionChecker(), groupId, categoryId,\n\t\t\t\tActionKeys.ADD_FILE)) {\n\n\t\t\tinputStreamOVPs = Collections.emptyList();\n\t\t}\n\n\t\tboolean preview = ParamUtil.getBoolean(serviceContext, \"preview\");\n\n\t\tint workFlowAction = serviceContext.getWorkflowAction();\n\n\t\tif ((workFlowAction == WorkflowConstants.STATUS_DRAFT) && !preview) {\n\t\t\tMBMessagePermission.check(\n\t\t\t\tgetPermissionChecker(), parentMessageId, ActionKeys.UPDATE);\n\t\t}\n\n\t\tif (!MBCategoryPermission.contains(\n\t\t\t\tgetPermissionChecker(), groupId, categoryId,\n\t\t\t\tActionKeys.UPDATE_THREAD_PRIORITY)) {\n\n\t\t\tpriority = MBThreadConstants.PRIORITY_NOT_GIVEN;\n\t\t}\n\n\t\treturn mbMessageLocalService.addMessage(\n\t\t\tgetGuestOrUserId(), null, groupId, categoryId, threadId,\n\t\t\tparentMessageId, subject, body, format, inputStreamOVPs, anonymous,\n\t\t\tpriority, allowPingbacks, serviceContext);\n\t}","id":36652,"modified_method":"public MBMessage addMessage(\n\t\t\tlong parentMessageId, String subject, String body, String format,\n\t\t\tList<ObjectValuePair<String, InputStream>> inputStreamOVPs,\n\t\t\tboolean anonymous, double priority, boolean allowPingbacks,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tMBMessage parentMessage = mbMessagePersistence.fetchByPrimaryKey(\n\t\t\tparentMessageId);\n\n\t\tcheckReplyToPermission(\n\t\t\tparentMessage.getGroupId(), parentMessage.getCategoryId(),\n\t\t\tparentMessageId);\n\n\t\tboolean preview = ParamUtil.getBoolean(serviceContext, \"preview\");\n\n\t\tint workFlowAction = serviceContext.getWorkflowAction();\n\n\t\tif ((workFlowAction == WorkflowConstants.STATUS_DRAFT) && !preview) {\n\t\t\tMBMessagePermission.check(\n\t\t\t\tgetPermissionChecker(), parentMessageId, ActionKeys.UPDATE);\n\t\t}\n\n\t\tif (lockLocalService.isLocked(\n\t\t\t\tMBThread.class.getName(), parentMessage.getThreadId())) {\n\n\t\t\tthrow new LockedThreadException();\n\t\t}\n\n\t\tif (!MBCategoryPermission.contains(\n\t\t\t\tgetPermissionChecker(), parentMessage.getGroupId(),\n\t\t\t\tparentMessage.getCategoryId(), ActionKeys.ADD_FILE)) {\n\n\t\t\tinputStreamOVPs = Collections.emptyList();\n\t\t}\n\n\t\tif (!MBCategoryPermission.contains(\n\t\t\t\tgetPermissionChecker(), parentMessage.getGroupId(),\n\t\t\t\tparentMessage.getCategoryId(),\n\t\t\t\tActionKeys.UPDATE_THREAD_PRIORITY)) {\n\n\t\t\tpriority = MBThreadConstants.PRIORITY_NOT_GIVEN;\n\t\t}\n\n\t\treturn mbMessageLocalService.addMessage(\n\t\t\tgetGuestOrUserId(), null, parentMessage.getGroupId(),\n\t\t\tparentMessage.getCategoryId(), parentMessage.getThreadId(),\n\t\t\tparentMessageId, subject, body, format, inputStreamOVPs, anonymous,\n\t\t\tpriority, allowPingbacks, serviceContext);\n\t}","commit_id":"fc458ab978ecbd695800f2b3a922a6e0fb69cd30","url":"https://github.com/liferay/liferay-portal"},{"original_method":"/**\n     * Returns the mandatory inbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static Object getMandatoryInBody(Exchange exchange) throws InvalidPayloadException {\n        Object answer = exchange.getIn().getBody();\n        if (answer == null) {\n            throw new InvalidPayloadException(exchange, Object.class);\n        }\n        return answer;\n    }","id":36653,"modified_method":"/**\n     * Returns the mandatory inbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static Object getMandatoryInBody(Exchange exchange) throws InvalidPayloadException {\n        return exchange.getIn().getMandatoryBody();\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns the mandatory outbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static Object getMandatoryOutBody(Exchange exchange) throws InvalidPayloadException {\n        Message out = exchange.getOut();\n        Object answer = out.getBody();\n        if (answer == null) {\n            throw new InvalidPayloadException(exchange, Object.class, out);\n        }\n        return answer;\n    }","id":36654,"modified_method":"/**\n     * Returns the mandatory outbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static Object getMandatoryOutBody(Exchange exchange) throws InvalidPayloadException {\n        return exchange.getOut().getMandatoryBody();\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Converts the value to the given expected type or throws an exception\n     */\n    public static <T> T convertToMandatoryType(Exchange exchange, Class<T> type, Object value)\n        throws InvalidTypeException {\n        T answer = convertToType(exchange, type, value);\n        if (answer == null) {\n            throw new InvalidTypeException(exchange, value, type);\n        }\n        return answer;\n    }","id":36655,"modified_method":"/**\n     * Converts the value to the given expected type or throws an exception\n     */\n    public static <T> T convertToMandatoryType(Exchange exchange, Class<T> type, Object value) throws NoTypeConversionAvailableException {\n        CamelContext camelContext = exchange.getContext();\n        TypeConverter converter = camelContext.getTypeConverter();\n        if (converter != null) {\n            return converter.mandatoryConvertTo(type, exchange, value);\n        }\n        throw new NoTypeConversionAvailableException(value, type);\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns the mandatory outbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static <T> T getMandatoryOutBody(Exchange exchange, Class<T> type) throws InvalidPayloadException {\n        Message out = exchange.getOut();\n        T answer = out.getBody(type);\n        if (answer == null) {\n            throw new InvalidPayloadException(exchange, type, out);\n        }\n        return answer;\n    }","id":36656,"modified_method":"/**\n     * Returns the mandatory outbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static <T> T getMandatoryOutBody(Exchange exchange, Class<T> type) throws InvalidPayloadException {\n        return exchange.getOut().getMandatoryBody(type);\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns the mandatory inbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static <T> T getMandatoryInBody(Exchange exchange, Class<T> type) throws InvalidPayloadException {\n        T answer = exchange.getIn().getBody(type);\n        if (answer == null) {\n            throw new InvalidPayloadException(exchange, type);\n        }\n        return answer;\n    }","id":36657,"modified_method":"/**\n     * Returns the mandatory inbound message body of the correct type or throws\n     * an exception if it is not present\n     */\n    public static <T> T getMandatoryInBody(Exchange exchange, Class<T> type) throws InvalidPayloadException {\n        return exchange.getIn().getMandatoryBody(type);\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the property value of the camel context with the given name\n     *\n     * @see Exchange#getProperty(String)\n     * @param propertyName the name of the property the expression will return\n     * @return an expression object which will return the property value\n     */\n    public static Expression camelContextPropertyExpression(final String propertyName) {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getContext().getProperties().get(propertyName);\n            }\n\n            @Override\n            public String toString() {\n                return \"camelContextProperty(\" + propertyName + \")\";\n            }\n        };\n    }","id":36658,"modified_method":"/**\n     * Returns an expression for the property value of the camel context with the given name\n     *\n     * @param propertyName the name of the property the expression will return\n     * @return an expression object which will return the property value\n     */\n    public static Expression camelContextPropertyExpression(final String propertyName) {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getContext().getProperties().get(propertyName);\n            }\n\n            @Override\n            public String toString() {\n                return \"camelContextProperty(\" + propertyName + \")\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the properties of exchange with the given name\n     *\n     * @see Exchange#getProperties()\n     * @return an expression object which will return the properties\n     */\n    public static Expression camelContextPropertiesExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getContext().getProperties();\n            }\n\n            @Override\n            public String toString() {\n                return \"camelContextProperties\";\n            }\n        };\n    }","id":36659,"modified_method":"/**\n     * Returns an expression for the properties of the camel context\n     *\n     * @return an expression object which will return the properties\n     */\n    public static Expression camelContextPropertiesExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getContext().getProperties();\n            }\n\n            @Override\n            public String toString() {\n                return \"camelContextProperties\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the outbound message headers\n     *\n     * @see Message#getHeaders()\n     * @return an expression object which will return the headers\n     */\n    public static Expression outHeadersExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getOut().getHeaders();\n            }\n\n            @Override\n            public String toString() {\n                return \"outHeaders\";\n            }\n        };\n    }","id":36660,"modified_method":"/**\n     * Returns an expression for the outbound message headers\n     *\n     * @return an expression object which will return the headers\n     */\n    public static Expression outHeadersExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getOut().getHeaders();\n            }\n\n            @Override\n            public String toString() {\n                return \"outHeaders\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the properties of exchange with the given name\n     *\n     * @see Exchange#getProperties()\n     * @return an expression object which will return the properties\n     */\n    public static Expression propertiesExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getProperties();\n            }\n\n            @Override\n            public String toString() {\n                return \"properties\";\n            }\n        };\n    }","id":36661,"modified_method":"/**\n     * Returns an expression for the properties of exchange\n     *\n     * @return an expression object which will return the properties\n     */\n    public static Expression propertiesExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getProperties();\n            }\n\n            @Override\n            public String toString() {\n                return \"properties\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the property value of exchange with the given name\n     *\n     * @see Exchange#getProperty(String)\n     * @param propertyName the name of the property the expression will return\n     * @return an expression object which will return the property value\n     */\n    public static Expression propertyExpression(final String propertyName) {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getProperty(propertyName);\n            }\n\n            @Override\n            public String toString() {\n                return \"property(\" + propertyName + \")\";\n            }\n        };\n    }","id":36662,"modified_method":"/**\n     * Returns an expression for the property value of exchange with the given name\n     *\n     * @param propertyName the name of the property the expression will return\n     * @return an expression object which will return the property value\n     */\n    public static Expression propertyExpression(final String propertyName) {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getProperty(propertyName);\n            }\n\n            @Override\n            public String toString() {\n                return \"property(\" + propertyName + \")\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Returns an expression for the inbound message headers\n     *\n     * @see Message#getHeaders()\n     * @return an expression object which will return the inbound headers\n     */\n    public static Expression headersExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getIn().getHeaders();\n            }\n\n            @Override\n            public String toString() {\n                return \"headers\";\n            }\n        };\n    }","id":36663,"modified_method":"/**\n     * Returns an expression for the inbound message headers\n     *\n     * @return an expression object which will return the inbound headers\n     */\n    public static Expression headersExpression() {\n        return new ExpressionAdapter() {\n            public Object evaluate(Exchange exchange) {\n                return exchange.getIn().getHeaders();\n            }\n\n            @Override\n            public String toString() {\n                return \"headers\";\n            }\n        };\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"public InvalidPayloadRuntimeException(Exchange exchange, Class<?> type) {\n        super(\"No in body available of type: \" + type.getName()\n              + NoSuchPropertyException.valueDescription(exchange.getIn().getBody()), exchange);\n        this.type = type;\n    }","id":36664,"modified_method":"public InvalidPayloadRuntimeException(Exchange exchange, Class<?> type) {\n        this(exchange, type, exchange.getIn());\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"public Exchange receive() {\n        Exchange exchange = getEndpoint().createExchange();\n        try {\n            processor.process(exchange);\n        } catch (Exception e) {\n            throw new RuntimeExchangeException(e, exchange);\n        }\n        return exchange;\n    }","id":36665,"modified_method":"public Exchange receive() {\n        Exchange exchange = getEndpoint().createExchange();\n        try {\n            processor.process(exchange);\n        } catch (Exception e) {\n            throw new RuntimeExchangeException(\"Error while processing exchange\", exchange, e);\n        }\n        return exchange;\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"public RuntimeExchangeException(String message, Exchange exchange) {\n        super(message + \" on the exchange: \" +  exchange);\n        this.exchange = exchange;\n    }","id":36666,"modified_method":"public RuntimeExchangeException(String message, Exchange exchange) {\n        super(createMessage(message, exchange));\n        this.exchange = exchange;\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"public RuntimeExchangeException(Exception e, Exchange exchange) {\n        super(e.getMessage(), e);\n        this.exchange = exchange;\n    }","id":36667,"modified_method":"public RuntimeExchangeException(String message, Exchange exchange, Throwable cause) {\n        super(createMessage(message, exchange), cause);\n        this.exchange = exchange;\n    }","commit_id":"7478fa4a382fdf61b9c1b3ffba1e09be68681488","url":"https://github.com/apache/camel"},{"original_method":"public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        BeanInvocation invocation = new BeanInvocation(method, args);\n        ExchangePattern pattern = ExchangePattern.InOut;\n        MethodInfo methodInfo = methodInfoCache.getMethodInfo(method);\n        if (methodInfo != null) {\n            pattern = methodInfo.getPattern();\n        }\n        Exchange exchange = new DefaultExchange(endpoint, pattern);\n        exchange.getIn().setBody(invocation);\n\n        producer.process(exchange);\n        Throwable fault = exchange.getException();\n        if (fault != null) {\n            if (fault instanceof RuntimeCamelException) {\n                // if the inner cause is a runtime exception we can throw it directly\n                if (fault.getCause() instanceof RuntimeException) {\n                    throw (RuntimeException) ((RuntimeCamelException) fault).getCause();\n                }\n                throw (RuntimeCamelException) fault;\n            }\n            throw new InvocationTargetException(fault);\n        }\n\n        // TODO: type convert to method signature\n        if (pattern.isOutCapable()) {\n            return exchange.getOut().getBody();\n        } else {\n            return null;\n        }\n    }","id":36668,"modified_method":"public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        BeanInvocation invocation = new BeanInvocation(method, args);\n        ExchangePattern pattern = ExchangePattern.InOut;\n        MethodInfo methodInfo = methodInfoCache.getMethodInfo(method);\n        if (methodInfo != null) {\n            pattern = methodInfo.getPattern();\n        }\n        Exchange exchange = new DefaultExchange(endpoint, pattern);\n        exchange.getIn().setBody(invocation);\n\n        // process the exchange\n        if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Proxied method call \" + method.getName() + \" invoking producer: \" + producer);\n        }\n        producer.process(exchange);\n\n        // check if we had an exception\n        Throwable fault = exchange.getException();\n        if (fault != null) {\n            if (fault instanceof RuntimeCamelException) {\n                // if the inner cause is a runtime exception we can throw it directly\n                if (fault.getCause() instanceof RuntimeException) {\n                    throw (RuntimeException) ((RuntimeCamelException) fault).getCause();\n                }\n                throw (RuntimeCamelException) fault;\n            }\n            throw new InvocationTargetException(fault);\n        }\n\n        // do not return a reply if the method is VOID or the MEP is not OUT capable\n        Class<?> to = method.getReturnType();\n        if (to == Void.TYPE || !pattern.isOutCapable()) {\n            return null;\n        }\n\n        // use type converter so we can convert output in the desired type defined by the method\n        // and let it be mandatory so we know wont return null if we cant convert it to the defined type\n        Object answer = exchange.getOut().getMandatoryBody(to);\n        if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Proxied method call \" + method.getName() + \" returning: \" + answer);\n        }\n        return answer;\n    }","commit_id":"a6584f9378f4cef362938c5d7f96c4e1b6ee1c2b","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Strategy method to extract the document from the exchange\n     */\n    @SuppressWarnings(\"unchecked\")\n    protected Object getDocument(Exchange exchange) {\n        Message in = exchange.getIn();\n        Class type = getDocumentType();\n        Object answer = null;\n        if (type != null) {\n            answer = in.getBody(type);\n        }\n\n        if (answer == null) {\n            answer = in.getBody();\n        }\n\n        // lets try coerce some common types into something JAXP can deal with\n        if (answer instanceof GenericFile) {\n            // special for files so we can work with them out of the box\n            InputStream is = exchange.getContext().getTypeConverter().convertTo(InputStream.class, answer);\n            answer = new InputSource(is);\n        } else if (answer instanceof String) {\n            answer = new InputSource(new StringReader(answer.toString()));\n        }\n\n        // call the reset if the in message body is StreamCache\n        MessageHelper.resetStreamCache(exchange.getIn());\n        return answer;\n    }","id":36669,"modified_method":"/**\n     * Strategy method to extract the document from the exchange\n     */\n    @SuppressWarnings(\"unchecked\")\n    protected Object getDocument(Exchange exchange) {\n        Message in = exchange.getIn();\n        Class type = getDocumentType();\n        Object answer = null;\n        if (type != null) {\n            answer = in.getBody(type);\n        }\n\n        if (answer == null) {\n            answer = in.getBody();\n        }\n\n        // lets try coerce some common types into something JAXP can deal with\n        if (answer instanceof GenericFile) {\n            // special for files so we can work with them out of the box\n            InputStream is = exchange.getContext().getTypeConverter().convertTo(InputStream.class, answer);\n            answer = new InputSource(is);\n        } else if (answer instanceof BeanInvocation) {\n            // if its a null bean invocation then handle that\n            BeanInvocation bi = exchange.getContext().getTypeConverter().convertTo(BeanInvocation.class, answer);\n            if (bi.getArgs() != null && bi.getArgs().length == 1 && bi.getArgs()[0] == null) {\n                // its a null argument from the bean invocation so use null as answer\n                answer = null;\n            }\n        } else if (answer instanceof String) {\n            answer = new InputSource(new StringReader(answer.toString()));\n        }\n\n        // call the reset if the in message body is StreamCache\n        MessageHelper.resetStreamCache(exchange.getIn());\n        return answer;\n    }","commit_id":"a6584f9378f4cef362938c5d7f96c4e1b6ee1c2b","url":"https://github.com/apache/camel"},{"original_method":"public FlashToSipAudioStream(final FlashToSipTranscoder transcoder, DatagramSocket srcSocket, SipConnectInfo connInfo) {\r\n\t\tthis.transcoder = transcoder;\r\n\t\tthis.srcSocket = srcSocket;\r\n\t\tthis.connInfo = connInfo;\t\t\r\n\t\ttalkStreamName = \"microphone_\" + System.currentTimeMillis();\r\n\t}","id":36670,"modified_method":"public FlashToSipAudioStream(final FlashToSipTranscoder transcoder, DatagramSocket srcSocket, SipConnectInfo connInfo) {\r\n\t\tthis.transcoder = transcoder;\r\n\t\tthis.srcSocket = srcSocket;\r\n\t\tthis.connInfo = connInfo;\t\t\r\n\t\ttalkStreamName = \"microphone_\" + System.currentTimeMillis();\r\n\t\tstreamFromFlash = new PipedOutputStream();\r\n\t\ttry {\r\n\t\t\tstreamToSip = new PipedInputStream(streamFromFlash);\r\n\t\t} catch (IOException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void start(IBroadcastStream broadcastStream, IScope scope) throws StreamException {\r\n\t    log.debug(\"startTranscodingStream({},{})\", broadcastStream.getPublishedName(), scope.getName());\r\n\t\r\n\t\tmInputListener = new IStreamListener() {\r\n\t\t\tpublic void packetReceived(IBroadcastStream broadcastStream, IStreamPacket packet) {\r\n\t\t      IoBuffer buf = packet.getData();\r\n\t\t      if (buf != null)\r\n\t\t    \t  buf.rewind();\r\n\t\t    \r\n\t\t      if (buf == null || buf.remaining() == 0){\r\n\t\t    \t  log.debug(\"skipping empty packet with no data\");\r\n\t\t    \t  return;\r\n\t\t      }\r\n\t\t      System.out.println(\"Receive RTMP packet.\"); \t\t      \r\n\t\t      if (packet instanceof AudioData) {\r\n\t\t    \t  System.out.println(\"**** Receive RTMP audio packet.\");\r\n\t\t    \t  byte[] data = SerializeUtils.ByteBufferToByteArray(buf);\r\n\t\t\t\t  AudioByteData abd = new AudioByteData(data, false);\r\n\t\t\t\t  try {\r\n\t\t\t\t\t  audioDataQ.put(abd);\r\n\t\t\t\t  } catch (InterruptedException e) {\r\n\t\t\t\t\t  // TODO Auto-generated catch block\r\n\t\t\t\t\t  e.printStackTrace();\r\n\t\t\t\t  }\t\t    \t\t\t  \t\t    \t  \r\n\t\t      } \r\n\t\t\t}\r\n\t\t};\r\n\t\t\t\t\r\n\t    broadcastStream.addStreamListener(mInputListener);    \r\n\t    rtpSender = new RtpStreamSender(srcSocket, connInfo);\r\n\t\trtpSender.connect();\r\n\t\t\t\t\r\n\t\tprocessAudioData = true;\t    \r\n\t    audioDataProcessor = new Runnable() {\r\n    \t\tpublic void run() {\r\n    \t\t\tprocessAudioData();   \t\t\t\r\n    \t\t}\r\n    \t};\r\n    \texec.execute(audioDataProcessor);\r\n\t}","id":36671,"modified_method":"public void start(IBroadcastStream broadcastStream, IScope scope) throws StreamException {\r\n\t    log.debug(\"startTranscodingStream({},{})\", broadcastStream.getPublishedName(), scope.getName());\r\n\t\r\n\t\tmInputListener = new IStreamListener() {\r\n\t\t\tpublic void packetReceived(IBroadcastStream broadcastStream, IStreamPacket packet) {\r\n\t\t      IoBuffer buf = packet.getData();\r\n\t\t      if (buf != null)\r\n\t\t    \t  buf.rewind();\r\n\t\t    \r\n\t\t      if (buf == null || buf.remaining() == 0){\r\n\t\t    \t  log.debug(\"skipping empty packet with no data\");\r\n\t\t    \t  return;\r\n\t\t      }\r\n\t\t      \t      \r\n\t\t      if (packet instanceof AudioData) {\r\n\t\t    \t  byte[] data = SerializeUtils.ByteBufferToByteArray(buf);\r\n//\t\t    \t  System.out.println(\"RTMP data lenght = \" + data.length);\r\n\t\t    \t  try {\r\n\t\t\t\t\tstreamFromFlash.write(data, 1, data.length-1);\r\n\t\t\t\t} catch (IOException e) {\r\n\t\t\t\t\t// TODO Auto-generated catch block\r\n\t\t\t\t\te.printStackTrace();\r\n\t\t\t\t}\t    \t\t\t  \t\t    \t  \r\n\t\t      } \r\n\t\t\t}\r\n\t\t};\r\n\t\t\t\t\r\n\t    broadcastStream.addStreamListener(mInputListener);    \r\n\t    rtpSender = new RtpStreamSender(srcSocket, connInfo);\r\n\t\trtpSender.connect();\r\n\t\t\t\t\r\n\t\tprocessAudioData = true;\t    \r\n\t    audioDataProcessor = new Runnable() {\r\n    \t\tpublic void run() {\r\n    \t\t\tprocessAudioData();   \t\t\t\r\n    \t\t}\r\n    \t};\r\n    \texec.execute(audioDataProcessor);\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void processAudioData() {\r\n\t\twhile (processAudioData) {\r\n\t\t\ttry {\r\n\t\t\t\tAudioByteData abd = audioDataQ.take();\r\n\t\t\t\tif (abd.status()) {\r\n\t\t\t\t\tlog.debug(\"Flash Queue Poisoned - Dieing\");\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t}\r\n\t\t\t\t\ttranscoder.transcode(abd, 1, abd.getData().length-1, new TranscodedAudioListener());\r\n\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\t// TODO Auto-generated catch block\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t}        \t\t\r\n\t\t}\t\r\n\t}","id":36672,"modified_method":"private void processAudioData() {\r\n\t\tint len = 64;\r\n\t\tbyte[] nellyAudio = new byte[len];\t\t\r\n\t\tint remaining = len;\r\n\t\tint offset = 0;\r\n\t\twhile (processAudioData) {\t\t\t\r\n\t\t\ttry {\r\n\t\t\t\tif (streamToSip.available() > 1000) {\r\n\t\t\t\t\tlong skipped = streamToSip.skip(1000L);\r\n\t\t\t\t\tSystem.out.println(\"   Skipping RTMP audio bytes[\" + skipped + \"]\");\r\n\t\t\t\t}\r\n\t\t\t\tint bytesRead =  streamToSip.read(nellyAudio, offset, remaining);\r\n\t\t\t\tremaining -= bytesRead;\r\n\t\t\t\tif (remaining == 0) {\r\n\t\t\t\t\tremaining = len;\r\n\t\t\t\t\toffset = 0;\r\n\t\t\t\t\ttranscoder.transcode(nellyAudio, 0, nellyAudio.length, new TranscodedAudioListener());\r\n\t\t\t\t} else {\r\n\t\t\t\t\toffset += bytesRead; \r\n\t\t\t\t}\r\n\t\t\t} catch (IOException e) {\r\n\t\t\t\t// TODO Auto-generated catch block\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t}        \t\t\r\n\t\t}\t\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic void transcode(AudioByteData audioData, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] codedBuffer = new byte[length];\r\n\t\tSystem.arraycopy(audioData.getData(), startOffset, codedBuffer, 0, length);\r\n\t\tbyte[] transcodedAudioData = new byte[sipCodec.getOutgoingEncodedFrameSize()];\r\n\t\t\r\n        asao_buffer_processed = false;\r\n\r\n        if (!hasInitilializedBuffers) {\r\n            tempBuffer = new float[NELLYMOSER_DECODED_PACKET_SIZE];\r\n            encodingBuffer = new float[sipCodec.getOutgoingDecodedFrameSize()];\r\n            hasInitilializedBuffers = true;\r\n        }\r\n\r\n        if (length > 0) {\r\n            do {\r\n                int encodedBytes = fillRtpPacketBuffer(codedBuffer, transcodedAudioData);\r\n                if (encodedBytes == 0) {\r\n                    break;\r\n                }\r\n\r\n                if (encodingOffset == sipCodec.getOutgoingDecodedFrameSize()) {\r\n                    encodingOffset = 0;\r\n                    listener.handleTranscodedAudioData(transcodedAudioData, timestamp += TS_INCREMENT);\r\n                }\r\n            } while (!asao_buffer_processed);\r\n        }\r\n\t}","id":36673,"modified_method":"@Override\r\n\tpublic void transcode(byte[] audioData, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] codedBuffer = new byte[length];\r\n\t\tSystem.arraycopy(audioData, startOffset, codedBuffer, 0, length);\r\n\t\tbyte[] transcodedAudioData = new byte[sipCodec.getOutgoingEncodedFrameSize()];\r\n\t\t\r\n        asao_buffer_processed = false;\r\n\r\n        if (!hasInitilializedBuffers) {\r\n            tempBuffer = new float[NELLYMOSER_DECODED_PACKET_SIZE];\r\n            encodingBuffer = new float[sipCodec.getOutgoingDecodedFrameSize()];\r\n            hasInitilializedBuffers = true;\r\n        }\r\n\r\n        if (length > 0) {\r\n            do {\r\n                int encodedBytes = fillRtpPacketBuffer(codedBuffer, transcodedAudioData);\r\n                if (encodedBytes == 0) {\r\n                    break;\r\n                }\r\n\r\n                if (encodingOffset == sipCodec.getOutgoingDecodedFrameSize()) {\r\n                    encodingOffset = 0;\r\n                    listener.handleTranscodedAudioData(transcodedAudioData, timestamp += TS_INCREMENT);\r\n                }\r\n            } while (!asao_buffer_processed);\r\n        }\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic void transcode(AudioByteData audioData, TranscodedAudioDataListener listener) {\r\n\t\ttranscodePcmToNellymoser(audioData.getData(), listener);     \r\n    }","id":36674,"modified_method":"@Override\r\n\tpublic void transcode(byte[] audioData, TranscodedAudioDataListener listener) {\r\n\t\ttranscodePcmToNellymoser(audioData, listener);     \r\n    }","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void processRtpPacket(RtpPacket rtpPacket) {\r\n\t\tlastSequenceNumber = rtpPacket.getSeqNum();\r\n\t\tlastPacketTimestamp = rtpPacket.getTimestamp();\r\n\t\tAudioByteData audioData = new AudioByteData(rtpPacket.getPayload(), false);\r\n\t\tif (listener != null) listener.onAudioDataReceived(audioData);\r\n\t\telse log.debug(\"No listener for incoming audio packet\");    \t\r\n    }","id":36675,"modified_method":"private void processRtpPacket(byte[] rtpAudio, int offset, int len) {\r\n\r\n\t\tif (listener != null) listener.onAudioDataReceived(rtpAudio, offset, len);\r\n\t\telse log.debug(\"No listener for incoming audio packet\");    \t\r\n    }","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void receiveRtpPackets() {    \r\n        int packetReceivedCounter = 0;\r\n        int internalBufferLength = payloadLength + RTP_HEADER_SIZE;\r\n        \r\n        while (receivePackets) {\r\n        \ttry {\r\n                byte[] internalBuffer; \r\n                RtpPacket rtpPacket;\r\n        \t\tinternalBuffer = new byte[internalBufferLength];\r\n            \trtpPacket = new RtpPacket(internalBuffer, internalBufferLength);        \t\t\t\r\n            \trtpSocket.receive(rtpPacket); \r\n            \t\r\n            \t\r\n            \tbyte[] pb = rtpPacket.getPacket();\r\n            \tStringBuilder p = new StringBuilder(\"Rx [\");\r\n            \tfor (int i = 0; i < pb.length; i++) {\r\n            \t\tp.append(Integer.toHexString(pb[i]  & 0xFF) + \",\");            \t\t\r\n            \t}\r\n            \tp.append(\"] \" + pb.length + \" \" + internalBufferLength);\r\n            \tlog.debug(p.toString());\r\n            \t\r\n        \t\t       \t\t\r\n        \t\tpacketReceivedCounter++;  \r\n    \t\t\tlog.debug(\"Received packet [\" + rtpPacket.getRtcpPayloadType() + \",\" + rtpPacket.getPayloadType() + \", length=\" + rtpPacket.getPayloadLength() + \"] seqNum[rtpSeqNum=\" + rtpPacket.getSeqNum() + \",lastSeqNum=\" + lastSequenceNumber \r\n    \t\t\t\t\t+ \"][rtpTS=\" + rtpPacket.getTimestamp() + \",lastTS=\" + lastPacketTimestamp + \"][port=\" + rtpSocket.getDatagramSocket().getLocalPort() + \"]\");          \t\t\t       \t\t\t\r\n        \t\tprocessRtpPacket(rtpPacket);\r\n        \t\t\r\n        \t\t/**\r\n        \t\t * Null this to see if the memory gets garbage collected quickly.\r\n        \t\t * ralam (dec 3, 2010)\r\n        \t\t */\r\n        \t\trtpPacket = null;\r\n        \t} catch (IOException e) { // We get this when the socket closes when the call hangs up.        \t\t\r\n        \t\treceivePackets = false;\r\n        \t}\r\n        }\r\n        log.debug(\"Rtp Receiver stopped. Packet Received = \" + packetReceivedCounter + \".\" );\r\n        if (listener != null) listener.onStoppedReceiving();\r\n    }","id":36676,"modified_method":"public void receiveRtpPackets() {    \r\n        int packetReceivedCounter = 0;\r\n        int internalBufferLength = payloadLength + RTP_HEADER_SIZE;\r\n        byte[] internalBuffer = new byte[internalBufferLength];\r\n        RtpPacket rtpPacket = new RtpPacket(internalBuffer, internalBufferLength);;\r\n        \r\n        while (receivePackets) {\r\n        \ttry {       \t\t\t\r\n        \t\trtpSocket.receive(rtpPacket);        \t\t\r\n        \t\tpacketReceivedCounter++;  \r\n//    \t\t\tlog.debug(\"Received packet [\" + rtpPacket.getRtcpPayloadType() + \",\" + rtpPacket.getPayloadType() + \", length=\" + rtpPacket.getPayloadLength() + \"] seqNum[rtpSeqNum=\" + rtpPacket.getSeqNum() + \",lastSeqNum=\" + lastSequenceNumber \r\n//    \t\t\t\t\t+ \"][rtpTS=\" + rtpPacket.getTimestamp() + \",lastTS=\" + lastPacketTimestamp + \"][port=\" + rtpSocket.getDatagramSocket().getLocalPort() + \"]\");          \t\t\t       \t\t\t\r\n     \r\n        \t\tif (shouldDropDelayedPacket(rtpPacket)) {\r\n        \t\t\tcontinue;\r\n        \t\t}\r\n        \t\tif (rtpPacket.isRtcpPacket()) {\r\n        \t\t\t/**\r\n        \t\t\t * Asterisk (1.6.2.5) send RTCP packets. We just ignore them (for now).\r\n        \t\t\t * It could be for KeepAlive (http://tools.ietf.org/html/draft-ietf-avt-app-rtp-keepalive-09)\r\n        \t\t\t */\r\n        \t\t\tif (log.isDebugEnabled()) \r\n        \t\t\t\tlog.debug(\"RTCP packet [\" + rtpPacket.getRtcpPayloadType() + \", length=\" + rtpPacket.getPayloadLength() + \"] seqNum[rtpSeqNum=\" + rtpPacket.getSeqNum() + \",lastSeqNum=\" + lastSequenceNumber \r\n        \t\t\t\t\t+ \"][rtpTS=\" + rtpPacket.getTimestamp() + \",lastTS=\" + lastPacketTimestamp + \"][port=\" + rtpSocket.getDatagramSocket().getLocalPort() + \"]\");          \t\t\t\r\n        \t\t} else {\r\n            \t\tif (shouldHandlePacket(rtpPacket)) {        \t\t\t            \t\t\t\r\n//            \t\t\tlog.debug(\"Handling packet [\" + rtpPacket.getRtcpPayloadType() + \",\" + rtpPacket.getPayloadType() + \", length=\" + rtpPacket.getPayloadLength() + \"] seqNum[rtpSeqNum=\" + rtpPacket.getSeqNum() + \",lastSeqNum=\" + lastSequenceNumber \r\n//            \t\t\t\t\t+ \"][rtpTS=\" + rtpPacket.getTimestamp() + \",lastTS=\" + lastPacketTimestamp + \"][port=\" + rtpSocket.getDatagramSocket().getLocalPort() + \"]\");          \t\t\t       \t\t\t\r\n            \t\t\tlastSequenceNumber = rtpPacket.getSeqNum();\r\n            \t\t\tlastPacketTimestamp = rtpPacket.getTimestamp();\r\n            \t\t\tprocessRtpPacket(internalBuffer, RTP_HEADER_SIZE, payloadLength);\r\n            \t\t} else {\r\n            \t\t\tif (log.isDebugEnabled())\r\n            \t\t\t\tlog.debug(\"Corrupt packet [\" + rtpPacket.getRtcpPayloadType() + \",\" + rtpPacket.getPayloadType() + \", length=\" + rtpPacket.getPayloadLength() + \"] seqNum[rtpSeqNum=\" + rtpPacket.getSeqNum() + \",lastSeqNum=\" + lastSequenceNumber \r\n            \t\t\t\t\t+ \"][rtpTS=\" + rtpPacket.getTimestamp() + \",lastTS=\" + lastPacketTimestamp + \"][port=\" + rtpSocket.getDatagramSocket().getLocalPort() + \"]\");          \t\t\t       \t\t\t\r\n\r\n            \t\t\tif (lastPacketDropped) successivePacketDroppedCount++;\r\n            \t\t\telse lastPacketDropped = true;           \t\t\t\r\n            \t\t}\r\n            \t}\r\n        \t} catch (IOException e) { // We get this when the socket closes when the call hangs up.        \t\t\r\n        \t\treceivePackets = false;\r\n        \t}\r\n        }\r\n        log.debug(\"Rtp Receiver stopped. Packet Received = \" + packetReceivedCounter + \".\" );\r\n        if (listener != null) listener.onStoppedReceiving();\r\n    }","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void sendAudio(byte[] audioData, int codecId, long timestamp) {\r\n    \tbyte[] transcodedAudioDataBuffer = new byte[audioData.length + RTP_HEADER_SIZE];\r\n    \tSystem.arraycopy(audioData, 0, transcodedAudioDataBuffer, RTP_HEADER_SIZE, audioData.length);\r\n    \tRtpPacket rtpPacket = new RtpPacket(transcodedAudioDataBuffer, transcodedAudioDataBuffer.length);\r\n    \tif (!marked) {\r\n    \t\trtpPacket.setMarker(true);\r\n    \t\tmarked = true;\r\n    \t}\r\n    \trtpPacket.setPadding(false);\r\n    \trtpPacket.setExtension(false);\r\n        rtpPacket.setPayloadType(codecId);\r\n    \trtpPacket.setSeqNum(sequenceNum++);   \r\n    \trtpPacket.setTimestamp(timestamp);\r\n        rtpPacket.setPayloadLength(audioData.length);\r\n        try {\r\n\t\t\trtpSocketSend(rtpPacket);\r\n\t\t} catch (StreamException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}  \r\n    }","id":36677,"modified_method":"public void sendAudio(byte[] audioData, int codecId, long timestamp) {\r\n    \tbyte[] transcodedAudioDataBuffer = new byte[audioData.length + RTP_HEADER_SIZE];\r\n    \tSystem.arraycopy(audioData, 0, transcodedAudioDataBuffer, RTP_HEADER_SIZE, audioData.length);\r\n    \tRtpPacket rtpPacket = new RtpPacket(transcodedAudioDataBuffer, transcodedAudioDataBuffer.length);\r\n    \tif (!marked) {\r\n    \t\trtpPacket.setMarker(true);\r\n    \t\tmarked = true;\r\n    \t\tstartTimestamp = System.currentTimeMillis();\r\n    \t}\r\n    \trtpPacket.setPadding(false);\r\n    \trtpPacket.setExtension(false);\r\n        rtpPacket.setPayloadType(codecId);\r\n    \trtpPacket.setSeqNum(sequenceNum++);   \r\n    \trtpPacket.setTimestamp(System.currentTimeMillis() - startTimestamp);\r\n        rtpPacket.setPayloadLength(audioData.length);\r\n        try {\r\n\t\t\trtpSocketSend(rtpPacket);\r\n\t\t} catch (StreamException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}  \r\n    }","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void pushAudio(byte[] audio, long timestamp) {\r\n\t\t\r\n\t\tsendFakeMetadata(timestamp);\r\n\t\r\n        IoBuffer buffer = IoBuffer.allocate(1024);\r\n        buffer.setAutoExpand(true);\r\n\r\n        buffer.clear();\r\n\r\n        buffer.put((byte) transcoder.getCodecId()); \r\n        byte[] copy = new byte[audio.length];\r\n\t    System.arraycopy(audio, 0, copy, 0, audio.length );\r\n        \r\n        buffer.put(copy);        \r\n        buffer.flip();\r\n\r\n        AudioData audioData = new AudioData(buffer);\r\n        audioData.setTimestamp((int)timestamp );\r\n\t\taudioBroadcastStream.dispatchEvent(audioData);\r\n\t\taudioData.release();\r\n    }","id":36678,"modified_method":"private void pushAudio(byte[] audio, long timestamp) {\r\n\t\t\r\n\t\tsendFakeMetadata(timestamp);\r\n\t\r\n        mBuffer.clear();\r\n        mBuffer.put((byte) transcoder.getCodecId()); \r\n\t    mBuffer.put(audio);        \r\n\t    mBuffer.flip();\r\n\t    \r\n        audioData.setTimestamp((int)(System.currentTimeMillis() - startTimestamp));\r\n        audioData.setData(mBuffer);\r\n\t\taudioBroadcastStream.dispatchEvent(audioData);\r\n\t\taudioData.release();\r\n    }","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void start() {\r\n\t\tlog.debug(\"started publishing stream in \" + scope.getName());\r\n\t\taudioBroadcastStream = new AudioBroadcastStream(listenStreamName);\r\n\t\taudioBroadcastStream.setPublishedName(listenStreamName);\r\n\t\taudioBroadcastStream.setScope(scope);\r\n\t\t\r\n\t\tIContext context = scope.getContext();\r\n\t\t\r\n\t\tIProviderService providerService = (IProviderService) context.getBean(IProviderService.BEAN_NAME);\r\n\t\tif (providerService.registerBroadcastStream(scope, listenStreamName, audioBroadcastStream)){\r\n\t\t\tIBroadcastScope bScope = (BroadcastScope) providerService.getLiveProviderInput(scope, listenStreamName, true);\t\t\t\r\n\t\t\tbScope.setAttribute(IBroadcastScope.STREAM_ATTRIBUTE, audioBroadcastStream);\r\n\t\t} else{\r\n\t\t\tlog.error(\"could not register broadcast stream\");\r\n\t\t\tthrow new RuntimeException(\"could not register broadcast stream\");\r\n\t\t}\r\n\t\t\r\n\t    audioBroadcastStream.start();\t    \r\n\t    processAudioData = true;\r\n\t    startTimestamp = System.currentTimeMillis();\r\n\t    \r\n\t    audioDataProcessor = new Runnable() {\r\n    \t\tpublic void run() {\r\n    \t\t\tprocessAudioData();       \t\t\t\r\n    \t\t}\r\n    \t};\r\n    \texec.execute(audioDataProcessor);\r\n    \t\r\n\t    rtpStreamReceiver.start();\n\t}","id":36679,"modified_method":"public void start() {\r\n\t\t\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void stop() {\r\n\t\tlog.debug(\"Stopping stream for {}\", listenStreamName);\n\t\tprocessAudioData = false;\r\n\t\ttry {\r\n\t\t\taudioDataQ.put(new AudioByteData(new byte[] {0}, true));\r\n\t\t} catch (InterruptedException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t\trtpStreamReceiver.stop();\r\n\t\tlog.debug(\"Stopped RTP Stream Receiver for {}\", listenStreamName);\n\t\tif (audioBroadcastStream != null) {\r\n\t\t\taudioBroadcastStream.stop();\r\n\t\t\tlog.debug(\"Stopped audioBroadcastStream for {}\", listenStreamName);\r\n\t\t\taudioBroadcastStream.close();\r\n\t\t    log.debug(\"Closed audioBroadcastStream for {}\", listenStreamName);\r\n\t\t} else\r\n\t\t\tlog.debug(\"audioBroadcastStream is null, couldn't stop\");\r\n\t    log.debug(\"Stream(s) stopped\");\n\t}","id":36680,"modified_method":"public void stop() {\r\n\t\tlog.debug(\"Stopping stream for {}\", listenStreamName);\n\t\tprocessAudioData = false;\r\n\t\trtpStreamReceiver.stop();\r\n\t\tlog.debug(\"Stopped RTP Stream Receiver for {}\", listenStreamName);\n\t\tif (audioBroadcastStream != null) {\r\n\t\t\taudioBroadcastStream.stop();\r\n\t\t\tlog.debug(\"Stopped audioBroadcastStream for {}\", listenStreamName);\r\n\t\t\taudioBroadcastStream.close();\r\n\t\t    log.debug(\"Closed audioBroadcastStream for {}\", listenStreamName);\r\n\t\t} else\r\n\t\t\tlog.debug(\"audioBroadcastStream is null, couldn't stop\");\r\n\t    log.debug(\"Stream(s) stopped\");\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void processAudioData() {\r\n\t\twhile (processAudioData) {\r\n\t\t\ttry {\r\n\t\t\t\tAudioByteData abd = audioDataQ.take();\r\n\t\t\t\tif (abd.status())\r\n\t\t\t\t\tbreak;\r\n\t\t\t\ttranscoder.transcode(abd, this);\r\n\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\t// TODO Auto-generated catch block\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t}        \t\t\r\n\t\t}\t\r\n\t}","id":36681,"modified_method":"private void processAudioData() {\r\n\t\tint len = 160;\r\n\t\tbyte[] pcmAudio = new byte[len];\t\t\r\n\t\tint remaining = len;\r\n\t\tint offset = 0;\r\n\t\twhile (processAudioData) {\r\n\t\t\ttry {\r\n\t//\t\t\tSystem.out.println(\"** Remaining[\" + remaining + \",\" + offset + \"] \" + streamToFlash.available());\t\r\n\t\t\t\tif (streamToFlash.available() > 1000) {\r\n\t\t\t\t\tlong skipped = streamToFlash.skip(1000L);\r\n\t\t\t\t\tSystem.out.println(\"** Skipping audio bytes[\" + skipped + \"]\");\r\n\t\t\t\t}\r\n\t\t\t\tint bytesRead =  streamToFlash.read(pcmAudio, offset, remaining);\t\t\r\n\t\t\t\tremaining -= bytesRead;\r\n\t\t\t\tif (remaining == 0) {\r\n\t\t\t\t\tremaining = len;\r\n\t\t\t\t\toffset = 0;\r\n\t\t\t\t\ttranscoder.transcode(pcmAudio, this);\r\n\t\t\t\t} else {\r\n\t\t\t\t\toffset += bytesRead; \r\n\t\t\t\t}\r\n\t\t\t} catch (IOException e) {\r\n\t\t\t\t// TODO Auto-generated catch block\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t}        \t\t\r\n\t\t}\t\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic void onAudioDataReceived(AudioByteData audioData) {\r\n\t\ttry {\r\n\t\t\taudioDataQ.put(audioData);\r\n\t\t} catch (InterruptedException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t}","id":36682,"modified_method":"@Override\r\n\tpublic void onAudioDataReceived(byte[] audioData, int offset, int len) {\r\n\t\ttry {\r\n\t//\t\tSystem.out.println(\"** Received[\" + audioData.length + \"]\");\r\n\t\t\tstreamFromSip.write(audioData, offset, len);\r\n\t\t} catch (IOException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void sendFakeMetadata(long timestamp) {\r\n\t\tif (!sentMetadata) {\r\n\t\t\t/*\r\n\t\t\t * Flash Player 10.1 requires us to send metadata for it to play audio.\r\n\t\t\t * We create a fake one here to get it going. Red5 should do this automatically\r\n\t\t\t * but for Red5 0.91, doesn't yet. (ralam Sept 24, 2010).\r\n\t\t\t */\r\n\t\t\tIoBuffer mBuffer = IoBuffer.allocate(1024);\r\n\t\t\tmBuffer.setAutoExpand(true);\r\n\r\n\t\t\tmBuffer.clear();\t        \r\n\t\t    mBuffer.put(fakeMetadata);         \r\n\t\t    mBuffer.flip();\r\n\r\n\t        Notify notifyData = new Notify(mBuffer);\r\n\t        notifyData.setTimestamp((int)timestamp );\r\n\t\t\taudioBroadcastStream.dispatchEvent(notifyData);\r\n\t\t\tnotifyData.release();\r\n\t\t\tsentMetadata = true;\r\n\t\t}\t\t\r\n\t}","id":36683,"modified_method":"private void sendFakeMetadata(long timestamp) {\r\n\t\tif (!sentMetadata) {\r\n\t\t\tstartTimestamp = System.currentTimeMillis();\r\n\t\t\t/*\r\n\t\t\t * Flash Player 10.1 requires us to send metadata for it to play audio.\r\n\t\t\t * We create a fake one here to get it going. Red5 should do this automatically\r\n\t\t\t * but for Red5 0.91, doesn't yet. (ralam Sept 24, 2010).\r\n\t\t\t */\r\n\t\t\tmBuffer.clear();\t        \r\n\t\t    mBuffer.put(fakeMetadata);         \r\n\t\t    mBuffer.flip();\r\n\r\n\t        Notify notifyData = new Notify(mBuffer);\r\n\t        notifyData.setTimestamp((int)startTimestamp);\r\n\t\t\taudioBroadcastStream.dispatchEvent(notifyData);\r\n\t\t\tnotifyData.release();\r\n\t\t\tsentMetadata = true;\r\n\t\t}\t\t\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public SipToFlashAudioStream(IScope scope, SipToFlashTranscoder transcoder, DatagramSocket socket) {\r\n\t\tthis.scope = scope;\r\n\t\tthis.transcoder = transcoder;\r\n\t\trtpStreamReceiver = new RtpStreamReceiver(socket, transcoder.getIncomingEncodedFrameSize());\r\n\t\trtpStreamReceiver.setRtpStreamReceiverListener(this);\r\n\t\tlistenStreamName = \"speaker_\" + System.currentTimeMillis();\t\t\n\t\tscope.setName(listenStreamName);\t\r\n\t}","id":36684,"modified_method":"public SipToFlashAudioStream(IScope scope, SipToFlashTranscoder transcoder, DatagramSocket socket) {\r\n\t\tthis.scope = scope;\r\n\t\tthis.transcoder = transcoder;\r\n\t\trtpStreamReceiver = new RtpStreamReceiver(socket, transcoder.getIncomingEncodedFrameSize());\r\n\t\trtpStreamReceiver.setRtpStreamReceiverListener(this);\r\n\t\tlistenStreamName = \"speaker_\" + System.currentTimeMillis();\t\t\n\t\tscope.setName(listenStreamName);\t\r\n\t\tstreamFromSip = new PipedOutputStream();\r\n\t\ttry {\r\n\t\t\tstreamToFlash = new PipedInputStream(streamFromSip);\r\n\t\t\tstartNow();\r\n\t\t\tmBuffer = IoBuffer.allocate(1024);\r\n\t\t\tmBuffer = mBuffer.setAutoExpand(true);\r\n\t        audioData = new AudioData();\r\n\t\t} catch (IOException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void transcode(AudioByteData audioData, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] transcodedAudio = new byte[length];\r\n\t\tSystem.arraycopy(audioData.getData(), startOffset, transcodedAudio, 0, length);\r\n\t\tlistener.handleTranscodedAudioData(transcodedAudio, timestamp += TS_INCREMENT);\r\n\t}","id":36685,"modified_method":"public void transcode(byte[] audioData, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] transcodedAudio = new byte[length];\r\n\t\tSystem.arraycopy(audioData, startOffset, transcodedAudio, 0, length);\r\n\t\tlistener.handleTranscodedAudioData(transcodedAudio, timestamp += TS_INCREMENT);\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic void transcode(AudioByteData audioData, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] codedBuffer = audioData.getData();\r\n\t\tlistener.handleTranscodedAudioData(codedBuffer, timestamp += TS_INCREMENT);\r\n\t}","id":36686,"modified_method":"@Override\r\n\tpublic void transcode(byte[] audioData, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] codedBuffer = audioData;\r\n\t\tlistener.handleTranscodedAudioData(codedBuffer, timestamp += TS_INCREMENT);\r\n\t}","commit_id":"a9c7605fad0780b69ac46f19d0e89248b81b18d8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void start(IBroadcastStream broadcastStream, IScope scope) throws StreamException {\r\n\t    log.debug(\"startTranscodingStream({},{})\", broadcastStream.getPublishedName(), scope.getName());\r\n\t\r\n\t\tmInputListener = new IStreamListener() {\r\n\t\t\tpublic void packetReceived(IBroadcastStream broadcastStream, IStreamPacket packet) {\r\n\t\t      IoBuffer buf = packet.getData();\r\n\t\t      if (buf != null)\r\n\t\t    \t  buf.rewind();\r\n\t\t    \r\n\t\t      if (buf == null || buf.remaining() == 0){\r\n\t\t    \t  log.debug(\"skipping empty packet with no data\");\r\n\t\t    \t  return;\r\n\t\t      }\r\n\t\t          \r\n\t\t      if (packet instanceof AudioData) {\r\n\t\t    \t  byte[] data = SerializeUtils.ByteBufferToByteArray(buf);\r\n\t\t    \t  System.out.println(\"Speex header \" + data[0] + \" packet length \" + (data.length -1));\r\n\t\t    \t  byte[] audioData = transcoder.transcodeAudio(data, 1, data.length-1);\t\r\n\t\t    \t  if (audioData != null) {\r\n\t\t    \t\t  rtpSender.sendAudio(audioData, transcoder.getCodecId());\r\n\t\t    \t  } else {\r\n\t\t    \t\t  log.warn(\"Transcodec audio is null. Discarding.\");\r\n\t\t    \t  }\r\n\t\t      } \r\n\t\t\t}\r\n\t\t};\r\n\t    broadcastStream.addStreamListener(mInputListener);    \r\n\t    rtpSender = new RtpStreamSender(srcSocket, connInfo);\r\n\t\trtpSender.connect();\r\n\t}","id":36687,"modified_method":"public void start(IBroadcastStream broadcastStream, IScope scope) throws StreamException {\r\n\t    log.debug(\"startTranscodingStream({},{})\", broadcastStream.getPublishedName(), scope.getName());\r\n\t\r\n\t\tmInputListener = new IStreamListener() {\r\n\t\t\tpublic void packetReceived(IBroadcastStream broadcastStream, IStreamPacket packet) {\r\n\t\t      IoBuffer buf = packet.getData();\r\n\t\t      if (buf != null)\r\n\t\t    \t  buf.rewind();\r\n\t\t    \r\n\t\t      if (buf == null || buf.remaining() == 0){\r\n\t\t    \t  log.debug(\"skipping empty packet with no data\");\r\n\t\t    \t  return;\r\n\t\t      }\r\n\t\t          \r\n\t\t      if (packet instanceof AudioData) {\r\n\t\t    \t  byte[] data = SerializeUtils.ByteBufferToByteArray(buf);\r\n\t\t    \t  System.out.println(\"Speex header \" + data[0] + \" packet length \" + (data.length -1));\r\n\t\t    \t  transcoder.transcodeAudio(data, 1, data.length-1, new TranscodedAudioListener());\t\t\t    \t  \r\n\t\t      } \r\n\t\t\t}\r\n\t\t};\r\n\t    broadcastStream.addStreamListener(mInputListener);    \r\n\t    rtpSender = new RtpStreamSender(srcSocket, connInfo);\r\n\t\trtpSender.connect();\r\n\t}","commit_id":"fcdf6dfb7899ebaea74bf797f106ddf44fa132b8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic byte[] transcodeAudio(byte[] srcAudio, int startOffset, int length) {\r\n\t\tbyte[] audioData = new byte[length];\r\n\t\tSystem.arraycopy(srcAudio, startOffset, audioData, 0, length);\r\n\t\tbyte[] transcodedAudioData = new byte[sipCodec.getOutgoingEncodedFrameSize()];\r\n\t\t\r\n        asao_buffer_processed = false;\r\n\r\n        if (!hasInitilializedBuffers) {\r\n            tempBuffer = new float[NELLYMOSER_DECODED_PACKET_SIZE];\r\n            encodingBuffer = new float[sipCodec.getOutgoingDecodedFrameSize()];\r\n            hasInitilializedBuffers = true;\r\n        }\r\n\r\n        if (length > 0) {\r\n            do {\r\n                int encodedBytes = fillRtpPacketBuffer(audioData, transcodedAudioData);\r\n                if (encodedBytes == 0) {\r\n                    break;\r\n                }\r\n\r\n                if (encodingOffset == sipCodec.getOutgoingDecodedFrameSize()) {\r\n                    encodingOffset = 0;\r\n                    return transcodedAudioData;\r\n                }\r\n            } while (!asao_buffer_processed);\r\n        }\r\n        return null;\r\n\t}","id":36688,"modified_method":"@Override\r\n\tpublic void transcodeAudio(byte[] srcAudio, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] audioData = new byte[length];\r\n\t\tSystem.arraycopy(srcAudio, startOffset, audioData, 0, length);\r\n\t\tbyte[] transcodedAudioData = new byte[sipCodec.getOutgoingEncodedFrameSize()];\r\n\t\t\r\n        asao_buffer_processed = false;\r\n\r\n        if (!hasInitilializedBuffers) {\r\n            tempBuffer = new float[NELLYMOSER_DECODED_PACKET_SIZE];\r\n            encodingBuffer = new float[sipCodec.getOutgoingDecodedFrameSize()];\r\n            hasInitilializedBuffers = true;\r\n        }\r\n\r\n        if (length > 0) {\r\n            do {\r\n                int encodedBytes = fillRtpPacketBuffer(audioData, transcodedAudioData);\r\n                if (encodedBytes == 0) {\r\n                    break;\r\n                }\r\n\r\n                if (encodingOffset == sipCodec.getOutgoingDecodedFrameSize()) {\r\n                    encodingOffset = 0;\r\n                    listener.handleTranscodedAudioData(transcodedAudioData);\r\n                }\r\n            } while (!asao_buffer_processed);\r\n        }\r\n\t}","commit_id":"fcdf6dfb7899ebaea74bf797f106ddf44fa132b8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"@Override\r\n\tpublic void onAudioDataReceived(byte[] audioData) {\r\n\t\tbyte[] transcodedAudio = transcoder.transcode(audioData);\r\n\t\tif (transcodedAudio != null) {\r\n\t\t\tpushAudio(transcodedAudio);\r\n\t\t} else {\r\n\t\t\tlog.warn(\"Transcoded audio is null. Discarding.\");\r\n\t\t}\r\n\t}","id":36689,"modified_method":"@Override\r\n\tpublic void onAudioDataReceived(byte[] audioData) {\r\n\t\ttranscoder.transcode(audioData, this);\r\n\t}","commit_id":"fcdf6dfb7899ebaea74bf797f106ddf44fa132b8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public byte[] transcodeAudio(byte[] srcAudio, int startOffset, int length) {\r\n\t\tbyte[] transcodedAudio = new byte[length];\r\n\t\tSystem.arraycopy(srcAudio, startOffset, transcodedAudio, 0, length);\r\n\t\treturn transcodedAudio;\r\n\t}","id":36690,"modified_method":"public void transcodeAudio(byte[] srcAudio, int startOffset, int length, TranscodedAudioDataListener listener) {\r\n\t\tbyte[] transcodedAudio = new byte[length];\r\n\t\tSystem.arraycopy(srcAudio, startOffset, transcodedAudio, 0, length);\r\n\t\tlistener.handleTranscodedAudioData(transcodedAudio);\r\n\t}","commit_id":"fcdf6dfb7899ebaea74bf797f106ddf44fa132b8","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"Expression transformBinaryExpression(final BinaryExpression bin) {\n        Object[] list = (Object[]) bin.getNodeMetaData(BINARY_EXP_TARGET);\n        Token operation = bin.getOperation();\n        int operationType = operation.getType();\n        if (operationType==Types.COMPARE_EQUAL || operationType == Types.COMPARE_NOT_EQUAL) {\n            // let's check if one of the operands is the null constant\n            CompareToNullExpression compareToNullExpression = null;\n            if (isNullConstant(bin.getLeftExpression())) {\n                compareToNullExpression = new CompareToNullExpression(staticCompilationTransformer.transform(bin.getRightExpression()), operationType==Types.COMPARE_EQUAL);\n            } else if (isNullConstant(bin.getRightExpression())) {\n                compareToNullExpression = new CompareToNullExpression(staticCompilationTransformer.transform(bin.getLeftExpression()), operationType==Types.COMPARE_EQUAL);\n            }\n            if (compareToNullExpression != null) {\n                compareToNullExpression.setSourcePosition(bin);\n                return compareToNullExpression;\n            }\n        } else if (operationType==Types.KEYWORD_IN) {\n            MethodCallExpression call = new MethodCallExpression(\n                    bin.getRightExpression(),\n                    \"isCase\",\n                    bin.getLeftExpression()\n            );\n            call.setMethodTarget((MethodNode) bin.getNodeMetaData(StaticTypesMarker.DIRECT_METHOD_CALL_TARGET));\n            call.setSourcePosition(bin);\n            call.copyNodeMetaData(bin);\n            return staticCompilationTransformer.transform(call);\n        }\n        if (list != null) {\n            if (operationType == Types.COMPARE_TO) {\n                StaticTypesTypeChooser typeChooser = staticCompilationTransformer.getTypeChooser();\n                ClassNode classNode = staticCompilationTransformer.getClassNode();\n                ClassNode leftType = typeChooser.resolveType(bin.getLeftExpression(), classNode);\n                if (leftType.implementsInterface(ClassHelper.COMPARABLE_TYPE)) {\n                    ClassNode rightType = typeChooser.resolveType(bin.getRightExpression(), classNode);\n                    if (rightType.implementsInterface(ClassHelper.COMPARABLE_TYPE)) {\n                        Expression left = staticCompilationTransformer.transform(bin.getLeftExpression());\n                        Expression right = staticCompilationTransformer.transform(bin.getRightExpression());\n                        MethodCallExpression call = new MethodCallExpression(left, \"compareTo\", new ArgumentListExpression(right));\n                        call.setImplicitThis(false);\n                        call.setMethodTarget(COMPARE_TO_METHOD);\n\n                        CompareIdentityExpression compareIdentity = new CompareIdentityExpression(\n                                left, right\n                        );\n                        compareIdentity.putNodeMetaData(StaticTypesMarker.INFERRED_RETURN_TYPE, ClassHelper.boolean_TYPE);\n                        TernaryExpression result = new TernaryExpression(\n                                new BooleanExpression(compareIdentity), // a==b\n                                CONSTANT_ZERO,\n                                new TernaryExpression(\n                                        new BooleanExpression(new CompareToNullExpression(left, true)), // a==null\n                                        CONSTANT_MINUS_ONE,\n                                        new TernaryExpression(\n                                                new BooleanExpression(new CompareToNullExpression(right, true)), // b==null\n                                                CONSTANT_ONE,\n                                                call\n                                        )\n                                )\n                        );\n                        compareIdentity.putNodeMetaData(StaticTypesMarker.INFERRED_RETURN_TYPE, ClassHelper.int_TYPE);\n                        result.putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        TernaryExpression expr = (TernaryExpression) result.getFalseExpression();\n                        expr.putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        expr.getFalseExpression().putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        return result;\n                    }\n                }\n            }\n            boolean isAssignment = StaticTypeCheckingSupport.isAssignment(operationType);\n            MethodCallExpression call;\n            MethodNode node = (MethodNode) list[0];\n            String name = (String) list[1];\n            Expression left = staticCompilationTransformer.transform(bin.getLeftExpression());\n            Expression right = staticCompilationTransformer.transform(bin.getRightExpression());\n            call = new MethodCallExpression(\n                    left,\n                    name,\n                    new ArgumentListExpression(right)\n            );\n            call.setImplicitThis(false);\n            call.setMethodTarget(node);\n            MethodNode adapter = StaticCompilationTransformer.BYTECODE_BINARY_ADAPTERS.get(operationType);\n            if (adapter != null) {\n                ClassExpression sba = new ClassExpression(StaticCompilationTransformer.BYTECODE_ADAPTER_CLASS);\n                // replace with compareEquals\n                call = new MethodCallExpression(sba,\n                        \"compareEquals\",\n                        new ArgumentListExpression(left, right));\n                call.setMethodTarget(adapter);\n                call.setImplicitThis(false);\n            }\n            if (!isAssignment) return call;\n            // case of +=, -=, /=, ...\n            // the method represents the operation type only, and we must add an assignment\n            return new BinaryExpression(left, Token.newSymbol(\"=\", operation.getStartLine(), operation.getStartColumn()), call);\n        }\n        if (bin.getOperation().getType() == Types.EQUAL && bin.getLeftExpression() instanceof TupleExpression && bin.getRightExpression() instanceof ListExpression) {\n            // multiple assignment\n            ListOfExpressionsExpression cle = new ListOfExpressionsExpression();\n            boolean isDeclaration = bin instanceof DeclarationExpression;\n            List<Expression> leftExpressions = ((TupleExpression) bin.getLeftExpression()).getExpressions();\n            List<Expression> rightExpressions = ((ListExpression) bin.getRightExpression()).getExpressions();\n            Iterator<Expression> leftIt = leftExpressions.iterator();\n            Iterator<Expression> rightIt = rightExpressions.iterator();\n            while (leftIt.hasNext()) {\n                Expression left = leftIt.next();\n                if (rightIt.hasNext()) {\n                    Expression right = rightIt.next();\n                    BinaryExpression bexp = isDeclaration?\n                            new DeclarationExpression(left, bin.getOperation(), right):\n                            new BinaryExpression(left, bin.getOperation(), right);\n                    bexp.setSourcePosition(right);\n                    cle.addExpression(bexp);\n                }\n            }\n            return staticCompilationTransformer.transform(cle);\n        }\n        return staticCompilationTransformer.superTransform(bin);\n    }","id":36691,"modified_method":"Expression transformBinaryExpression(final BinaryExpression bin) {\n        Object[] list = (Object[]) bin.getNodeMetaData(BINARY_EXP_TARGET);\n        Token operation = bin.getOperation();\n        int operationType = operation.getType();\n        Expression rightExpression = bin.getRightExpression();\n        Expression leftExpression = bin.getLeftExpression();\n        if (operationType==Types.COMPARE_EQUAL || operationType == Types.COMPARE_NOT_EQUAL) {\n            // let's check if one of the operands is the null constant\n            CompareToNullExpression compareToNullExpression = null;\n            if (isNullConstant(leftExpression)) {\n                compareToNullExpression = new CompareToNullExpression(staticCompilationTransformer.transform(rightExpression), operationType==Types.COMPARE_EQUAL);\n            } else if (isNullConstant(rightExpression)) {\n                compareToNullExpression = new CompareToNullExpression(staticCompilationTransformer.transform(leftExpression), operationType==Types.COMPARE_EQUAL);\n            }\n            if (compareToNullExpression != null) {\n                compareToNullExpression.setSourcePosition(bin);\n                return compareToNullExpression;\n            }\n        } else if (operationType==Types.KEYWORD_IN) {\n            MethodCallExpression call = new MethodCallExpression(\n                    rightExpression,\n                    \"isCase\",\n                    leftExpression\n            );\n            call.setMethodTarget((MethodNode) bin.getNodeMetaData(StaticTypesMarker.DIRECT_METHOD_CALL_TARGET));\n            call.setSourcePosition(bin);\n            call.copyNodeMetaData(bin);\n            TernaryExpression tExp = new TernaryExpression(\n                    new BooleanExpression(\n                            new BinaryExpression(rightExpression, Token.newSymbol(\"==\",-1,-1), new ConstantExpression(null))\n                    ),\n                    new BinaryExpression(leftExpression, Token.newSymbol(\"==\", -1, -1), new ConstantExpression(null)),\n                    call\n            );\n            return staticCompilationTransformer.transform(tExp);\n        }\n        if (list != null) {\n            if (operationType == Types.COMPARE_TO) {\n                StaticTypesTypeChooser typeChooser = staticCompilationTransformer.getTypeChooser();\n                ClassNode classNode = staticCompilationTransformer.getClassNode();\n                ClassNode leftType = typeChooser.resolveType(leftExpression, classNode);\n                if (leftType.implementsInterface(ClassHelper.COMPARABLE_TYPE)) {\n                    ClassNode rightType = typeChooser.resolveType(rightExpression, classNode);\n                    if (rightType.implementsInterface(ClassHelper.COMPARABLE_TYPE)) {\n                        Expression left = staticCompilationTransformer.transform(leftExpression);\n                        Expression right = staticCompilationTransformer.transform(rightExpression);\n                        MethodCallExpression call = new MethodCallExpression(left, \"compareTo\", new ArgumentListExpression(right));\n                        call.setImplicitThis(false);\n                        call.setMethodTarget(COMPARE_TO_METHOD);\n\n                        CompareIdentityExpression compareIdentity = new CompareIdentityExpression(\n                                left, right\n                        );\n                        compareIdentity.putNodeMetaData(StaticTypesMarker.INFERRED_RETURN_TYPE, ClassHelper.boolean_TYPE);\n                        TernaryExpression result = new TernaryExpression(\n                                new BooleanExpression(compareIdentity), // a==b\n                                CONSTANT_ZERO,\n                                new TernaryExpression(\n                                        new BooleanExpression(new CompareToNullExpression(left, true)), // a==null\n                                        CONSTANT_MINUS_ONE,\n                                        new TernaryExpression(\n                                                new BooleanExpression(new CompareToNullExpression(right, true)), // b==null\n                                                CONSTANT_ONE,\n                                                call\n                                        )\n                                )\n                        );\n                        compareIdentity.putNodeMetaData(StaticTypesMarker.INFERRED_RETURN_TYPE, ClassHelper.int_TYPE);\n                        result.putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        TernaryExpression expr = (TernaryExpression) result.getFalseExpression();\n                        expr.putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        expr.getFalseExpression().putNodeMetaData(StaticTypesMarker.INFERRED_TYPE, ClassHelper.int_TYPE);\n                        return result;\n                    }\n                }\n            }\n            boolean isAssignment = StaticTypeCheckingSupport.isAssignment(operationType);\n            MethodCallExpression call;\n            MethodNode node = (MethodNode) list[0];\n            String name = (String) list[1];\n            Expression left = staticCompilationTransformer.transform(leftExpression);\n            Expression right = staticCompilationTransformer.transform(rightExpression);\n            call = new MethodCallExpression(\n                    left,\n                    name,\n                    new ArgumentListExpression(right)\n            );\n            call.setImplicitThis(false);\n            call.setMethodTarget(node);\n            MethodNode adapter = StaticCompilationTransformer.BYTECODE_BINARY_ADAPTERS.get(operationType);\n            if (adapter != null) {\n                ClassExpression sba = new ClassExpression(StaticCompilationTransformer.BYTECODE_ADAPTER_CLASS);\n                // replace with compareEquals\n                call = new MethodCallExpression(sba,\n                        \"compareEquals\",\n                        new ArgumentListExpression(left, right));\n                call.setMethodTarget(adapter);\n                call.setImplicitThis(false);\n            }\n            if (!isAssignment) return call;\n            // case of +=, -=, /=, ...\n            // the method represents the operation type only, and we must add an assignment\n            return new BinaryExpression(left, Token.newSymbol(\"=\", operation.getStartLine(), operation.getStartColumn()), call);\n        }\n        if (bin.getOperation().getType() == Types.EQUAL && leftExpression instanceof TupleExpression && rightExpression instanceof ListExpression) {\n            // multiple assignment\n            ListOfExpressionsExpression cle = new ListOfExpressionsExpression();\n            boolean isDeclaration = bin instanceof DeclarationExpression;\n            List<Expression> leftExpressions = ((TupleExpression) leftExpression).getExpressions();\n            List<Expression> rightExpressions = ((ListExpression) rightExpression).getExpressions();\n            Iterator<Expression> leftIt = leftExpressions.iterator();\n            Iterator<Expression> rightIt = rightExpressions.iterator();\n            while (leftIt.hasNext()) {\n                Expression left = leftIt.next();\n                if (rightIt.hasNext()) {\n                    Expression right = rightIt.next();\n                    BinaryExpression bexp = isDeclaration?\n                            new DeclarationExpression(left, bin.getOperation(), right):\n                            new BinaryExpression(left, bin.getOperation(), right);\n                    bexp.setSourcePosition(right);\n                    cle.addExpression(bexp);\n                }\n            }\n            return staticCompilationTransformer.transform(cle);\n        }\n        return staticCompilationTransformer.superTransform(bin);\n    }","commit_id":"02f9977fdc666d6434b52f4ab61c451ce30bd358","url":"https://github.com/apache/groovy"},{"original_method":"@Override\n    public void visitPrefixExpression(final PrefixExpression expression) {\n        super.visitPrefixExpression(expression);\n        checkPrePostfixOperation(expression.getExpression(), expression);\n    }","id":36692,"modified_method":"@Override\n    public void visitPrefixExpression(final PrefixExpression expression) {\n        inAssignment = expression.getExpression() instanceof VariableExpression;\n        super.visitPrefixExpression(expression);\n        inAssignment = false;\n        checkPrePostfixOperation(expression.getExpression(), expression);\n    }","commit_id":"240d1b97700affca6b42b2ba58daa17706e9ee4b","url":"https://github.com/apache/groovy"},{"original_method":"private void recordAssignment(\n            Variable var,\n            boolean isDeclaration,\n            boolean uninitialized,\n            boolean forceVariable,\n            Expression expression) {\n        if (var == null) {\n            return;\n        }\n        if (!isDeclaration && var.isClosureSharedVariable()) {\n            getState().put(var, VariableState.is_var);\n        }\n        VariableState count = getState().get(var);\n        if (count == null) {\n            count = uninitialized ? VariableState.is_uninitialized : VariableState.is_final;\n            if (var instanceof Parameter) {\n                count = VariableState.is_var;\n            }\n        } else {\n            count = count.getNext();\n        }\n        if (forceVariable) {\n            count = VariableState.is_var;\n        }\n        getState().put(var, count);\n        if (count == VariableState.is_var && callback != null) {\n            callback.variableNotFinal(var, expression);\n        }\n    }","id":36693,"modified_method":"private void recordAssignment(\n            Variable var,\n            boolean isDeclaration,\n            boolean uninitialized,\n            boolean forceVariable,\n            Expression expression) {\n        if (var == null) {\n            return;\n        }\n        if (!isDeclaration && var.isClosureSharedVariable()) {\n            getState().put(var, VariableState.is_var);\n        }\n        VariableState variableState = getState().get(var);\n        if (variableState == null) {\n            variableState = uninitialized ? VariableState.is_uninitialized : VariableState.is_final;\n            if (var instanceof Parameter) {\n                variableState = VariableState.is_var;\n            }\n        } else {\n            variableState = variableState.getNext();\n        }\n        if (forceVariable) {\n            variableState = VariableState.is_var;\n        }\n        getState().put(var, variableState);\n        if (variableState == VariableState.is_var && callback != null) {\n            callback.variableNotFinal(var, expression);\n        }\n    }","commit_id":"240d1b97700affca6b42b2ba58daa17706e9ee4b","url":"https://github.com/apache/groovy"},{"original_method":"@Override\n    public void visitBinaryExpression(final BinaryExpression expression) {\n        super.visitBinaryExpression(expression);\n        if (StaticTypeCheckingSupport.isAssignment(expression.getOperation().getType())) {\n            Expression leftExpression = expression.getLeftExpression();\n            if (leftExpression instanceof Variable) {\n                boolean isDeclaration = expression instanceof DeclarationExpression;\n                boolean uninitialized =\n                        isDeclaration &&\n                                expression.getRightExpression() == EmptyExpression.INSTANCE;\n                recordAssignment((Variable) leftExpression, isDeclaration, uninitialized, false, expression);\n                if (leftExpression instanceof VariableExpression) {\n                    Variable accessed = ((VariableExpression) leftExpression).getAccessedVariable();\n                    if (accessed != leftExpression) {\n                        recordAssignment(accessed, isDeclaration, uninitialized, false, expression);\n                    }\n                }\n            }\n        }\n    }","id":36694,"modified_method":"@Override\n    public void visitBinaryExpression(final BinaryExpression expression) {\n        boolean assignment = StaticTypeCheckingSupport.isAssignment(expression.getOperation().getType());\n        boolean isDeclaration = expression instanceof DeclarationExpression;\n        Expression leftExpression = expression.getLeftExpression();\n        Expression rightExpression = expression.getRightExpression();\n        leftExpression.visit(this);\n        inAssignment = assignment;\n        rightExpression.visit(this);\n        inAssignment = false;\n        if (assignment) {\n            if (leftExpression instanceof Variable) {\n                boolean uninitialized =\n                        isDeclaration &&\n                                rightExpression == EmptyExpression.INSTANCE;\n                recordAssignment((Variable) leftExpression, isDeclaration, uninitialized, false, expression);\n                if (leftExpression instanceof VariableExpression) {\n                    Variable accessed = ((VariableExpression) leftExpression).getAccessedVariable();\n                    if (accessed != leftExpression) {\n                        recordAssignment(accessed, isDeclaration, uninitialized, false, expression);\n                    }\n                }\n            }\n        }\n    }","commit_id":"240d1b97700affca6b42b2ba58daa17706e9ee4b","url":"https://github.com/apache/groovy"},{"original_method":"@Override\n    public void visitPostfixExpression(final PostfixExpression expression) {\n        super.visitPostfixExpression(expression);\n        checkPrePostfixOperation(expression.getExpression(), expression);\n    }","id":36695,"modified_method":"@Override\n    public void visitPostfixExpression(final PostfixExpression expression) {\n        inAssignment = expression.getExpression() instanceof VariableExpression;\n        super.visitPostfixExpression(expression);\n        inAssignment = false;\n        checkPrePostfixOperation(expression.getExpression(), expression);\n    }","commit_id":"240d1b97700affca6b42b2ba58daa17706e9ee4b","url":"https://github.com/apache/groovy"},{"original_method":"private void checkFinalVariables(ClassNode node) {\n        FinalVariableAnalyzer analyzer = new FinalVariableAnalyzer(null, new FinalVariableAnalyzer.VariableNotFinalCallback() {\n            @Override\n            public void variableNotFinal(Variable var, Expression bexp) {\n                if (var instanceof VariableExpression) {\n                    var = ((VariableExpression) var).getAccessedVariable();\n                }\n                if (var instanceof VariableExpression && Modifier.isFinal(var.getModifiers())) {\n                    throw new RuntimeParserException(\"The variable [\"+var.getName()+\"] is declared final but is reassigned\",bexp);\n                }\n                if (var instanceof Parameter && Modifier.isFinal(var.getModifiers())) {\n                    throw new RuntimeParserException(\"The parameter [\"+var.getName()+\"] is declared final but is reassigned\",bexp);\n                }\n            }\n        });\n        analyzer.visitClass(node);\n\n    }","id":36696,"modified_method":"private void checkFinalVariables(ClassNode node) {\n        FinalVariableAnalyzer analyzer = new FinalVariableAnalyzer(null, new FinalVariableAnalyzer.VariableNotFinalCallback() {\n            @Override\n            public void variableNotFinal(Variable var, Expression bexp) {\n                if (var instanceof VariableExpression) {\n                    var = ((VariableExpression) var).getAccessedVariable();\n                }\n                if (var instanceof VariableExpression && Modifier.isFinal(var.getModifiers())) {\n                    throw new RuntimeParserException(\"The variable [\"+var.getName()+\"] is declared final but is reassigned\",bexp);\n                }\n                if (var instanceof Parameter && Modifier.isFinal(var.getModifiers())) {\n                    throw new RuntimeParserException(\"The parameter [\"+var.getName()+\"] is declared final but is reassigned\",bexp);\n                }\n            }\n\n            @Override\n            public void variableNotAlwaysInitialized(final VariableExpression var) {\n                throw new RuntimeParserException(\"The variable [\"+var.getName()+\"] may be uninitialized\", var);\n            }\n        });\n        analyzer.visitClass(node);\n\n    }","commit_id":"240d1b97700affca6b42b2ba58daa17706e9ee4b","url":"https://github.com/apache/groovy"},{"original_method":"private boolean isRightSimplified(@NotNull final PyBinaryExpression leftExpression,\n                                      @NotNull final PyBinaryExpression rightExpression) {\n      final PyExpression leftRight = leftExpression.getRightExpression();\n      if (leftRight != null && PyTokenTypes.AND_KEYWORD == leftExpression.getOperator()) {\n        if (isRightSimplified((PyBinaryExpression)leftRight, rightExpression)) {\n          getInnerRight = true;\n          return true;\n        }\n      }\n\n      if (leftRight instanceof PyBinaryExpression &&\n          PyTokenTypes.RELATIONAL_OPERATIONS.contains(((PyBinaryExpression)leftRight).getOperator())){\n        if (isRightSimplified((PyBinaryExpression)leftRight, rightExpression))\n          return true;\n      }\n\n      myOperator = leftExpression.getOperator();\n      if (PyTokenTypes.RELATIONAL_OPERATIONS.contains(myOperator)) {\n        if (leftRight != null) {\n          if (leftRight.getText().equals(getLeftExpression(rightExpression, true).getText())) {\n            myIsLeft = false;\n            myIsRight = true;\n            return true;\n          }\n\n          final PyExpression right = getSmallestRight(rightExpression, true);\n          if (right != null && leftRight.getText().equals(right.getText())) {\n            myIsLeft = false;\n            myIsRight = false;\n            return true;\n          }\n        }\n      }\n      return false;\n    }","id":36697,"modified_method":"private boolean isRightSimplified(@NotNull final PyBinaryExpression leftExpression,\n                                      @NotNull final PyBinaryExpression rightExpression) {\n      final PyExpression leftRight = leftExpression.getRightExpression();\n      if (leftRight instanceof PyBinaryExpression && PyTokenTypes.AND_KEYWORD == leftExpression.getOperator()) {\n        if (isRightSimplified((PyBinaryExpression)leftRight, rightExpression)) {\n          getInnerRight = true;\n          return true;\n        }\n      }\n\n      if (leftRight instanceof PyBinaryExpression &&\n          PyTokenTypes.RELATIONAL_OPERATIONS.contains(((PyBinaryExpression)leftRight).getOperator())){\n        if (isRightSimplified((PyBinaryExpression)leftRight, rightExpression))\n          return true;\n      }\n\n      myOperator = leftExpression.getOperator();\n      if (PyTokenTypes.RELATIONAL_OPERATIONS.contains(myOperator)) {\n        if (leftRight != null) {\n          if (leftRight.getText().equals(getLeftExpression(rightExpression, true).getText())) {\n            myIsLeft = false;\n            myIsRight = true;\n            return true;\n          }\n\n          final PyExpression right = getSmallestRight(rightExpression, true);\n          if (right != null && leftRight.getText().equals(right.getText())) {\n            myIsLeft = false;\n            myIsRight = false;\n            return true;\n          }\n        }\n      }\n      return false;\n    }","commit_id":"df506fa27b198e4a3214b9db7944df94b2e284bd","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean isLeftSimplified(PyBinaryExpression leftExpression, PyBinaryExpression rightExpression) {\n      final PyExpression leftRight = leftExpression.getLeftExpression();\n      if (leftExpression.getRightExpression() instanceof PyBinaryExpression\n          && PyTokenTypes.AND_KEYWORD == leftExpression.getOperator()) {\n        if (isLeftSimplified((PyBinaryExpression)leftExpression.getRightExpression(), rightExpression)) {\n          getInnerRight = true;\n          return true;\n        }\n      }\n\n      if (leftRight instanceof PyBinaryExpression &&\n        PyTokenTypes.RELATIONAL_OPERATIONS.contains(((PyBinaryExpression)leftRight).getOperator())){\n        if (isLeftSimplified((PyBinaryExpression)leftRight, rightExpression))\n          return true;\n      }\n\n      myOperator = leftExpression.getOperator();\n      if (PyTokenTypes.RELATIONAL_OPERATIONS.contains(myOperator)) {\n        if (leftRight != null) {\n          if (leftRight.getText().equals(getLeftExpression(rightExpression, false).getText())) {\n            myIsLeft = true;\n            myIsRight = true;\n            return true;\n          }\n          final PyExpression right = getSmallestRight(rightExpression, false);\n          if (right != null && leftRight.getText().equals(right.getText())) {\n            myIsLeft = true;\n            myIsRight = false;\n            return true;\n          }\n        }\n      }\n      return false;\n    }","id":36698,"modified_method":"private boolean isLeftSimplified(PyBinaryExpression leftExpression, PyBinaryExpression rightExpression) {\n      final PyExpression leftLeft = leftExpression.getLeftExpression();\n      final PyExpression leftRight = leftExpression.getRightExpression();\n      if (leftRight instanceof PyBinaryExpression\n          && PyTokenTypes.AND_KEYWORD == leftExpression.getOperator()) {\n        if (isLeftSimplified((PyBinaryExpression)leftRight, rightExpression)) {\n          getInnerRight = true;\n          return true;\n        }\n      }\n\n      if (leftLeft instanceof PyBinaryExpression &&\n        PyTokenTypes.RELATIONAL_OPERATIONS.contains(((PyBinaryExpression)leftLeft).getOperator())){\n        if (isLeftSimplified((PyBinaryExpression)leftLeft, rightExpression))\n          return true;\n      }\n\n      myOperator = leftExpression.getOperator();\n      if (PyTokenTypes.RELATIONAL_OPERATIONS.contains(myOperator)) {\n        if (leftLeft != null) {\n          if (leftLeft.getText().equals(getLeftExpression(rightExpression, false).getText())) {\n            myIsLeft = true;\n            myIsRight = true;\n            return true;\n          }\n          final PyExpression right = getSmallestRight(rightExpression, false);\n          if (right != null && leftLeft.getText().equals(right.getText())) {\n            myIsLeft = true;\n            myIsRight = false;\n            return true;\n          }\n        }\n      }\n      return false;\n    }","commit_id":"df506fa27b198e4a3214b9db7944df94b2e284bd","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void backup(Collection current, BackupDialog dialog)\n\t\tthrows XMLDBException, IOException, SAXException {\n\t\tif (current == null)\n\t\t\treturn;\n\t\tcurrent.setProperty(OutputKeys.ENCODING, \"UTF-8\");\n\t\tcurrent.setProperty(OutputKeys.INDENT, \"no\");\n\t\tcurrent.setProperty(EXistOutputKeys.EXPAND_XINCLUDES, \"no\");\n\t\tcurrent.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"no\");\n\n\t\t// get resources and permissions\n\t\tString[] resources = current.listResources();\n\t\t\n\t\tString cname = current.getName();\n\t\tif (cname.charAt(0) != '/')\n\t\t\tcname = '/' + cname;\n\t\tString path = backupDir + encode(cname);\n\t\t\n\t\tUserManagementService mgtService =\n\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\tPermission perms[] = mgtService.listResourcePermissions();\n\t\tPermission currentPerms = mgtService.getPermissions(current);\n\n\t\tif (dialog != null) {\n\t\t\tdialog.setCollection(current.getName());\n\t\t\tdialog.setResourceCount(resources.length);\n\t\t}\n\t\t// create directory and open __contents__.xml\n\t\tFile file = new File(path);\n\t\tif(file.exists()) {\n\t\t\tSystem.out.println(\"removing \" + path);\n\t\t\tfile.delete();\n\t\t}\n\t\tfile.mkdirs();\n\t\tBufferedWriter contents =\n\t\t\tnew BufferedWriter(\n\t\t\t\tnew OutputStreamWriter(\n\t\t\t\t\tnew FileOutputStream(path + '/' + \"__contents__.xml\"),\n\t\t\t\t\t\"UTF-8\"));\n\t\t// serializer writes to __contents__.xml\n\t\tSAXSerializer serializer = SAXSerializerPool.getInstance().borrowSAXSerializer();\n\t\tserializer.setWriter(contents);\n\t\tserializer.setOutputProperties(defaultOutputProperties);\n\t\t\n\t\tserializer.startDocument();\n\t\tserializer.startPrefixMapping(\"\", NS);\n\t\t// write <collection> element\n\t\tCollectionImpl cur = (CollectionImpl)current;\n\t\tAttributesImpl attr = new AttributesImpl();\n\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", current.getName());\n\t\tattr.addAttribute(NS, \"owner\", \"owner\", \"CDATA\", currentPerms.getOwner());\n\t\tattr.addAttribute(NS, \"group\", \"group\", \"CDATA\", currentPerms.getOwnerGroup());\n\t\tattr.addAttribute(\n\t\t\tNS,\n\t\t\t\"mode\",\n\t\t\t\"mode\",\n\t\t\t\"CDATA\",\n\t\t\tInteger.toOctalString(currentPerms.getPermissions()));\n\t\tattr.addAttribute(\n\t\t\t\tNS,\n\t\t\t\t\"created\",\n\t\t\t\t\"created\",\n\t\t\t\t\"CDATA\",\n\t\t\t\tcur.getCreationTime().toString());\n\t\tserializer.startElement(NS, \"collection\", \"collection\", attr);\n\n\t\t// scan through resources\n\t\tResource resource;\n\t\tFileOutputStream os;\n\t\tBufferedWriter writer;\n\t\tSAXSerializer contentSerializer;\n\t\tfor (int i = 0; i < resources.length; i++) {\n\t\t\tresource = current.getResource(resources[i]);\n\t\t\tfile = new File(path);\n\t\t\tif (!file.exists())\n\t\t\t\tfile.mkdirs();\n\t\t\tif (dialog == null)\n\t\t\t\tSystem.out.println(\"writing \" + path + '/' + resources[i]);\n\t\t\telse {\n\t\t\t\tdialog.setResource(resources[i]);\n\t\t\t\tdialog.setProgress(i);\n\t\t\t}\n\t\t\t//os = new FileOutputStream(path + '/' + resources[i]);\n\t\t\tos = new FileOutputStream(path + '/' + encode(resources[i]));\n\t\t\tif(resource.getResourceType().equals(\"BinaryResource\")) {\n\t\t\t\tbyte[] bdata = (byte[])resource.getContent();\n\t\t\t\tos.write(bdata);\n\t\t\t\tos.close();\n\t\t\t} else {\n\t\t\t    try {\n\t\t\t\t\twriter =\n\t\t\t\t\t\tnew BufferedWriter(\n\t\t\t\t\t\t\tnew OutputStreamWriter(os, \"UTF-8\"));\n\t\t\t\t\t// write resource to contentSerializer\n\t\t\t\t\tcontentSerializer = SAXSerializerPool.getInstance().borrowSAXSerializer();\n\t\t\t\t\tcontentSerializer.setWriter(writer);\n\t\t\t\t\tcontentSerializer.setOutputProperties(defaultOutputProperties);\n\t\t\t\t\t((EXistResource)resource).setLexicalHandler(contentSerializer);\n\t\t\t\t\t((XMLResource)resource).getContentAsSAX(contentSerializer);\n\t\t\t\t\tSAXSerializerPool.getInstance().returnSAXSerializer(contentSerializer);\n\t\t\t\t\twriter.close();\n\t\t\t    } catch(Exception e) {\n\t\t\t        System.err.println(\"An exception occurred while writing the resource: \" + e.getMessage());\n\t\t\t        e.printStackTrace();\n\t\t\t        continue;\n\t\t\t    }\n\t\t\t}\n\t\t\tEXistResource ris = (EXistResource)resource;\n\t\t\t\n\t\t\t//store permissions\n\t\t\tattr.clear();\n\t\t\tattr.addAttribute(NS, \"type\", \"type\", \"CDATA\", resource.getResourceType());\n\t\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", resources[i]);\n\t\t\tattr.addAttribute(NS, \"owner\", \"owner\", \"CDATA\", perms[i].getOwner());\n\t\t\tattr.addAttribute(NS, \"group\", \"group\", \"CDATA\", perms[i].getOwnerGroup());\n\t\t\tattr.addAttribute(\n\t\t\t\tNS,\n\t\t\t\t\"mode\",\n\t\t\t\t\"mode\",\n\t\t\t\t\"CDATA\",\n\t\t\t\tInteger.toOctalString(perms[i].getPermissions()));\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"created\",\n\t\t\t\t\t\"created\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tris.getCreationTime().toString());\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"modified\",\n\t\t\t\t\t\"modified\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tris.getLastModificationTime().toString());\n\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"filename\",\n\t\t\t\t\t\"filename\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tencode( \"\"+resources[i] )\n\t\t\t\t\t );\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"mimetype\",\n\t\t\t\t\t\"mimetype\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tencode( ((EXistResource)resource).getMimeType())\n\t\t\t\t\t );\n\t\t\t\n\t\t\tserializer.startElement(NS, \"resource\", \"resource\", attr);\n\t\t\tserializer.endElement(NS, \"resource\", \"resource\");\n\t\t}\n\t\t// write subcollections\n\t\tString[] collections = current.listChildCollections();\n\t\tfor (int i = 0; i < collections.length; i++) {\n\t\t\tif (current.getName().equals(\"db\") && collections[i].equals(\"system\"))\n\t\t\t\tcontinue;\n\t\t\tattr.clear();\n\t\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", collections[i]);\n\t\t\tattr.addAttribute(NS, \"filename\", \"filename\", \"CDATA\", encode(collections[i]));\n\t\t\tserializer.startElement(NS, \"subcollection\", \"subcollection\", attr);\n\t\t\tserializer.endElement(NS, \"subcollection\", \"subcollection\");\n\t\t}\n\t\t// close <collection>\n\t\tserializer.endElement(NS, \"collection\", \"collection\");\n\t\tserializer.endPrefixMapping(\"\");\n\t\tserializer.endDocument();\n\t\tcontents.close();\n\t\tSAXSerializerPool.getInstance().returnSAXSerializer(serializer);\n\t\t// descend into subcollections\n\t\tCollection child;\n\t\tfor (int i = 0; i < collections.length; i++) {\n\t\t\tchild = current.getChildCollection(collections[i]);\n\t\t\tbackup(child, dialog);\n\t\t}\n\t}","id":36699,"modified_method":"private void backup(Collection current, BackupDialog dialog)\n\t\tthrows XMLDBException, IOException, SAXException {\n\t\tif (current == null)\n\t\t\treturn;\n\t\tcurrent.setProperty(OutputKeys.ENCODING, \"UTF-8\");\n\t\tcurrent.setProperty(OutputKeys.INDENT, \"no\");\n\t\tcurrent.setProperty(EXistOutputKeys.EXPAND_XINCLUDES, \"no\");\n\t\tcurrent.setProperty(EXistOutputKeys.PROCESS_XSL_PI, \"no\");\n\n\t\t// get resources and permissions\n\t\tString[] resources = current.listResources();\n\t\t\n\t\tString cname = current.getName();\n\t\tif (cname.charAt(0) != '/')\n\t\t\tcname = '/' + cname;\n\t\tString path = backupDir + encode(cname);\n\t\t\n\t\tUserManagementService mgtService =\n\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\tPermission perms[] = mgtService.listResourcePermissions();\n\t\tPermission currentPerms = mgtService.getPermissions(current);\n\n\t\tif (dialog != null) {\n\t\t\tdialog.setCollection(current.getName());\n\t\t\tdialog.setResourceCount(resources.length);\n\t\t}\n\t\t// create directory and open __contents__.xml\n\t\tFile file = new File(path);\n\t\tif(file.exists()) {\n\t\t\tSystem.out.println(\"removing \" + path);\n\t\t\tfile.delete();\n\t\t}\n\t\tfile.mkdirs();\n\t\tBufferedWriter contents =\n\t\t\tnew BufferedWriter(\n\t\t\t\tnew OutputStreamWriter(\n\t\t\t\t\tnew FileOutputStream(path + '/' + \"__contents__.xml\"),\n\t\t\t\t\t\"UTF-8\"));\n\t\t// serializer writes to __contents__.xml\n\t\tSAXSerializer serializer = SAXSerializerPool.getInstance().borrowSAXSerializer();\n\t\tserializer.setWriter(contents);\n\t\tserializer.setOutputProperties(defaultOutputProperties);\n\t\t\n\t\tserializer.startDocument();\n\t\tserializer.startPrefixMapping(\"\", NS);\n\t\t// write <collection> element\n\t\tCollectionImpl cur = (CollectionImpl)current;\n\t\tAttributesImpl attr = new AttributesImpl();\n\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", current.getName());\n\t\tattr.addAttribute(NS, \"owner\", \"owner\", \"CDATA\", currentPerms.getOwner());\n\t\tattr.addAttribute(NS, \"group\", \"group\", \"CDATA\", currentPerms.getOwnerGroup());\n\t\tattr.addAttribute(\n\t\t\tNS,\n\t\t\t\"mode\",\n\t\t\t\"mode\",\n\t\t\t\"CDATA\",\n\t\t\tInteger.toOctalString(currentPerms.getPermissions()));\n\t\tattr.addAttribute(\n\t\t\t\tNS,\n\t\t\t\t\"created\",\n\t\t\t\t\"created\",\n\t\t\t\t\"CDATA\",\n\t\t\t\t\"\"+new DateTimeValue(cur.getCreationTime().getTime()));\n\t\tserializer.startElement(NS, \"collection\", \"collection\", attr);\n\n\t\t// scan through resources\n\t\tResource resource;\n\t\tFileOutputStream os;\n\t\tBufferedWriter writer;\n\t\tSAXSerializer contentSerializer;\n\t\tfor (int i = 0; i < resources.length; i++) {\n\t\t\tresource = current.getResource(resources[i]);\n\t\t\tfile = new File(path);\n\t\t\tif (!file.exists())\n\t\t\t\tfile.mkdirs();\n\t\t\tif (dialog == null)\n\t\t\t\tSystem.out.println(\"writing \" + path + '/' + resources[i]);\n\t\t\telse {\n\t\t\t\tdialog.setResource(resources[i]);\n\t\t\t\tdialog.setProgress(i);\n\t\t\t}\n\t\t\t//os = new FileOutputStream(path + '/' + resources[i]);\n\t\t\tos = new FileOutputStream(path + '/' + encode(resources[i]));\n\t\t\tif(resource.getResourceType().equals(\"BinaryResource\")) {\n\t\t\t\tbyte[] bdata = (byte[])resource.getContent();\n\t\t\t\tos.write(bdata);\n\t\t\t\tos.close();\n\t\t\t} else {\n\t\t\t    try {\n\t\t\t\t\twriter =\n\t\t\t\t\t\tnew BufferedWriter(\n\t\t\t\t\t\t\tnew OutputStreamWriter(os, \"UTF-8\"));\n\t\t\t\t\t// write resource to contentSerializer\n\t\t\t\t\tcontentSerializer = SAXSerializerPool.getInstance().borrowSAXSerializer();\n\t\t\t\t\tcontentSerializer.setWriter(writer);\n\t\t\t\t\tcontentSerializer.setOutputProperties(defaultOutputProperties);\n\t\t\t\t\t((EXistResource)resource).setLexicalHandler(contentSerializer);\n\t\t\t\t\t((XMLResource)resource).getContentAsSAX(contentSerializer);\n\t\t\t\t\tSAXSerializerPool.getInstance().returnSAXSerializer(contentSerializer);\n\t\t\t\t\twriter.close();\n\t\t\t    } catch(Exception e) {\n\t\t\t        System.err.println(\"An exception occurred while writing the resource: \" + e.getMessage());\n\t\t\t        e.printStackTrace();\n\t\t\t        continue;\n\t\t\t    }\n\t\t\t}\n\t\t\tEXistResource ris = (EXistResource)resource;\n\t\t\t\n\t\t\t//store permissions\n\t\t\tattr.clear();\n\t\t\tattr.addAttribute(NS, \"type\", \"type\", \"CDATA\", resource.getResourceType());\n\t\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", resources[i]);\n\t\t\tattr.addAttribute(NS, \"owner\", \"owner\", \"CDATA\", perms[i].getOwner());\n\t\t\tattr.addAttribute(NS, \"group\", \"group\", \"CDATA\", perms[i].getOwnerGroup());\n\t\t\tattr.addAttribute(\n\t\t\t\tNS,\n\t\t\t\t\"mode\",\n\t\t\t\t\"mode\",\n\t\t\t\t\"CDATA\",\n\t\t\t\tInteger.toOctalString(perms[i].getPermissions()));\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"created\",\n\t\t\t\t\t\"created\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\t\"\"+new DateTimeValue(ris.getCreationTime().getTime()));\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"modified\",\n\t\t\t\t\t\"modified\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\t\"\"+new DateTimeValue(ris.getLastModificationTime().getTime()));\n\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"filename\",\n\t\t\t\t\t\"filename\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tencode( \"\"+resources[i] )\n\t\t\t\t\t );\n\t\t\tattr.addAttribute(\n\t\t\t\t\tNS,\n\t\t\t\t\t\"mimetype\",\n\t\t\t\t\t\"mimetype\",\n\t\t\t\t\t\"CDATA\",\n\t\t\t\t\tencode( ((EXistResource)resource).getMimeType())\n\t\t\t\t\t );\n\t\t\t\n\t\t\tserializer.startElement(NS, \"resource\", \"resource\", attr);\n\t\t\tserializer.endElement(NS, \"resource\", \"resource\");\n\t\t}\n\t\t// write subcollections\n\t\tString[] collections = current.listChildCollections();\n\t\tfor (int i = 0; i < collections.length; i++) {\n\t\t\tif (current.getName().equals(\"db\") && collections[i].equals(\"system\"))\n\t\t\t\tcontinue;\n\t\t\tattr.clear();\n\t\t\tattr.addAttribute(NS, \"name\", \"name\", \"CDATA\", collections[i]);\n\t\t\tattr.addAttribute(NS, \"filename\", \"filename\", \"CDATA\", encode(collections[i]));\n\t\t\tserializer.startElement(NS, \"subcollection\", \"subcollection\", attr);\n\t\t\tserializer.endElement(NS, \"subcollection\", \"subcollection\");\n\t\t}\n\t\t// close <collection>\n\t\tserializer.endElement(NS, \"collection\", \"collection\");\n\t\tserializer.endPrefixMapping(\"\");\n\t\tserializer.endDocument();\n\t\tcontents.close();\n\t\tSAXSerializerPool.getInstance().returnSAXSerializer(serializer);\n\t\t// descend into subcollections\n\t\tCollection child;\n\t\tfor (int i = 0; i < collections.length; i++) {\n\t\t\tchild = current.getChildCollection(collections[i]);\n\t\t\tbackup(child, dialog);\n\t\t}\n\t}","commit_id":"752ea5d6ba9e817523d3f5a9b2d19ae1ada578f5","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n\t * @see org.xml.sax.ContentHandler#startElement(java.lang.String, java.lang.String, java.lang.String, org.xml.sax.Attributes)\n\t */\n\tpublic void startElement(String namespaceURI, String localName, String qName, Attributes atts)\n\t\tthrows SAXException {\n\t\tif (namespaceURI.equals(NS)) {\n\t\t\tif (localName.equals(\"collection\")) {\n\t\t\t\tfinal String name = atts.getValue(\"name\");\n\t\t\t\tfinal String owner = atts.getValue(\"owner\");\n\t\t\t\tfinal String group = atts.getValue(\"group\");\n\t\t\t\tfinal String mode = atts.getValue(\"mode\");\n\t\t\t\tfinal String created = atts.getValue(\"created\");\n\n\t\t\t\t\n\t\t\t\tif (name == null)\n\t\t\t\t\tthrow new SAXException(\"collection requires a name \" + \"attribute\");\n\t\t\t\ttry {\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.displayMessage(\"creating collection \" + name);\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tSimpleDateFormat formatter\n\t\t\t\t     = new SimpleDateFormat (\"EEE MMM dd HH:mm:ss 'CET' yyyy\", Locale.US);\n\t\t\t\t\t\n\t\t\t\t\tDate date_created = null;\n\t\t\t\t\t\n\t\t\t\t\tif (created != null) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\tdate_created = formatter.parse( created);\n\t\t\t\t\t\t} catch (ParseException e) {\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t \n\t\t\t\t\t\n\t\t\t\t\tcurrent = mkcol(name, date_created);\n\t\t\t\t\tUserManagementService service =\n\t\t\t\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\t\t\t\tUser u = new User(owner, null, group);\n\t\t\t\t\tservice.chown(u, group);\n\t\t\t\t\tservice.chmod(Integer.parseInt(mode, 8));\n\t\t\t\t} catch (XMLDBException e) {\n\t\t\t\t\tthrow new SAXException(e.getMessage(), e);\n\t\t\t\t}\n\t\t\t\tif(dialog != null)\n\t\t\t\t\tdialog.setCollection(name);\n\t\t\t} else if (localName.equals(\"subcollection\")) {\n\t\t\t\t\n\t\t\t\t String name = atts.getValue(\"filename\");\n\t\t\t\t\n\t\t\t\tif (name == null) name = atts.getValue(\"name\");\n\n\t\t\t\tfinal String fname =\n\t\t\t\t\tcontents.getParentFile().getAbsolutePath()\n\t\t\t\t\t\t+ File.separatorChar\n\t\t\t\t\t\t+ name\n\t\t\t\t\t\t+ File.separatorChar\n\t\t\t\t\t\t+ \"__contents__.xml\";\n\t\t\t\tfinal File f = new File(fname);\n\t\t\t\tif (f.exists() && f.canRead())\n\t\t\t\t\tstack.push(f);\n\t\t\t\telse\n\t\t\t\t\tSystem.err.println(f.getAbsolutePath() + \" does not exist or is not readable.\");\n\t\t\t} else if (localName.equals(\"resource\")) {\n\t\t\t\tString type = atts.getValue(\"type\");\n\t\t\t\tif(type == null)\n\t\t\t\t\ttype =\"XMLResource\";\n\t\t\t\tfinal String name = atts.getValue(\"name\");\n\t\t\t\tfinal String owner = atts.getValue(\"owner\");\n\t\t\t\tfinal String group = atts.getValue(\"group\");\n\t\t\t\tfinal String perms = atts.getValue(\"mode\");\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tString filename = atts.getValue(\"filename\");\n\t\t\t\tfinal String mimetype = atts.getValue(\"mimetype\");\n\t\t\t\tfinal String created = atts.getValue(\"created\");\n\t\t\t\tfinal String modified = atts.getValue(\"modified\");\n\t\t\t\t\n\t\t\t\tif (filename == null) filename = name;\n\n\t\t\t\tif (name == null)\n\t\t\t\t\tthrow new SAXException(\"collection requires a name attribute\");\n\t\t\t\tfinal File f =\n\t\t\t\t\tnew File(\n\t\t\t\t\t\tcontents.getParentFile().getAbsolutePath() + File.separatorChar + filename);\n\t\t\t\ttry {\n\t\t\t\t\tif (dialog != null && current instanceof Observable) {\n\t\t\t\t\t\t((Observable) current).addObserver(dialog.getObserver());\n\t\t\t\t\t}\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.setResource(name);\n\t\t\t\t\tfinal Resource res =\n\t\t\t\t\t\tcurrent.createResource(name, type);\n\t\t\t\t\tif (mimetype != null)\n\t\t\t\t\t\t((EXistResource)res).setMimeType(mimetype);\n\t\t\t\t\t\n\t\t\t\t\tres.setContent(f);\n\t\t\t\t\tif(dialog == null)\n\t\t\t\t\t\tSystem.out.println(\"restoring \" + name);\n\t\t\t\t\t\n\t\t\t\t\tSimpleDateFormat formatter\n\t\t\t\t     = new SimpleDateFormat (\"EEE MMM dd HH:mm:ss 'CET' yyyy\", Locale.US);\n\t\t\t\t\t\n\t\t\t\t\tDate date_created = null;\n\t\t\t\t\tDate date_modified = null;\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tif (created != null) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\tdate_created = formatter.parse( created);\n\t\t\t\t\t\t} catch (ParseException e) {\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t \n\t\t\t\t\tif (modified != null){\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\tdate_modified = formatter.parse( modified);\n\t\t\t\t\t\t} catch (ParseException e) {\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tcurrent.storeResource(res, date_created, date_modified);\n\t\t\t\t\tUserManagementService service =\n\t\t\t\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\t\t\t\tUser u = new User(owner, null, group);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tservice.chown(res, u, group);\n\t\t\t\t\t} catch (XMLDBException e1) {\n\t\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\t\tdialog.displayMessage(\"failed to change owner on document \" + name + \"; skipping ...\");\n\t\t\t\t\t}\n\t\t\t\t\tservice.chmod(res, Integer.parseInt(perms, 8));\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.displayMessage(\"restored \" + name);\n\t\t\t\t} catch (XMLDBException e) {\n\t\t\t\t\tthrow new SAXException(e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}","id":36700,"modified_method":"/**\n\t * @see org.xml.sax.ContentHandler#startElement(java.lang.String, java.lang.String, java.lang.String, org.xml.sax.Attributes)\n\t */\n\tpublic void startElement(String namespaceURI, String localName, String qName, Attributes atts)\n\t\tthrows SAXException {\n\t\tif (namespaceURI.equals(NS)) {\n\t\t\tif (localName.equals(\"collection\")) {\n\t\t\t\tfinal String name = atts.getValue(\"name\");\n\t\t\t\tfinal String owner = atts.getValue(\"owner\");\n\t\t\t\tfinal String group = atts.getValue(\"group\");\n\t\t\t\tfinal String mode = atts.getValue(\"mode\");\n\t\t\t\tfinal String created = atts.getValue(\"created\");\n\n\t\t\t\t\n\t\t\t\tif (name == null)\n\t\t\t\t\tthrow new SAXException(\"collection requires a name \" + \"attribute\");\n\t\t\t\ttry {\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.displayMessage(\"creating collection \" + name);\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tDate date_created = null;\n\t\t\t\t\t\n\t\t\t\t\tif (created != null)\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tdate_created = (Date)(new DateTimeValue(created)).getDate();\n\t\t\t\t\t\t} catch (XPathException e2) {\n\t\t\t\t\t\t} \n\n\t\t\t\t\t \n\t\t\t\t\t\n\t\t\t\t\tcurrent = mkcol(name, date_created);\n\t\t\t\t\tUserManagementService service =\n\t\t\t\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\t\t\t\tUser u = new User(owner, null, group);\n\t\t\t\t\tservice.chown(u, group);\n\t\t\t\t\tservice.chmod(Integer.parseInt(mode, 8));\n\t\t\t\t} catch (XMLDBException e) {\n\t\t\t\t\tthrow new SAXException(e.getMessage(), e);\n\t\t\t\t}\n\t\t\t\tif(dialog != null)\n\t\t\t\t\tdialog.setCollection(name);\n\t\t\t} else if (localName.equals(\"subcollection\")) {\n\t\t\t\t\n\t\t\t\t String name = atts.getValue(\"filename\");\n\t\t\t\t\n\t\t\t\tif (name == null) name = atts.getValue(\"name\");\n\n\t\t\t\tfinal String fname =\n\t\t\t\t\tcontents.getParentFile().getAbsolutePath()\n\t\t\t\t\t\t+ File.separatorChar\n\t\t\t\t\t\t+ name\n\t\t\t\t\t\t+ File.separatorChar\n\t\t\t\t\t\t+ \"__contents__.xml\";\n\t\t\t\tfinal File f = new File(fname);\n\t\t\t\tif (f.exists() && f.canRead())\n\t\t\t\t\tstack.push(f);\n\t\t\t\telse\n\t\t\t\t\tSystem.err.println(f.getAbsolutePath() + \" does not exist or is not readable.\");\n\t\t\t} else if (localName.equals(\"resource\")) {\n\n\t\t\t\tString type = atts.getValue(\"type\");\n\t\t\t\tif(type == null)\n\t\t\t\t\ttype =\"XMLResource\";\n\t\t\t\tfinal String name = atts.getValue(\"name\");\n\t\t\t\tfinal String owner = atts.getValue(\"owner\");\n\t\t\t\tfinal String group = atts.getValue(\"group\");\n\t\t\t\tfinal String perms = atts.getValue(\"mode\");\n\t\t\t\t\n\t\t\t\tString filename = atts.getValue(\"filename\");\n\t\t\t\tfinal String mimetype = atts.getValue(\"mimetype\");\n\t\t\t\tfinal String created = atts.getValue(\"created\");\n\t\t\t\tfinal String modified = atts.getValue(\"modified\");\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tif (filename == null) filename = name;\n\n\t\t\t\tif (name == null)\n\t\t\t\t\tthrow new SAXException(\"collection requires a name attribute\");\n\t\t\t\tfinal File f =\n\t\t\t\t\tnew File(\n\t\t\t\t\t\tcontents.getParentFile().getAbsolutePath() + File.separatorChar + filename);\n\t\t\t\ttry {\n\t\t\t\t\tif (dialog != null && current instanceof Observable) {\n\t\t\t\t\t\t((Observable) current).addObserver(dialog.getObserver());\n\t\t\t\t\t}\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.setResource(name);\n\t\t\t\t\tfinal Resource res =\n\t\t\t\t\t\tcurrent.createResource(name, type);\n\t\t\t\t\tif (mimetype != null)\n\t\t\t\t\t\t((EXistResource)res).setMimeType(mimetype);\n\t\t\t\t\t\n\t\t\t\t\tres.setContent(f);\n\t\t\t\t\tif(dialog == null)\n\t\t\t\t\t\tSystem.out.println(\"restoring \" + name);\n\t\t\t\t\t\n\t\t\t\t\tDate date_created = null;\n\t\t\t\t\tDate date_modified = null;\n\t\t\t\t\t\n\t\t\t\t\tif (created != null)\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tdate_created = (Date)(new DateTimeValue(created)).getDate();\n\t\t\t\t\t\t} catch (XPathException e2) {\n\t\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\tif (modified != null)\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tdate_modified = (Date)(new DateTimeValue(modified)).getDate();\n\t\t\t\t\t\t} catch (XPathException e2) {\n\t\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\tcurrent.storeResource(res, date_created, date_modified);\n\t\t\t\t\tUserManagementService service =\n\t\t\t\t\t\t(UserManagementService) current.getService(\"UserManagementService\", \"1.0\");\n\t\t\t\t\tUser u = new User(owner, null, group);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tservice.chown(res, u, group);\n\t\t\t\t\t} catch (XMLDBException e1) {\n\t\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\t\tdialog.displayMessage(\"failed to change owner on document \" + name + \"; skipping ...\");\n\t\t\t\t\t}\n\t\t\t\t\tservice.chmod(res, Integer.parseInt(perms, 8));\n\t\t\t\t\tif(dialog != null)\n\t\t\t\t\t\tdialog.displayMessage(\"restored \" + name);\n\t\t\t\t} catch (XMLDBException e) {\n\t\t\t\t\tthrow new SAXException(e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}","commit_id":"752ea5d6ba9e817523d3f5a9b2d19ae1ada578f5","url":"https://github.com/eXist-db/exist"},{"original_method":"public JBColor(Color regular, Color dark) {\n    super(regular.getRGB(), regular.getAlpha() != 255);\n    darkColor = dark;\n    //noinspection AssignmentToStaticFieldFromInstanceMethod\n    DARK = UIUtil.isUnderDarcula(); //Double check. Sometimes DARK != isDarcula() after dialogs appear on splash screen\n  }","id":36701,"modified_method":"public JBColor(Color regular, Color dark) {\n    super(regular.getRGB(), regular.getAlpha() != 255);\n    darkColor = dark;\n    //noinspection AssignmentToStaticFieldFromInstanceMethod\n    DARK = UIUtil.isUnderDarcula(); //Double check. Sometimes DARK != isDarcula() after dialogs appear on splash screen\n    func = null;\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getGreen() {\n    return DARK ? getDarkVariant().getGreen() : super.getGreen();\n  }","id":36702,"modified_method":"@Override\n  public int getGreen() {\n    final Color c = getColor();\n    return c == this ? super.getGreen() : c.getGreen();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public synchronized PaintContext createContext(ColorModel cm, Rectangle r, Rectangle2D r2d, AffineTransform xform, RenderingHints hints) {\n    return DARK ? getDarkVariant().createContext(cm, r, r2d, xform, hints) : super.createContext(cm, r, r2d, xform, hints);\n  }","id":36703,"modified_method":"@Override\n  public synchronized PaintContext createContext(ColorModel cm, Rectangle r, Rectangle2D r2d, AffineTransform xform, RenderingHints hints) {\n    final Color c = getColor();\n    return c == this ? super.createContext(cm, r, r2d, xform, hints) : c.createContext(cm, r, r2d, xform, hints);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static Color background() {return UIUtil.getListBackground();}","id":36704,"modified_method":"public static Color background() {\n    return new JBColor(new NotNullProducer<Color>() {\n      @NotNull\n      @Override\n      public Color produce() {\n        return UIUtil.getListBackground();\n      }\n    });\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int hashCode() {\n    return DARK ? getDarkVariant().hashCode() : super.hashCode();\n  }","id":36705,"modified_method":"@Override\n  public int hashCode() {\n    final Color c = getColor();\n    return c == this ? super.hashCode() : c.hashCode();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getRGBColorComponents(float[] compArray) {\n    return DARK ? getDarkVariant().getRGBColorComponents(compArray) : super.getRGBComponents(compArray);\n  }","id":36706,"modified_method":"@Override\n  public float[] getRGBColorComponents(float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getRGBComponents(compArray) : c.getRGBColorComponents(compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public ColorSpace getColorSpace() {\n    return DARK ? getDarkVariant().getColorSpace() : super.getColorSpace();\n  }","id":36707,"modified_method":"@Override\n  public ColorSpace getColorSpace() {\n    final Color c = getColor();\n    return c == this ? super.getColorSpace() : c.getColorSpace();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getTransparency() {\n    return DARK ? getDarkVariant().getTransparency() : super.getTransparency();\n  }","id":36708,"modified_method":"@Override\n  public int getTransparency() {\n    final Color c = getColor();\n    return c == this ? super.getTransparency() : c.getTransparency();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public Color darker() {\n    return new JBColor(super.darker(), getDarkVariant().darker());\n  }","id":36709,"modified_method":"@Override\n  public Color darker() {\n    if (func != null) {\n      return new JBColor(new NotNullProducer<Color>() {\n        @NotNull\n        @Override\n        public Color produce() {\n          return func.produce().darker();\n        }\n      });\n    }\n    return new JBColor(super.darker(), getDarkVariant().darker());\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getComponents(ColorSpace cspace, float[] compArray) {\n    return DARK ? getDarkVariant().getComponents(cspace, compArray) : super.getComponents(cspace, compArray);\n  }","id":36710,"modified_method":"@Override\n  public float[] getComponents(ColorSpace cspace, float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getComponents(cspace, compArray) : c.getComponents(cspace, compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static Color foreground() {return UIUtil.getLabelForeground();}","id":36711,"modified_method":"public static Color foreground() {\n    return new JBColor(new NotNullProducer<Color>() {\n      @NotNull\n      @Override\n      public Color produce() {\n        return UIUtil.getLabelForeground();\n      }\n    });\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getRed() {\n    return DARK ? getDarkVariant().getRed() : super.getRed();\n  }","id":36712,"modified_method":"@Override\n  public int getRed() {\n    final Color c = getColor();\n    return c == this ? super.getRed() : c.getRed();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public Color brighter() {\n    return new JBColor(super.brighter(), getDarkVariant().brighter());\n  }","id":36713,"modified_method":"@Override\n  public Color brighter() {\n    if (func != null) {\n      return new JBColor(new NotNullProducer<Color>() {\n        @NotNull\n        @Override\n        public Color produce() {\n          return func.produce().brighter();\n        }\n      });\n    }\n    return new JBColor(super.brighter(), getDarkVariant().brighter());\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getColorComponents(float[] compArray) {\n    return DARK ? getDarkVariant().getColorComponents(compArray) : super.getColorComponents(compArray);\n  }","id":36714,"modified_method":"@Override\n  public float[] getColorComponents(float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getColorComponents(compArray) : c.getColorComponents(compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public String toString() {\n    return DARK ? getDarkVariant().toString() : super.toString();\n  }","id":36715,"modified_method":"@Override\n  public String toString() {\n    final Color c = getColor();\n    return c == this ? super.toString() : c.toString();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getComponents(float[] compArray) {\n    return DARK ? getDarkVariant().getComponents(compArray) : super.getComponents(compArray);\n  }","id":36716,"modified_method":"@Override\n  public float[] getComponents(float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getComponents(compArray) : c.getComponents(compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public boolean equals(Object obj) {\n    return DARK ? getDarkVariant().equals(obj) : super.equals(obj);\n  }","id":36717,"modified_method":"@Override\n  public boolean equals(Object obj) {\n    final Color c = getColor();\n    return c == this ? super.equals(obj) : c.equals(obj);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getRGBComponents(float[] compArray) {\n    return DARK ? getDarkVariant().getRGBComponents(compArray) : super.getRGBComponents(compArray);\n  }","id":36718,"modified_method":"@Override\n  public float[] getRGBComponents(float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getRGBComponents(compArray) : c.getRGBComponents(compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getRGB() {\n    return DARK ? getDarkVariant().getRGB() : super.getRGB();\n  }","id":36719,"modified_method":"@Override\n  public int getRGB() {\n    final Color c = getColor();\n    return c == this ? super.getRGB() : c.getRGB();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getBlue() {\n    return DARK ? getDarkVariant().getBlue() : super.getBlue();\n  }","id":36720,"modified_method":"@Override\n  public int getBlue() {\n    final Color c = getColor();\n    return c == this ? super.getBlue() : c.getBlue();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public int getAlpha() {\n    return DARK ? getDarkVariant().getAlpha() : super.getAlpha();\n  }","id":36721,"modified_method":"@Override\n  public int getAlpha() {\n    final Color c = getColor();\n    return c == this ? super.getAlpha() : c.getAlpha();\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public float[] getColorComponents(ColorSpace cspace, float[] compArray) {\n    return DARK ? getDarkVariant().getColorComponents(cspace, compArray) : super.getColorComponents(cspace, compArray);\n  }","id":36722,"modified_method":"@Override\n  public float[] getColorComponents(ColorSpace cspace, float[] compArray) {\n    final Color c = getColor();\n    return c == this ? super.getColorComponents(cspace, compArray) : c.getColorComponents(cspace, compArray);\n  }","commit_id":"eb667f33b0ac5ed01f4df711ca1c68549404ce74","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void setColor(Color c) {\n    log(String.format(\"setColor(%s) alpha=%d\", toHex(c), c.getAlpha()));\n    myPeer.setColor(c);\n  }","id":36723,"modified_method":"@Override\n  public void setColor(Color c) {\n    log(String.format(\"setColor(%s) alpha=%d\", toHex(c), c == null ? 0 : c.getAlpha()));\n    myPeer.setColor(c);\n  }","commit_id":"e15291ee376e30a05bf294a7a2205f5d2255df8e","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JComponent setValue(@NotNull final Color value) {\n      setText(\"r:\" + value.getRed() + \", g:\" + value.getGreen() + \", b:\" + value.getBlue() + \", a:\" + value.getAlpha());\n      setIcon(new ColorIcon(13, 11, value, true));\n      return this;\n    }","id":36724,"modified_method":"public JComponent setValue(@NotNull final Color value) {\n      StringBuilder sb = new StringBuilder();\n      String hex = Integer.toHexString(value.getRGB());\n      for (int i = hex.length(); i < 8; i++) sb.append('0');\n      sb.append(hex.toUpperCase(ENGLISH));\n      sb.append(\", r:\").append(value.getRed());\n      sb.append(\", g:\").append(value.getGreen());\n      sb.append(\", b:\").append(value.getBlue());\n      sb.append(\", a:\").append(value.getAlpha());\n      if (value instanceof UIResource) sb.append(\" [UI]\");\n      setText(sb.toString());\n      setIcon(new ColorIcon(13, 11, value, true));\n      return this;\n    }","commit_id":"c565d6ff4d1b57ae57f3c499a7b38e9e1cdc0924","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public JComponent setValue(@NotNull final Font value) {\n      setText(value.getFontName() + \" (\" + value.getFamily() + \"), \" + value.getSize() + \"px\");\n      return this;\n    }","id":36725,"modified_method":"public JComponent setValue(@NotNull final Font value) {\n      StringBuilder sb = new StringBuilder();\n      sb.append(value.getFontName()).append(\" (\").append(value.getFamily()).append(\"), \").append(value.getSize()).append(\"px\");\n      if (Font.BOLD == (Font.BOLD & value.getStyle())) sb.append(\" bold\");\n      if (Font.ITALIC == (Font.ITALIC & value.getStyle())) sb.append(\" italic\");\n      if (value instanceof UIResource) sb.append(\" [UI]\");\n      setText(sb.toString());\n      return this;\n    }","commit_id":"c565d6ff4d1b57ae57f3c499a7b38e9e1cdc0924","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"Bundle registerModule(ModuleIdentifier moduleId) throws Exception {\n        final ServiceController<?> bundleContextService = getServiceContainer().getRequiredService(BundleContextService.SERVICE_NAME);\n        if (bundleContextService.getMode() == Mode.ON_DEMAND && bundleContextService.getState() == State.DOWN) {\n            final CountDownLatch latch = new CountDownLatch(1);\n            bundleContextService.addListener(new AbstractServiceListener<Object>() {\n\n                @Override\n                public void serviceStarted(ServiceController<? extends Object> controller) {\n                    latch.countDown();\n                    controller.removeListener(this);\n                }\n\n                @Override\n                public void serviceFailed(ServiceController<? extends Object> controller, StartException reason) {\n                    latch.countDown();\n                    controller.removeListener(this);\n                }\n            });\n            bundleContextService.setMode(Mode.ACTIVE);\n            latch.await(10, TimeUnit.SECONDS);\n\n            if (bundleContextService.getState() != State.UP)\n                throw new IllegalStateException(\"BundleContextService not started\");\n        }\n\n        final ServiceController<?> bundleManagerService = getServiceContainer().getRequiredService(FrameworkExt.SERVICE_NAME);\n        FrameworkExt bundleManager = (FrameworkExt) bundleManagerService.getValue();\n        if (bundleManager == null)\n            throw new IllegalStateException(\"FrameworkExt not started\");\n\n        return bundleManager.installBundle(moduleId);\n    }","id":36726,"modified_method":"Bundle registerModule(ModuleIdentifier moduleId) throws Exception {\n        final ServiceController<?> bundleContextService = getServiceContainer().getRequiredService(BundleContextService.SERVICE_NAME);\n        if (bundleContextService.getMode() == Mode.ON_DEMAND && bundleContextService.getState() == State.DOWN) {\n            final CountDownLatch latch = new CountDownLatch(1);\n            bundleContextService.addListener(new AbstractServiceListener<Object>() {\n\n                @Override\n                public void serviceStarted(ServiceController<? extends Object> controller) {\n                    latch.countDown();\n                    controller.removeListener(this);\n                }\n\n                @Override\n                public void serviceFailed(ServiceController<? extends Object> controller, StartException reason) {\n                    latch.countDown();\n                    controller.removeListener(this);\n                }\n            });\n            bundleContextService.setMode(Mode.ACTIVE);\n            latch.await(10, TimeUnit.SECONDS);\n\n            if (bundleContextService.getState() != State.UP)\n                throw new IllegalStateException(\"BundleContextService not started\");\n        }\n\n        final ServiceController<?> bundleManagerService = getServiceContainer().getRequiredService(FrameworkIntegration.SERVICE_NAME);\n        FrameworkIntegration bundleManager = (FrameworkIntegration) bundleManagerService.getValue();\n        if (bundleManager == null)\n            throw new IllegalStateException(\"FrameworkIntegration not started\");\n\n        ServiceContainer serviceContainer = getServiceContainer();\n        ServiceTarget serviceTarget = serviceContainer.subTarget();\n        ServiceName serviceName = bundleManager.installBundle(serviceTarget, moduleId);\n        return getBundleFromService(serviceContainer, serviceName);\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n\n        ArquillianConfig arqConfig = phaseContext.getDeploymentUnit().getAttachment(ArquillianConfig.KEY);\n        if (arqConfig == null)\n            return;\n\n        ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n        DeploymentTrackerService tracker = new DeploymentTrackerService(arqConfig);\n        ServiceBuilder<Object> serviceBuilder = serviceTarget.addService(SERVICE_NAME_BASE.append(phaseContext.getDeploymentUnit().getName()), tracker);\n        serviceBuilder.addDependency(ArquillianService.SERVICE_NAME, ArquillianService.class, tracker.injectedArquillianService);\n\n        // If this is an OSGi deployment, add a dependency on the associated service\n        Deployment osgiDeployment = OSGiDeploymentAttachment.getDeployment(phaseContext.getDeploymentUnit());\n        if (osgiDeployment != null) {\n            ServiceName serviceName = OSGiDeploymentService.getServiceName(phaseContext.getDeploymentUnit().getName());\n            serviceBuilder.addDependency(serviceName);\n            osgiDeployment.setAutoStart(false);\n        }\n        serviceBuilder.install();\n    }","id":36727,"modified_method":"@Override\n    public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n\n        ArquillianConfig arqConfig = phaseContext.getDeploymentUnit().getAttachment(ArquillianConfig.KEY);\n        if (arqConfig == null)\n            return;\n\n        ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n        DeploymentTrackerService tracker = new DeploymentTrackerService(arqConfig);\n        ServiceBuilder<Object> serviceBuilder = serviceTarget.addService(SERVICE_NAME_BASE.append(phaseContext.getDeploymentUnit().getName()), tracker);\n        serviceBuilder.addDependency(ArquillianService.SERVICE_NAME, ArquillianService.class, tracker.injectedArquillianService);\n\n        // If this is an OSGi deployment, add a dependency on the associated service\n        Deployment osgiDeployment = OSGiDeploymentAttachment.getDeployment(phaseContext.getDeploymentUnit());\n        if (osgiDeployment != null) {\n            ServiceName serviceName = BundleInstallService.getServiceName(phaseContext.getDeploymentUnit().getName());\n            serviceBuilder.addDependency(serviceName);\n            osgiDeployment.setAutoStart(false);\n        }\n        serviceBuilder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(final ServiceTarget target, Activation policy) {\n        BundleContextService service = new BundleContextService();\n        ServiceBuilder<?> serviceBuilder = target.addService(BundleContextService.SERVICE_NAME, service);\n        serviceBuilder.addDependency(FrameworkService.SERVICE_NAME, Framework.class, service.injectedFramework);\n        serviceBuilder.setInitialMode(policy == Activation.LAZY ? Mode.ON_DEMAND : Mode.ACTIVE);\n        serviceBuilder.install();\n    }","id":36728,"modified_method":"public static void addService(final ServiceTarget target, Activation policy) {\n        BundleContextService service = new BundleContextService();\n        ServiceBuilder<?> builder = target.addService(BundleContextService.SERVICE_NAME, service);\n        builder.addDependency(FrameworkService.SERVICE_NAME, Framework.class, service.injectedFramework);\n        builder.setInitialMode(policy == Activation.LAZY ? Mode.ON_DEMAND : Mode.ACTIVE);\n        builder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void configurationModified() {\n            String updatePart = new Long(updateCount.incrementAndGet()).toString();\n            ServiceName serviceName = ServiceName.of(ConfigurationModifiedService.class.getName(), updatePart);\n            ServiceBuilder<?> serviceBuilder = serviceContainer.addService(serviceName, this);\n            serviceBuilder.install();\n        }","id":36729,"modified_method":"public void configurationModified() {\n            String updatePart = new Long(updateCount.incrementAndGet()).toString();\n            ServiceName serviceName = ServiceName.of(ConfigurationModifiedService.class.getName(), updatePart);\n            ServiceBuilder<?> builder = serviceContainer.addService(serviceName, this);\n            builder.install();\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(final ServiceTarget target, SubsystemState subsystemState) {\n        ConfigAdminServiceImpl service = new ConfigAdminServiceImpl(subsystemState);\n        ServiceBuilder<?> serviceBuilder = target.addService(ConfigAdminServiceImpl.SERVICE_NAME, service);\n        //serviceBuilder.addDependency(ServerConfigurationPersister.SERVICE_NAME, ServerConfigurationPersister.class, service.injectedConfigPersister);\n        serviceBuilder.install();\n    }","id":36730,"modified_method":"public static void addService(final ServiceTarget target, SubsystemState subsystemState) {\n        ConfigAdminServiceImpl service = new ConfigAdminServiceImpl(subsystemState);\n        ServiceBuilder<?> builder = target.addService(ConfigAdminServiceImpl.SERVICE_NAME, service);\n        //builder.addDependency(ServerConfigurationPersister.SERVICE_NAME, ServerConfigurationPersister.class, service.injectedConfigPersister);\n        builder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(ServiceTarget serviceTarget, String contextName, Deployment dep) {\n        DeploymentHolderService service = new DeploymentHolderService(dep);\n        ServiceBuilder<Deployment> serviceBuilder = serviceTarget.addService(getServiceName(contextName), service);\n        serviceBuilder.setInitialMode(Mode.ACTIVE);\n        serviceBuilder.install();\n    }","id":36731,"modified_method":"public static void addService(ServiceTarget serviceTarget, String contextName, Deployment dep) {\n        DeploymentHolderService service = new DeploymentHolderService(dep);\n        ServiceBuilder<Deployment> builder = serviceTarget.addService(getServiceName(contextName), service);\n        builder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public synchronized void start(StartContext context) throws StartException {\n        log.infof(\"Starting OSGi Framework\");\n        try {\n            ServiceContainer serviceContainer = context.getController().getServiceContainer();\n\n            // Setup the OSGi {@link Framework} properties\n            Map<String, Object> props = new HashMap<String, Object>(subsystemState.getProperties());\n            setupIntegrationProperties(context, props);\n\n            // Start the OSGi {@link Framework}\n            FrameworkBuilder builder = new FrameworkBuilder(props);\n            builder.setServiceContainer(serviceContainer);\n            builder.addProvidedService(DeployerServiceProvider.SERVICE_NAME);\n            builder.addProvidedService(FrameworkModuleProvider.SERVICE_NAME);\n            builder.addProvidedService(ModuleLoaderProvider.SERVICE_NAME);\n            framework = builder.build();\n            framework.start();\n\n            // Register the {@link MBeanServer} as OSGi service\n            BundleContext systemContext = framework.getBundleContext();\n            MBeanServer mbeanServer = injectedMBeanServer.getValue();\n            systemContext.registerService(MBeanServer.class.getName(), mbeanServer, null);\n\n            // Register the {@link ServiceContainer} as OSGi service\n            systemContext.registerService(ServiceContainer.class.getName(), serviceContainer, null);\n\n        } catch (Throwable t) {\n            throw new StartException(\"Failed to start OSGi Framework: \" + framework, t);\n        }\n    }","id":36732,"modified_method":"public synchronized void start(StartContext context) throws StartException {\n        log.infof(\"Starting OSGi Framework\");\n        try {\n            ServiceContainer serviceContainer = context.getController().getServiceContainer();\n\n            // Setup the OSGi {@link Framework} properties\n            Map<String, Object> props = new HashMap<String, Object>(subsystemState.getProperties());\n            setupIntegrationProperties(context, props);\n\n            // Start the OSGi {@link Framework}\n            FrameworkBuilder builder = new FrameworkBuilder(props);\n            builder.setServiceContainer(serviceContainer);\n            builder.addProvidedService(AutoInstallProvider.SERVICE_NAME);\n            builder.addProvidedService(DeployerServiceProvider.SERVICE_NAME);\n            builder.addProvidedService(FrameworkModuleProvider.SERVICE_NAME);\n            builder.addProvidedService(ModuleLoaderProvider.SERVICE_NAME);\n            builder.addProvidedService(SystemServicesProvider.SERVICE_NAME);\n\n            framework = builder.build();\n            framework.start();\n        } catch (Throwable t) {\n            throw new StartException(\"Failed to start OSGi Framework: \" + framework, t);\n        }\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"private static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n            FrameworkModuleIntegration service = new FrameworkModuleIntegration(subsystemState);\n            ServiceBuilder<?> serviceBuilder = target.addService(FrameworkModuleProvider.SERVICE_NAME, service);\n            serviceBuilder.addDependency(SystemModuleProvider.SERVICE_NAME, Module.class, service.injectedSystemModule);\n            serviceBuilder.setInitialMode(Mode.PASSIVE);\n            serviceBuilder.install();\n        }","id":36733,"modified_method":"private static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n            FrameworkModuleIntegration service = new FrameworkModuleIntegration(subsystemState);\n            ServiceBuilder<?> builder = target.addService(FrameworkModuleProvider.SERVICE_NAME, service);\n            builder.addDependency(SystemModuleProvider.SERVICE_NAME, Module.class, service.injectedSystemModule);\n            builder.setInitialMode(Mode.PASSIVE);\n            builder.install();\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n         * Create a {@link Deployment} from the given ModuleIdentifier.\n         */\n        private Deployment createDeployment(final ModuleIdentifier identifier) throws BundleException {\n\n            String location = \"module:\" + identifier.getName();\n            if (\"main\".equals(identifier.getSlot()) == false)\n                location += \":\" + identifier.getSlot();\n\n            // Check if we have a single root file\n            File repoFile = getModuleRepositoryEntry(identifier);\n            if (repoFile == null)\n                throw new IllegalArgumentException(\"Cannot obtain repository entry for: \" + identifier);\n\n            // Try to process this as a valid OSGi bundle\n            try {\n                VirtualFile rootFile = AbstractVFS.toVirtualFile(repoFile.toURI());\n                BundleInfo info = BundleInfo.createBundleInfo(rootFile, location);\n                return DeploymentFactory.createDeployment(info);\n            } catch (IOException ex) {\n                throw new BundleException(\"Cannot create deployment for: \" + identifier, ex);\n            }\n        }","id":36734,"modified_method":"private URL getModuleLocation(final ModuleIdentifier identifier) throws IOException {\n\n            String location = \"module:\" + identifier.getName();\n            if (\"main\".equals(identifier.getSlot()) == false)\n                location += \":\" + identifier.getSlot();\n\n            // Check if we have a single root file\n            File repoFile = getModuleRepositoryEntry(identifier);\n            if (repoFile == null)\n                throw new IllegalArgumentException(\"Cannot obtain repository entry for: \" + identifier);\n\n            return repoFile.toURI().toURL();\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n        public void start(StartContext context) throws StartException {\n\n            try {\n                // Create the list of {@link Deployment}s for the configured modules\n                List<Deployment> deployments = new ArrayList<Deployment>();\n                for (OSGiModule moduleMetaData : subsystemState.getModules()) {\n                    ModuleIdentifier identifier = moduleMetaData.getIdentifier();\n                    Deployment dep = createDeployment(identifier);\n                    dep.setAutoStart(moduleMetaData.isStart());\n                    deployments.add(dep);\n                }\n\n                // Deploy the bundles through the {@link SystemDeployerService}\n                // [TODO] Revisit whether these deployments should go through the {@link DeploymentUnitProcessor} chain\n                final BundleContext systemContext = injectedBundleContext.getValue();\n                final FrameworkExt bundleManager = injectedBundleManager.getValue();\n                DeployerService service = new SystemDeployerService(systemContext) {\n                    @Override\n                    protected Bundle installBundle(Deployment dep) throws BundleException {\n                        return bundleManager.installBundle(dep);\n                    }\n                };\n                service.deploy(deployments.toArray(new Deployment[deployments.size()]));\n            } catch (BundleException ex) {\n                throw new StartException(\"Failed to auto install bundles\", ex);\n            }\n        }","id":36735,"modified_method":"@Override\n        public void start(StartContext context) throws StartException {\n            try {\n                // Create the list of {@link Deployment}s for the configured modules\n                for (OSGiModule moduleMetaData : subsystemState.getModules()) {\n                    ModuleIdentifier identifier = moduleMetaData.getIdentifier();\n                    URL fileURL = getModuleLocation(identifier);\n                    if (moduleMetaData.isStart())\n                        autoStart.add(fileURL);\n                    else\n                        autoInstall.add(fileURL);\n                }\n            } catch (IOException ex) {\n                throw new StartException(\"Failed to create auto install list\", ex);\n            }\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n        FrameworkService service = new FrameworkService(subsystemState);\n        ServiceBuilder<?> serviceBuilder = target.addService(FrameworkService.SERVICE_NAME, service);\n        serviceBuilder.addDependency(ServerEnvironmentService.SERVICE_NAME, ServerEnvironment.class, service.injectedEnvironment);\n        serviceBuilder.addDependency(MBeanServerService.SERVICE_NAME, MBeanServer.class, service.injectedMBeanServer);\n        serviceBuilder.addDependency(SocketBinding.JBOSS_BINDING_NAME.append(\"osgi-http\"), SocketBinding.class, service.httpServerPortBinding);\n        serviceBuilder.setInitialMode(Mode.ON_DEMAND);\n        serviceBuilder.install();\n\n        AutoInstallIntegration.addService(target, subsystemState);\n        FrameworkModuleIntegration.addService(target, subsystemState);\n        ModuleLoaderIntegration.addService(target);\n    }","id":36736,"modified_method":"public static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n        FrameworkService service = new FrameworkService(subsystemState);\n        ServiceBuilder<?> builder = target.addService(FrameworkService.SERVICE_NAME, service);\n        builder.addDependency(ServerEnvironmentService.SERVICE_NAME, ServerEnvironment.class, service.injectedEnvironment);\n        builder.addDependency(SocketBinding.JBOSS_BINDING_NAME.append(\"osgi-http\"), SocketBinding.class, service.httpServerPortBinding);\n        builder.setInitialMode(Mode.ON_DEMAND);\n        builder.install();\n\n        AutoInstallIntegration.addService(target, subsystemState);\n        FrameworkModuleIntegration.addService(target, subsystemState);\n        ModuleLoaderIntegration.addService(target);\n        SystemServicesIntegration.addService(target);\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"private static void addService(final ServiceTarget target) {\n            ModuleLoaderIntegration service = new ModuleLoaderIntegration();\n            ServiceBuilder<?> serviceBuilder = target.addService(ModuleLoaderProvider.SERVICE_NAME, service);\n            serviceBuilder.addDependency(Services.JBOSS_SERVICE_MODULE_LOADER, ServiceModuleLoader.class, service.injectedModuleLoader);\n            serviceBuilder.setInitialMode(Mode.ON_DEMAND);\n            serviceBuilder.install();\n        }","id":36737,"modified_method":"private static void addService(final ServiceTarget target) {\n            ModuleLoaderIntegration service = new ModuleLoaderIntegration();\n            ServiceBuilder<?> builder = target.addService(ModuleLoaderProvider.SERVICE_NAME, service);\n            builder.addDependency(Services.JBOSS_SERVICE_MODULE_LOADER, ServiceModuleLoader.class, service.injectedModuleLoader);\n            builder.setInitialMode(Mode.ON_DEMAND);\n            builder.install();\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"private static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n            AutoInstallIntegration service = new AutoInstallIntegration(subsystemState);\n            ServiceBuilder<?> serviceBuilder = target.addService(SERVICE_NAME.append(\"autoinstall\"), service);\n            serviceBuilder.addDependency(BundleContextService.SERVICE_NAME, BundleContext.class, service.injectedBundleContext);\n            serviceBuilder.addDependency(FrameworkExt.SERVICE_NAME, FrameworkExt.class, service.injectedBundleManager);\n            serviceBuilder.setInitialMode(Mode.PASSIVE);\n            serviceBuilder.install();\n        }","id":36738,"modified_method":"private static void addService(final ServiceTarget target, final SubsystemState subsystemState) {\n            AutoInstallIntegration service = new AutoInstallIntegration(subsystemState);\n            ServiceBuilder<?> builder = target.addService(AutoInstallProvider.SERVICE_NAME, service);\n            builder.addDependency(FrameworkIntegration.SERVICE_NAME, FrameworkIntegration.class, service.injectedBundleManager);\n            builder.addDependency(SystemBundleProvider.SERVICE_NAME, Bundle.class, service.injectedSystemBundle);\n            builder.setInitialMode(Mode.PASSIVE);\n            builder.install();\n        }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public synchronized void stop(StopContext context) {\n        log.infof(\"Stopping OSGi Framework\");\n        ServiceContainer serviceContainer = context.getController().getServiceContainer();\n        ServiceController<?> controller = serviceContainer.getService(FrameworkExt.SERVICE_NAME);\n        if (controller != null) {\n            controller.setMode(Mode.REMOVE);\n        }\n    }","id":36739,"modified_method":"public synchronized void stop(StopContext context) {\n        log.infof(\"Stopping OSGi Framework\");\n        ServiceContainer serviceContainer = context.getController().getServiceContainer();\n        ServiceController<?> controller = serviceContainer.getService(FrameworkIntegration.SERVICE_NAME);\n        if (controller != null) {\n            controller.setMode(Mode.REMOVE);\n        }\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n     * Activate the services required for service deployments.\n     */\n    public void activate(final BootOperationContext updateContext) {\n        updateContext.addDeploymentProcessor(Phase.STRUCTURE, Phase.STRUCTURE_OSGI_MANIFEST, new OSGiManifestStructureProcessor());\n        updateContext.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_BUNDLE_INFO, new OSGiBundleInfoParseProcessor());\n        updateContext.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_PROPERTIES, new OSGiXServiceParseProcessor());\n        updateContext.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_DEPLOYMENT, new OSGiDeploymentInstallProcessor());\n    }","id":36740,"modified_method":"/**\n     * Activate the services required for service deployments.\n     */\n    public void activate(final BootOperationContext updateContext) {\n        updateContext.addDeploymentProcessor(Phase.STRUCTURE, Phase.STRUCTURE_OSGI_MANIFEST, new OSGiManifestStructureProcessor());\n        updateContext.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_BUNDLE_INFO, new OSGiBundleInfoParseProcessor());\n        updateContext.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_PROPERTIES, new OSGiXServiceParseProcessor());\n        updateContext.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_DEPLOYMENT, new BundleInstallProcessor());\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public OperationResult execute(final OperationContext context, final ModelNode operation, final ResultHandler resultHandler) {\n        populateSubModel(context.getSubModel(), operation);\n\n        if (context instanceof BootOperationContext) {\n            final BootOperationContext updateContext = (BootOperationContext) context;\n            context.getRuntimeContext().setRuntimeTask(new RuntimeTask() {\n                public void execute(RuntimeTaskContext context) throws OperationFailedException {\n                    log.infof(\"Activating OSGi Subsystem\");\n                    long begin = System.currentTimeMillis();\n                    SubsystemState subsystemState = createSubsystemState(operation);\n\n                    // TODO: Hack, which registers the framework module with the {@link ModularURLStreamHandlerFactory}\n                    String value = SecurityActions.getSystemProperty(\"jboss.protocol.handler.modules\", \"org.jboss.osgi.framework\");\n                    if (!value.equals(\"org.jboss.osgi.framework\")) {\n                        value = value + \"|org.jboss.osgi.framework\";\n                    }\n                    SecurityActions.setSystemProperty(\"jboss.protocol.handler.modules\", value);\n\n                    ServiceTarget target = context.getServiceTarget();\n                    Activation policy = subsystemState.getActivationPolicy();\n                    BundleContextService.addService(target, policy);\n                    DeployerServiceIntegration.addService(target);\n                    FrameworkService.addService(target, subsystemState);\n                    PackageAdminService.addService(target);\n                    StartLevelService.addService(target);\n\n                    ConfigAdminServiceImpl.addService(target, subsystemState);\n\n                    new OSGiDeploymentActivator().activate(updateContext);\n                    resultHandler.handleResultComplete();\n\n                    long end = System.currentTimeMillis();\n                    log.debugf(\"Activated OSGi Subsystem in %dms\", end - begin);\n                }\n            });\n        } else {\n            resultHandler.handleResultComplete();\n        }\n\n        // Create the compensating operation\n        final ModelNode compensatingOperation = new ModelNode();\n        compensatingOperation.get(OP).set(REMOVE);\n        compensatingOperation.get(OP_ADDR).set(operation.require(OP_ADDR));\n        return new BasicOperationResult(compensatingOperation);\n    }","id":36741,"modified_method":"@Override\n    public OperationResult execute(final OperationContext context, final ModelNode operation, final ResultHandler resultHandler) {\n        populateSubModel(context.getSubModel(), operation);\n\n        if (context instanceof BootOperationContext) {\n            final BootOperationContext updateContext = (BootOperationContext) context;\n            context.getRuntimeContext().setRuntimeTask(new RuntimeTask() {\n                public void execute(RuntimeTaskContext context) throws OperationFailedException {\n                    log.infof(\"Activating OSGi Subsystem\");\n                    long begin = System.currentTimeMillis();\n                    SubsystemState subsystemState = createSubsystemState(operation);\n\n                    // TODO: Hack, which registers the framework module with the {@link ModularURLStreamHandlerFactory}\n                    String value = SecurityActions.getSystemProperty(\"jboss.protocol.handler.modules\", \"org.jboss.osgi.framework\");\n                    if (!value.equals(\"org.jboss.osgi.framework\")) {\n                        value = value + \"|org.jboss.osgi.framework\";\n                    }\n                    SecurityActions.setSystemProperty(\"jboss.protocol.handler.modules\", value);\n\n                    ServiceTarget serviceTarget = context.getServiceTarget();\n                    Activation policy = subsystemState.getActivationPolicy();\n                    BundleContextService.addService(serviceTarget, policy);\n                    BundleStartupProcessor.addService(serviceTarget);\n                    DeployerServiceIntegration.addService(serviceTarget);\n                    FrameworkService.addService(serviceTarget, subsystemState);\n                    PackageAdminService.addService(serviceTarget);\n                    StartLevelService.addService(serviceTarget);\n\n                    ConfigAdminServiceImpl.addService(serviceTarget, subsystemState);\n\n                    new OSGiDeploymentActivator().activate(updateContext);\n                    resultHandler.handleResultComplete();\n\n                    long end = System.currentTimeMillis();\n                    log.debugf(\"Activated OSGi Subsystem in %dms\", end - begin);\n                }\n            });\n        } else {\n            resultHandler.handleResultComplete();\n        }\n\n        // Create the compensating operation\n        final ModelNode compensatingOperation = new ModelNode();\n        compensatingOperation.get(OP).set(REMOVE);\n        compensatingOperation.get(OP_ADDR).set(operation.require(OP_ADDR));\n        return new BasicOperationResult(compensatingOperation);\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(final ServiceTarget target) {\n        PackageAdminService service = new PackageAdminService();\n        ServiceBuilder<?> serviceBuilder = target.addService(PackageAdminService.SERVICE_NAME, service);\n        serviceBuilder.addDependency(BundleContextService.SERVICE_NAME, BundleContext.class, service.injectedContext);\n        serviceBuilder.setInitialMode(Mode.ON_DEMAND);\n        serviceBuilder.install();\n    }","id":36742,"modified_method":"public static void addService(final ServiceTarget target) {\n        PackageAdminService service = new PackageAdminService();\n        ServiceBuilder<?> builder = target.addService(PackageAdminService.SERVICE_NAME, service);\n        builder.addDependency(BundleContextService.SERVICE_NAME, BundleContext.class, service.injectedContext);\n        builder.setInitialMode(Mode.ON_DEMAND);\n        builder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static void addService(final ServiceTarget batchBuilder) {\n        StartLevelService service = new StartLevelService();\n        ServiceBuilder<?> serviceBuilder = batchBuilder.addService(StartLevelService.SERVICE_NAME, service);\n        serviceBuilder.addDependency(BundleContextService.SERVICE_NAME, BundleContext.class, service.injectedContext);\n        serviceBuilder.setInitialMode(Mode.ON_DEMAND);\n        serviceBuilder.install();\n    }","id":36743,"modified_method":"public static void addService(final ServiceTarget batchBuilder) {\n        StartLevelService service = new StartLevelService();\n        ServiceBuilder<?> builder = batchBuilder.addService(StartLevelService.SERVICE_NAME, service);\n        builder.addDependency(BundleContextService.SERVICE_NAME, BundleContext.class, service.injectedContext);\n        builder.setInitialMode(Mode.ON_DEMAND);\n        builder.install();\n    }","commit_id":"e7bee4d0e9f0c260b467fe27337a5931f2b222e4","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void installBundle(String location, File bundleFile,\n            int startLevel, boolean start) {\n        if (bundleFile != null) {\n\n            // try to get the bundle name, fail if none\n            String symbolicName = this.getSymbolicName(bundleFile);\n            if (symbolicName == null) {\n                return;\n            }\n\n            // check for existing bundle first\n            Bundle newBundle = null;\n            Bundle[] bundles = this.getBundleContext().getBundles();\n            for (int i = 0; i < bundles.length; i++) {\n                if ((bundles[i].getLocation() != null && bundles[i].getLocation().equals(\n                    location))\n                    || (bundles[i].getSymbolicName() != null && bundles[i].getSymbolicName().equals(\n                        symbolicName))) {\n                    newBundle = bundles[i];\n                    break;\n                }\n            }\n\n            try {\n                // stream will be closed by update or installBundle\n                InputStream bundleStream = new FileInputStream(bundleFile);\n\n                if (newBundle != null) {\n                    // update existing bundle, to not set startlevel or start\n                    updateBackground(newBundle, bundleFile, bundleStream);\n\n                } else {\n\n                    installBackground(bundleFile, location, startLevel, start);\n\n                }\n            } catch (Throwable t) {\n                getLog().log(LogService.LOG_ERROR, \"Failed to install bundle \" + symbolicName\n                    + \" (Location:\" + location + \")\", t);\n            }\n        }\n    }","id":36744,"modified_method":"private void installBundle(String location, File bundleFile,\n            int startLevel, boolean start) {\n        if (bundleFile != null) {\n\n            // try to get the bundle name, fail if none\n            String symbolicName = this.getSymbolicName(bundleFile);\n            if (symbolicName == null) {\n                bundleFile.delete();\n                return;\n            }\n\n            // check for existing bundle first\n            Bundle updateBundle = null;\n            Bundle[] bundles = this.getBundleContext().getBundles();\n            for (int i = 0; i < bundles.length; i++) {\n                if ((bundles[i].getLocation() != null && bundles[i].getLocation().equals(\n                    location))\n                    || (bundles[i].getSymbolicName() != null && bundles[i].getSymbolicName().equals(\n                        symbolicName))) {\n                    updateBundle = bundles[i];\n                    break;\n                }\n            }\n\n            if (updateBundle != null) {\n\n                updateBackground(updateBundle, bundleFile);\n\n            } else {\n\n                installBackground(bundleFile, location, startLevel, start);\n\n            }\n        }\n    }","commit_id":"ede12f077a001a70b207b18ae6aa697d33ee8ee6","url":"https://github.com/apache/sling"},{"original_method":"public boolean performAction(HttpServletRequest request,\n            HttpServletResponse response) {\n\n        // get the uploaded data\n        @SuppressWarnings(\"unchecked\")\n        Map<String, FileItem[]> params = (Map<String, FileItem[]>) request.getAttribute(Util.ATTR_FILEUPLOAD);\n        if (params == null) {\n            return true;\n        }\n\n        FileItem startItem = this.getFileItem(params, FIELD_START, true);\n        FileItem startLevelItem = this.getFileItem(params, FIELD_STARTLEVEL,\n            true);\n        FileItem bundleItem = this.getFileItem(params, FIELD_BUNDLEFILE, false);\n\n        // don't care any more if not bundle item\n        if (bundleItem == null || bundleItem.getSize() <= 0) {\n            return true;\n        }\n\n        // default values\n        boolean start = startItem != null; // don't care for the value, as long\n        // it exists\n        int startLevel = -1;\n        String bundleLocation = \"inputstream:\";\n\n        // convert the start level value\n        if (startLevelItem != null) {\n            try {\n                startLevel = Integer.parseInt(startLevelItem.getString());\n            } catch (NumberFormatException nfe) {\n                // TODO: Handle or ignore\n            }\n        }\n\n        // install the bundle now\n        File tmpFile = null;\n        try {\n            // copy the data to a file for better processing\n            tmpFile = File.createTempFile(\"install\", \".tmp\");\n            bundleItem.write(tmpFile);\n            bundleLocation = \"inputstream:\" + bundleItem.getName();\n\n            this.installBundle(bundleLocation, tmpFile, startLevel, start);\n        } catch (Exception e) {\n            getLog().log(LogService.LOG_ERROR,\n                \"Problem accessing uploaded bundle file\", e);\n        } finally {\n            if (tmpFile != null) {\n                tmpFile.delete();\n            }\n        }\n\n        return true;\n    }","id":36745,"modified_method":"public boolean performAction(HttpServletRequest request,\n            HttpServletResponse response) {\n\n        // get the uploaded data\n        @SuppressWarnings(\"unchecked\")\n        Map<String, FileItem[]> params = (Map<String, FileItem[]>) request.getAttribute(Util.ATTR_FILEUPLOAD);\n        if (params == null) {\n            return true;\n        }\n\n        FileItem startItem = this.getFileItem(params, FIELD_START, true);\n        FileItem startLevelItem = this.getFileItem(params, FIELD_STARTLEVEL,\n            true);\n        FileItem bundleItem = this.getFileItem(params, FIELD_BUNDLEFILE, false);\n\n        // don't care any more if not bundle item\n        if (bundleItem == null || bundleItem.getSize() <= 0) {\n            return true;\n        }\n\n        // default values\n        boolean start = startItem != null; // don't care for the value, as long\n        // it exists\n        int startLevel = -1;\n        String bundleLocation = \"inputstream:\";\n\n        // convert the start level value\n        if (startLevelItem != null) {\n            try {\n                startLevel = Integer.parseInt(startLevelItem.getString());\n            } catch (NumberFormatException nfe) {\n                getLog().log(\n                    LogService.LOG_INFO,\n                    \"Cannot parse start level parameter \" + startLevelItem\n                        + \" to a number, not setting start level\");\n            }\n        }\n\n        // write the bundle data to a temporary file to ease processing\n        File tmpFile = null;\n        try {\n            // copy the data to a file for better processing\n            tmpFile = File.createTempFile(\"install\", \".tmp\");\n            bundleItem.write(tmpFile);\n        } catch (Exception e) {\n            getLog().log(LogService.LOG_ERROR,\n                \"Problem accessing uploaded bundle file\", e);\n\n            // remove the tmporary file\n            if (tmpFile != null) {\n                tmpFile.delete();\n                tmpFile = null;\n            }\n        }\n\n        // install or update the bundle now\n        if (tmpFile != null) {\n            bundleLocation = \"inputstream:\" + bundleItem.getName();\n            installBundle(bundleLocation, tmpFile, startLevel, start);\n        }\n\n        return true;\n    }","commit_id":"ede12f077a001a70b207b18ae6aa697d33ee8ee6","url":"https://github.com/apache/sling"},{"original_method":"private void updateBackground(final Bundle bundle, final File bundleFile,\n            final InputStream bundleStream) {\n        Thread t = new Thread(\"Background Update\" + bundle.getSymbolicName()\n            + \" (\" + bundle.getBundleId() + \")\") {\n            public void run() {\n                // wait some time for the request to settle\n                try {\n                    sleep(500L);\n                } catch (InterruptedException ie) {\n                    // don't care\n                }\n\n                // now deploy the resolved bundles\n                try {\n                    bundle.update(bundleStream);\n                } catch (BundleException be) {\n                    // TODO: log\n                } finally {\n                    bundleFile.delete();\n                }\n            }\n        };\n\n        t.setDaemon(true); // make a daemon thread (detach from current thread)\n        t.start();\n    }","id":36746,"modified_method":"private void updateBackground(final Bundle bundle, final File bundleFile) {\n        Thread t = new InstallHelper(this, \"Background Update\"\n            + bundle.getSymbolicName() + \" (\" + bundle.getBundleId() + \")\",\n            bundleFile) {\n\n            @Override\n            protected void doRun(InputStream bundleStream)\n                    throws BundleException {\n                bundle.update(bundleStream);\n            }\n        };\n\n        t.start();\n    }","commit_id":"ede12f077a001a70b207b18ae6aa697d33ee8ee6","url":"https://github.com/apache/sling"},{"original_method":"private String getSymbolicName(File bundleFile) {\n        JarFile jar = null;\n        try {\n            jar = new JarFile(bundleFile);\n            Manifest m = jar.getManifest();\n            if (m != null) {\n                return m.getMainAttributes().getValue(\n                    Constants.BUNDLE_SYMBOLICNAME);\n            }\n        } catch (IOException ioe) {\n            // TODO: should log\n        } finally {\n            if (jar != null) {\n                try {\n                    jar.close();\n                } catch (IOException ioe) {\n                    // ignore\n                }\n            }\n        }\n\n        // fall back to \"not found\"\n        return null;\n    }","id":36747,"modified_method":"private String getSymbolicName(File bundleFile) {\n        JarFile jar = null;\n        try {\n            jar = new JarFile(bundleFile);\n            Manifest m = jar.getManifest();\n            if (m != null) {\n                return m.getMainAttributes().getValue(\n                    Constants.BUNDLE_SYMBOLICNAME);\n            }\n        } catch (IOException ioe) {\n            getLog().log(LogService.LOG_WARNING,\n                \"Cannot extract symbolic name of bundle file \" + bundleFile,\n                ioe);\n        } finally {\n            if (jar != null) {\n                try {\n                    jar.close();\n                } catch (IOException ioe) {\n                    // ignore\n                }\n            }\n        }\n\n        // fall back to \"not found\"\n        return null;\n    }","commit_id":"ede12f077a001a70b207b18ae6aa697d33ee8ee6","url":"https://github.com/apache/sling"},{"original_method":"private void installBackground(final File bundleFile,\n            final String location, final int startlevel, final boolean doStart) {\n\n        Thread t = new Thread(\"Background Install \" + bundleFile) {\n            public void run() {\n                // wait some time for the request to settle\n                try {\n                    sleep(500L);\n                } catch (InterruptedException ie) {\n                    // don't care\n                }\n\n                // now deploy the resolved bundles\n                InputStream fin = null;\n                try {\n                    fin = new FileInputStream(bundleFile);\n                    Bundle bundle = getBundleContext().installBundle(location,\n                        fin);\n\n                    StartLevel sl = getStartLevel();\n                    if (sl != null) {\n                        sl.setBundleStartLevel(bundle, startlevel);\n                    }\n\n                    if (doStart) {\n                        bundle.start();\n                    }\n                } catch (IOException ioe) {\n                    // TODO: log\n                } catch (BundleException be) {\n                    // TODO: log\n                } finally {\n                    if (fin != null) {\n                        try {\n                            fin.close();\n                        } catch (IOException ignore) {\n                        }\n                    }\n                    bundleFile.delete();\n                }\n            }\n        };\n\n        t.setDaemon(true); // make a daemon thread (detach from current thread)\n        t.start();\n    }","id":36748,"modified_method":"private void installBackground(final File bundleFile,\n            final String location, final int startlevel, final boolean doStart) {\n\n        Thread t = new InstallHelper(this, \"Background Install \" + bundleFile,\n            bundleFile) {\n\n            @Override\n            protected void doRun(InputStream bundleStream)\n                    throws BundleException {\n                Bundle bundle = getBundleContext().installBundle(location,\n                    bundleStream);\n\n                StartLevel sl = getStartLevel();\n                if (sl != null) {\n                    sl.setBundleStartLevel(bundle, startlevel);\n                }\n\n                if (doStart) {\n                    bundle.start();\n                }\n            }\n        };\n\n        t.start();\n    }","commit_id":"ede12f077a001a70b207b18ae6aa697d33ee8ee6","url":"https://github.com/apache/sling"},{"original_method":"@Override\n\tpublic List<Bundle> deploy(BundleContext bundleContext, File lpkgFile)\n\t\tthrows IOException {\n\n\t\tPath lpkgFilePath = lpkgFile.toPath();\n\n\t\tif (!lpkgFilePath.startsWith(_deploymentDirPath)) {\n\t\t\tthrow new LPKGVerifyException(\n\t\t\t\t\"Unable to deploy \" + lpkgFile +\n\t\t\t\t\t\" from outside the deployment directory \" +\n\t\t\t\t\t\t_deploymentDirPath);\n\t\t}\n\n\t\tList<Bundle> oldBundles = _lpkgVerifier.verify(lpkgFile);\n\n\t\tfor (Bundle bundle : oldBundles) {\n\t\t\ttry {\n\t\t\t\tbundle.uninstall();\n\n\t\t\t\tif (_log.isInfoEnabled()) {\n\t\t\t\t\t_log.info(\n\t\t\t\t\t\t\"Uninstalled older LPKG bundle \" + bundle +\n\t\t\t\t\t\t\t\" in order to install \" + lpkgFile);\n\t\t\t\t}\n\n\t\t\t\tString location = bundle.getLocation();\n\n\t\t\t\tif (!location.equals(lpkgFile.getCanonicalPath()) &&\n\t\t\t\t\tFiles.deleteIfExists(Paths.get(bundle.getLocation())) &&\n\t\t\t\t\t_log.isInfoEnabled()) {\n\n\t\t\t\t\t_log.info(\n\t\t\t\t\t\t\"Removed old LPKG bundle \" + bundle.getLocation());\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (BundleException be) {\n\t\t\t\t_log.error(\n\t\t\t\t\t\"Unable to uninstall \" + bundle + \" in order to install \" +\n\t\t\t\t\t\tlpkgFile,\n\t\t\t\t\tbe);\n\t\t\t}\n\t\t}\n\n\t\ttry {\n\t\t\tList<Bundle> bundles = new ArrayList<>();\n\n\t\t\tBundle lpkgBundle = bundleContext.installBundle(\n\t\t\t\tlpkgFile.getCanonicalPath(), toBundle(lpkgFile));\n\n\t\t\tBundleStartLevel bundleStartLevel = lpkgBundle.adapt(\n\t\t\t\tBundleStartLevel.class);\n\n\t\t\tbundleStartLevel.setStartLevel(\n\t\t\t\tPropsValues.MODULE_FRAMEWORK_DYNAMIC_INSTALL_START_LEVEL);\n\n\t\t\tbundles.add(lpkgBundle);\n\n\t\t\tList<Bundle> newBundles = _lpkgBundleTracker.getObject(lpkgBundle);\n\n\t\t\tif (newBundles != null) {\n\t\t\t\tbundles.addAll(newBundles);\n\t\t\t}\n\n\t\t\tif (LPKGIndexValidatorThreadLocal.isEnabled()) {\n\t\t\t\t_lpkgIndexValidator.updateIntegrityProperties();\n\t\t\t}\n\n\t\t\tif (!oldBundles.isEmpty()) {\n\t\t\t\t_refreshRemovalPendingBundles(bundleContext, lpkgBundle);\n\t\t\t}\n\n\t\t\treturn bundles;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","id":36749,"modified_method":"@Override\n\tpublic List<Bundle> deploy(BundleContext bundleContext, File lpkgFile)\n\t\tthrows IOException {\n\n\t\tPath lpkgFilePath = lpkgFile.toPath();\n\n\t\tif (!lpkgFilePath.startsWith(_deploymentDirPath)) {\n\t\t\tthrow new LPKGVerifyException(\n\t\t\t\t\"Unable to deploy \" + lpkgFile +\n\t\t\t\t\t\" from outside the deployment directory \" +\n\t\t\t\t\t\t_deploymentDirPath);\n\t\t}\n\n\t\tList<Bundle> oldBundles = _lpkgVerifier.verify(lpkgFile);\n\n\t\tfor (Bundle bundle : oldBundles) {\n\t\t\ttry {\n\t\t\t\tbundle.uninstall();\n\n\t\t\t\tif (_log.isInfoEnabled()) {\n\t\t\t\t\t_log.info(\n\t\t\t\t\t\t\"Uninstalled older LPKG bundle \" + bundle +\n\t\t\t\t\t\t\t\" in order to install \" + lpkgFile);\n\t\t\t\t}\n\n\t\t\t\tString location = bundle.getLocation();\n\n\t\t\t\tif (!location.equals(lpkgFile.getCanonicalPath()) &&\n\t\t\t\t\tFiles.deleteIfExists(Paths.get(bundle.getLocation())) &&\n\t\t\t\t\t_log.isInfoEnabled()) {\n\n\t\t\t\t\t_log.info(\n\t\t\t\t\t\t\"Removed old LPKG bundle \" + bundle.getLocation());\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (BundleException be) {\n\t\t\t\t_log.error(\n\t\t\t\t\t\"Unable to uninstall \" + bundle + \" in order to install \" +\n\t\t\t\t\t\tlpkgFile,\n\t\t\t\t\tbe);\n\t\t\t}\n\t\t}\n\n\t\ttry {\n\t\t\tString location = lpkgFile.getCanonicalPath();\n\n\t\t\tBundle lpkgBundle = bundleContext.getBundle(location);\n\n\t\t\tif (lpkgBundle != null) {\n\t\t\t\treturn Collections.emptyList();\n\t\t\t}\n\n\t\t\tList<Bundle> bundles = new ArrayList<>();\n\n\t\t\tlpkgBundle = bundleContext.installBundle(\n\t\t\t\tlocation, toBundle(lpkgFile));\n\n\t\t\tBundleStartLevel bundleStartLevel = lpkgBundle.adapt(\n\t\t\t\tBundleStartLevel.class);\n\n\t\t\tbundleStartLevel.setStartLevel(\n\t\t\t\tPropsValues.MODULE_FRAMEWORK_DYNAMIC_INSTALL_START_LEVEL);\n\n\t\t\tbundles.add(lpkgBundle);\n\n\t\t\tList<Bundle> newBundles = _lpkgBundleTracker.getObject(lpkgBundle);\n\n\t\t\tif (newBundles != null) {\n\t\t\t\tbundles.addAll(newBundles);\n\t\t\t}\n\n\t\t\tif (LPKGIndexValidatorThreadLocal.isEnabled()) {\n\t\t\t\t_lpkgIndexValidator.updateIntegrityProperties();\n\t\t\t}\n\n\t\t\tif (!oldBundles.isEmpty()) {\n\t\t\t\t_refreshRemovalPendingBundles(bundleContext, lpkgBundle);\n\t\t\t}\n\n\t\t\treturn bundles;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}","commit_id":"8e40d714a55b41f807b740a947323b32e2fbf3b4","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\tpublic List<Bundle> deploy(BundleContext bundleContext, File lpkgFile)\n\t\tthrows IOException {\n\n\t\ttry {\n\t\t\tList<Bundle> bundles = new ArrayList<>();\n\n\t\t\tBundle lpkgBundle = bundleContext.installBundle(\n\t\t\t\tlpkgFile.getCanonicalPath(), _lpkgToOSGiBundle(lpkgFile));\n\n\t\t\tBundleStartLevel bundleStartLevel = lpkgBundle.adapt(\n\t\t\t\tBundleStartLevel.class);\n\n\t\t\tbundleStartLevel.setStartLevel(\n\t\t\t\tPropsValues.MODULE_FRAMEWORK_DYNAMIC_INSTALL_START_LEVEL);\n\n\t\t\tbundles.add(lpkgBundle);\n\n\t\t\tList<Bundle> newBundles = _lpkgBundleTracker.getObject(lpkgBundle);\n\n\t\t\tif (newBundles != null) {\n\t\t\t\tbundles.addAll(newBundles);\n\t\t\t}\n\n\t\t\treturn bundles;\n\t\t}\n\t\tcatch (BundleException be) {\n\t\t\tthrow new IOException(be);\n\t\t}\n\t}","id":36750,"modified_method":"@Override\n\tpublic List<Bundle> deploy(BundleContext bundleContext, File lpkgFile)\n\t\tthrows IOException {\n\n\t\tString canonicalPath = lpkgFile.getCanonicalPath();\n\n\t\tfor (Bundle bundle : _lpkgVerifier.verify(lpkgFile)) {\n\t\t\ttry {\n\t\t\t\tbundle.uninstall();\n\n\t\t\t\tif (_log.isInfoEnabled()) {\n\t\t\t\t\t_log.info(\n\t\t\t\t\t\t\"Uninstalled older version LPKG bundle \" + bundle +\n\t\t\t\t\t\t\t\" in order to install \" + lpkgFile);\n\t\t\t\t}\n\n\t\t\t\tString location = bundle.getLocation();\n\n\t\t\t\tif (!location.equals(canonicalPath) &&\n\t\t\t\t\tFiles.deleteIfExists(Paths.get(bundle.getLocation())) &&\n\t\t\t\t\t_log.isInfoEnabled()) {\n\n\t\t\t\t\t_log.info(\"Removed old lpkg file \" + bundle.getLocation());\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (BundleException be) {\n\t\t\t\t_log.error(\n\t\t\t\t\t\"Unable to uninstall \" + bundle + \" for \" + lpkgFile, be);\n\t\t\t}\n\t\t}\n\n\t\ttry {\n\t\t\tList<Bundle> bundles = new ArrayList<>();\n\n\t\t\tBundle lpkgBundle = bundleContext.installBundle(\n\t\t\t\tcanonicalPath, _lpkgToOSGiBundle(lpkgFile));\n\n\t\t\tBundleStartLevel bundleStartLevel = lpkgBundle.adapt(\n\t\t\t\tBundleStartLevel.class);\n\n\t\t\tbundleStartLevel.setStartLevel(\n\t\t\t\tPropsValues.MODULE_FRAMEWORK_DYNAMIC_INSTALL_START_LEVEL);\n\n\t\t\tbundles.add(lpkgBundle);\n\n\t\t\tList<Bundle> newBundles = _lpkgBundleTracker.getObject(lpkgBundle);\n\n\t\t\tif (newBundles != null) {\n\t\t\t\tbundles.addAll(newBundles);\n\t\t\t}\n\n\t\t\treturn bundles;\n\t\t}\n\t\tcatch (BundleException be) {\n\t\t\tthrow new IOException(be);\n\t\t}\n\t}","commit_id":"a169d75fe4f0d61a5e8b3544ce4a39683beb7cf0","url":"https://github.com/liferay/liferay-portal"},{"original_method":"private ServiceName installBundleFromURL(ServiceTarget serviceTarget, URL bundleURL, Integer startLevel, Map<ServiceName, Deployment> installedBundles) throws Exception {\n        BundleManager bundleManager = injectedBundleManager.getValue();\n        BundleInfo info = BundleInfo.createBundleInfo(bundleURL);\n        Deployment dep = DeploymentFactory.createDeployment(info);\n        if (startLevel != null) {\n            dep.setStartLevel(startLevel.intValue());\n            dep.setAutoStart(true);\n        }\n        ServiceName serviceName = bundleManager.installBundle(serviceTarget, dep);\n        installedBundles.put(serviceName, dep);\n        return serviceName;\n    }","id":36751,"modified_method":"private ServiceName installBundleFromURL(ServiceTarget serviceTarget, URL bundleURL, Integer level, ServiceListener<Bundle> listener) throws Exception {\n        BundleManager bundleManager = injectedBundleManager.getValue();\n        BundleInfo info = BundleInfo.createBundleInfo(bundleURL);\n        Deployment dep = DeploymentFactory.createDeployment(info);\n        if (level != null) {\n            dep.setStartLevel(level.intValue());\n            dep.setAutoStart(true);\n        }\n        StorageStateProvider storageProvider = injectedStorageProvider.getValue();\n        StorageState storageState = storageProvider.getByLocation(dep.getLocation());\n        if (storageState != null) {\n            dep.addAttachment(StorageState.class, storageState);\n        }\n        return bundleManager.installBundle(serviceTarget, dep, listener);\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> serviceController = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", serviceController.getName(), serviceController.getMode());\n\n        final Map<ServiceName, Deployment> installedBundles = new LinkedHashMap<ServiceName, Deployment>();\n        final Set<ServiceName> resolvableServices = new LinkedHashSet<ServiceName>();\n\n        final BundleContext syscontext = injectedSystemBundle.getValue().getBundleContext();\n        final String startLevelProp = syscontext.getProperty(Constants.FRAMEWORK_BEGINNING_STARTLEVEL);\n        final int beginningStartLevel = startLevelProp != null ? Integer.parseInt(startLevelProp) : 1;\n\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n\n            ServerEnvironment serverEnvironment = injectedServerEnvironment.getValue();\n            bundlesDir = serverEnvironment.getBundlesDir();\n            if (bundlesDir.isDirectory() == false)\n                throw MESSAGES.illegalStateCannotFindBundleDir(bundlesDir);\n\n            List<OSGiCapability> configcaps = new ArrayList<OSGiCapability>();\n            configcaps.add(new OSGiCapability(\"org.osgi.enterprise\", null));\n            configcaps.addAll(injectedSubsystemState.getValue().getCapabilities());\n            for (OSGiCapability moduleMetaData : configcaps) {\n                ServiceName serviceName = installCapability(serviceTarget, moduleMetaData, installedBundles);\n                int startLevel = moduleMetaData.getStartLevel() != null ? moduleMetaData.getStartLevel() : 1;\n                if (serviceName != null && startLevel <= beginningStartLevel) {\n                    resolvableServices.add(serviceName);\n                }\n            }\n\n            AutoInstallHandlerComplete installComplete = new AutoInstallHandlerComplete(installedBundles) {\n                @Override\n                public void start(StartContext context) throws StartException {\n                    // Resolve all bundles up until and including the Framework beginning start level\n                    Set<Bundle> resolvableBundles = new LinkedHashSet<Bundle>();\n                    ServiceContainer serviceContainer = context.getController().getServiceContainer();\n                    for (ServiceName serviceName : resolvableServices) {\n                        ServiceController<?> requiredService = serviceContainer.getRequiredService(serviceName);\n                        resolvableBundles.add((Bundle) requiredService.getValue());\n                    }\n                    Bundle[] bundleArr = resolvableBundles.toArray(new Bundle[resolvableBundles.size()]);\n                    PackageAdmin packageAdmin = injectedPackageAdmin.getValue();\n                    packageAdmin.resolveBundles(bundleArr);\n                    super.start(context);\n                }\n            };\n            installComplete.install(serviceTarget);\n        } catch (Exception ex) {\n            throw MESSAGES.startFailedToProcessInitialCapabilites(ex);\n        }\n    }","id":36752,"modified_method":"@Override\n    public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> serviceController = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", serviceController.getName(), serviceController.getMode());\n\n        final BundleContext syscontext = injectedSystemBundle.getValue().getBundleContext();\n        final String startLevelProp = syscontext.getProperty(Constants.FRAMEWORK_BEGINNING_STARTLEVEL);\n        final int beginningStartLevel = startLevelProp != null ? Integer.parseInt(startLevelProp) : 1;\n\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n\n            ServerEnvironment serverEnvironment = injectedServerEnvironment.getValue();\n            bundlesDir = serverEnvironment.getBundlesDir();\n            if (bundlesDir.isDirectory() == false)\n                throw MESSAGES.illegalStateCannotFindBundleDir(bundlesDir);\n\n            final List<OSGiCapability> configcaps = new ArrayList<OSGiCapability>();\n            configcaps.add(new OSGiCapability(\"org.osgi.enterprise\", null));\n            configcaps.addAll(injectedSubsystemState.getValue().getCapabilities());\n            Iterator<OSGiCapability> iterator = configcaps.iterator();\n            while (iterator.hasNext()) {\n                OSGiCapability configcap = iterator.next();\n                if (installModuleCapability(serviceTarget, configcap))\n                    iterator.remove();\n            }\n\n            final Set<ServiceName> resolvableServices = new LinkedHashSet<ServiceName>();\n            AutoInstallComplete installComplete = new AutoInstallComplete() {\n\n                @Override\n                protected boolean allServicesAdded(Set<ServiceName> trackedServices) {\n                    return configcaps.size() == trackedServices.size();\n                }\n\n                @Override\n                public void start(StartContext context) throws StartException {\n                    // Resolve all bundles up until and including the Framework beginning start level\n                    Set<Bundle> resolvableBundles = new LinkedHashSet<Bundle>();\n                    ServiceContainer serviceContainer = context.getController().getServiceContainer();\n                    for (ServiceName serviceName : resolvableServices) {\n                        ServiceController<?> requiredService = serviceContainer.getRequiredService(serviceName);\n                        resolvableBundles.add((Bundle) requiredService.getValue());\n                    }\n                    Bundle[] bundleArr = resolvableBundles.toArray(new Bundle[resolvableBundles.size()]);\n                    PackageAdmin packageAdmin = injectedPackageAdmin.getValue();\n                    packageAdmin.resolveBundles(bundleArr);\n                    super.start(context);\n                }\n            };\n            installComplete.install(serviceTarget);\n            ServiceListener<Bundle> listener = installComplete.getListener();\n\n            for (OSGiCapability configcap : configcaps) {\n                ServiceName serviceName = installCapability(serviceTarget, configcap, listener);\n                int startLevel = configcap.getStartLevel() != null ? configcap.getStartLevel() : 1;\n                if (serviceName != null && startLevel <= beginningStartLevel) {\n                    resolvableServices.add(serviceName);\n                }\n            }\n        } catch (Exception ex) {\n            throw MESSAGES.startFailedToProcessInitialCapabilites(ex);\n        }\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"private ServiceName  installCapability(ServiceTarget serviceTarget, OSGiCapability osgicap, Map<ServiceName, Deployment> installedBundles) throws Exception {\n        String identifier = osgicap.getIdentifier();\n        Integer startLevel = osgicap.getStartLevel();\n\n        // Try the identifier as ModuleIdentifier\n        if (isValidModuleIdentifier(identifier)) {\n            ModuleIdentifier moduleId = ModuleIdentifier.fromString(identifier);\n\n            // Attempt to install the bundle from the bundles hierarchy\n            File bundleFile = ModuleIdentityArtifactProvider.getRepositoryEntry(bundlesDir, moduleId);\n            if (bundleFile != null) {\n                URL bundleURL = bundleFile.toURI().toURL();\n                return installBundleFromURL(serviceTarget, bundleURL, startLevel, installedBundles);\n            }\n\n            // Attempt to load the module from the modules hierarchy\n            Module module = null;\n            try {\n                ModuleLoader moduleLoader = Module.getBootModuleLoader();\n                module = moduleLoader.loadModule(moduleId);\n            } catch (ModuleLoadException e) {\n                LOGGER.debugf(\"Cannot load module: %s\", moduleId);\n            }\n            if (module != null) {\n                OSGiMetaData metadata = getModuleMetadata(module);\n                XResourceBuilder builder = XResourceBuilderFactory.create();\n                if (metadata != null) {\n                    builder.loadFrom(metadata);\n                } else {\n                    builder.loadFrom(module);\n                }\n                XResource res = builder.getResource();\n                res.addAttachment(Module.class, module);\n                injectedEnvironment.getValue().installResources(res);\n                return null;\n            }\n        }\n\n        // Try the identifier as MavenCoordinates\n        else if (isValidMavenIdentifier(identifier)) {\n            Repository repository = injectedRepository.getValue();\n            MavenCoordinates mavenId = MavenCoordinates.parse(identifier);\n            Requirement req = XRequirementBuilder.createArtifactRequirement(mavenId);\n            Collection<Capability> caps = repository.findProviders(Collections.singleton(req)).get(req);\n            if (caps.isEmpty() == false) {\n                XIdentityCapability icap = (XIdentityCapability) caps.iterator().next();\n                URL bundleURL = (URL) icap.getAttribute(XResourceConstants.CONTENT_URL);\n                return installBundleFromURL(serviceTarget, bundleURL, startLevel, installedBundles);\n            }\n        }\n        LOGGER.warnCannotResolveCapability(identifier);\n        return null;\n    }","id":36753,"modified_method":"private ServiceName installCapability(ServiceTarget serviceTarget, OSGiCapability osgicap, ServiceListener<Bundle> listener) throws Exception {\n        String identifier = osgicap.getIdentifier();\n        Integer level = osgicap.getStartLevel();\n\n        // Try the identifier as ModuleIdentifier\n        if (isValidModuleIdentifier(identifier)) {\n            ModuleIdentifier moduleId = ModuleIdentifier.fromString(identifier);\n\n            // Attempt to install the bundle from the bundles hierarchy\n            File bundleFile = ModuleIdentityArtifactProvider.getRepositoryEntry(bundlesDir, moduleId);\n            if (bundleFile != null) {\n                URL bundleURL = bundleFile.toURI().toURL();\n                return installBundleFromURL(serviceTarget, bundleURL, level, listener);\n            }\n        }\n\n        // Try the identifier as MavenCoordinates\n        else if (isValidMavenIdentifier(identifier)) {\n            Repository repository = injectedRepository.getValue();\n            MavenCoordinates mavenId = MavenCoordinates.parse(identifier);\n            Requirement req = XRequirementBuilder.createArtifactRequirement(mavenId);\n            Collection<Capability> caps = repository.findProviders(Collections.singleton(req)).get(req);\n            if (caps.isEmpty() == false) {\n                XIdentityCapability icap = (XIdentityCapability) caps.iterator().next();\n                URL bundleURL = (URL) icap.getAttribute(XResourceConstants.CONTENT_URL);\n                return installBundleFromURL(serviceTarget, bundleURL, level, listener);\n            }\n        }\n\n        LOGGER.warnCannotResolveCapability(identifier);\n        return null;\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        deploymentManager = new ModelControllerServerDeploymentManager(injectedController.getValue());\n    }","id":36754,"modified_method":"@Override\n    public void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        deploymentManager = new ModelControllerServerDeploymentManager(injectedController.getValue());\n        serviceTarget = context.getChildTarget();\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void installBundle(ServiceTarget serviceTarget, Deployment dep) throws BundleException {\n        LOGGER.tracef(\"Install deployment: %s\", dep);\n        try {\n\n            // Install the {@link Deployment} holder service\n            String contextName = DeploymentHolderService.getContextName(dep);\n            DeploymentHolderService.addService(serviceTarget, contextName, dep);\n\n            // Build and execute the deployment plan\n            InputStream inputStream = dep.getRoot().openStream();\n            try {\n                DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n                builder = builder.add(contextName, inputStream).andDeploy();\n                DeploymentPlan plan = builder.build();\n                DeploymentAction deployAction = builder.getLastAction();\n                executeDeploymentPlan(plan, deployAction);\n            } finally {\n                if(inputStream != null) try {\n                    inputStream.close();\n                } catch (IOException e) {\n                    LOGGER.debugf(e, \"Failed to close resource %s\", inputStream);\n                }\n            }\n        } catch (RuntimeException rte) {\n            throw rte;\n        } catch (BundleException ex) {\n            throw ex;\n        } catch (Exception ex) {\n            throw MESSAGES.cannotDeployBundle(ex, dep);\n        }\n    }","id":36755,"modified_method":"@Override\n    public void installBundle(Deployment dep) throws BundleException {\n        LOGGER.tracef(\"Install deployment: %s\", dep);\n        try {\n\n            // Install the {@link Deployment} holder service\n            String contextName = DeploymentHolderService.getContextName(dep);\n            DeploymentHolderService.addService(serviceTarget, contextName, dep);\n\n            // Build and execute the deployment plan\n            InputStream inputStream = dep.getRoot().openStream();\n            try {\n                DeploymentPlanBuilder builder = deploymentManager.newDeploymentPlan();\n                builder = builder.add(contextName, inputStream).andDeploy();\n                DeploymentPlan plan = builder.build();\n                DeploymentAction deployAction = builder.getLastAction();\n                executeDeploymentPlan(plan, deployAction);\n            } finally {\n                if(inputStream != null) try {\n                    inputStream.close();\n                } catch (IOException e) {\n                    LOGGER.debugf(e, \"Failed to close resource %s\", inputStream);\n                }\n            }\n        } catch (RuntimeException rte) {\n            throw rte;\n        } catch (BundleException ex) {\n            throw ex;\n        } catch (Exception ex) {\n            throw MESSAGES.cannotDeployBundle(ex, dep);\n        }\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void deploy(final DeploymentPhaseContext context) throws DeploymentUnitProcessingException {\n        final DeploymentUnit depUnit = context.getDeploymentUnit();\n        final Deployment deployment = OSGiDeploymentAttachment.getDeployment(depUnit);\n        if (deployment != null) {\n            if (frameworkActivated.compareAndSet(false, true)) {\n                activateFramework(context);\n            }\n            ServiceName serviceName;\n            if (deploymentTracker.isClosed() == false && deploymentTracker.removeDeploymentName(depUnit.getName())) {\n                serviceName = PersistentBundleInstallService.addService(deploymentTracker, context, deployment);\n                deploymentTracker.registerPersistentBundleInstallService(serviceName);\n            } else {\n                serviceName = BundleInstallService.addService(context, deployment);\n            }\n            depUnit.putAttachment(INSTALL_SERVICE_NAME_KEY, serviceName);\n        }\n    }","id":36756,"modified_method":"@Override\n    public void deploy(final DeploymentPhaseContext context) throws DeploymentUnitProcessingException {\n        final DeploymentUnit depUnit = context.getDeploymentUnit();\n        final Deployment deployment = OSGiDeploymentAttachment.getDeployment(depUnit);\n        if (deployment != null) {\n            if (frameworkActivated.compareAndSet(false, true)) {\n                activateFramework(context);\n            }\n            ServiceName serviceName;\n            if (!deploymentTracker.isClosed() && deploymentTracker.hasDeploymentName(depUnit.getName())) {\n                serviceName = PersistentBundleInstallService.addService(deploymentTracker, context, deployment);\n                deploymentTracker.registerBundleInstallService(serviceName);\n            } else {\n                serviceName = BundleInstallService.addService(context, deployment);\n            }\n            depUnit.putAttachment(INSTALL_SERVICE_NAME_KEY, serviceName);\n        }\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public BundleInstallProcessor(InitialDeploymentTracker deploymentListener) {\n        this.deploymentTracker = deploymentListener;\n    }","id":36757,"modified_method":"public BundleInstallProcessor(InitialDeploymentTracker deploymentTracker) {\n        this.deploymentTracker = deploymentTracker;\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n            BundleManager bundleManager = injectedBundleManager.getValue();\n            bundleManager.installBundle(serviceTarget, deployment);\n        } catch (Throwable th) {\n            throw MESSAGES.startFailedToInstallDeployment(th, deployment);\n        }\n    }","id":36758,"modified_method":"public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n            BundleManager bundleManager = injectedBundleManager.getValue();\n            bundleManager.installBundle(serviceTarget, deployment, null);\n        } catch (Throwable th) {\n            throw MESSAGES.startFailedToInstallDeployment(th, deployment);\n        }\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected void performBoottime(final OperationContext context, final ModelNode operation, final ModelNode model,\n            final ServiceVerificationHandler verificationHandler, final List<ServiceController<?>> newControllers) {\n\n        LOGGER.infoActivatingSubsystem();\n\n        final InitialDeploymentTracker deploymentTracker = new InitialDeploymentTracker(context);\n\n        context.addStep(new OperationStepHandler() {\n            public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n                ServiceTarget serviceTarget = context.getServiceTarget();\n                newControllers.add(BundleInstallIntegration.addService(serviceTarget));\n                newControllers.add(FrameworkBootstrapService.addService(serviceTarget, verificationHandler));\n                newControllers.add(PersistentBundlesIntegration.addService(serviceTarget, deploymentTracker));\n                context.completeStep();\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        context.addStep(new AbstractDeploymentChainStep() {\n            protected void execute(DeploymentProcessorTarget processorTarget) {\n                processorTarget.addDeploymentProcessor(Phase.STRUCTURE, Phase.STRUCTURE_OSGI_MANIFEST, new OSGiManifestStructureProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_BUNDLE_INFO, new OSGiBundleInfoParseProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_XSERVICE_PROPERTIES, new OSGiXServiceParseProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_DEPLOYMENT, new BundleDeploymentProcessor());\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_BUNDLE_CONTEXT_BINDING, new BundleContextBindingProcessor());\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_DEPLOYMENT, new BundleInstallProcessor(deploymentTracker));\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_MODULE, new ModuleRegisterProcessor());\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        ServiceTarget serviceTarget = context.getServiceTarget();\n        newControllers.add(SubsystemState.addService(serviceTarget, getActivationMode(operation)));\n\n        // This step injects the System Bundle Service into our custom resource\n        context.addStep(new OperationStepHandler() {\n            @Override\n            public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n                ServiceBuilder<Void> builder = context.getServiceTarget().addService(Services.JBOSGI_BASE_NAME.append(\"OSGiSubsystem\").append(\"initialize\"),\n                        new AbstractService<Void>() {\n                            @SuppressWarnings(\"unchecked\")\n                            @Override\n                            public void start(StartContext context) throws StartException {\n                                try {\n                                    ServiceContainer ctr = context.getController().getServiceContainer();\n                                    ServiceController<Bundle> sc = (ServiceController<Bundle>) ctr.getRequiredService(Services.SYSTEM_BUNDLE);\n                                    resource.setBundleContextServiceController(sc);\n                                } finally {\n                                    context.getController().setMode(Mode.REMOVE);\n                                }\n                            }\n                        });\n                builder.addDependency(Services.SYSTEM_BUNDLE);\n                builder.setInitialMode(Mode.PASSIVE);\n                builder.install();\n                context.completeStep();\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        LOGGER.debugf(\"Activated OSGi Subsystem\");\n    }","id":36759,"modified_method":"protected void performBoottime(final OperationContext context, final ModelNode operation, final ModelNode model,\n            final ServiceVerificationHandler verificationHandler, final List<ServiceController<?>> newControllers) {\n\n        LOGGER.infoActivatingSubsystem();\n\n        final Activation activationMode = getActivationMode(operation);\n        final InitialDeploymentTracker deploymentTracker = new InitialDeploymentTracker(context, activationMode);\n\n        context.addStep(new OperationStepHandler() {\n            public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n                ServiceTarget serviceTarget = context.getServiceTarget();\n                newControllers.add(SubsystemState.addService(serviceTarget, activationMode));\n                newControllers.add(BundleInstallIntegration.addService(serviceTarget));\n                newControllers.add(FrameworkBootstrapService.addService(serviceTarget, verificationHandler));\n                newControllers.add(PersistentBundlesIntegration.addService(serviceTarget, deploymentTracker));\n                context.completeStep();\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        context.addStep(new AbstractDeploymentChainStep() {\n            protected void execute(DeploymentProcessorTarget processorTarget) {\n                processorTarget.addDeploymentProcessor(Phase.STRUCTURE, Phase.STRUCTURE_OSGI_MANIFEST, new OSGiManifestStructureProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_BUNDLE_INFO, new OSGiBundleInfoParseProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_XSERVICE_PROPERTIES, new OSGiXServiceParseProcessor());\n                processorTarget.addDeploymentProcessor(Phase.PARSE, Phase.PARSE_OSGI_DEPLOYMENT, new BundleDeploymentProcessor());\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_BUNDLE_CONTEXT_BINDING, new BundleContextBindingProcessor());\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_DEPLOYMENT, new BundleInstallProcessor(deploymentTracker));\n                processorTarget.addDeploymentProcessor(Phase.INSTALL, Phase.INSTALL_OSGI_MODULE, new ModuleRegisterProcessor());\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        // This step injects the System Bundle Service into our custom resource\n        context.addStep(new OperationStepHandler() {\n            @Override\n            public void execute(OperationContext context, ModelNode operation) throws OperationFailedException {\n                ServiceBuilder<Void> builder = context.getServiceTarget().addService(Services.JBOSGI_BASE_NAME.append(\"OSGiSubsystem\").append(\"initialize\"),\n                        new AbstractService<Void>() {\n                            @SuppressWarnings(\"unchecked\")\n                            @Override\n                            public void start(StartContext context) throws StartException {\n                                try {\n                                    ServiceContainer ctr = context.getController().getServiceContainer();\n                                    ServiceController<Bundle> sc = (ServiceController<Bundle>) ctr.getRequiredService(Services.SYSTEM_BUNDLE);\n                                    resource.setBundleContextServiceController(sc);\n                                } finally {\n                                    context.getController().setMode(Mode.REMOVE);\n                                }\n                            }\n                        });\n                builder.addDependency(Services.SYSTEM_BUNDLE);\n                builder.setInitialMode(Mode.PASSIVE);\n                builder.install();\n                context.completeStep();\n            }\n        }, OperationContext.Stage.RUNTIME);\n\n        LOGGER.debugf(\"Activated OSGi Subsystem\");\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n            BundleManager bundleManager = injectedBundleManager.getValue();\n            StorageStateProvider storageStateProvider = injectedStorageProvider.getValue();\n            StorageState storageState = storageStateProvider.getByLocation(deployment.getLocation());\n            if (storageState != null) {\n                deployment.addAttachment(StorageState.class, storageState);\n            }\n            ServiceName serviceName = bundleManager.installBundle(serviceTarget, deployment);\n            deploymentTracker.addInstalledBundle(serviceName, deployment);\n        } catch (Throwable th) {\n            throw MESSAGES.startFailedToInstallDeployment(th, deployment);\n        }\n    }","id":36760,"modified_method":"public synchronized void start(StartContext context) throws StartException {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        try {\n            ServiceTarget serviceTarget = context.getChildTarget();\n            BundleManager bundleManager = injectedBundleManager.getValue();\n            StorageStateProvider storageStateProvider = injectedStorageProvider.getValue();\n            StorageState storageState = storageStateProvider.getByLocation(deployment.getLocation());\n            if (storageState != null) {\n                deployment.addAttachment(StorageState.class, storageState);\n            }\n            ServiceListener<Bundle> listener = deploymentTracker.getBundleInstallListener();\n            bundleManager.installBundle(serviceTarget, deployment, listener);\n        } catch (Throwable th) {\n            throw MESSAGES.startFailedToInstallDeployment(th, deployment);\n        }\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static ServiceName addService(InitialDeploymentTracker deploymentTracker, DeploymentPhaseContext phaseContext, Deployment deployment) {\n        final DeploymentUnit depUnit = phaseContext.getDeploymentUnit();\n        final PersistentBundleInstallService service = new PersistentBundleInstallService(deploymentTracker, deployment);\n        final String contextName = depUnit.getName();\n        final ServiceName serviceName = getServiceName(depUnit);\n        final ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n        ServiceBuilder<Void> builder = serviceTarget.addService(serviceName, service);\n        builder.addDependency(Services.BUNDLE_MANAGER, BundleManager.class, service.injectedBundleManager);\n        builder.addDependency(Services.STORAGE_STATE_PROVIDER, StorageStateProvider.class, service.injectedStorageProvider);\n        builder.addDependency(deploymentUnitName(contextName));\n        builder.addDependency(IntegrationServices.AUTOINSTALL_HANDLER_COMPLETE);\n        builder.install();\n        return serviceName;\n    }","id":36761,"modified_method":"public static ServiceName addService(InitialDeploymentTracker deploymentTracker, DeploymentPhaseContext phaseContext, Deployment deployment) {\n        final DeploymentUnit depUnit = phaseContext.getDeploymentUnit();\n        final PersistentBundleInstallService service = new PersistentBundleInstallService(deploymentTracker, deployment);\n        final String contextName = depUnit.getName();\n        final ServiceName serviceName = getServiceName(depUnit);\n        final ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n        ServiceBuilder<Void> builder = serviceTarget.addService(serviceName, service);\n        builder.addDependency(Services.BUNDLE_MANAGER, BundleManager.class, service.injectedBundleManager);\n        builder.addDependency(Services.STORAGE_STATE_PROVIDER, StorageStateProvider.class, service.injectedStorageProvider);\n        builder.addDependency(deploymentUnitName(contextName));\n        builder.addDependency(IntegrationServices.AUTOINSTALL_COMPLETE);\n        builder.install();\n        return serviceName;\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"private PersistentBundlesIntegration(InitialDeploymentTracker deploymentTracker) {\n        this.deploymentTracker = deploymentTracker;\n    }","id":36762,"modified_method":"private PersistentBundlesIntegration() {\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static ServiceController<?> addService(ServiceTarget serviceTarget, InitialDeploymentTracker deploymentTracker) {\n        PersistentBundlesIntegration service = new PersistentBundlesIntegration(deploymentTracker);\n        ServiceBuilder<PersistentBundlesHandler> builder = serviceTarget.addService(IntegrationServices.PERSISTENT_BUNDLES_HANDLER, service);\n        builder.addDependencies(IntegrationServices.AUTOINSTALL_HANDLER_COMPLETE, InitialDeploymentTracker.INITIAL_DEPLOYMENTS_COMPLETE);\n        builder.setInitialMode(Mode.ON_DEMAND);\n        return builder.install();\n    }","id":36763,"modified_method":"public static ServiceController<?> addService(ServiceTarget serviceTarget, InitialDeploymentTracker deploymentTracker) {\n        PersistentBundlesIntegration service = new PersistentBundlesIntegration();\n        ServiceBuilder<PersistentBundlesHandler> builder = serviceTarget.addService(IntegrationServices.PERSISTENT_BUNDLES_HANDLER, service);\n        builder.addDependencies(IntegrationServices.AUTOINSTALL_COMPLETE, InitialDeploymentTracker.INITIAL_DEPLOYMENTS_COMPLETE);\n        builder.setInitialMode(Mode.ON_DEMAND);\n        return builder.install();\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void stop(StopContext context) {\n        ServiceController<?> controller = context.getController();\n        LOGGER.infof(\"Stopping: %s in mode %s\", controller.getName(), controller.getMode());\n    }","id":36764,"modified_method":"@Override\n    public void stop(StopContext context) {\n        ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Stopping: %s in mode %s\", controller.getName(), controller.getMode());\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void addInstalledBundle(ServiceName serviceName, Deployment deployment) {\n            if (isClosed() == false) {\n                LOGGER.infof(\"Add installed bundle dependency: %s\", serviceName);\n                installedBundles.put(serviceName, deployment);\n            }\n        }","id":36765,"modified_method":"private void initialDeploymentsComplete(ServiceTarget serviceTarget) {\n            LOGGER.debugf(\"Initial deployments complete\");\n            final ServiceBuilder<Void> deploymentCompleteBuilder = serviceTarget.addService(INITIAL_DEPLOYMENTS_COMPLETE, new AbstractService<Void>() {\n                public void start(StartContext context) throws StartException {\n                    final ServiceController<?> controller = context.getController();\n                    LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n                }\n            });\n            deploymentInstallComplete.set(true);\n            deploymentCompleteBuilder.install();\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void start(StartContext context) throws StartException {\n        final ServiceController<?> controller = context.getController();\n        LOGGER.infof(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n        Map<ServiceName, Deployment> installedBundles = deploymentTracker.getInstalledBundles();\n        PersistentBundlesHandlerComplete installComplete = new PersistentBundlesHandlerComplete(installedBundles);\n        installComplete.install(context.getChildTarget());\n    }","id":36766,"modified_method":"@Override\n    public void start(StartContext context) throws StartException {\n        final ServiceController<?> controller = context.getController();\n        LOGGER.debugf(\"Starting: %s in mode %s\", controller.getName(), controller.getMode());\n    }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"private Set<String> getDeploymentNames(OperationContext context) {\n            final Set<String> result = new HashSet<String>();\n            final ModelNode model = Resource.Tools.readModel(context.readResourceFromRoot(PathAddress.EMPTY_ADDRESS, true));\n            final ModelNode depmodel = model.get(ModelDescriptionConstants.DEPLOYMENT);\n            if (depmodel.isDefined()) {\n                final List<ModelNode> deploymentNodes = depmodel.asList();\n                for (ModelNode node : deploymentNodes) {\n                    Property property = node.asProperty();\n                    result.add(property.getName());\n                }\n                LOGGER.infof(\"Expecting initial deployments: %s\", result);\n            }\n            return result;\n        }","id":36767,"modified_method":"private Set<String> getDeploymentNames(OperationContext context) {\n            final Set<String> result = new HashSet<String>();\n            final ModelNode model = Resource.Tools.readModel(context.readResourceFromRoot(PathAddress.EMPTY_ADDRESS, true));\n            final ModelNode depmodel = model.get(ModelDescriptionConstants.DEPLOYMENT);\n            if (depmodel.isDefined()) {\n                final List<ModelNode> deploymentNodes = depmodel.asList();\n                for (ModelNode node : deploymentNodes) {\n                    Property property = node.asProperty();\n                    result.add(property.getName());\n                }\n                LOGGER.debugf(\"Expecting initial deployments: %s\", result);\n            }\n            return result;\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public boolean removeDeploymentName(String depname) {\n            return deploymentNames.remove(depname);\n        }","id":36768,"modified_method":"public boolean hasDeploymentName(String depname) {\n            return deploymentNames.contains(depname);\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public InitialDeploymentTracker(OperationContext context) {\n            serviceTarget = context.getServiceTarget();\n            deploymentNames = getDeploymentNames(context);\n            deploymentCount = new AtomicInteger(deploymentNames.size());\n            if (deploymentCount.get() == 0) {\n                initialDeploymentsComplete();\n                return;\n            }\n\n            bundleInstallServices = new HashSet<ServiceName>();\n            deploymentServiceNames = new HashSet<ServiceName>();\n            installedBundles = new LinkedHashMap<ServiceName, Deployment>();\n\n            for (String deploymentName : deploymentNames) {\n                ServiceName serviceName = Services.deploymentUnitName(deploymentName);\n                deploymentServiceNames.add(serviceName.append(Phase.INSTALL.toString()));\n            }\n            ServiceRegistry serviceRegistry = context.getServiceRegistry(false);\n            listenerTarget = serviceRegistry.getService(JBOSS_SERVER_CONTROLLER).getServiceContainer();\n            listenerTarget.addListener(Inheritance.ALL, this);\n        }","id":36769,"modified_method":"public InitialDeploymentTracker(final OperationContext context, Activation activationMode) {\n\n            final ServiceTarget serviceTarget = context.getServiceTarget();\n            final PersistentBundlesComplete installComplete = new PersistentBundlesComplete() {\n                @Override\n                protected boolean allServicesAdded(Set<ServiceName> trackedServices) {\n                    synchronized (bundleInstallServices) {\n                        return deploymentInstallComplete.get() && bundleInstallServices.size() == trackedServices.size();\n                    }\n                }\n            };\n            ServiceBuilder<Void> installCompleteBuilder = installComplete.install(serviceTarget);\n            installCompleteBuilder.setInitialMode(activationMode == Activation.EAGER ? Mode.ACTIVE : Mode.ON_DEMAND);\n\n            deploymentNames = getDeploymentNames(context);\n            deploymentCount = new AtomicInteger(deploymentNames.size());\n            if (deploymentCount.get() == 0) {\n                // Install the INITIAL_DEPLOYMENTS_COMPLETE service\n                initialDeploymentsComplete(serviceTarget);\n                // Install the PERSISTENT_BUNDLES_COMPLETE service\n                installCompleteBuilder.install();\n                return;\n            }\n\n            final Set<ServiceName> deploymentServiceNames = new HashSet<ServiceName>();\n            for (String deploymentName : deploymentNames) {\n                ServiceName serviceName = Services.deploymentUnitName(deploymentName);\n                deploymentServiceNames.add(serviceName.append(Phase.INSTALL.toString()));\n            }\n\n            final ServiceRegistry serviceRegistry = context.getServiceRegistry(false);\n            final ServiceTarget listenerTarget = serviceRegistry.getService(JBOSS_SERVER_CONTROLLER).getServiceContainer();\n            bundleInstallListener = installComplete.getListener();\n            ServiceListener<Object> listener = new AbstractServiceListener<Object>() {\n                @Override\n                public void transition(ServiceController<? extends Object> controller, Transition transition) {\n                    if (isClosed() == false) {\n                        ServiceName serviceName = controller.getName();\n                        synchronized (deploymentServiceNames) {\n                            if (deploymentServiceNames.contains(serviceName)) {\n                                switch (transition) {\n                                    case STARTING_to_UP:\n                                    case STARTING_to_START_FAILED:\n                                        deploymentServiceNames.remove(serviceName);\n                                        int remaining = deploymentCount.decrementAndGet();\n                                        LOGGER.debugf(\"Deployment tracked: %s (remaining=%d)\", serviceName.getCanonicalName(), remaining);\n                                        if (deploymentCount.get() == 0) {\n                                            listenerTarget.removeListener(this);\n                                            initialDeploymentsComplete(serviceTarget);\n                                            installComplete.checkAndComplete();\n                                        }\n                                }\n                            }\n                        }\n                    }\n                }\n            };\n            listenerTarget.addListener(Inheritance.ALL, listener);\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@SuppressWarnings(\"unchecked\")\n        private Map<ServiceName, Deployment> getInstalledBundles() {\n            return installedBundles != null ? installedBundles : Collections.EMPTY_MAP;\n        }","id":36770,"modified_method":"public ServiceListener<Bundle> getBundleInstallListener() {\n            return bundleInstallListener;\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void registerPersistentBundleInstallService(ServiceName serviceName) {\n            if (isClosed() == false) {\n                LOGGER.infof(\"Add bundle install dependency: %s\", serviceName);\n                bundleInstallServices.add(serviceName);\n            }\n        }","id":36771,"modified_method":"public void registerBundleInstallService(ServiceName serviceName) {\n            synchronized (bundleInstallServices) {\n                LOGGER.debugf(\"Register bundle install service: %s\", serviceName);\n                bundleInstallServices.add(serviceName);\n            }\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n        public boolean equals(Object obj) {\n            if (obj instanceof OSGiCapability == false)\n                return false;\n\n            OSGiCapability om = (OSGiCapability) obj;\n            return identifier == null ? om.identifier == null : identifier.equals(om.identifier);\n        }","id":36772,"modified_method":"@Override\n        public boolean equals(Object obj) {\n            if (obj instanceof OSGiCapability == false)\n                return false;\n            OSGiCapability other = (OSGiCapability) obj;\n            return identifier.equals(other.identifier);\n        }","commit_id":"1dc7e0e1c28d169c53c41f3fc0632fc26f51b88c","url":"https://github.com/wildfly/wildfly"},{"original_method":"boolean connectInDebugMode(ILaunch launch, IServer iServer, IProgressMonitor monitor)\n\t\t\tthrows CoreException {\n        \n        long start = System.currentTimeMillis();\n        \n\t\tthis.launch = launch;\n\t\tboolean success = false;\n\t\tIVMConnector connector = null;\n\t\tconnector = JavaRuntime.getVMConnector(\"org.eclipse.jdt.launching.socketAttachConnector\");\n\t\tif (connector == null) {\n\t\t\tconnector = JavaRuntime.getDefaultVMConnector();\n\t\t}\n\t\tif (connector == null) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t\t\t\t\"Could not get jvm connctor\"));\n\t\t}\n\t\t\n\t\tISlingLaunchpadServer launchpadServer = (ISlingLaunchpadServer) iServer.loadAdapter(SlingLaunchpadServer.class,\n\t\t        monitor);\n\n\t\tISlingLaunchpadConfiguration configuration = launchpadServer.getConfiguration();\n\t\t\n\t\tint debugPort = configuration.getDebugPort();\n\t\t\n\t\tif (debugPort<=0) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t            \"debug port not configured\"));\n\t\t}\n\t\t\n\t\tMap<String, String> connectMap = new HashMap<>();\n\t\tconnectMap.put(\"hostname\", iServer.getHost());\n\t\tconnectMap.put(\"port\", String.valueOf(debugPort));\n\t\t\n//\t\t\tMap argMap = null;//configuration.getAttribute(IJavaLaunchConfigurationConstants.ATTR_CONNECT_MAP, (Map)null);\n\t\t\n\t\tint connectTimeout = JavaRuntime.getPreferences().getInt(JavaRuntime.PREF_CONNECT_TIMEOUT);\n\t\tconnectMap.put(\"timeout\", Integer.toString(connectTimeout));  //$NON-NLS-1$\n\n\t\t// set the default source locator if required\n\t\t@SuppressWarnings(\"restriction\")\n\t\tISourceLookupDirector sourceLocator = new JavaSourceLookupDirector();\n\t\tsourceLocator\n\t\t\t\t.setSourcePathComputer(DebugPlugin.getDefault().getLaunchManager()\n\t\t\t\t\t\t.getSourcePathComputer(\n\t\t\t\t\t\t\t\t\"org.eclipse.jdt.launching.sourceLookup.javaSourcePathComputer\")); //$NON-NLS-1$\n\t\tList<IRuntimeClasspathEntry> classpathEntries = new ArrayList<>();\n\t\t\n\t\t// TODO - only add the projects which are deployed as modules on the server\n\t\t// 1. add java projects first\n        for (IJavaProject javaProject : ProjectHelper.getAllJavaProjects()) {\n            classpathEntries.add(JavaRuntime.newProjectRuntimeClasspathEntry(javaProject));\n        }\n\t\t\n        // 2. add the other modules deployed on server\n        ProgressUtils.advance(monitor, 10); // 20/50\n        \n        SourceReferenceResolver resolver = Activator.getDefault().getSourceReferenceResolver();\n        if ( resolver != null ) {\n            try {\n                List<SourceReference> references = osgiClient.findSourceReferences();\n                SubMonitor subMonitor = SubMonitor.convert(monitor, \"Resolving source references\", 24).setWorkRemaining(references.size());\n                for ( SourceReference reference :  references ) {\n                    try {\n                        subMonitor.setTaskName(\"Resolving source reference: \" + reference);\n                        IRuntimeClasspathEntry classpathEntry = resolver.resolve(reference);\n                        if ( classpathEntry != null ) {\n                            classpathEntries.add(classpathEntry);\n                        }\n                        ProgressUtils.advance(subMonitor, 1);\n                        \n                    } catch (CoreException e) {\n                        // don't fail the debug launch for artifact resolution errors\n                        Activator.getDefault().getPluginLogger().warn(\"Failed resolving source reference\", e);\n                    }\n                }\n                subMonitor.done(); // 49/50\n            } catch (OsgiClientException e1) {\n                throw new CoreException(new Status(Status.ERROR, Activator.PLUGIN_ID, e1.getMessage(), e1));\n            }\n        }\n        \n        // 3. add the JRE entry\n\t\tclasspathEntries.add(JavaRuntime.computeJREEntry(launch.getLaunchConfiguration()));\n\t\t\n\t\tIRuntimeClasspathEntry[] resolved = JavaRuntime.resolveSourceLookupPath(classpathEntries.toArray(new IRuntimeClasspathEntry[0]), launch.getLaunchConfiguration());\n\t\t\n\t\tsourceLocator.setSourceContainers(JavaRuntime.getSourceContainers(resolved));\n\t\tsourceLocator.initializeParticipants();\n\t\tlaunch.setSourceLocator(sourceLocator);\n\n\t\t// connect to remote VM\n\t\ttry{\n\t\t\tconnector.connect(connectMap, monitor, launch); // 50/50\n\t\t\tsuccess = true;\n\t\t\t\n\t\t\tlong elapsedMillis = System.currentTimeMillis() - start;\n\t\t\tActivator.getDefault().getPluginLogger().tracePerformance(\"Debug connection to {0}\", elapsedMillis, iServer.getName());\n\t\t} catch(Exception e) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t            \"could not establish debug connection to \"+iServer.getHost()+\" : \"+debugPort, e));\n\t\t}\n\t\treturn success;\n\t}","id":36773,"modified_method":"boolean connectInDebugMode(ILaunch launch, IServer iServer, IProgressMonitor monitor)\n\t\t\tthrows CoreException {\n        \n        long start = System.currentTimeMillis();\n        \n\t\tthis.launch = launch;\n\t\tboolean success = false;\n\t\tIVMConnector connector = null;\n\t\tconnector = JavaRuntime.getVMConnector(\"org.eclipse.jdt.launching.socketAttachConnector\");\n\t\tif (connector == null) {\n\t\t\tconnector = JavaRuntime.getDefaultVMConnector();\n\t\t}\n\t\tif (connector == null) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t\t\t\t\"Could not get jvm connctor\"));\n\t\t}\n\t\t\n\t\tISlingLaunchpadServer launchpadServer = (ISlingLaunchpadServer) iServer.loadAdapter(SlingLaunchpadServer.class,\n\t\t        monitor);\n\n\t\tISlingLaunchpadConfiguration configuration = launchpadServer.getConfiguration();\n\t\t\n\t\tint debugPort = configuration.getDebugPort();\n\t\t\n\t\tif (debugPort<=0) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t            \"debug port not configured\"));\n\t\t}\n\t\t\n\t\tMap<String, String> connectMap = new HashMap<>();\n\t\tconnectMap.put(\"hostname\", iServer.getHost());\n\t\tconnectMap.put(\"port\", String.valueOf(debugPort));\n\t\t\n//\t\t\tMap argMap = null;//configuration.getAttribute(IJavaLaunchConfigurationConstants.ATTR_CONNECT_MAP, (Map)null);\n\t\t\n\t\tint connectTimeout = JavaRuntime.getPreferences().getInt(JavaRuntime.PREF_CONNECT_TIMEOUT);\n\t\tconnectMap.put(\"timeout\", Integer.toString(connectTimeout));  //$NON-NLS-1$\n\n\t\t// set the default source locator if required\n\t\t@SuppressWarnings(\"restriction\")\n\t\tISourceLookupDirector sourceLocator = new JavaSourceLookupDirector();\n\t\tsourceLocator\n\t\t\t\t.setSourcePathComputer(DebugPlugin.getDefault().getLaunchManager()\n\t\t\t\t\t\t.getSourcePathComputer(\n\t\t\t\t\t\t\t\t\"org.eclipse.jdt.launching.sourceLookup.javaSourcePathComputer\")); //$NON-NLS-1$\n\t\tList<IRuntimeClasspathEntry> classpathEntries = new ArrayList<>();\n\t\t\n\t\t// TODO - only add the projects which are deployed as modules on the server\n\t\t// 1. add java projects first\n        for (IJavaProject javaProject : ProjectHelper.getAllJavaProjects()) {\n            classpathEntries.add(JavaRuntime.newProjectRuntimeClasspathEntry(javaProject));\n        }\n\t\t\n        // 2. add the other modules deployed on server\n        ProgressUtils.advance(monitor, 5); // 5/30\n        \n        SourceReferenceResolver resolver = Activator.getDefault().getSourceReferenceResolver();\n        if ( resolver != null ) {\n            try {\n                List<SourceReference> references = osgiClient.findSourceReferences();\n                SubMonitor subMonitor = SubMonitor.convert(monitor, \"Resolving source references\", 24).setWorkRemaining(references.size());\n                for ( SourceReference reference :  references ) {\n                    try {\n                        subMonitor.setTaskName(\"Resolving source reference: \" + reference);\n                        IRuntimeClasspathEntry classpathEntry = resolver.resolve(reference);\n                        if ( classpathEntry != null ) {\n                            classpathEntries.add(classpathEntry);\n                        }\n                        ProgressUtils.advance(subMonitor, 1);\n                        \n                    } catch (CoreException e) {\n                        // don't fail the debug launch for artifact resolution errors\n                        Activator.getDefault().getPluginLogger().warn(\"Failed resolving source reference\", e);\n                    }\n                }\n                subMonitor.done(); // 29/30\n            } catch (OsgiClientException e1) {\n                throw new CoreException(new Status(Status.ERROR, Activator.PLUGIN_ID, e1.getMessage(), e1));\n            }\n        }\n        \n        // 3. add the JRE entry\n\t\tclasspathEntries.add(JavaRuntime.computeJREEntry(launch.getLaunchConfiguration()));\n\t\t\n\t\tIRuntimeClasspathEntry[] resolved = JavaRuntime.resolveSourceLookupPath(classpathEntries.toArray(new IRuntimeClasspathEntry[0]), launch.getLaunchConfiguration());\n\t\t\n\t\tsourceLocator.setSourceContainers(JavaRuntime.getSourceContainers(resolved));\n\t\tsourceLocator.initializeParticipants();\n\t\tlaunch.setSourceLocator(sourceLocator);\n\n\t\t// connect to remote VM\n\t\ttry{\n\t\t\tconnector.connect(connectMap, monitor, launch); // 30/30\n\t\t\tsuccess = true;\n\t\t\t\n\t\t\tlong elapsedMillis = System.currentTimeMillis() - start;\n\t\t\tActivator.getDefault().getPluginLogger().tracePerformance(\"Debug connection to {0}\", elapsedMillis, iServer.getName());\n\t\t} catch(Exception e) {\n\t\t\tthrow new CoreException(new Status(IStatus.ERROR, \"org.apache.sling.ide.eclipse.wst\",\n\t\t            \"could not establish debug connection to \"+iServer.getHost()+\" : \"+debugPort, e));\n\t\t}\n\t\treturn success;\n\t}","commit_id":"621e1d2ae467dc4878b9e8a3ef345a0324022c0c","url":"https://github.com/apache/sling"},{"original_method":"private void installBundle(IProgressMonitor monitor, OsgiClient client, final EmbeddedArtifact bundle,\n            String bundleSymbolicName) throws OsgiClientException, IOException {\n        \n        Version remoteVersion = client.getBundleVersion(bundleSymbolicName);\n        \n        monitor.worked(7);\n        \n        final Version embeddedVersion = new Version(bundle.getOsgiFriendlyVersion());\n        \n        ISlingLaunchpadServer launchpadServer = (ISlingLaunchpadServer) getServer().loadAdapter(SlingLaunchpadServer.class,\n                monitor);\n        if (remoteVersion == null || remoteVersion.compareTo(embeddedVersion) < 0 \n                || ( remoteVersion.equals(embeddedVersion) || \"SNAPSHOT\".equals(embeddedVersion.getQualifier()))) {\n            try ( InputStream contents = bundle.openInputStream() ){\n                client.installBundle(contents, bundle.getName());\n            }\n            remoteVersion = embeddedVersion;\n\n        }\n        launchpadServer.setBundleVersion(bundleSymbolicName, remoteVersion,\n                monitor);\n        \n        monitor.worked(8);\n    }","id":36774,"modified_method":"private void installBundle(IProgressMonitor monitor, OsgiClient client, final EmbeddedArtifact bundle,\n            String bundleSymbolicName) throws OsgiClientException, IOException {\n\n        Version embeddedVersion = new Version(bundle.getOsgiFriendlyVersion());\n        \n        monitor.setTaskName(\"Installing \" + bundleSymbolicName + \" \" + embeddedVersion);\n\n        Version remoteVersion = client.getBundleVersion(bundleSymbolicName);\n        \n        monitor.worked(2);\n        \n        ISlingLaunchpadServer launchpadServer = (ISlingLaunchpadServer) getServer().loadAdapter(SlingLaunchpadServer.class,\n                monitor);\n        if (remoteVersion == null || remoteVersion.compareTo(embeddedVersion) < 0 \n                || ( remoteVersion.equals(embeddedVersion) || \"SNAPSHOT\".equals(embeddedVersion.getQualifier()))) {\n            try ( InputStream contents = bundle.openInputStream() ){\n                client.installBundle(contents, bundle.getName());\n            }\n            remoteVersion = embeddedVersion;\n\n        }\n        launchpadServer.setBundleVersion(bundleSymbolicName, remoteVersion,\n                monitor);\n        \n        monitor.worked(3);\n    }","commit_id":"621e1d2ae467dc4878b9e8a3ef345a0324022c0c","url":"https://github.com/apache/sling"},{"original_method":"public void start(IProgressMonitor monitor) throws CoreException {\n\n        boolean success = false;\n        Result<ResourceProxy> result = null;\n        monitor = SubMonitor.convert(monitor, \"Starting server\", 10).setWorkRemaining(50);\n        \n        Repository repository;\n        RepositoryInfo repositoryInfo;\n        OsgiClient client;\n        try {\n            repository = ServerUtil.connectRepository(getServer(), monitor);\n            repositoryInfo = ServerUtil.getRepositoryInfo(getServer(), monitor);\n            client = Activator.getDefault().getOsgiClientFactory().createOsgiClient(repositoryInfo);\n        } catch (CoreException e) {\n            setServerState(IServer.STATE_STOPPED);\n            throw e;\n        } catch (URISyntaxException e) {\n            setServerState(IServer.STATE_STOPPED);\n            throw new CoreException(new Status(IStatus.ERROR, Activator.PLUGIN_ID, e.getMessage(), e));\n        }\n\n        monitor.worked(10); // 10/50 done\n\n        try {\n            if (getServer().getMode().equals(ILaunchManager.DEBUG_MODE)) {\n                debuggerConnection = new JVMDebuggerConnection(client);\n                \n                success = debuggerConnection.connectInDebugMode(launch, getServer(), monitor);\n\n                monitor.worked(5); // 7/7 done\n\n            } else {\n                \n                Command<ResourceProxy> command = repository.newListChildrenNodeCommand(\"/\");\n                result = command.execute();\n                success = result.isSuccess();\n                \n                monitor.worked(10); // 20/50 done\n                \n                try {\n                    EmbeddedArtifactLocator artifactLocator = Activator.getDefault().getArtifactLocator();\n                    \n                    installBundle(monitor, client, artifactLocator.loadToolingSupportBundle(), \n                            EmbeddedArtifactLocator.SUPPORT_BUNDLE_SYMBOLIC_NAME); // 35/50 done\n                    installBundle(monitor, client, artifactLocator.loadSourceSupportBundle(), \n                            EmbeddedArtifactLocator.SUPPORT_SOURCE_BUNDLE_SYMBOLIC_NAME); // 50/50 done\n                    \n                } catch ( IOException | OsgiClientException e) {\n                    Activator.getDefault().getPluginLogger()\n                        .warn(\"Failed reading the installation support bundle\", e);\n                }\n            }\n\n            if (success) {\n                setServerState(IServer.STATE_STARTED);\n            } else {\n                setServerState(IServer.STATE_STOPPED);\n                String message = \"Unable to connect to the Server. Please make sure a server instance is running \";\n                if (result != null) {\n                    message += \" (\" + result.toString() + \")\";\n                }\n                throw new CoreException(new Status(IStatus.ERROR, Activator.PLUGIN_ID, message));\n            }\n        } catch ( CoreException | RuntimeException e ) {\n            setServerState(IServer.STATE_STOPPED);\n            throw e;\n        } finally {\n            monitor.done();\n        }\n    }","id":36775,"modified_method":"public void start(IProgressMonitor monitor) throws CoreException {\n\n        boolean success = false;\n        Result<ResourceProxy> result = null;\n        monitor = SubMonitor.convert(monitor, \"Starting server\", 10).setWorkRemaining(50);\n        \n        Repository repository;\n        RepositoryInfo repositoryInfo;\n        OsgiClient client;\n        try {\n            repository = ServerUtil.connectRepository(getServer(), monitor);\n            repositoryInfo = ServerUtil.getRepositoryInfo(getServer(), monitor);\n            client = Activator.getDefault().getOsgiClientFactory().createOsgiClient(repositoryInfo);\n        } catch (CoreException e) {\n            setServerState(IServer.STATE_STOPPED);\n            throw e;\n        } catch (URISyntaxException e) {\n            setServerState(IServer.STATE_STOPPED);\n            throw new CoreException(new Status(IStatus.ERROR, Activator.PLUGIN_ID, e.getMessage(), e));\n        }\n\n        monitor.worked(10); // 10/50 done\n        \n        try {\n            EmbeddedArtifactLocator artifactLocator = Activator.getDefault().getArtifactLocator();\n\n            installBundle(monitor,client, artifactLocator.loadSourceSupportBundle(), SUPPORT_SOURCE_BUNDLE_SYMBOLIC_NAME); // 15/50 done\n            installBundle(monitor,client, artifactLocator.loadToolingSupportBundle(), SUPPORT_BUNDLE_SYMBOLIC_NAME); // 20/50 done\n            \n        } catch ( IOException | OsgiClientException e) {\n            Activator.getDefault().getPluginLogger()\n                .warn(\"Failed reading the installation support bundle\", e);\n        }\n        \n        try {\n            if (getServer().getMode().equals(ILaunchManager.DEBUG_MODE)) {\n                debuggerConnection = new JVMDebuggerConnection(client);\n                \n                success = debuggerConnection.connectInDebugMode(launch, getServer(), SubMonitor.convert(monitor, 30));\n\n                // 50/50 done\n\n            } else {\n                \n                Command<ResourceProxy> command = repository.newListChildrenNodeCommand(\"/\");\n                result = command.execute();\n                success = result.isSuccess();\n                \n                monitor.worked(30); // 50/50 done\n                \n            }\n\n            if (success) {\n                setServerState(IServer.STATE_STARTED);\n            } else {\n                setServerState(IServer.STATE_STOPPED);\n                String message = \"Unable to connect to the Server. Please make sure a server instance is running \";\n                if (result != null) {\n                    message += \" (\" + result.toString() + \")\";\n                }\n                throw new CoreException(new Status(IStatus.ERROR, Activator.PLUGIN_ID, message));\n            }\n        } catch ( CoreException | RuntimeException e ) {\n            setServerState(IServer.STATE_STOPPED);\n            throw e;\n        } finally {\n            monitor.done();\n        }\n    }","commit_id":"621e1d2ae467dc4878b9e8a3ef345a0324022c0c","url":"https://github.com/apache/sling"},{"original_method":"public void process(Reader input) throws Exception {\n        final CrankstartParserImpl parser = new CrankstartParserImpl() {\n            @Override\n            protected String getVariable(String name) {\n                String result = System.getProperty(name);\n                if(result == null) {\n                    result = defaults.get(name);\n                }\n                if(result == null) {\n                    result = super.getVariable(name); \n                }\n                if(result != null) {\n                    result = result.trim();\n                }\n                return result;\n            }\n        };\n        final Iterator<CrankstartCommandLine> it = parser.parse(input);\n        while(it.hasNext()) {\n            final CrankstartCommandLine cmdLine = it.next();\n            \n            // First try the built-in commands\n            // If no command found try existing extension commands\n            // If no command found reload extension commands and try them again\n            // If no command found fail\n            if(execute(cmdLine, builtinCommands) == 0) {\n                if(execute(cmdLine, extensionCommands) == 0) {\n                    reloadExtensionCommands();\n                    if(execute(cmdLine, extensionCommands) == 0) {\n                        throw new CrankstartException(\n                                \"Invalid command '\" + cmdLine.getVerb()\n                                + \"', built-in commands:\" + getDescriptions(builtinCommands)\n                                + \", extension commands: \" + getDescriptions(extensionCommands)\n                                );\n                    }\n                }\n            }\n            \n        }\n    }","id":36776,"modified_method":"public void process(Reader input) throws Exception {\n        final CrankstartParserImpl parser = new CrankstartParserImpl() {\n            @Override\n            protected String getVariable(String name) {\n                String result = System.getProperty(name);\n                if(result == null) {\n                    result = crankstartContext.getDefaults().get(name);\n                }\n                if(result == null) {\n                    result = super.getVariable(name); \n                }\n                if(result != null) {\n                    result = result.trim();\n                }\n                return result;\n            }\n        };\n        final Iterator<CrankstartCommandLine> it = parser.parse(input);\n        while(it.hasNext()) {\n            final CrankstartCommandLine cmdLine = it.next();\n            \n            // First try the built-in commands\n            // If no command found try existing extension commands\n            // If no command found reload extension commands and try them again\n            // If no command found fail\n            if(execute(cmdLine, builtinCommands) == 0) {\n                if(execute(cmdLine, extensionCommands) == 0) {\n                    reloadExtensionCommands();\n                    if(execute(cmdLine, extensionCommands) == 0) {\n                        throw new CrankstartException(\n                                \"Invalid command '\" + cmdLine.getVerb()\n                                + \"', built-in commands:\" + getDescriptions(builtinCommands)\n                                + \", extension commands: \" + getDescriptions(extensionCommands)\n                                );\n                    }\n                }\n            }\n            \n        }\n    }","commit_id":"d83bdd576178cef1eecffb0013a058fa3e6d8b96","url":"https://github.com/apache/sling"},{"original_method":"public CrankstartFileProcessor(CrankstartContext ctx) {\n        this.crankstartContext = ctx;\n        builtinCommands.add(new InstallBundle());\n        builtinCommands.add(new Log());\n        builtinCommands.add(new SetOsgiFrameworkProperty());\n        builtinCommands.add(new StartBundles());\n        builtinCommands.add(new StartFramework());\n        builtinCommands.add(new Configure());\n        builtinCommands.add(new Defaults(defaults));\n        \n        // Need a null \"classpath\" command as our launcher uses it\n        // outside of the usual command mechanism - it shouldn't cause\n        // an error in the normal processing\n        builtinCommands.add(new NullCommand(\"classpath\", \"set the classpath used by the Crankstart launcher\"));\n        \n        log.info(\"{} ready, built-in commands: {}\", getClass().getSimpleName(), getDescriptions(builtinCommands));\n    }","id":36777,"modified_method":"public CrankstartFileProcessor(CrankstartContext ctx) {\n        this.crankstartContext = ctx;\n        builtinCommands.add(new InstallBundle());\n        builtinCommands.add(new Log());\n        builtinCommands.add(new SetOsgiFrameworkProperty());\n        builtinCommands.add(new StartBundles());\n        builtinCommands.add(new StartFramework());\n        builtinCommands.add(new Configure());\n        builtinCommands.add(new Defaults());\n        \n        // Need a null \"classpath\" command as our launcher uses it\n        // outside of the usual command mechanism - it shouldn't cause\n        // an error in the normal processing\n        builtinCommands.add(new NullCommand(\"classpath\", \"set the classpath used by the Crankstart launcher\"));\n        \n        log.info(\"{} ready, built-in commands: {}\", getClass().getSimpleName(), getDescriptions(builtinCommands));\n    }","commit_id":"d83bdd576178cef1eecffb0013a058fa3e6d8b96","url":"https://github.com/apache/sling"},{"original_method":"@Override\n    public void execute(CrankstartContext crankstartContext, CrankstartCommandLine commandLine) throws Exception {\n        final String [] parts = commandLine.getQualifier().split(\" \");\n        final String key = parts[0];\n        final StringBuilder sb = new StringBuilder();\n        for(int i=1 ; i < parts.length; i++) {\n            if(sb.length() > 0) {\n                sb.append(' ');\n            }\n            sb.append(parts[i]);\n        }\n        final String value = sb.toString();\n        variables.put(key, value);\n        log.info(\"[{}] has default value [{}]\", key, value);\n    }","id":36778,"modified_method":"@Override\n    public void execute(CrankstartContext crankstartContext, CrankstartCommandLine commandLine) throws Exception {\n        final String [] parts = commandLine.getQualifier().split(\" \");\n        final String key = parts[0];\n        final StringBuilder sb = new StringBuilder();\n        for(int i=1 ; i < parts.length; i++) {\n            if(sb.length() > 0) {\n                sb.append(' ');\n            }\n            sb.append(parts[i]);\n        }\n        final String value = sb.toString();\n        crankstartContext.getDefaults().put(key, value);\n        log.info(\"[{}] has default value [{}]\", key, value);\n    }","commit_id":"d83bdd576178cef1eecffb0013a058fa3e6d8b96","url":"https://github.com/apache/sling"},{"original_method":"@Override\n    public void execute(CrankstartContext crankstartContext, CrankstartCommandLine commandLine) throws Exception {\n        final String bundleRef = commandLine.getQualifier();\n        final URL url = new URL(bundleRef);\n        final BundleContext ctx = crankstartContext.getOsgiFramework().getBundleContext();\n        final InputStream bundleStream = url.openStream();\n        try {\n            ctx.installBundle(bundleRef, url.openStream());\n            log.info(\"bundle installed: {}\", bundleRef);\n        } finally {\n            bundleStream.close();\n        }\n    }","id":36779,"modified_method":"@Override\n    public void execute(CrankstartContext crankstartContext, CrankstartCommandLine commandLine) throws Exception {\n        final String bundleRef = commandLine.getQualifier();\n        final URL url = new URL(bundleRef);\n        final BundleContext ctx = crankstartContext.getOsgiFramework().getBundleContext();\n        final InputStream bundleStream = url.openStream();\n        try {\n            final Bundle b = ctx.installBundle(bundleRef, url.openStream());\n            \n            final int level = getStartLevel(crankstartContext);\n            if(level > 0) {\n                final BundleStartLevel bsl = (BundleStartLevel)b.adapt(BundleStartLevel.class);\n                if(bsl == null) {\n                    log.warn(\"Bundle does not adapt to BundleStartLevel, cannot set start level\", bundleRef);\n                }\n                bsl.setStartLevel(level);\n            }\n            \n            log.info(\"bundle installed at start level {}: {}\", level, bundleRef);\n        } finally {\n            bundleStream.close();\n        }\n    }","commit_id":"d83bdd576178cef1eecffb0013a058fa3e6d8b96","url":"https://github.com/apache/sling"},{"original_method":"public <T extends GrMembersDeclaration> T addMemberDeclaration(@NotNull T decl, PsiElement anchorBefore)\n    throws IncorrectOperationException {\n\n    if (anchorBefore == null) {\n      return (T)add(decl);\n    }\n\n    GrTypeDefinitionBody body = getBody();\n    if (body == null) throw new IncorrectOperationException(\"Type definition without a body\");\n//    ASTNode anchorNode;\n//    anchorNode = anchorBefore.getNode();\n//    ASTNode bodyNode = body.getNode();\n    decl = (T)body.addBefore(decl, anchorBefore);\n//    bodyNode.addLeaf(GroovyTokenTypes.mWS, \" \", decl.getNode()); //add whitespaces before and after to hack over incorrect auto reformat\n//    bodyNode.addLeaf(GroovyTokenTypes.mWS, \" \", anchorNode);\n    return decl;\n  }","id":36780,"modified_method":"public <T extends GrMembersDeclaration> T addMemberDeclaration(@NotNull T decl, PsiElement anchorBefore)\n    throws IncorrectOperationException {\n\n    if (anchorBefore == null) {\n      return (T)add(decl);\n    }\n\n    GrTypeDefinitionBody body = getBody();\n    if (body == null) throw new IncorrectOperationException(\"Type definition without a body\");\n    return  (T)body.addBefore(decl, anchorBefore);\n  }","commit_id":"aeb479595af82a46a09f4737975e7637b4ab3349","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiElement addAfter(@NotNull PsiElement element, PsiElement anchor) throws IncorrectOperationException {\n    if (anchor == null) {\n      return add(element);\n    }\n    final GrTypeDefinitionBody body = getBody();\n    if (anchor.getParent() == body) {\n\n      final PsiElement nextChild = anchor.getNextSibling();\n      if (nextChild == null) {\n        add(element);\n        return element;\n      }\n\n      return body.addBefore(element, nextChild);\n    }\n    else {\n      return super.addAfter(element, anchor);\n    }\n  }","id":36781,"modified_method":"public PsiElement addAfter(@NotNull PsiElement element, PsiElement anchor) throws IncorrectOperationException {\n    if (anchor == null) {\n      return add(element);\n    }\n    final GrTypeDefinitionBody body = getBody();\n    if (anchor.getParent() == body) {\n\n      final PsiElement nextChild = anchor.getNextSibling();\n      if (nextChild == null) {\n        add(element);\n        return element;\n      }\n\n      if (body == null) throw new IncorrectOperationException(\"Class must have body\");\n      return body.addBefore(element, nextChild);\n    }\n    else {\n      return super.addAfter(element, anchor);\n    }\n  }","commit_id":"aeb479595af82a46a09f4737975e7637b4ab3349","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiElement addBefore(@NotNull PsiElement element, PsiElement anchor) throws IncorrectOperationException {\n    if (anchor == null) {\n      add(element);\n      return element;\n    }\n\n    final GrTypeDefinitionBody body = getBody();\n    if (anchor.getParent() != body) {\n      return super.addBefore(element, anchor);\n    }\n\n    return body.addBefore(element, anchor);\n  }","id":36782,"modified_method":"public PsiElement addBefore(@NotNull PsiElement element, PsiElement anchor) throws IncorrectOperationException {\n    if (anchor == null) {\n      add(element);\n      return element;\n    }\n\n    final GrTypeDefinitionBody body = getBody();\n    if (anchor.getParent() != body) {\n      return super.addBefore(element, anchor);\n    }\n\n    if (body == null) throw new IncorrectOperationException(\"Class must have body\");\n    return body.addBefore(element, anchor);\n  }","commit_id":"aeb479595af82a46a09f4737975e7637b4ab3349","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void insert(PsiClass aClass, PsiElement anchor, boolean before) throws IncorrectOperationException {\n    super.insert(aClass, anchor, before);\n    final T member = getPsiMember();\n    if (member != null) {\n      assert member instanceof GroovyPsiElement;\n      GrReferenceAdjuster.shortenReferences(member);\n    }\n  }","id":36783,"modified_method":"@Override\n  public void insert(PsiClass aClass, PsiElement anchor, boolean before) throws IncorrectOperationException {\n    super.insert(aClass, anchor, before);\n\n    final T member = getPsiMember();\n    if (member == null) return;\n\n    LOG.assertTrue(member instanceof GroovyPsiElement);\n    final GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(member.getProject());\n\n    final PsiElement prev = member.getPrevSibling();\n    if (prev!=null && GroovyTokenTypes.mNLS == prev.getNode().getElementType()) {\n      prev.replace(factory.createLineTerminator(1));\n    }\n\n    final PsiElement next = member.getNextSibling();\n    if (next != null && GroovyTokenTypes.mNLS == next.getNode().getElementType()) {\n      next.replace(factory.createLineTerminator(1));\n    }\n\n    GrReferenceAdjuster.shortenReferences(member);\n  }","commit_id":"aeb479595af82a46a09f4737975e7637b4ab3349","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void processExternalUsage(UsageInfo usage, GrIntroduceParameterSettings settings, PsiElement expression) {\n    final PsiElement element = usage.getElement();\n    GrCall callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(element);\n    if (callExpression == null) {\n      final PsiElement parent = element.getParent();\n      if (parent instanceof GrReferenceExpression && element == ((GrReferenceExpression)parent).getQualifier() && \"call\".equals(\n        ((GrReferenceExpression)parent).getReferenceName())) {\n        callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(parent);\n      }\n    }\n    \n    if (callExpression == null) return;\n      \n      \n    //LOG.assertTrue(callExpression != null);\n\n    //check for x.getFoo()(args)\n    if (callExpression instanceof GrMethodCall) {\n      final GrExpression invoked = ((GrMethodCall)callExpression).getInvokedExpression();\n      if (invoked instanceof GrReferenceExpression) {\n        final GroovyResolveResult result = ((GrReferenceExpression)invoked).advancedResolve();\n        final PsiElement resolved = result.getElement();\n        if (resolved instanceof GrAccessorMethod && !result.isInvokedOnProperty()) {\n          PsiElement actualCallExpression = callExpression.getParent();\n          if (actualCallExpression instanceof GrCall) {\n            callExpression = (GrCall)actualCallExpression;\n          }\n        }\n      }\n    }\n    \n    GrArgumentList argList = callExpression.getArgumentList();\n    LOG.assertTrue(argList != null);\n    GrExpression[] oldArgs = argList.getExpressionArguments();\n\n    GrClosableBlock toReplaceIn = (GrClosableBlock)settings.getToReplaceIn();\n    GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(settings.getProject());\n\n    final GrExpression anchor = getAnchorForArgument(oldArgs, toReplaceIn.isVarArgs(), toReplaceIn.getParameterList());\n\n    GrClosureSignature signature = GrClosureSignatureUtil.createSignature(callExpression);\n    if (signature == null) signature = GrClosureSignatureUtil.createSignature(toReplaceIn);\n\n    final GrClosureSignatureUtil.ArgInfo<PsiElement>[] actualArgs =\n      GrClosureSignatureUtil.mapParametersToArguments(signature, argList, callExpression, callExpression.getClosureArguments(), true);\n\n    if (PsiTreeUtil.isAncestor(toReplaceIn, callExpression, false)) {\n      argList.addAfter(factory.createExpressionFromText(settings.getName()), anchor);\n    }\n    else {\n      PsiElement initializer = ExpressionConverter.getExpression(expression, GroovyFileType.GROOVY_LANGUAGE, settings.getProject());\n      LOG.assertTrue(initializer instanceof GrExpression);\n\n      GrExpression newArg = GroovyIntroduceParameterUtil.addClosureToCall(initializer, argList);\n      if (newArg == null) {\n        final PsiElement dummy = argList.addAfter(factory.createExpressionFromText(\"1\"), anchor);\n        newArg = ((GrExpression)dummy).replaceWithExpression((GrExpression)initializer, true);\n      }\n      new OldReferencesResolver(callExpression, newArg, toReplaceIn, settings.replaceFieldsWithGetters(), initializer, signature,\n                                actualArgs, toReplaceIn.getParameters()).resolve();\n      ChangeContextUtil.clearContextInfo(initializer);\n      GrReferenceAdjuster.shortenReferences(newArg);\n    }\n\n    if (actualArgs == null) {\n      GroovyIntroduceParameterUtil\n        .removeParamsFromUnresolvedCall(callExpression, toReplaceIn.getParameters(), settings.parametersToRemove());\n    }\n    else {\n      GroovyIntroduceParameterUtil.removeParametersFromCall(actualArgs, settings.parametersToRemove());\n    }\n\n    if (argList.getAllArguments().length == 0 && hasClosureArgs(argList)) {\n      final GrArgumentList emptyArgList = ((GrMethodCallExpression)factory.createExpressionFromText(\"foo{}\")).getArgumentList();\n      LOG.assertTrue(emptyArgList != null);\n      argList.replace(emptyArgList);\n    }\n\n  }","id":36784,"modified_method":"private static void processExternalUsage(UsageInfo usage, GrIntroduceParameterSettings settings, PsiElement expression) {\n    final PsiElement element = usage.getElement();\n    GrCall callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(element);\n    if (callExpression == null) {\n      final PsiElement parent = element.getParent();\n      if (parent instanceof GrReferenceExpression && element == ((GrReferenceExpression)parent).getQualifier() && \"call\".equals(\n        ((GrReferenceExpression)parent).getReferenceName())) {\n        callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(parent);\n      }\n    }\n    \n    if (callExpression == null) return;\n      \n      \n    //LOG.assertTrue(callExpression != null);\n\n    //check for x.getFoo()(args)\n    if (callExpression instanceof GrMethodCall) {\n      final GrExpression invoked = ((GrMethodCall)callExpression).getInvokedExpression();\n      if (invoked instanceof GrReferenceExpression) {\n        final GroovyResolveResult result = ((GrReferenceExpression)invoked).advancedResolve();\n        final PsiElement resolved = result.getElement();\n        if (resolved instanceof GrAccessorMethod && !result.isInvokedOnProperty()) {\n          PsiElement actualCallExpression = callExpression.getParent();\n          if (actualCallExpression instanceof GrCall) {\n            callExpression = (GrCall)actualCallExpression;\n          }\n        }\n      }\n    }\n    \n    GrArgumentList argList = callExpression.getArgumentList();\n    LOG.assertTrue(argList != null);\n    GrExpression[] oldArgs = argList.getExpressionArguments();\n\n    GrClosableBlock toReplaceIn = (GrClosableBlock)settings.getToReplaceIn();\n    GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(settings.getProject());\n\n    final GrExpression anchor = getAnchorForArgument(oldArgs, toReplaceIn.isVarArgs(), toReplaceIn.getParameterList());\n\n    GrClosureSignature signature = GrClosureSignatureUtil.createSignature(callExpression);\n    if (signature == null) signature = GrClosureSignatureUtil.createSignature(toReplaceIn);\n\n    final GrClosureSignatureUtil.ArgInfo<PsiElement>[] actualArgs =\n      GrClosureSignatureUtil.mapParametersToArguments(signature, argList, callExpression, callExpression.getClosureArguments(), true);\n\n    if (PsiTreeUtil.isAncestor(toReplaceIn, callExpression, false)) {\n      argList.addAfter(factory.createExpressionFromText(settings.getName()), anchor);\n    }\n    else {\n      PsiElement initializer = ExpressionConverter.getExpression(expression, GroovyFileType.GROOVY_LANGUAGE, settings.getProject());\n      LOG.assertTrue(initializer instanceof GrExpression);\n\n      GrExpression newArg = GroovyIntroduceParameterUtil.addClosureToCall(initializer, argList);\n      if (newArg == null) {\n        final PsiElement dummy = argList.addAfter(factory.createExpressionFromText(\"1\"), anchor);\n        newArg = ((GrExpression)dummy).replaceWithExpression((GrExpression)initializer, true);\n      }\n      new OldReferencesResolver(callExpression, newArg, toReplaceIn, settings.replaceFieldsWithGetters(), initializer, signature,\n                                actualArgs, toReplaceIn.getParameters()).resolve();\n      ChangeContextUtil.clearContextInfo(initializer);\n\n      //newarg can be replaced by OldReferenceResolve\n      if (newArg.isValid()) {\n        GrReferenceAdjuster.shortenReferences(newArg);\n        CodeStyleManager.getInstance(settings.getProject()).reformat(newArg);\n      }\n    }\n\n    if (actualArgs == null) {\n      GroovyIntroduceParameterUtil\n        .removeParamsFromUnresolvedCall(callExpression, toReplaceIn.getParameters(), settings.parametersToRemove());\n    }\n    else {\n      GroovyIntroduceParameterUtil.removeParametersFromCall(actualArgs, settings.parametersToRemove());\n    }\n\n    if (argList.getAllArguments().length == 0 && hasClosureArgs(argList)) {\n      final GrArgumentList emptyArgList = ((GrMethodCallExpression)factory.createExpressionFromText(\"foo{}\")).getArgumentList();\n      LOG.assertTrue(emptyArgList != null);\n      argList.replace(emptyArgList);\n    }\n\n  }","commit_id":"d880505e5e5a24a8b7b2756bb7580604af403f9f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean processChangeMethodUsage(IntroduceParameterData data, UsageInfo usage, UsageInfo[] usages) throws IncorrectOperationException {\n    GrCall callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(usage.getElement());\n    if (callExpression == null) return true;\n    GrArgumentList argList = callExpression.getArgumentList();\n    GrExpression[] oldArgs = argList.getExpressionArguments();\n\n    final GrExpression anchor;\n    if (!data.getMethodToSearchFor().isVarArgs()) {\n      anchor = getLast(oldArgs);\n    }\n    else {\n      final PsiParameter[] parameters = data.getMethodToSearchFor().getParameterList().getParameters();\n      if (parameters.length > oldArgs.length) {\n        anchor = getLast(oldArgs);\n      }\n      else {\n        final int lastNonVararg = parameters.length - 2;\n        anchor = lastNonVararg >= 0 ? oldArgs[lastNonVararg] : null;\n      }\n    }\n\n    PsiMethod method = PsiTreeUtil.getParentOfType(argList, PsiMethod.class);\n\n    GrClosureSignature signature = GrClosureSignatureUtil.createSignature(callExpression);\n    if (signature == null) signature = GrClosureSignatureUtil.createSignature(data.getMethodToSearchFor(), PsiSubstitutor.EMPTY);\n\n    final GrClosureSignatureUtil.ArgInfo<PsiElement>[] actualArgs =\n      GrClosureSignatureUtil.mapParametersToArguments(signature, argList, callExpression, callExpression.getClosureArguments(), true);\n\n    final GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(data.getProject());\n\n    if (method != null && IntroduceParameterUtil.isMethodInUsages(data, method, usages)) {\n      argList.addAfter(factory.createExpressionFromText(data.getParameterName()), anchor);\n    }\n    else {\n      final PsiElement _expr = data.getParameterInitializer().getExpression();\n      PsiElement initializer = ExpressionConverter.getExpression(_expr, GroovyFileType.GROOVY_LANGUAGE, data.getProject());\n      LOG.assertTrue(initializer instanceof GrExpression);\n\n      GrExpression newArg = GroovyIntroduceParameterUtil.addClosureToCall(initializer, argList);\n      if (newArg == null) {\n        final PsiElement dummy = argList.addAfter(factory.createExpressionFromText(\"1\"), anchor);\n        newArg = ((GrExpression)dummy).replaceWithExpression((GrExpression)initializer, true);\n      }\n      final PsiMethod methodToReplaceIn = data.getMethodToReplaceIn();\n      new OldReferencesResolver(callExpression, newArg, methodToReplaceIn, data.getReplaceFieldsWithGetters(), initializer,\n                                signature, actualArgs, methodToReplaceIn.getParameterList().getParameters()).resolve();\n      ChangeContextUtil.clearContextInfo(initializer);\n      GrReferenceAdjuster.shortenReferences(newArg);\n    }\n\n    if (actualArgs == null) {\n      removeParamsFromUnresolvedCall(callExpression, data);\n    }\n    else {\n      removeParametersFromCall(actualArgs, data.getParametersToRemove());\n    }\n\n    if (argList.getAllArguments().length == 0 && hasClosureArgs(argList)) {\n      final GrArgumentList emptyArgList = ((GrMethodCallExpression)factory.createExpressionFromText(\"foo{}\")).getArgumentList();\n      LOG.assertTrue(emptyArgList != null);\n      argList.replace(emptyArgList);\n    }\n    return false;\n  }","id":36785,"modified_method":"public boolean processChangeMethodUsage(IntroduceParameterData data, UsageInfo usage, UsageInfo[] usages) throws IncorrectOperationException {\n    GrCall callExpression = GroovyRefactoringUtil.getCallExpressionByMethodReference(usage.getElement());\n    if (callExpression == null) return true;\n    GrArgumentList argList = callExpression.getArgumentList();\n    GrExpression[] oldArgs = argList.getExpressionArguments();\n\n    final GrExpression anchor;\n    if (!data.getMethodToSearchFor().isVarArgs()) {\n      anchor = getLast(oldArgs);\n    }\n    else {\n      final PsiParameter[] parameters = data.getMethodToSearchFor().getParameterList().getParameters();\n      if (parameters.length > oldArgs.length) {\n        anchor = getLast(oldArgs);\n      }\n      else {\n        final int lastNonVararg = parameters.length - 2;\n        anchor = lastNonVararg >= 0 ? oldArgs[lastNonVararg] : null;\n      }\n    }\n\n    PsiMethod method = PsiTreeUtil.getParentOfType(argList, PsiMethod.class);\n\n    GrClosureSignature signature = GrClosureSignatureUtil.createSignature(callExpression);\n    if (signature == null) signature = GrClosureSignatureUtil.createSignature(data.getMethodToSearchFor(), PsiSubstitutor.EMPTY);\n\n    final GrClosureSignatureUtil.ArgInfo<PsiElement>[] actualArgs =\n      GrClosureSignatureUtil.mapParametersToArguments(signature, argList, callExpression, callExpression.getClosureArguments(), true);\n\n    final GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(data.getProject());\n\n    if (method != null && IntroduceParameterUtil.isMethodInUsages(data, method, usages)) {\n      argList.addAfter(factory.createExpressionFromText(data.getParameterName()), anchor);\n    }\n    else {\n      final PsiElement _expr = data.getParameterInitializer().getExpression();\n      PsiElement initializer = ExpressionConverter.getExpression(_expr, GroovyFileType.GROOVY_LANGUAGE, data.getProject());\n      LOG.assertTrue(initializer instanceof GrExpression);\n\n      GrExpression newArg = GroovyIntroduceParameterUtil.addClosureToCall(initializer, argList);\n      if (newArg == null) {\n        final PsiElement dummy = argList.addAfter(factory.createExpressionFromText(\"1\"), anchor);\n        newArg = ((GrExpression)dummy).replaceWithExpression((GrExpression)initializer, true);\n      }\n      final PsiMethod methodToReplaceIn = data.getMethodToReplaceIn();\n      new OldReferencesResolver(callExpression, newArg, methodToReplaceIn, data.getReplaceFieldsWithGetters(), initializer,\n                                signature, actualArgs, methodToReplaceIn.getParameterList().getParameters()).resolve();\n      ChangeContextUtil.clearContextInfo(initializer);\n\n      //newArg can be replaced by OldReferenceResolver\n      if (newArg.isValid()) {\n        GrReferenceAdjuster.shortenReferences(newArg);\n        CodeStyleManager.getInstance(data.getProject()).reformat(newArg);\n      }\n    }\n\n    if (actualArgs == null) {\n      removeParamsFromUnresolvedCall(callExpression, data);\n    }\n    else {\n      removeParametersFromCall(actualArgs, data.getParametersToRemove());\n    }\n\n    if (argList.getAllArguments().length == 0 && hasClosureArgs(argList)) {\n      final GrArgumentList emptyArgList = ((GrMethodCallExpression)factory.createExpressionFromText(\"foo{}\")).getArgumentList();\n      LOG.assertTrue(emptyArgList != null);\n      argList.replace(emptyArgList);\n    }\n    return false;\n  }","commit_id":"d880505e5e5a24a8b7b2756bb7580604af403f9f","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n    public void testDeleteAliases() throws Exception {\n\n        logger.info(\"--> creating index [test1]\");\n        admin().indices().create(createIndexRequest(\"test1\")).actionGet();\n\n        logger.info(\"--> creating index [test2]\");\n        admin().indices().create(createIndexRequest(\"test2\")).actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"tests\", termFilter(\"name\", \"test\")).execute().actionGet();\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"tests\", termFilter(\"name\", \"test\")).execute().actionGet();\n        \n        String[] indices = {\"test1\", \"test2\"}; \n        String[] aliases = {\"aliasToTest1\", \"foos\", \"bars\", \"tests\", \"aliasToTest2\", \"aliasToTests\"};\n        \n        admin().indices().prepareAliases().removeAlias(indices, aliases).execute().actionGet();\n        \n        AliasesExistResponse response = admin().indices().prepareAliasesExist(aliases).execute().actionGet();\n        assertThat(response.exists(), equalTo(false));\n\n    }","id":36786,"modified_method":"@Test\n    public void testDeleteAliases() throws Exception {\n        logger.info(\"--> creating index [test1] and [test2]\");\n        createIndex(\"test1\", \"test2\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\")\n                .addAlias(\"test1\", \"aliasToTests\")\n                .addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\"))\n                .addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\"))\n                .addAlias(\"test1\", \"tests\", termFilter(\"name\", \"test\")));\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\")\n                .addAlias(\"test2\", \"aliasToTests\")\n                .addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\"))\n                .addAlias(\"test2\", \"tests\", termFilter(\"name\", \"test\")));\n        \n        String[] indices = {\"test1\", \"test2\"}; \n        String[] aliases = {\"aliasToTest1\", \"foos\", \"bars\", \"tests\", \"aliasToTest2\", \"aliasToTests\"};\n        \n        admin().indices().prepareAliases().removeAlias(indices, aliases).get();\n        \n        AliasesExistResponse response = admin().indices().prepareAliasesExist(aliases).get();\n        assertThat(response.exists(), equalTo(false));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testRemoveAliasEmptyAliasEmptyIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"\"))\n                    .execute().actionGet();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","id":36787,"modified_method":"@Test\n    public void testRemoveAliasEmptyAliasEmptyIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"\")).get();\n            fail(\"Should throw \" + ActionRequestValidationException.class.getSimpleName());\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testRemoveAliasNullAliasNullIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(null, null))\n                    .execute().actionGet();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","id":36788,"modified_method":"@Test\n    public void testRemoveAliasNullAliasNullIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(null, null)).get();\n            fail(\"Should throw \" + ActionRequestValidationException.class.getSimpleName());\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testFilteringAliases() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> aliasing index [test] with [alias1] and filter [user:kimchy]\");\n        FilterBuilder filter = termFilter(\"user\", \"kimchy\");\n        admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", filter).execute().actionGet();\n\n        // For now just making sure that filter was stored with the alias\n        logger.info(\"--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]\");\n        ClusterState clusterState = admin().cluster().prepareState().execute().actionGet().getState();\n        IndexMetaData indexMd = clusterState.metaData().index(\"test\");\n        assertThat(indexMd.aliases().get(\"alias1\").filter().string(), equalTo(\"{\\\"term\\\":{\\\"user\\\":\\\"kimchy\\\"}}\"));\n\n    }","id":36789,"modified_method":"@Test\n    public void testFilteringAliases() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> aliasing index [test] with [alias1] and filter [user:kimchy]\");\n        FilterBuilder filter = termFilter(\"user\", \"kimchy\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", filter));\n\n        // For now just making sure that filter was stored with the alias\n        logger.info(\"--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]\");\n        ClusterState clusterState = admin().cluster().prepareState().get().getState();\n        IndexMetaData indexMd = clusterState.metaData().index(\"test\");\n        assertThat(indexMd.aliases().get(\"alias1\").filter().string(), equalTo(\"{\\\"term\\\":{\\\"user\\\":\\\"kimchy\\\"}}\"));\n\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSameAlias() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> creating alias1 \");\n        assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\").execute().actionGet().isAcknowledged(), equalTo(true));\n        TimeValue timeout = TimeValue.timeValueSeconds(2);\n        logger.info(\"--> recreating alias1 \");\n        StopWatch stopWatch = new StopWatch();\n        stopWatch.start();\n        assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\").setTimeout(timeout).execute().actionGet().isAcknowledged(), equalTo(true));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> modifying alias1 to have a filter\");\n        stopWatch.start();\n        assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"foo\")).setTimeout(timeout).execute().actionGet().isAcknowledged(), equalTo(true));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> recreating alias1 with the same filter\");\n        stopWatch.start();\n        assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"foo\")).setTimeout(timeout).execute().actionGet().isAcknowledged(), equalTo(true));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> recreating alias1 with a different filter\");\n        stopWatch.start();\n        assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"bar\")).setTimeout(timeout).execute().actionGet().isAcknowledged(), equalTo(true));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> verify that filter was updated\");\n        AliasMetaData aliasMetaData = cluster().clusterService().state().metaData().aliases().get(\"alias1\").get(\"test\");\n        assertThat(aliasMetaData.getFilter().toString(), equalTo(\"{\\\"term\\\":{\\\"name\\\":\\\"bar\\\"}}\"));\n\n        logger.info(\"--> deleting alias1\");\n        stopWatch.start();\n        assertThat(admin().indices().prepareAliases().removeAlias(\"test\", \"alias1\").setTimeout(timeout).execute().actionGet().isAcknowledged(), equalTo(true));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        \n    }","id":36790,"modified_method":"@Test\n    public void testSameAlias() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> creating alias1 \");\n        assertAcked((admin().indices().prepareAliases().addAlias(\"test\", \"alias1\")));\n        TimeValue timeout = TimeValue.timeValueSeconds(2);\n        logger.info(\"--> recreating alias1 \");\n        StopWatch stopWatch = new StopWatch();\n        stopWatch.start();\n        assertAcked((admin().indices().prepareAliases().addAlias(\"test\", \"alias1\").setTimeout(timeout)));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> modifying alias1 to have a filter\");\n        stopWatch.start();\n        assertAcked((admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"foo\")).setTimeout(timeout)));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> recreating alias1 with the same filter\");\n        stopWatch.start();\n        assertAcked((admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"foo\")).setTimeout(timeout)));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> recreating alias1 with a different filter\");\n        stopWatch.start();\n        assertAcked((admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", termFilter(\"name\", \"bar\")).setTimeout(timeout)));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        logger.info(\"--> verify that filter was updated\");\n        AliasMetaData aliasMetaData = cluster().clusterService().state().metaData().aliases().get(\"alias1\").get(\"test\");\n        assertThat(aliasMetaData.getFilter().toString(), equalTo(\"{\\\"term\\\":{\\\"name\\\":\\\"bar\\\"}}\"));\n\n        logger.info(\"--> deleting alias1\");\n        stopWatch.start();\n        assertAcked((admin().indices().prepareAliases().removeAlias(\"test\", \"alias1\").setTimeout(timeout)));\n        assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));\n\n        \n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testGetAllAliasesWorks() {\n        createIndex(\"index1\");\n        createIndex(\"index2\");\n\n        ensureYellow();\n\n        admin().indices().prepareAliases().addAlias(\"index1\", \"alias1\").addAlias(\"index2\", \"alias2\").get();\n\n        GetAliasesResponse response = admin().indices().prepareGetAliases().get();\n        assertThat(response.getAliases(), hasKey(\"index1\"));\n        assertThat(response.getAliases(), hasKey(\"index1\"));\n    }","id":36791,"modified_method":"@Test\n    public void testGetAllAliasesWorks() {\n        createIndex(\"index1\");\n        createIndex(\"index2\");\n\n        ensureYellow();\n\n        assertAcked(admin().indices().prepareAliases().addAlias(\"index1\", \"alias1\").addAlias(\"index2\", \"alias2\"));\n\n        GetAliasesResponse response = admin().indices().prepareGetAliases().get();\n        assertThat(response.getAliases(), hasKey(\"index1\"));\n        assertThat(response.getAliases(), hasKey(\"index1\"));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasNullAlias() {\n\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"index1\", null))\n                .execute().actionGet();\n    }","id":36792,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasNullAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"index1\", null)).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSearchingFilteringAliasesMultipleIndices() throws Exception {\n\n        logger.info(\"--> creating indices\");\n        admin().indices().create(createIndexRequest(\"test1\")).actionGet();\n        admin().indices().create(createIndexRequest(\"test2\")).actionGet();\n        admin().indices().create(createIndexRequest(\"test3\")).actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> adding aliases to indices\");\n        admin().indices().prepareAliases().addAlias(\"test1\", \"alias12\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"alias12\").execute().actionGet();\n\n        logger.info(\"--> adding filtering aliases to indices\");\n        admin().indices().prepareAliases().addAlias(\"test1\", \"filter1\", termFilter(\"name\", \"test1\")).execute().actionGet();\n\n        admin().indices().prepareAliases().addAlias(\"test2\", \"filter23\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test3\", \"filter23\", termFilter(\"name\", \"foo\")).execute().actionGet();\n\n        admin().indices().prepareAliases().addAlias(\"test1\", \"filter13\", termFilter(\"name\", \"baz\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test3\", \"filter13\", termFilter(\"name\", \"baz\")).execute().actionGet();\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"11\").source(source(\"11\", \"foo test1\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"12\").source(source(\"12\", \"bar test1\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"13\").source(source(\"13\", \"baz test1\")).refresh(true)).actionGet();\n\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"21\").source(source(\"21\", \"foo test2\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"22\").source(source(\"22\", \"bar test2\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"23\").source(source(\"23\", \"baz test2\")).refresh(true)).actionGet();\n\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"31\").source(source(\"31\", \"foo test3\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"32\").source(source(\"32\", \"bar test3\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"33\").source(source(\"33\", \"baz test3\")).refresh(true)).actionGet();\n\n        logger.info(\"--> checking filtering alias for multiple indices\");\n        SearchResponse searchResponse = client().prepareSearch(\"filter23\", \"filter13\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"21\", \"31\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(4L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"21\", \"31\", \"11\", \"12\", \"13\");\n        assertThat(client().prepareCount(\"filter23\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(5L));\n\n        searchResponse = client().prepareSearch(\"filter13\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter13\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(4L));\n\n        searchResponse = client().prepareSearch(\"filter13\", \"filter1\", \"filter23\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"21\", \"31\", \"33\");\n        assertThat(client().prepareCount(\"filter13\", \"filter1\", \"filter23\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(6L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter13\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"21\", \"22\", \"23\", \"31\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(6L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter13\", \"test1\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"21\", \"22\", \"23\", \"31\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\", \"test1\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(8L));\n\n    }","id":36793,"modified_method":"@Test\n    public void testSearchingFilteringAliasesMultipleIndices() throws Exception {\n        logger.info(\"--> creating indices\");\n        createIndex(\"test1\", \"test2\", \"test3\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding aliases to indices\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"alias12\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"alias12\"));\n\n        logger.info(\"--> adding filtering aliases to indices\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"filter1\", termFilter(\"name\", \"test1\")));\n\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"filter23\", termFilter(\"name\", \"foo\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test3\", \"filter23\", termFilter(\"name\", \"foo\")));\n\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"filter13\", termFilter(\"name\", \"baz\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test3\", \"filter13\", termFilter(\"name\", \"baz\")));\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"11\").source(source(\"11\", \"foo test1\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"12\").source(source(\"12\", \"bar test1\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"13\").source(source(\"13\", \"baz test1\"))).get();\n\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"21\").source(source(\"21\", \"foo test2\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"22\").source(source(\"22\", \"bar test2\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"23\").source(source(\"23\", \"baz test2\"))).get();\n\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"31\").source(source(\"31\", \"foo test3\"))).get();\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"32\").source(source(\"32\", \"bar test3\"))).get();\n        client().index(indexRequest(\"test3\").type(\"type1\").id(\"33\").source(source(\"33\", \"baz test3\"))).get();\n\n        refresh();\n\n        logger.info(\"--> checking filtering alias for multiple indices\");\n        SearchResponse searchResponse = client().prepareSearch(\"filter23\", \"filter13\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"21\", \"31\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(4L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"21\", \"31\", \"11\", \"12\", \"13\");\n        assertThat(client().prepareCount(\"filter23\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(5L));\n\n        searchResponse = client().prepareSearch(\"filter13\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter13\", \"filter1\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(4L));\n\n        searchResponse = client().prepareSearch(\"filter13\", \"filter1\", \"filter23\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"21\", \"31\", \"33\");\n        assertThat(client().prepareCount(\"filter13\", \"filter1\", \"filter23\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(6L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter13\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"21\", \"22\", \"23\", \"31\", \"13\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(6L));\n\n        searchResponse = client().prepareSearch(\"filter23\", \"filter13\", \"test1\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"11\", \"12\", \"13\", \"21\", \"22\", \"23\", \"31\", \"33\");\n        assertThat(client().prepareCount(\"filter23\", \"filter13\", \"test1\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(8L));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasEmptyAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"index1\", \"\"))\n                .execute().actionGet();\n    }","id":36794,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasEmptyAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"index1\", \"\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testWaitForAliasCreationMultipleShards() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        for (int i = 0; i < 10; i++) {\n            assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias\" + i).execute().actionGet().isAcknowledged(), equalTo(true));\n            client().index(indexRequest(\"alias\" + i).type(\"type1\").id(\"1\").source(source(\"1\", \"test\")).refresh(true)).actionGet();\n        }\n\n    }","id":36795,"modified_method":"@Test\n    public void testWaitForAliasCreationMultipleShards() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        for (int i = 0; i < 10; i++) {\n            assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias\" + i));\n            client().index(indexRequest(\"alias\" + i).type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).get();\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testWaitForAliasCreationSingleShard() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        admin().indices().create(createIndexRequest(\"test\").settings(settingsBuilder().put(\"index.numberOfReplicas\", 0).put(\"index.numberOfShards\", 1))).actionGet();\n\n        ensureGreen();\n\n        for (int i = 0; i < 10; i++) {\n            assertThat(admin().indices().prepareAliases().addAlias(\"test\", \"alias\" + i).execute().actionGet().isAcknowledged(), equalTo(true));\n            client().index(indexRequest(\"alias\" + i).type(\"type1\").id(\"1\").source(source(\"1\", \"test\")).refresh(true)).actionGet();\n        }\n    }","id":36796,"modified_method":"@Test\n    public void testWaitForAliasCreationSingleShard() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        assertAcked(admin().indices().create(createIndexRequest(\"test\").settings(settingsBuilder().put(\"index.numberOfReplicas\", 0).put(\"index.numberOfShards\", 1))).get());\n\n        ensureGreen();\n\n        for (int i = 0; i < 10; i++) {\n            assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias\" + i));\n            client().index(indexRequest(\"alias\" + i).type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).get();\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = IndexMissingException.class)\n    public void testAddAliasNullIndex() {\n\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(null, \"alias1\"))\n                .execute().actionGet();\n    }","id":36797,"modified_method":"@Test(expected = IndexMissingException.class)\n    public void testAddAliasNullIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(null, \"alias1\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSearchingFilteringAliasesTwoIndices() throws Exception {\n\n        logger.info(\"--> creating index [test1]\");\n        admin().indices().create(createIndexRequest(\"test1\")).actionGet();\n\n        logger.info(\"--> creating index [test2]\");\n        admin().indices().create(createIndexRequest(\"test2\")).actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\")).execute().actionGet();\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> indexing against [test2]\");\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"5\").source(source(\"5\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"6\").source(source(\"6\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"7\").source(source(\"7\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"8\").source(source(\"8\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> checking filtering alias for two indices\");\n        SearchResponse searchResponse = client().prepareSearch(\"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"5\");\n        assertThat(client().prepareCount(\"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2L));\n\n        logger.info(\"--> checking filtering alias for one index\");\n        searchResponse = client().prepareSearch(\"bars\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"2\");\n        assertThat(client().prepareCount(\"bars\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1L));\n\n        logger.info(\"--> checking filtering alias for two indices and one complete index\");\n        searchResponse = client().prepareSearch(\"foos\", \"test1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\", \"5\");\n        assertThat(client().prepareCount(\"foos\", \"test1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(5L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for one index\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTest1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\", \"5\");\n        assertThat(client().prepareCount(\"foos\", \"aliasToTest1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(5L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for both indices\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertThat(searchResponse.getHits().totalHits(), equalTo(8L));\n        assertThat(client().prepareCount(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(8L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for both indices\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.termQuery(\"name\", \"something\")).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"4\", \"8\");\n        assertThat(client().prepareCount(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.termQuery(\"name\", \"something\")).execute().actionGet().getCount(), equalTo(2L));\n    }","id":36798,"modified_method":"@Test\n    public void testSearchingFilteringAliasesTwoIndices() throws Exception {\n        logger.info(\"--> creating index [test1]\");\n        createIndex(\"test1\");\n\n        logger.info(\"--> creating index [test2]\");\n        createIndex(\"test2\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTests\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\")));\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTests\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\")));\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\"))).get();\n\n        logger.info(\"--> indexing against [test2]\");\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"5\").source(source(\"5\", \"foo test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"6\").source(source(\"6\", \"bar test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"7\").source(source(\"7\", \"baz test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"8\").source(source(\"8\", \"something else\"))).get();\n\n        refresh();\n\n        logger.info(\"--> checking filtering alias for two indices\");\n        SearchResponse searchResponse = client().prepareSearch(\"foos\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"5\");\n        assertThat(client().prepareCount(\"foos\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(2L));\n\n        logger.info(\"--> checking filtering alias for one index\");\n        searchResponse = client().prepareSearch(\"bars\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"2\");\n        assertThat(client().prepareCount(\"bars\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(1L));\n\n        logger.info(\"--> checking filtering alias for two indices and one complete index\");\n        searchResponse = client().prepareSearch(\"foos\", \"test1\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\", \"5\");\n        assertThat(client().prepareCount(\"foos\", \"test1\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(5L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for one index\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTest1\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\", \"5\");\n        assertThat(client().prepareCount(\"foos\", \"aliasToTest1\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(5L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for both indices\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertThat(searchResponse.getHits().totalHits(), equalTo(8L));\n        assertThat(client().prepareCount(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(8L));\n\n        logger.info(\"--> checking filtering alias for two indices and non-filtering alias for both indices\");\n        searchResponse = client().prepareSearch(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.termQuery(\"name\", \"something\")).get();\n        assertHits(searchResponse.getHits(), \"4\", \"8\");\n        assertThat(client().prepareCount(\"foos\", \"aliasToTests\").setQuery(QueryBuilders.termQuery(\"name\", \"something\")).get().getCount(), equalTo(2L));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testAliases() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n//\n//        try {\n//            logger.info(\"--> indexing against [alias1], should fail\");\n//            client().index(indexRequest(\"alias1\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n//            fail(\"index [alias1] should not exists\");\n//        } catch (IndexMissingException e) {\n//            assertThat(e.index().name(), equalTo(\"alias1\"));\n//        } \n        // TODO this is bogus and should have a dedicated test\n\n        logger.info(\"--> aliasing index [test] with [alias1]\");\n        admin().indices().prepareAliases().addAlias(\"test\", \"alias1\").execute().actionGet();\n\n        logger.info(\"--> indexing against [alias1], should work now\");\n        IndexResponse indexResponse = client().index(indexRequest(\"alias1\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n        assertThat(indexResponse.getIndex(), equalTo(\"test\"));\n\n        logger.info(\"--> creating index [test]\");\n        admin().indices().create(createIndexRequest(\"test_x\")).actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> remove [alias1], Aliasing index [test_x] with [alias1]\");\n        admin().indices().aliases(indexAliasesRequest().removeAlias(\"test\", \"alias1\").addAlias(\"alias1\", \"test_x\")).actionGet();\n        Thread.sleep(300);\n\n        logger.info(\"--> indexing against [alias1], should work against [test_x]\");\n        indexResponse = client().index(indexRequest(\"alias1\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n        assertThat(indexResponse.getIndex(), equalTo(\"test_x\"));\n    }","id":36799,"modified_method":"@Test\n    public void testAliases() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> aliasing index [test] with [alias1]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\"));\n\n        logger.info(\"--> indexing against [alias1], should work now\");\n        IndexResponse indexResponse = client().index(indexRequest(\"alias1\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n        assertThat(indexResponse.getIndex(), equalTo(\"test\"));\n\n        logger.info(\"--> creating index [test_x]\");\n        createIndex(\"test_x\");\n\n        ensureGreen();\n\n        logger.info(\"--> remove [alias1], Aliasing index [test_x] with [alias1]\");\n        assertAcked(admin().indices().prepareAliases().removeAlias(\"test\", \"alias1\").addAlias(\"test_x\", \"alias1\"));\n\n        logger.info(\"--> indexing against [alias1], should work against [test_x]\");\n        indexResponse = client().index(indexRequest(\"alias1\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n        assertThat(indexResponse.getIndex(), equalTo(\"test_x\"));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSearchingFilteringAliasesSingleIndex() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test]\");\n        admin().indices().prepareAliases().addAlias(\"test\", \"alias1\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test\", \"alias2\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test\", \"bars\", termFilter(\"name\", \"bar\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test\", \"tests\", termFilter(\"name\", \"test\")).execute().actionGet();\n\n        logger.info(\"--> indexing against [test]\");\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> checking single filtering alias search\");\n        SearchResponse searchResponse = client().prepareSearch(\"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\");\n\n        logger.info(\"--> checking single filtering alias wildcard search\");\n        searchResponse = client().prepareSearch(\"fo*\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\");\n\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\");\n\n        logger.info(\"--> checking single filtering alias search with sort\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchAllQuery()).addSort(\"_uid\", SortOrder.ASC).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\");\n\n        logger.info(\"--> checking single filtering alias search with global facets\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(true))\n                .execute().actionGet();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(4));\n\n        logger.info(\"--> checking single filtering alias search with global facets and sort\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(true))\n                .addSort(\"_uid\", SortOrder.ASC).execute().actionGet();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(4));\n\n        logger.info(\"--> checking single filtering alias search with non-global facets\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(false))\n                .addSort(\"_uid\", SortOrder.ASC).execute().actionGet();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(2));\n\n        searchResponse = client().prepareSearch(\"foos\", \"bars\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\");\n\n        logger.info(\"--> checking single non-filtering alias search\");\n        searchResponse = client().prepareSearch(\"alias1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking non-filtering alias and filtering alias search\");\n        searchResponse = client().prepareSearch(\"alias1\", \"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking index and filtering alias search\");\n        searchResponse = client().prepareSearch(\"test\", \"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking index and alias wildcard search\");\n        searchResponse = client().prepareSearch(\"te*\", \"fo*\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n    }","id":36800,"modified_method":"@Test\n    public void testSearchingFilteringAliasesSingleIndex() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias2\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"foos\", termFilter(\"name\", \"foo\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"bars\", termFilter(\"name\", \"bar\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"tests\", termFilter(\"name\", \"test\")));\n\n        logger.info(\"--> indexing against [test]\");\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> checking single filtering alias search\");\n        SearchResponse searchResponse = client().prepareSearch(\"foos\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\");\n\n        logger.info(\"--> checking single filtering alias wildcard search\");\n        searchResponse = client().prepareSearch(\"fo*\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\");\n\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\");\n\n        logger.info(\"--> checking single filtering alias search with sort\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchAllQuery()).addSort(\"_uid\", SortOrder.ASC).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\");\n\n        logger.info(\"--> checking single filtering alias search with global facets\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(true))\n                .get();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(4));\n\n        logger.info(\"--> checking single filtering alias search with global facets and sort\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(true))\n                .addSort(\"_uid\", SortOrder.ASC).get();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(4));\n\n        logger.info(\"--> checking single filtering alias search with non-global facets\");\n        searchResponse = client().prepareSearch(\"tests\").setQuery(QueryBuilders.matchQuery(\"name\", \"bar\"))\n                .addFacet(FacetBuilders.termsFacet(\"test\").field(\"name\").global(false))\n                .addSort(\"_uid\", SortOrder.ASC).get();\n        assertThat(((TermsFacet) searchResponse.getFacets().facet(\"test\")).getEntries().size(), equalTo(2));\n\n        searchResponse = client().prepareSearch(\"foos\", \"bars\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\");\n\n        logger.info(\"--> checking single non-filtering alias search\");\n        searchResponse = client().prepareSearch(\"alias1\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking non-filtering alias and filtering alias search\");\n        searchResponse = client().prepareSearch(\"alias1\", \"foos\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking index and filtering alias search\");\n        searchResponse = client().prepareSearch(\"test\", \"foos\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n\n        logger.info(\"--> checking index and alias wildcard search\");\n        searchResponse = client().prepareSearch(\"te*\", \"fo*\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"1\", \"2\", \"3\", \"4\");\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testEmptyFilter() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n\n        logger.info(\"--> aliasing index [test] with [alias1] and empty filter\");\n        IndicesAliasesResponse indicesAliasesResponse = admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", \"{}\").get();\n        //just checking that the empty doesn't lead to issues\n        assertThat(indicesAliasesResponse.isAcknowledged(), equalTo(true));\n    }","id":36801,"modified_method":"@Test\n    public void testEmptyFilter() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n\n        logger.info(\"--> aliasing index [test] with [alias1] and empty filter\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", \"{}\"));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testWaitForAliasSimultaneousUpdate() throws Exception {\n        final int aliasCount = 10;\n\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        ExecutorService executor = Executors.newFixedThreadPool(aliasCount);\n        for (int i = 0; i < aliasCount; i++) {\n            final String aliasName = \"alias\" + i;\n            executor.submit(new Runnable() {\n                @Override\n                public void run() {\n                    assertThat(admin().indices().prepareAliases().addAlias(\"test\", aliasName).execute().actionGet().isAcknowledged(), equalTo(true));\n                    client().index(indexRequest(aliasName).type(\"type1\").id(\"1\").source(source(\"1\", \"test\")).refresh(true)).actionGet();\n                }\n            });\n        }\n        executor.shutdown();\n        boolean done = executor.awaitTermination(10, TimeUnit.SECONDS);\n        assertThat(done, equalTo(true));\n        if (!done) {\n            executor.shutdownNow();\n        }\n    }","id":36802,"modified_method":"@Test\n    public void testWaitForAliasSimultaneousUpdate() throws Exception {\n        final int aliasCount = 10;\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        ExecutorService executor = Executors.newFixedThreadPool(aliasCount);\n        for (int i = 0; i < aliasCount; i++) {\n            final String aliasName = \"alias\" + i;\n            executor.submit(new Runnable() {\n                @Override\n                public void run() {\n                    assertAcked(admin().indices().prepareAliases().addAlias(\"test\", aliasName));\n                    client().index(indexRequest(aliasName).type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();\n                }\n            });\n        }\n        executor.shutdown();\n        boolean done = executor.awaitTermination(10, TimeUnit.SECONDS);\n        assertThat(done, equalTo(true));\n        if (!done) {\n            executor.shutdownNow();\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testIndicesGetAliases() throws Exception {\n        Settings indexSettings = ImmutableSettings.settingsBuilder()\n                .put(\"index.number_of_shards\", 1)\n                .put(\"index.number_of_replicas\", 0)\n                .build();\n        logger.info(\"--> creating indices [foobar, test, test123, foobarbaz, bazbar]\");\n        admin().indices().prepareCreate(\"foobar\")\n                .setSettings(indexSettings)\n                .execute().actionGet();\n        admin().indices().prepareCreate(\"test\")\n                .setSettings(indexSettings)\n                .execute().actionGet();\n        admin().indices().prepareCreate(\"test123\")\n                .setSettings(indexSettings)\n                .execute().actionGet();\n        admin().indices().prepareCreate(\"foobarbaz\")\n                .setSettings(indexSettings)\n                .execute().actionGet();\n        admin().indices().prepareCreate(\"bazbar\")\n                .setSettings(indexSettings)\n                .execute().actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> creating aliases [alias1, alias2]\");\n        admin().indices().prepareAliases()\n                .addAlias(\"foobar\", \"alias1\")\n                .execute().actionGet();\n\n        IndicesAliasesResponse indicesAliasesResponse = admin().indices().prepareAliases()\n                .addAlias(\"foobar\", \"alias2\")\n                .execute().actionGet();\n        assertThat(indicesAliasesResponse.isAcknowledged(), equalTo(true));\n\n        logger.info(\"--> getting alias1\");\n        GetAliasesResponse getResponse = admin().indices().prepareGetAliases(\"alias1\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"alias1\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        AliasesExistResponse existsResponse = admin().indices().prepareAliasesExist(\"alias1\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting all aliases that start with alias*\");\n        getResponse = admin().indices().prepareGetAliases(\"alias*\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"alias2\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).alias(), equalTo(\"alias1\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"alias*\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n\n        logger.info(\"--> creating aliases [bar, baz, foo]\");\n        admin().indices().prepareAliases()\n                .addAlias(\"bazbar\", \"bar\")\n                .addAlias(\"bazbar\", \"bac\", termFilter(\"field\", \"value\"))\n                .addAlias(\"foobar\", \"foo\")\n                .execute().actionGet();\n\n        indicesAliasesResponse = admin().indices().prepareAliases()\n                .addAliasAction(new AliasAction(AliasAction.Type.ADD, \"foobar\", \"bac\").routing(\"bla\"))\n                .execute().actionGet();\n        assertThat(indicesAliasesResponse.isAcknowledged(), equalTo(true));\n\n        logger.info(\"--> getting bar and baz for index bazbar\");\n        getResponse = admin().indices().prepareGetAliases(\"bar\", \"bac\").addIndices(\"bazbar\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"bar\", \"bac\")\n                .addIndices(\"bazbar\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting *b* for index baz*\");\n        getResponse = admin().indices().prepareGetAliases(\"*b*\").addIndices(\"baz*\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"*b*\")\n                .addIndices(\"baz*\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting *b* for index *bar\");\n        getResponse = admin().indices().prepareGetAliases(\"b*\").addIndices(\"*bar\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), equalTo(\"bla\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), equalTo(\"bla\"));\n        existsResponse = admin().indices().prepareAliasesExist(\"b*\")\n                .addIndices(\"*bar\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting f* for index *bar\");\n        getResponse = admin().indices().prepareGetAliases(\"f*\").addIndices(\"*bar\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"f*\")\n                .addIndices(\"*bar\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        // alias at work\n        logger.info(\"--> getting f* for index *bac\");\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"*bac\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\")\n                .addIndices(\"*bac\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting foo for index foobar\");\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"foobar\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\")\n                .addIndices(\"foobar\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        // alias at work again\n        logger.info(\"--> getting * for index *bac\");\n        getResponse = admin().indices().prepareGetAliases(\"*\").addIndices(\"*bac\").execute().actionGet();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(4));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        existsResponse = admin().indices().prepareAliasesExist(\"*\")\n                .addIndices(\"*bac\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        indicesAliasesResponse = admin().indices().prepareAliases()\n                .removeAlias(\"foobar\", \"foo\")\n                .execute().actionGet();\n        assertThat(indicesAliasesResponse.isAcknowledged(), equalTo(true));\n\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"foobar\").execute().actionGet();\n        assertThat(getResponse.getAliases().isEmpty(), equalTo(true));\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\")\n                .addIndices(\"foobar\").execute().actionGet();\n        assertThat(existsResponse.exists(), equalTo(false));\n    }","id":36803,"modified_method":"@Test\n    public void testIndicesGetAliases() throws Exception {\n        Settings indexSettings = ImmutableSettings.settingsBuilder()\n                .put(\"index.number_of_shards\", 1)\n                .put(\"index.number_of_replicas\", 0)\n                .build();\n        logger.info(\"--> creating indices [foobar, test, test123, foobarbaz, bazbar]\");\n        assertAcked(prepareCreate(\"foobar\").setSettings(indexSettings));\n        assertAcked(prepareCreate(\"test\").setSettings(indexSettings));\n        assertAcked(prepareCreate(\"test123\").setSettings(indexSettings));\n        assertAcked(prepareCreate(\"foobarbaz\").setSettings(indexSettings));\n        assertAcked(prepareCreate(\"bazbar\").setSettings(indexSettings));\n\n        ensureGreen();\n\n        logger.info(\"--> creating aliases [alias1, alias2]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"foobar\", \"alias1\").addAlias(\"foobar\", \"alias2\"));\n\n        logger.info(\"--> getting alias1\");\n        GetAliasesResponse getResponse = admin().indices().prepareGetAliases(\"alias1\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"alias1\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        AliasesExistResponse existsResponse = admin().indices().prepareAliasesExist(\"alias1\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting all aliases that start with alias*\");\n        getResponse = admin().indices().prepareGetAliases(\"alias*\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"alias2\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).alias(), equalTo(\"alias1\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"alias*\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n\n        logger.info(\"--> creating aliases [bar, baz, foo]\");\n        assertAcked(admin().indices().prepareAliases()\n                .addAlias(\"bazbar\", \"bar\")\n                .addAlias(\"bazbar\", \"bac\", termFilter(\"field\", \"value\"))\n                .addAlias(\"foobar\", \"foo\"));\n\n        assertAcked(admin().indices().prepareAliases()\n                .addAliasAction(new AliasAction(AliasAction.Type.ADD, \"foobar\", \"bac\").routing(\"bla\")));\n\n        logger.info(\"--> getting bar and baz for index bazbar\");\n        getResponse = admin().indices().prepareGetAliases(\"bar\", \"bac\").addIndices(\"bazbar\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"bar\", \"bac\")\n                .addIndices(\"bazbar\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting *b* for index baz*\");\n        getResponse = admin().indices().prepareGetAliases(\"*b*\").addIndices(\"baz*\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"*b*\")\n                .addIndices(\"baz*\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting *b* for index *bar\");\n        getResponse = admin().indices().prepareGetAliases(\"b*\").addIndices(\"*bar\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"term\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"field\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getFilter().string(), containsString(\"value\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(0).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1), notNullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).alias(), equalTo(\"bar\"));\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"bazbar\").get(1).getSearchRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"bac\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), equalTo(\"bla\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), equalTo(\"bla\"));\n        existsResponse = admin().indices().prepareAliasesExist(\"b*\")\n                .addIndices(\"*bar\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting f* for index *bar\");\n        getResponse = admin().indices().prepareGetAliases(\"f*\").addIndices(\"*bar\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"f*\")\n                .addIndices(\"*bar\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        // alias at work\n        logger.info(\"--> getting f* for index *bac\");\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"*bac\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\")\n                .addIndices(\"*bac\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        logger.info(\"--> getting foo for index foobar\");\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"foobar\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(1));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0), notNullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).alias(), equalTo(\"foo\"));\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getFilter(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getIndexRouting(), nullValue());\n        assertThat(getResponse.getAliases().get(\"foobar\").get(0).getSearchRouting(), nullValue());\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\")\n                .addIndices(\"foobar\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        // alias at work again\n        logger.info(\"--> getting * for index *bac\");\n        getResponse = admin().indices().prepareGetAliases(\"*\").addIndices(\"*bac\").get();\n        assertThat(getResponse, notNullValue());\n        assertThat(getResponse.getAliases().size(), equalTo(2));\n        assertThat(getResponse.getAliases().get(\"foobar\").size(), equalTo(4));\n        assertThat(getResponse.getAliases().get(\"bazbar\").size(), equalTo(2));\n        existsResponse = admin().indices().prepareAliasesExist(\"*\")\n                .addIndices(\"*bac\").get();\n        assertThat(existsResponse.exists(), equalTo(true));\n\n        assertAcked(admin().indices().prepareAliases()\n                .removeAlias(\"foobar\", \"foo\"));\n\n        getResponse = admin().indices().prepareGetAliases(\"foo\").addIndices(\"foobar\").get();\n        assertThat(getResponse.getAliases().isEmpty(), equalTo(true));\n        existsResponse = admin().indices().prepareAliasesExist(\"foo\").addIndices(\"foobar\").get();\n        assertThat(existsResponse.exists(), equalTo(false));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasNullAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"index1\", null))\n                .execute().actionGet();\n    }","id":36804,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasNullAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"index1\", null)).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasEmptyIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"\", \"alias1\"))\n                .execute().actionGet();\n    }","id":36805,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasEmptyIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(\"\", \"alias1\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasEmptyAlias() {\n\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"index1\", \"\"))\n                .execute().actionGet();\n    }","id":36806,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasEmptyAlias() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"index1\", \"\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = AliasesMissingException.class)\n    public void testIndicesRemoveNonExistingAliasResponds404() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n        logger.info(\"--> deleting alias1 which does not exist\");\n        assertThat(admin().indices().prepareAliases().removeAlias(\"test\", \"alias1\").execute().actionGet().isAcknowledged(), equalTo(true));\n    }","id":36807,"modified_method":"@Test(expected = AliasesMissingException.class)\n    public void testIndicesRemoveNonExistingAliasResponds404() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n        ensureGreen();\n        logger.info(\"--> deleting alias1 which does not exist\");\n        assertAcked((admin().indices().prepareAliases().removeAlias(\"test\", \"alias1\")));\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testAddAliasEmptyAliasEmptyIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"\"))\n                    .execute().actionGet();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","id":36808,"modified_method":"@Test\n    public void testAddAliasEmptyAliasEmptyIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"\")).get();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(2));\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDeletingByQueryFilteringAliases() throws Exception {\n\n        logger.info(\"--> creating index [test1]\");\n        admin().indices().create(createIndexRequest(\"test1\")).actionGet();\n\n        logger.info(\"--> creating index [test2]\");\n        admin().indices().create(createIndexRequest(\"test2\")).actionGet();\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test1\", \"tests\", termFilter(\"name\", \"test\")).execute().actionGet();\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTests\").execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\")).execute().actionGet();\n        admin().indices().prepareAliases().addAlias(\"test2\", \"tests\", termFilter(\"name\", \"test\")).execute().actionGet();\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> indexing against [test2]\");\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"5\").source(source(\"5\", \"foo test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"6\").source(source(\"6\", \"bar test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"7\").source(source(\"7\", \"baz test\")).refresh(true)).actionGet();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"8\").source(source(\"8\", \"something else\")).refresh(true)).actionGet();\n\n        logger.info(\"--> checking counts before delete\");\n        assertThat(client().prepareCount(\"bars\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1L));\n\n        logger.info(\"--> delete by query from a single alias\");\n        client().prepareDeleteByQuery(\"bars\").setQuery(QueryBuilders.termQuery(\"name\", \"test\")).execute().actionGet();\n        admin().indices().prepareRefresh().execute().actionGet();\n\n        logger.info(\"--> verify that only one record was deleted\");\n        assertThat(client().prepareCount(\"test1\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(3L));\n\n        logger.info(\"--> delete by query from an aliases pointing to two indices\");\n        client().prepareDeleteByQuery(\"foos\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        admin().indices().prepareRefresh().execute().actionGet();\n\n        logger.info(\"--> verify that proper records were deleted\");\n        SearchResponse searchResponse = client().prepareSearch(\"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"3\", \"4\", \"6\", \"7\", \"8\");\n\n        logger.info(\"--> delete by query from an aliases and an index\");\n        client().prepareDeleteByQuery(\"tests\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        admin().indices().prepareRefresh().execute().actionGet();\n\n        logger.info(\"--> verify that proper records were deleted\");\n        searchResponse = client().prepareSearch(\"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertHits(searchResponse.getHits(), \"4\");\n    }","id":36809,"modified_method":"@Test\n    public void testDeletingByQueryFilteringAliases() throws Exception {\n        logger.info(\"--> creating index [test1] and [test2\");\n        createIndex(\"test1\", \"test2\");\n\n        ensureGreen();\n\n        logger.info(\"--> adding filtering aliases to index [test1]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTest1\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"aliasToTests\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"foos\", termFilter(\"name\", \"foo\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"bars\", termFilter(\"name\", \"bar\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test1\", \"tests\", termFilter(\"name\", \"test\")));\n\n        logger.info(\"--> adding filtering aliases to index [test2]\");\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTest2\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"aliasToTests\"));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"foos\", termFilter(\"name\", \"foo\")));\n        assertAcked(admin().indices().prepareAliases().addAlias(\"test2\", \"tests\", termFilter(\"name\", \"test\")));\n\n        logger.info(\"--> indexing against [test1]\");\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"1\").source(source(\"1\", \"foo test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"2\").source(source(\"2\", \"bar test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"3\").source(source(\"3\", \"baz test\"))).get();\n        client().index(indexRequest(\"test1\").type(\"type1\").id(\"4\").source(source(\"4\", \"something else\"))).get();\n\n        logger.info(\"--> indexing against [test2]\");\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"5\").source(source(\"5\", \"foo test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"6\").source(source(\"6\", \"bar test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"7\").source(source(\"7\", \"baz test\"))).get();\n        client().index(indexRequest(\"test2\").type(\"type1\").id(\"8\").source(source(\"8\", \"something else\"))).get();\n\n        refresh();\n\n        logger.info(\"--> checking counts before delete\");\n        assertThat(client().prepareCount(\"bars\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(1L));\n\n        logger.info(\"--> delete by query from a single alias\");\n        client().prepareDeleteByQuery(\"bars\").setQuery(QueryBuilders.termQuery(\"name\", \"test\")).get();\n\n        logger.info(\"--> verify that only one record was deleted\");\n        assertThat(client().prepareCount(\"test1\").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(3L));\n\n        logger.info(\"--> delete by query from an aliases pointing to two indices\");\n        client().prepareDeleteByQuery(\"foos\").setQuery(QueryBuilders.matchAllQuery()).get();\n\n        logger.info(\"--> verify that proper records were deleted\");\n        SearchResponse searchResponse = client().prepareSearch(\"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"3\", \"4\", \"6\", \"7\", \"8\");\n\n        logger.info(\"--> delete by query from an aliases and an index\");\n        client().prepareDeleteByQuery(\"tests\", \"test2\").setQuery(QueryBuilders.matchAllQuery()).get();\n\n        logger.info(\"--> verify that proper records were deleted\");\n        searchResponse = client().prepareSearch(\"aliasToTests\").setQuery(QueryBuilders.matchAllQuery()).get();\n        assertHits(searchResponse.getHits(), \"4\");\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasEmptyIndex() {\n\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"alias1\"))\n                .execute().actionGet();\n    }","id":36810,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void testAddAliasEmptyIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(\"\", \"alias1\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testAddAliasNullAliasNullIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(null, null))\n                    .execute().actionGet();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(1));\n        }\n    }","id":36811,"modified_method":"@Test\n    public void testAddAliasNullAliasNullIndex() {\n        try {\n            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction(null, null)).get();\n            assertTrue(\"Should throw \" + ActionRequestValidationException.class.getSimpleName(), false);\n        } catch (ActionRequestValidationException e) {\n            assertThat(e.validationErrors(), notNullValue());\n            assertThat(e.validationErrors().size(), equalTo(1));\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasNullIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(null, \"alias1\"))\n                .execute().actionGet();\n    }","id":36812,"modified_method":"@Test(expected = ActionRequestValidationException.class)\n    public void tesRemoveAliasNullIndex() {\n        admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction(null, \"alias1\")).get();\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testFailedFilter() throws Exception {\n\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        try {\n            logger.info(\"--> aliasing index [test] with [alias1] and filter [t]\");\n            admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", \"{ t }\").execute().actionGet();\n            fail();\n        } catch (Exception e) {\n            // all is well\n        }\n    }","id":36813,"modified_method":"@Test\n    public void testFailedFilter() throws Exception {\n        logger.info(\"--> creating index [test]\");\n        createIndex(\"test\");\n\n        ensureGreen();\n\n        try {\n            logger.info(\"--> aliasing index [test] with [alias1] and filter [t]\");\n            admin().indices().prepareAliases().addAlias(\"test\", \"alias1\", \"{ t }\").get();\n            fail();\n        } catch (Exception e) {\n            // all is well\n        }\n    }","commit_id":"c4edf156330b93dd9d18c2f386c99b089cb031f7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public static <E extends Throwable> void assertThrows(ActionFuture future, Class<E> exceptionClass) {\n        boolean fail = false;\n        try {\n            future.actionGet();\n            fail = true;\n\n        } catch (ElasticSearchException esException) {\n            assertThat(esException.unwrapCause(), instanceOf(exceptionClass));\n        } catch (Throwable e) {\n            assertThat(e, instanceOf(exceptionClass));\n        }\n        // has to be outside catch clause to get a proper message\n        if (fail) {\n            throw new AssertionError(\"Expected a \" + exceptionClass + \" exception to be thrown\");\n        }\n    }","id":36814,"modified_method":"public static <E extends Throwable> void assertThrows(ActionFuture future, Class<E> exceptionClass) {\n        assertThrows(future, exceptionClass, null);\n    }","commit_id":"4ddfe89bdb9963a425189fefa5bf2855e306510e","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void testExpectActionRequestValidationException(String... names) {\n        try {\n            client().admin().indices().prepareGetTemplates(names).execute().actionGet();\n            fail(\"We should have raised an ActionRequestValidationException for \" + names);\n        } catch (ActionRequestValidationException e) {\n            // That's fine!\n        }\n    }","id":36815,"modified_method":"private void testExpectActionRequestValidationException(String... names) {\n        assertThrows(client().admin().indices().prepareGetTemplates(names),\n                ActionRequestValidationException.class,\n                \"get template with \" + Arrays.toString(names));\n    }","commit_id":"4ddfe89bdb9963a425189fefa5bf2855e306510e","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void simpleIndexTemplateTests() throws Exception {\n        client().admin().indices().preparePutTemplate(\"template_1\")\n                .setTemplate(\"te*\")\n                .setOrder(0)\n                .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                        .startObject(\"field1\").field(\"type\", \"string\").field(\"store\", \"yes\").endObject()\n                        .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"yes\").field(\"index\", \"not_analyzed\").endObject()\n                        .endObject().endObject().endObject())\n                .execute().actionGet();\n\n        client().admin().indices().preparePutTemplate(\"template_2\")\n                .setTemplate(\"test*\")\n                .setOrder(1)\n                .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                        .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"no\").endObject()\n                        .endObject().endObject().endObject())\n                .execute().actionGet();\n\n        // test create param\n        try {\n            client().admin().indices().preparePutTemplate(\"template_2\")\n                    .setTemplate(\"test*\")\n                    .setCreate(true)\n                    .setOrder(1)\n                    .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                            .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"no\").endObject()\n                            .endObject().endObject().endObject())\n                    .execute().actionGet();\n            assertThat(false, equalTo(true));\n        } catch (IndexTemplateAlreadyExistsException e) {\n            // OK\n        } catch (Exception e) {\n            assertThat(false, equalTo(true));\n        }\n\n\n        // index something into test_index, will match on both templates\n        client().prepareIndex(\"test_index\", \"type1\", \"1\").setSource(\"field1\", \"value1\", \"field2\", \"value 2\").setRefresh(true).execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        SearchResponse searchResponse = client().prepareSearch(\"test_index\")\n                .setQuery(termQuery(\"field1\", \"value1\"))\n                .addField(\"field1\").addField(\"field2\")\n                .execute().actionGet();\n        if (searchResponse.getFailedShards() > 0) {\n            logger.warn(\"failed search \" + Arrays.toString(searchResponse.getShardFailures()));\n        }\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field1\").value().toString(), equalTo(\"value1\"));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field2\").value().toString(), equalTo(\"value 2\")); // this will still be loaded because of the source feature\n\n        client().prepareIndex(\"text_index\", \"type1\", \"1\").setSource(\"field1\", \"value1\", \"field2\", \"value 2\").setRefresh(true).execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        // now only match on one template (template_1)\n        searchResponse = client().prepareSearch(\"text_index\")\n                .setQuery(termQuery(\"field1\", \"value1\"))\n                .addField(\"field1\").addField(\"field2\")\n                .execute().actionGet();\n        if (searchResponse.getFailedShards() > 0) {\n            logger.warn(\"failed search \" + Arrays.toString(searchResponse.getShardFailures()));\n        }\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field1\").value().toString(), equalTo(\"value1\"));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field2\").value().toString(), equalTo(\"value 2\"));\n    }","id":36816,"modified_method":"@Test\n    public void simpleIndexTemplateTests() throws Exception {\n        // clean all templates setup by the framework.\n        client().admin().indices().prepareDeleteTemplate(\"*\").get();\n\n        // check get all templates on an empty index.\n        GetIndexTemplatesResponse response = client().admin().indices().prepareGetTemplates().get();\n        assertThat(response.getIndexTemplates(), empty());\n\n\n        client().admin().indices().preparePutTemplate(\"template_1\")\n                .setTemplate(\"te*\")\n                .setOrder(0)\n                .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                        .startObject(\"field1\").field(\"type\", \"string\").field(\"store\", \"yes\").endObject()\n                        .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"yes\").field(\"index\", \"not_analyzed\").endObject()\n                        .endObject().endObject().endObject())\n                .get();\n\n        client().admin().indices().preparePutTemplate(\"template_2\")\n                .setTemplate(\"test*\")\n                .setOrder(1)\n                .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                        .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"no\").endObject()\n                        .endObject().endObject().endObject())\n                .get();\n\n        // test create param\n        assertThrows(client().admin().indices().preparePutTemplate(\"template_2\")\n                .setTemplate(\"test*\")\n                .setCreate(true)\n                .setOrder(1)\n                .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                        .startObject(\"field2\").field(\"type\", \"string\").field(\"store\", \"no\").endObject()\n                        .endObject().endObject().endObject())\n                , IndexTemplateAlreadyExistsException.class\n        );\n\n        response = client().admin().indices().prepareGetTemplates().get();\n        assertThat(response.getIndexTemplates(), hasSize(2));\n\n\n        // index something into test_index, will match on both templates\n        client().prepareIndex(\"test_index\", \"type1\", \"1\").setSource(\"field1\", \"value1\", \"field2\", \"value 2\").setRefresh(true).execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        SearchResponse searchResponse = client().prepareSearch(\"test_index\")\n                .setQuery(termQuery(\"field1\", \"value1\"))\n                .addField(\"field1\").addField(\"field2\")\n                .execute().actionGet();\n\n        assertHitCount(searchResponse, 1);\n        assertThat(searchResponse.getHits().getAt(0).field(\"field1\").value().toString(), equalTo(\"value1\"));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field2\").value().toString(), equalTo(\"value 2\")); // this will still be loaded because of the source feature\n\n        client().prepareIndex(\"text_index\", \"type1\", \"1\").setSource(\"field1\", \"value1\", \"field2\", \"value 2\").setRefresh(true).execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        // now only match on one template (template_1)\n        searchResponse = client().prepareSearch(\"text_index\")\n                .setQuery(termQuery(\"field1\", \"value1\"))\n                .addField(\"field1\").addField(\"field2\")\n                .execute().actionGet();\n        if (searchResponse.getFailedShards() > 0) {\n            logger.warn(\"failed search \" + Arrays.toString(searchResponse.getShardFailures()));\n        }\n        assertHitCount(searchResponse, 1);\n        assertThat(searchResponse.getHits().getAt(0).field(\"field1\").value().toString(), equalTo(\"value1\"));\n        assertThat(searchResponse.getHits().getAt(0).field(\"field2\").value().toString(), equalTo(\"value 2\"));\n    }","commit_id":"4ddfe89bdb9963a425189fefa5bf2855e306510e","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void setupSuiteScopeCluster() throws Exception {\n        createIndex(\"idx\");\n        createIndex(\"idx_unmapped\");\n        // TODO: would be nice to have more random data here\n        prepareCreate(\"empty_bucket_idx\").addMapping(\"type\", \"value\", \"type=integer\").execute().actionGet();\n        List<IndexRequestBuilder> builders = new ArrayList<>();\n        for (int i = 0; i < 2; i++) {\n            builders.add(client().prepareIndex(\"empty_bucket_idx\", \"type\", \"\"+i).setSource(jsonBuilder()\n                    .startObject()\n                    .field(\"value\", i*2)\n                    .endObject()));\n        }\n        builders.addAll(Arrays.asList(\n                indexDoc(1, 2, 1),  // date: Jan 2, dates: Jan 2, Feb 3\n                indexDoc(2, 2, 2),  // date: Feb 2, dates: Feb 2, Mar 3\n                indexDoc(2, 15, 3), // date: Feb 15, dates: Feb 15, Mar 16\n                indexDoc(3, 2, 4),  // date: Mar 2, dates: Mar 2, Apr 3\n                indexDoc(3, 15, 5), // date: Mar 15, dates: Mar 15, Apr 16\n                indexDoc(3, 23, 6))); // date: Mar 23, dates: Mar 23, Apr 24\n        indexRandom(true, builders);\n        ensureSearchable();\n    }","id":36817,"modified_method":"@Override\n    public void setupSuiteScopeCluster() throws Exception {\n        assertAcked(prepareCreate(\"idx\").addMapping(\"type\", \"_timestamp\", \"enabled=true\"));\n        createIndex(\"idx_unmapped\");\n        // TODO: would be nice to have more random data here\n        assertAcked(prepareCreate(\"empty_bucket_idx\").addMapping(\"type\", \"value\", \"type=integer\"));\n        List<IndexRequestBuilder> builders = new ArrayList<>();\n        for (int i = 0; i < 2; i++) {\n            builders.add(client().prepareIndex(\"empty_bucket_idx\", \"type\", \"\"+i).setSource(jsonBuilder()\n                    .startObject()\n                    .field(\"value\", i*2)\n                    .endObject()));\n        }\n        builders.addAll(Arrays.asList(\n                indexDoc(1, 2, 1),  // date: Jan 2, dates: Jan 2, Feb 3\n                indexDoc(2, 2, 2),  // date: Feb 2, dates: Feb 2, Mar 3\n                indexDoc(2, 15, 3), // date: Feb 15, dates: Feb 15, Mar 16\n                indexDoc(3, 2, 4),  // date: Mar 2, dates: Mar 2, Apr 3\n                indexDoc(3, 15, 5), // date: Mar 15, dates: Mar 15, Apr 16\n                indexDoc(3, 23, 6))); // date: Mar 23, dates: Mar 23, Apr 24\n        indexRandom(true, builders);\n        ensureSearchable();\n    }","commit_id":"cdd13253deee8c4f0cafe5a048161e4efb9ffce7","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // flt query with no field -> OK\n        SearchResponse searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery().likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with string fields\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\").likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with at least a numeric field -> fail\n        try {\n            searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")).execute().actionGet();\n            fail();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // flt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt field query on a numeric field -> failure\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\")), SearchPhaseExecutionException.class);\n\n        // flt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","id":36818,"modified_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // flt query with no field -> OK\n        SearchResponse searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery().likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with string fields\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\").likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with at least a numeric field -> fail by default\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")), SearchPhaseExecutionException.class);\n\n        // flt query with at least a numeric field -> fail by command\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(true)), SearchPhaseExecutionException.class);\n\n\n        // flt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt field query on a numeric field -> failure by default\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\")), SearchPhaseExecutionException.class);\n\n        // flt field query on a numeric field -> failure by command\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\").failOnUnsupportedField(true)), SearchPhaseExecutionException.class);\n\n        // flt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (!failOnUnsupportedField) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","id":36819,"modified_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (failOnUnsupportedField != null) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (!failOnUnsupportedField) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n    }","id":36820,"modified_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(FuzzyLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"fuzzyLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (maxQueryTerms != null) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (minSimilarity != null) {\n            builder.field(\"min_similarity\", minSimilarity);\n        }\n        if (prefixLength != null) {\n            builder.field(\"prefix_length\", prefixLength);\n        }\n        if (ignoreTF != null) {\n            builder.field(\"ignore_tf\", ignoreTF);\n        }\n        if (boost != null) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (failOnUnsupportedField != null) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // Implicit list of fields -> ignore numeric fields\n        SearchResponse searchResponse = client().prepareMoreLikeThis(\"test\", \"type\", \"1\").setMinDocFreq(1).setMinTermFreq(1).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1L));\n\n        // Explicit list of fields including numeric fields -> fail\n        try {\n            searchResponse = client().prepareMoreLikeThis(\"test\", \"type\", \"1\").setField(\"string_value\", \"int_value\").execute().actionGet();\n            fail();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // mlt query with no field -> OK\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery().likeText(\"index\").minTermFreq(1).minDocFreq(1)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt query with string fields\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\").likeText(\"index\").minTermFreq(1).minDocFreq(1)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt query with at least a numeric field -> fail\n        try {\n            searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")).execute().actionGet();\n            fail();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // mlt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt field query on a numeric field -> failure\n        try {\n            searchResponse = client().prepareSearch().setQuery(moreLikeThisFieldQuery(\"int_value\").likeText(\"42\").minTermFreq(1).minDocFreq(1)).execute().actionGet();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // mlt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisFieldQuery(\"int_value\").likeText(\"42\").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","id":36821,"modified_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // Implicit list of fields -> ignore numeric fields\n        SearchResponse searchResponse = client().prepareMoreLikeThis(\"test\", \"type\", \"1\").setMinDocFreq(1).setMinTermFreq(1).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1L));\n\n        // Explicit list of fields including numeric fields -> fail\n        assertThrows(client().prepareMoreLikeThis(\"test\", \"type\", \"1\").setField(\"string_value\", \"int_value\"), SearchPhaseExecutionException.class);\n\n        // mlt query with no field -> OK\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery().likeText(\"index\").minTermFreq(1).minDocFreq(1)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt query with string fields\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\").likeText(\"index\").minTermFreq(1).minDocFreq(1)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt query with at least a numeric field -> fail by default\n        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")), SearchPhaseExecutionException.class);\n\n        // mlt query with at least a numeric field -> fail by command\n        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(true)), SearchPhaseExecutionException.class);\n\n\n        // mlt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).get();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // mlt field query on a numeric field -> failure by default\n        assertThrows(client().prepareSearch().setQuery(moreLikeThisFieldQuery(\"int_value\").likeText(\"42\").minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);\n\n        // mlt field query on a numeric field -> failure by command\n        assertThrows(client().prepareSearch().setQuery(moreLikeThisFieldQuery(\"int_value\").likeText(\"42\").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(true)),\n                SearchPhaseExecutionException.class);\n\n        // mlt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(moreLikeThisFieldQuery(\"int_value\").likeText(\"42\").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThisField requires 'like_text' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (!failOnUnsupportedField) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","id":36822,"modified_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisFieldQueryParser.NAME);\n        builder.startObject(name);\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThisField requires 'like_text' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (failOnUnsupportedField != null) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n        builder.endObject();\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (!failOnUnsupportedField) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n    }","id":36823,"modified_method":"@Override\n    protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(MoreLikeThisQueryParser.NAME);\n        if (fields != null) {\n            builder.startArray(\"fields\");\n            for (String field : fields) {\n                builder.value(field);\n            }\n            builder.endArray();\n        }\n        if (likeText == null) {\n            throw new QueryBuilderException(\"moreLikeThis requires 'likeText' to be provided\");\n        }\n        builder.field(\"like_text\", likeText);\n        if (percentTermsToMatch != -1) {\n            builder.field(\"percent_terms_to_match\", percentTermsToMatch);\n        }\n        if (minTermFreq != -1) {\n            builder.field(\"min_term_freq\", minTermFreq);\n        }\n        if (maxQueryTerms != -1) {\n            builder.field(\"max_query_terms\", maxQueryTerms);\n        }\n        if (stopWords != null && stopWords.length > 0) {\n            builder.startArray(\"stop_words\");\n            for (String stopWord : stopWords) {\n                builder.value(stopWord);\n            }\n            builder.endArray();\n        }\n        if (minDocFreq != -1) {\n            builder.field(\"min_doc_freq\", minDocFreq);\n        }\n        if (maxDocFreq != -1) {\n            builder.field(\"max_doc_freq\", maxDocFreq);\n        }\n        if (minWordLen != -1) {\n            builder.field(\"min_word_len\", minWordLen);\n        }\n        if (maxWordLen != -1) {\n            builder.field(\"max_word_len\", maxWordLen);\n        }\n        if (boostTerms != -1) {\n            builder.field(\"boost_terms\", boostTerms);\n        }\n        if (boost != -1) {\n            builder.field(\"boost\", boost);\n        }\n        if (analyzer != null) {\n            builder.field(\"analyzer\", analyzer);\n        }\n        if (failOnUnsupportedField != null) {\n            builder.field(\"fail_on_unsupported_field\", failOnUnsupportedField);\n        }\n        builder.endObject();\n    }","commit_id":"e0e6a58357e7b8c7552fecd3786826b3a6142497","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Test that a breaker correctly redistributes to a different breaker, in\n     * this case, the fielddata breaker borrows space from the request breaker\n     */\n    @Test\n    public void testParentChecking() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        Client client = client();\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, reqs);\n\n        // We need the request limit beforehand, just from a single node because the limit should always be the same\n        long beforeReqLimit = client.admin().cluster().prepareNodesStats().setBreaker(true).get()\n                .getNodes()[0].getBreaker().getStats(CircuitBreaker.Name.REQUEST).getLimit();\n\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, \"10b\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings).execute().actionGet();\n\n        // Perform a search to load field data for the \"test\" field\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n            fail(\"should have thrown an exception\");\n        } catch (Exception e) {\n            String errMsg = \"[FIELDDATA] Data too large, data for [test] would be larger than limit of [10/10b]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n\n        assertFailures(client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC),\n                RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [10/10b]\"));\n\n        // Adjust settings so the parent breaker will fail, but the fielddata breaker doesn't\n        resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING, \"15b\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, \"90%\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings).execute().actionGet();\n\n        // Perform a search to load field data for the \"test\" field\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n            fail(\"should have thrown an exception\");\n        } catch (Exception e) {\n            String errMsg = \"[PARENT] Data too large, data for [test] would be larger than limit of [15/15b]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n    }","id":36824,"modified_method":"/**\n     * Test that a breaker correctly redistributes to a different breaker, in\n     * this case, the fielddata breaker borrows space from the request breaker\n     */\n    @Test\n    public void testParentChecking() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        Client client = client();\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, reqs);\n\n        // We need the request limit beforehand, just from a single node because the limit should always be the same\n        long beforeReqLimit = client.admin().cluster().prepareNodesStats().setBreaker(true).get()\n                .getNodes()[0].getBreaker().getStats(CircuitBreaker.Name.REQUEST).getLimit();\n\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, \"10b\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        assertAcked(client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings));\n\n        // Perform a search to load field data for the \"test\" field\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n            fail(\"should have thrown an exception\");\n        } catch (Exception e) {\n            String errMsg = \"[FIELDDATA] Data too large, data for [test] would be larger than limit of [10/10b]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n\n        assertFailures(client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC),\n                RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [10/10b]\"));\n\n        // Adjust settings so the parent breaker will fail, but the fielddata breaker doesn't\n        resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING, \"15b\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, \"90%\")\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings).execute().actionGet();\n\n        // Perform a search to load field data for the \"test\" field\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n            fail(\"should have thrown an exception\");\n        } catch (Exception e) {\n            String errMsg = \"[PARENT] Data too large, data for [test] would be larger than limit of [15/15b]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n    }","commit_id":"1d8fd0fc04f0b582976beec1d6d78ebfcfcbb833","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testMemoryBreaker() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        final Client client = client();\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, false, true, reqs);\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        SearchRequestBuilder searchRequest = client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC);\n        searchRequest.get();\n\n        // clear field data cache (thus setting the loaded field data back to 0)\n        client.admin().indices().prepareClearCache(\"cb-test\").setFieldDataCache(true).execute().actionGet();\n\n        // Update circuit breaker settings\n        Settings settings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, randomRidiculouslySmallLimit())\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.05)\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(settings).execute().actionGet();\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        // again, this time it should trip the breaker\n        assertFailures(searchRequest, RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [100/100b]\"));\n\n        NodesStatsResponse stats = client.admin().cluster().prepareNodesStats().setBreaker(true).get();\n        int breaks = 0;\n        for (NodeStats stat : stats.getNodes()) {\n            CircuitBreakerStats breakerStats = stat.getBreaker().getStats(CircuitBreaker.Name.FIELDDATA);\n            breaks += breakerStats.getTrippedCount();\n        }\n        assertThat(breaks, greaterThanOrEqualTo(1));\n    }","id":36825,"modified_method":"@Test\n    public void testMemoryBreaker() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        final Client client = client();\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, false, true, reqs);\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        SearchRequestBuilder searchRequest = client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC);\n        searchRequest.get();\n\n        // clear field data cache (thus setting the loaded field data back to 0)\n        clearFieldData();\n\n        // Update circuit breaker settings\n        Settings settings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, randomRidiculouslySmallLimit())\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.05)\n                .build();\n        assertAcked(client.admin().cluster().prepareUpdateSettings().setTransientSettings(settings));\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        // again, this time it should trip the breaker\n        assertFailures(searchRequest, RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [100/100b]\"));\n\n        NodesStatsResponse stats = client.admin().cluster().prepareNodesStats().setBreaker(true).get();\n        int breaks = 0;\n        for (NodeStats stat : stats.getNodes()) {\n            CircuitBreakerStats breakerStats = stat.getBreaker().getStats(CircuitBreaker.Name.FIELDDATA);\n            breaks += breakerStats.getTrippedCount();\n        }\n        assertThat(breaks, greaterThanOrEqualTo(1));\n    }","commit_id":"1d8fd0fc04f0b582976beec1d6d78ebfcfcbb833","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testRamAccountingTermsEnum() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        final Client client = client();\n\n        // Create an index where the mappings have a field data filter\n        assertAcked(prepareCreate(\"ramtest\").setSource(\"{\\\"mappings\\\": {\\\"type\\\": {\\\"properties\\\": {\\\"test\\\": \" +\n                \"{\\\"type\\\": \\\"string\\\",\\\"fielddata\\\": {\\\"filter\\\": {\\\"regex\\\": {\\\"pattern\\\": \\\"^value.*\\\"}}}}}}}}\"));\n\n        ensureGreen(TimeValue.timeValueSeconds(10), \"ramtest\");\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"ramtest\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, reqs);\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        client.prepareSearch(\"ramtest\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n\n        // clear field data cache (thus setting the loaded field data back to 0)\n        client.admin().indices().prepareClearCache(\"ramtest\").setFieldDataCache(true).execute().actionGet();\n\n        // Update circuit breaker settings\n        Settings settings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, randomRidiculouslySmallLimit())\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.05)\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(settings).execute().actionGet();\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        // again, this time it should trip the breaker\n        assertFailures(client.prepareSearch(\"ramtest\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC),\n                RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [100/100b]\"));\n\n        NodesStatsResponse stats = client.admin().cluster().prepareNodesStats().setBreaker(true).get();\n        int breaks = 0;\n        for (NodeStats stat : stats.getNodes()) {\n            CircuitBreakerStats breakerStats = stat.getBreaker().getStats(CircuitBreaker.Name.FIELDDATA);\n            breaks += breakerStats.getTrippedCount();\n        }\n        assertThat(breaks, greaterThanOrEqualTo(1));\n    }","id":36826,"modified_method":"@Test\n    public void testRamAccountingTermsEnum() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        final Client client = client();\n\n        // Create an index where the mappings have a field data filter\n        assertAcked(prepareCreate(\"ramtest\").setSource(\"{\\\"mappings\\\": {\\\"type\\\": {\\\"properties\\\": {\\\"test\\\": \" +\n                \"{\\\"type\\\": \\\"string\\\",\\\"fielddata\\\": {\\\"filter\\\": {\\\"regex\\\": {\\\"pattern\\\": \\\"^value.*\\\"}}}}}}}}\"));\n\n        ensureGreen(TimeValue.timeValueSeconds(10), \"ramtest\");\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"ramtest\", \"type\", Long.toString(id)).setSource(\"test\", \"value\" + id));\n        }\n        indexRandom(true, reqs);\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        client.prepareSearch(\"ramtest\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC).get();\n\n        // clear field data cache (thus setting the loaded field data back to 0)\n        clearFieldData();\n\n        // Update circuit breaker settings\n        Settings settings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING, randomRidiculouslySmallLimit())\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.05)\n                .build();\n        assertAcked(client.admin().cluster().prepareUpdateSettings().setTransientSettings(settings));\n\n        // execute a search that loads field data (sorting on the \"test\" field)\n        // again, this time it should trip the breaker\n        assertFailures(client.prepareSearch(\"ramtest\").setQuery(matchAllQuery()).addSort(\"test\", SortOrder.DESC),\n                RestStatus.INTERNAL_SERVER_ERROR,\n                containsString(\"Data too large, data for [test] would be larger than limit of [100/100b]\"));\n\n        NodesStatsResponse stats = client.admin().cluster().prepareNodesStats().setBreaker(true).get();\n        int breaks = 0;\n        for (NodeStats stat : stats.getNodes()) {\n            CircuitBreakerStats breakerStats = stat.getBreaker().getStats(CircuitBreaker.Name.FIELDDATA);\n            breaks += breakerStats.getTrippedCount();\n        }\n        assertThat(breaks, greaterThanOrEqualTo(1));\n    }","commit_id":"1d8fd0fc04f0b582976beec1d6d78ebfcfcbb833","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testRequestBreaker() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        Client client = client();\n\n        // Make request breaker limited to a small amount\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING, \"10b\")\n                .build();\n        client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings).execute().actionGet();\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", id));\n        }\n        indexRandom(true, reqs);\n\n        // A cardinality aggregation uses BigArrays and thus the REQUEST breaker\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addAggregation(cardinality(\"card\").field(\"test\")).get();\n            fail(\"aggregation should have tripped the breaker\");\n        } catch (Exception e) {\n            String errMsg = \"CircuitBreakingException[[REQUEST] Data too large, data for [<reused_arrays>] would be larger than limit of [10/10b]]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n    }","id":36827,"modified_method":"@Test\n    public void testRequestBreaker() throws Exception {\n        if (noopBreakerUsed()) {\n            logger.info(\"--> noop breakers used, skipping test\");\n            return;\n        }\n        assertAcked(prepareCreate(\"cb-test\", 1, settingsBuilder().put(SETTING_NUMBER_OF_REPLICAS, between(0, 1))));\n        Client client = client();\n\n        // Make request breaker limited to a small amount\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING, \"10b\")\n                .build();\n        assertAcked(client.admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings));\n\n        // index some different terms so we have some field data for loading\n        int docCount = scaledRandomIntBetween(300, 1000);\n        List<IndexRequestBuilder> reqs = newArrayList();\n        for (long id = 0; id < docCount; id++) {\n            reqs.add(client.prepareIndex(\"cb-test\", \"type\", Long.toString(id)).setSource(\"test\", id));\n        }\n        indexRandom(true, reqs);\n\n        // A cardinality aggregation uses BigArrays and thus the REQUEST breaker\n        try {\n            client.prepareSearch(\"cb-test\").setQuery(matchAllQuery()).addAggregation(cardinality(\"card\").field(\"test\")).get();\n            fail(\"aggregation should have tripped the breaker\");\n        } catch (Exception e) {\n            String errMsg = \"CircuitBreakingException[[REQUEST] Data too large, data for [<reused_arrays>] would be larger than limit of [10/10b]]\";\n            assertThat(\"Exception: \" + ExceptionsHelper.unwrapCause(e) + \" should contain a CircuitBreakingException\",\n                    ExceptionsHelper.unwrapCause(e).getMessage().contains(errMsg), equalTo(true));\n        }\n    }","commit_id":"1d8fd0fc04f0b582976beec1d6d78ebfcfcbb833","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/** Reset all breaker settings back to their defaults */\n    private void reset() {\n        logger.info(\"--> resetting breaker settings\");\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_FIELDDATA_BREAKER_LIMIT)\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_FIELDDATA_OVERHEAD_CONSTANT)\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_REQUEST_BREAKER_LIMIT)\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        client().admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings).execute().actionGet();\n    }","id":36828,"modified_method":"/** Reset all breaker settings back to their defaults */\n    private void reset() {\n        logger.info(\"--> resetting breaker settings\");\n        Settings resetSettings = settingsBuilder()\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_LIMIT_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_FIELDDATA_BREAKER_LIMIT)\n                .put(HierarchyCircuitBreakerService.FIELDDATA_CIRCUIT_BREAKER_OVERHEAD_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_FIELDDATA_OVERHEAD_CONSTANT)\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,\n                        HierarchyCircuitBreakerService.DEFAULT_REQUEST_BREAKER_LIMIT)\n                .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_OVERHEAD_SETTING, 1.0)\n                .build();\n        assertAcked(client().admin().cluster().prepareUpdateSettings().setTransientSettings(resetSettings));\n    }","commit_id":"1d8fd0fc04f0b582976beec1d6d78ebfcfcbb833","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDeletePercolatorType() throws Exception {\n        DeleteIndexResponse deleteIndexResponse = client().admin().indices().prepareDelete(\"_all\").execute().actionGet();\n        assertThat(\"Delete Index failed - not acked\", deleteIndexResponse.isAcknowledged(), equalTo(true));\n        ensureGreen();\n\n        client().admin().indices().prepareCreate(\"test1\").execute().actionGet();\n        client().admin().indices().prepareCreate(\"test2\").execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test1\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test2\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 2l);\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test1\").setType(PercolatorService.TYPE_NAME));\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test2\").setType(PercolatorService.TYPE_NAME));\n        // Percolate api should return 0 matches, because all docs in _percolate type have been removed.\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 0l);\n    }","id":36829,"modified_method":"@Test\n    public void testDeletePercolatorType() throws Exception {\n        assertAcked(client().admin().indices().prepareCreate(\"test1\"));\n        assertAcked(client().admin().indices().prepareCreate(\"test2\"));\n\n        client().prepareIndex(\"test1\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test2\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 2l);\n\n        awaitBusy(new Predicate<Object>() {\n            @Override\n            public boolean apply(Object o) {\n                GetMappingsResponse getMappingsResponse = client().admin().indices().prepareGetMappings(\"test1\", \"test2\").get();\n                boolean hasPercolatorType = getMappingsResponse.getMappings().get(\"test1\").containsKey(PercolatorService.TYPE_NAME);\n                if (hasPercolatorType) {\n                    return getMappingsResponse.getMappings().get(\"test2\").containsKey(PercolatorService.TYPE_NAME);\n                } else {\n                    return false;\n                }\n            }\n        });\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test1\").setType(PercolatorService.TYPE_NAME));\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 1l);\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test2\").setType(PercolatorService.TYPE_NAME));\n        // Percolate api should return 0 matches, because all docs in _percolate type have been removed.\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertMatchCount(response, 0l);\n    }","commit_id":"cb75830c68ef0e57c820247027f6deacf9f7a998","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testNullShape() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\", \"aNullshape\").setSource(\"{\\\"location\\\": null}\").execute().actionGet();\n        GetResponse result = client().prepareGet(\"test\", \"type1\", \"aNullshape\").execute().actionGet();\n        assertThat(result.getField(\"location\"), nullValue());\n    }","id":36830,"modified_method":"@Test\n    public void testNullShape() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        ensureGreen();\n\n        indexRandom(false, client().prepareIndex(\"test\", \"type1\", \"aNullshape\").setSource(\"{\\\"location\\\": null}\"));\n        GetResponse result = client().prepareGet(\"test\", \"type1\", \"aNullshape\").execute().actionGet();\n        assertThat(result.getField(\"location\"), nullValue());\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test // Issue 2944\n    public void testThatShapeIsReturnedEvenWhenExclusionsAreSet() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .endObject().endObject()\n                .startObject(\"_source\")\n                .startArray(\"excludes\").value(\"nonExistingField\").endArray()\n                .endObject()\n                .endObject().endObject()\n                .string();\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Document 1\")\n                .startObject(\"location\")\n                .field(\"type\", \"envelope\")\n                .startArray(\"coordinates\").startArray().value(-45.0).value(45).endArray().startArray().value(45).value(-45).endArray().endArray()\n                .endObject()\n                .endObject()).execute().actionGet();\n\n        client().admin().indices().prepareRefresh(\"test\").execute().actionGet();\n\n        SearchResponse searchResponse = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1L));\n\n        Map<String, Object> indexedMap = searchResponse.getHits().getAt(0).sourceAsMap();\n        assertThat(indexedMap.get(\"location\"), instanceOf(Map.class));\n        Map<String, Object> locationMap = (Map<String, Object>) indexedMap.get(\"location\");\n        assertThat(locationMap.get(\"coordinates\"), instanceOf(List.class));\n        List<List<Number>> coordinates = (List<List<Number>>) locationMap.get(\"coordinates\");\n        assertThat(coordinates.size(), equalTo(2));\n        assertThat(coordinates.get(0).size(), equalTo(2));\n        assertThat(coordinates.get(0).get(0).doubleValue(), equalTo(-45.0));\n        assertThat(coordinates.get(0).get(1).doubleValue(), equalTo(45.0));\n        assertThat(coordinates.get(1).size(), equalTo(2));\n        assertThat(coordinates.get(1).get(0).doubleValue(), equalTo(45.0));\n        assertThat(coordinates.get(1).get(1).doubleValue(), equalTo(-45.0));\n        assertThat(locationMap.size(), equalTo(2));\n    }","id":36831,"modified_method":"@Test // Issue 2944\n    public void testThatShapeIsReturnedEvenWhenExclusionsAreSet() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .endObject().endObject()\n                .startObject(\"_source\")\n                .startArray(\"excludes\").value(\"nonExistingField\").endArray()\n                .endObject()\n                .endObject().endObject()\n                .string();\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        ensureGreen();\n\n        indexRandom(true,\n                client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                    .field(\"name\", \"Document 1\")\n                    .startObject(\"location\")\n                    .field(\"type\", \"envelope\")\n                    .startArray(\"coordinates\").startArray().value(-45.0).value(45).endArray().startArray().value(45).value(-45).endArray().endArray()\n                    .endObject()\n                    .endObject()));\n\n        SearchResponse searchResponse = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();\n        assertThat(searchResponse.getHits().totalHits(), equalTo(1L));\n\n        Map<String, Object> indexedMap = searchResponse.getHits().getAt(0).sourceAsMap();\n        assertThat(indexedMap.get(\"location\"), instanceOf(Map.class));\n        Map<String, Object> locationMap = (Map<String, Object>) indexedMap.get(\"location\");\n        assertThat(locationMap.get(\"coordinates\"), instanceOf(List.class));\n        List<List<Number>> coordinates = (List<List<Number>>) locationMap.get(\"coordinates\");\n        assertThat(coordinates.size(), equalTo(2));\n        assertThat(coordinates.get(0).size(), equalTo(2));\n        assertThat(coordinates.get(0).get(0).doubleValue(), equalTo(-45.0));\n        assertThat(coordinates.get(0).get(1).doubleValue(), equalTo(45.0));\n        assertThat(coordinates.get(1).size(), equalTo(2));\n        assertThat(coordinates.get(1).get(0).doubleValue(), equalTo(45.0));\n        assertThat(coordinates.get(1).get(1).doubleValue(), equalTo(-45.0));\n        assertThat(locationMap.size(), equalTo(2));\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testIndexedShapeReference() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Document 1\")\n                .startObject(\"location\")\n                .field(\"type\", \"point\")\n                .startArray(\"coordinates\").value(-30).value(-30).endArray()\n                .endObject()\n                .endObject()).execute().actionGet();\n\n        refresh();\n\n        ShapeBuilder shape = ShapeBuilder.newEnvelope().topLeft(-45, 45).bottomRight(45, -45);\n        XContentBuilder shapeContent = jsonBuilder().startObject()\n                .field(\"shape\", shape);\n        shapeContent.endObject();\n        createIndex(\"shapes\");\n        ensureGreen();\n        client().prepareIndex(\"shapes\", \"shape_type\", \"Big_Rectangle\").setSource(shapeContent).execute().actionGet();\n        refresh();\n\n        SearchResponse searchResponse = client().prepareSearch(\"test\")\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", \"Big_Rectangle\", \"shape_type\")))\n                .execute().actionGet();\n\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n\n        searchResponse = client().prepareSearch()\n                .setQuery(geoShapeQuery(\"location\", \"Big_Rectangle\", \"shape_type\"))\n                .execute().actionGet();\n\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n    }","id":36832,"modified_method":"@Test\n    public void testIndexedShapeReference() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        createIndex(\"shapes\");\n        ensureGreen();\n\n        ShapeBuilder shape = ShapeBuilder.newEnvelope().topLeft(-45, 45).bottomRight(45, -45);\n\n        indexRandom(true,\n            client().prepareIndex(\"shapes\", \"shape_type\", \"Big_Rectangle\").setSource(jsonBuilder().startObject()\n                .field(\"shape\", shape).endObject()),\n            client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Document 1\")\n                .startObject(\"location\")\n                .field(\"type\", \"point\")\n                .startArray(\"coordinates\").value(-30).value(-30).endArray()\n                .endObject()\n                .endObject()));\n\n        SearchResponse searchResponse = client().prepareSearch(\"test\")\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", \"Big_Rectangle\", \"shape_type\")))\n                .execute().actionGet();\n\n        assertSearchResponse(searchResponse);\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n\n        searchResponse = client().prepareSearch(\"test\")\n                .setQuery(geoShapeQuery(\"location\", \"Big_Rectangle\", \"shape_type\"))\n                .execute().actionGet();\n\n        assertSearchResponse(searchResponse);\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testIndexPointsFilterRectangle() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Document 1\")\n                .startObject(\"location\")\n                .field(\"type\", \"point\")\n                .startArray(\"coordinates\").value(-30).value(-30).endArray()\n                .endObject()\n                .endObject()).execute().actionGet();\n\n        client().prepareIndex(\"test\", \"type1\", \"2\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Document 2\")\n                .startObject(\"location\")\n                .field(\"type\", \"point\")\n                .startArray(\"coordinates\").value(-45).value(-50).endArray()\n                .endObject()\n                .endObject()).execute().actionGet();\n\n        refresh();\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        ShapeBuilder shape = ShapeBuilder.newEnvelope().topLeft(-45, 45).bottomRight(45, -45);\n\n        SearchResponse searchResponse = client().prepareSearch()\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", shape)))\n                .execute().actionGet();\n\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n\n        searchResponse = client().prepareSearch()\n                .setQuery(geoShapeQuery(\"location\", shape))\n                .execute().actionGet();\n\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n    }","id":36833,"modified_method":"@Test\n    public void testIndexPointsFilterRectangle() throws Exception {\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        ensureGreen();\n\n        indexRandom(true,\n\n                client().prepareIndex(\"test\", \"type1\", \"1\").setSource(jsonBuilder().startObject()\n                        .field(\"name\", \"Document 1\")\n                        .startObject(\"location\")\n                        .field(\"type\", \"point\")\n                        .startArray(\"coordinates\").value(-30).value(-30).endArray()\n                        .endObject()\n                        .endObject()),\n\n                client().prepareIndex(\"test\", \"type1\", \"2\").setSource(jsonBuilder().startObject()\n                        .field(\"name\", \"Document 2\")\n                        .startObject(\"location\")\n                        .field(\"type\", \"point\")\n                        .startArray(\"coordinates\").value(-45).value(-50).endArray()\n                        .endObject()\n                        .endObject()));\n\n        ShapeBuilder shape = ShapeBuilder.newEnvelope().topLeft(-45, 45).bottomRight(45, -45);\n\n        SearchResponse searchResponse = client().prepareSearch()\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", shape)))\n                .execute().actionGet();\n\n        assertSearchResponse(searchResponse);\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n\n        searchResponse = client().prepareSearch()\n                .setQuery(geoShapeQuery(\"location\", shape))\n                .execute().actionGet();\n\n        assertSearchResponse(searchResponse);\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"1\"));\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testShapeFetching_path() throws IOException {\n        prepareCreate(\"shapes\").execute().actionGet();\n        prepareCreate(\"test\").addMapping(\"type\", \"location\", \"type=geo_shape\").execute().actionGet();\n        String location = \"\\\"location\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}\";\n        client().prepareIndex(\"shapes\", \"type\", \"1\")\n                .setSource(\n                        String.format(\n                                Locale.ROOT, \"{ %s, \\\"1\\\" : { %s, \\\"2\\\" : { %s, \\\"3\\\" : { %s } }} }\", location, location, location, location\n                        )\n                ).get();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().startObject(\"location\")\n                        .field(\"type\", \"polygon\")\n                        .startArray(\"coordinates\").startArray()\n                        .startArray().value(-20).value(-20).endArray()\n                        .startArray().value(20).value(-20).endArray()\n                        .startArray().value(20).value(20).endArray()\n                        .startArray().value(-20).value(20).endArray()\n                        .startArray().value(-20).value(-20).endArray()\n                        .endArray().endArray()\n                        .endObject().endObject()).get();\n        client().admin().indices().prepareRefresh(\"test\", \"shapes\").execute().actionGet();\n\n        GeoShapeFilterBuilder filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"location\");\n        SearchResponse result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.3.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertHitCount(result, 1);\n\n        // now test the query variant\n        GeoShapeQueryBuilder query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.3.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertHitCount(result, 1);\n    }","id":36834,"modified_method":"@Test\n    public void testShapeFetching_path() throws Exception {\n        createIndex(\"shapes\");\n        assertAcked(prepareCreate(\"test\").addMapping(\"type\", \"location\", \"type=geo_shape\"));\n\n        String location = \"\\\"location\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}\";\n        indexRandom(true,\n                client().prepareIndex(\"shapes\", \"type\", \"1\")\n                .setSource(\n                        String.format(\n                                Locale.ROOT, \"{ %s, \\\"1\\\" : { %s, \\\"2\\\" : { %s, \\\"3\\\" : { %s } }} }\", location, location, location, location\n                        )\n                ),\n                client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().startObject(\"location\")\n                        .field(\"type\", \"polygon\")\n                        .startArray(\"coordinates\").startArray()\n                        .startArray().value(-20).value(-20).endArray()\n                        .startArray().value(20).value(-20).endArray()\n                        .startArray().value(20).value(20).endArray()\n                        .startArray().value(-20).value(20).endArray()\n                        .startArray().value(-20).value(-20).endArray()\n                        .endArray().endArray()\n                        .endObject().endObject()));\n        ensureSearchable(\"test\", \"shapes\");\n\n        GeoShapeFilterBuilder filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"location\");\n        SearchResponse result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        filter = FilterBuilders.geoShapeFilter(\"location\", \"1\", \"type\", ShapeRelation.INTERSECTS)\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.3.location\");\n        result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery())\n                .setPostFilter(filter).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n\n        // now test the query variant\n        GeoShapeQueryBuilder query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n        query = QueryBuilders.geoShapeQuery(\"location\", \"1\", \"type\")\n                .indexedShapeIndex(\"shapes\")\n                .indexedShapePath(\"1.2.3.location\");\n        result = client().prepareSearch(\"test\").setQuery(query).get();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testParsingMultipleShapes() throws IOException {\n        String mapping = XContentFactory.jsonBuilder()\n                .startObject()\n                .startObject(\"type1\")\n                .startObject(\"properties\")\n                .startObject(\"location1\")\n                .field(\"type\", \"geo_shape\")\n                .endObject()\n                .startObject(\"location2\")\n                .field(\"type\", \"geo_shape\")\n                .endObject()\n                .endObject()\n                .endObject()\n                .endObject()\n                .string();\n\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureYellow();\n\n        String p1 = \"\\\"location1\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}\";\n        String p2 = \"\\\"location2\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-20,-20],[20,-20],[20,20],[-20,20],[-20,-20]]]}\";\n        String o1 = \"{\" + p1 + \", \" + p2 + \"}\";\n\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(o1).execute().actionGet();\n        client().admin().indices().prepareRefresh(\"test\").execute().actionGet();\n\n        String filter = \"{\\\"geo_shape\\\": {\\\"location2\\\": {\\\"indexed_shape\\\": {\"\n                + \"\\\"id\\\": \\\"1\\\",\"\n                + \"\\\"type\\\": \\\"type1\\\",\"\n                + \"\\\"index\\\": \\\"test\\\",\"\n                + \"\\\"path\\\": \\\"location2\\\"\"\n                + \"}}}}\";\n\n        SearchResponse result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();\n        assertHitCount(result, 1);\n    }","id":36835,"modified_method":"@Test\n    public void testParsingMultipleShapes() throws Exception {\n        String mapping = XContentFactory.jsonBuilder()\n                .startObject()\n                .startObject(\"type1\")\n                .startObject(\"properties\")\n                .startObject(\"location1\")\n                .field(\"type\", \"geo_shape\")\n                .endObject()\n                .startObject(\"location2\")\n                .field(\"type\", \"geo_shape\")\n                .endObject()\n                .endObject()\n                .endObject()\n                .endObject()\n                .string();\n\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        ensureYellow();\n\n        String p1 = \"\\\"location1\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}\";\n        String p2 = \"\\\"location2\\\" : {\\\"type\\\":\\\"polygon\\\", \\\"coordinates\\\":[[[-20,-20],[20,-20],[20,20],[-20,20],[-20,-20]]]}\";\n        String o1 = \"{\" + p1 + \", \" + p2 + \"}\";\n\n        indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"1\").setSource(o1));\n\n        String filter = \"{\\\"geo_shape\\\": {\\\"location2\\\": {\\\"indexed_shape\\\": {\"\n                + \"\\\"id\\\": \\\"1\\\",\"\n                + \"\\\"type\\\": \\\"type1\\\",\"\n                + \"\\\"index\\\": \\\"test\\\",\"\n                + \"\\\"path\\\": \\\"location2\\\"\"\n                + \"}}}}\";\n\n        SearchResponse result = client().prepareSearch(\"test\").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();\n        assertSearchResponse(result);\n        assertHitCount(result, 1);\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testEdgeCases() throws Exception {\n\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        prepareCreate(\"test\").addMapping(\"type1\", mapping).execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\", \"blakely\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Blakely Island\")\n                .startObject(\"location\")\n                .field(\"type\", \"polygon\")\n                .startArray(\"coordinates\").startArray()\n                .startArray().value(-122.83).value(48.57).endArray()\n                .startArray().value(-122.77).value(48.56).endArray()\n                .startArray().value(-122.79).value(48.53).endArray()\n                .startArray().value(-122.83).value(48.57).endArray() // close the polygon\n                .endArray().endArray()\n                .endObject()\n                .endObject()).execute().actionGet();\n\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        ShapeBuilder query = ShapeBuilder.newEnvelope().topLeft(-122.88, 48.62).bottomRight(-122.82, 48.54);\n\n        // This search would fail if both geoshape indexing and geoshape filtering\n        // used the bottom-level optimization in SpatialPrefixTree#recursiveGetNodes.\n        SearchResponse searchResponse = client().prepareSearch()\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", query)))\n                .execute().actionGet();\n\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"blakely\"));\n    }","id":36836,"modified_method":"@Test\n    public void testEdgeCases() throws Exception {\n\n        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n                .startObject(\"properties\").startObject(\"location\")\n                .field(\"type\", \"geo_shape\")\n                .field(\"tree\", \"quadtree\")\n                .endObject().endObject()\n                .endObject().endObject().string();\n        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", mapping));\n        ensureGreen();\n\n        indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"blakely\").setSource(jsonBuilder().startObject()\n                .field(\"name\", \"Blakely Island\")\n                .startObject(\"location\")\n                .field(\"type\", \"polygon\")\n                .startArray(\"coordinates\").startArray()\n                .startArray().value(-122.83).value(48.57).endArray()\n                .startArray().value(-122.77).value(48.56).endArray()\n                .startArray().value(-122.79).value(48.53).endArray()\n                .startArray().value(-122.83).value(48.57).endArray() // close the polygon\n                .endArray().endArray()\n                .endObject()\n                .endObject()));\n\n\n        ShapeBuilder query = ShapeBuilder.newEnvelope().topLeft(-122.88, 48.62).bottomRight(-122.82, 48.54);\n\n        // This search would fail if both geoshape indexing and geoshape filtering\n        // used the bottom-level optimization in SpatialPrefixTree#recursiveGetNodes.\n        SearchResponse searchResponse = client().prepareSearch()\n                .setQuery(filteredQuery(matchAllQuery(),\n                        geoIntersectionFilter(\"location\", query)))\n                .execute().actionGet();\n\n        assertSearchResponse(searchResponse);\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));\n        assertThat(searchResponse.getHits().hits().length, equalTo(1));\n        assertThat(searchResponse.getHits().getAt(0).id(), equalTo(\"blakely\"));\n    }","commit_id":"8a09ec0e06a19eae966e4d614e11d3c14613277c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void createIndexAndThenRegisterPercolator() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").setSettings(settingsBuilder().put(\"index.number_of_shards\", 1)).execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> register a query\");\n        client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, \"kuku\")\n                .setSource(jsonBuilder().startObject()\n                        .field(\"color\", \"blue\")\n                        .field(\"query\", termQuery(\"field1\", \"value1\"))\n                        .endObject())\n                .execute().actionGet();\n\n        refresh();\n        CountResponse countResponse = client().prepareCount()\n                .setQuery(matchAllQuery()).setTypes(PercolatorService.TYPE_NAME)\n                .execute().actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n\n        for (int i = 0; i < 10; i++) {\n            PercolateResponse percolate = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type1\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", \"value1\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(percolate.getMatches(), arrayWithSize(1));\n        }\n\n        for (int i = 0; i < 10; i++) {\n            PercolateResponse percolate = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type1\")\n                    .setPreference(\"_local\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", \"value1\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(percolate.getMatches(), arrayWithSize(1));\n        }\n\n\n        logger.info(\"--> delete the index\");\n        client().admin().indices().prepareDelete(\"test\").execute().actionGet();\n        logger.info(\"--> make sure percolated queries for it have been deleted as well\");\n        countResponse = client().prepareCount()\n                .setQuery(matchAllQuery()).setTypes(PercolatorService.TYPE_NAME)\n                .execute().actionGet();\n        assertThat(countResponse.getCount(), equalTo(0l));\n    }","id":36837,"modified_method":"@Test\n    public void createIndexAndThenRegisterPercolator() throws Exception {\n        assertAcked(client().admin().indices().prepareCreate(\"test\").setSettings(settingsBuilder().put(\"index.number_of_shards\", 1)));\n        ensureGreen();\n\n        logger.info(\"--> register a query\");\n        client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, \"kuku\")\n                .setSource(jsonBuilder().startObject()\n                        .field(\"color\", \"blue\")\n                        .field(\"query\", termQuery(\"field1\", \"value1\"))\n                        .endObject())\n                .execute().actionGet();\n\n        refresh();\n        CountResponse countResponse = client().prepareCount()\n                .setQuery(matchAllQuery()).setTypes(PercolatorService.TYPE_NAME)\n                .execute().actionGet();\n        assertThat(countResponse.getCount(), equalTo(1l));\n\n\n        for (int i = 0; i < 10; i++) {\n            PercolateResponse percolate = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type1\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", \"value1\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(percolate.getMatches(), arrayWithSize(1));\n        }\n\n        for (int i = 0; i < 10; i++) {\n            PercolateResponse percolate = client().preparePercolate()\n                    .setIndices(\"test\").setDocumentType(\"type1\")\n                    .setPreference(\"_local\")\n                    .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", \"value1\").endObject().endObject())\n                    .execute().actionGet();\n            assertThat(percolate.getMatches(), arrayWithSize(1));\n        }\n\n\n        logger.info(\"--> delete the index\");\n        client().admin().indices().prepareDelete(\"test\").execute().actionGet();\n        logger.info(\"--> make sure percolated queries for it have been deleted as well\");\n        countResponse = client().prepareCount()\n                .setQuery(matchAllQuery()).setTypes(PercolatorService.TYPE_NAME)\n                .execute().actionGet();\n        assertThat(countResponse.getCount(), equalTo(0l));\n    }","commit_id":"1608ccc373fb0479a299a5db4f2d58a5f7b5e011","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDeletePercolatorType() throws Exception {\n        DeleteIndexResponse deleteIndexResponse = client().admin().indices().prepareDelete().execute().actionGet();\n        assertThat(\"Delete Index failed - not acked\", deleteIndexResponse.isAcknowledged(), equalTo(true));\n        ensureGreen();\n\n        client().admin().indices().prepareCreate(\"test1\").execute().actionGet();\n        client().admin().indices().prepareCreate(\"test2\").execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test1\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test2\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertThat(response.getCount(), equalTo(2l));\n\n        CountDownLatch test1Latch = createCountDownLatch(\"test1\");\n        CountDownLatch test2Latch = createCountDownLatch(\"test2\");\n\n        client().admin().indices().prepareDeleteMapping(\"test1\").setType(PercolatorService.TYPE_NAME).execute().actionGet();\n        test1Latch.await();\n\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertNoFailures(response);\n        assertThat(response.getCount(), equalTo(1l));\n\n        client().admin().indices().prepareDeleteMapping(\"test2\").setType(PercolatorService.TYPE_NAME).execute().actionGet();\n        test2Latch.await();\n\n        // Percolate api should return 0 matches, because all _percolate types have been removed.\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertNoFailures(response);\n        assertThat(response.getCount(), equalTo(0l));\n    }","id":36838,"modified_method":"@Test\n    public void testDeletePercolatorType() throws Exception {\n        DeleteIndexResponse deleteIndexResponse = client().admin().indices().prepareDelete().execute().actionGet();\n        assertThat(\"Delete Index failed - not acked\", deleteIndexResponse.isAcknowledged(), equalTo(true));\n        ensureGreen();\n\n        client().admin().indices().prepareCreate(\"test1\").execute().actionGet();\n        client().admin().indices().prepareCreate(\"test2\").execute().actionGet();\n        ensureGreen();\n\n        client().prepareIndex(\"test1\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test2\", PercolatorService.TYPE_NAME, \"1\")\n                .setSource(jsonBuilder().startObject().field(\"query\", matchAllQuery()).endObject())\n                .execute().actionGet();\n\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertThat(response.getCount(), equalTo(2l));\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test1\").setType(PercolatorService.TYPE_NAME));\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertNoFailures(response);\n        assertThat(response.getCount(), equalTo(1l));\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test2\").setType(PercolatorService.TYPE_NAME));\n        // Percolate api should return 0 matches, because all docs in _percolate type have been removed.\n        response = client().preparePercolate()\n                .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)\n                .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field(\"field1\", \"b\").endObject()))\n                .execute().actionGet();\n        assertNoFailures(response);\n        assertThat(response.getCount(), equalTo(0l));\n    }","commit_id":"1608ccc373fb0479a299a5db4f2d58a5f7b5e011","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    @Slow\n    public void testLoadingPercolateQueriesDuringCloseAndOpen() throws Exception {\n        Settings settings = settingsBuilder()\n                .put(super.indexSettings())\n                .put(\"gateway.type\", \"local\")\n                .build();\n        logger.info(\"--> Starting 2 nodes\");\n        cluster().startNode(settings);\n        cluster().startNode(settings);\n\n        client().admin().indices().prepareDelete().execute().actionGet();\n        ensureGreen();\n\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder().put(\"index.number_of_shards\", 2))\n                .execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> Add dummy docs\");\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"field1\", 0).execute().actionGet();\n        client().prepareIndex(\"test\", \"type2\", \"1\").setSource(\"field1\", \"0\").execute().actionGet();\n\n        logger.info(\"--> register a queries\");\n        for (int i = 1; i <= 100; i++) {\n            client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, Integer.toString(i))\n                    .setSource(jsonBuilder().startObject()\n                            .field(\"query\", rangeQuery(\"field1\").from(0).to(i))\n                                    // The type must be set now, because two fields with the same name exist in different types.\n                                    // Setting the type to `type1`, makes sure that the range query gets parsed to a Lucene NumericRangeQuery.\n                            .field(\"type\", \"type1\")\n                            .endObject())\n                    .execute().actionGet();\n        }\n\n        logger.info(\"--> Percolate doc with field1=95\");\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type1\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", 95).endObject().endObject())\n                .execute().actionGet();\n        assertThat(response.getMatches(), arrayWithSize(6));\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContainingInAnyOrder(\"95\", \"96\", \"97\", \"98\", \"99\", \"100\"));\n\n        logger.info(\"--> Close and open index to trigger percolate queries loading...\");\n        client().admin().indices().prepareClose(\"test\").execute().actionGet();\n        ensureGreen();\n        client().admin().indices().prepareOpen(\"test\").execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> Percolate doc with field1=100\");\n        response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type1\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", 100).endObject().endObject())\n                .execute().actionGet();\n        assertThat(response.getMatches(), arrayWithSize(1));\n        assertThat(response.getMatches()[0].getId().string(), equalTo(\"100\"));\n    }","id":36839,"modified_method":"@Test\n    @Slow\n    public void testLoadingPercolateQueriesDuringCloseAndOpen() throws Exception {\n        Settings settings = settingsBuilder()\n                .put(super.indexSettings())\n                .put(\"gateway.type\", \"local\")\n                .build();\n        logger.info(\"--> Starting 2 nodes\");\n        cluster().startNode(settings);\n        cluster().startNode(settings);\n\n        client().admin().indices().prepareDelete().execute().actionGet();\n        ensureGreen();\n\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder().put(\"index.number_of_shards\", 2))\n                .execute().actionGet();\n        ensureGreen();\n\n        logger.info(\"--> Add dummy docs\");\n        client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"field1\", 0).execute().actionGet();\n        client().prepareIndex(\"test\", \"type2\", \"1\").setSource(\"field1\", \"0\").execute().actionGet();\n\n        logger.info(\"--> register a queries\");\n        for (int i = 1; i <= 100; i++) {\n            client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, Integer.toString(i))\n                    .setSource(jsonBuilder().startObject()\n                            .field(\"query\", rangeQuery(\"field1\").from(0).to(i))\n                                    // The type must be set now, because two fields with the same name exist in different types.\n                                    // Setting the type to `type1`, makes sure that the range query gets parsed to a Lucene NumericRangeQuery.\n                            .field(\"type\", \"type1\")\n                            .endObject())\n                    .execute().actionGet();\n        }\n\n        logger.info(\"--> Percolate doc with field1=95\");\n        PercolateResponse response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type1\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", 95).endObject().endObject())\n                .execute().actionGet();\n        assertThat(response.getMatches(), arrayWithSize(6));\n        assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContainingInAnyOrder(\"95\", \"96\", \"97\", \"98\", \"99\", \"100\"));\n\n        logger.info(\"--> Close and open index to trigger percolate queries loading...\");\n        assertAcked(client().admin().indices().prepareClose(\"test\"));\n        assertAcked(client().admin().indices().prepareOpen(\"test\"));\n        ensureGreen();\n\n        logger.info(\"--> Percolate doc with field1=100\");\n        response = client().preparePercolate()\n                .setIndices(\"test\").setDocumentType(\"type1\")\n                .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field1\", 100).endObject().endObject())\n                .execute().actionGet();\n        assertThat(response.getMatches(), arrayWithSize(1));\n        assertThat(response.getMatches()[0].getId().string(), equalTo(\"100\"));\n    }","commit_id":"1608ccc373fb0479a299a5db4f2d58a5f7b5e011","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void testCloseIndexAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        CloseIndexResponse closeIndexResponse = client().admin().indices().prepareClose(\"test\").execute().actionGet();\n        assertThat(closeIndexResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            ClusterStateResponse clusterStateResponse = client.admin().cluster().prepareState().setLocal(true).execute().actionGet();\n            IndexMetaData indexMetaData = clusterStateResponse.getState().metaData().indices().get(\"test\");\n            assertThat(indexMetaData.getState(), equalTo(IndexMetaData.State.CLOSE));\n        }\n    }","id":36840,"modified_method":"public void testCloseIndexAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        assertAcked(client().admin().indices().prepareClose(\"test\"));\n\n        for (Client client : clients()) {\n            IndexMetaData indexMetaData = getLocalClusterState(client).metaData().indices().get(\"test\");\n            assertThat(indexMetaData.getState(), equalTo(IndexMetaData.State.CLOSE));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testIndicesAliasesAcknowledgement() {\n        createIndex(\"test\");\n\n        //testing acknowledgement when trying to submit an existing alias too\n        //in that case it would not make any change, but we are sure about the cluster state\n        //as the previous operation was acknowledged\n        for (int i = 0; i < 2; i++) {\n            assertAcked(client().admin().indices().prepareAliases().addAlias(\"test\", \"alias\"));\n\n            for (Client client : clients()) {\n                ClusterState clusterState = client.admin().cluster().prepareState().setLocal(true).get().getState();\n                AliasMetaData aliasMetaData = clusterState.metaData().aliases().get(\"alias\").get(\"test\");\n                assertThat(aliasMetaData.alias(), equalTo(\"alias\"));\n            }\n        }\n    }","id":36841,"modified_method":"@Test\n    public void testIndicesAliasesAcknowledgement() {\n        createIndex(\"test\");\n\n        //testing acknowledgement when trying to submit an existing alias too\n        //in that case it would not make any change, but we are sure about the cluster state\n        //as the previous operation was acknowledged\n        for (int i = 0; i < 2; i++) {\n            assertAcked(client().admin().indices().prepareAliases().addAlias(\"test\", \"alias\"));\n\n            for (Client client : clients()) {\n                AliasMetaData aliasMetaData = getLocalClusterState(client).metaData().aliases().get(\"alias\").get(\"test\");\n                assertThat(aliasMetaData.alias(), equalTo(\"alias\"));\n            }\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testOpenIndexAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        CloseIndexResponse closeIndexResponse = client().admin().indices().prepareClose(\"test\").execute().actionGet();\n        assertThat(closeIndexResponse.isAcknowledged(), equalTo(true));\n\n        OpenIndexResponse openIndexResponse= client().admin().indices().prepareOpen(\"test\").execute().actionGet();\n        assertThat(openIndexResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            ClusterStateResponse clusterStateResponse = client.admin().cluster().prepareState().setLocal(true).execute().actionGet();\n            IndexMetaData indexMetaData = clusterStateResponse.getState().metaData().indices().get(\"test\");\n            assertThat(indexMetaData.getState(), equalTo(IndexMetaData.State.OPEN));\n        }\n    }","id":36842,"modified_method":"@Test\n    public void testOpenIndexAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        assertAcked(client().admin().indices().prepareClose(\"test\"));\n\n        assertAcked(client().admin().indices().prepareOpen(\"test\"));\n\n        for (Client client : clients()) {\n            IndexMetaData indexMetaData = getLocalClusterState(client).metaData().indices().get(\"test\");\n            assertThat(indexMetaData.getState(), equalTo(IndexMetaData.State.OPEN));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testUpdateSettingsAcknowledgement() {\n        createIndex(\"test\");\n\n        UpdateSettingsResponse updateSettingsResponse = client().admin().indices().prepareUpdateSettings(\"test\")\n                .setSettings(ImmutableSettings.builder().put(\"refresh_interval\", 9999)).get();\n        assertThat(updateSettingsResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            ClusterStateResponse clusterStateResponse = client.admin().cluster().prepareState().setLocal(true).get();\n            String refreshInterval = clusterStateResponse.getState().metaData().index(\"test\").settings().get(\"index.refresh_interval\");\n            assertThat(refreshInterval, equalTo(\"9999\"));\n        }\n    }","id":36843,"modified_method":"@Test\n    public void testUpdateSettingsAcknowledgement() {\n        createIndex(\"test\");\n\n        assertAcked(client().admin().indices().prepareUpdateSettings(\"test\")\n                .setSettings(ImmutableSettings.builder().put(\"refresh_interval\", 9999)));\n\n        for (Client client : clients()) {\n            String refreshInterval = getLocalClusterState(client).metaData().index(\"test\").settings().get(\"index.refresh_interval\");\n            assertThat(refreshInterval, equalTo(\"9999\"));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testClusterRerouteAcknowledgementDryRun() throws InterruptedException {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n        MoveAllocationCommand moveAllocationCommand = getAllocationCommand();\n\n        ClusterRerouteResponse clusterRerouteResponse = client().admin().cluster().prepareReroute().setDryRun(true).add(moveAllocationCommand).get();\n        assertThat(clusterRerouteResponse.isAcknowledged(), equalTo(true));\n\n        //testing only on master with the latest cluster state as we didn't make any change thus we cannot guarantee that\n        //all nodes hold the same cluster state version. We only know there was no need to change anything, thus no need for ack on this update.\n        ClusterStateResponse clusterStateResponse = client().admin().cluster().prepareState().get();\n        RoutingNode routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.fromNode());\n        boolean found = false;\n        for (MutableShardRouting mutableShardRouting : routingNode) {\n            //the shard that we wanted to move is still on the same node, as we had dryRun flag\n            if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                assertThat(mutableShardRouting.started(), equalTo(true));\n                found = true;\n                break;\n            }\n        }\n        assertThat(found, equalTo(true));\n\n        routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.toNode());\n        for (MutableShardRouting mutableShardRouting : routingNode) {\n            if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                fail(\"shard [\" + mutableShardRouting + \"] shouldn't be on node [\" + moveAllocationCommand.toString() + \"]\");\n            }\n        }\n    }","id":36844,"modified_method":"@Test\n    public void testClusterRerouteAcknowledgementDryRun() throws InterruptedException {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n        MoveAllocationCommand moveAllocationCommand = getAllocationCommand();\n\n        assertAcked(client().admin().cluster().prepareReroute().setDryRun(true).add(moveAllocationCommand));\n\n        //testing only on master with the latest cluster state as we didn't make any change thus we cannot guarantee that\n        //all nodes hold the same cluster state version. We only know there was no need to change anything, thus no need for ack on this update.\n        ClusterStateResponse clusterStateResponse = client().admin().cluster().prepareState().get();\n        RoutingNode routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.fromNode());\n        boolean found = false;\n        for (MutableShardRouting mutableShardRouting : routingNode) {\n            //the shard that we wanted to move is still on the same node, as we had dryRun flag\n            if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                assertThat(mutableShardRouting.started(), equalTo(true));\n                found = true;\n                break;\n            }\n        }\n        assertThat(found, equalTo(true));\n\n        routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.toNode());\n        for (MutableShardRouting mutableShardRouting : routingNode) {\n            if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                fail(\"shard [\" + mutableShardRouting + \"] shouldn't be on node [\" + moveAllocationCommand.toString() + \"]\");\n            }\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testClusterUpdateSettingsAcknowledgement() {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n        NodesInfoResponse nodesInfo = client().admin().cluster().prepareNodesInfo().get();\n        String excludedNodeId = null;\n        for (NodeInfo nodeInfo : nodesInfo) {\n            if (nodeInfo.getNode().isDataNode()) {\n                excludedNodeId = nodesInfo.getAt(0).getNode().id();\n                break;\n            }\n        }\n        assert excludedNodeId != null;\n\n        ClusterUpdateSettingsResponse clusterUpdateSettingsResponse = client().admin().cluster().prepareUpdateSettings()\n                .setTransientSettings(settingsBuilder().put(\"cluster.routing.allocation.exclude._id\", excludedNodeId)).get();\n        assertThat(clusterUpdateSettingsResponse.isAcknowledged(), equalTo(true));\n        assertThat(clusterUpdateSettingsResponse.getTransientSettings().get(\"cluster.routing.allocation.exclude._id\"), equalTo(excludedNodeId));\n\n        for (Client client : clients()) {\n            ClusterState clusterState = client.admin().cluster().prepareState().setLocal(true).get().getState();\n            assertThat(clusterState.routingNodes().metaData().transientSettings().get(\"cluster.routing.allocation.exclude._id\"), equalTo(excludedNodeId));\n            for (IndexRoutingTable indexRoutingTable : clusterState.routingTable()) {\n                for (IndexShardRoutingTable indexShardRoutingTable : indexRoutingTable) {\n                    for (ShardRouting shardRouting : indexShardRoutingTable) {\n                        if (clusterState.nodes().get(shardRouting.currentNodeId()).id().equals(excludedNodeId)) {\n                            //if the shard is still there it must be relocating and all nodes need to know, since the request was acknowledged\n                            assertThat(shardRouting.relocating(), equalTo(true));\n                        }\n                    }\n                }\n            }\n        }\n\n        //let's wait for the relocation to be completed, otherwise there can be issues with after test checks (mock directory wrapper etc.)\n        waitForRelocation();\n\n        //removes the allocation exclude settings\n        client().admin().cluster().prepareUpdateSettings().setTransientSettings(settingsBuilder().put(\"cluster.routing.allocation.exclude._id\", \"\")).get();\n    }","id":36845,"modified_method":"@Test\n    public void testClusterUpdateSettingsAcknowledgement() {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n        NodesInfoResponse nodesInfo = client().admin().cluster().prepareNodesInfo().get();\n        String excludedNodeId = null;\n        for (NodeInfo nodeInfo : nodesInfo) {\n            if (nodeInfo.getNode().isDataNode()) {\n                excludedNodeId = nodesInfo.getAt(0).getNode().id();\n                break;\n            }\n        }\n        assert excludedNodeId != null;\n\n        ClusterUpdateSettingsResponse clusterUpdateSettingsResponse = client().admin().cluster().prepareUpdateSettings()\n                .setTransientSettings(settingsBuilder().put(\"cluster.routing.allocation.exclude._id\", excludedNodeId)).get();\n        assertAcked(clusterUpdateSettingsResponse);\n        assertThat(clusterUpdateSettingsResponse.getTransientSettings().get(\"cluster.routing.allocation.exclude._id\"), equalTo(excludedNodeId));\n\n        for (Client client : clients()) {\n            ClusterState clusterState = getLocalClusterState(client);\n            assertThat(clusterState.routingNodes().metaData().transientSettings().get(\"cluster.routing.allocation.exclude._id\"), equalTo(excludedNodeId));\n            for (IndexRoutingTable indexRoutingTable : clusterState.routingTable()) {\n                for (IndexShardRoutingTable indexShardRoutingTable : indexRoutingTable) {\n                    for (ShardRouting shardRouting : indexShardRoutingTable) {\n                        if (clusterState.nodes().get(shardRouting.currentNodeId()).id().equals(excludedNodeId)) {\n                            //if the shard is still there it must be relocating and all nodes need to know, since the request was acknowledged\n                            assertThat(shardRouting.relocating(), equalTo(true));\n                        }\n                    }\n                }\n            }\n        }\n\n        //let's wait for the relocation to be completed, otherwise there can be issues with after test checks (mock directory wrapper etc.)\n        waitForRelocation();\n\n        //removes the allocation exclude settings\n        client().admin().cluster().prepareUpdateSettings().setTransientSettings(settingsBuilder().put(\"cluster.routing.allocation.exclude._id\", \"\")).get();\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDeleteMappingAcknowledgement() {\n        client().admin().indices().prepareCreate(\"test\")\n                .addMapping(\"type1\", \"field1\", \"type=string\").get();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\").setSource(\"field1\", \"value1\");\n\n        GetMappingsResponse getMappingsResponse = client().admin().indices().prepareGetMappings(\"test\").addTypes(\"type1\").get();\n        assertThat(getMappingsResponse.mappings().get(\"test\").get(\"type1\"), notNullValue());\n\n        DeleteMappingResponse deleteMappingResponse = client().admin().indices().prepareDeleteMapping(\"test\").setType(\"type1\").get();\n        assertThat(deleteMappingResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            getMappingsResponse = client.admin().indices().prepareGetMappings(\"test\").addTypes(\"type1\").setLocal(true).get();\n            assertThat(getMappingsResponse.mappings().size(), equalTo(0));\n        }\n    }","id":36846,"modified_method":"@Test\n    public void testDeleteMappingAcknowledgement() {\n        client().admin().indices().prepareCreate(\"test\")\n                .addMapping(\"type1\", \"field1\", \"type=string\").get();\n        ensureGreen();\n\n        client().prepareIndex(\"test\", \"type1\").setSource(\"field1\", \"value1\");\n\n        GetMappingsResponse getMappingsResponse = client().admin().indices().prepareGetMappings(\"test\").addTypes(\"type1\").get();\n        assertThat(getMappingsResponse.mappings().get(\"test\").get(\"type1\"), notNullValue());\n\n        assertAcked(client().admin().indices().prepareDeleteMapping(\"test\").setType(\"type1\"));\n\n        for (Client client : clients()) {\n            getMappingsResponse = client.admin().indices().prepareGetMappings(\"test\").addTypes(\"type1\").setLocal(true).get();\n            assertThat(getMappingsResponse.mappings().size(), equalTo(0));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testDeleteWarmerAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        PutWarmerResponse putWarmerResponse = client().admin().indices().preparePutWarmer(\"custom_warmer\")\n                .setSearchRequest(client().prepareSearch(\"test\").setTypes(\"test\").setQuery(QueryBuilders.matchAllQuery()))\n                .get();\n        assertThat(putWarmerResponse.isAcknowledged(), equalTo(true));\n\n        DeleteWarmerResponse deleteWarmerResponse = client().admin().indices().prepareDeleteWarmer().setIndices(\"test\").setName(\"custom_warmer\").get();\n        assertThat(deleteWarmerResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            GetWarmersResponse getWarmersResponse = client.admin().indices().prepareGetWarmers().setLocal(true).get();\n            assertThat(getWarmersResponse.warmers().size(), equalTo(0));\n        }\n    }","id":36847,"modified_method":"@Test\n    public void testDeleteWarmerAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        assertAcked(client().admin().indices().preparePutWarmer(\"custom_warmer\")\n                .setSearchRequest(client().prepareSearch(\"test\").setTypes(\"test\").setQuery(QueryBuilders.matchAllQuery())));\n\n        assertAcked(client().admin().indices().prepareDeleteWarmer().setIndices(\"test\").setName(\"custom_warmer\"));\n\n        for (Client client : clients()) {\n            GetWarmersResponse getWarmersResponse = client.admin().indices().prepareGetWarmers().setLocal(true).get();\n            assertThat(getWarmersResponse.warmers().size(), equalTo(0));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testPutWarmerAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        PutWarmerResponse putWarmerResponse = client().admin().indices().preparePutWarmer(\"custom_warmer\")\n                .setSearchRequest(client().prepareSearch(\"test\").setTypes(\"test\").setQuery(QueryBuilders.matchAllQuery()))\n                .get();\n        assertThat(putWarmerResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            GetWarmersResponse getWarmersResponse = client.admin().indices().prepareGetWarmers().setLocal(true).get();\n            assertThat(getWarmersResponse.warmers().size(), equalTo(1));\n            Map.Entry<String,ImmutableList<IndexWarmersMetaData.Entry>> entry = getWarmersResponse.warmers().entrySet().iterator().next();\n            assertThat(entry.getKey(), equalTo(\"test\"));\n            assertThat(entry.getValue().size(), equalTo(1));\n            assertThat(entry.getValue().get(0).name(), equalTo(\"custom_warmer\"));\n        }\n    }","id":36848,"modified_method":"@Test\n    public void testPutWarmerAcknowledgement() {\n        createIndex(\"test\");\n        ensureGreen();\n\n        assertAcked(client().admin().indices().preparePutWarmer(\"custom_warmer\")\n                .setSearchRequest(client().prepareSearch(\"test\").setTypes(\"test\").setQuery(QueryBuilders.matchAllQuery())));\n\n        for (Client client : clients()) {\n            GetWarmersResponse getWarmersResponse = client.admin().indices().prepareGetWarmers().setLocal(true).get();\n            assertThat(getWarmersResponse.warmers().size(), equalTo(1));\n            Map.Entry<String,ImmutableList<IndexWarmersMetaData.Entry>> entry = getWarmersResponse.warmers().entrySet().iterator().next();\n            assertThat(entry.getKey(), equalTo(\"test\"));\n            assertThat(entry.getValue().size(), equalTo(1));\n            assertThat(entry.getValue().get(0).name(), equalTo(\"custom_warmer\"));\n        }\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testClusterRerouteAcknowledgement() throws InterruptedException {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n\n        MoveAllocationCommand moveAllocationCommand = getAllocationCommand();\n\n        ClusterRerouteResponse clusterRerouteResponse = client().admin().cluster().prepareReroute().add(moveAllocationCommand).get();\n        assertThat(clusterRerouteResponse.isAcknowledged(), equalTo(true));\n\n        for (Client client : clients()) {\n            ClusterStateResponse clusterStateResponse = client.admin().cluster().prepareState().setLocal(true).get();\n            RoutingNode routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.fromNode());\n            for (MutableShardRouting mutableShardRouting : routingNode) {\n                //if the shard that we wanted to move is still on the same node, it must be relocating\n                if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                    assertThat(mutableShardRouting.relocating(), equalTo(true));\n                }\n\n            }\n\n            routingNode = clusterStateResponse.getState().routingNodes().nodesToShards().get(moveAllocationCommand.toNode());\n            boolean found = false;\n            for (MutableShardRouting mutableShardRouting : routingNode) {\n                if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                    assertThat(mutableShardRouting.state(), anyOf(equalTo(ShardRoutingState.INITIALIZING), equalTo(ShardRoutingState.STARTED)));\n                    found = true;\n                    break;\n                }\n            }\n            assertThat(found, equalTo(true));\n        }\n        //let's wait for the relocation to be completed, otherwise there can be issues with after test checks (mock directory wrapper etc.)\n        waitForRelocation();\n    }","id":36849,"modified_method":"@Test\n    public void testClusterRerouteAcknowledgement() throws InterruptedException {\n        client().admin().indices().prepareCreate(\"test\")\n                .setSettings(settingsBuilder()\n                        .put(\"number_of_shards\", atLeast(cluster().size()))\n                        .put(\"number_of_replicas\", 0)).get();\n        ensureGreen();\n\n\n        MoveAllocationCommand moveAllocationCommand = getAllocationCommand();\n\n        assertAcked(client().admin().cluster().prepareReroute().add(moveAllocationCommand));\n\n        for (Client client : clients()) {\n            ClusterState clusterState = getLocalClusterState(client);\n            RoutingNode routingNode = clusterState.routingNodes().nodesToShards().get(moveAllocationCommand.fromNode());\n            for (MutableShardRouting mutableShardRouting : routingNode) {\n                //if the shard that we wanted to move is still on the same node, it must be relocating\n                if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                    assertThat(mutableShardRouting.relocating(), equalTo(true));\n                }\n\n            }\n\n            routingNode = clusterState.routingNodes().nodesToShards().get(moveAllocationCommand.toNode());\n            boolean found = false;\n            for (MutableShardRouting mutableShardRouting : routingNode) {\n                if (mutableShardRouting.shardId().equals(moveAllocationCommand.shardId())) {\n                    assertThat(mutableShardRouting.state(), anyOf(equalTo(ShardRoutingState.INITIALIZING), equalTo(ShardRoutingState.STARTED)));\n                    found = true;\n                    break;\n                }\n            }\n            assertThat(found, equalTo(true));\n        }\n        //let's wait for the relocation to be completed, otherwise there can be issues with after test checks (mock directory wrapper etc.)\n        waitForRelocation();\n    }","commit_id":"22852d8040df7c789e0cdbb32d33ef1e5cc76435","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public static void wipeIndices(String... names) {\n        try {\n            final DeleteIndexResponse actionGet = client().admin().indices().prepareDelete(names).execute().actionGet();\n            assertThat(\"Delete Index failed - not acked\", actionGet.isAcknowledged(), equalTo(true));\n        } catch (IndexMissingException e) {\n            // ignore\n        }\n    }","id":36850,"modified_method":"public static void wipeIndices(String... names) {\n        try {\n            assertAcked(client().admin().indices().prepareDelete(names));\n        } catch (IndexMissingException e) {\n            // ignore\n        }\n    }","commit_id":"459d59a04ad4eb1671bac50a6faf3a7ad372d0e4","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void createIndex(String... names) {\n        for (String name : names) {\n            try {\n                prepareCreate(name).setSettings(getSettings()).execute().actionGet();\n                continue;\n            } catch (IndexAlreadyExistsException ex) {\n                wipeIndex(name);\n            }\n            prepareCreate(name).setSettings(getSettings()).execute().actionGet();\n        }\n    }","id":36851,"modified_method":"public void createIndex(String... names) {\n        for (String name : names) {\n            try {\n                assertAcked(prepareCreate(name).setSettings(getSettings()));\n                continue;\n            } catch (IndexAlreadyExistsException ex) {\n                wipeIndex(name);\n            }\n            assertAcked(prepareCreate(name).setSettings(getSettings()));\n        }\n    }","commit_id":"459d59a04ad4eb1671bac50a6faf3a7ad372d0e4","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // flt query with no field -> OK\n        SearchResponse searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery().likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with string fields\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\").likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with at least a numeric field -> fail\n        try {\n            searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")).execute().actionGet();\n            fail();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // flt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt field query on a numeric field -> failure\n        try {\n            searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\")).execute().actionGet();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // flt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","id":36852,"modified_method":"@Test\n    // See issue https://github.com/elasticsearch/elasticsearch/issues/3252\n    public void testNumericField() throws Exception {\n        prepareCreate(\"test\").execute().actionGet();\n        ensureGreen();\n        client().prepareIndex(\"test\", \"type\", \"1\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"lucene index\").field(\"int_value\", 1).endObject())\n                .execute().actionGet();\n        client().prepareIndex(\"test\", \"type\", \"2\")\n                .setSource(jsonBuilder().startObject().field(\"string_value\", \"elasticsearch index\").field(\"int_value\", 42).endObject())\n                .execute().actionGet();\n\n        refresh();\n\n        // flt query with no field -> OK\n        SearchResponse searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery().likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with string fields\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\").likeText(\"index\")).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt query with at least a numeric field -> fail\n        try {\n            searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\")).execute().actionGet();\n            fail();\n        } catch (SearchPhaseExecutionException e) {\n            // OK\n        }\n\n        // flt query with at least a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisQuery(\"string_value\", \"int_value\").likeText(\"index\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2L));\n\n        // flt field query on a numeric field -> failure\n        assertThrows(client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\")), SearchPhaseExecutionException.class);\n\n        // flt field query on a numeric field but fail_on_unsupported_field set to false\n        searchResponse = client().prepareSearch().setQuery(fuzzyLikeThisFieldQuery(\"int_value\").likeText(\"42\").failOnUnsupportedField(false)).execute().actionGet();\n        assertThat(searchResponse.getFailedShards(), equalTo(0));\n        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));\n    }","commit_id":"497032e6e7eb321016ddef04d7806d1886455210","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void handleRequest(final RestRequest request, final RestChannel channel) {\n        SearchRequest searchRequest;\n        searchRequest = RestSearchAction.parseSearchRequest(request);\n        searchRequest.listenerThreaded(false);\n        client.search(searchRequest, new RestToXContentListener<SearchResponse>(channel));\n    }","id":36853,"modified_method":"@Override\n    public void handleRequest(final RestRequest request, final RestChannel channel) {\n        SearchRequest searchRequest;\n        searchRequest = RestSearchAction.parseSearchRequest(request);\n        searchRequest.listenerThreaded(false);\n        client.search(searchRequest, new RestStatusToXContentListener<SearchResponse>(channel));\n    }","commit_id":"d356881664dc7ce60f46aaed4d910f87be3cfea9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override\n    public void handleRequest(final RestRequest request, final RestChannel channel) {\n        String scrollId = request.param(\"scroll_id\");\n        if (scrollId == null) {\n            scrollId = RestActions.getRestContent(request).toUtf8();\n        }\n        SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId);\n        searchScrollRequest.listenerThreaded(false);\n        String scroll = request.param(\"scroll\");\n        if (scroll != null) {\n            searchScrollRequest.scroll(new Scroll(parseTimeValue(scroll, null)));\n        }\n        client.searchScroll(searchScrollRequest, new RestToXContentListener<SearchResponse>(channel));\n    }","id":36854,"modified_method":"@Override\n    public void handleRequest(final RestRequest request, final RestChannel channel) {\n        String scrollId = request.param(\"scroll_id\");\n        if (scrollId == null) {\n            scrollId = RestActions.getRestContent(request).toUtf8();\n        }\n        SearchScrollRequest searchScrollRequest = new SearchScrollRequest(scrollId);\n        searchScrollRequest.listenerThreaded(false);\n        String scroll = request.param(\"scroll\");\n        if (scroll != null) {\n            searchScrollRequest.scroll(new Scroll(parseTimeValue(scroll, null)));\n        }\n\n        client.searchScroll(searchScrollRequest, new RestStatusToXContentListener(channel));\n    }","commit_id":"d356881664dc7ce60f46aaed4d910f87be3cfea9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleScrollQueryThenFetch_clearAllScrollIds() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", 3)).execute().actionGet();\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        for (int i = 0; i < 100; i++) {\n            client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(jsonBuilder().startObject().field(\"field\", i).endObject()).execute().actionGet();\n        }\n\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        SearchResponse searchResponse1 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        SearchResponse searchResponse2 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        long counter1 = 0;\n        long counter2 = 0;\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        ClearScrollResponse clearResponse = client().prepareClearScroll().addScrollId(\"_all\")\n                .execute().actionGet();\n        assertThat(clearResponse.isSucceeded(), equalTo(true));\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(0l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(0));\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(0l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(0));\n    }","id":36855,"modified_method":"@Test\n    public void testSimpleScrollQueryThenFetch_clearAllScrollIds() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", 3)).execute().actionGet();\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        for (int i = 0; i < 100; i++) {\n            client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(jsonBuilder().startObject().field(\"field\", i).endObject()).execute().actionGet();\n        }\n\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        SearchResponse searchResponse1 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        SearchResponse searchResponse2 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        long counter1 = 0;\n        long counter2 = 0;\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        ClearScrollResponse clearResponse = client().prepareClearScroll().addScrollId(\"_all\")\n                .execute().actionGet();\n        assertThat(clearResponse.isSucceeded(), equalTo(true));\n\n        assertThrows(cluster().transportClient().prepareSearchScroll(searchResponse1.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)), SearchContextMissingException.class);\n        assertThrows(cluster().transportClient().prepareSearchScroll(searchResponse2.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)), SearchContextMissingException.class);\n    }","commit_id":"d356881664dc7ce60f46aaed4d910f87be3cfea9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Test\n    public void testSimpleScrollQueryThenFetch_clearScrollIds() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", 3)).execute().actionGet();\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        for (int i = 0; i < 100; i++) {\n            client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(jsonBuilder().startObject().field(\"field\", i).endObject()).execute().actionGet();\n        }\n\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        SearchResponse searchResponse1 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        SearchResponse searchResponse2 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        long counter1 = 0;\n        long counter2 = 0;\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        ClearScrollResponse clearResponse = client().prepareClearScroll()\n                .addScrollId(searchResponse1.getScrollId())\n                .addScrollId(searchResponse2.getScrollId())\n                .execute().actionGet();\n        assertThat(clearResponse.isSucceeded(), equalTo(true));\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(0l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(0));\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(0l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(0));\n    }","id":36856,"modified_method":"@Test\n    public void testSimpleScrollQueryThenFetch_clearScrollIds() throws Exception {\n        client().admin().indices().prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder().put(\"index.number_of_shards\", 3)).execute().actionGet();\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n\n        for (int i = 0; i < 100; i++) {\n            client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(jsonBuilder().startObject().field(\"field\", i).endObject()).execute().actionGet();\n        }\n\n        client().admin().indices().prepareRefresh().execute().actionGet();\n\n        SearchResponse searchResponse1 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        SearchResponse searchResponse2 = client().prepareSearch()\n                .setQuery(matchAllQuery())\n                .setSize(35)\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .setSearchType(SearchType.QUERY_THEN_FETCH)\n                .addSort(\"field\", SortOrder.ASC)\n                .execute().actionGet();\n\n        long counter1 = 0;\n        long counter2 = 0;\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        searchResponse1 = client().prepareSearchScroll(searchResponse1.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        searchResponse2 = client().prepareSearchScroll(searchResponse2.getScrollId())\n                .setScroll(TimeValue.timeValueMinutes(2))\n                .execute().actionGet();\n\n        assertThat(searchResponse1.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse1.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse1.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter1++));\n        }\n\n        assertThat(searchResponse2.getHits().getTotalHits(), equalTo(100l));\n        assertThat(searchResponse2.getHits().hits().length, equalTo(35));\n        for (SearchHit hit : searchResponse2.getHits()) {\n            assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter2++));\n        }\n\n        ClearScrollResponse clearResponse = client().prepareClearScroll()\n                .addScrollId(searchResponse1.getScrollId())\n                .addScrollId(searchResponse2.getScrollId())\n                .execute().actionGet();\n        assertThat(clearResponse.isSucceeded(), equalTo(true));\n\n        assertThrows(client().prepareSearchScroll(searchResponse1.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)), SearchContextMissingException.class);\n        assertThrows(client().prepareSearchScroll(searchResponse2.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)), SearchContextMissingException.class);\n    }","commit_id":"d356881664dc7ce60f46aaed4d910f87be3cfea9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void executeQueryPhase(final int shardIndex, final AtomicInteger counter, DiscoveryNode node, final long searchId) {\n            InternalScrollSearchRequest internalRequest = internalScrollSearchRequest(searchId, request);\n            searchService.sendExecuteQuery(node, internalRequest, new SearchServiceListener<QuerySearchResult>() {\n                @Override\n                public void onResult(QuerySearchResult result) {\n                    queryResults.set(shardIndex, result);\n                    if (counter.decrementAndGet() == 0) {\n                        try {\n                            executeFetchPhase();\n                        } catch (Throwable e) {\n                            onFailure(e);\n                        }\n                    }\n                }\n\n                @Override\n                public void onFailure(Throwable t) {\n                    onQueryPhaseFailure(shardIndex, counter, searchId, t);\n                }\n            });\n        }","id":36857,"modified_method":"private void executeQueryPhase(final int shardIndex, final AtomicInteger counter, DiscoveryNode node, final long searchId) {\n            InternalScrollSearchRequest internalRequest = internalScrollSearchRequest(searchId, request);\n            searchService.sendExecuteQuery(node, internalRequest, new SearchServiceListener<QuerySearchResult>() {\n                @Override\n                public void onResult(QuerySearchResult result) {\n                    queryResults.set(shardIndex, result);\n                    if (counter.decrementAndGet() == 0) {\n                        try {\n                            executeFetchPhase();\n                        } catch (Throwable e) {\n                            onFailure(e);\n                        }\n                    }\n                }\n\n                @Override\n                public void onFailure(Throwable t) {\n                    Throwable cause = ExceptionsHelper.unwrapCause(t);\n                    if (cause instanceof SearchContextMissingException) {\n                        listener.onFailure(t);\n                    } else {\n                        onQueryPhaseFailure(shardIndex, counter, searchId, t);\n                    }\n                }\n            });\n        }","commit_id":"d356881664dc7ce60f46aaed4d910f87be3cfea9","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public void manage(ManageAction manageAction) throws ManageActionException {\n\t\tmanageAction.action();\n\t}","id":36858,"modified_method":"public <T> T manage(ManageAction<T> manageAction)\n\t\tthrows ManageActionException {\n\t\treturn manageAction.action();\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public ClusterManageActionWrapper(\n\t\tClusterGroup clusterGroup, ManageAction manageAction) {\n\n\t\t_clusterGroup = clusterGroup;\n\t\t_manageAction = manageAction;\n\t}","id":36859,"modified_method":"public ClusterManageActionWrapper(\n\t\tClusterGroup clusterGroup, ManageAction<?> manageAction) {\n\n\t\t_clusterGroup = clusterGroup;\n\t\t_manageAction = manageAction;\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tdoAction();\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow new ManageActionException(\n\t\t\t\t\"Failed to execute cluster manage action\", se);\n\t\t}\n\t}","id":36860,"modified_method":"public FutureClusterResponses action() throws ManageActionException {\n\t\ttry {\n\t\t\treturn doAction();\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow new ManageActionException(\n\t\t\t\t\"Failed to execute cluster manage action\", se);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"private void doAction() throws ManageActionException, SystemException {\n\t\tMethodHandler manageActionMethodHandler =\n\t\t\tPortalManagerUtil.createManageActionMethodHandler(_manageAction);\n\n\t\tClusterRequest clusterRequest = null;\n\n\t\tif (_clusterGroup.isWholeCluster()) {\n\t\t\tclusterRequest = ClusterRequest.createMulticastRequest(\n\t\t\t\tmanageActionMethodHandler);\n\t\t}\n\t\telse {\n\t\t\tverifyClusterGroup();\n\n\t\t\tclusterRequest = ClusterRequest.createUnicastRequest(\n\t\t\t\tmanageActionMethodHandler,\n\t\t\t\t_clusterGroup.getClusterNodeIdsArray());\n\t\t}\n\n\t\tClusterExecutorUtil.execute(clusterRequest);\n\t}","id":36861,"modified_method":"private FutureClusterResponses doAction()\n\t\tthrows ManageActionException, SystemException {\n\t\tMethodHandler manageActionMethodHandler =\n\t\t\tPortalManagerUtil.createManageActionMethodHandler(_manageAction);\n\n\t\tClusterRequest clusterRequest = null;\n\n\t\tif (_clusterGroup.isWholeCluster()) {\n\t\t\tclusterRequest = ClusterRequest.createMulticastRequest(\n\t\t\t\tmanageActionMethodHandler);\n\t\t}\n\t\telse {\n\t\t\tverifyClusterGroup();\n\n\t\t\tclusterRequest = ClusterRequest.createUnicastRequest(\n\t\t\t\tmanageActionMethodHandler,\n\t\t\t\t_clusterGroup.getClusterNodeIdsArray());\n\t\t}\n\n\t\treturn ClusterExecutorUtil.execute(clusterRequest);\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"private void verifyClusterGroup() throws ManageActionException {\n\t\tList<ClusterNode> clusterNodes = ClusterExecutorUtil.getClusterNodes();\n\n\t\tString[] requiredClusterNodesIds =\n\t\t\t_clusterGroup.getClusterNodeIdsArray();\n\n\t\tfor (String requiredClusterNodeId : requiredClusterNodesIds) {\n\t\t\tfor (ClusterNode clusterNode : clusterNodes) {\n\t\t\t\tString clusterNodeId = clusterNode.getClusterNodeId();\n\n\t\t\t\tif (clusterNodeId.equals(requiredClusterNodeId)) {\n\t\t\t\t\tclusterNodes.remove(clusterNode);\n\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tthrow new ManageActionException(\n\t\t\t\t\"Cluster node \" + requiredClusterNodeId + \" is not available\");\n\t\t}\n\t}","id":36862,"modified_method":"private void verifyClusterGroup() throws ManageActionException {\n\t\tList<ClusterNode> clusterNodes = ClusterExecutorUtil.getClusterNodes();\n\n\t\tString[] requiredClusterNodesIds =\n\t\t\t_clusterGroup.getClusterNodeIdsArray();\n\n\t\tRequired:\n\t\tfor (String requiredClusterNodeId : requiredClusterNodesIds) {\n\t\t\tIterator<ClusterNode> iterator = clusterNodes.iterator();\n\t\t\twhile (iterator.hasNext()) {\n\t\t\t\tClusterNode clusterNode = iterator.next();\n\t\t\t\tString clusterNodeId = clusterNode.getClusterNodeId();\n\n\t\t\t\tif (clusterNodeId.equals(requiredClusterNodeId)) {\n\t\t\t\t\tclusterNodes.remove(clusterNode);\n\n\t\t\t\t\tcontinue Required;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tthrow new ManageActionException(\n\t\t\t\t\"Cluster node \" + requiredClusterNodeId + \" is not available\");\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\t_result = mBeanServer.invoke(\n\t\t\t\t_objectName, _operationName, _parameters, _signature);\n\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","id":36863,"modified_method":"public Object action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\treturn mBeanServer.invoke(\n\t\t\t\t_objectName, _operationName, _parameters, _signature);\n\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tObjectName objectName = _mBean.getObjectName();\n\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tMBeanInfo mBeanInfo = mBeanServer.getMBeanInfo(objectName);\n\n\t\t\tMBeanAttributeInfo[] mBeanAttributeInfos =\n\t\t\t\tmBeanInfo.getAttributes();\n\n\t\t\tString[] attributeNames = new String[mBeanAttributeInfos.length];\n\n\t\t\tfor (int i = 0; i < attributeNames.length; i++) {\n\t\t\t\tattributeNames[i] = mBeanAttributeInfos[i].getName();\n\t\t\t}\n\n\t\t\t_attributeList = mBeanServer.getAttributes(\n\t\t\t\tobjectName, attributeNames);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","id":36864,"modified_method":"public AttributeList action() throws ManageActionException {\n\t\ttry {\n\t\t\tObjectName objectName = _mBean.getObjectName();\n\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tMBeanInfo mBeanInfo = mBeanServer.getMBeanInfo(objectName);\n\n\t\t\tMBeanAttributeInfo[] mBeanAttributeInfos =\n\t\t\t\tmBeanInfo.getAttributes();\n\n\t\t\tString[] attributeNames = new String[mBeanAttributeInfos.length];\n\n\t\t\tfor (int i = 0; i < attributeNames.length; i++) {\n\t\t\t\tattributeNames[i] = mBeanAttributeInfos[i].getName();\n\t\t\t}\n\n\t\t\treturn mBeanServer.getAttributes(objectName, attributeNames);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() {\n\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t_domains = mBeanServer.getDomains();\n\t}","id":36865,"modified_method":"public String[] action() {\n\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\treturn mBeanServer.getDomains();\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tSet<ObjectName> objectNames = mBeanServer.queryNames(\n\t\t\t\tnull, new ObjectName(_domainName.concat(\":*\")));\n\n\t\t\t_mBeans = new HashSet<MBean>(objectNames.size());\n\n\t\t\tfor (ObjectName objectName : objectNames) {\n\t\t\t\t_mBeans.add(new MBean(objectName));\n\t\t\t}\n\t\t}\n\t\tcatch (MalformedObjectNameException mone) {\n\t\t\tthrow new ManageActionException(mone);\n\t\t}\n\t}","id":36866,"modified_method":"public Set<MBean> action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tSet<ObjectName> objectNames = mBeanServer.queryNames(\n\t\t\t\tnull, new ObjectName(_domainName.concat(\":*\")));\n\n\t\t\tSet<MBean> mBeans = new HashSet<MBean>(objectNames.size());\n\n\t\t\tfor (ObjectName objectName : objectNames) {\n\t\t\t\tmBeans.add(new MBean(objectName));\n\t\t\t}\n\n\t\t\treturn mBeans;\n\t\t}\n\t\tcatch (MalformedObjectNameException mone) {\n\t\t\tthrow new ManageActionException(mone);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tObjectName objectName = _mBean.getObjectName();\n\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tMBeanInfo mBeanInfo = mBeanServer.getMBeanInfo(objectName);\n\n\t\t\t_mBean = new MBean(objectName, mBeanInfo);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","id":36867,"modified_method":"public MBean action() throws ManageActionException {\n\t\ttry {\n\t\t\tObjectName objectName = _mBean.getObjectName();\n\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tMBeanInfo mBeanInfo = mBeanServer.getMBeanInfo(objectName);\n\n\t\t\treturn new MBean(objectName, mBeanInfo);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void manage(ManageAction manageAction)\n\t\tthrows ManageActionException {\n\n\t\t_portalManager.manage(manageAction);\n\t}","id":36868,"modified_method":"public static <T> T manage(ManageAction<T> manageAction)\n\t\tthrows ManageActionException {\n\n\t\treturn _portalManager.manage(manageAction);\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static void manage(\n\t\t\tClusterGroup clusterGroup, ManageAction manageAction)\n\t\tthrows ManageActionException {\n\n\t\tManageAction action = new ClusterManageActionWrapper(\n\t\t\tclusterGroup, manageAction);\n\n\t\t_portalManager.manage(action);\n\t}","id":36869,"modified_method":"public static FutureClusterResponses manage(\n\t\t\tClusterGroup clusterGroup, ManageAction<?> manageAction)\n\t\tthrows ManageActionException {\n\n\t\tManageAction<FutureClusterResponses> action =\n\t\t\tnew ClusterManageActionWrapper(clusterGroup, manageAction);\n\n\t\treturn _portalManager.manage(action);\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tmBeanServer.setAttribute(_objectName, new Attribute(_name, _value));\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","id":36870,"modified_method":"public Void action() throws ManageActionException {\n\t\ttry {\n\t\t\tMBeanServer mBeanServer = getMBeanServer();\n\n\t\t\tmBeanServer.setAttribute(_objectName, new Attribute(_name, _value));\n\n\t\t\treturn null;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new ManageActionException(e);\n\t\t}\n\t}","commit_id":"f72f8884ebdb343503064b352ebb12ace037adc3","url":"https://github.com/liferay/liferay-portal"},{"original_method":"/** Changes the current animation by blending the new on top of the old during the transition time. */\n\tpublic void animate(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\tanimate(obtain(id, loopCount, speed, listener), transitionTime);\n\t}","id":36871,"modified_method":"/** Changes the current animation by blending the new on top of the old during the transition time.\n\t * @param id The ID of the {@link Animation} within the {@link ModelInstance}.\n\t * @param loopCount The number of times to loop the animation, zero to play the animation only once, \n\t * negative to continuously loop the animation. \n\t * @param speed The speed at which the animation should be played. Default is 1.0f. A value of 2.0f will play\n\t * the animation at twice the normal speed, a value of 0.5f will play the animation at half the normal speed, etc.\n\t * This value can be negative, causing the animation to played in reverse.\n\t * This value cannot be zero.\n\t * @param listener The {@link AnimationListener} which will be informed when the animation is looped or completed.\n\t * @param transitionTime The time to transition the new animation on top of the currently playing animation (if any).\n\t * @return The {@link AnimationDesc} which can be read to get the progress of the animation. Will be invalid when the\n\t * animation is completed. */\n\tpublic AnimationDesc animate(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn animate(obtain(id, loopCount, speed, listener), transitionTime);\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Set the active animation, replacing any current animation. */\n\tprotected void setAnimation(final AnimationDesc anim) {\n\t\tif (updating) // FIXME Remove this? Just intended for debugging\n\t\t\tthrow new GdxRuntimeException(\"Cannot change animation during update\");\n\t\tif (current == null)\n\t\t\tcurrent = anim;\n\t\telse {\n\t\t\tif (current.animation == anim.animation)\n\t\t\t\tanim.time = current.time;\n\t\t\tanimationPool.free(current);\n\t\t\tcurrent = anim;\n\t\t}\n\t}","id":36872,"modified_method":"/** Set the active animation, replacing any current animation. */\n\tprotected AnimationDesc setAnimation(final AnimationDesc anim) {\n\t\tif (updating) // FIXME Remove this? Just intended for debugging\n\t\t\tthrow new GdxRuntimeException(\"Cannot change animation during update\");\n\t\tif (current == null)\n\t\t\tcurrent = anim;\n\t\telse {\n\t\t\tif (current.animation == anim.animation)\n\t\t\t\tanim.time = current.time;\n\t\t\tanimationPool.free(current);\n\t\t\tcurrent = anim;\n\t\t}\n\t\treturn anim;\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** @return the remaining time or 0 if still animating. */\n\t\tpublic float update(float delta) {\n\t\t\tif (loopCount != 0 && animation != null) {\n\t\t\t\tfinal float duration = animation.duration;\n\t\t\t\tfinal float diff = speed * delta; \n\t\t\t\ttime += diff;\n\t\t\t\tint loops = (int)Math.abs(time / duration);\n\t\t\t\tif (time < 0f) {\n\t\t\t\t\tloops++;\n\t\t\t\t\twhile (time < 0f)\n\t\t\t\t\t\ttime += duration;\n\t\t\t\t}\n\t\t\t\ttime = Math.abs(time % duration);\n\t\t\t\tfor (int i = 0; i < loops; i++) {\n\t\t\t\t\tif (loopCount > 0)\n\t\t\t\t\t\tloopCount--;\n\t\t\t\t\tif (listener != null)\n\t\t\t\t\t\tlistener.onLoop(this);\n\t\t\t\t\tif (loopCount == 0) {\n\t\t\t\t\t\tfinal float result = ((loops - 1) - i) * duration + (diff < 0f ? duration - time : time); \n\t\t\t\t\t\ttime = (diff < 0f) ? duration : 0f;\n\t\t\t\t\t\tif (listener != null)\n\t\t\t\t\t\t\tlistener.onEnd(this);\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn 0f;\n\t\t\t} else\n\t\t\t\treturn delta;\n\t\t}","id":36873,"modified_method":"/** @return the remaining time or 0 if still animating. */\n\t\tprotected float update(float delta) {\n\t\t\tif (loopCount != 0 && animation != null) {\n\t\t\t\tfinal float duration = animation.duration;\n\t\t\t\tfinal float diff = speed * delta; \n\t\t\t\ttime += diff;\n\t\t\t\tint loops = (int)Math.abs(time / duration);\n\t\t\t\tif (time < 0f) {\n\t\t\t\t\tloops++;\n\t\t\t\t\twhile (time < 0f)\n\t\t\t\t\t\ttime += duration;\n\t\t\t\t}\n\t\t\t\ttime = Math.abs(time % duration);\n\t\t\t\tfor (int i = 0; i < loops; i++) {\n\t\t\t\t\tif (loopCount > 0)\n\t\t\t\t\t\tloopCount--;\n\t\t\t\t\tif (loopCount != 0 && listener != null)\n\t\t\t\t\t\tlistener.onLoop(this);\n\t\t\t\t\tif (loopCount == 0) {\n\t\t\t\t\t\tfinal float result = ((loops - 1) - i) * duration + (diff < 0f ? duration - time : time); \n\t\t\t\t\t\ttime = (diff < 0f) ? duration : 0f;\n\t\t\t\t\t\tif (listener != null)\n\t\t\t\t\t\t\tlistener.onEnd(this);\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn 0f;\n\t\t\t} else\n\t\t\t\treturn delta;\n\t\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"void onEnd(final AnimationDesc animation);","id":36874,"modified_method":"/** Gets called when an animation is completed.\n\t\t * @param animation The animation which just completed. */\n\t\tvoid onEnd(final AnimationDesc animation);","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"void onLoop(final AnimationDesc animation);","id":36875,"modified_method":"/** Gets called when an animation is looped. The {@link AnimationDesc#loopCount} is updated prior to this call\n\t\t * and can be read or written to alter the number of remaining loops. \n\t\t * @param animation The animation which just looped. */\n\t\tvoid onLoop(final AnimationDesc animation);","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Queue an animation to be applied when the current is finished. If current is continuous it will be synced on next loop. */\n\tpublic void queue(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\tqueue(obtain(id, loopCount, speed, listener), transitionTime);\t\n\t}","id":36876,"modified_method":"/** Queue an animation to be applied when the {@link #current} animation is finished. \n\t * If the current animation is continuously looping it will be synchronized on next loop.\n\t * @param id The ID of the {@link Animation} within the {@link ModelInstance}.\n\t * @param loopCount The number of times to loop the animation, zero to play the animation only once, \n\t * negative to continuously loop the animation. \n\t * @param speed The speed at which the animation should be played. Default is 1.0f. A value of 2.0f will play\n\t * the animation at twice the normal speed, a value of 0.5f will play the animation at half the normal speed, etc.\n\t * This value can be negative, causing the animation to played in reverse.\n\t * This value cannot be zero.\n\t * @param listener The {@link AnimationListener} which will be informed when the animation is looped or completed.\n\t * @param transitionTime The time to transition the new animation on top of the currently playing animation (if any).\n\t * @return The {@link AnimationDesc} which can be read to get the progress of the animation. Will be invalid when the\n\t * animation is completed. */\n\tpublic AnimationDesc queue(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn queue(obtain(id, loopCount, speed, listener), transitionTime);\t\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Changes the current animation by blending the new on top of the old during the transition time. */\n\tprotected void animate(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\tanimate(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","id":36877,"modified_method":"/** Changes the current animation by blending the new on top of the old during the transition time. */\n\tprotected AnimationDesc animate(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn animate(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Queue an animation to be applied when the current is finished. If current is continuous it will be synced on next loop. */\n\tprotected void queue(final AnimationDesc anim, float transitionTime) {\n\t\tif (current == null || current.loopCount == 0)\n\t\t\tanimate(anim, transitionTime);\n\t\telse {\n\t\t\tif (queued != null)\n\t\t\t\tanimationPool.free(queued);\n\t\t\tqueued = anim;\n\t\t\tqueuedTransitionTime = transitionTime;\n\t\t\tif (current.loopCount < 0)\n\t\t\t\tcurrent.loopCount = 1;\n\t\t}\n\t}","id":36878,"modified_method":"/** Queue an animation to be applied when the current is finished. If current is continuous it will be synced on next loop. */\n\tprotected AnimationDesc queue(final AnimationDesc anim, float transitionTime) {\n\t\tif (current == null || current.loopCount == 0)\n\t\t\tanimate(anim, transitionTime);\n\t\telse {\n\t\t\tif (queued != null)\n\t\t\t\tanimationPool.free(queued);\n\t\t\tqueued = anim;\n\t\t\tqueuedTransitionTime = transitionTime;\n\t\t\tif (current.loopCount < 0)\n\t\t\t\tcurrent.loopCount = 1;\n\t\t}\n\t\treturn anim;\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"public AnimationController (ModelInstance target) {\n\t\tsuper(target);\n\t}","id":36879,"modified_method":"/** Construct a new AnimationController.\n\t * @param target The {@link ModelInstance} on which the animations will be performed. */\n\tpublic AnimationController (final ModelInstance target) {\n\t\tsuper(target);\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Set the active animation, replacing any current animation. */\n\tpublic void setAnimation(final String id, int loopCount, float speed, final AnimationListener listener) {\n\t\tsetAnimation(obtain(id, loopCount, speed, listener));\n\t}","id":36880,"modified_method":"/** Set the active animation, replacing any current animation.\n\t * @param id The ID of the {@link Animation} within the {@link ModelInstance}.\n\t * @param loopCount The number of times to loop the animation, zero to play the animation only once, \n\t * negative to continuously loop the animation. \n\t * @param speed The speed at which the animation should be played. Default is 1.0f. A value of 2.0f will play\n\t * the animation at twice the normal speed, a value of 0.5f will play the animation at half the normal speed, etc.\n\t * This value can be negative, causing the animation to played in reverse.\n\t * This value cannot be zero.\n\t * @param listener The {@link AnimationListener} which will be informed when the animation is looped or completed.\n\t * @return The {@link AnimationDesc} which can be read to get the progress of the animation. Will be invalid when the\n\t * animation is completed. */\n\tpublic AnimationDesc setAnimation(final String id, int loopCount, float speed, final AnimationListener listener) {\n\t\treturn setAnimation(obtain(id, loopCount, speed, listener));\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Apply an action animation on top of the current animation. */\n\tprotected void action(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\taction(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","id":36881,"modified_method":"/** Apply an action animation on top of the current animation. */\n\tprotected AnimationDesc action(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn action(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Apply an action animation on top of the current animation. */\n\tpublic void action(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\taction(obtain(id, loopCount, speed, listener), transitionTime);\t\n\t}","id":36882,"modified_method":"/** Apply an action animation on top of the current animation.\n\t * @param id The ID of the {@link Animation} within the {@link ModelInstance}.\n\t * @param loopCount The number of times to loop the animation, zero to play the animation only once, \n\t * negative to continuously loop the animation. \n\t * @param speed The speed at which the animation should be played. Default is 1.0f. A value of 2.0f will play\n\t * the animation at twice the normal speed, a value of 0.5f will play the animation at half the normal speed, etc.\n\t * This value can be negative, causing the animation to played in reverse.\n\t * This value cannot be zero.\n\t * @param listener The {@link AnimationListener} which will be informed when the animation is looped or completed.\n\t * @param transitionTime The time to transition the new animation on top of the currently playing animation (if any).\n\t * @return The {@link AnimationDesc} which can be read to get the progress of the animation. Will be invalid when the\n\t * animation is completed. */\n\tpublic AnimationDesc action(final String id, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn action(obtain(id, loopCount, speed, listener), transitionTime);\t\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Set the active animation, replacing any current animation. */\n\tprotected void setAnimation(final Animation anim, int loopCount, float speed, final AnimationListener listener) {\n\t\tsetAnimation(obtain(anim, loopCount, speed, listener));\n\t}","id":36883,"modified_method":"/** Set the active animation, replacing any current animation. */\n\tprotected AnimationDesc setAnimation(final Animation anim, int loopCount, float speed, final AnimationListener listener) {\n\t\treturn setAnimation(obtain(anim, loopCount, speed, listener));\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Queue an animation to be applied when the current is finished. If current is continuous it will be synced on next loop. */\n\tprotected void queue(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\tqueue(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","id":36884,"modified_method":"/** Queue an animation to be applied when the current is finished. If current is continuous it will be synced on next loop. */\n\tprotected AnimationDesc queue(final Animation anim, int loopCount, float speed, final AnimationListener listener, float transitionTime) {\n\t\treturn queue(obtain(anim, loopCount, speed, listener), transitionTime);\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Changes the current animation by blending the new on top of the old during the transition time. */ \n\tprotected void animate(final AnimationDesc anim, float transitionTime) {\n\t\tif (current == null)\n\t\t\tcurrent = anim;\n\t\telse if (inAction)\n\t\t\tqueue(anim, transitionTime);\n\t\telse if (current.animation == anim.animation) {\n\t\t\tanim.time = current.time;\n\t\t\tanimationPool.free(current);\n\t\t\tcurrent = anim;\n\t\t} else {\n\t\t\tif (previous != null)\n\t\t\t\tanimationPool.free(previous);\n\t\t\tprevious = current;\n\t\t\tcurrent = anim;\n\t\t\ttransitionCurrentTime = 0f;\n\t\t\ttransitionTargetTime = transitionTime;\n\t\t}\n\t}","id":36885,"modified_method":"/** Changes the current animation by blending the new on top of the old during the transition time. */ \n\tprotected AnimationDesc animate(final AnimationDesc anim, float transitionTime) {\n\t\tif (current == null)\n\t\t\tcurrent = anim;\n\t\telse if (inAction)\n\t\t\tqueue(anim, transitionTime);\n\t\telse if (current.animation == anim.animation) {\n\t\t\tanim.time = current.time;\n\t\t\tanimationPool.free(current);\n\t\t\tcurrent = anim;\n\t\t} else {\n\t\t\tif (previous != null)\n\t\t\t\tanimationPool.free(previous);\n\t\t\tprevious = current;\n\t\t\tcurrent = anim;\n\t\t\ttransitionCurrentTime = 0f;\n\t\t\ttransitionTargetTime = transitionTime;\n\t\t}\n\t\treturn anim;\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"/** Apply an action animation on top of the current animation. */\n\tprotected void action(final AnimationDesc anim, float transitionTime) {\n\t\tif (anim.loopCount < 0)\n\t\t\tthrow new GdxRuntimeException(\"An action cannot be continuous\");\n\t\tif (current == null || current.loopCount == 0)\n\t\t\tanimate(anim, transitionTime);\n\t\telse {\n\t\t\tAnimationDesc toQueue = inAction ? null : obtain(current);\n\t\t\tinAction = false;\n\t\t\tanimate(anim, transitionTime);\n\t\t\tinAction = true;\n\t\t\tif (toQueue != null)\n\t\t\t\tqueue(toQueue, transitionTime);\n\t\t}\n\t}","id":36886,"modified_method":"/** Apply an action animation on top of the current animation. */\n\tprotected AnimationDesc action(final AnimationDesc anim, float transitionTime) {\n\t\tif (anim.loopCount < 0)\n\t\t\tthrow new GdxRuntimeException(\"An action cannot be continuous\");\n\t\tif (current == null || current.loopCount == 0)\n\t\t\tanimate(anim, transitionTime);\n\t\telse {\n\t\t\tAnimationDesc toQueue = inAction ? null : obtain(current);\n\t\t\tinAction = false;\n\t\t\tanimate(anim, transitionTime);\n\t\t\tinAction = true;\n\t\t\tif (toQueue != null)\n\t\t\t\tqueue(toQueue, transitionTime);\n\t\t}\n\t\treturn anim;\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"public BaseAnimationController(final ModelInstance target) {\n\t\tthis.target = target;\n\t}","id":36887,"modified_method":"/** Construct a new BaseAnimationController.\n\t * @param target The {@link ModelInstance} on which the animations are being performed. */\n\tpublic BaseAnimationController(final ModelInstance target) {\n\t\tthis.target = target;\n\t}","commit_id":"a0f3713cdded1504c73ae6ad7dbd2db20f8cef13","url":"https://github.com/libgdx/libgdx"},{"original_method":"@Override \n    public String getAction(OperationInfo op, Method method) {\n        method = getDeclaredMethod(method);\n        WebMethod wm = method.getAnnotation(WebMethod.class);\n        if (wm != null) {\n            return wm.action();\n        } else {\n            return \"\";\n        }\n    }","id":36888,"modified_method":"@Override \n    public String getAction(OperationInfo op, Method method) {\n        method = getDeclaredMethod(method);\n        WebMethod wm = method.getAnnotation(WebMethod.class);\n        String action = \"\";\n        if (wm != null) {\n            action = wm.action();\n        }\n        if (StringUtils.isEmpty(action)) {\n            Action act = method.getAnnotation(Action.class);\n            if (act != null) {\n                action = act.input();\n            }\n        }\n        return action;\n    }","commit_id":"c75a366b09e9731ab8ff321a15719eae631b137e","url":"https://github.com/apache/cxf"},{"original_method":"private Object computeAction(OperationInfo op, String postFix) {\n        StringBuilder s = new StringBuilder(op.getName().getNamespaceURI());\n        if (s.charAt(s.length() - 1) != '/') {\n            s.append('/');\n        }\n        s.append(op.getInterface().getName().getLocalPart())\n            .append('/').append(op.getName().getLocalPart()).append(postFix);\n        return s.toString();\n    }","id":36889,"modified_method":"private String computeAction(OperationInfo op, String postFix) {\n        StringBuilder s = new StringBuilder(op.getName().getNamespaceURI());\n        if (s.charAt(s.length() - 1) != '/') {\n            s.append('/');\n        }\n        s.append(op.getInterface().getName().getLocalPart())\n            .append('/').append(op.getName().getLocalPart()).append(postFix);\n        return s.toString();\n    }","commit_id":"c75a366b09e9731ab8ff321a15719eae631b137e","url":"https://github.com/apache/cxf"},{"original_method":"private void buildWSAActions(OperationInfo operation, Method method) {\n        //nothing\n        if (method == null) {\n            return;\n        }\n\n        Action action = method.getAnnotation(Action.class);\n        Addressing addressing = method.getDeclaringClass().getAnnotation(Addressing.class);\n        if (action == null && addressing == null) {\n            return;\n        }\n        if (action == null && addressing != null) {\n            operation.getInput().addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME,\n                                                       computeAction(operation, \"Request\"));\n            operation.getInput().addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME,\n                                                       computeAction(operation, \"Request\"));\n            operation.getOutput().addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME,\n                                                       computeAction(operation, \"Response\"));\n            operation.getOutput().addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME,\n                                                        computeAction(operation, \"Response\"));\n\n        } else {\n            MessageInfo input = operation.getInput();\n            if (!StringUtils.isEmpty(action.input())) {\n                input.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, action.input());\n                input.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, action.input());\n            } else {\n                input.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, computeAction(operation,\n                                                                                             \"Request\"));\n                \n            }\n\n            MessageInfo output = operation.getOutput();\n            if (output != null && !StringUtils.isEmpty(action.output())) {\n                output.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, action.output());\n                output.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, action.output());\n            } else if (output != null) {\n                output.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, computeAction(operation,\n                                                                                              \"Response\"));\n            }\n\n            FaultAction[] faultActions = action.fault();\n            if (faultActions != null && faultActions.length > 0 && operation.getFaults() != null) {\n                for (FaultAction faultAction : faultActions) {\n                    FaultInfo faultInfo = getFaultInfo(operation, faultAction.className());\n                    if (!StringUtils.isEmpty(faultAction.value())) {\n                        faultInfo.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, faultAction\n                            .value());\n                        faultInfo.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, faultAction\n                            .value());\n                    }\n                    if (operation.isUnwrappedCapable()) {\n                        faultInfo = getFaultInfo(operation.getUnwrappedOperation(), faultAction.className());\n                        if (!StringUtils.isEmpty(faultAction.value())) {\n                            faultInfo.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, faultAction\n                                .value());\n                            faultInfo.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, faultAction\n                                .value());\n                        }\n                    }\n                }\n            }\n        }\n        for (FaultInfo fi : operation.getFaults()) {\n            if (fi.getExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME) == null) {\n                String f = \"/Fault/\" + fi.getName().getLocalPart();\n                fi.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, \n                                         computeAction(operation, f));\n                if (operation.isUnwrappedCapable()) {\n                    fi = operation.getUnwrappedOperation().getFault(fi.getName());\n                    fi.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, \n                                             computeAction(operation, f));\n                }                \n            }\n        }\n    }","id":36890,"modified_method":"private void buildWSAActions(OperationInfo operation, Method method) {\n        //nothing\n        if (method == null) {\n            return;\n        }\n\n        Action action = method.getAnnotation(Action.class);\n        Addressing addressing = method.getDeclaringClass().getAnnotation(Addressing.class);\n        if (action == null && addressing == null) {\n            return;\n        }\n        WebMethod wm = method.getAnnotation(WebMethod.class);\n        String inputAction = \"\";\n        if (action != null) {\n            inputAction = action.input();\n        }\n        if (wm != null && StringUtils.isEmpty(inputAction)) {\n            inputAction = wm.action(); \n        }\n        if (StringUtils.isEmpty(inputAction)) {\n            inputAction = computeAction(operation, \"Request\");\n        }\n        if (action == null && addressing != null) {\n            operation.getInput().addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME,\n                                                       inputAction);\n            operation.getInput().addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME,\n                                                       inputAction);\n            operation.getOutput().addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME,\n                                                       computeAction(operation, \"Response\"));\n            operation.getOutput().addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME,\n                                                        computeAction(operation, \"Response\"));\n\n        } else {\n            MessageInfo input = operation.getInput();\n            input.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, inputAction);\n            if (!StringUtils.isEmpty(action.input())) {\n                input.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, inputAction);\n            }\n\n            MessageInfo output = operation.getOutput();\n            if (output != null && !StringUtils.isEmpty(action.output())) {\n                output.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, action.output());\n                output.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, action.output());\n            } else if (output != null) {\n                output.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, computeAction(operation,\n                                                                                              \"Response\"));\n            }\n\n            FaultAction[] faultActions = action.fault();\n            if (faultActions != null && faultActions.length > 0 && operation.getFaults() != null) {\n                for (FaultAction faultAction : faultActions) {\n                    FaultInfo faultInfo = getFaultInfo(operation, faultAction.className());\n                    if (!StringUtils.isEmpty(faultAction.value())) {\n                        faultInfo.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, faultAction\n                            .value());\n                        faultInfo.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, faultAction\n                            .value());\n                    }\n                    if (operation.isUnwrappedCapable()) {\n                        faultInfo = getFaultInfo(operation.getUnwrappedOperation(), faultAction.className());\n                        if (!StringUtils.isEmpty(faultAction.value())) {\n                            faultInfo.addExtensionAttribute(JAXWSAConstants.WSAW_ACTION_QNAME, faultAction\n                                .value());\n                            faultInfo.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, faultAction\n                                .value());\n                        }\n                    }\n                }\n            }\n        }\n        for (FaultInfo fi : operation.getFaults()) {\n            if (fi.getExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME) == null) {\n                String f = \"/Fault/\" + fi.getName().getLocalPart();\n                fi.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, \n                                         computeAction(operation, f));\n                if (operation.isUnwrappedCapable()) {\n                    fi = operation.getUnwrappedOperation().getFault(fi.getName());\n                    fi.addExtensionAttribute(JAXWSAConstants.WSAM_ACTION_QNAME, \n                                             computeAction(operation, f));\n                }                \n            }\n        }\n    }","commit_id":"c75a366b09e9731ab8ff321a15719eae631b137e","url":"https://github.com/apache/cxf"},{"original_method":"private int scheduleMatchingServices(String criteria) {\n        String sql = \"SELECT ifServices.nodeId AS nodeId, node.nodeLabel AS nodeLabel, ifServices.ipAddr AS ipAddr, \" +\n                \"ifServices.serviceId AS serviceId, service.serviceName AS serviceName, ifServices.status as status, \" +\n                \"outages.svcLostEventId AS svcLostEventId, events.eventUei AS svcLostEventUei, \" +\n                \"outages.ifLostService AS ifLostService, outages.ifRegainedService AS ifRegainedService \" +\n        \"FROM ifServices \" +\n        \"JOIN node ON ifServices.nodeId = node.nodeId \" +\n        \"JOIN service ON ifServices.serviceId = service.serviceId \" +\n        \"LEFT OUTER JOIN outages ON \" +\n        \"ifServices.nodeId = outages.nodeId AND \" +\n        \"ifServices.ipAddr = outages.ipAddr AND \" +\n        \"ifServices.serviceId = outages.serviceId AND \" +\n        \"ifRegainedService IS NULL \" +\n        \"LEFT OUTER JOIN events ON outages.svcLostEventId = events.eventid \" +\n        \"WHERE ifServices.status in ('A','N')\" +\n        (criteria == null ? \"\" : \" AND \"+criteria);\n       \n        \n        final AtomicInteger count = new AtomicInteger(0);\n        \n        Querier querier = new Querier(m_dataSource, sql) {\n            @Override\n            public void processRow(ResultSet rs) throws SQLException {\n                if (scheduleService(rs.getInt(\"nodeId\"), rs.getString(\"nodeLabel\"), rs.getString(\"ipAddr\"), rs.getString(\"serviceName\"), \n                                \"A\".equals(rs.getString(\"status\")), (Number)rs.getObject(\"svcLostEventId\"), rs.getTimestamp(\"ifLostService\"), \n                                rs.getString(\"svcLostEventUei\"))) {\n                    count.incrementAndGet();\n                }\n            }\n        };\n        querier.execute();\n        \n        \n        return count.get();\n\n    }","id":36891,"modified_method":"/**\n     * @deprecated Rewrite this function using the DAO calls instead of SQL.\n     * \n     * @param criteria\n     * @return\n     */\n    private int scheduleMatchingServices(String criteria) {\n        String sql = \"SELECT ifServices.nodeId AS nodeId, node.nodeLabel AS nodeLabel, ifServices.ipAddr AS ipAddr, \" +\n                \"ifServices.serviceId AS serviceId, service.serviceName AS serviceName, ifServices.status as status, \" +\n                \"outages.svcLostEventId AS svcLostEventId, events.eventUei AS svcLostEventUei, \" +\n                \"outages.ifLostService AS ifLostService, outages.ifRegainedService AS ifRegainedService \" +\n        \"FROM ifServices \" +\n        \"JOIN node ON ifServices.nodeId = node.nodeId \" +\n        \"JOIN service ON ifServices.serviceId = service.serviceId \" +\n        \"LEFT OUTER JOIN outages ON \" +\n        \"ifServices.nodeId = outages.nodeId AND \" +\n        \"ifServices.ipAddr = outages.ipAddr AND \" +\n        \"ifServices.serviceId = outages.serviceId AND \" +\n        \"ifRegainedService IS NULL \" +\n        \"LEFT OUTER JOIN events ON outages.svcLostEventId = events.eventid \" +\n        \"WHERE ifServices.status in ('A','N')\" +\n        (criteria == null ? \"\" : \" AND \"+criteria);\n       \n        \n        final AtomicInteger count = new AtomicInteger(0);\n        \n        Querier querier = new Querier(m_dataSource, sql) {\n            @Override\n            public void processRow(ResultSet rs) throws SQLException {\n                if (scheduleService(rs.getInt(\"nodeId\"), rs.getString(\"nodeLabel\"), rs.getString(\"ipAddr\"), rs.getString(\"serviceName\"), \n                                \"A\".equals(rs.getString(\"status\")), (Number)rs.getObject(\"svcLostEventId\"), rs.getTimestamp(\"ifLostService\"), \n                                rs.getString(\"svcLostEventUei\"))) {\n                    count.incrementAndGet();\n                }\n            }\n        };\n        querier.execute();\n        \n        \n        return count.get();\n\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <p>onInit<\/p>\n     */\n    @Override\n    protected void onInit() {\n        \n        // serviceUnresponsive behavior enabled/disabled?\n        LOG.debug(\"init: serviceUnresponsive behavior: {}\", (getPollerConfig().isServiceUnresponsiveEnabled() ? \"enabled\" : \"disabled\"));\n\n        createScheduler();\n        \n        try {\n            LOG.debug(\"init: Closing outages for unmanaged services\");\n            \n            closeOutagesForUnmanagedServices();\n        } catch (Throwable e) {\n            LOG.error(\"init: Failed to close ouates for unmanage services\", e);\n        }\n        \n\n        // Schedule the interfaces currently in the database\n        //\n        try {\n            LOG.debug(\"start: Scheduling existing interfaces\");\n\n            scheduleExistingServices();\n        } catch (Throwable sqlE) {\n            LOG.error(\"start: Failed to schedule existing interfaces\", sqlE);\n        }\n\n        // Create an event receiver. The receiver will\n        // receive events, process them, creates network\n        // interfaces, and schedulers them.\n        //\n        try {\n            LOG.debug(\"start: Creating event broadcast event processor\");\n\n            setEventProcessor(new PollerEventProcessor(this));\n        } catch (Throwable t) {\n            LOG.error(\"start: Failed to initialized the broadcast event receiver\", t);\n\n            throw new UndeclaredThrowableException(t);\n        }\n\n        m_initialized = true;\n\n    }","id":36892,"modified_method":"/**\n     * <p>onInit<\/p>\n     */\n    @Override\n    protected void onInit() {\n        \n        // serviceUnresponsive behavior enabled/disabled?\n        LOG.debug(\"init: serviceUnresponsive behavior: {}\", (getPollerConfig().isServiceUnresponsiveEnabled() ? \"enabled\" : \"disabled\"));\n\n        createScheduler();\n        \n        try {\n            LOG.debug(\"init: Closing outages for unmanaged services\");\n            \n            m_queryManager.closeOutagesForUnmanagedServices();\n        } catch (Throwable e) {\n            LOG.error(\"init: Failed to close ouates for unmanage services\", e);\n        }\n        \n\n        // Schedule the interfaces currently in the database\n        //\n        try {\n            LOG.debug(\"start: Scheduling existing interfaces\");\n\n            scheduleExistingServices();\n        } catch (Throwable sqlE) {\n            LOG.error(\"start: Failed to schedule existing interfaces\", sqlE);\n        }\n\n        // Create an event receiver. The receiver will\n        // receive events, process them, creates network\n        // interfaces, and schedulers them.\n        //\n        try {\n            LOG.debug(\"start: Creating event broadcast event processor\");\n\n            setEventProcessor(new PollerEventProcessor(this));\n        } catch (Throwable t) {\n            LOG.error(\"start: Failed to initialized the broadcast event receiver\", t);\n\n            throw new UndeclaredThrowableException(t);\n        }\n\n        m_initialized = true;\n\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <p>setQueryManager<\/p>\n     *\n     * @param queryManager a {@link org.opennms.netmgt.poller.QueryManager} object.\n     */\n    public void setQueryManager(QueryManager queryManager) {\n        m_queryManager = queryManager;\n    }","id":36893,"modified_method":"/**\n     * <p>setQueryManager<\/p>\n     *\n     * @param queryManager a {@link org.opennms.netmgt.poller.QueryManager} object.\n     */\n    void setQueryManager(QueryManager queryManager) {\n        m_queryManager = queryManager;\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <p>setEventManager<\/p>\n     *\n     * @param eventMgr a {@link org.opennms.netmgt.model.events.EventIpcManager} object.\n     */\n    public void setEventManager(EventIpcManager eventMgr) {\n        m_eventMgr = eventMgr;\n    }","id":36894,"modified_method":"/**\n     * <p>setEventManager<\/p>\n     *\n     * @param eventMgr a {@link org.opennms.netmgt.model.events.EventIpcManager} object.\n     */\n    void setEventManager(EventIpcManager eventMgr) {\n        m_eventMgr = eventMgr;\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <p>setDataSource<\/p>\n     *\n     * @param dataSource a {@link javax.sql.DataSource} object.\n     */\n    public void setDataSource(DataSource dataSource) {\n        m_dataSource = dataSource;\n    }","id":36895,"modified_method":"/**\n     * <p>setDataSource<\/p>\n     *\n     * @param dataSource a {@link javax.sql.DataSource} object.\n     */\n    void setDataSource(DataSource dataSource) {\n        m_dataSource = dataSource;\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private boolean scheduleService(int nodeId, String nodeLabel, String ipAddr, String serviceName, boolean active, Number svcLostEventId, Date date, String svcLostUei) {\n        // We don't want to adjust the management state of the service if we're\n        // on a machine that uses multiple servers with access to the same database\n        // so check the value of OpennmsServerConfigFactory.getInstance().verifyServer()\n        // before doing any updates.\n        Package pkg = findPackageForService(ipAddr, serviceName);\n        if (pkg == null) {\n            if(active && !OpennmsServerConfigFactory.getInstance().verifyServer()){\n                LOG.warn(\"Active service {} on {} not configured for any package. Marking as Not Polled.\", serviceName, ipAddr);\n                updateServiceStatus(nodeId, ipAddr, serviceName, \"N\");\n            }\n            return false;\n        } else if (!active && !OpennmsServerConfigFactory.getInstance().verifyServer()) {\n            LOG.info(\"Active service {} on {} is now configured for any package. Marking as active.\", serviceName, ipAddr);\n            updateServiceStatus(nodeId, ipAddr, serviceName, \"A\");\n        }\n\n        ServiceMonitor monitor = m_pollerConfig.getServiceMonitor(serviceName);\n        if (monitor == null) {\n            LOG.info(\"Could not find service monitor associated with service {}\", serviceName);\n            return false;\n        }\n        \n        InetAddress addr;\n        addr = InetAddressUtils.addr(ipAddr);\n        if (addr == null) {\n            LOG.error(\"Could not convert {} as an InetAddress {}\", ipAddr, ipAddr);\n            return false;\n        }\n        \n        PollableService svc = getNetwork().createService(nodeId, nodeLabel, addr, serviceName);\n        PollableServiceConfig pollConfig = new PollableServiceConfig(svc, m_pollerConfig, m_pollOutagesConfig, pkg, getScheduler());\n        svc.setPollConfig(pollConfig);\n        synchronized(svc) {\n            if (svc.getSchedule() == null) {\n                Schedule schedule = new Schedule(svc, pollConfig, getScheduler());\n                svc.setSchedule(schedule);\n            }\n        }\n        \n        \n        if (svcLostEventId == null) \n            if (svc.getParent().getStatus().isUnknown()) {\n                svc.updateStatus(PollStatus.up());\n            } else {\n                svc.updateStatus(svc.getParent().getStatus());\n            }\n        else {\n            svc.updateStatus(PollStatus.down());\n            \n            PollEvent cause = new DbPollEvent(svcLostEventId.intValue(), svcLostUei, date);\n\n            svc.setCause(cause);\n\n        }\n        \n        svc.schedule();\n        \n        return true;\n\n    }","id":36896,"modified_method":"private boolean scheduleService(int nodeId, String nodeLabel, String ipAddr, String serviceName, boolean active, Number svcLostEventId, Date date, String svcLostUei) {\n        // We don't want to adjust the management state of the service if we're\n        // on a machine that uses multiple servers with access to the same database\n        // so check the value of OpennmsServerConfigFactory.getInstance().verifyServer()\n        // before doing any updates.\n        Package pkg = findPackageForService(ipAddr, serviceName);\n        if (pkg == null) {\n            if(active && !OpennmsServerConfigFactory.getInstance().verifyServer()){\n                LOG.warn(\"Active service {} on {} not configured for any package. Marking as Not Polled.\", serviceName, ipAddr);\n                m_queryManager.updateServiceStatus(nodeId, ipAddr, serviceName, \"N\");\n            }\n            return false;\n        } else if (!active && !OpennmsServerConfigFactory.getInstance().verifyServer()) {\n            LOG.info(\"Active service {} on {} is now configured for any package. Marking as active.\", serviceName, ipAddr);\n            m_queryManager.updateServiceStatus(nodeId, ipAddr, serviceName, \"A\");\n        }\n\n        ServiceMonitor monitor = m_pollerConfig.getServiceMonitor(serviceName);\n        if (monitor == null) {\n            LOG.info(\"Could not find service monitor associated with service {}\", serviceName);\n            return false;\n        }\n        \n        InetAddress addr;\n        addr = InetAddressUtils.addr(ipAddr);\n        if (addr == null) {\n            LOG.error(\"Could not convert {} as an InetAddress {}\", ipAddr, ipAddr);\n            return false;\n        }\n        \n        PollableService svc = getNetwork().createService(nodeId, nodeLabel, addr, serviceName);\n        PollableServiceConfig pollConfig = new PollableServiceConfig(svc, m_pollerConfig, m_pollOutagesConfig, pkg, getScheduler());\n        svc.setPollConfig(pollConfig);\n        synchronized(svc) {\n            if (svc.getSchedule() == null) {\n                Schedule schedule = new Schedule(svc, pollConfig, getScheduler());\n                svc.setSchedule(schedule);\n            }\n        }\n        \n        \n        if (svcLostEventId == null) \n            if (svc.getParent().getStatus().isUnknown()) {\n                svc.updateStatus(PollStatus.up());\n            } else {\n                svc.updateStatus(svc.getParent().getStatus());\n            }\n        else {\n            svc.updateStatus(PollStatus.down());\n            \n            PollEvent cause = new DbPollEvent(svcLostEventId.intValue(), svcLostUei, date);\n\n            svc.setCause(cause);\n\n        }\n        \n        svc.schedule();\n        \n        return true;\n\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * \n     */\n    private void interfaceDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        String sourceUei = event.getUei();\n        InetAddress ipAddr = event.getInterfaceAddress();\n        \n        // Extract node label and transaction No. from the event parms\n        long txNo = -1L;\n        String parmName = null;\n        Value parmValue = null;\n        String parmContent = null;\n\n        for (Parm parm : event.getParmCollection()) {\n            parmName = parm.getParmName();\n            parmValue = parm.getValue();\n            if (parmValue == null)\n                continue;\n            else\n                parmContent = parmValue.getContent();\n\n            // get the external transaction number\n            if (parmName.equals(EventConstants.PARM_TRANSACTION_NO)) {\n                String temp = parmContent;\n                LOG.debug(\"interfaceDeletedHandlerHandler:  parmName: {} /parmContent: {}\", parmName, parmContent);\n                try {\n                    txNo = Long.valueOf(temp).longValue();\n                } catch (final NumberFormatException nfe) {\n                    LOG.warn(\"interfaceDeletedHandlerHandler: Parameter {} cannot be non-numberic\", EventConstants.PARM_TRANSACTION_NO, nfe);\n                    txNo = -1;\n                }\n            }\n        }\n\n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().closeOutagesForInterface(closeDate, event.getDbid(), nodeId.intValue(), InetAddressUtils.str(ipAddr));\n\n        \n        PollableInterface iface = getNetwork().getInterface(nodeId.intValue(), ipAddr);\n        if (iface == null) {\n          LOG.error(\"Interface {}/{} does not exist in pollable node map, unable to delete node.\", nodeId, event.getInterface());\n          if (isXmlRPCEnabled()) {\n              int status = EventConstants.XMLRPC_NOTIFY_FAILURE;\n              XmlrpcUtil.createAndSendXmlrpcNotificationEvent(txNo, sourceUei, \"Interface does not exist in pollable node map.\", status, \"OpenNMS.Poller\");\n          }\n          return;\n        }\n        iface.delete();\n\n    }","id":36897,"modified_method":"/**\n     * \n     */\n    private void interfaceDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        String sourceUei = event.getUei();\n        InetAddress ipAddr = event.getInterfaceAddress();\n        \n        // Extract node label and transaction No. from the event parms\n        long txNo = -1L;\n        String parmName = null;\n        Value parmValue = null;\n        String parmContent = null;\n\n        for (Parm parm : event.getParmCollection()) {\n            parmName = parm.getParmName();\n            parmValue = parm.getValue();\n            if (parmValue == null)\n                continue;\n            else\n                parmContent = parmValue.getContent();\n\n            // get the external transaction number\n            if (parmName.equals(EventConstants.PARM_TRANSACTION_NO)) {\n                String temp = parmContent;\n                LOG.debug(\"interfaceDeletedHandlerHandler:  parmName: {} /parmContent: {}\", parmName, parmContent);\n                try {\n                    txNo = Long.valueOf(temp).longValue();\n                } catch (final NumberFormatException nfe) {\n                    LOG.warn(\"interfaceDeletedHandlerHandler: Parameter {} cannot be non-numberic\", EventConstants.PARM_TRANSACTION_NO, nfe);\n                    txNo = -1;\n                }\n            }\n        }\n\n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().getQueryManager().closeOutagesForInterface(closeDate, event.getDbid(), nodeId.intValue(), InetAddressUtils.str(ipAddr));\n\n        \n        PollableInterface iface = getNetwork().getInterface(nodeId.intValue(), ipAddr);\n        if (iface == null) {\n          LOG.error(\"Interface {}/{} does not exist in pollable node map, unable to delete node.\", nodeId, event.getInterface());\n          if (isXmlRPCEnabled()) {\n              int status = EventConstants.XMLRPC_NOTIFY_FAILURE;\n              XmlrpcUtil.createAndSendXmlrpcNotificationEvent(txNo, sourceUei, \"Interface does not exist in pollable node map.\", status, \"OpenNMS.Poller\");\n          }\n          return;\n        }\n        iface.delete();\n\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * This method is responsible for removing the node specified in the\n     * nodeDeleted event from the Poller's pollable node map.\n     */\n    private void nodeDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        final String sourceUei = event.getUei();\n\n        // Extract node label and transaction No. from the event parms\n        long txNo = -1L;\n        String parmName = null;\n        Value parmValue = null;\n        String parmContent = null;\n\n        for (Parm parm : event.getParmCollection()) {\n            parmName = parm.getParmName();\n            parmValue = parm.getValue();\n            if (parmValue == null)\n                continue;\n            else\n                parmContent = parmValue.getContent();\n\n            // get the external transaction number\n            if (parmName.equals(EventConstants.PARM_TRANSACTION_NO)) {\n                String temp = parmContent;\n                LOG.debug(\"nodeDeletedHandler:  parmName: {} /parmContent: {}\", parmName, parmContent);\n                try {\n                    txNo = Long.valueOf(temp).longValue();\n                } catch (final NumberFormatException nfe) {\n                    LOG.warn(\"nodeDeletedHandler: Parameter {} cannot be non-numeric\", EventConstants.PARM_TRANSACTION_NO, nfe);\n                    txNo = -1;\n                }\n            }\n        }\n\n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().closeOutagesForNode(closeDate, event.getDbid(), nodeId.intValue());\n\n        \n        PollableNode node = getNetwork().getNode(nodeId.intValue());\n        if (node == null) {\n          LOG.error(\"Nodeid {} does not exist in pollable node map, unable to delete node.\", nodeId);\n          if (isXmlRPCEnabled()) {\n              int status = EventConstants.XMLRPC_NOTIFY_FAILURE;\n              XmlrpcUtil.createAndSendXmlrpcNotificationEvent(txNo, sourceUei, \"Node does not exist in pollable node map.\", status, \"OpenNMS.Poller\");\n          }\n          return;\n        }\n        node.delete();\n       \n    }","id":36898,"modified_method":"/**\n     * This method is responsible for removing the node specified in the\n     * nodeDeleted event from the Poller's pollable node map.\n     */\n    private void nodeDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        final String sourceUei = event.getUei();\n\n        // Extract node label and transaction No. from the event parms\n        long txNo = -1L;\n        String parmName = null;\n        Value parmValue = null;\n        String parmContent = null;\n\n        for (Parm parm : event.getParmCollection()) {\n            parmName = parm.getParmName();\n            parmValue = parm.getValue();\n            if (parmValue == null)\n                continue;\n            else\n                parmContent = parmValue.getContent();\n\n            // get the external transaction number\n            if (parmName.equals(EventConstants.PARM_TRANSACTION_NO)) {\n                String temp = parmContent;\n                LOG.debug(\"nodeDeletedHandler:  parmName: {} /parmContent: {}\", parmName, parmContent);\n                try {\n                    txNo = Long.valueOf(temp).longValue();\n                } catch (final NumberFormatException nfe) {\n                    LOG.warn(\"nodeDeletedHandler: Parameter {} cannot be non-numeric\", EventConstants.PARM_TRANSACTION_NO, nfe);\n                    txNo = -1;\n                }\n            }\n        }\n\n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().getQueryManager().closeOutagesForNode(closeDate, event.getDbid(), nodeId.intValue());\n\n        \n        PollableNode node = getNetwork().getNode(nodeId.intValue());\n        if (node == null) {\n          LOG.error(\"Nodeid {} does not exist in pollable node map, unable to delete node.\", nodeId);\n          if (isXmlRPCEnabled()) {\n              int status = EventConstants.XMLRPC_NOTIFY_FAILURE;\n              XmlrpcUtil.createAndSendXmlrpcNotificationEvent(txNo, sourceUei, \"Node does not exist in pollable node map.\", status, \"OpenNMS.Poller\");\n          }\n          return;\n        }\n        node.delete();\n       \n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private void serviceReschedule(Event event)   {       \n       PollableNode pnode = getNetwork().getNode(event.getNodeid().intValue());\n       Long nodeId = event.getNodeid();\n       String nodeLabel = pnode.getNodeLabel();\n       \n       //pnode.delete();\n       //nodeDeletedHandler(event);\n       \n       /*while(pnode.isDeleted()==false){\n           \n           LOG.debug(\"Waiting for node to delete...\");\n           \n       }*/\n       \n       List<String[]> list = getPoller().getQueryManager().getNodeServices(nodeId.intValue());\n       \n       for(String[] row : list){\n           LOG.debug(\" Removing the following from the list: {}:{}\", row[0],row[1]);\n           \n           InetAddress addr;\n           addr = InetAddressUtils.addr(row[0]);\n           if (addr == null) {\n               LOG.warn(\"Rescheduler: Could not convert {} to an InetAddress\", row[0]);\n               return;\n           }\n           \n           Date closeDate;\n           try {\n               closeDate = EventConstants.parseToDate(event.getTime());\n           } catch (ParseException e) {\n               closeDate = new Date();\n           }\n           \n           getPoller().closeOutagesForService(closeDate, event.getDbid(), nodeId.intValue(), row[0], row[1]);\n           \n           PollableService svc = getNetwork().getService(nodeId.intValue(),addr,row[1]);\n           \n           if (svc != null) {\n           \n               svc.delete();\n           \n               while(svc.isDeleted()==false){\n                   LOG.debug(\"Waiting for the service to delete...\");\n               }\n           \n           }\n           \n           else {\n               LOG.debug(\"Service Not Found\");\n           }\n           \n       }\n       \n       getPoller().getPollerConfig().rebuildPackageIpListMap();\n       \n       for(String[] row : list){\n           LOG.debug(\" Re-adding the following to the list: {}:{}\", row[0],row[1]);\n           getPoller().scheduleService(nodeId.intValue(),nodeLabel,row[0],row[1]);\n       }\n    }","id":36899,"modified_method":"private void serviceReschedule(Event event)   {       \n       PollableNode pnode = getNetwork().getNode(event.getNodeid().intValue());\n       Long nodeId = event.getNodeid();\n       String nodeLabel = pnode.getNodeLabel();\n       \n       //pnode.delete();\n       //nodeDeletedHandler(event);\n       \n       /*while(pnode.isDeleted()==false){\n           \n           LOG.debug(\"Waiting for node to delete...\");\n           \n       }*/\n       \n       List<String[]> list = getPoller().getQueryManager().getNodeServices(nodeId.intValue());\n       \n       for(String[] row : list){\n           LOG.debug(\" Removing the following from the list: {}:{}\", row[0],row[1]);\n           \n           InetAddress addr;\n           addr = InetAddressUtils.addr(row[0]);\n           if (addr == null) {\n               LOG.warn(\"Rescheduler: Could not convert {} to an InetAddress\", row[0]);\n               return;\n           }\n           \n           Date closeDate;\n           try {\n               closeDate = EventConstants.parseToDate(event.getTime());\n           } catch (ParseException e) {\n               closeDate = new Date();\n           }\n           \n           getPoller().getQueryManager().closeOutagesForService(closeDate, event.getDbid(), nodeId.intValue(), row[0], row[1]);\n           \n           PollableService svc = getNetwork().getService(nodeId.intValue(),addr,row[1]);\n           \n           if (svc != null) {\n           \n               svc.delete();\n           \n               while(svc.isDeleted()==false){\n                   LOG.debug(\"Waiting for the service to delete...\");\n               }\n           \n           }\n           \n           else {\n               LOG.debug(\"Service Not Found\");\n           }\n           \n       }\n       \n       getPoller().getPollerConfig().rebuildPackageIpListMap();\n       \n       for(String[] row : list){\n           LOG.debug(\" Re-adding the following to the list: {}:{}\", row[0],row[1]);\n           getPoller().scheduleService(nodeId.intValue(),nodeLabel,row[0],row[1]);\n       }\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * <p>\n     * This method remove a deleted service from the pollable service list of\n     * the specified interface, so that it will not be scheduled by the poller.\n     * <\/p>\n     */\n    private void serviceDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        InetAddress ipAddr = event.getInterfaceAddress();\n        String service = event.getService();\n        \n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().closeOutagesForService(closeDate, event.getDbid(), nodeId.intValue(), InetAddressUtils.str(ipAddr), service);\n        \n        PollableService svc = getNetwork().getService(nodeId.intValue(), ipAddr, service);\n        if (svc == null) {\n          LOG.error(\"Interface {}/{} does not exist in pollable node map, unable to delete node.\", nodeId, event.getInterface());\n          return;\n        }\n        \n        svc.delete();\n\n    }","id":36900,"modified_method":"/**\n     * <p>\n     * This method remove a deleted service from the pollable service list of\n     * the specified interface, so that it will not be scheduled by the poller.\n     * <\/p>\n     */\n    private void serviceDeletedHandler(Event event) {\n        Long nodeId = event.getNodeid();\n        InetAddress ipAddr = event.getInterfaceAddress();\n        String service = event.getService();\n        \n        Date closeDate;\n        try {\n            closeDate = EventConstants.parseToDate(event.getTime());\n        } catch (ParseException e) {\n            closeDate = new Date();\n        }\n        \n        getPoller().getQueryManager().closeOutagesForService(closeDate, event.getDbid(), nodeId.intValue(), InetAddressUtils.str(ipAddr), service);\n        \n        PollableService svc = getNetwork().getService(nodeId.intValue(), ipAddr, service);\n        if (svc == null) {\n          LOG.error(\"Interface {}/{} does not exist in pollable node map, unable to delete node.\", nodeId, event.getInterface());\n          return;\n        }\n        \n        svc.delete();\n\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/** {@inheritDoc} */\n    @Override\n    public void openOutage(String outageIdSQL, int nodeId, String ipAddr, String svcName, int dbId, String time) {\n        \n        int attempt = 0;\n        boolean notUpdated = true;\n        int serviceId = getServiceID(svcName);\n        \n        while (attempt < 2 && notUpdated) {\n            try {\n                LOG.info(\"openOutage: opening outage for {}:{}:{} with cause {}:{}\", nodeId, ipAddr, svcName, dbId, time);\n                \n                SingleResultQuerier srq = new SingleResultQuerier(getDataSource(), outageIdSQL);\n                srq.execute();\n                Object outageId = srq.getResult();\n                \n                if (outageId == null) {\n                    throw (new Exception(\"Null outageId returned from Querier with SQL: \"+outageIdSQL));\n                }\n                \n                String sql = \"insert into outages (outageId, svcLostEventId, nodeId, ipAddr, serviceId, ifLostService) values (\"+outageId+\", ?, ?, ?, ?, ?)\";\n                \n                Object values[] = {\n                        Integer.valueOf(dbId),\n                        Integer.valueOf(nodeId),\n                        ipAddr,\n                        Integer.valueOf(serviceId),\n                        convertEventTimeToTimeStamp(time),\n                };\n\n                Updater updater = new Updater(getDataSource(), sql);\n                updater.execute(values);\n                notUpdated = false;\n            } catch (Throwable e) {\n                if (attempt > 1) {\n                    LOG.error(\"openOutage: Second and final attempt failed opening outage for {}:{}:{}\", nodeId, ipAddr, svcName, e);\n                } else {\n                    LOG.info(\"openOutage: First attempt failed opening outage for {}:{}:{}\", nodeId, ipAddr, svcName, e);\n                }\n            }\n            attempt++;\n        }\n    }","id":36901,"modified_method":"@Override\n    public void openOutage(String outageIdSQL, int nodeId, String ipAddr, String svcName, int dbId, String time) {\n        openOutage(nodeId, ipAddr, svcName, dbId, time);\n    }","commit_id":"b95154f2a6506b5a7f28e664298e63aeedaa25b9","url":"https://github.com/OpenNMS/opennms"},{"original_method":"protected void addDelegateStaticMethod(ClassNode classNode, MethodCallExpression apiLookupMethod,\n            MethodNode declaredMethod, Map<String, ClassNode> genericsPlaceholders) {\n        GrailsASTUtils.addDelegateStaticMethod(apiLookupMethod, classNode, declaredMethod, getMarkerAnnotation(), genericsPlaceholders);\n    }","id":36902,"modified_method":"protected void addDelegateStaticMethod(ClassNode classNode, MethodCallExpression apiLookupMethod,\n            MethodNode declaredMethod, Map<String, ClassNode> genericsPlaceholders) {\n        GrailsASTUtils.addCompileStaticAnnotation(GrailsASTUtils.addDelegateStaticMethod(apiLookupMethod, classNode, declaredMethod, getMarkerAnnotation(), genericsPlaceholders, true));\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"protected void addApiLookupFieldAndSetter(ClassNode classNode, ClassNode implementationNode,\n            String apiProperty, Expression initialValueExpression) {\n        FieldNode fieldNode = classNode.getField(apiProperty);\n        if (fieldNode == null || !fieldNode.getDeclaringClass().equals(classNode)) {\n            fieldNode = new FieldNode(apiProperty, Modifier.PRIVATE | Modifier.STATIC, implementationNode, classNode, initialValueExpression);\n            classNode.addField(fieldNode);\n            \n            String setterName = \"set\" + MetaClassHelper.capitalize(apiProperty);\n            Parameter setterParameter = new Parameter(implementationNode, apiProperty);\n            BlockStatement setterBody = new BlockStatement();\n            setterBody.addStatement(new ExpressionStatement(new BinaryExpression(new AttributeExpression(\n                    new ClassExpression(classNode), new ConstantExpression(apiProperty)), Token.newSymbol(Types.EQUAL, 0, 0),\n                    new VariableExpression(setterParameter))));\n\n            classNode.addMethod(setterName, Modifier.PUBLIC | Modifier.STATIC, ClassHelper.VOID_TYPE, new Parameter[]{setterParameter}, null, setterBody);\n        }\n    }","id":36903,"modified_method":"protected void addApiLookupFieldAndSetter(ClassNode classNode, ClassNode implementationNode,\n            String apiProperty, Expression initialValueExpression) {\n        FieldNode fieldNode = classNode.getField(apiProperty);\n        if (fieldNode == null || !fieldNode.getDeclaringClass().equals(classNode)) {\n            fieldNode = new FieldNode(apiProperty, Modifier.PRIVATE | Modifier.STATIC, implementationNode, classNode, initialValueExpression);\n            classNode.addField(fieldNode);\n            \n            String setterName = \"set\" + MetaClassHelper.capitalize(apiProperty);\n            Parameter setterParameter = new Parameter(implementationNode, apiProperty);\n            BlockStatement setterBody = new BlockStatement();\n            setterBody.addStatement(new ExpressionStatement(new BinaryExpression(new AttributeExpression(\n                    new ClassExpression(classNode), new ConstantExpression(apiProperty)), Token.newSymbol(Types.EQUAL, 0, 0),\n                    new VariableExpression(setterParameter))));\n\n            GrailsASTUtils.addCompileStaticAnnotation(classNode.addMethod(setterName, Modifier.PUBLIC | Modifier.STATIC, ClassHelper.VOID_TYPE, new Parameter[]{setterParameter}, null, setterBody));\n        }\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"protected void addDelegateInstanceMethod(ClassNode classNode, Expression delegate, MethodNode declaredMethod, AnnotationNode markerAnnotation, Map<String, ClassNode> genericsPlaceholders) {\n        GrailsASTUtils.addDelegateInstanceMethod(classNode, delegate, declaredMethod, getMarkerAnnotation(), true, genericsPlaceholders);\n    }","id":36904,"modified_method":"protected void addDelegateInstanceMethod(ClassNode classNode, Expression delegate, MethodNode declaredMethod, AnnotationNode markerAnnotation, Map<String, ClassNode> genericsPlaceholders) {\n        GrailsASTUtils.addCompileStaticAnnotation(GrailsASTUtils.addDelegateInstanceMethod(classNode, delegate, declaredMethod, getMarkerAnnotation(), true, genericsPlaceholders, true));\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"protected MethodNode populateAutowiredApiLookupMethod(ClassNode classNode, ClassNode implementationNode,\n                                                          String apiProperty, String methodName, BlockStatement methodBody) {\n        \n        addApiLookupFieldAndSetter(classNode, implementationNode, apiProperty, null);\n        \n        VariableExpression apiVar = new VariableExpression(apiProperty, implementationNode);\n        \n        BlockStatement ifBlock = new BlockStatement();\n        ArgumentListExpression arguments = new ArgumentListExpression();\n        arguments.addExpression(new ConstantExpression(\"Method on class [\"+classNode+\"] was used outside of a Grails application. If running in the context of a test using the mocking API or bootstrap Grails correctly.\"));\n        ifBlock.addStatement(new ThrowStatement(new ConstructorCallExpression(new ClassNode(IllegalStateException.class), arguments)));        \n        BlockStatement elseBlock = new BlockStatement();\n        elseBlock.addStatement(new ReturnStatement(apiVar));\n        methodBody.addStatement(new IfStatement(new BooleanExpression(new BinaryExpression(apiVar, GrailsASTUtils.EQUALS_OPERATOR, GrailsASTUtils.NULL_EXPRESSION)),ifBlock,elseBlock));\n        \n        return new MethodNode(methodName, PUBLIC_STATIC_MODIFIER, implementationNode,ZERO_PARAMETERS,null,methodBody);\n    }","id":36905,"modified_method":"protected MethodNode populateAutowiredApiLookupMethod(ClassNode classNode, ClassNode implementationNode,\n                                                          String apiProperty, String methodName, BlockStatement methodBody) {\n        \n        addApiLookupFieldAndSetter(classNode, implementationNode, apiProperty, null);\n        \n        VariableExpression apiVar = new VariableExpression(apiProperty, implementationNode);\n        \n        BlockStatement ifBlock = new BlockStatement();\n        ArgumentListExpression arguments = new ArgumentListExpression();\n        arguments.addExpression(new ConstantExpression(\"Method on class [\"+classNode+\"] was used outside of a Grails application. If running in the context of a test using the mocking API or bootstrap Grails correctly.\"));\n        ifBlock.addStatement(new ThrowStatement(new ConstructorCallExpression(new ClassNode(IllegalStateException.class), arguments)));        \n        BlockStatement elseBlock = new BlockStatement();\n        elseBlock.addStatement(new ReturnStatement(apiVar));\n        methodBody.addStatement(new IfStatement(new BooleanExpression(new BinaryExpression(apiVar, GrailsASTUtils.EQUALS_OPERATOR, GrailsASTUtils.NULL_EXPRESSION)),ifBlock,elseBlock));\n        \n        MethodNode methodNode = new MethodNode(methodName, PUBLIC_STATIC_MODIFIER, implementationNode,ZERO_PARAMETERS,null,methodBody);        \n        return methodNode;\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"private void createStaticLookupMethod(ClassNode classNode, ClassNode implementationNode, String apiProperty, String lookupMethodName) {\n        // if autowiring is required we add a default method that throws an exception\n        // the method should be override via meta-programming in the Grails environment\n        MethodNode lookupMethod = classNode.getMethod(lookupMethodName, ZERO_PARAMETERS);\n        if (lookupMethod == null  || !lookupMethod.getDeclaringClass().equals(classNode)) {\n            BlockStatement methodBody = new BlockStatement();\n            lookupMethod = populateAutowiredApiLookupMethod(classNode, implementationNode, apiProperty, lookupMethodName, methodBody);\n            classNode.addMethod(lookupMethod);\n        }\n    }","id":36906,"modified_method":"private void createStaticLookupMethod(ClassNode classNode, ClassNode implementationNode, String apiProperty, String lookupMethodName) {\n        // if autowiring is required we add a default method that throws an exception\n        // the method should be override via meta-programming in the Grails environment\n        MethodNode lookupMethod = classNode.getMethod(lookupMethodName, ZERO_PARAMETERS);\n        if (lookupMethod == null  || !lookupMethod.getDeclaringClass().equals(classNode)) {\n            BlockStatement methodBody = new BlockStatement();\n            lookupMethod = populateAutowiredApiLookupMethod(classNode, implementationNode, apiProperty, lookupMethodName, methodBody);\n            classNode.addMethod(lookupMethod);\n            GrailsASTUtils.addCompileStaticAnnotation(lookupMethod);\n        }\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"private static VariableExpression addApiVariableDeclaration(Expression delegate, MethodNode declaredMethod, BlockStatement methodBody) {\n        VariableExpression apiVar = new VariableExpression(\"$api_\" + declaredMethod.getName());\n        DeclarationExpression de = new DeclarationExpression(apiVar, ASSIGNMENT_OPERATOR, delegate);\n        methodBody.addStatement(new ExpressionStatement(de));\n        return apiVar;\n    }","id":36907,"modified_method":"private static VariableExpression addApiVariableDeclaration(Expression delegate, MethodNode declaredMethod, BlockStatement methodBody) {\n        VariableExpression apiVar = new VariableExpression(\"$api_\" + declaredMethod.getName(), delegate.getType());\n        DeclarationExpression de = new DeclarationExpression(apiVar, ASSIGNMENT_OPERATOR, delegate);\n        methodBody.addStatement(new ExpressionStatement(de));\n        return apiVar;\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"/**\n     * Adds or modifies an existing constructor to delegate to the\n     * given static constructor method for initialization logic.\n     *\n     * @param classNode The class node\n     * @param constructorMethod The constructor static method\n     */\n    public static void addDelegateConstructor(ClassNode classNode, MethodNode constructorMethod, Map<String, ClassNode> genericsPlaceholders) {\n        BlockStatement constructorBody = new BlockStatement();\n        Parameter[] constructorParams = getRemainingParameterTypes(constructorMethod.getParameters());\n        ArgumentListExpression arguments = createArgumentListFromParameters(constructorParams, true, genericsPlaceholders);\n        MethodCallExpression constructCallExpression = new MethodCallExpression(\n                new ClassExpression(constructorMethod.getDeclaringClass()), \"initialize\", arguments);\n        constructCallExpression.setMethodTarget(constructorMethod);\n        ExpressionStatement constructorInitExpression = new ExpressionStatement(constructCallExpression);\n        if (constructorParams.length > 0) {\n            constructorBody.addStatement(new ExpressionStatement(new ConstructorCallExpression(ClassNode.THIS, GrailsArtefactClassInjector.ZERO_ARGS)));\n        }\n        constructorBody.addStatement(constructorInitExpression);\n\n        if (constructorParams.length == 0) {\n            // handle default constructor\n\n            ConstructorNode constructorNode = getDefaultConstructor(classNode);\n            if (constructorNode != null) {\n                List<AnnotationNode> annotations = constructorNode.getAnnotations(new ClassNode(GrailsDelegatingConstructor.class));\n                if (annotations.size() == 0) {\n                    Statement existingBodyCode = constructorNode.getCode();\n                    if (existingBodyCode instanceof BlockStatement) {\n                        ((BlockStatement) existingBodyCode).addStatement(constructorInitExpression);\n                    }\n                    else {\n                        constructorNode.setCode(constructorBody);\n                    }\n                }\n            } else {\n                constructorNode = new ConstructorNode(Modifier.PUBLIC, constructorBody);\n                classNode.addConstructor(constructorNode);\n            }\n            constructorNode.addAnnotation(new AnnotationNode(new ClassNode(GrailsDelegatingConstructor.class)));\n        }\n        else {\n            // create new constructor, restoring default constructor if there is none\n            ConstructorNode cn = findConstructor(classNode, constructorParams);\n            if (cn == null) {\n                cn = new ConstructorNode(Modifier.PUBLIC, copyParameters(constructorParams, genericsPlaceholders), null, constructorBody);\n                classNode.addConstructor(cn);\n            }\n            else {\n                List<AnnotationNode> annotations = cn.getAnnotations(new ClassNode(GrailsDelegatingConstructor.class));\n                if (annotations.size() == 0) {\n                    Statement code = cn.getCode();\n                    constructorBody.addStatement(code);\n                    cn.setCode(constructorBody);\n                }\n            }\n\n            ConstructorNode defaultConstructor = getDefaultConstructor(classNode);\n            if (defaultConstructor == null) {\n                // add empty\n                classNode.addConstructor(new ConstructorNode(Modifier.PUBLIC, new BlockStatement()));\n            }\n            cn.addAnnotation(new AnnotationNode(new ClassNode(GrailsDelegatingConstructor.class)));\n        }\n    }","id":36908,"modified_method":"/**\n     * Adds or modifies an existing constructor to delegate to the\n     * given static constructor method for initialization logic.\n     *\n     * @param classNode The class node\n     * @param constructorMethod The constructor static method\n     */\n    public static ConstructorNode addDelegateConstructor(ClassNode classNode, MethodNode constructorMethod, Map<String, ClassNode> genericsPlaceholders) {\n        BlockStatement constructorBody = new BlockStatement();\n        Parameter[] constructorParams = getRemainingParameterTypes(constructorMethod.getParameters());\n        ArgumentListExpression arguments = createArgumentListFromParameters(constructorParams, true, genericsPlaceholders);\n        MethodCallExpression constructCallExpression = new MethodCallExpression(\n                new ClassExpression(constructorMethod.getDeclaringClass()), \"initialize\", arguments);\n        constructCallExpression.setMethodTarget(constructorMethod);\n        ExpressionStatement constructorInitExpression = new ExpressionStatement(constructCallExpression);\n        if (constructorParams.length > 0) {\n            constructorBody.addStatement(new ExpressionStatement(new ConstructorCallExpression(ClassNode.THIS, GrailsArtefactClassInjector.ZERO_ARGS)));\n        }\n        constructorBody.addStatement(constructorInitExpression);\n\n        if (constructorParams.length == 0) {\n            // handle default constructor\n\n            ConstructorNode constructorNode = getDefaultConstructor(classNode);\n            if (constructorNode != null) {\n                List<AnnotationNode> annotations = constructorNode.getAnnotations(new ClassNode(GrailsDelegatingConstructor.class));\n                if (annotations.size() == 0) {\n                    Statement existingBodyCode = constructorNode.getCode();\n                    if (existingBodyCode instanceof BlockStatement) {\n                        ((BlockStatement) existingBodyCode).addStatement(constructorInitExpression);\n                    }\n                    else {\n                        constructorNode.setCode(constructorBody);\n                    }\n                }\n            } else {\n                constructorNode = new ConstructorNode(Modifier.PUBLIC, constructorBody);\n                classNode.addConstructor(constructorNode);\n            }\n            constructorNode.addAnnotation(new AnnotationNode(new ClassNode(GrailsDelegatingConstructor.class)));\n            return constructorNode;\n        }\n        else {\n            // create new constructor, restoring default constructor if there is none\n            ConstructorNode cn = findConstructor(classNode, constructorParams);\n            if (cn == null) {\n                cn = new ConstructorNode(Modifier.PUBLIC, copyParameters(constructorParams, genericsPlaceholders), null, constructorBody);\n                classNode.addConstructor(cn);\n            }\n            else {\n                List<AnnotationNode> annotations = cn.getAnnotations(new ClassNode(GrailsDelegatingConstructor.class));\n                if (annotations.size() == 0) {\n                    Statement code = cn.getCode();\n                    constructorBody.addStatement(code);\n                    cn.setCode(constructorBody);\n                }\n            }\n\n            ConstructorNode defaultConstructor = getDefaultConstructor(classNode);\n            if (defaultConstructor == null) {\n                // add empty\n                classNode.addConstructor(new ConstructorNode(Modifier.PUBLIC, new BlockStatement()));\n            }\n            cn.addAnnotation(new AnnotationNode(new ClassNode(GrailsDelegatingConstructor.class)));\n            return cn;\n        }\n    }","commit_id":"8fb057d05c0e0f403d0df4f0165b8e80af4c5199","url":"https://github.com/grails/grails-core"},{"original_method":"public ControllersApi() {\n        super(null);\n    }","id":36909,"modified_method":"public ControllersApi() {\n        this(null);\n    }","commit_id":"852d04ca4f9598cc09085f5905afdbf28a1dfd3c","url":"https://github.com/grails/grails-core"},{"original_method":"/**\n     * Adds a delegate method to the target class node where the first argument is to the delegate method is 'this'.\n     * In other words a method such as foo(Object instance, String bar) would be added with a signature of foo(String)\n     * and 'this' is passed to the delegate instance\n     *\n     * @param classNode The class node\n     * @param delegate The expression that looks up the delegate\n     * @param declaredMethod The declared method\n     * @param thisAsFirstArgument Whether 'this' should be passed as the first argument to the method\n     */\n    public static void addDelegateInstanceMethod(ClassNode classNode, Expression delegate, MethodNode declaredMethod, boolean thisAsFirstArgument) {\n        Parameter[] parameterTypes = getRemainingParameterTypes(declaredMethod.getParameters());\n        if(!classNode.hasDeclaredMethod(declaredMethod.getName(), parameterTypes)) {\n            BlockStatement methodBody = new BlockStatement();\n            ArgumentListExpression arguments = new ArgumentListExpression();\n\n            if(thisAsFirstArgument) {\n                arguments.addExpression(AbstractGrailsArtefactTransformer.THIS_EXPRESSION);\n            }\n\n            for (Parameter parameterType : parameterTypes) {\n                arguments.addExpression(new VariableExpression(parameterType.getName()));\n            }\n            methodBody.addStatement(new ExpressionStatement( new MethodCallExpression(delegate, declaredMethod.getName(), arguments)));\n            MethodNode methodNode = new MethodNode(declaredMethod.getName(),\n                                                   Modifier.PUBLIC,\n                                                   declaredMethod.getReturnType(),\n                                                   parameterTypes,\n                                                   GrailsArtefactClassInjector.EMPTY_CLASS_ARRAY,\n                                                   methodBody\n                                                    );\n            methodNode.addAnnotations(declaredMethod.getAnnotations());\n\n            classNode.addMethod(methodNode);\n        }\n    }","id":36910,"modified_method":"/**\n     * Adds a delegate method to the target class node where the first argument is to the delegate method is 'this'.\n     * In other words a method such as foo(Object instance, String bar) would be added with a signature of foo(String)\n     * and 'this' is passed to the delegate instance\n     *\n     * @param classNode The class node\n     * @param delegate The expression that looks up the delegate\n     * @param declaredMethod The declared method\n     * @param thisAsFirstArgument Whether 'this' should be passed as the first argument to the method\n     */\n    public static void addDelegateInstanceMethod(ClassNode classNode, Expression delegate, MethodNode declaredMethod, boolean thisAsFirstArgument) {\n        Parameter[] parameterTypes = thisAsFirstArgument ? getRemainingParameterTypes(declaredMethod.getParameters()) : declaredMethod.getParameters();\n        if(!classNode.hasDeclaredMethod(declaredMethod.getName(), parameterTypes)) {\n            BlockStatement methodBody = new BlockStatement();\n            ArgumentListExpression arguments = new ArgumentListExpression();\n\n            if(thisAsFirstArgument) {\n                arguments.addExpression(AbstractGrailsArtefactTransformer.THIS_EXPRESSION);\n            }\n\n            for (Parameter parameterType : parameterTypes) {\n                arguments.addExpression(new VariableExpression(parameterType.getName()));\n            }\n            methodBody.addStatement(new ExpressionStatement( new MethodCallExpression(delegate, declaredMethod.getName(), arguments)));\n            MethodNode methodNode = new MethodNode(declaredMethod.getName(),\n                                                   Modifier.PUBLIC,\n                                                   declaredMethod.getReturnType(),\n                                                   parameterTypes,\n                                                   GrailsArtefactClassInjector.EMPTY_CLASS_ARRAY,\n                                                   methodBody\n                                                    );\n            methodNode.addAnnotations(declaredMethod.getAnnotations());\n\n            classNode.addMethod(methodNode);\n        }\n    }","commit_id":"852d04ca4f9598cc09085f5905afdbf28a1dfd3c","url":"https://github.com/grails/grails-core"},{"original_method":"private UrlMappingsHolder getUrlMappingsHolder(GrailsWebRequest webRequest) {\n        if(this.urlMappingsHolder == null) {\n            urlMappingsHolder = webRequest.getApplicationContext().getBean(UrlMappingsHolder.BEAN_ID, UrlMappingsHolder.class);\n        }\n        return urlMappingsHolder;\n    }","id":36911,"modified_method":"private UrlMappingsHolder getUrlMappingsHolder(GrailsWebRequest webRequest) {\n        if(this.urlMappingsHolder == null) {\n            ApplicationContext applicationContext = webRequest.getApplicationContext();\n            if(applicationContext != null) {\n                urlMappingsHolder = applicationContext.getBean(UrlMappingsHolder.BEAN_ID, UrlMappingsHolder.class);\n            }\n        }\n        return urlMappingsHolder;\n    }","commit_id":"852d04ca4f9598cc09085f5905afdbf28a1dfd3c","url":"https://github.com/grails/grails-core"},{"original_method":"public void visit(ASTNode[] astNodes, SourceUnit source) {\n        if (!(astNodes[0] instanceof AnnotationNode) || !(astNodes[1] instanceof AnnotatedNode)) {\n            throw new RuntimeException(\"Internal error: wrong types: $node.class / $parent.class\");\n        }\n\n        AnnotatedNode parent = (AnnotatedNode) astNodes[1];\n        AnnotationNode node = (AnnotationNode) astNodes[0];\n        if (!MY_TYPE.equals(node.getClassNode()) || !(parent instanceof ClassNode)) {\n            return;\n        }\n\n        ClassNode classNode = (ClassNode) parent;\n        String cName = classNode.getName();\n        if (classNode.isInterface()) {\n            throw new RuntimeException(\"Error processing interface '\" + cName + \"'. \" +\n                    MY_TYPE_NAME + \" not allowed for interfaces.\");\n        }\n\n        Expression value = node.getMember(\"value\");\n\n        if(value instanceof ClassExpression) {\n            ClassExpression ce = (ClassExpression) value;\n\n            final ClassNode mixinClassNode = ce.getType();\n\n            final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n            classNode.addField(fieldName, Modifier.PRIVATE, mixinClassNode, new ConstructorCallExpression(mixinClassNode, new ArgumentListExpression()));\n            VariableExpression fieldReference = new VariableExpression(fieldName);\n\n\n            final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n            boolean isJunit3 = isJunit3Test(classNode);\n\n            List<MethodNode> beforeMethods = null;\n            List<MethodNode> afterMethods = null;\n            if (isJunit3) {\n                beforeMethods = new ArrayList<MethodNode>();\n                afterMethods = new ArrayList<MethodNode>();\n            }\n\n            for (MethodNode mixinMethod : mixinMethods) {\n                if(isCandidateMethod(mixinMethod) && !classNode.hasDeclaredMethod(mixinMethod.getName(), mixinMethod.getParameters())) {\n                    GrailsASTUtils.addDelegateInstanceMethod(classNode,fieldReference, mixinMethod, false);\n                    if(isJunit3) {\n\n                        if(!mixinMethod.getAnnotations(new ClassNode(Before.class)).isEmpty()) {\n                             beforeMethods.add(mixinMethod);\n                        }\n                        if(!mixinMethod.getAnnotations(new ClassNode(After.class)).isEmpty()) {\n                             afterMethods.add(mixinMethod);\n                        }\n                    }\n                }\n            }\n\n            if(isJunit3) {\n                addMethodCallsToMethod(classNode, SET_UP_METHOD, beforeMethods);\n                addMethodCallsToMethod(classNode, TEAR_DOWN_METHOD, afterMethods);\n            }\n        }\n    }","id":36912,"modified_method":"public void visit(ASTNode[] astNodes, SourceUnit source) {\n        if (!(astNodes[0] instanceof AnnotationNode) || !(astNodes[1] instanceof AnnotatedNode)) {\n            throw new RuntimeException(\"Internal error: wrong types: $node.class / $parent.class\");\n        }\n\n        AnnotatedNode parent = (AnnotatedNode) astNodes[1];\n        AnnotationNode node = (AnnotationNode) astNodes[0];\n        if (!MY_TYPE.equals(node.getClassNode()) || !(parent instanceof ClassNode)) {\n            return;\n        }\n\n        ClassNode classNode = (ClassNode) parent;\n        String cName = classNode.getName();\n        if (classNode.isInterface()) {\n            throw new RuntimeException(\"Error processing interface '\" + cName + \"'. \" +\n                    MY_TYPE_NAME + \" not allowed for interfaces.\");\n        }\n\n        Expression value = node.getMember(\"value\");\n\n        if(value instanceof ClassExpression) {\n            ClassExpression ce = (ClassExpression) value;\n\n            ClassNode mixinClassNode = ce.getType();\n\n            final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n            classNode.addField(fieldName, Modifier.PRIVATE, mixinClassNode, new ConstructorCallExpression(mixinClassNode, new ArgumentListExpression()));\n            VariableExpression fieldReference = new VariableExpression(fieldName);\n\n            boolean isJunit3 = isJunit3Test(classNode);\n            List<MethodNode> beforeMethods = null;\n            List<MethodNode> afterMethods = null;\n            if (isJunit3) {\n                beforeMethods = new ArrayList<MethodNode>();\n                afterMethods = new ArrayList<MethodNode>();\n            }\n\n            while (!mixinClassNode.getName().equals(OBJECT_CLASS)) {\n                final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n                int beforeClassMethodCount = 0;\n                int afterClassMethodCount = 0;\n                for (MethodNode mixinMethod : mixinMethods) {\n                    if(isCandidateMethod(mixinMethod) && !hasDeclaredMethod(classNode, mixinMethod)) {\n                        if(mixinMethod.isStatic()) {\n                            GrailsASTUtils.addDelegateStaticMethod(classNode,mixinMethod);\n                        }\n                        else {\n                            GrailsASTUtils.addDelegateInstanceMethod(classNode,fieldReference, mixinMethod, false);\n                        }\n                        if(isJunit3) {\n\n                            if(hasAnnotation(mixinMethod, Before.class)) {\n                                beforeMethods.add(mixinMethod);\n                            }\n                            if(hasAnnotation(mixinMethod, BeforeClass.class)) {\n                                beforeMethods.add(beforeClassMethodCount++, mixinMethod);\n                            }\n                            if(hasAnnotation(mixinMethod, After.class)) {\n                                afterMethods.add(mixinMethod);\n                            }\n                            if(hasAnnotation(mixinMethod, AfterClass.class)) {\n                                afterMethods.add(afterClassMethodCount++, mixinMethod);\n                            }\n                        }\n                    }\n                }\n\n                mixinClassNode = mixinClassNode.getSuperClass();\n            }\n\n            if(isJunit3) {\n                addMethodCallsToMethod(classNode, SET_UP_METHOD, beforeMethods);\n                addMethodCallsToMethod(classNode, TEAR_DOWN_METHOD, afterMethods);\n            }\n\n\n        }\n    }","commit_id":"852d04ca4f9598cc09085f5905afdbf28a1dfd3c","url":"https://github.com/grails/grails-core"},{"original_method":"public void afterPropertiesSet() throws Exception {\n        Assert.state(grailsApplication != null, \"Property [grailsApplication] must be set!\");\n\n        List urlMappings = new ArrayList();\n        List excludePatterns = new ArrayList();\n\n        GrailsClass[] mappings = grailsApplication.getArtefacts(UrlMappingsArtefactHandler.TYPE);\n\n        final DefaultUrlMappingEvaluator defaultUrlMappingEvaluator = new DefaultUrlMappingEvaluator(servletContext);\n        defaultUrlMappingEvaluator.setPluginManager(pluginManager);\n        mappingEvaluator = defaultUrlMappingEvaluator;\n\n\n        for (GrailsClass mapping : mappings) {\n            GrailsUrlMappingsClass mappingClass = (GrailsUrlMappingsClass) mapping;\n            List grailsClassMappings;\n            if (Script.class.isAssignableFrom(mappingClass.getClass())) {\n                grailsClassMappings = mappingEvaluator.evaluateMappings(mappingClass.getClazz());\n            }\n            else {\n                grailsClassMappings = mappingEvaluator.evaluateMappings(mappingClass.getMappingsClosure());\n            }\n\n            urlMappings.addAll(grailsClassMappings);\n            if (mappingClass.getExcludePatterns() != null) {\n                excludePatterns.addAll(mappingClass.getExcludePatterns());\n            }\n        }\n\n        DefaultUrlMappingsHolder defaultUrlMappingsHolder = new DefaultUrlMappingsHolder(urlMappings, excludePatterns, true);\n\n        Map flatConfig = grailsApplication.getFlatConfig();\n        Integer cacheSize = mapGetInteger(flatConfig, URL_MAPPING_CACHE_MAX_SIZE);\n        if (cacheSize != null){\n            defaultUrlMappingsHolder.setMaxWeightedCacheCapacity(cacheSize);\n        }\n        Integer urlCreatorCacheSize = mapGetInteger(flatConfig, URL_CREATOR_CACHE_MAX_SIZE);\n        if (urlCreatorCacheSize != null) {\n            defaultUrlMappingsHolder.setUrlCreatorMaxWeightedCacheCapacity(urlCreatorCacheSize);\n        }\n        // call initialize() after settings are in place\n        defaultUrlMappingsHolder.initialize();\n        urlMappingsHolder=defaultUrlMappingsHolder;\n    }","id":36913,"modified_method":"public void afterPropertiesSet() throws Exception {\n        Assert.state(grailsApplication != null, \"Property [grailsApplication] must be set!\");\n\n        List urlMappings = new ArrayList();\n        List excludePatterns = new ArrayList();\n\n        GrailsClass[] mappings = grailsApplication.getArtefacts(UrlMappingsArtefactHandler.TYPE);\n\n        final DefaultUrlMappingEvaluator defaultUrlMappingEvaluator = new DefaultUrlMappingEvaluator(servletContext);\n        defaultUrlMappingEvaluator.setPluginManager(pluginManager);\n        mappingEvaluator = defaultUrlMappingEvaluator;\n\n        if(mappings.length == 0) {\n            urlMappings.addAll( mappingEvaluator.evaluateMappings(DefaultUrlMappings.getMappings()) );\n        }\n        else {\n            for (GrailsClass mapping : mappings) {\n                GrailsUrlMappingsClass mappingClass = (GrailsUrlMappingsClass) mapping;\n                List grailsClassMappings;\n                if (Script.class.isAssignableFrom(mappingClass.getClass())) {\n                    grailsClassMappings = mappingEvaluator.evaluateMappings(mappingClass.getClazz());\n                }\n                else {\n                    grailsClassMappings = mappingEvaluator.evaluateMappings(mappingClass.getMappingsClosure());\n                }\n\n                urlMappings.addAll(grailsClassMappings);\n                if (mappingClass.getExcludePatterns() != null) {\n                    excludePatterns.addAll(mappingClass.getExcludePatterns());\n                }\n            }\n        }\n\n\n        DefaultUrlMappingsHolder defaultUrlMappingsHolder = new DefaultUrlMappingsHolder(urlMappings, excludePatterns, true);\n\n        Map flatConfig = grailsApplication.getFlatConfig();\n        Integer cacheSize = mapGetInteger(flatConfig, URL_MAPPING_CACHE_MAX_SIZE);\n        if (cacheSize != null){\n            defaultUrlMappingsHolder.setMaxWeightedCacheCapacity(cacheSize);\n        }\n        Integer urlCreatorCacheSize = mapGetInteger(flatConfig, URL_CREATOR_CACHE_MAX_SIZE);\n        if (urlCreatorCacheSize != null) {\n            defaultUrlMappingsHolder.setUrlCreatorMaxWeightedCacheCapacity(urlCreatorCacheSize);\n        }\n        // call initialize() after settings are in place\n        defaultUrlMappingsHolder.initialize();\n        urlMappingsHolder=defaultUrlMappingsHolder;\n    }","commit_id":"852d04ca4f9598cc09085f5905afdbf28a1dfd3c","url":"https://github.com/grails/grails-core"},{"original_method":"public void visit(ASTNode[] nodes, SourceUnit source) {\n        if (nodes.length != 2 || !(nodes[0] instanceof AnnotationNode) || !(nodes[1] instanceof AnnotatedNode)) {\n            throw new GroovyBugError(\"Internal error: expecting [AnnotationNode, AnnotatedNode] but got: \" + Arrays.asList(nodes));\n        }\n\n        AnnotatedNode parent = (AnnotatedNode) nodes[1];\n        AnnotationNode annotationNode = (AnnotationNode) nodes[0];\n\n        if (parent instanceof FieldNode) {\n            Expression value = annotationNode.getMember(\"value\");\n            FieldNode fieldNode = (FieldNode) parent;\n            final ClassNode type = fieldNode.getType();\n            final ClassNode owner = fieldNode.getOwner();\n            ClassNode supportedType = owner;\n            if (value instanceof ClassExpression) {\n                supportedType = value.getType();\n            }\n\n            GrailsASTUtils.addDelegateInstanceMethods(supportedType, owner, type, new VariableExpression(fieldNode.getName()), resolveGenericsPlaceHolders(supportedType), isNoNullCheck());\n        }\n    }","id":36914,"modified_method":"public void visit(ASTNode[] nodes, SourceUnit source) {\n        if (nodes.length != 2 || !(nodes[0] instanceof AnnotationNode) || !(nodes[1] instanceof AnnotatedNode)) {\n            throw new GroovyBugError(\"Internal error: expecting [AnnotationNode, AnnotatedNode] but got: \" + Arrays.asList(nodes));\n        }\n\n        AnnotatedNode parent = (AnnotatedNode) nodes[1];\n        AnnotationNode annotationNode = (AnnotationNode) nodes[0];\n\n        if (parent instanceof FieldNode) {\n            Expression value = annotationNode.getMember(\"value\");\n            FieldNode fieldNode = (FieldNode) parent;\n            final ClassNode type = fieldNode.getType();\n            final ClassNode owner = fieldNode.getOwner();\n            ClassNode supportedType = owner;\n            if (value instanceof ClassExpression) {\n                supportedType = value.getType();\n            }\n\n            GrailsASTUtils.addDelegateInstanceMethods(supportedType, owner, type, new VariableExpression(fieldNode.getName()), resolveGenericsPlaceHolders(supportedType), isNoNullCheck(), isUseCompileStatic());\n        }\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"protected boolean isNoNullCheck() {\n        return false;\n    }","id":36915,"modified_method":"protected boolean isNoNullCheck() {\n        return true;\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"public static void addDelegateInstanceMethods(ClassNode supportedSuperType, ClassNode classNode, ClassNode delegateNode, Expression delegateInstance) {\n        addDelegateInstanceMethods(supportedSuperType, classNode, delegateNode, delegateInstance, null, false);\n    }","id":36916,"modified_method":"public static void addDelegateInstanceMethods(ClassNode supportedSuperType, ClassNode classNode, ClassNode delegateNode, Expression delegateInstance) {\n        addDelegateInstanceMethods(supportedSuperType, classNode, delegateNode, delegateInstance, null, false, false);\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"public static void addDelegateInstanceMethods(ClassNode classNode, ClassNode delegateNode, Expression delegateInstance, Map<String, ClassNode> genericsPlaceholders) {\n        addDelegateInstanceMethods(classNode, classNode, delegateNode, delegateInstance, genericsPlaceholders, false);\n    }","id":36917,"modified_method":"public static void addDelegateInstanceMethods(ClassNode classNode, ClassNode delegateNode, Expression delegateInstance, Map<String, ClassNode> genericsPlaceholders) {\n        addDelegateInstanceMethods(classNode, classNode, delegateNode, delegateInstance, genericsPlaceholders, false, false);\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"public static void addDelegateInstanceMethods(ClassNode supportedSuperType, ClassNode classNode, ClassNode delegateNode, Expression delegateInstance, Map<String, ClassNode> genericsPlaceholders, boolean noNullCheck) {\n        while (!delegateNode.equals(AbstractGrailsArtefactTransformer.OBJECT_CLASS)) {\n            List<MethodNode> declaredMethods = delegateNode.getMethods();\n            for (MethodNode declaredMethod : declaredMethods) {\n\n                if (isConstructorMethod(declaredMethod)) {\n                    addDelegateConstructor(classNode, declaredMethod, genericsPlaceholders);\n                }\n                else if (isCandidateInstanceMethod(supportedSuperType, declaredMethod)) {\n                    addDelegateInstanceMethod(classNode, delegateInstance, declaredMethod, null, true, genericsPlaceholders, noNullCheck);\n                }\n            }\n            delegateNode = delegateNode.getSuperClass();\n        }\n    }","id":36918,"modified_method":"public static void addDelegateInstanceMethods(ClassNode supportedSuperType, ClassNode classNode, ClassNode delegateNode, Expression delegateInstance, Map<String, ClassNode> genericsPlaceholders, boolean noNullCheck, boolean addCompileStatic) {\n        while (!delegateNode.equals(AbstractGrailsArtefactTransformer.OBJECT_CLASS)) {\n            List<MethodNode> declaredMethods = delegateNode.getMethods();\n            for (MethodNode declaredMethod : declaredMethods) {\n\n                if (isConstructorMethod(declaredMethod)) {\n                    addDelegateConstructor(classNode, declaredMethod, genericsPlaceholders);\n                }\n                else if (isCandidateInstanceMethod(supportedSuperType, declaredMethod)) {\n                    MethodNode methodNode = addDelegateInstanceMethod(classNode, delegateInstance, declaredMethod, null, true, genericsPlaceholders, noNullCheck);\n                    if(addCompileStatic) {\n                        addCompileStaticAnnotation(methodNode);\n                    }\n                }\n            }\n            delegateNode = delegateNode.getSuperClass();\n        }\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"public void weaveMixinsIntoClass(ClassNode classNode, ListExpression values) {\n        if (values != null) {\n            for (Expression current : values.getExpressions()) {\n                if (current instanceof ClassExpression) {\n                    ClassExpression ce = (ClassExpression) current;\n\n                    ClassNode mixinClassNode = ce.getType();\n\n                    final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n\n                    GrailsASTUtils.addFieldIfNonExistent(classNode, mixinClassNode, fieldName);\n                    VariableExpression fieldReference = new VariableExpression(fieldName);\n\n                    while (!mixinClassNode.getName().equals(OBJECT_CLASS)) {\n                        final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n                        for (MethodNode mixinMethod : mixinMethods) {\n                            if (isCandidateMethod(mixinMethod) && !hasDeclaredMethod(classNode, mixinMethod)) {\n                                if (mixinMethod.isStatic()) {\n                                    /*MethodNode methodNode =*/ GrailsASTUtils.addDelegateStaticMethod(classNode, mixinMethod);\n                                }\n                                else {\n                                    /*MethodNode methodNode =*/ GrailsASTUtils.addDelegateInstanceMethod(classNode, fieldReference, mixinMethod, false);\n                                }\n                            }\n                        }\n\n                        mixinClassNode = mixinClassNode.getSuperClass();\n                    }\n                }\n            }\n        }\n    }","id":36919,"modified_method":"public void weaveMixinsIntoClass(ClassNode classNode, ListExpression values) {\n        if (values != null) {\n            for (Expression current : values.getExpressions()) {\n                if (current instanceof ClassExpression) {\n                    ClassExpression ce = (ClassExpression) current;\n\n                    ClassNode mixinClassNode = ce.getType();\n\n                    final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n\n                    GrailsASTUtils.addFieldIfNonExistent(classNode, mixinClassNode, fieldName);\n                    VariableExpression fieldReference = new VariableExpression(fieldName, mixinClassNode);\n\n                    while (!mixinClassNode.getName().equals(OBJECT_CLASS)) {\n                        final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n                        for (MethodNode mixinMethod : mixinMethods) {\n                            if (isCandidateMethod(mixinMethod) && !hasDeclaredMethod(classNode, mixinMethod)) {\n                                if (mixinMethod.isStatic()) {\n                                    GrailsASTUtils.addCompileStaticAnnotation(GrailsASTUtils.addDelegateStaticMethod(classNode, mixinMethod));\n                                }\n                                else {\n                                    GrailsASTUtils.addCompileStaticAnnotation(GrailsASTUtils.addDelegateInstanceMethod(classNode, fieldReference, mixinMethod, false));\n                                }\n                            }\n                        }\n\n                        mixinClassNode = mixinClassNode.getSuperClass();\n                    }\n                }\n            }\n        }\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"public void weaveMixinsIntoClass(ClassNode classNode, ListExpression values) {\n        if (values == null) {\n            return;\n        }\n\n        boolean isJunit3 = isJunit3Test(classNode);\n        List<MethodNode> beforeMethods = null;\n        List<MethodNode> afterMethods = null;\n        if (isJunit3) {\n            beforeMethods = new ArrayList<MethodNode>();\n            afterMethods = new ArrayList<MethodNode>();\n        }\n\n        for (Expression current : values.getExpressions()) {\n            if (current instanceof ClassExpression) {\n                ClassExpression ce = (ClassExpression) current;\n\n                ClassNode mixinClassNode = ce.getType();\n\n                final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n\n                FieldNode fieldNode = addFieldIfNonExistent(classNode, mixinClassNode, fieldName);\n\n                if (fieldNode == null) return; // already woven\n                VariableExpression fieldReference = new VariableExpression(fieldName);\n\n                while (!mixinClassNode.getName().equals(OBJECT_CLASS)) {\n                    final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n                    int beforeClassMethodCount = 0;\n                    int afterClassMethodCount = 0;\n                    for (MethodNode mixinMethod : mixinMethods) {\n                        if (!isCandidateMethod(mixinMethod) || hasDeclaredMethod(classNode, mixinMethod)) {\n                            continue;\n                        }\n\n                        if (mixinMethod.isStatic()) {\n                            MethodNode methodNode = GrailsASTUtils.addDelegateStaticMethod(classNode, mixinMethod);\n\n                            if (methodNode != null) {\n                                methodNode.addAnnotation(MIXIN_METHOD_ANNOTATION);\n                            }\n                        }\n                        else {\n                            MethodNode methodNode = GrailsASTUtils.addDelegateInstanceMethod(classNode, fieldReference, mixinMethod, false);\n                            if (methodNode != null) {\n                                methodNode.addAnnotation(MIXIN_METHOD_ANNOTATION);\n                            }\n                        }\n\n                        if (isJunit3) {\n                            if (hasAnnotation(mixinMethod, Before.class)) {\n                                beforeMethods.add(mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, BeforeClass.class)) {\n                                beforeMethods.add(beforeClassMethodCount++, mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, After.class)) {\n                                afterMethods.add(mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, AfterClass.class)) {\n                                afterMethods.add(afterClassMethodCount++, mixinMethod);\n                            }\n                        }\n                    }\n\n                    mixinClassNode = mixinClassNode.getSuperClass();\n                }\n            }\n        }\n\n        if (isJunit3) {\n            addMethodCallsToMethod(classNode, SET_UP_METHOD, beforeMethods);\n            addMethodCallsToMethod(classNode, TEAR_DOWN_METHOD, afterMethods);\n        }\n    }","id":36920,"modified_method":"public void weaveMixinsIntoClass(ClassNode classNode, ListExpression values) {\n        if (values == null) {\n            return;\n        }\n\n        boolean isJunit3 = isJunit3Test(classNode);\n        List<MethodNode> beforeMethods = null;\n        List<MethodNode> afterMethods = null;\n        if (isJunit3) {\n            beforeMethods = new ArrayList<MethodNode>();\n            afterMethods = new ArrayList<MethodNode>();\n        }\n\n        for (Expression current : values.getExpressions()) {\n            if (current instanceof ClassExpression) {\n                ClassExpression ce = (ClassExpression) current;\n\n                ClassNode mixinClassNode = ce.getType();\n\n                final String fieldName = '$' + GrailsNameUtils.getPropertyName(mixinClassNode.getName());\n\n                FieldNode fieldNode = addFieldIfNonExistent(classNode, mixinClassNode, fieldName);\n\n                if (fieldNode == null) return; // already woven\n                VariableExpression fieldReference = new VariableExpression(fieldName);\n\n                while (!mixinClassNode.getName().equals(OBJECT_CLASS)) {\n                    final List<MethodNode> mixinMethods = mixinClassNode.getMethods();\n\n                    int beforeClassMethodCount = 0;\n                    int afterClassMethodCount = 0;\n                    for (MethodNode mixinMethod : mixinMethods) {\n                        if (!isCandidateMethod(mixinMethod) || hasDeclaredMethod(classNode, mixinMethod)) {\n                            continue;\n                        }\n\n                        MethodNode methodNode;\n                        if (mixinMethod.isStatic()) {\n                            methodNode = GrailsASTUtils.addDelegateStaticMethod(classNode, mixinMethod);\n                        }\n                        else {\n                            methodNode = GrailsASTUtils.addDelegateInstanceMethod(classNode, fieldReference, mixinMethod, false);\n                        }\n                        if (methodNode != null) {\n                            methodNode.addAnnotation(MIXIN_METHOD_ANNOTATION);\n                            GrailsASTUtils.addCompileStaticAnnotation(methodNode);\n                        }\n\n                        if (isJunit3) {\n                            if (hasAnnotation(mixinMethod, Before.class)) {\n                                beforeMethods.add(mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, BeforeClass.class)) {\n                                beforeMethods.add(beforeClassMethodCount++, mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, After.class)) {\n                                afterMethods.add(mixinMethod);\n                            }\n                            if (hasAnnotation(mixinMethod, AfterClass.class)) {\n                                afterMethods.add(afterClassMethodCount++, mixinMethod);\n                            }\n                        }\n                    }\n\n                    mixinClassNode = mixinClassNode.getSuperClass();\n                }\n            }\n        }\n\n        if (isJunit3) {\n            addMethodCallsToMethod(classNode, SET_UP_METHOD, beforeMethods);\n            addMethodCallsToMethod(classNode, TEAR_DOWN_METHOD, afterMethods);\n        }\n    }","commit_id":"6155062c01578efea760cbb551d48a83e3c58d80","url":"https://github.com/grails/grails-core"},{"original_method":"/**\n\t * Look, whether any object is selected. If not, select the nearest node.\n\t * If there are no nodes in the dataset, do nothing.\n\t * \n\t * If the user did not press the left mouse button, do nothing.\n\t * \n\t * Also remember the starting position of the movement and change the mouse \n\t * cursor to movement.\n\t */\n\t@Override public void mousePressed(MouseEvent e) {\n\t\tif (e.getButton() != MouseEvent.BUTTON1)\n\t\t\treturn;\n\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\tboolean alt = (e.getModifiers() & ActionEvent.ALT_MASK) != 0;\n\t\tboolean shift = (e.getModifiers() & ActionEvent.SHIFT_MASK) != 0;\n\t\t\n\t\tmouseDownTime = System.currentTimeMillis();\n\n\t\tOsmPrimitive osm = Main.map.mapView.getNearest(e.getPoint());\n\t\tCollection<OsmPrimitive> osmColl;\n\t\tif (osm == null) {\n\t\t\tosmColl = Collections.emptySet();\n\t\t} else {\n\t\t\tosmColl = Collections.singleton(osm);\n\t\t}\n\n\t\tif (ctrl && shift) {\n\t\t\tselectPrims(osmColl, true, false);\n\t\t\tmode = Mode.rotate;\n\t\t\tsetCursor(ImageProvider.getCursor(\"rotate\", null));\n\t\t} else if (osm != null) {\n\t\t\tselectPrims(osmColl, shift, ctrl);\n\t\t\tmode = Mode.move;\n\t\t} else {\n\t\t\tmode = Mode.select;\n\t\t\toldCursor = Main.map.mapView.getCursor();\n\t\t\tselectionManager.register(Main.map.mapView);\n\t\t\tselectionManager.mousePressed(e);\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tMain.map.mapView.repaint();\n\n\t\tmousePos = e.getPoint();\n\t}","id":36921,"modified_method":"/**\n\t * Look, whether any object is selected. If not, select the nearest node.\n\t * If there are no nodes in the dataset, do nothing.\n\t * \n\t * If the user did not press the left mouse button, do nothing.\n\t * \n\t * Also remember the starting position of the movement and change the mouse \n\t * cursor to movement.\n\t */\n\t@Override public void mousePressed(MouseEvent e) {\n\t\tif (e.getButton() != MouseEvent.BUTTON1)\n\t\t\treturn;\n\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\tboolean alt = (e.getModifiers() & ActionEvent.ALT_MASK) != 0;\n\t\tboolean shift = (e.getModifiers() & ActionEvent.SHIFT_MASK) != 0;\n\t\t\n\t\tmouseDownTime = System.currentTimeMillis();\n\n\t\t// find the object that was clicked on.\n\t\t// if the object is not part of the current selection, clear current\n\t\t// selection before proceeding.\n\t\tCollection<OsmPrimitive> osmColl = null;\n\t\tOsmPrimitive osm = Main.map.mapView.getNearest(e.getPoint());\n\t\tif (osm == null) {\n\t\t\tosmColl = Collections.emptySet();\n\t\t\tMain.ds.setSelected();\n\t\t} else {\n\t\t\tosmColl = Collections.singleton(osm);\n\t\t\tif (!Main.ds.getSelected().contains(osm)) Main.ds.setSelected();\n\t\t}\n\t\t\n\t\tif (ctrl && shift) {\n\t\t\tif (Main.ds.getSelected().isEmpty()) selectPrims(osmColl, true, false);\n\t\t\tmode = Mode.rotate;\n\t\t\tsetCursor(ImageProvider.getCursor(\"rotate\", null));\n\t\t} else if (!osmColl.isEmpty()) {\n\t\t\tif (Main.ds.getSelected().isEmpty()) selectPrims(osmColl, shift, ctrl);\n\t\t\tmode = Mode.move;\n\t\t} else {\n\t\t\tmode = Mode.select;\n\t\t\toldCursor = Main.map.mapView.getCursor();\n\t\t\tselectionManager.register(Main.map.mapView);\n\t\t\tselectionManager.mousePressed(e);\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tMain.map.mapView.repaint();\n\n\t\tmousePos = e.getPoint();\n\t}","commit_id":"6fb4420bf9ac966fad1d4e636bc103e1ebf8d45c","url":"https://github.com/openstreetmap/josm"},{"original_method":"/**\n\t * Restore the old mouse cursor.\n\t */\n\t@Override public void mouseReleased(MouseEvent e) {\n\t\tif (mode == Mode.select) {\n\t\t\tselectionManager.unregister(Main.map.mapView);\n\t\t}\n\t\trestoreCursor();\n\n\t\tif (mode == Mode.move) {\n\t\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\t\tif (ctrl) {\n\t\t\t\tCollection<OsmPrimitive> selection = Main.ds.getSelected();\n\t\t\t\tCollection<Node> affectedNodes = AllNodesVisitor.getAllNodes(selection);\n\t\t\t\tCollection<Node> nn = Main.map.mapView.getNearestNodes(e.getPoint(), affectedNodes);\n\t\t\t\tif (nn != null) {\n\t\t\t\t\tNode n = nn.iterator().next();\n\t\t\t\t    LinkedList<Node> selNodes = new LinkedList<Node>();\n\t\t\t\t    for (OsmPrimitive osm : selection)\n\t\t\t\t\t\tif (osm instanceof Node)\n\t\t\t\t\t\t\tselNodes.add((Node)osm);\n\t\t\t\t\tif (selNodes.size() > 0) {\n\t\t\t\t\t\tselNodes.add(n);\n\t\t\t\t\t\tMergeNodesAction.mergeNodes(selNodes, n);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tmode = null;\n\t\tupdateStatusLine();\n\t}","id":36922,"modified_method":"/**\n\t * Restore the old mouse cursor.\n\t */\n\t@Override public void mouseReleased(MouseEvent e) {\n\t\tif (mode == Mode.select) {\n\t\t\tselectionManager.unregister(Main.map.mapView);\n\t\t}\n\t\trestoreCursor();\n\n\t\tif (mode == Mode.move) {\n\t\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\t\tboolean shift = (e.getModifiers() & ActionEvent.SHIFT_MASK) != 0;\n\t\t\tif (!didMove) {\n\t\t\t\tselectPrims(\n\t\t\t\t\tMain.map.mapView.getNearestCollection(e.getPoint()),\n\t\t\t\t\tshift, ctrl);\n\t\t\t} else if (ctrl) {\n\t\t\t\tCollection<OsmPrimitive> selection = Main.ds.getSelected();\n\t\t\t\tCollection<Node> affectedNodes = AllNodesVisitor.getAllNodes(selection);\n\t\t\t\tCollection<Node> nn = Main.map.mapView.getNearestNodes(e.getPoint(), affectedNodes);\n\t\t\t\tif (nn != null) {\n\t\t\t\t\tNode n = nn.iterator().next();\n\t\t\t\t    LinkedList<Node> selNodes = new LinkedList<Node>();\n\t\t\t\t    for (OsmPrimitive osm : selection)\n\t\t\t\t\t\tif (osm instanceof Node)\n\t\t\t\t\t\t\tselNodes.add((Node)osm);\n\t\t\t\t\tif (selNodes.size() > 0) {\n\t\t\t\t\t\tselNodes.add(n);\n\t\t\t\t\t\tMergeNodesAction.mergeNodes(selNodes, n);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tmode = null;\n\t\tupdateStatusLine();\n\t}","commit_id":"d8edba1e788af72e0f8a721695b705e15620fdad","url":"https://github.com/openstreetmap/josm"},{"original_method":"/**\n\t * Look, whether any object is selected. If not, select the nearest node.\n\t * If there are no nodes in the dataset, do nothing.\n\t * \n\t * If the user did not press the left mouse button, do nothing.\n\t * \n\t * Also remember the starting position of the movement and change the mouse \n\t * cursor to movement.\n\t */\n\t@Override public void mousePressed(MouseEvent e) {\n\t\tif (e.getButton() != MouseEvent.BUTTON1)\n\t\t\treturn;\n\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\tboolean alt = (e.getModifiers() & ActionEvent.ALT_MASK) != 0;\n\t\tboolean shift = (e.getModifiers() & ActionEvent.SHIFT_MASK) != 0;\n\t\t\n\t\tmouseDownTime = System.currentTimeMillis();\n\n\t\t// find the object that was clicked on.\n\t\t// if the object is not part of the current selection, clear current\n\t\t// selection before proceeding.\n\t\tCollection<OsmPrimitive> osmColl = null;\n\t\tOsmPrimitive osm = Main.map.mapView.getNearest(e.getPoint());\n\t\tif (osm == null) {\n\t\t\tosmColl = Collections.emptySet();\n\t\t\tMain.ds.setSelected();\n\t\t} else {\n\t\t\tosmColl = Collections.singleton(osm);\n\t\t\tif (!Main.ds.getSelected().contains(osm)) Main.ds.setSelected();\n\t\t}\n\t\t\n\t\tif (ctrl && shift) {\n\t\t\tif (Main.ds.getSelected().isEmpty()) selectPrims(osmColl, true, false);\n\t\t\tmode = Mode.rotate;\n\t\t\tsetCursor(ImageProvider.getCursor(\"rotate\", null));\n\t\t} else if (!osmColl.isEmpty()) {\n\t\t\tif (Main.ds.getSelected().isEmpty()) selectPrims(osmColl, shift, ctrl);\n\t\t\tmode = Mode.move;\n\t\t} else {\n\t\t\tmode = Mode.select;\n\t\t\toldCursor = Main.map.mapView.getCursor();\n\t\t\tselectionManager.register(Main.map.mapView);\n\t\t\tselectionManager.mousePressed(e);\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tMain.map.mapView.repaint();\n\n\t\tmousePos = e.getPoint();\n\t}","id":36923,"modified_method":"/**\n\t * Look, whether any object is selected. If not, select the nearest node.\n\t * If there are no nodes in the dataset, do nothing.\n\t * \n\t * If the user did not press the left mouse button, do nothing.\n\t * \n\t * Also remember the starting position of the movement and change the mouse \n\t * cursor to movement.\n\t */\n\t@Override public void mousePressed(MouseEvent e) {\n\t\tif (e.getButton() != MouseEvent.BUTTON1)\n\t\t\treturn;\n\t\tboolean ctrl = (e.getModifiers() & ActionEvent.CTRL_MASK) != 0;\n\t\tboolean alt = (e.getModifiers() & ActionEvent.ALT_MASK) != 0;\n\t\tboolean shift = (e.getModifiers() & ActionEvent.SHIFT_MASK) != 0;\n\t\t\n\t\tmouseDownTime = System.currentTimeMillis();\n\t\tdidMove = false;\n\n\t\tCollection<OsmPrimitive> osmColl =\n\t\t\tMain.map.mapView.getNearestCollection(e.getPoint());\n\n\t\tif (ctrl && shift) {\n\t\t\tif (Main.ds.getSelected().isEmpty()) selectPrims(osmColl, true, false);\n\t\t\tmode = Mode.rotate;\n\t\t\tsetCursor(ImageProvider.getCursor(\"rotate\", null));\n\t\t} else if (!osmColl.isEmpty()) {\n\t\t\t// Only add to selection for now, we only do replace and remove in\n\t\t\t// mouseReleased if the user didn't try to move.\n\t\t\tselectPrims(osmColl, true, ctrl);\n\t\t\tmode = Mode.move;\n\t\t} else {\n\t\t\tmode = Mode.select;\n\t\t\toldCursor = Main.map.mapView.getCursor();\n\t\t\tselectionManager.register(Main.map.mapView);\n\t\t\tselectionManager.mousePressed(e);\n\t\t}\n\n\t\tupdateStatusLine();\n\t\tMain.map.mapView.repaint();\n\n\t\tmousePos = e.getPoint();\n\t}","commit_id":"d8edba1e788af72e0f8a721695b705e15620fdad","url":"https://github.com/openstreetmap/josm"},{"original_method":"/**\n\t * If the left mouse button is pressed, move all currently selected\n\t * objects (if one of them is under the mouse) or the current one under the\n\t * mouse (which will become selected).\n\t */\n\t@Override public void mouseDragged(MouseEvent e) {\n\t\tif (mode == Mode.select) return;\n\t\t\n\t\t// do not count anything as a move if it lasts less than 100 milliseconds.\n\t\tif ((mode == Mode.move) && (System.currentTimeMillis() - mouseDownTime < initialMoveDelay)) return;\n\n\t\tif ((e.getModifiersEx() & MouseEvent.BUTTON1_DOWN_MASK) == 0)\n\t\t\treturn;\n\n\t\tif (mode == Mode.move) {\n\t\t\tsetCursor(Cursor.getPredefinedCursor(Cursor.MOVE_CURSOR));\n\t\t}\n\n\t\tif (mousePos == null) {\n\t\t\tmousePos = e.getPoint();\n\t\t}\n\t\t\n\t\tEastNorth mouseEN = Main.map.mapView.getEastNorth(e.getX(), e.getY());\n\t\tEastNorth mouseStartEN = Main.map.mapView.getEastNorth(mousePos.x, mousePos.y);\n\t\tdouble dx = mouseEN.east() - mouseStartEN.east();\n\t\tdouble dy = mouseEN.north() - mouseStartEN.north();\n\t\tif (dx == 0 && dy == 0)\n\t\t\treturn;\n\n\t\tCollection<OsmPrimitive> selection = Main.ds.getSelected();\n\t\tCollection<Node> affectedNodes = AllNodesVisitor.getAllNodes(selection);\n\t\t\n\t\t// when rotating, having only one node makes no sense - quit silently\n\t\tif (mode == Mode.rotate && affectedNodes.size() < 2) \n\t\t\treturn;\n\t\t\n\n\t\t// check if any coordinate would be outside the world\n\t\tfor (OsmPrimitive osm : affectedNodes) {\n\t\t\tif (osm instanceof Node && ((Node)osm).coor.isOutSideWorld()) {\n\t\t\t\tJOptionPane.showMessageDialog(Main.parent,\n\t\t\t\t\ttr(\"Cannot move objects outside of the world.\"));\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tCommand c = !Main.main.undoRedo.commands.isEmpty()\n\t\t\t? Main.main.undoRedo.commands.getLast() : null;\n\n\t\tif (mode == Mode.move) {\n\t\t\tif (c instanceof MoveCommand && affectedNodes.equals(((MoveCommand)c).objects))\n\t\t\t\t((MoveCommand)c).moveAgain(dx,dy);\n\t\t\telse\n\t\t\t\tMain.main.undoRedo.add(new MoveCommand(selection, dx, dy));\n\t\t} else if (mode == Mode.rotate) {\n\t\t\tif (c instanceof RotateCommand && affectedNodes.equals(((RotateCommand)c).objects))\n\t\t\t\t((RotateCommand)c).rotateAgain(mouseStartEN, mouseEN);\n\t\t\telse\n\t\t\t\tMain.main.undoRedo.add(new RotateCommand(selection, mouseStartEN, mouseEN));\n\t\t}\n\n\t\tMain.map.mapView.repaint();\n\t\tmousePos = e.getPoint();\n\t}","id":36924,"modified_method":"/**\n\t * If the left mouse button is pressed, move all currently selected\n\t * objects (if one of them is under the mouse) or the current one under the\n\t * mouse (which will become selected).\n\t */\n\t@Override public void mouseDragged(MouseEvent e) {\n\t\tif (mode == Mode.select) return;\n\t\t\n\t\t// do not count anything as a move if it lasts less than 100 milliseconds.\n\t\tif ((mode == Mode.move) && (System.currentTimeMillis() - mouseDownTime < initialMoveDelay)) return;\n\n\t\tif ((e.getModifiersEx() & MouseEvent.BUTTON1_DOWN_MASK) == 0)\n\t\t\treturn;\n\n\t\tif (mode == Mode.move) {\n\t\t\tsetCursor(Cursor.getPredefinedCursor(Cursor.MOVE_CURSOR));\n\t\t}\n\n\t\tif (mousePos == null) {\n\t\t\tmousePos = e.getPoint();\n\t\t}\n\t\t\n\t\tEastNorth mouseEN = Main.map.mapView.getEastNorth(e.getX(), e.getY());\n\t\tEastNorth mouseStartEN = Main.map.mapView.getEastNorth(mousePos.x, mousePos.y);\n\t\tdouble dx = mouseEN.east() - mouseStartEN.east();\n\t\tdouble dy = mouseEN.north() - mouseStartEN.north();\n\t\tif (dx == 0 && dy == 0)\n\t\t\treturn;\n\n\t\tCollection<OsmPrimitive> selection = Main.ds.getSelected();\n\t\tCollection<Node> affectedNodes = AllNodesVisitor.getAllNodes(selection);\n\t\t\n\t\t// when rotating, having only one node makes no sense - quit silently\n\t\tif (mode == Mode.rotate && affectedNodes.size() < 2) \n\t\t\treturn;\n\t\t\n\n\t\t// check if any coordinate would be outside the world\n\t\tfor (OsmPrimitive osm : affectedNodes) {\n\t\t\tif (osm instanceof Node && ((Node)osm).coor.isOutSideWorld()) {\n\t\t\t\tJOptionPane.showMessageDialog(Main.parent,\n\t\t\t\t\ttr(\"Cannot move objects outside of the world.\"));\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tCommand c = !Main.main.undoRedo.commands.isEmpty()\n\t\t\t? Main.main.undoRedo.commands.getLast() : null;\n\n\t\tif (mode == Mode.move) {\n\t\t\tif (c instanceof MoveCommand && affectedNodes.equals(((MoveCommand)c).objects))\n\t\t\t\t((MoveCommand)c).moveAgain(dx,dy);\n\t\t\telse\n\t\t\t\tMain.main.undoRedo.add(new MoveCommand(selection, dx, dy));\n\t\t} else if (mode == Mode.rotate) {\n\t\t\tif (c instanceof RotateCommand && affectedNodes.equals(((RotateCommand)c).objects))\n\t\t\t\t((RotateCommand)c).rotateAgain(mouseStartEN, mouseEN);\n\t\t\telse\n\t\t\t\tMain.main.undoRedo.add(new RotateCommand(selection, mouseStartEN, mouseEN));\n\t\t}\n\n\t\tMain.map.mapView.repaint();\n\t\tmousePos = e.getPoint();\n\n\t\tdidMove = true;\n\t}","commit_id":"d8edba1e788af72e0f8a721695b705e15620fdad","url":"https://github.com/openstreetmap/josm"},{"original_method":"@NonNls\n    public static String getRuntimeClasspathProperty(@NonNls String moduleName) {\n        return convertName(moduleName) + \".runtime.module.classpath\";\n    }","id":36925,"modified_method":"@NonNls\n  public static String getRuntimeClasspathProperty(@NonNls String moduleName) {\n    return convertName(moduleName) + \".runtime.production.module.classpath\";\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NonNls\n    public static String getClasspathProperty(@NonNls String moduleName) {\n        return convertName(moduleName) + \".module.classpath\";\n    }","id":36926,"modified_method":"@NonNls\n  public static String getClasspathProperty(@NonNls String moduleName) {\n    return convertName(moduleName) + \".module.production.classpath\";\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public ChunkBuild(Project project, ModuleChunk chunk, GenerationOptions genOptions) {\n    final File chunkBaseDir = chunk.getBaseDir();\n    if (genOptions.forceTargetJdk) {\n      if (chunk.isJdkInherited()) {\n        add(new Property(BuildProperties.getModuleChunkJdkHomeProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_HOME)));\n        add(new Property(BuildProperties.getModuleChunkJdkBinProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_BIN)));\n        add(new Property(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_CLASSPATH)));\n      }\n      else {\n        final Sdk jdk = chunk.getJdk();\n        add(new Property(BuildProperties.getModuleChunkJdkHomeProperty(chunk.getName()), jdk != null? BuildProperties.propertyRef(BuildProperties.getJdkHomeProperty(jdk.getName())): \"\"));\n        add(new Property(BuildProperties.getModuleChunkJdkBinProperty(chunk.getName()), jdk != null? BuildProperties.propertyRef(BuildProperties.getJdkBinProperty(jdk.getName())): \"\"));\n        add(new Property(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()), jdk != null? BuildProperties.getJdkPathId(jdk.getName()) : \"\"));\n      }\n    }\n\n    add(new Property(BuildProperties.getModuleChunkCompilerArgsProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_COMPILER_ADDITIONAL_ARGS)), 1);\n\n    final String outputPathUrl = chunk.getOutputDirUrl();\n    String location = outputPathUrl != null?\n                      GenerationUtils.toRelativePath(VirtualFileManager.extractPath(outputPathUrl), chunkBaseDir, BuildProperties.getModuleChunkBasedirProperty(chunk), genOptions) :\n                      CompilerBundle.message(\"value.undefined\");\n    add(new Property(BuildProperties.getOutputPathProperty(chunk.getName()), location), 1);\n\n    final String testOutputPathUrl = chunk.getTestsOutputDirUrl();\n    if (testOutputPathUrl != null) {\n      location = GenerationUtils.toRelativePath(VirtualFileManager.extractPath(testOutputPathUrl), chunkBaseDir, BuildProperties.getModuleChunkBasedirProperty(chunk), genOptions);\n    }\n    add(new Property(BuildProperties.getOutputPathForTestsProperty(chunk.getName()), location));\n\n    add(createBootclasspath(chunk), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, false), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, true), 1);\n\n    final ModuleChunkSourcepath moduleSources = new ModuleChunkSourcepath(project, chunk, genOptions);\n    add(moduleSources, 1);\n    add(new CompileModuleChunkTarget(project, chunk, moduleSources.getSourceRoots(), moduleSources.getTestSourceRoots(), chunkBaseDir, genOptions), 1);\n    add(new CleanModule(chunk), 1);\n\n    ChunkBuildExtension.process(this, chunk, genOptions);\n  }","id":36927,"modified_method":"public ChunkBuild(Project project, ModuleChunk chunk, GenerationOptions genOptions) {\n    final File chunkBaseDir = chunk.getBaseDir();\n    if (genOptions.forceTargetJdk) {\n      if (chunk.isJdkInherited()) {\n        add(new Property(BuildProperties.getModuleChunkJdkHomeProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_HOME)));\n        add(new Property(BuildProperties.getModuleChunkJdkBinProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_BIN)));\n        add(new Property(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_PROJECT_JDK_CLASSPATH)));\n      }\n      else {\n        final Sdk jdk = chunk.getJdk();\n        add(new Property(BuildProperties.getModuleChunkJdkHomeProperty(chunk.getName()), jdk != null? BuildProperties.propertyRef(BuildProperties.getJdkHomeProperty(jdk.getName())): \"\"));\n        add(new Property(BuildProperties.getModuleChunkJdkBinProperty(chunk.getName()), jdk != null? BuildProperties.propertyRef(BuildProperties.getJdkBinProperty(jdk.getName())): \"\"));\n        add(new Property(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()), jdk != null? BuildProperties.getJdkPathId(jdk.getName()) : \"\"));\n      }\n    }\n\n    add(new Property(BuildProperties.getModuleChunkCompilerArgsProperty(chunk.getName()), BuildProperties.propertyRef(BuildProperties.PROPERTY_COMPILER_ADDITIONAL_ARGS)), 1);\n\n    final String outputPathUrl = chunk.getOutputDirUrl();\n    String location = outputPathUrl != null?\n                      GenerationUtils.toRelativePath(VirtualFileManager.extractPath(outputPathUrl), chunkBaseDir, BuildProperties.getModuleChunkBasedirProperty(chunk), genOptions) :\n                      CompilerBundle.message(\"value.undefined\");\n    add(new Property(BuildProperties.getOutputPathProperty(chunk.getName()), location), 1);\n\n    final String testOutputPathUrl = chunk.getTestsOutputDirUrl();\n    if (testOutputPathUrl != null) {\n      location = GenerationUtils.toRelativePath(VirtualFileManager.extractPath(testOutputPathUrl), chunkBaseDir, BuildProperties.getModuleChunkBasedirProperty(chunk), genOptions);\n    }\n    add(new Property(BuildProperties.getOutputPathForTestsProperty(chunk.getName()), location));\n\n    add(createBootclasspath(chunk), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, false, false), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, true, false), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, false, true), 1);\n    add(new ModuleChunkClasspath(chunk, genOptions, true, true), 1);\n\n    final ModuleChunkSourcepath moduleSources = new ModuleChunkSourcepath(project, chunk, genOptions);\n    add(moduleSources, 1);\n    add(new CompileModuleChunkTarget(project, chunk, moduleSources.getSourceRoots(), moduleSources.getTestSourceRoots(), chunkBaseDir, genOptions), 1);\n    add(new CleanModule(chunk), 1);\n\n    ChunkBuildExtension.process(this, chunk, genOptions);\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n     * Create custom compiler tasks\n     *\n     * @param project          the proejct\n     * @param moduleChunk      the module chunkc\n     * @param genOptions       generation options\n     * @param compileTests     if true tests are being compiled\n     * @param customCompilers  an array of custom compilers for this cunk\n     * @param compilerArgs     the javac compilier arguements\n     * @param bootclasspathTag the boot classpath element for the javac compiler\n     * @param classpathTag     the classpath tag for the javac compiler\n     * @param compilerExcludes the compiler excluded tag\n     * @param srcTag           the soruce tag\n     * @param outputPathRef    the output path references\n     * @param target           the target where to add custom compiler\n     */\n    private void createCustomCompilerTasks(Project project,\n                                           ModuleChunk moduleChunk,\n                                           GenerationOptions genOptions,\n                                           boolean compileTests,\n                                           ChunkCustomCompilerExtension[] customCompilers,\n                                           Tag compilerArgs,\n                                           Tag bootclasspathTag,\n                                           Tag classpathTag,\n                                           PatternSetRef compilerExcludes,\n                                           Tag srcTag,\n                                           String outputPathRef,\n                                           Target target) {\n        if (customCompilers.length > 1) {\n            target.add(new Tag(\"fail\", Pair.create(\"message\", CompilerBundle.message(\n                    \"generated.ant.build.compile.modules.fail.custom.comipilers\"))));\n        }\n        for (ChunkCustomCompilerExtension ext : customCompilers) {\n            ext.generateCustomCompile(project, moduleChunk, genOptions, compileTests, target, compilerArgs, bootclasspathTag,\n                                      classpathTag, compilerExcludes, srcTag, outputPathRef);\n        }\n    }","id":36928,"modified_method":"/**\n   * Create custom compiler tasks\n   *\n   * @param project          the proejct\n   * @param moduleChunk      the module chunkc\n   * @param genOptions       generation options\n   * @param compileTests     if true tests are being compiled\n   * @param customCompilers  an array of custom compilers for this cunk\n   * @param compilerArgs     the javac compilier arguements\n   * @param bootclasspathTag the boot classpath element for the javac compiler\n   * @param classpathTag     the classpath tag for the javac compiler\n   * @param compilerExcludes the compiler excluded tag\n   * @param srcTag           the soruce tag\n   * @param outputPathRef    the output path references\n   * @param target           the target where to add custom compiler\n   */\n  private static void createCustomCompilerTasks(Project project,\n                                         ModuleChunk moduleChunk,\n                                         GenerationOptions genOptions,\n                                         boolean compileTests,\n                                         ChunkCustomCompilerExtension[] customCompilers,\n                                         Tag compilerArgs,\n                                         Tag bootclasspathTag,\n                                         Tag classpathTag,\n                                         PatternSetRef compilerExcludes,\n                                         Tag srcTag,\n                                         String outputPathRef,\n                                         Target target) {\n    if (customCompilers.length > 1) {\n      target.add(new Tag(\"fail\", Pair.create(\"message\", CompilerBundle.message(\n        \"generated.ant.build.compile.modules.fail.custom.compilers\"))));\n    }\n    for (ChunkCustomCompilerExtension ext : customCompilers) {\n      ext.generateCustomCompile(project, moduleChunk, genOptions, compileTests, target, compilerArgs, bootclasspathTag,\n                                classpathTag, compilerExcludes, srcTag, outputPathRef);\n    }\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public CompileModuleChunkTarget(final Project project,\n                                    ModuleChunk moduleChunk,\n                                    VirtualFile[] sourceRoots,\n                                    VirtualFile[] testSourceRoots,\n                                    File baseDir,\n                                    GenerationOptions genOptions) {\n        final String moduleChunkName = moduleChunk.getName();\n        //noinspection HardCodedStringLiteral\n        final Tag compilerArgs = new Tag(\"compilerarg\", Pair.create(\"line\", BuildProperties.propertyRef(\n                BuildProperties.getModuleChunkCompilerArgsProperty(moduleChunkName))));\n        //noinspection HardCodedStringLiteral\n        final Pair<String, String> classpathRef = Pair.create(\"refid\", BuildProperties.getClasspathProperty(moduleChunkName));\n        final Tag classpathTag = new Tag(\"classpath\", classpathRef);\n        //noinspection HardCodedStringLiteral\n        final Tag bootclasspathTag =\n                new Tag(\"bootclasspath\", Pair.create(\"refid\", BuildProperties.getBootClasspathProperty(moduleChunkName)));\n        final PatternSetRef compilerExcludes = new PatternSetRef(BuildProperties.getExcludedFromCompilationProperty(moduleChunkName));\n\n        final String mainTargetName = BuildProperties.getCompileTargetName(moduleChunkName);\n        final @NonNls String productionTargetName = mainTargetName + \".production\";\n        final @NonNls String testsTargetName = mainTargetName + \".tests\";\n\n        final int modulesCount = moduleChunk.getModules().length;\n        myMainTarget = new Target(mainTargetName, productionTargetName + \",\" + testsTargetName,\n                                  CompilerBundle.message(\"generated.ant.build.compile.modules.main.target.comment\", modulesCount,\n                                                         moduleChunkName), null);\n        myProductionTarget = new Target(productionTargetName, getChunkDependenciesString(moduleChunk),\n                                        CompilerBundle.message(\"generated.ant.build.compile.modules.production.classes.target.comment\",\n                                                               modulesCount, moduleChunkName), null);\n        myTestsTarget = new Target(testsTargetName, productionTargetName,\n                                   CompilerBundle.message(\"generated.ant.build.compile.modules.tests.target.comment\", modulesCount,\n                                                          moduleChunkName), BuildProperties.PROPERTY_SKIP_TESTS);\n        final ChunkCustomCompilerExtension[] customCompilers = moduleChunk.getCustomCompilers();\n\n        if (sourceRoots.length > 0) {\n            final String outputPathRef = BuildProperties.propertyRef(BuildProperties.getOutputPathProperty(moduleChunkName));\n            final Tag srcTag = new Tag(\"src\", Pair.create(\"refid\", BuildProperties.getSourcepathProperty(moduleChunkName)));\n            myProductionTarget.add(new Mkdir(outputPathRef));\n            createCustomCompilerTasks(project, moduleChunk, genOptions, false, customCompilers, compilerArgs, bootclasspathTag,\n                                      classpathTag, compilerExcludes, srcTag, outputPathRef, myProductionTarget);\n            if (customCompilers.length == 0 || genOptions.enableFormCompiler) {\n                final Javac javac = new Javac(genOptions, moduleChunk, outputPathRef);\n                javac.add(compilerArgs);\n                javac.add(bootclasspathTag);\n                javac.add(classpathTag);\n                //noinspection HardCodedStringLiteral\n                javac.add(srcTag);\n                javac.add(compilerExcludes);\n                myProductionTarget.add(javac);\n            }\n            myProductionTarget.add(createCopyTask(project, moduleChunk, sourceRoots, outputPathRef, baseDir, genOptions));\n        }\n\n        if (testSourceRoots.length > 0) {\n            final String testOutputPathRef = BuildProperties.propertyRef(BuildProperties.getOutputPathForTestsProperty(moduleChunkName));\n            final Tag srcTag = new Tag(\"src\", Pair.create(\"refid\", BuildProperties.getTestSourcepathProperty(moduleChunkName)));\n            final Tag testClassPath = new Tag(\"classpath\");\n            testClassPath.add(new Tag(\"path\", classpathRef));\n            testClassPath.add(new PathElement(BuildProperties.propertyRef(BuildProperties.getOutputPathProperty(moduleChunkName))));\n            myTestsTarget.add(new Mkdir(testOutputPathRef));\n            createCustomCompilerTasks(project, moduleChunk, genOptions, true, customCompilers, compilerArgs, bootclasspathTag,\n                                      testClassPath, compilerExcludes, srcTag, testOutputPathRef, myTestsTarget);\n            if (customCompilers.length == 0 || genOptions.enableFormCompiler) {\n                final Javac javac = new Javac(genOptions, moduleChunk, testOutputPathRef);\n                javac.add(compilerArgs);\n                javac.add(classpathTag);\n                //noinspection HardCodedStringLiteral\n                javac.add(testClassPath);\n                //noinspection HardCodedStringLiteral\n                javac.add(srcTag);\n                javac.add(compilerExcludes);\n                myTestsTarget.add(javac);\n            }\n            myTestsTarget.add(createCopyTask(project, moduleChunk, testSourceRoots, testOutputPathRef, baseDir, genOptions));\n        }\n\n        add(myMainTarget);\n        add(myProductionTarget, 1);\n        add(myTestsTarget, 1);\n    }","id":36929,"modified_method":"public CompileModuleChunkTarget(final Project project,\n                                  ModuleChunk moduleChunk,\n                                  VirtualFile[] sourceRoots,\n                                  VirtualFile[] testSourceRoots,\n                                  File baseDir,\n                                  GenerationOptions genOptions) {\n    final String moduleChunkName = moduleChunk.getName();\n    //noinspection HardCodedStringLiteral\n    final Tag compilerArgs = new Tag(\"compilerarg\", Pair.create(\"line\", BuildProperties.propertyRef(\n      BuildProperties.getModuleChunkCompilerArgsProperty(moduleChunkName))));\n    //noinspection HardCodedStringLiteral\n    final Pair<String, String> classpathRef = Pair.create(\"refid\", BuildProperties.getClasspathProperty(moduleChunkName));\n    final Tag classpathTag = new Tag(\"classpath\", classpathRef);\n    //noinspection HardCodedStringLiteral\n    final Tag bootclasspathTag =\n      new Tag(\"bootclasspath\", Pair.create(\"refid\", BuildProperties.getBootClasspathProperty(moduleChunkName)));\n    final PatternSetRef compilerExcludes = new PatternSetRef(BuildProperties.getExcludedFromCompilationProperty(moduleChunkName));\n\n    final String mainTargetName = BuildProperties.getCompileTargetName(moduleChunkName);\n    final @NonNls String productionTargetName = mainTargetName + \".production\";\n    final @NonNls String testsTargetName = mainTargetName + \".tests\";\n\n    final int modulesCount = moduleChunk.getModules().length;\n    Target mainTarget = new Target(mainTargetName, productionTargetName + \",\" + testsTargetName,\n                                   CompilerBundle.message(\"generated.ant.build.compile.modules.main.target.comment\", modulesCount,\n                                                          moduleChunkName), null);\n    Target productionTarget = new Target(productionTargetName, getChunkDependenciesString(moduleChunk),\n                                         CompilerBundle.message(\"generated.ant.build.compile.modules.production.classes.target.comment\",\n                                                                modulesCount, moduleChunkName), null);\n    Target testsTarget = new Target(testsTargetName, productionTargetName,\n                                    CompilerBundle.message(\"generated.ant.build.compile.modules.tests.target.comment\", modulesCount,\n                                                           moduleChunkName), BuildProperties.PROPERTY_SKIP_TESTS);\n    final ChunkCustomCompilerExtension[] customCompilers = moduleChunk.getCustomCompilers();\n\n    if (sourceRoots.length > 0) {\n      final String outputPathRef = BuildProperties.propertyRef(BuildProperties.getOutputPathProperty(moduleChunkName));\n      final Tag srcTag = new Tag(\"src\", Pair.create(\"refid\", BuildProperties.getSourcepathProperty(moduleChunkName)));\n      productionTarget.add(new Mkdir(outputPathRef));\n      createCustomCompilerTasks(project, moduleChunk, genOptions, false, customCompilers, compilerArgs, bootclasspathTag,\n                                classpathTag, compilerExcludes, srcTag, outputPathRef, productionTarget);\n      if (customCompilers.length == 0 || genOptions.enableFormCompiler) {\n        final Javac javac = new Javac(genOptions, moduleChunk, outputPathRef);\n        javac.add(compilerArgs);\n        javac.add(bootclasspathTag);\n        javac.add(classpathTag);\n        javac.add(srcTag);\n        javac.add(compilerExcludes);\n        productionTarget.add(javac);\n      }\n      productionTarget.add(createCopyTask(project, moduleChunk, sourceRoots, outputPathRef, baseDir, genOptions));\n    }\n\n    if (testSourceRoots.length > 0) {\n\n      final String testOutputPathRef = BuildProperties.propertyRef(BuildProperties.getOutputPathForTestsProperty(moduleChunkName));\n      final Tag srcTag = new Tag(\"src\", Pair.create(\"refid\", BuildProperties.getTestSourcepathProperty(moduleChunkName)));\n      final Pair<String, String> testClasspathRef = Pair.create(\"refid\", BuildProperties.getTestClasspathProperty(moduleChunkName));\n      final Tag testClassPath = new Tag(\"classpath\", testClasspathRef);\n      testsTarget.add(new Mkdir(testOutputPathRef));\n      createCustomCompilerTasks(project, moduleChunk, genOptions, true, customCompilers, compilerArgs, bootclasspathTag,\n                                testClassPath, compilerExcludes, srcTag, testOutputPathRef, testsTarget);\n      if (customCompilers.length == 0 || genOptions.enableFormCompiler) {\n        final Javac javac = new Javac(genOptions, moduleChunk, testOutputPathRef);\n        javac.add(compilerArgs);\n        javac.add(bootclasspathTag);\n        javac.add(testClassPath);\n        javac.add(srcTag);\n        javac.add(compilerExcludes);\n        testsTarget.add(javac);\n      }\n      testsTarget.add(createCopyTask(project, moduleChunk, testSourceRoots, testOutputPathRef, baseDir, genOptions));\n    }\n\n    add(mainTarget);\n    add(productionTarget, 1);\n    add(testsTarget, 1);\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * Validate generation options and notify user about possible problems\n   *\n   * @param project    a context project\n   * @param genOptions a generation optiosn\n   * @return true if the generator should proceed with current options or if there is not conflict.\n   */\n  private static boolean validateGenOptions(Project project, GenerationOptionsImpl genOptions) {\n    final Collection<String> EMPTY = Collections.emptyList();\n    Collection<String> conflicts = EMPTY;\n    for (ModuleChunk chunk : genOptions.getModuleChunks()) {\n      final ChunkCustomCompilerExtension[] customeCompilers = chunk.getCustomCompilers();\n      if (customeCompilers.length > 1) {\n        if (conflicts == EMPTY) {\n          conflicts = new LinkedList<String>();\n        }\n        conflicts.add(chunk.getName());\n      }\n    }\n    if (!conflicts.isEmpty()) {\n      StringBuilder msg = new StringBuilder();\n      for (String conflictingChunk : conflicts) {\n        msg.append(CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.message.row\", conflictingChunk));\n      }\n      int rc = Messages\n        .showOkCancelDialog(project, CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.message\", msg.toString()),\n                            CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.titile\"), Messages.getErrorIcon());\n      if (rc != 0) {\n        return false;\n      }\n    }\n    return true;\n  }","id":36930,"modified_method":"/**\n   * Validate generation options and notify user about possible problems\n   *\n   * @param project    a context project\n   * @param genOptions a generation optiosn\n   * @return true if the generator should proceed with current options or if there is not conflict.\n   */\n  private static boolean validateGenOptions(Project project, GenerationOptionsImpl genOptions) {\n    final Collection<String> EMPTY = Collections.emptyList();\n    Collection<String> conflicts = EMPTY;\n    for (ModuleChunk chunk : genOptions.getModuleChunks()) {\n      final ChunkCustomCompilerExtension[] customeCompilers = chunk.getCustomCompilers();\n      if (customeCompilers.length > 1) {\n        if (conflicts == EMPTY) {\n          conflicts = new LinkedList<String>();\n        }\n        conflicts.add(chunk.getName());\n      }\n    }\n    if (!conflicts.isEmpty()) {\n      StringBuilder msg = new StringBuilder();\n      for (String conflictingChunk : conflicts) {\n        msg.append(CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.message.row\", conflictingChunk));\n      }\n      int rc = Messages\n        .showOkCancelDialog(project, CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.message\", msg.toString()),\n                            CompilerBundle.message(\"generate.ant.build.custom.compiler.conflict.title\"), Messages.getErrorIcon());\n      if (rc != 0) {\n        return false;\n      }\n    }\n    return true;\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static String[] getCompilationClasses(final OrderEntry orderEntry,\n                                                final GenerationOptionsImpl options,\n                                                final boolean forRuntime) {\n    if (!forRuntime) {\n      return orderEntry.getUrls(OrderRootType.COMPILATION_CLASSES);\n    }\n    final Set<String> jdkUrls = options.getAllJdkUrls();\n\n    final OrderedSet<String> urls = new OrderedSet<String>();\n    urls.addAll(Arrays.asList(orderEntry.getUrls(OrderRootType.CLASSES_AND_OUTPUT)));\n    urls.removeAll(jdkUrls);\n    return ArrayUtil.toStringArray(urls);\n  }","id":36931,"modified_method":"private static String[] getCompilationClasses(final OrderEntry orderEntry,\n                                                final GenerationOptionsImpl options,\n                                                final boolean forRuntime,\n                                                final boolean forTest,\n                                                final boolean firstLevel) {\n    if (!forRuntime) {\n      if (forTest) {\n        return orderEntry.getUrls(firstLevel ? OrderRootType.PRODUCTION_COMPILATION_CLASSES : OrderRootType.COMPILATION_CLASSES);\n      }\n      else {\n        return firstLevel ? new String[0] : orderEntry.getUrls(OrderRootType.PRODUCTION_COMPILATION_CLASSES);\n      }\n    }\n    final Set<String> jdkUrls = options.getAllJdkUrls();\n\n    final OrderedSet<String> urls = new OrderedSet<String>();\n    urls.addAll(Arrays.asList(orderEntry.getUrls(forTest ? OrderRootType.COMPILATION_CLASSES\n                                                         : OrderRootType.PRODUCTION_COMPILATION_CLASSES)));\n    urls.removeAll(jdkUrls);\n    return ArrayUtil.toStringArray(urls);\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * A constructor\n   *\n   * @param chunk                    a chunk to process\n   * @param genOptions               a generation options\n   * @param generateRuntimeClasspath if true, runtime classpath is being generated. Otherwise a compile time classpath is constructed\n   */\n  @SuppressWarnings({\"unchecked\"})\n  public ModuleChunkClasspath(final ModuleChunk chunk, final GenerationOptions genOptions, final boolean generateRuntimeClasspath) {\n    super(generateRuntimeClasspath\n          ? BuildProperties.getRuntimeClasspathProperty(chunk.getName())\n          : BuildProperties.getClasspathProperty(chunk.getName()));\n\n    final OrderedSet<ClasspathItem> pathItems =\n      new OrderedSet<ClasspathItem>((TObjectHashingStrategy<ClasspathItem>)TObjectHashingStrategy.CANONICAL);\n    final String moduleChunkBasedirProperty = BuildProperties.getModuleChunkBasedirProperty(chunk);\n    final Module[] modules = chunk.getModules();\n    // processed chunks (used only in runtime classpath), every chunk is referenced exactly once\n    final Set<ModuleChunk> processedChunks = new HashSet<ModuleChunk>();\n    // pocessed modules\n    final Set<Module> processedModules = new HashSet<Module>();\n    for (final Module module : modules) {\n      new Object() {\n        /**\n         * Process the module. The logic is different for compile-time case and runtime case.\n         * In the case of runtime, only directly referenced objects are included in classpath.\n         * Indirectly referenced are\n         *\n         * @param module a module to process.\n         * @param dependencyLevel is increased with every of recursion.\n         * @param isModuleExported if true the module is exported from the previous level\n         */\n        public void processModule(final Module module, final int dependencyLevel, final boolean isModuleExported) {\n          if (processedModules.contains(module)) {\n            // the module is already processed, nothing should be done\n            return;\n          }\n          if (dependencyLevel > 1 && !isModuleExported && !(genOptions.inlineRuntimeClasspath && generateRuntimeClasspath)) {\n            // the module is not in exports and it is not directly included skip it in the case of library pathgeneration\n            return;\n          }\n          processedModules.add(module);\n          final ProjectEx project = (ProjectEx)chunk.getProject();\n          final File baseDir = BuildProperties.getProjectBaseDir(project);\n          for (final OrderEntry orderEntry : ModuleRootManager.getInstance(module).getOrderEntries()) {\n            if (!orderEntry.isValid()) {\n              continue;\n            }\n            if (!generateRuntimeClasspath) {\n              // needed for compilation classpath only\n              if ((orderEntry instanceof ModuleSourceOrderEntry)) {\n                // this is the entry for outpath of the currently processed module\n                if (dependencyLevel == 0 || chunk.contains(module)) {\n                  // the root module is never included\n                  continue;\n                }\n              }\n              else {\n                final boolean isExported = (orderEntry instanceof ExportableOrderEntry) && ((ExportableOrderEntry)orderEntry).isExported();\n                if (dependencyLevel > 0 && !isExported) {\n                  if (!(orderEntry instanceof ModuleOrderEntry)) {\n                    // non-exported dependencies are excluded and not processed\n                    continue;\n                  }\n                }\n              }\n            }\n            if (orderEntry instanceof JdkOrderEntry) {\n              if (genOptions.forceTargetJdk && !generateRuntimeClasspath) {\n                pathItems\n                  .add(new PathRefItem(BuildProperties.propertyRef(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()))));\n              }\n            }\n            else if (orderEntry instanceof ModuleOrderEntry) {\n              final ModuleOrderEntry moduleOrderEntry = (ModuleOrderEntry)orderEntry;\n              final Module dependentModule = moduleOrderEntry.getModule();\n              if (!chunk.contains(dependentModule)) {\n                if (generateRuntimeClasspath && !genOptions.inlineRuntimeClasspath) {\n                  // in case of runtime classpath, just an referenced to corresponding classpath is created\n                  final ModuleChunk depChunk = genOptions.getChunkByModule(dependentModule);\n                  if (!processedChunks.contains(depChunk)) {\n                    // chunk references are included in the runtime classpath only once\n                    processedChunks.add(depChunk);\n                    pathItems.add(new PathRefItem(BuildProperties.getRuntimeClasspathProperty(depChunk.getName())));\n                  }\n                }\n                else {\n                  // in case of compile classpath or inlined runtime classpath,\n                  // the referenced module is processed recursively\n                  processModule(dependentModule, dependencyLevel + 1, moduleOrderEntry.isExported());\n                }\n              }\n            }\n            else if (orderEntry instanceof LibraryOrderEntry) {\n              final LibraryOrderEntry libraryOrderEntry = (LibraryOrderEntry)orderEntry;\n              final String libraryName = libraryOrderEntry.getLibraryName();\n              if (((LibraryOrderEntry)orderEntry).isModuleLevel()) {\n                CompositeGenerator gen = new CompositeGenerator();\n                gen.setHasLeadingNewline(false);\n                LibraryDefinitionsGeneratorFactory.genLibraryContent(project, genOptions, libraryOrderEntry.getLibrary(), baseDir, gen);\n                pathItems.add(new GeneratorItem(libraryName, gen));\n              }\n              else {\n                pathItems.add(new PathRefItem(BuildProperties.getLibraryPathId(libraryName)));\n              }\n            }\n            else {\n              // Module source entry?\n              for (String url : getCompilationClasses(orderEntry, ((GenerationOptionsImpl)genOptions), generateRuntimeClasspath)) {\n                if (url.endsWith(JarFileSystem.JAR_SEPARATOR)) {\n                  url = url.substring(0, url.length() - JarFileSystem.JAR_SEPARATOR.length());\n                }\n                final String propertyRef = genOptions.getPropertyRefForUrl(url);\n                if (propertyRef != null) {\n                  pathItems.add(new PathElementItem(propertyRef));\n                }\n                else {\n                  final String path = VirtualFileManager.extractPath(url);\n                  pathItems.add(new PathElementItem(\n                    GenerationUtils.toRelativePath(path, chunk.getBaseDir(), moduleChunkBasedirProperty, genOptions)));\n                }\n              }\n            }\n          }\n        }\n      }.processModule(module, 0, false);\n    }\n    // convert path items to generators\n    for (final ClasspathItem pathItem : pathItems) {\n      add(pathItem.toGenerator());\n    }\n  }","id":36932,"modified_method":"/**\n   * A constructor\n   *\n   * @param chunk                    a chunk to process\n   * @param genOptions               a generation options\n   * @param generateRuntimeClasspath if true, runtime classpath is being generated. Otherwise a compile time classpath is constructed\n   * @param generateTestClasspath    if true, a test classpath is generated.\n   */\n  @SuppressWarnings({\"unchecked\"})\n  public ModuleChunkClasspath(final ModuleChunk chunk,\n                              final GenerationOptions genOptions,\n                              final boolean generateRuntimeClasspath,\n                              final boolean generateTestClasspath) {\n    super(generateClasspathName(chunk, generateRuntimeClasspath, generateTestClasspath));\n\n    final OrderedSet<ClasspathItem> pathItems =\n      new OrderedSet<ClasspathItem>((TObjectHashingStrategy<ClasspathItem>)TObjectHashingStrategy.CANONICAL);\n    final String moduleChunkBasedirProperty = BuildProperties.getModuleChunkBasedirProperty(chunk);\n    final Module[] modules = chunk.getModules();\n    // processed chunks (used only in runtime classpath), every chunk is referenced exactly once\n    final Set<ModuleChunk> processedChunks = new HashSet<ModuleChunk>();\n    // pocessed modules\n    final Set<Module> processedModules = new HashSet<Module>();\n    for (final Module module : modules) {\n      new Object() {\n        /**\n         * Process the module. The logic is different for compile-time case and runtime case.\n         * In the case of runtime, only directly referenced objects are included in classpath.\n         * Indirectly referenced are\n         *\n         * @param module a module to process.\n         * @param dependencyLevel is increased with every of recursion.\n         * @param isModuleExported if true the module is exported from the previous level\n         */\n        public void processModule(final Module module, final int dependencyLevel, final boolean isModuleExported) {\n          if (processedModules.contains(module)) {\n            // the module is already processed, nothing should be done\n            return;\n          }\n          if (dependencyLevel > 1 && !isModuleExported && !(genOptions.inlineRuntimeClasspath && generateRuntimeClasspath)) {\n            // the module is not in exports and it is not directly included skip it in the case of library pathgeneration\n            return;\n          }\n          processedModules.add(module);\n          final ProjectEx project = (ProjectEx)chunk.getProject();\n          final File baseDir = BuildProperties.getProjectBaseDir(project);\n          for (final OrderEntry orderEntry : ModuleRootManager.getInstance(module).getOrderEntries()) {\n            if (!orderEntry.isValid()) {\n              continue;\n            }\n            if (orderEntry instanceof ExportableOrderEntry) {\n              ExportableOrderEntry e = (ExportableOrderEntry)orderEntry;\n              switch (e.getScope()) {\n                case COMPILE:\n                  break;\n                case PROVIDED:\n                  if (generateRuntimeClasspath && !generateTestClasspath) {\n                    continue;\n                  }\n                  break;\n                case RUNTIME:\n                  if (!generateRuntimeClasspath) {\n                    continue;\n                  }\n                  break;\n                case TEST:\n                  if (!generateTestClasspath) {\n                    continue;\n                  }\n                  break;\n              }\n            }\n            if (!generateRuntimeClasspath) {\n              // needed for compilation classpath only\n              if ((orderEntry instanceof ModuleSourceOrderEntry)) {\n                // this is the entry for outpath of the currently processed module\n                if (dependencyLevel == 0 || chunk.contains(module)) {\n                  // the root module is never included\n                  continue;\n                }\n              }\n              else {\n                final boolean isExported = (orderEntry instanceof ExportableOrderEntry) && ((ExportableOrderEntry)orderEntry).isExported();\n                if (dependencyLevel > 0 && !isExported) {\n                  if (!(orderEntry instanceof ModuleOrderEntry)) {\n                    // non-exported dependencies are excluded and not processed\n                    continue;\n                  }\n                }\n              }\n            }\n            if (orderEntry instanceof JdkOrderEntry) {\n              if (genOptions.forceTargetJdk && !generateRuntimeClasspath) {\n                pathItems\n                  .add(new PathRefItem(BuildProperties.propertyRef(BuildProperties.getModuleChunkJdkClasspathProperty(chunk.getName()))));\n              }\n            }\n            else if (orderEntry instanceof ModuleOrderEntry) {\n              final ModuleOrderEntry moduleOrderEntry = (ModuleOrderEntry)orderEntry;\n              final Module dependentModule = moduleOrderEntry.getModule();\n              if (!chunk.contains(dependentModule)) {\n                if (generateRuntimeClasspath && !genOptions.inlineRuntimeClasspath) {\n                  // in case of runtime classpath, just an referenced to corresponding classpath is created\n                  final ModuleChunk depChunk = genOptions.getChunkByModule(dependentModule);\n                  if (!processedChunks.contains(depChunk)) {\n                    // chunk references are included in the runtime classpath only once\n                    processedChunks.add(depChunk);\n                    String property = generateTestClasspath ? BuildProperties.getTestRuntimeClasspathProperty(depChunk.getName())\n                                                            : BuildProperties.getRuntimeClasspathProperty(depChunk.getName());\n                    pathItems.add(new PathRefItem(property));\n                  }\n                }\n                else {\n                  // in case of compile classpath or inlined runtime classpath,\n                  // the referenced module is processed recursively\n                  processModule(dependentModule, dependencyLevel + 1, moduleOrderEntry.isExported());\n                }\n              }\n            }\n            else if (orderEntry instanceof LibraryOrderEntry) {\n              final LibraryOrderEntry libraryOrderEntry = (LibraryOrderEntry)orderEntry;\n              final String libraryName = libraryOrderEntry.getLibraryName();\n              if (((LibraryOrderEntry)orderEntry).isModuleLevel()) {\n                CompositeGenerator gen = new CompositeGenerator();\n                gen.setHasLeadingNewline(false);\n                LibraryDefinitionsGeneratorFactory.genLibraryContent(project, genOptions, libraryOrderEntry.getLibrary(), baseDir, gen);\n                pathItems.add(new GeneratorItem(libraryName, gen));\n              }\n              else {\n                pathItems.add(new PathRefItem(BuildProperties.getLibraryPathId(libraryName)));\n              }\n            }\n            else if (orderEntry instanceof ModuleSourceOrderEntry) {\n              // Module source entry?\n              for (String url : getCompilationClasses(orderEntry, ((GenerationOptionsImpl)genOptions), generateRuntimeClasspath,\n                                                      generateTestClasspath, dependencyLevel == 0)) {\n                if (url.endsWith(JarFileSystem.JAR_SEPARATOR)) {\n                  url = url.substring(0, url.length() - JarFileSystem.JAR_SEPARATOR.length());\n                }\n                final String propertyRef = genOptions.getPropertyRefForUrl(url);\n                if (propertyRef != null) {\n                  pathItems.add(new PathElementItem(propertyRef));\n                }\n                else {\n                  final String path = VirtualFileManager.extractPath(url);\n                  pathItems.add(new PathElementItem(\n                    GenerationUtils.toRelativePath(path, chunk.getBaseDir(), moduleChunkBasedirProperty, genOptions)));\n                }\n              }\n            }\n            else {\n              // Unknown order entry type. If it is actually encountered, extension point should be implemented\n              pathItems.add(new GeneratorItem(orderEntry.getClass().getName(),\n                                              new Comment(\"Unknown OrderEntryType: \" + orderEntry.getClass().getName())));\n            }\n          }\n        }\n      }.processModule(module, 0, false);\n    }\n    // convert path items to generators\n    for (final ClasspathItem pathItem : pathItems) {\n      add(pathItem.toGenerator());\n    }\n  }","commit_id":"67743ac4d93e9389dbd1c110873f2fecf6853603","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static String[] getServiceUrls() {\n    final List<String> configured = getInstance().getUrls();\n    if (!configured.isEmpty()) return ArrayUtil.toStringArray(configured);\n    return new String[]{\n      \"http://oss.sonatype.org/service/local/\",\n      \"http://repo.jfrog.org/artifactory/api/\",\n      \"https://repository.jboss.org/nexus/service/local/\"\n    };\n  }","id":36933,"modified_method":"public static String[] getServiceUrls() {\n    return ArrayUtil.toStringArray(getInstance().getUrls());\n  }","commit_id":"6917f0e5e9b1b5f7235054537d8c8443df7994fd","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public Element getState() {\n    final Element element = new Element(\"maven-services\");\n    for (String url : myUrls) {\n      final Element child = new Element(\"service-url\");\n      child.setText(StringUtil.escapeXml(url));\n      element.addContent(child);\n    }\n    return element;\n  }","id":36934,"modified_method":"@Override\n  public MavenRepositoryServicesManager getState() {\n    return this;\n  }","commit_id":"6917f0e5e9b1b5f7235054537d8c8443df7994fd","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void ensureLibrariesAreDownloaded(final Project project, final MultiMap<Library, Module> libraries, ProgressIndicator indicator) {\n    THashMap<Library, Pair<Integer, String>> libsToSync = new THashMap<Library, Pair<Integer, String>>();\n\n    String localRepositoryPath = FileUtil.toSystemIndependentName(MavenProjectsManager.getInstance(project).getLocalRepository().getPath());\n\n    // todo group libraries together later\n    AccessToken token = ApplicationManager.getApplication().acquireReadActionLock();\n    try {\n      for (final Library library : libraries.keySet()) {\n        String[] urls = library.getUrls(OrderRootType.CLASSES);\n        VirtualFile[] files = library.getFiles(OrderRootType.CLASSES);\n        // check library state via URLs vs files number test\n        if (urls.length <= files.length) continue;\n        int flag = 0;\n        if (library.getUrls(OrderRootType.SOURCES).length > 0) flag |= 0x1;\n        if (library.getUrls(JavadocOrderRootType.getInstance()).length > 0) flag |= 0x2;\n\n        String firstUrl = StringUtil.trimStart(PathUtil.getLocalPath(urls[0]), JarFileSystem.PROTOCOL_PREFIX);\n        String storagePath = firstUrl.startsWith(localRepositoryPath) ? null : FileUtil.toSystemDependentName(\n          PathUtil.getParentPath(firstUrl));\n\n        libsToSync.put(library, Pair.create(flag, storagePath));\n      }\n    }\n    finally {\n      token.finish();\n    }\n    if (libsToSync.isEmpty()) return;\n\n    Map<String, MavenRepositoryInfo> repoMap = new THashMap<String, MavenRepositoryInfo>();\n    for (String url : MavenRepositoryServicesManager.getServiceUrls()) {\n      for (MavenRepositoryInfo info : MavenRepositoryServicesManager.getRepositories(url)) {\n        repoMap.put(info.getId(), info);\n      }\n    }\n    final List<MavenArtifact> dowloaded = new ArrayList<MavenArtifact>();\n    for (final Library library : libsToSync.keySet()) {\n      int flag = libsToSync.get(library).first;\n      final String storagePath = libsToSync.get(library).second;\n      final SmartList<MavenExtraArtifactType> extraTypes = new SmartList<MavenExtraArtifactType>();\n      if ((flag & 0x1) != 0) extraTypes.add(MavenExtraArtifactType.SOURCES);\n      if ((flag & 0x2) != 0) extraTypes.add(MavenExtraArtifactType.DOCS);\n\n      RepositoryLibraryProperties properties = (RepositoryLibraryProperties)((LibraryEx)library).getProperties();\n      MavenId mavenId = RepositoryAttachHandler.getMavenId(properties.getMavenId());\n      List<MavenId> idsToResolve = Collections.singletonList(mavenId);\n\n      indicator.setText(\"Synchronizing \" + mavenId.getDisplayString() + \"...\");\n\n      // detect repositories: we need to re-search artifacts, it's faster than to query hundreds of them.\n      ArrayList<MavenRepositoryInfo> repositories = new ArrayList<MavenRepositoryInfo>();\n      for (String url : MavenRepositoryServicesManager.getServiceUrls()) {\n        List<MavenArtifactInfo> artifacts = MavenRepositoryServicesManager.findArtifacts(new MavenArtifactInfo(mavenId, \"jar\", null), url);\n        for (MavenArtifactInfo artifact : artifacts) {\n          ContainerUtil.addIfNotNull(repositories, repoMap.get(artifact.getRepositoryId()));\n        }\n      }\n\n      RepositoryAttachHandler.doResolveInner(\n        project, idsToResolve, extraTypes, repositories,\n        new Processor<List<MavenArtifact>>() {\n          @Override\n          public boolean process(final List<MavenArtifact> artifacts) {\n            dowloaded.addAll(artifacts);\n            ApplicationManager.getApplication().invokeLater(new DumbAwareRunnable() {\n              @Override\n              public void run() {\n                if (((LibraryEx)library).isDisposed()) return;\n                AccessToken token = ApplicationManager.getApplication().acquireWriteActionLock(RepositoryLibrarySynchronizer.class);\n                try {\n                  List<OrderRoot> roots = RepositoryAttachHandler.createRoots(artifacts, storagePath);\n                  Library.ModifiableModel model = library.getModifiableModel();\n                  for (OrderRoot root : roots) {\n                    String fileName = PathUtil.getFileName(PathUtil.getLocalPath(root.getFile().getUrl()));\n                    for (String existingUrl : model.getUrls(root.getType())) {\n                      if (Comparing.equal(PathUtil.getFileName(PathUtil.getLocalPath(existingUrl)), fileName)) {\n                        model.removeRoot(existingUrl, root.getType());\n                      }\n                    }\n                    model.addRoot(root.getFile(), root.getType());\n                  }\n                  model.commit();\n                }\n                finally {\n                  token.finish();\n                }\n              }\n            }, project.getDisposed());\n            return true;\n          }\n        }, indicator);\n    }\n    RepositoryAttachHandler.notifyArtifactsDownloaded(project, dowloaded);\n  }","id":36935,"modified_method":"private static void ensureLibrariesAreDownloaded(final Project project, final MultiMap<Library, Module> libraries, ProgressIndicator indicator) {\n    THashMap<Library, Pair<Integer, String>> libsToSync = new THashMap<Library, Pair<Integer, String>>();\n\n    String localRepositoryPath = FileUtil.toSystemIndependentName(MavenProjectsManager.getInstance(project).getLocalRepository().getPath());\n\n    // todo group libraries together later\n    AccessToken token = ApplicationManager.getApplication().acquireReadActionLock();\n    try {\n      for (final Library library : libraries.keySet()) {\n        String[] urls = library.getUrls(OrderRootType.CLASSES);\n        VirtualFile[] files = library.getFiles(OrderRootType.CLASSES);\n        // check library state via URLs vs files number test\n        if (urls.length <= files.length) continue;\n        int flag = 0;\n        if (library.getUrls(OrderRootType.SOURCES).length > 0) flag |= 0x1;\n        if (library.getUrls(JavadocOrderRootType.getInstance()).length > 0) flag |= 0x2;\n\n        String firstUrl = StringUtil.trimStart(PathUtil.getLocalPath(urls[0]), JarFileSystem.PROTOCOL_PREFIX);\n        String storagePath = firstUrl.startsWith(localRepositoryPath) ? null : FileUtil.toSystemDependentName(\n          PathUtil.getParentPath(firstUrl));\n\n        libsToSync.put(library, Pair.create(flag, storagePath));\n      }\n    }\n    finally {\n      token.finish();\n    }\n    if (libsToSync.isEmpty()) return;\n\n    Map<String, MavenRepositoryInfo> repoMap = new THashMap<String, MavenRepositoryInfo>();\n    for (String url : MavenRepositoryServicesManager.getInstance().getUrls()) {\n      for (MavenRepositoryInfo info : MavenRepositoryServicesManager.getRepositories(url)) {\n        repoMap.put(info.getId(), info);\n      }\n    }\n    final List<MavenArtifact> dowloaded = new ArrayList<MavenArtifact>();\n    for (final Library library : libsToSync.keySet()) {\n      int flag = libsToSync.get(library).first;\n      final String storagePath = libsToSync.get(library).second;\n      final SmartList<MavenExtraArtifactType> extraTypes = new SmartList<MavenExtraArtifactType>();\n      if ((flag & 0x1) != 0) extraTypes.add(MavenExtraArtifactType.SOURCES);\n      if ((flag & 0x2) != 0) extraTypes.add(MavenExtraArtifactType.DOCS);\n\n      RepositoryLibraryProperties properties = (RepositoryLibraryProperties)((LibraryEx)library).getProperties();\n      MavenId mavenId = RepositoryAttachHandler.getMavenId(properties.getMavenId());\n      List<MavenId> idsToResolve = Collections.singletonList(mavenId);\n\n      indicator.setText(\"Synchronizing \" + mavenId.getDisplayString() + \"...\");\n\n      // detect repositories: we need to re-search artifacts, it's faster than to query hundreds of them.\n      ArrayList<MavenRepositoryInfo> repositories = new ArrayList<MavenRepositoryInfo>();\n      for (String url : MavenRepositoryServicesManager.getInstance().getUrls()) {\n        List<MavenArtifactInfo> artifacts = MavenRepositoryServicesManager.findArtifacts(new MavenArtifactInfo(mavenId, \"jar\", null), url);\n        for (MavenArtifactInfo artifact : artifacts) {\n          ContainerUtil.addIfNotNull(repositories, repoMap.get(artifact.getRepositoryId()));\n        }\n      }\n\n      RepositoryAttachHandler.doResolveInner(\n        project, idsToResolve, extraTypes, repositories,\n        new Processor<List<MavenArtifact>>() {\n          @Override\n          public boolean process(final List<MavenArtifact> artifacts) {\n            dowloaded.addAll(artifacts);\n            ApplicationManager.getApplication().invokeLater(new DumbAwareRunnable() {\n              @Override\n              public void run() {\n                if (((LibraryEx)library).isDisposed()) return;\n                AccessToken token = ApplicationManager.getApplication().acquireWriteActionLock(RepositoryLibrarySynchronizer.class);\n                try {\n                  List<OrderRoot> roots = RepositoryAttachHandler.createRoots(artifacts, storagePath);\n                  Library.ModifiableModel model = library.getModifiableModel();\n                  for (OrderRoot root : roots) {\n                    String fileName = PathUtil.getFileName(PathUtil.getLocalPath(root.getFile().getUrl()));\n                    for (String existingUrl : model.getUrls(root.getType())) {\n                      if (Comparing.equal(PathUtil.getFileName(PathUtil.getLocalPath(existingUrl)), fileName)) {\n                        model.removeRoot(existingUrl, root.getType());\n                      }\n                    }\n                    model.addRoot(root.getFile(), root.getType());\n                  }\n                  model.commit();\n                }\n                finally {\n                  token.finish();\n                }\n              }\n            }, project.getDisposed());\n            return true;\n          }\n        }, indicator);\n    }\n    RepositoryAttachHandler.notifyArtifactsDownloaded(project, dowloaded);\n  }","commit_id":"6917f0e5e9b1b5f7235054537d8c8443df7994fd","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  @NotNull\n  public String[] getUrls(@NotNull OrderRootType rootType) {\n    checkDisposed();\n\n    final VirtualFilePointerContainer result = myRoots.get(rootType);\n    return result.getUrls();\n  }","id":36936,"modified_method":"@Override\n  @NotNull\n  public String[] getUrls(@NotNull OrderRootType rootType) {\n    checkDisposed();\n\n    VirtualFilePointerContainer result = myRoots.get(rootType);\n    return result == null ? ArrayUtilRt.EMPTY_STRING_ARRAY : result.getUrls();\n  }","commit_id":"7ce50b9953f59f3e57422ee945bf118cc6d47c59","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  @Override\n  protected Url getUrl(@NotNull OpenInBrowserRequest request, @NotNull VirtualFile file) throws BrowserException {\n    if (file instanceof HttpVirtualFile) {\n      return Urls.newFromVirtualFile(file);\n    }\n    else {\n      return ContainerUtil.getFirstItem(getUrls(file, request.getProject(), null));\n    }\n  }","id":36937,"modified_method":"@Nullable\n  @Override\n  protected Url getUrl(@NotNull OpenInBrowserRequest request, @NotNull VirtualFile file) throws BrowserException {\n    if (file instanceof HttpVirtualFile) {\n      return Urls.newFromVirtualFile(file);\n    }\n    else {\n      return ContainerUtil.getFirstItem(getUrls(file, request.getProject(), null, request.isAppendAccessToken()));\n    }\n  }","commit_id":"275c227e83ea14b73159780b368ed0e991a52996","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  public static List<Url> getUrls(@NotNull VirtualFile file, @NotNull Project project, @Nullable String currentAuthority) {\n    if (currentAuthority != null && !compareAuthority(currentAuthority)) {\n      return Collections.emptyList();\n    }\n\n    PathInfo info = WebServerPathToFileManager.getInstance(project).getPathInfo(file);\n    if (info == null) {\n      return Collections.emptyList();\n    }\n\n    int effectiveBuiltInServerPort = BuiltInServerOptions.getInstance().getEffectiveBuiltInServerPort();\n    String path = info.getPath();\n\n    String authority = currentAuthority == null ? \"localhost:\" + effectiveBuiltInServerPort : currentAuthority;\n    String query = \"?\" + BuiltInWebServerKt.TOKEN_PARAM_NAME + \"=\" + BuiltInWebServerKt.acquireToken();\n    List<Url> urls = new SmartList<>(Urls.newHttpUrl(authority, '/' + project.getName() + '/' + path, query));\n\n    String path2 = info.getRootLessPathIfPossible();\n    if (path2 != null) {\n      urls.add(Urls.newHttpUrl(authority, '/' + project.getName() + '/' + path2, query));\n    }\n\n    int defaultPort = BuiltInServerManager.getInstance().getPort();\n    if (currentAuthority == null && defaultPort != effectiveBuiltInServerPort) {\n      String defaultAuthority = \"localhost:\" + defaultPort;\n      urls.add(Urls.newHttpUrl(defaultAuthority, '/' + project.getName() + '/' + path, query));\n      if (path2 != null) {\n        urls.add(Urls.newHttpUrl(defaultAuthority, '/' + project.getName() + '/' + path2, query));\n      }\n    }\n    \n    return urls;\n  }","id":36938,"modified_method":"@NotNull\n  public static List<Url> getUrls(@NotNull VirtualFile file, @NotNull Project project, @Nullable String currentAuthority) {\n    return getUrls(file, project, currentAuthority, true);\n  }","commit_id":"275c227e83ea14b73159780b368ed0e991a52996","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  public static Collection<Url> getDebuggableUrls(@Nullable PsiElement context) {\n    try {\n      OpenInBrowserRequest request = context == null ? null : OpenInBrowserRequest.create(context);\n      return request == null || request.getFile().getViewProvider().getBaseLanguage() == XMLLanguage.INSTANCE ? Collections.<Url>emptyList() : getUrls(getProvider(request), request);\n    }\n    catch (WebBrowserUrlProvider.BrowserException ignored) {\n      return Collections.emptyList();\n    }\n  }","id":36939,"modified_method":"@NotNull\n  public static Collection<Url> getDebuggableUrls(@Nullable PsiElement context) {\n    try {\n      OpenInBrowserRequest request = context == null ? null : OpenInBrowserRequest.create(context);\n      if (request == null || request.getFile().getViewProvider().getBaseLanguage() == XMLLanguage.INSTANCE) {\n        return Collections.<Url>emptyList();\n      }\n      else {\n        // it is client responsibility to set token\n        request.setAppendAccessToken(false);\n        return getUrls(getProvider(request), request);\n      }\n    }\n    catch (WebBrowserUrlProvider.BrowserException ignored) {\n      return Collections.emptyList();\n    }\n  }","commit_id":"275c227e83ea14b73159780b368ed0e991a52996","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void doResolveInner(Project project,\n                                     MavenId mavenId,\n                                     List<MavenExtraArtifactType> extraTypes,\n                                     Collection<MavenRepositoryInfo> repositories,\n                                     final Processor<List<MavenArtifact>> resultProcessor,\n                                     ProgressIndicator indicator) {\n    doResolveInner(project, Collections.singletonList(mavenId), extraTypes, repositories, resultProcessor, indicator);\n  }","id":36940,"modified_method":"public static void doResolveInner(Project project,\n                                    final MavenId mavenId,\n                                    List<MavenExtraArtifactType> extraTypes,\n                                    Collection<MavenRepositoryInfo> repositories,\n                                    @Nullable final Processor<List<MavenArtifact>> resultProcessor,\n                                    ProgressIndicator indicator) {\n    boolean cancelled = false;\n    final Collection<MavenArtifact> result = new LinkedHashSet<MavenArtifact>();\n    MavenEmbeddersManager manager = MavenProjectsManager.getInstance(project).getEmbeddersManager();\n    MavenEmbedderWrapper embedder = manager.getEmbedder(MavenEmbeddersManager.FOR_DOWNLOAD);\n    try {\n      final MavenGeneralSettings mavenGeneralSettings = MavenProjectsManager.getInstance(project).getGeneralSettings();\n      embedder.customizeForResolve(\n        new SoutMavenConsole(mavenGeneralSettings.getOutputLevel(), mavenGeneralSettings.isPrintErrorStackTraces()),\n        new MavenProgressIndicator(indicator));\n      List<MavenRemoteRepository> remoteRepositories = convertRepositories(repositories);\n      List<MavenArtifactInfo> artifacts = Collections.singletonList(new MavenArtifactInfo(mavenId, \"jar\", null));\n      List<MavenArtifact> firstResult = embedder.resolveTransitively(artifacts, remoteRepositories);\n      for (MavenArtifact artifact : firstResult) {\n        if (!artifact.isResolved() || MavenConstants.SCOPE_TEST.equals(artifact.getScope())) {\n          continue;\n        }\n        result.add(artifact);\n      }\n      // download docs & sources\n      if (!extraTypes.isEmpty()) {\n        Set<String> allowedClassifiers = JBIterable.from(extraTypes).transform(new Function<MavenExtraArtifactType, String>() {\n          @Override\n          public String fun(MavenExtraArtifactType extraType) {\n            return extraType.getDefaultClassifier();\n          }\n        }).toSet();\n        List<MavenArtifactInfo> resolve = JBIterable.from(extraTypes).transform(new Function<MavenExtraArtifactType, MavenArtifactInfo>() {\n          @Override\n          public MavenArtifactInfo fun(MavenExtraArtifactType extraType) {\n            return new MavenArtifactInfo(mavenId, extraType.getDefaultExtension(), extraType.getDefaultClassifier());\n          }\n        }).toList();\n        // skip sources/javadoc for dependencies\n        for (MavenArtifact artifact : embedder.resolveTransitively(new ArrayList<MavenArtifactInfo>(resolve), remoteRepositories)) {\n          if (!artifact.isResolved() || MavenConstants.SCOPE_TEST.equals(artifact.getScope()) || !allowedClassifiers.contains(artifact.getClassifier())) {\n            continue;\n          }\n          result.add(artifact);\n        }\n      }\n    }\n    catch (MavenProcessCanceledException e) {\n      cancelled = true;\n    }\n    finally {\n      manager.release(embedder);\n      if (!cancelled && resultProcessor != null) {\n        ApplicationManager.getApplication().invokeAndWait(new Runnable() {\n          public void run() {\n            DumbService.allowStartingDumbModeInside(DumbModePermission.MAY_START_BACKGROUND, new Runnable() {\n              @Override\n              public void run() {\n                resultProcessor.process(new ArrayList<MavenArtifact>(result));\n              }\n            });\n          }\n        }, indicator.getModalityState());\n      }\n    }\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void notifyArtifactsDownloaded(Project project, List<MavenArtifact> artifacts) {\n    final StringBuilder sb = new StringBuilder();\n    final String title = \"The following files were downloaded:\";\n    sb.append(\"<ol>\");\n    for (MavenArtifact each : artifacts) {\n      sb.append(\"<li>\");\n      sb.append(each.getFile().getName());\n      final String scope = each.getScope();\n      if (scope != null) {\n        sb.append(\" (\");\n        sb.append(scope);\n        sb.append(\")\");\n      }\n      sb.append(\"<\/li>\");\n    }\n    sb.append(\"<\/ol>\");\n    Notifications.Bus.notify(new Notification(\"Repository\", title, sb.toString(), NotificationType.INFORMATION), project);\n  }","id":36941,"modified_method":"public static void notifyArtifactsDownloaded(Project project, List<OrderRoot> roots) {\n    final StringBuilder sb = new StringBuilder();\n    final String title = \"The following files were downloaded:\";\n    sb.append(\"<ol>\");\n    for (OrderRoot root : roots) {\n      sb.append(\"<li>\");\n      sb.append(root.getFile().getName());\n      sb.append(\"<\/li>\");\n    }\n    sb.append(\"<\/ol>\");\n    Notifications.Bus.notify(new Notification(\"Repository\", title, sb.toString(), NotificationType.INFORMATION), project);\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static NewLibraryConfiguration resolveAndDownload(final Project project,\n                                                           final String coord,\n                                                           boolean attachJavaDoc,\n                                                           boolean attachSources,\n                                                           @Nullable final String copyTo,\n                                                           List<MavenRepositoryInfo> repositories) {\n    final List<OrderRoot> roots = resolveAndDownloadImpl(project, coord, attachJavaDoc, attachSources, copyTo, repositories);\n    return new NewLibraryConfiguration(coord, RepositoryLibraryType.getInstance(), new RepositoryLibraryProperties(coord)) {\n      @Override\n      public void addRoots(@NotNull LibraryEditor editor) {\n        editor.addRoots(roots);\n      }\n    };\n  }","id":36942,"modified_method":"public static NewLibraryConfiguration resolveAndDownload(final Project project,\n                                                           final String coord,\n                                                           boolean attachJavaDoc,\n                                                           boolean attachSources,\n                                                           @Nullable final String copyTo,\n                                                           List<MavenRepositoryInfo> repositories) {\n    RepositoryLibraryProperties libraryProperties = new RepositoryLibraryProperties(coord);\n    final List<OrderRoot> roots = MavenDependenciesRemoteManager.getInstance(project)\n      .downloadDependenciesModal(libraryProperties, attachSources, attachJavaDoc, copyTo);\n    notifyArtifactsDownloaded(project, roots);\n    RepositoryLibraryDescription libraryDescription = RepositoryLibraryDescription.findDescription(libraryProperties);\n    return new NewLibraryConfiguration(\n      libraryDescription.getDisplayName(libraryProperties.getVersion()),\n      RepositoryLibraryType.getInstance(),\n      new RepositoryLibraryProperties(coord)) {\n      @Override\n      public void addRoots(@NotNull LibraryEditor editor) {\n        editor.addRoots(roots);\n      }\n    };\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static List<OrderRoot> resolveAndDownloadImpl(final Project project,\n                                                       final String coord,\n                                                       boolean attachJavaDoc,\n                                                       boolean attachSources,\n                                                       @Nullable final String copyTo,\n                                                       List<MavenRepositoryInfo> repositories) {\n    final SmartList<MavenExtraArtifactType> extraTypes = new SmartList<MavenExtraArtifactType>();\n    if (attachSources) extraTypes.add(MavenExtraArtifactType.SOURCES);\n    if (attachJavaDoc) extraTypes.add(MavenExtraArtifactType.DOCS);\n    final Ref<List<OrderRoot>> result = Ref.create(null);\n    resolveLibrary(project, coord, extraTypes, repositories, new Processor<List<MavenArtifact>>() {\n      public boolean process(final List<MavenArtifact> artifacts) {\n        if (!artifacts.isEmpty()) {\n          AccessToken accessToken = WriteAction.start();\n          try {\n            final List<OrderRoot> roots = createRoots(artifacts, copyTo);\n            result.set(roots);\n          }\n          finally {\n            accessToken.finish();\n          }\n          notifyArtifactsDownloaded(project, artifacts);\n        }\n        return true;\n      }\n    });\n    return result.get();\n  }","id":36943,"modified_method":"public static List<OrderRoot> resolveAndDownloadImpl(final Project project,\n                                                       final String coord,\n                                                       boolean attachJavaDoc,\n                                                       boolean attachSources,\n                                                       @Nullable final String copyTo,\n                                                       List<MavenRepositoryInfo> repositories,\n                                                       ProgressIndicator indicator) {\n    final SmartList<MavenExtraArtifactType> extraTypes = new SmartList<MavenExtraArtifactType>();\n    if (attachSources) extraTypes.add(MavenExtraArtifactType.SOURCES);\n    if (attachJavaDoc) extraTypes.add(MavenExtraArtifactType.DOCS);\n    final Ref<List<OrderRoot>> result = Ref.create(null);\n    doResolveInner(project, getMavenId(coord), extraTypes, repositories, new Processor<List<MavenArtifact>>() {\n      public boolean process(final List<MavenArtifact> artifacts) {\n        if (!artifacts.isEmpty()) {\n          AccessToken accessToken = WriteAction.start();\n          try {\n            final List<OrderRoot> roots = createRoots(artifacts, copyTo);\n            result.set(roots);\n          }\n          finally {\n            accessToken.finish();\n          }\n        }\n        return true;\n      }\n    }, indicator);\n    return result.get();\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void reloadVersionsAsync() {\n    setState(State.Loading);\n    Task task = new Task.Backgroundable(\n      project,\n      ProjectBundle.message(\"maven.loading.library.version.hint\", repositoryLibraryDescription.getDisplayName()),\n      false) {\n      public void run(@NotNull ProgressIndicator indicator) {\n        try {\n          List<String> versions = RepositoryAttachHandler.retrieveVersions(\n            project,\n            repositoryLibraryDescription.getGroupId(),\n            repositoryLibraryDescription.getArtifactId(),\n            repositoryLibraryDescription.getRemoteRepositories());\n          versionsLoaded(versions);\n        }\n        catch (Exception e) {\n          versionsFailedToLoad();\n        }\n      }\n    };\n    ProgressManager.getInstance().run(task);\n  }","id":36944,"modified_method":"private void reloadVersionsAsync() {\n    setState(State.Loading);\n    MavenVersionsRemoteManager.getInstance(project)\n      .getMavenArtifactVersionsAsync(\n        repositoryLibraryDescription.getGroupId(),\n        repositoryLibraryDescription.getArtifactId(),\n        new MavenRemoteTask.ResultProcessor<List<String>>() {\n          @Override\n          public void process(List<String> versions) {\n            versionsLoaded(versions);\n          }\n        });\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private LibraryEx createNewLibrary(@NotNull final Module module, final LibraryTable.ModifiableModel modifiableModel) {\n    RepositoryLibraryProperties libraryProperties = new RepositoryLibraryProperties(\n      libraryDescription.getGroupId(),\n      libraryDescription.getArtifactId(),\n      model.getVersion());\n    final LibraryEx library = (LibraryEx)modifiableModel.createLibrary(\n      LibraryEditingUtil.suggestNewLibraryName(modifiableModel, RepositoryLibraryType.getInstance().getDescription(libraryProperties)),\n      RepositoryLibraryType.REPOSITORY_LIBRARY_KIND);\n    RepositoryLibraryProperties realLibraryProperties = (RepositoryLibraryProperties)library.getProperties();\n    realLibraryProperties.setMavenId(libraryProperties.getMavenId());\n\n    ApplicationManager.getApplication().runWriteAction(new Runnable() {\n      @Override\n      public void run() {\n        modifiableModel.commit();\n      }\n    });\n    Task task = new Task.Backgroundable(project, \"Maven\", false) {\n      public void run(@NotNull ProgressIndicator indicator) {\n        RepositoryUtils.loadDependencies(\n          indicator,\n          module.getProject(),\n          library,\n          model.isDownloadSources(),\n          model.isDownloadJavaDocs());\n      }\n    };\n    ProgressManager.getInstance().run(task);\n\n    return library;\n  }","id":36945,"modified_method":"private LibraryEx createNewLibrary(@NotNull final Module module, final LibraryTable.ModifiableModel modifiableModel) {\n    RepositoryLibraryProperties libraryProperties = new RepositoryLibraryProperties(\n      libraryDescription.getGroupId(),\n      libraryDescription.getArtifactId(),\n      model.getVersion());\n    final LibraryEx library = (LibraryEx)modifiableModel.createLibrary(\n      LibraryEditingUtil.suggestNewLibraryName(modifiableModel, RepositoryLibraryType.getInstance().getDescription(libraryProperties)),\n      RepositoryLibraryType.REPOSITORY_LIBRARY_KIND);\n    RepositoryLibraryProperties realLibraryProperties = (RepositoryLibraryProperties)library.getProperties();\n    realLibraryProperties.setMavenId(libraryProperties.getMavenId());\n\n    ApplicationManager.getApplication().runWriteAction(new Runnable() {\n      @Override\n      public void run() {\n        modifiableModel.commit();\n      }\n    });\n    RepositoryUtils.loadDependencies(\n      module.getProject(),\n      library,\n      model.isDownloadSources(),\n      model.isDownloadJavaDocs(),\n      null);\n    return library;\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static Collection<Library> collectLibraries(final @NotNull Project project, final @NotNull Predicate<Library> predicate) {\n    final com.intellij.util.containers.HashSet<Library> result = new com.intellij.util.containers.HashSet<Library>();\n    ApplicationManager.getApplication().runReadAction(new Runnable() {\n      @Override\n      public void run() {\n        for (final Module module : ModuleManager.getInstance(project).getModules()) {\n          OrderEnumerator.orderEntries(module).withoutSdk().forEachLibrary(new Processor<Library>() {\n            @Override\n            public boolean process(Library library) {\n              if (predicate.apply(library)) {\n                result.add(library);\n              }\n              return true;\n            }\n          });\n        }\n        for (Library library : ProjectLibraryTable.getInstance(project).getLibraries()) {\n          if (predicate.apply(library)) {\n            result.add(library);\n          }\n        }\n      }\n    });\n    return result;\n  }","id":36946,"modified_method":"private static Collection<Library> collectLibraries(final @NotNull Project project, final @NotNull Predicate<Library> predicate) {\n    final HashSet<Library> result = new HashSet<Library>();\n    ApplicationManager.getApplication().runReadAction(new Runnable() {\n      @Override\n      public void run() {\n        for (final Module module : ModuleManager.getInstance(project).getModules()) {\n          OrderEnumerator.orderEntries(module).withoutSdk().forEachLibrary(new Processor<Library>() {\n            @Override\n            public boolean process(Library library) {\n              if (predicate.apply(library)) {\n                result.add(library);\n              }\n              return true;\n            }\n          });\n        }\n        for (Library library : ProjectLibraryTable.getInstance(project).getLibraries()) {\n          if (predicate.apply(library)) {\n            result.add(library);\n          }\n        }\n      }\n    });\n    return result;\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void runActivity(@NotNull final Project project) {\n    StartupManager.getInstance(project).registerPostStartupActivity(new DumbAwareRunnable() {\n      @Override\n      public void run() {\n        ApplicationManager.getApplication().invokeLater(new DumbAwareRunnable() {\n          @Override\n          public void run() {\n            final Collection<Library> libraries = collectLibraries(project, new Predicate<Library>() {\n              @Override\n              public boolean apply(Library library) {\n                if (!(library instanceof LibraryEx)) {\n                  return false;\n                }\n                LibraryEx libraryEx = (LibraryEx)library;\n                return libraryEx.getKind() == RepositoryLibraryType.REPOSITORY_LIBRARY_KIND &&\n                       libraryEx.getProperties() instanceof RepositoryLibraryProperties;\n              }\n            });\n            if (libraries.isEmpty()) return;\n            Task task = new Task.Backgroundable(project, \"Maven\", false) {\n              public void run(@NotNull ProgressIndicator indicator) {\n                for (Library library : libraries) {\n                  LibraryEx libraryEx = (LibraryEx)library;\n                  RepositoryLibraryProperties properties = (RepositoryLibraryProperties)libraryEx.getProperties();\n\n                  if (isLibraryNeedToBeReloaded(libraryEx, properties)) {\n                    RepositoryUtils.reloadDependencies(\n                      indicator,\n                      project,\n                      libraryEx);\n                  }\n                }\n              }\n            };\n            ProgressManager.getInstance().run(task);\n          }\n        }, project.getDisposed());\n      }\n    });\n  }","id":36947,"modified_method":"@Override\n  public void runActivity(@NotNull final Project project) {\n    StartupManager.getInstance(project).registerPostStartupActivity(new DumbAwareRunnable() {\n      @Override\n      public void run() {\n        ApplicationManager.getApplication().invokeLater(new DumbAwareRunnable() {\n          @Override\n          public void run() {\n            final Collection<Library> libraries = collectLibraries(project, new Predicate<Library>() {\n              @Override\n              public boolean apply(Library library) {\n                if (!(library instanceof LibraryEx)) {\n                  return false;\n                }\n                LibraryEx libraryEx = (LibraryEx)library;\n                return libraryEx.getKind() == RepositoryLibraryType.REPOSITORY_LIBRARY_KIND &&\n                       libraryEx.getProperties() instanceof RepositoryLibraryProperties;\n              }\n            });\n            for (Library library : libraries) {\n              final LibraryEx libraryEx = (LibraryEx)library;\n              RepositoryUtils.reloadDependencies(project, libraryEx);\n            }\n          }\n        }, project.getDisposed());\n      }\n    });\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  protected void edit() {\n    @NotNull RepositoryLibraryProperties properties = myEditorComponent.getProperties();\n    //String oldVersion = properties.getVersion();\n    boolean wasGeneratedName =\n      RepositoryLibraryType.getInstance().getDescription(properties).equals(myEditorComponent.getLibraryEditor().getName());\n    RepositoryLibraryPropertiesModel model = new RepositoryLibraryPropertiesModel(\n      properties.getVersion(),\n      RepositoryUtils.libraryHasSources(myEditorComponent.getLibraryEditor()),\n      RepositoryUtils.libraryHasJavaDocs(myEditorComponent.getLibraryEditor()));\n    RepositoryLibraryPropertiesDialog dialog = new RepositoryLibraryPropertiesDialog(\n      myEditorComponent.getProject(),\n      model,\n      RepositoryLibraryDescription.findDescription(properties),\n      true);\n    if (!dialog.showAndGet()) {\n      return;\n    }\n    myEditorComponent.getProperties().changeVersion(model.getVersion());\n    if (wasGeneratedName) {\n      myEditorComponent.renameLibrary(RepositoryLibraryType.getInstance().getDescription(properties));\n    }\n    myEditorComponent.getLibraryEditor().removeAllRoots();\n    myEditorComponent.getLibraryEditor().addRoots(RepositoryUtils.download(\n      myEditorComponent.getProject(),\n      model.isDownloadSources(),\n      model.isDownloadJavaDocs(),\n      properties));\n  }","id":36948,"modified_method":"@Override\n  protected void edit() {\n    @NotNull RepositoryLibraryProperties properties = myEditorComponent.getProperties();\n    //String oldVersion = properties.getVersion();\n    boolean wasGeneratedName =\n      RepositoryLibraryType.getInstance().getDescription(properties).equals(myEditorComponent.getLibraryEditor().getName());\n    RepositoryLibraryPropertiesModel model = new RepositoryLibraryPropertiesModel(\n      properties.getVersion(),\n      RepositoryUtils.libraryHasSources(myEditorComponent.getLibraryEditor()),\n      RepositoryUtils.libraryHasJavaDocs(myEditorComponent.getLibraryEditor()));\n    RepositoryLibraryPropertiesDialog dialog = new RepositoryLibraryPropertiesDialog(\n      myEditorComponent.getProject(),\n      model,\n      RepositoryLibraryDescription.findDescription(properties),\n      true);\n    if (!dialog.showAndGet()) {\n      return;\n    }\n    myEditorComponent.getProperties().changeVersion(model.getVersion());\n    if (wasGeneratedName) {\n      myEditorComponent.renameLibrary(RepositoryLibraryType.getInstance().getDescription(properties));\n    }\n\n    final LibraryEditor libraryEditor = myEditorComponent.getLibraryEditor();\n    MavenDependenciesRemoteManager.getInstance(myEditorComponent.getProject())\n      .downloadDependenciesAsync(\n        properties,\n        model.isDownloadSources(),\n        model.isDownloadJavaDocs(),\n        RepositoryUtils.getStorageRoot(myEditorComponent.getLibraryEditor().getUrls(OrderRootType.CLASSES), myEditorComponent.getProject()),\n        new MavenRemoteTask.ResultProcessor<List<OrderRoot>>() {\n          @Override\n          public void process(List<OrderRoot> roots) {\n            libraryEditor.removeAllRoots();\n            libraryEditor.addRoots(roots);\n          }\n        }\n      );\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void loadDependencies(@NotNull ProgressIndicator indicator,\n                                      @NotNull final Project project,\n                                      @NotNull final LibraryEx library,\n                                      boolean downloadSources,\n                                      boolean downloadJavaDocs) {\n    final String storageRoot = getStorageRoot(library, project);\n    final RepositoryLibraryProperties libraryProperties = (RepositoryLibraryProperties)library.getProperties();\n    loadDependencies(indicator,\n                     project,\n                     libraryProperties,\n                     downloadSources,\n                     downloadJavaDocs,\n                     library.getName(),\n                     new Processor<List<MavenArtifact>>() {\n                       @Override\n                       public boolean process(List<MavenArtifact> artifacts) {\n                         if (artifacts == null || artifacts.isEmpty()) {\n                           return true;\n                         }\n                         final List<OrderRoot> roots = RepositoryAttachHandler.createRoots(artifacts, storageRoot);\n                         ApplicationManager.getApplication().invokeLater(new Runnable() {\n                           @Override\n                           public void run() {\n                             if (library.isDisposed()) {\n                               return;\n                             }\n                             AccessToken token = WriteAction.start();\n                             try {\n                               final NewLibraryEditor editor = new NewLibraryEditor(null, libraryProperties);\n                               editor.removeAllRoots();\n                               editor.addRoots(roots);\n                               final Library.ModifiableModel model = library.getModifiableModel();\n                               editor.applyTo((LibraryEx.ModifiableModelEx)model);\n                               model.commit();\n                             }\n                             finally {\n                               token.finish();\n                             }\n                           }\n                         });\n                         return true;\n                       }\n                     });\n  }","id":36949,"modified_method":"public static void loadDependencies(@NotNull final Project project,\n                                      @NotNull final LibraryEx library,\n                                      boolean downloadSources,\n                                      boolean downloadJavaDocs,\n                                      @Nullable String copyTo) {\n    if (library.getKind() != RepositoryLibraryType.REPOSITORY_LIBRARY_KIND) {\n      return;\n    }\n    final RepositoryLibraryProperties properties = (RepositoryLibraryProperties)library.getProperties();\n\n    MavenDependenciesRemoteManager.getInstance(project)\n      .downloadDependenciesAsync(\n        properties,\n        downloadSources,\n        downloadJavaDocs,\n        copyTo,\n        new MavenRemoteTask.ResultProcessor<List<OrderRoot>>() {\n          @Override\n          public void process(final List<OrderRoot> roots) {\n            ApplicationManager.getApplication().invokeLater(new Runnable() {\n              @Override\n              public void run() {\n                if (library.isDisposed()) {\n                  return;\n                }\n                AccessToken token = WriteAction.start();\n                try {\n                  final NewLibraryEditor editor = new NewLibraryEditor(null, properties);\n                  editor.removeAllRoots();\n                  editor.addRoots(roots);\n                  final Library.ModifiableModel model = library.getModifiableModel();\n                  editor.applyTo((LibraryEx.ModifiableModelEx)model);\n                  model.commit();\n                }\n                finally {\n                  token.finish();\n                }\n              }\n            });\n          }\n        }\n      );\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static String getStorageRoot(Library library, Project project) {\n    final String[] urls = library.getUrls(OrderRootType.CLASSES);\n    if (urls.length == 0) {\n      return null;\n    }\n    final String localRepositoryPath =\n      FileUtil.toSystemIndependentName(MavenProjectsManager.getInstance(project).getLocalRepository().getPath());\n    List<String> roots = JBIterable.of(urls).transform(new Function<String, String>() {\n      @Override\n      public String fun(String urlWithPrefix) {\n        String url = StringUtil.trimStart(urlWithPrefix, JarFileSystem.PROTOCOL_PREFIX);\n        return url.startsWith(localRepositoryPath) ? null : FileUtil.toSystemDependentName(PathUtil.getParentPath(url));\n      }\n    }).toList();\n    Map<String, Integer> counts = new HashMap<String, Integer>();\n    for (String root : roots) {\n      int count = counts.get(root) != null ? counts.get(root) : 0;\n      counts.put(root, count + 1);\n    }\n    return Collections.max(counts.entrySet(), new Comparator<Map.Entry<String, Integer>>() {\n      @Override\n      public int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2) {\n        return o1.getValue().compareTo(o2.getValue());\n      }\n    }).getKey();\n  }","id":36950,"modified_method":"public static String getStorageRoot(Library library, Project project) {\n    return getStorageRoot(library.getUrls(OrderRootType.CLASSES), project);\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void reloadDependenciesAsync(@NotNull final Project project,\n                                             @NotNull final LibraryEx library) {\n    Task task = new Task.Backgroundable(project, \"Maven\", false) {\n      public void run(@NotNull ProgressIndicator indicator) {\n        reloadDependencies(\n          indicator,\n          project,\n          library);\n      }\n    };\n    ProgressManager.getInstance().run(task);\n  }","id":36951,"modified_method":"public static void reloadDependencies(@NotNull final Project project,\n                                        @NotNull final LibraryEx library) {\n    loadDependencies(project, library, libraryHasSources(library), libraryHasJavaDocs(library), getStorageRoot(library, project));\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static String resolveEffectiveVersion(@NotNull Project project, @NotNull RepositoryLibraryProperties properties) {\n    String version = properties.getVersion();\n    boolean isLatest = LatestVersionId.equals(version);\n    boolean isRelease = ReleaseVersionId.equals(version);\n    if (isLatest || isRelease) {\n      Iterable<String> versions = RepositoryAttachHandler.retrieveVersions(\n        project,\n        properties.getGroupId(),\n        properties.getArtifactId(),\n        RepositoryLibraryDescription.findDescription(properties).getRemoteRepositories());\n      if (isRelease) {\n        versions = Iterables.filter(versions, new Predicate<String>() {\n          @Override\n          public boolean apply(String input) {\n            return !input.endsWith(SnapshotVersionSuffix);\n          }\n        });\n      }\n      Iterator<String> iterator = versions.iterator();\n      if (iterator.hasNext()) {\n        version = iterator.next();\n      }\n    }\n    return version;\n  }","id":36952,"modified_method":"public static String resolveEffectiveVersion(@NotNull Project project, @NotNull RepositoryLibraryProperties properties) {\n    String version = properties.getVersion();\n    boolean isLatest = LatestVersionId.equals(version);\n    boolean isRelease = ReleaseVersionId.equals(version);\n    if (isLatest || isRelease) {\n      Iterable<String> versions = MavenVersionsRemoteManager.getInstance(project).getMavenArtifactVersions(\n        properties.getGroupId(),\n        properties.getArtifactId());\n      if (isRelease) {\n        versions = Iterables.filter(versions, new Predicate<String>() {\n          @Override\n          public boolean apply(String input) {\n            return !input.endsWith(SnapshotVersionSuffix);\n          }\n        });\n      }\n      Iterator<String> iterator = versions.iterator();\n      if (iterator.hasNext()) {\n        version = iterator.next();\n      }\n    }\n    return version;\n  }","commit_id":"f069f634d36e5025b2fe9c2c32ef8b552ee7baf7","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n\t * Creates a new file with the overgiven content and resourcetype.\n\t * If some mandatory metadefinitions for the resourcetype are missing, a \n\t * CmsException will be thrown, because the file cannot be created without\n\t * the mandatory metainformations.<BR/>\n\t * If the resourcetype is set to folder, a CmsException will be thrown.<BR/>\n\t * If there is already a file with this filename, a CmsDuplicateKey exception will\n\t * be thrown.\n\t * \n\t * @param callingUser The user who wants to use this method.\n\t * @param project The project in which the resource will be used.\n\t * @param folder The complete path to the folder in which the file will be created.\n\t * @param filename The name of the new file (, No pathinformation allowed).\n\t * @param contents The contents of the new file.\n\t * @param type The resourcetype of the new file.\n\t * @param metainfos A Hashtable of metainfos, that should be set for this file.\n\t * The keys for this Hashtable are the names for metadefinitions, the values are\n\t * the values for the metainfos.\n\t * \n\t * @return file The created file.\n\t * \n\t * @exception CmsException will be thrown for missing metainfos, for worng metadefs\n\t * or if resourcetype is set to folder. The CmsException is also thrown, if the \n\t * filename is not valid. The CmsException will also be thrown, if the user\n\t * has not the rights for this resource.\n\t * @exception CmsDuplikateKeyException if there is already a resource with \n\t * this name.\n\t */\n\tabstract CmsFile createFile(String project, String folder, String filename, \n\t\t\t\t\t\t\t\tbyte[] contents, A_CmsResourceType type, \n\t\t\t\t\t\t\t\tHashtable metainfos)\n\t\tthrows CmsException, CmsDuplicateKeyException;","id":36953,"modified_method":"/**\n\t * Creates a new file with the overgiven content and resourcetype.\n     *\n\t * If the resourcetype is set to folder, a CmsException will be thrown.<BR/>\n\t * \n\t * @param user The user who wants to create the file.\n\t * @param project The project in which the resource will be used.\n\t * @param filename The complete name of the new file (including pathinformation).\n\t * @param flags The flags of this resource.\n\t * @param contents The contents of the new file.\n\t * @param resourceType The resourceType of the new file.\n\t * The keys for this Hashtable are the names for metadefinitions, the values are\n\t * the values for the metainfos.\n\t * \n\t * @return file The created file.\n\t * \n     * @exception CmsException Throws CmsException if operation was not succesful\n     */\n    \n\tabstract CmsFile createFile(A_CmsUser user, A_CmsProject project,\n                                String filename, int flags,\n\t\t\t\t\t\t\t\tbyte[] contents, A_CmsResourceType resourceType)\n        throws CmsException;","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Reads a file from the Cms.<BR/>\n\t * \n\t * @param callingUser The user who wants to use this method.\n\t * @param project The project in which the resource will be used.\n\t * @param folder The complete path to the folder from which the file will be read.\n\t * @param filename The name of the file to be read.\n\t * \n\t * @return file The read file.\n\t * \n\t * @exception CmsException will be thrown, if the file couldn't be read. \n\t * The CmsException will also be thrown, if the user has not the rights \n\t * for this resource.\n\t */\n\tabstract CmsFile readFile(String project, String folder, String filename)\n\t\tthrows CmsException;","id":36954,"modified_method":"/**\n\t * Reads a file from the Cms.<BR/>\n\t * \n\t * @param project The project in which the resource will be used.\n\t * @param filename The complete name of the new file (including pathinformation).\n\t * \n\t * @return file The read file.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\tabstract CmsFile readFile(A_CmsProject project, String filename)\n\t\tthrows CmsException;","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Reads a file header from the Cms.<BR/>\n\t * The reading excludes the filecontent.\n\t * \n\t * @param callingUser The user who wants to use this method.\n\t * @param project The project in which the resource will be used.\n\t * @param folder The complete path to the folder from which the file will be read.\n\t * @param filename The name of the file to be read.\n\t * \n\t * @return file The read file.\n\t * \n\t * @exception CmsException will be thrown, if the file couldn't be read. \n\t * The CmsException will also be thrown, if the user has not the rights \n\t * for this resource.\n\t */\n\tabstract A_CmsResource readFileHeader(String project, String folder, \n\t\t\t\t\t\t\t\t\t\tString filename)\n\t\tthrows CmsException;","id":36955,"modified_method":"/**\n\t * Reads a file header from the Cms.<BR/>\n\t * The reading excludes the filecontent.\n\t * \n\t * @param callingUser The user who wants to use this method.\n\t * @param project The project in which the resource will be used.\n\t * @param filename The complete name of the new file (including pathinformation).\n\t * \n\t * @return file The read file.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\tabstract A_CmsResource readFileHeader(A_CmsProject project, String filename)\n\t\tthrows CmsException;","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns all ResourceTypes in a hashtable. The ResourceType-name is the\n\t * key into this hashtable.\n\t * \n\t * @return a hashtable with all possible ResourceTypes.\n\t */\n\tabstract public Hashtable getResourceTypes();","id":36956,"modified_method":"/**\n\t * Returns the type of this resource-type.\n\t * \n\t * @return the type of this resource-type.\n\t */\n\tabstract int getResourceType();","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns the launcher for this resource-type.<BR/>\n\t * The launcher will start the resource in its needed environment.\n\t * Possibly the resource will be processed bevore delivering.\n\t * \n\t * @return the launcher for this resource-type.\n\t */\n\tabstract public Class getLauncher();","id":36957,"modified_method":"/**\n\t * Returns the launcher type needed for this resource-type.\n\t * \n\t * @return the launcher type for this resource-type.\n\t */\n\tabstract int getLauncherType();","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a group object.<P/>\n\t * \n\t * @param groupname The name of the group that is to be read.\n\t * @return Group.\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\n     A_CmsGroup readGroup(String groupname)\n         throws CmsException {\n  \n         A_CmsGroup group=null;\n   \n         try{\n             // read the group from the database\n             m_statementGroupRead.setString(1,groupname);\n             ResultSet res = m_statementGroupRead.executeQuery();\n             // create new Cms group object\n\t\t\t if(res.next()) {\n                group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));                                \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return group;\n     }","id":36958,"modified_method":"/**\n\t * Returns a group object.<P/>\n\t * \n\t * @param groupname The name of the group that is to be read.\n\t * @return Group.\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\n     A_CmsGroup readGroup(String groupname)\n         throws CmsException {\n  \n         A_CmsGroup group=null;\n         ResultSet res = null;\n   \n         try{ \n             synchronized (m_statementGroupRead) {\n                // read the group from the database\n                m_statementGroupRead.setString(1,groupname);\n                res = m_statementGroupRead.executeQuery();\n             }\n             // create new Cms group object\n\t\t\t if(res.next()) {\n                group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));                                \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return group;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a group object.<P/>\n\t * \n\t * @param groupname The id of the group that is to be read.\n\t * @return Group.\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\n     A_CmsGroup readGroup(int id)\n         throws CmsException {\n  \n         A_CmsGroup group=null;\n   \n         try{\n             // read the group from the database\n             m_statementGroupReadId.setInt(1,id);\n             ResultSet res = m_statementGroupReadId.executeQuery();\n             // create new Cms group object\n\t\t\t if(res.next()) {\n                group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));                                \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return group;\n     }","id":36959,"modified_method":"/**\n\t * Returns a group object.<P/>\n\t * \n\t * @param groupname The id of the group that is to be read.\n\t * @return Group.\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\n     A_CmsGroup readGroup(int id)\n         throws CmsException {\n  \n         A_CmsGroup group=null;\n         ResultSet res = null;\n   \n         try{\n             synchronized(m_statementGroupReadId) {\n                 // read the group from the database\n                m_statementGroupReadId.setInt(1,id);\n                res = m_statementGroupReadId.executeQuery();\n             }\n             // create new Cms group object\n\t\t\t if(res.next()) {\n                group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));                                \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return group;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Writes an already existing group in the Cms.<BR/>\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param group The group that should be written to the Cms.\n\t * @exception CmsException  Throws CmsException if operation was not succesfull.\n\t */\t\n\t void writeGroup(A_CmsGroup group)\n         throws CmsException {\n         try {\n            if (group != null){\n                m_statementGroupWrite.setString(1,group.getDescription());\n                m_statementGroupWrite.setInt(2,group.getFlags());\n                m_statementGroupWrite.setInt(3,group.getId());\n                m_statementGroupWrite.executeUpdate();  \n            } else {\n                throw new CmsException(CmsException.C_NO_GROUP);\t\n            }\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","id":36960,"modified_method":"/**\n\t * Writes an already existing group in the Cms.<BR/>\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param group The group that should be written to the Cms.\n\t * @exception CmsException  Throws CmsException if operation was not succesfull.\n\t */\t\n\t void writeGroup(A_CmsGroup group)\n         throws CmsException {\n         try {\n            if (group != null){\n                synchronized (m_statementGroupWrite) {\n                    m_statementGroupWrite.setString(1,group.getDescription());\n                    m_statementGroupWrite.setInt(2,group.getFlags());\n                    m_statementGroupWrite.setInt(3,group.getId());\n                    m_statementGroupWrite.executeUpdate();  \n                }\n            } else {\n                throw new CmsException(CmsException.C_NO_GROUP);\t\n            }\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns all child groups of a groups<P/>\n\t * \n\t * \n\t * @param groupname The name of the group.\n\t * @return users A Vector of all child groups or null.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getChild(String groupname) \n      throws CmsException {\n         \n         Vector childs = new Vector();\n         A_CmsGroup group;\n         A_CmsGroup parent;\n         \n         try {\n             // get parent group\n             parent=readGroup(groupname);\n            // parent group exists, so get all childs\n            if (parent != null) {\n                m_statementGroupChilds.setInt(1,parent.getId());\n                ResultSet res = m_statementGroupChilds.executeQuery();\n                // create new Cms group objects\n\t\t    \twhile ( res.next() ) {\n                    group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                       res.getInt(C_PARENT_GROUP_ID),\n                                       res.getString(C_GROUP_NAME),\n                                       res.getString(C_GROUP_DESCRIPTION),\n                                       res.getInt(C_GROUP_FLAGS)); \n                    childs.addElement(group);\n                }\n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         //check if the child vector has no elements, set it to null.\n         if (childs.size() == 0) {\n             childs=null;\n         }\n         return childs;\n     }","id":36961,"modified_method":"/**\n\t * Returns all child groups of a groups<P/>\n\t * \n\t * \n\t * @param groupname The name of the group.\n\t * @return users A Vector of all child groups or null.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getChild(String groupname) \n      throws CmsException {\n         \n         Vector childs = new Vector();\n         A_CmsGroup group;\n         A_CmsGroup parent;\n         ResultSet res = null;\n         \n         try {\n             // get parent group\n             parent=readGroup(groupname);\n            // parent group exists, so get all childs\n            if (parent != null) {\n                synchronized (m_statementGroupChilds) {\n                    m_statementGroupChilds.setInt(1,parent.getId());\n                    res = m_statementGroupChilds.executeQuery();\n                }\n                // create new Cms group objects\n\t\t    \twhile ( res.next() ) {\n                    group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                       res.getInt(C_PARENT_GROUP_ID),\n                                       res.getString(C_GROUP_NAME),\n                                       res.getString(C_GROUP_DESCRIPTION),\n                                       res.getInt(C_GROUP_FLAGS)); \n                    childs.addElement(group);\n                }\n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         //check if the child vector has no elements, set it to null.\n         if (childs.size() == 0) {\n             childs=null;\n         }\n         return childs;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Add a new group to the Cms.<BR/>\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param name The name of the new group.\n\t * @param description The description for the new group.\n\t * @int flags The flags for the new group.\n\t * @param name The name of the parent group (or null).\n\t *\n\t * @return Group\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\t\n\t A_CmsGroup addGroup(String name, String description, int flags,String parent)\n         throws CmsException {\n         \n         int id=C_UNKNOWN_ID;\n         int parentId=C_UNKNOWN_ID;\n         A_CmsGroup group=null;\n        \n         try {\n       \n            // get the id of the parent group if nescessary\n            if (parent != null) {\n                parentId=readGroup(parent).getId();\n            }\n               \n            // write new group to the database\n            m_statementGroupCreate.setInt(1,0);\n            m_statementGroupCreate.setInt(2,parentId);\n            m_statementGroupCreate.setString(3,name);\n            m_statementGroupCreate.setString(4,description);\n            m_statementGroupCreate.setInt(5,flags);\n            m_statementGroupCreate.executeUpdate();\n            \n            // create the user group by reading it from the database.\n            // this is nescessary to get the group id which is generated in the\n            // database.\n            group=readGroup(name);\n         } catch (SQLException e){\n                 throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n  \t\t}\n         return group;\n     }","id":36962,"modified_method":"/**\n\t * Add a new group to the Cms.<BR/>\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param name The name of the new group.\n\t * @param description The description for the new group.\n\t * @int flags The flags for the new group.\n\t * @param name The name of the parent group (or null).\n\t *\n\t * @return Group\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\t\n\t A_CmsGroup addGroup(String name, String description, int flags,String parent)\n         throws CmsException {\n         \n         int id=C_UNKNOWN_ID;\n         int parentId=C_UNKNOWN_ID;\n         A_CmsGroup group=null;\n        \n         try {\n       \n            // get the id of the parent group if nescessary\n            if (parent != null) {\n                parentId=readGroup(parent).getId();\n            }\n            synchronized (m_statementGroupCreate){\n                // write new group to the database\n                m_statementGroupCreate.setInt(1,0);\n                m_statementGroupCreate.setInt(2,parentId);\n                m_statementGroupCreate.setString(3,name);\n                m_statementGroupCreate.setString(4,description);\n                m_statementGroupCreate.setInt(5,flags);\n                m_statementGroupCreate.executeUpdate();\n            }\n            \n            // create the user group by reading it from the database.\n            // this is nescessary to get the group id which is generated in the\n            // database.\n            group=readGroup(name);\n         } catch (SQLException e){\n                 throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n  \t\t}\n         return group;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Delete a group from the Cms.<BR/>\n\t * Only groups that contain no subgroups can be deleted.\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param delgroup The name of the group that is to be deleted.\n\t * @exception CmsException  Throws CmsException if operation was not succesfull.\n\t */\t\n\t void deleteGroup(String delgroup)\n         throws CmsException {\n         try {\n            m_statementGroupDelete.setString(1,delgroup);\n            m_statementGroupDelete.executeUpdate();\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","id":36963,"modified_method":"/**\n\t * Delete a group from the Cms.<BR/>\n\t * Only groups that contain no subgroups can be deleted.\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param delgroup The name of the group that is to be deleted.\n\t * @exception CmsException  Throws CmsException if operation was not succesfull.\n\t */\t\n\t void deleteGroup(String delgroup)\n         throws CmsException {\n         try {\n             synchronized (m_statementGroupDelete) {\n                m_statementGroupDelete.setString(1,delgroup);\n                m_statementGroupDelete.executeUpdate();\n             }\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns all groups<P/>\n\t * \n\t * @return users A Vector of all existing groups.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getGroups() \n      throws CmsException {\n         Vector groups = new Vector();\n         A_CmsGroup group=null;\n         \n         try {\n            //  get all groups\n            ResultSet res = m_statementGroupGetAll.executeQuery();\n            // create new Cms group objects\n\t\t    while ( res.next() ) {\n                    group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                       res.getInt(C_PARENT_GROUP_ID),\n                                       res.getString(C_GROUP_NAME),\n                                       res.getString(C_GROUP_DESCRIPTION),\n                                       res.getInt(C_GROUP_FLAGS)); \n                    groups.addElement(group);\n             }\n             \n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n      return groups;\n     }","id":36964,"modified_method":"/**\n\t * Returns all groups<P/>\n\t * \n\t * @return users A Vector of all existing groups.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getGroups() \n      throws CmsException {\n         Vector groups = new Vector();\n         A_CmsGroup group=null;\n         ResultSet res = null;\n         \n         try {\n            //  get all groups\n             synchronized (m_statementGroupGetAll) {\n                res = m_statementGroupGetAll.executeQuery();\n             }\n            // create new Cms group objects\n\t\t    while ( res.next() ) {\n                    group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                       res.getInt(C_PARENT_GROUP_ID),\n                                       res.getString(C_GROUP_NAME),\n                                       res.getString(C_GROUP_DESCRIPTION),\n                                       res.getInt(C_GROUP_FLAGS)); \n                    groups.addElement(group);\n             }\n             \n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n      return groups;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a list of users in a group.<P/>\n\t * \n\t * @param groupId The id of the group to list users from.\n\t * @return Vector of user id's.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n\t Vector getUsersOfGroup(int groupId)\n         throws CmsException {\n         \n         Vector userid=new Vector();\n         try {\n            //  get all all users id's of this group.\n            m_statementGetUsersInGroup.setInt(1,groupId);\n            ResultSet res = m_statementGetUsersInGroup.executeQuery();\n            // create new Vector.\n\t\t    while ( res.next() ) {\n                  userid.addElement(new Integer(res.getInt(C_USER_ID)));\n             }\n  \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         \n         return userid;\n     }","id":36965,"modified_method":"/**\n\t * Returns a list of users in a group.<P/>\n\t * \n\t * @param groupId The id of the group to list users from.\n\t * @return Vector of user id's.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n\t Vector getUsersOfGroup(int groupId)\n         throws CmsException {\n         \n         Vector userid=new Vector();\n         ResultSet res = null;\n         try {\n             synchronized (m_statementGetUsersInGroup) {\n                //  get all all users id's of this group.\n                m_statementGetUsersInGroup.setInt(1,groupId);\n                res = m_statementGetUsersInGroup.executeQuery();\n             }\n            // create new Vector.\n\t\t    while ( res.next() ) {\n                  userid.addElement(new Integer(res.getInt(C_USER_ID)));\n             }\n  \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         \n         return userid;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Adds a user to a group.<BR/>\n     *\n\t * Only the admin can do this.<P/>\n\t * \n\t * @param userid The id of the user that is to be added to the group.\n\t * @param groupid The id of the group.\n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\t\n\tvoid addUserToGroup(int userid, int groupid)\n        throws CmsException {\n        \n        // check if user is already in group\n        if (!userInGroup(userid,groupid)) {\n            // if not, add this user to the group\n            try {\n                    \n                // write the new assingment to the database\n                m_statementAddUserToGroup.setInt(1,groupid);\n                m_statementAddUserToGroup.setInt(2,userid);\n                //flag field is not used yet\n                m_statementAddUserToGroup.setInt(3,C_UNKNOWN_INT);\n                m_statementAddUserToGroup.executeUpdate();\n   \n             } catch (SQLException e){\n                 throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n          \n\t    \t}\n        }\n        \n    }","id":36966,"modified_method":"/**\n\t * Adds a user to a group.<BR/>\n     *\n\t * Only the admin can do this.<P/>\n\t * \n\t * @param userid The id of the user that is to be added to the group.\n\t * @param groupid The id of the group.\n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\t\n\tvoid addUserToGroup(int userid, int groupid)\n        throws CmsException {\n        \n        // check if user is already in group\n        if (!userInGroup(userid,groupid)) {\n            // if not, add this user to the group\n            try {\n                synchronized (m_statementAddUserToGroup) {    \n                    // write the new assingment to the database\n                    m_statementAddUserToGroup.setInt(1,groupid);\n                    m_statementAddUserToGroup.setInt(2,userid);\n                    //flag field is not used yet\n                    m_statementAddUserToGroup.setInt(3,C_UNKNOWN_INT);\n                    m_statementAddUserToGroup.executeUpdate();\n                }\n   \n             } catch (SQLException e){\n                 throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n          \n\t    \t}\n        }\n        \n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a list of groups of a user.<P/>\n\t * \n\t * @param userid The id of the user.\n\t * @return Vector of groups\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\tVector getGroupsOfUser(int userid)\n\t\tthrows CmsException {\n        A_CmsGroup group;\n        Vector groups=new Vector();\n         try {\n            //  get all all groups of the user\n            m_statementGetGroupsOfUser.setInt(1,userid);\n            ResultSet res = m_statementGetGroupsOfUser.executeQuery();\n            // create new Vector.\n\t\t    while ( res.next() ) {\n                 group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));   \n                 groups.addElement(group);\n             }\n  \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         \n        \n        \n        return groups;\n    }","id":36967,"modified_method":"/**\n\t * Returns a list of groups of a user.<P/>\n\t * \n\t * @param userid The id of the user.\n\t * @return Vector of groups\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\tVector getGroupsOfUser(int userid)\n\t\tthrows CmsException {\n        A_CmsGroup group;\n        Vector groups=new Vector();\n        ResultSet res = null;\n         try {\n             synchronized (m_statementGetGroupsOfUser) {\n                //  get all all groups of the user\n                m_statementGetGroupsOfUser.setInt(1,userid);\n                res = m_statementGetGroupsOfUser.executeQuery();\n             }\n            // create new Vector.\n\t\t    while ( res.next() ) {\n                 group=new CmsGroup(res.getInt(C_GROUP_ID),\n                                   res.getInt(C_PARENT_GROUP_ID),\n                                   res.getString(C_GROUP_NAME),\n                                   res.getString(C_GROUP_DESCRIPTION),\n                                   res.getInt(C_GROUP_FLAGS));   \n                 groups.addElement(group);\n             }\n  \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         \n        \n        \n        return groups;\n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Checks if a user is member of a group.<P/>\n\t *  \n\t * @param nameid The id of the user to check.\n\t * @param groupid The id of the group to check.\n\t * @return True or False\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t boolean userInGroup(int userid, int groupid)\n         throws CmsException {\n         boolean userInGroup=false;\n                     \n        try {\n            m_statementUserInGroup.setInt(1,groupid);\n            m_statementUserInGroup.setInt(2,userid);\n            ResultSet res = m_statementUserInGroup.executeQuery();\n            if (res.next()){        \n                userInGroup=true;\n            }                     \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}             \n         return userInGroup;\n     }","id":36968,"modified_method":"/**\n\t * Checks if a user is member of a group.<P/>\n\t *  \n\t * @param nameid The id of the user to check.\n\t * @param groupid The id of the group to check.\n\t * @return True or False\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t boolean userInGroup(int userid, int groupid)\n         throws CmsException {\n         boolean userInGroup=false;\n         ResultSet res=null;\n                     \n        try {\n            synchronized (m_statementUserInGroup) {\n                m_statementUserInGroup.setInt(1,groupid);\n                m_statementUserInGroup.setInt(2,userid);\n                res = m_statementUserInGroup.executeQuery();\n            }\n            if (res.next()){        \n                userInGroup=true;\n            }                     \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}             \n         return userInGroup;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Removes a user from a group.\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param userid The id of the user that is to be added to the group.\n\t * @param groupid The id of the group.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\t\n\t void removeUserFromGroup(int userid, int groupid)\n         throws CmsException {\n         try {\n            m_statementRemoveUserFromGroup.setInt(1,groupid);\n            m_statementRemoveUserFromGroup.setInt(2,userid);\n            m_statementRemoveUserFromGroup.executeUpdate();\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","id":36969,"modified_method":"/**\n\t * Removes a user from a group.\n\t * \n\t * Only the admin can do this.<P/>\n\t * \n\t * @param userid The id of the user that is to be added to the group.\n\t * @param groupid The id of the group.\n\t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\t\n\t void removeUserFromGroup(int userid, int groupid)\n         throws CmsException {\n         try {\n             synchronized (m_statementRemoveUserFromGroup) {\n                m_statementRemoveUserFromGroup.setInt(1,groupid);\n                m_statementRemoveUserFromGroup.setInt(2,userid);\n                m_statementRemoveUserFromGroup.executeUpdate();\n             }\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Deletes a serializable object from the propertys.\n\t * \n\t * @param name The name of the property.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tvoid deleteProperty(String name)\n        throws CmsException {\n        \n\t\ttry\t{\n             m_statementPropertyDelete.setString(1,name);\n             m_statementPropertyDelete.executeUpdate();\n\t\t\n\t\t}catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n    }","id":36970,"modified_method":"/**\n\t * Deletes a serializable object from the propertys.\n\t * \n\t * @param name The name of the property.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tvoid deleteProperty(String name)\n        throws CmsException {\n        \n\t\ttry\t{\n            synchronized (m_statementPropertyDelete) {\n                m_statementPropertyDelete.setString(1,name);\n                m_statementPropertyDelete.executeUpdate();\n            }           \n\t\t}catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Writes a serializable object to the propertys.\n\t * \n\t * @param name The name of the property.\n\t * @param object The property-object.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tSerializable writeProperty(String name, Serializable object)\n        throws CmsException {\n        \n        byte[] value=null;\n        \n        try\t{\t\t\t\n            // serialize the object\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();   \n    \n            m_statementPropertyUpdate.setBytes(1,value);\n            m_statementPropertyUpdate.setString(2,name);\n\t\t    m_statementPropertyUpdate.executeUpdate();\n\t\t\t\n        }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\n          return readProperty(name);\n    }","id":36971,"modified_method":"/**\n\t * Writes a serializable object to the propertys.\n\t * \n\t * @param name The name of the property.\n\t * @param object The property-object.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tSerializable writeProperty(String name, Serializable object)\n        throws CmsException {\n        \n        byte[] value=null;\n        \n        try\t{\t\t\t\n            // serialize the object\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();   \n            \n            synchronized (m_statementPropertyUpdate) {\n                m_statementPropertyUpdate.setBytes(1,value);\n                m_statementPropertyUpdate.setString(2,name);\n\t\t        m_statementPropertyUpdate.executeUpdate();\n            }\n\t\t\t\n        }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\n          return readProperty(name);\n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Reads a serializable object from the propertys.\n\t * \n\t * @param name The name of the property.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tSerializable readProperty(String name)\n        throws CmsException {\n        \n        Serializable property=null;\n        byte[] value;\n            \n        // create get the property data from the database\n    \ttry {\n            m_statementPropertyRead.setString(1,name);\n           \tResultSet res = m_statementPropertyRead.executeQuery();\n\t\t\t\n            if(res.next()) {\n\t\t\t\tvalue = res.getBytes(C_PROPERTY_VALUE);\n                // now deserialize the object\n                ByteArrayInputStream bin= new ByteArrayInputStream(value);\n                ObjectInputStream oin = new ObjectInputStream(bin);\n                property=(Serializable)oin.readObject();                \n\t\t\t}\t\n\t\t\t\n\t\t}\n\t\tcatch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\t\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\t    catch (ClassNotFoundException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\t\n        return property;\n    }","id":36972,"modified_method":"/**\n\t * Reads a serializable object from the propertys.\n\t * \n\t * @param name The name of the property.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tSerializable readProperty(String name)\n        throws CmsException {\n        \n        Serializable property=null;\n        byte[] value;\n        ResultSet res = null;\n            \n        // create get the property data from the database\n    \ttry {\n            synchronized (m_statementPropertyRead) {\n                m_statementPropertyRead.setString(1,name);\n           \t    res = m_statementPropertyRead.executeQuery();\n            }\n\t\t\t\n            if(res.next()) {\n\t\t\t\tvalue = res.getBytes(C_PROPERTY_VALUE);\n                // now deserialize the object\n                ByteArrayInputStream bin= new ByteArrayInputStream(value);\n                ObjectInputStream oin = new ObjectInputStream(bin);\n                property=(Serializable)oin.readObject();                \n\t\t\t}\t\n\t\t\t\n\t\t}\n\t\tcatch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\t\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\t    catch (ClassNotFoundException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\t\n        return property;\n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Creates a serializable object in the propertys.\n\t * \n\t * @param name The name of the property.\n\t * @param object The property-object.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t Serializable addProperty(String name, Serializable object)\n         throws CmsException {\n         \n        Serializable property=null;\n        byte[] value;\n        \n         try\t{\t\t\t\n            // serialize the object\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();\n            \n            // create the object\n            m_statementPropertyWrite.setString(1,name);\n            m_statementPropertyWrite.setBytes(2,value);\n            m_statementPropertyWrite.executeUpdate();\n        } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t} catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n       \n        return readProperty(name);\n     }","id":36973,"modified_method":"/**\n\t * Creates a serializable object in the propertys.\n\t * \n\t * @param name The name of the property.\n\t * @param object The property-object.\n\t * \n\t * @return object The property-object.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t Serializable addProperty(String name, Serializable object)\n         throws CmsException {\n         \n        Serializable property=null;\n        byte[] value;\n        \n         try\t{\t\t\t\n            // serialize the object\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();\n            \n            // create the object\n            synchronized (m_statementPropertyWrite) {\n                m_statementPropertyWrite.setString(1,name);\n                m_statementPropertyWrite.setBytes(2,value);\n                m_statementPropertyWrite.executeUpdate();\n            }\n        } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t} catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n       \n        return readProperty(name);\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Deletes a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * @param id The id of the user.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t void deleteUserInformation(int id)\n         throws CmsException {\n               \n\t\ttry\t{\t\t\t\n            m_statementUserinfoDelete.setInt(1,id);\n          \tm_statementUserinfoDelete.executeUpdate();\n\t\t}catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         \n     }","id":36974,"modified_method":"/**\n\t * Deletes a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * @param id The id of the user.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t void deleteUserInformation(int id)\n         throws CmsException {\n               \n\t\ttry\t{\t\t\t\n            synchronized(m_statementUserinfoDelete) {\n                m_statementUserinfoDelete.setInt(1,id);\n          \t    m_statementUserinfoDelete.executeUpdate();  \n            }\n\t\t}catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         \n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Writes a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * The hashtable is serialized and written into the databse.\n\t * \n\t * @param id The id of the user.\n\t * @param infos The additional user information.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t void writeUserInformation(int id , Hashtable infos)\n         throws CmsException {\n         \n        byte[] value=null;\n        try\t{\t\t\t\n            // serialize the hashtable\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(infos);\n            oout.close();\n            value=bout.toByteArray();\n            m_statementUserinfoUpdate.setBytes(1,value);\n            m_statementUserinfoUpdate.setInt(2,id);\n      \t\tm_statementUserinfoUpdate.executeUpdate();\n     \n         }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n   \n     }","id":36975,"modified_method":"/**\n\t * Writes a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * The hashtable is serialized and written into the databse.\n\t * \n\t * @param id The id of the user.\n\t * @param infos The additional user information.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\t void writeUserInformation(int id , Hashtable infos)\n         throws CmsException {\n         \n        byte[] value=null;\n        try\t{\t\t\t\n            // serialize the hashtable\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(infos);\n            oout.close();\n            value=bout.toByteArray();\n            \n            synchronized (m_statementUserinfoUpdate) {\n                m_statementUserinfoUpdate.setBytes(1,value);\n                m_statementUserinfoUpdate.setInt(2,id);\n      \t\t    m_statementUserinfoUpdate.executeUpdate();\n            }\n     \n         }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n   \n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Creates a new hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * @param id The id of the user.\n\t * @param object The hashtable including the user information\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tvoid addUserInformation(int id, Hashtable object)\n        throws  CmsException {\n        byte[] value=null;\n        try\t{\t\t\t\n            // serialize the hashtable\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();\n            // write data to database             \n            m_statementUserinfoWrite.setInt(1,id);\n            m_statementUserinfoWrite.setBytes(2,value);\n            m_statementUserinfoWrite.executeUpdate();    \n        \n         }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n     \n    }","id":36976,"modified_method":"/**\n\t * Creates a new hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * @param id The id of the user.\n\t * @param object The hashtable including the user information\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tvoid addUserInformation(int id, Hashtable object)\n        throws  CmsException {\n        byte[] value=null;\n        try\t{\t\t\t\n            // serialize the hashtable\n            ByteArrayOutputStream bout= new ByteArrayOutputStream();            \n            ObjectOutputStream oout=new ObjectOutputStream(bout);\n            oout.writeObject(object);\n            oout.close();\n            value=bout.toByteArray();\n            // write data to database     \n            synchronized(m_statementUserinfoWrite) {\n                m_statementUserinfoWrite.setInt(1,id);\n                m_statementUserinfoWrite.setBytes(2,value);\n                m_statementUserinfoWrite.executeUpdate();    \n            }\n        \n         }\n        catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n     \n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Reads a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * The hashtable is read from the database and deserialized.\n\t * \n\t * @param id The id of the user.\n\t * \n\t * @return object The additional user information.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tHashtable readUserInformation(int id)\n        throws CmsException {\n        \n        Hashtable info=null;\n        byte[] value;\n       \n        // get the additional user information data from the database\n    \ttry {\n\t\t    m_statementUserinfoRead.setInt(1,id);\n           \tResultSet res = m_statementUserinfoRead.executeQuery();\n\t        if(res.next()) {\n                value = res.getBytes(C_USER_INFO);\n                 // now deserialize the object\n                ByteArrayInputStream bin= new ByteArrayInputStream(value);\n                ObjectInputStream oin = new ObjectInputStream(bin);\n                info=(Hashtable)oin.readObject();                \n\t\t\t}\t\n\t\t\t\n\t\t}\n\t\tcatch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\t\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\t    catch (ClassNotFoundException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\t\n  \n        return info;\n    }","id":36977,"modified_method":"/**\n\t * Reads a hashtable containing additional user information to the user \n\t * information database.\n\t * \n\t * The hashtable is read from the database and deserialized.\n\t * \n\t * @param id The id of the user.\n\t * \n\t * @return object The additional user information.\n\t * \n\t * @exception CmsException Throws CmsException if something goes wrong.\n\t */\n\tHashtable readUserInformation(int id)\n        throws CmsException {\n        \n        Hashtable info=null;\n        byte[] value;\n        ResultSet res = null;\n       \n        // get the additional user information data from the database\n    \ttry {\n            synchronized(m_statementUserinfoRead) {\n\t\t        m_statementUserinfoRead.setInt(1,id);\n           \t    res = m_statementUserinfoRead.executeQuery();\n            }\n\t        if(res.next()) {\n                value = res.getBytes(C_USER_INFO);\n                 // now deserialize the object\n                ByteArrayInputStream bin= new ByteArrayInputStream(value);\n                ObjectInputStream oin = new ObjectInputStream(bin);\n                info=(Hashtable)oin.readObject();                \n\t\t\t}\t\n\t\t\t\n\t\t}\n\t\tcatch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\t\n        catch (IOException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\n\t    catch (ClassNotFoundException e){\n            throw new CmsException(CmsException. C_SERIALIZATION, e);\t\t\t\n\t\t}\t\n  \n        return info;\n    }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a user object.<P/>\n\t * \n\t * @param username The name of the user that is to be read.\n\t * @return User\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t A_CmsUser readUser(String username)\n         throws CmsException {\n      \n         A_CmsUser user=null;\n   \n         try{\n             // read the user from the database\n             m_statementUserRead.setString(1,username);\n             ResultSet res = m_statementUserRead.executeQuery();\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n  \n     }","id":36978,"modified_method":"/**\n\t * Returns a user object.<P/>\n\t * \n\t * @param username The name of the user that is to be read.\n\t * @return User\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t A_CmsUser readUser(String username)\n         throws CmsException {\n      \n         A_CmsUser user=null;\n         ResultSet res = null;\n   \n         try{\n             // read the user from the database\n             synchronized (m_statementUserRead) {\n                m_statementUserRead.setString(1,username);\n                res = m_statementUserRead.executeQuery();\n             }\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n  \n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a user object.<P/>\n\t * \n\t * @param userid The id of the user that is to be read.\n\t * @return User\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t A_CmsUser readUser(int userid)\n         throws CmsException {\n      \n         A_CmsUser user=null;\n         \n         try{\n             // read the user from the database\n             m_statementUserReadId.setInt(1,userid);\n             ResultSet res = m_statementUserReadId.executeQuery();\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n  \n     }","id":36979,"modified_method":"/**\n\t * Returns a user object.<P/>\n\t * \n\t * @param userid The id of the user that is to be read.\n\t * @return User\n\t * @exception CmsException Throws CmsException if operation was not succesful\n\t */\n\t A_CmsUser readUser(int userid)\n         throws CmsException {\n      \n         A_CmsUser user=null;\n         ResultSet res = null;\n         \n         try{\n             // read the user from the database\n             synchronized(m_statementUserReadId) {\n                m_statementUserReadId.setInt(1,userid);\n                res = m_statementUserReadId.executeQuery();\n             }\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n  \n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/** \n\t * Sets the password for a user.\n\t * \n\t * Only a adminstrator or the curretuser can do this.<P/>\n\t * \n\t * @param username The name of the user.\n\t * @param newPassword The new password.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t void setPassword(String username, String newPassword)\n         throws CmsException {\n          try {     \n            // write new password\n            m_statementSetPwd.setString(1,newPassword);    \n            m_statementSetPwd.setString(2,username);\n            m_statementSetPwd.executeUpdate();\n            \n         } catch (SQLException e){\n             throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n          }\n     }","id":36980,"modified_method":"/** \n\t * Sets the password for a user.\n\t * \n\t * Only a adminstrator or the curretuser can do this.<P/>\n\t * \n\t * @param username The name of the user.\n\t * @param newPassword The new password.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t void setPassword(String username, String newPassword)\n         throws CmsException {\n          try {     \n              synchronized(m_statementSetPwd) {\n                // write new password\n                m_statementSetPwd.setString(1,newPassword);    \n                m_statementSetPwd.setString(2,username);\n                m_statementSetPwd.executeUpdate();\n              }\n            \n         } catch (SQLException e){\n             throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n          }\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns a user object if the password for the user is correct.<P/>\n\t * \n\t * @param username The username of the user that is to be read.\n\t * @param password The password of the user that is to be read.\n\t * @return User\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\t\t\n\t A_CmsUser readUser(String username, String password)\n         throws CmsException {\n         \n         A_CmsUser user=null;\n   \n         try{\n             // read the user from the database\n             m_statementUserReadPwd.setString(1,username);\n             m_statementUserReadPwd.setString(2,password);\n             ResultSet res = m_statementUserReadPwd.executeQuery();\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n     }","id":36981,"modified_method":"/**\n\t * Returns a user object if the password for the user is correct.<P/>\n\t * \n\t * @param username The username of the user that is to be read.\n\t * @param password The password of the user that is to be read.\n\t * @return User\n\t * \n\t * @exception CmsException  Throws CmsException if operation was not succesful\n\t */\t\t\n\t A_CmsUser readUser(String username, String password)\n         throws CmsException {\n         \n         A_CmsUser user=null;\n         ResultSet res=null;\n   \n         try{\n             // read the user from the database\n             synchronized (m_statementUserReadPwd) {\n                m_statementUserReadPwd.setString(1,username);\n                m_statementUserReadPwd.setString(2,password);\n                res = m_statementUserReadPwd.executeQuery();\n             }\n             // create new Cms user object\n\t\t\t if(res.next()) {\n                user=new CmsUser(res.getInt(C_USER_ID),\n                                 res.getString(C_USER_NAME),\n                                 res.getString(C_USER_DESCRIPTION));                                                        \n             }\n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n         return user;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/** \n\t * Deletes a user from the Cms.\n\t * \n\t * Only a adminstrator can do this.<P/>\n\t * \n\t * @param name The name of the user to be deleted.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t void deleteUser(String username)\n         throws CmsException {\n          try {\n            m_statementUserDelete.setString(1,username);\n            m_statementUserDelete.executeUpdate();\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n \n     }","id":36982,"modified_method":"/** \n\t * Deletes a user from the Cms.\n\t * \n\t * Only a adminstrator can do this.<P/>\n\t * \n\t * @param name The name of the user to be deleted.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t void deleteUser(String username)\n         throws CmsException {\n          try {\n              synchronized(m_statementUserDelete) {\n                m_statementUserDelete.setString(1,username);\n                m_statementUserDelete.executeUpdate();\n              }\n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n\t\t}\n \n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Returns all users<P/>\n\t * \n\t * @return users A Vector of all existing users.\n \t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getUsers()\n     throws CmsException {\n         Vector users=new Vector();\n         A_CmsUser user=null;\n         \n         try {\n            //  get all users\n            ResultSet res = m_statementUserGetAll.executeQuery();\n            // create new Cms group objects\n\t\t    while ( res.next() ) {\n                    user=new CmsUser(res.getInt(C_USER_ID),\n                                     res.getString(C_USER_NAME),\n                                     res.getString(C_USER_DESCRIPTION));\n                    users.addElement(user);\n             }\n             \n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         return users;\n     }","id":36983,"modified_method":"/**\n\t * Returns all users<P/>\n\t * \n\t * @return users A Vector of all existing users.\n \t * @exception CmsException Throws CmsException if operation was not succesful.\n\t */\n     Vector getUsers()\n     throws CmsException {\n         Vector users=new Vector();\n         A_CmsUser user=null;\n         ResultSet res =null;\n         \n         try {\n            //  get all users\n            synchronized(m_statementUserGetAll) {\n                res = m_statementUserGetAll.executeQuery();\n            }\n            // create new Cms group objects\n\t\t    while ( res.next() ) {\n                    user=new CmsUser(res.getInt(C_USER_ID),\n                                     res.getString(C_USER_NAME),\n                                     res.getString(C_USER_DESCRIPTION));\n                    users.addElement(user);\n             }\n             \n       \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\n         }\n         return users;\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/** \n\t * Adds a user to the Cms.\n\t * \n\t * Only a adminstrator can add users to the cms.<P/>\n\t * \n\t * @param name The new name for the user.\n\t * @param password The new password for the user.\n\t * @param description The description for the user.\n\t * \n\t * @return user The added user will be returned.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t A_CmsUser addUser(String name, String password, \n\t\t\t\t\t   String description) \t\t\t\t\n        throws CmsException {\n\n         A_CmsUser user=null;\n                 \n         try {     \n            // write new user to the database\n            m_statementUserWrite.setInt(1,0);\n            m_statementUserWrite.setString(2,name);\n            m_statementUserWrite.setString(3,password);\n            m_statementUserWrite.setString(4,description);\n            m_statementUserWrite.executeUpdate();\n            \n            // read the new user object\n            user=readUser(name);\n            \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n         }\n         return user;\n     }","id":36984,"modified_method":"/** \n\t * Adds a user to the Cms.\n\t * \n\t * Only a adminstrator can add users to the cms.<P/>\n\t * \n\t * @param name The new name for the user.\n\t * @param password The new password for the user.\n\t * @param description The description for the user.\n\t * \n\t * @return user The added user will be returned.\n\t * \n\t * @exception CmsException Throws CmsException if operation was not succesfull.\n\t */\n\t A_CmsUser addUser(String name, String password, \n\t\t\t\t\t   String description) \t\t\t\t\n        throws CmsException {\n\n                        \n         try {     \n            // write new user to the database\n             synchronized (m_statementUserWrite) {\n                m_statementUserWrite.setInt(1,0);\n                m_statementUserWrite.setString(2,name);\n                m_statementUserWrite.setString(3,password);\n                m_statementUserWrite.setString(4,description);\n                m_statementUserWrite.executeUpdate();\n             }\n          \n            \n         } catch (SQLException e){\n            throw new CmsException(e.getMessage(),CmsException.C_SQL_ERROR, e);\t\t\t\n         }\n         return readUser(name);\n     }","commit_id":"1dab43779a6d9b732dfcba10493408926c461e64","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * @see org.opencms.workplace.tools.A_CmsToolHandler#isVisible(org.opencms.workplace.CmsWorkplace)\n     */\n    @Override\n    public boolean isVisible(CmsWorkplace wp) {\n\n        CmsObject cms = wp.getCms();\n        if (!isVisible(cms)) {\n            return false;\n        }\n\n        String ouFqn = CmsRequestUtil.getNotEmptyDecodedParameter(\n            wp.getJsp().getRequest(),\n            A_CmsOrgUnitDialog.PARAM_OUFQN);\n        if (ouFqn == null) {\n            ouFqn = cms.getRequestContext().getOuFqn();\n        }\n        String parentOu = CmsOrganizationalUnit.getParentFqn(ouFqn);\n        try {\n            m_webuserOu = OpenCms.getOrgUnitManager().readOrganizationalUnit(cms, ouFqn).hasFlagWebuser();\n        } catch (CmsException e) {\n            // ignore\n            if (LOG.isErrorEnabled()) {\n                LOG.error(e.getLocalizedMessage(), e);\n            }\n        }\n\n        if (getLink().equals(getPath(OVERVIEW_FILE))) {\n            if (parentOu != null) {\n                return !OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu));\n            }\n            return true;\n        } else if (getLink().equals(getPath(OU_EDIT_FILE))) {\n            if (parentOu != null) {\n                return (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)\n                    && OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu)));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(NEW_FILE))) {\n            if (m_webuserOu) {\n                return false;\n            }\n            return OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR);\n        } else if (getLink().equals(getPath(PARENT_FILE))) {\n            if (parentOu != null) {\n                return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER.forOrgUnit(parentOu));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(DELETE_FILE))) {\n            if (parentOu != null) {\n                return (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)\n                    && OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu)));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(ASSIGN_FILE))) {\n            try {\n                List<CmsOrganizationalUnit> orgUnits = OpenCms.getRoleManager().getOrgUnitsForRole(\n                    cms,\n                    CmsRole.ACCOUNT_MANAGER.forOrgUnit(\"\"),\n                    true);\n                if (orgUnits.size() == 1) {\n                    return false;\n                }\n                return !m_webuserOu;\n            } catch (CmsException e) {\n                // ignore\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n        } else if (getLink().equals(getPath(OUROLES_FILE))) {\n            return !m_webuserOu;\n        } else if (getLink().equals(getPath(SWITCHUSER_FILE))) {\n            boolean visible = OpenCms.getRoleManager().hasRole(cms, CmsRole.ROOT_ADMIN);\n            CmsUUID userId = new CmsUUID(\n                CmsRequestUtil.getNotEmptyDecodedParameter(wp.getJsp().getRequest(), A_CmsEditUserDialog.PARAM_USERID));\n            try {\n                visible &= OpenCms.getRoleManager().hasRole(\n                    cms,\n                    cms.readUser(userId).getName(),\n                    CmsRole.WORKPLACE_USER);\n            } catch (CmsException e) {\n                // should never happen\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n            return visible;\n        } else if (getPath().indexOf(\"/users/edit/\") > -1) {\n            // check if the current user is the root administrator\n            if (OpenCms.getRoleManager().hasRole(cms, CmsRole.ROOT_ADMIN) && !PATH_UNLOCK.equals(getPath())) {\n                return true;\n            }\n\n            if (PATH_KILL_SESSIONS.equals(getPath())) {\n                return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER);\n            }\n            CmsUUID userId = new CmsUUID(\n                CmsRequestUtil.getNotEmptyDecodedParameter(wp.getJsp().getRequest(), A_CmsEditUserDialog.PARAM_USERID));\n            try {\n                CmsUser user = cms.readUser(userId);\n                if (PATH_UNLOCK.equals(getPath())) {\n                    return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER)\n                        && OpenCms.getLoginManager().isUserLocked(user);\n                }\n\n                // check if the user to change is root administrator\n                if (OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.ROOT_ADMIN)) {\n                    return false;\n                }\n                // check if the current user is an administrator\n                if (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)) {\n                    return true;\n                }\n                // check if the user to change is an administrator\n                return !OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.ADMINISTRATOR);\n            } catch (CmsException e) {\n                // should never happen\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n            return false;\n        } else if (getLink().equals(getPath(USERROLE_FILE)) || getLink().equals(getPath(GROUP_USERS_FILE))) {\n            String userId = CmsRequestUtil.getNotEmptyDecodedParameter(\n                wp.getJsp().getRequest(),\n                A_CmsEditUserDialog.PARAM_USERID);\n            if (userId == null) {\n                return false;\n            }\n            try {\n                return !cms.readUser(new CmsUUID(userId)).isWebuser();\n            } catch (Exception e) {\n                // ignore\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n        } else if (getLink().equals(getPath(ACCMAN_FILE))) {\n            return m_webuserOu;\n        }\n        return true;\n    }","id":36985,"modified_method":"/**\n     * @see org.opencms.workplace.tools.A_CmsToolHandler#isVisible(org.opencms.workplace.CmsWorkplace)\n     */\n    @Override\n    public boolean isVisible(CmsWorkplace wp) {\n\n        CmsObject cms = wp.getCms();\n        if (!isVisible(cms)) {\n            return false;\n        }\n\n        String ouFqn = CmsRequestUtil.getNotEmptyDecodedParameter(\n            wp.getJsp().getRequest(),\n            A_CmsOrgUnitDialog.PARAM_OUFQN);\n        if (ouFqn == null) {\n            ouFqn = cms.getRequestContext().getOuFqn();\n        }\n        String parentOu = CmsOrganizationalUnit.getParentFqn(ouFqn);\n        try {\n            m_webuserOu = OpenCms.getOrgUnitManager().readOrganizationalUnit(cms, ouFqn).hasFlagWebuser();\n        } catch (CmsException e) {\n            // ignore\n            if (LOG.isErrorEnabled()) {\n                LOG.error(e.getLocalizedMessage(), e);\n            }\n        }\n\n        if (getLink().equals(getPath(OVERVIEW_FILE))) {\n            if (parentOu != null) {\n                return !OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu));\n            }\n            return true;\n        } else if (getLink().equals(getPath(OU_EDIT_FILE))) {\n            if (parentOu != null) {\n                return (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)\n                    && OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu)));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(NEW_FILE))) {\n            if (m_webuserOu) {\n                return false;\n            }\n            return OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR);\n        } else if (getLink().equals(getPath(PARENT_FILE))) {\n            if (parentOu != null) {\n                return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER.forOrgUnit(parentOu));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(DELETE_FILE))) {\n            if (parentOu != null) {\n                return (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)\n                    && OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR.forOrgUnit(parentOu)));\n            } else {\n                return false;\n            }\n        } else if (getLink().equals(getPath(ASSIGN_FILE))) {\n            try {\n                List<CmsOrganizationalUnit> orgUnits = OpenCms.getRoleManager().getOrgUnitsForRole(\n                    cms,\n                    CmsRole.ACCOUNT_MANAGER.forOrgUnit(\"\"),\n                    true);\n                if (orgUnits.size() == 1) {\n                    return false;\n                }\n                return !m_webuserOu;\n            } catch (CmsException e) {\n                // ignore\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n        } else if (getLink().equals(getPath(OUROLES_FILE))) {\n            return !m_webuserOu;\n        } else if (getLink().equals(getPath(SWITCHUSER_FILE))) {\n            boolean visible = OpenCms.getRoleManager().hasRole(cms, CmsRole.ROOT_ADMIN);\n            CmsUUID userId = new CmsUUID(\n                CmsRequestUtil.getNotEmptyDecodedParameter(wp.getJsp().getRequest(), A_CmsEditUserDialog.PARAM_USERID));\n            try {\n                visible &= OpenCms.getRoleManager().hasRole(\n                    cms,\n                    cms.readUser(userId).getName(),\n                    CmsRole.ELEMENT_AUTHOR);\n            } catch (CmsException e) {\n                // should never happen\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n            return visible;\n        } else if (getPath().indexOf(\"/users/edit/\") > -1) {\n            // check if the current user is the root administrator\n            if (OpenCms.getRoleManager().hasRole(cms, CmsRole.ROOT_ADMIN) && !PATH_UNLOCK.equals(getPath())) {\n                return true;\n            }\n\n            if (PATH_KILL_SESSIONS.equals(getPath())) {\n                return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER);\n            }\n            CmsUUID userId = new CmsUUID(\n                CmsRequestUtil.getNotEmptyDecodedParameter(wp.getJsp().getRequest(), A_CmsEditUserDialog.PARAM_USERID));\n            try {\n                CmsUser user = cms.readUser(userId);\n                if (PATH_UNLOCK.equals(getPath())) {\n                    return OpenCms.getRoleManager().hasRole(cms, CmsRole.ACCOUNT_MANAGER)\n                        && OpenCms.getLoginManager().isUserLocked(user);\n                }\n\n                // check if the user to change is root administrator\n                if (OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.ROOT_ADMIN)) {\n                    return false;\n                }\n                // check if the current user is an administrator\n                if (OpenCms.getRoleManager().hasRole(cms, CmsRole.ADMINISTRATOR)) {\n                    return true;\n                }\n                // check if the user to change is an administrator\n                return !OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.ADMINISTRATOR);\n            } catch (CmsException e) {\n                // should never happen\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n            return false;\n        } else if (getLink().equals(getPath(USERROLE_FILE)) || getLink().equals(getPath(GROUP_USERS_FILE))) {\n            String userId = CmsRequestUtil.getNotEmptyDecodedParameter(\n                wp.getJsp().getRequest(),\n                A_CmsEditUserDialog.PARAM_USERID);\n            if (userId == null) {\n                return false;\n            }\n            try {\n                return !cms.readUser(new CmsUUID(userId)).isWebuser();\n            } catch (Exception e) {\n                // ignore\n                if (LOG.isErrorEnabled()) {\n                    LOG.error(e.getLocalizedMessage(), e);\n                }\n            }\n        } else if (getLink().equals(getPath(ACCMAN_FILE))) {\n            return m_webuserOu;\n        }\n        return true;\n    }","commit_id":"696c78d31ac65dc60eb1fca42a7306cc997336a4","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Switches the current user to the given user. The session info is rebuild as if the given user\n     * performs a login at the workplace.\n     *\n     * @param cms the current CmsObject\n     * @param req the current request\n     * @param user the user to switch to\n     *\n     * @throws CmsException if something goes wrong\n     */\n    public void switchUser(CmsObject cms, HttpServletRequest req, CmsUser user) throws CmsException {\n\n        // only user with root administrator role are allowed to switch the user\n        OpenCms.getRoleManager().checkRole(cms, CmsRole.ROOT_ADMIN.forOrgUnit(user.getOuFqn()));\n        CmsSessionInfo info = getSessionInfo(req);\n        HttpSession session = req.getSession(false);\n        if ((info == null) || (session == null)) {\n            throw new CmsException(Messages.get().container(Messages.ERR_NO_SESSIONINFO_SESSION_0));\n        }\n\n        if (!OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.WORKPLACE_USER)) {\n            throw new CmsSecurityException(Messages.get().container(Messages.ERR_NO_WORKPLACE_PERMISSIONS_0));\n        }\n\n        // get the user settings for the given user and set the start project and the site root\n        CmsUserSettings settings = new CmsUserSettings(user);\n        String ouFqn = user.getOuFqn();\n        CmsProject userProject = cms.readProject(\n            ouFqn + OpenCms.getWorkplaceManager().getDefaultUserSettings().getStartProject());\n        try {\n            userProject = cms.readProject(settings.getStartProject());\n        } catch (Exception e) {\n            // ignore, use default\n        }\n        String userSiteRoot = settings.getStartSite();\n        CmsRequestContext context = new CmsRequestContext(\n            user,\n            userProject,\n            null,\n            cms.getRequestContext().getRequestMatcher(),\n            userSiteRoot,\n            cms.getRequestContext().isSecureRequest(),\n            null,\n            null,\n            null,\n            0,\n            null,\n            null,\n            ouFqn);\n        // delete the stored workplace settings, so the session has to receive them again\n        session.removeAttribute(CmsWorkplaceManager.SESSION_WORKPLACE_SETTINGS);\n\n        // create a new CmsSessionInfo and store it inside the session map\n        CmsSessionInfo newInfo = new CmsSessionInfo(context, info.getSessionId(), info.getMaxInactiveInterval());\n        addSessionInfo(newInfo);\n        // set the site root, project and ou fqn to current cms context\n        cms.getRequestContext().setSiteRoot(userSiteRoot);\n        cms.getRequestContext().setCurrentProject(userProject);\n        cms.getRequestContext().setOuFqn(user.getOuFqn());\n    }","id":36986,"modified_method":"/**\n     * Switches the current user to the given user. The session info is rebuild as if the given user\n     * performs a login at the workplace.\n     *\n     * @param cms the current CmsObject\n     * @param req the current request\n     * @param user the user to switch to\n     *\n     * @return the direct edit target if available\n     *\n     * @throws CmsException if something goes wrong\n     */\n    public String switchUser(CmsObject cms, HttpServletRequest req, CmsUser user) throws CmsException {\n\n        // only user with root administrator role are allowed to switch the user\n        OpenCms.getRoleManager().checkRole(cms, CmsRole.ROOT_ADMIN.forOrgUnit(user.getOuFqn()));\n        CmsSessionInfo info = getSessionInfo(req);\n        HttpSession session = req.getSession(false);\n        if ((info == null) || (session == null)) {\n            throw new CmsException(Messages.get().container(Messages.ERR_NO_SESSIONINFO_SESSION_0));\n        }\n\n        if (!OpenCms.getRoleManager().hasRole(cms, user.getName(), CmsRole.ELEMENT_AUTHOR)) {\n            throw new CmsSecurityException(Messages.get().container(Messages.ERR_NO_WORKPLACE_PERMISSIONS_0));\n        }\n\n        // get the user settings for the given user and set the start project and the site root\n        CmsUserSettings settings = new CmsUserSettings(user);\n        String ouFqn = user.getOuFqn();\n        CmsProject userProject = cms.readProject(\n            ouFqn + OpenCms.getWorkplaceManager().getDefaultUserSettings().getStartProject());\n        try {\n            userProject = cms.readProject(settings.getStartProject());\n        } catch (Exception e) {\n            // ignore, use default\n        }\n        String userSiteRoot = settings.getStartSite();\n        CmsRequestContext context = new CmsRequestContext(\n            user,\n            userProject,\n            null,\n            cms.getRequestContext().getRequestMatcher(),\n            userSiteRoot,\n            cms.getRequestContext().isSecureRequest(),\n            null,\n            null,\n            null,\n            0,\n            null,\n            null,\n            ouFqn);\n        // delete the stored workplace settings, so the session has to receive them again\n        session.removeAttribute(CmsWorkplaceManager.SESSION_WORKPLACE_SETTINGS);\n\n        // create a new CmsSessionInfo and store it inside the session map\n        CmsSessionInfo newInfo = new CmsSessionInfo(context, info.getSessionId(), info.getMaxInactiveInterval());\n        addSessionInfo(newInfo);\n        // set the site root, project and ou fqn to current cms context\n        cms.getRequestContext().setSiteRoot(userSiteRoot);\n        cms.getRequestContext().setCurrentProject(userProject);\n        cms.getRequestContext().setOuFqn(user.getOuFqn());\n        String directEditTarget = CmsLoginHelper.getDirectEditPath(cms, new CmsUserSettings(user), false);\n        return directEditTarget != null\n        ? OpenCms.getLinkManager().substituteLink(cms, directEditTarget, userSiteRoot)\n        : null;\n    }","commit_id":"696c78d31ac65dc60eb1fca42a7306cc997336a4","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Calls the switch user method of the SessionManager.<p>\n     *\n     * @throws CmsException if something goes wrong\n     */\n    public void actionSwitchUser() throws CmsException {\n\n        try {\n            CmsSessionManager sessionManager = OpenCms.getSessionManager();\n            sessionManager.switchUser(\n                getCms(),\n                getJsp().getRequest(),\n                getCms().readUser(new CmsUUID(getJsp().getRequest().getParameter(\"userid\"))));\n        } catch (CmsException e) {\n            String toolPath = getCurrentToolPath().substring(0, getCurrentToolPath().lastIndexOf(\"/\"));\n            getToolManager().setCurrentToolPath(this, toolPath);\n            throw e;\n        }\n    }","id":36987,"modified_method":"/**\n     * Calls the switch user method of the SessionManager.<p>\n     *\n     * @return the direct edit patch\n     *\n     * @throws CmsException if something goes wrong\n     */\n    public String actionSwitchUser() throws CmsException {\n\n        try {\n            CmsSessionManager sessionManager = OpenCms.getSessionManager();\n            CmsUser user = getCms().readUser(new CmsUUID(getJsp().getRequest().getParameter(\"userid\")));\n            return sessionManager.switchUser(getCms(), getJsp().getRequest(), user);\n        } catch (CmsException e) {\n            String toolPath = getCurrentToolPath().substring(0, getCurrentToolPath().lastIndexOf(\"/\"));\n            getToolManager().setCurrentToolPath(this, toolPath);\n            throw e;\n        }\n    }","commit_id":"696c78d31ac65dc60eb1fca42a7306cc997336a4","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Commits the edited user to the db.<p>\n     */\n    @Override\n    public void actionCommit() {\n\n        // no saving is done\n        setCommitErrors(new ArrayList());\n    }","id":36988,"modified_method":"/**\n     * Commits the edited user to the db.<p>\n     */\n    @Override\n    public void actionCommit() {\n\n        // no saving is done\n        setCommitErrors(new ArrayList<Throwable>());\n    }","commit_id":"696c78d31ac65dc60eb1fca42a7306cc997336a4","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n\t * Reads a user from the cms, only if the password is correct.<p>\n\t *\n\t * @param name the name of the user\n\t * @param password the password of the user\n\t * @param the remote address of the request\n\t * @param type the type of the user\n\t * @return the read user\n\t * @throws throws CmsException if something goes wrong\n\t */\n\tpublic CmsUser readUser(String name, String password, String remoteAddress, int type) throws CmsException {\n\t\treturn readUser(name, password, type);\n\t}","id":36989,"modified_method":"/**\n\t * Reads a user from the cms, only if the password is correct.<p>\n\t *\n\t * @param name the name of the user\n\t * @param password the password of the user\n\t * @param the remote address of the request\n\t * @param type the type of the user\n\t * @return the read user\n\t * @throws throws CmsException if something goes wrong\n\t */\n\tpublic CmsUser readUser(String name, String password, String remoteAddress, int type) throws CmsException {\n\t\tCmsUser user = readUser(name, password, type);\n\t\tuser.setLastRemoteAddress(remoteAddress);\n\t\treturn user;\n\t}","commit_id":"51c36aac4edd82b1947b74e0710265471c9e34af","url":"https://github.com/alkacon/opencms-core"},{"original_method":"public static NSArray fetchCompanys(EOEditingContext editingContext, EOQualifier qualifier, NSArray sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Company.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray eoObjects = editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","id":36990,"modified_method":"public static NSArray<Company> fetchCompanys(EOEditingContext editingContext, EOQualifier qualifier, NSArray<EOSortOrdering> sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Company.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray<Company> eoObjects = (NSArray<Company>)editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Company fetchCompany(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray eoObjects = _Company.fetchCompanys(editingContext, qualifier, null);\n\t\tCompany eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Company)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Company that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","id":36991,"modified_method":"public static Company fetchCompany(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray<Company> eoObjects = _Company.fetchCompanys(editingContext, qualifier, null);\n\t\tCompany eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Company)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Company that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public Company localInstanceOfCompany(EOEditingContext editingContext) {\n\t\treturn (Company)EOUtilities.localInstanceOfObject(editingContext, this);\n\t}","id":36992,"modified_method":"public Company localInstanceOfCompany(EOEditingContext editingContext) {\n\t\tCompany localInstance = (Company)EOUtilities.localInstanceOfObject(editingContext, this);\n\t\tif (localInstance == null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + this + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public NSArray employees() {\n\t\treturn (NSArray)storedValueForKey(\"employees\");\n\t}","id":36993,"modified_method":"public NSArray<Employee> employees() {\n\t\treturn (NSArray<Employee>)storedValueForKey(\"employees\");\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Company localInstanceOfCompany(EOEditingContext editingContext, Company eo) {\n\t\treturn (eo == null) ? null : (Company)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t}","id":36994,"modified_method":"public static Company localInstanceOfCompany(EOEditingContext editingContext, Company eo) {\n\t\tCompany localInstance = (eo == null) ? null : (Company)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t\tif (localInstance == null && eo != null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + eo + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\t\t\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public NSArray employees(EOQualifier qualifier, NSArray sortOrderings, boolean fetch) {\n\t\tNSArray results;\n\n\t\tif (fetch) {\n\t\t\tEOQualifier fullQualifier;\n\t\t\tEOQualifier inverseQualifier = new EOKeyValueQualifier(Employee.COMPANY_KEY, EOQualifier.QualifierOperatorEqual, this);\n\t\t\tif (qualifier == null) {\n\t\t\t\tfullQualifier = inverseQualifier;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tNSMutableArray qualifiers = new NSMutableArray();\n\t\t\t\tqualifiers.addObject(qualifier);\n\t\t\t\tqualifiers.addObject(inverseQualifier);\n\t\t\t\tfullQualifier = new EOAndQualifier(qualifiers);\n\t\t\t}\n\t\t\tresults = Employee.fetchEmployees(editingContext(), fullQualifier, sortOrderings);\n\t\t}\n\t\telse {\n\n\t\t\tresults = employees();\n\t\t\tif (qualifier != null) {\n\t\t\t\tresults = EOQualifier.filteredArrayWithQualifier(results, qualifier);\n\t\t\t}\n\t\t\tif (sortOrderings != null) {\n\t\t\t\tresults = EOSortOrdering.sortedArrayUsingKeyOrderArray(results, sortOrderings);\n\t\t\t}\n\n\t\t}\n\n\t\treturn results;\n\t}","id":36995,"modified_method":"public NSArray<Employee> employees(EOQualifier qualifier, NSArray<EOSortOrdering> sortOrderings, boolean fetch) {\n\t\tNSArray<Employee> results;\n\n\t\tif (fetch) {\n\t\t\tEOQualifier fullQualifier;\n\t\t\tEOQualifier inverseQualifier = new EOKeyValueQualifier(Employee.COMPANY_KEY, EOQualifier.QualifierOperatorEqual, this);\n\t\t\tif (qualifier == null) {\n\t\t\t\tfullQualifier = inverseQualifier;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tNSMutableArray qualifiers = new NSMutableArray();\n\t\t\t\tqualifiers.addObject(qualifier);\n\t\t\t\tqualifiers.addObject(inverseQualifier);\n\t\t\t\tfullQualifier = new EOAndQualifier(qualifiers);\n\t\t\t}\n\t\t\tresults = Employee.fetchEmployees(editingContext(), fullQualifier, sortOrderings);\n\t\t}\n\t\telse {\n\n\t\t\tresults = employees();\n\t\t\tif (qualifier != null) {\n\t\t\t\tresults = (NSArray<Employee>)EOQualifier.filteredArrayWithQualifier(results, qualifier);\n\t\t\t}\n\t\t\tif (sortOrderings != null) {\n\t\t\t\tresults = (NSArray<Employee>)EOSortOrdering.sortedArrayUsingKeyOrderArray(results, sortOrderings);\n\t\t\t}\n\n\t\t}\n\n\t\treturn results;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static NSArray fetchAllCompanys(EOEditingContext editingContext, NSArray sortOrderings) {\n\t\treturn _Company.fetchCompanys(editingContext, null, sortOrderings);\n\t}","id":36996,"modified_method":"public static NSArray<Company> fetchAllCompanys(EOEditingContext editingContext, NSArray<EOSortOrdering> sortOrderings) {\n\t\treturn _Company.fetchCompanys(editingContext, null, sortOrderings);\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public Employee localInstanceOfEmployee(EOEditingContext editingContext) {\n\t\treturn (Employee)EOUtilities.localInstanceOfObject(editingContext, this);\n\t}","id":36997,"modified_method":"public Employee localInstanceOfEmployee(EOEditingContext editingContext) {\n\t\tEmployee localInstance = (Employee)EOUtilities.localInstanceOfObject(editingContext, this);\n\t\tif (localInstance == null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + this + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static NSArray fetchAllEmployees(EOEditingContext editingContext, NSArray sortOrderings) {\n\t\treturn _Employee.fetchEmployees(editingContext, null, sortOrderings);\n\t}","id":36998,"modified_method":"public static NSArray<Employee> fetchAllEmployees(EOEditingContext editingContext, NSArray<EOSortOrdering> sortOrderings) {\n\t\treturn _Employee.fetchEmployees(editingContext, null, sortOrderings);\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Employee fetchEmployee(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray eoObjects = _Employee.fetchEmployees(editingContext, qualifier, null);\n\t\tEmployee eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Employee)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Employee that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","id":36999,"modified_method":"public static Employee fetchEmployee(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray<Employee> eoObjects = _Employee.fetchEmployees(editingContext, qualifier, null);\n\t\tEmployee eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Employee)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Employee that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"}]