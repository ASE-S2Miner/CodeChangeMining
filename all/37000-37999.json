[{"original_method":"public static NSArray fetchEmployees(EOEditingContext editingContext, EOQualifier qualifier, NSArray sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Employee.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray eoObjects = editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","id":37000,"modified_method":"public static NSArray<Employee> fetchEmployees(EOEditingContext editingContext, EOQualifier qualifier, NSArray<EOSortOrdering> sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Employee.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray<Employee> eoObjects = (NSArray<Employee>)editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public NSArray paychecks() {\n\t\treturn (NSArray)storedValueForKey(\"paychecks\");\n\t}","id":37001,"modified_method":"public NSArray<Paycheck> paychecks() {\n\t\treturn (NSArray<Paycheck>)storedValueForKey(\"paychecks\");\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Employee localInstanceOfEmployee(EOEditingContext editingContext, Employee eo) {\n\t\treturn (eo == null) ? null : (Employee)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t}","id":37002,"modified_method":"public static Employee localInstanceOfEmployee(EOEditingContext editingContext, Employee eo) {\n\t\tEmployee localInstance = (eo == null) ? null : (Employee)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t\tif (localInstance == null && eo != null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + eo + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\t\t\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public NSArray paychecks(EOQualifier qualifier, NSArray sortOrderings, boolean fetch) {\n\t\tNSArray results;\n\n\t\tif (fetch) {\n\t\t\tEOQualifier fullQualifier;\n\t\t\tEOQualifier inverseQualifier = new EOKeyValueQualifier(Paycheck.EMPLOYEE_KEY, EOQualifier.QualifierOperatorEqual, this);\n\t\t\tif (qualifier == null) {\n\t\t\t\tfullQualifier = inverseQualifier;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tNSMutableArray qualifiers = new NSMutableArray();\n\t\t\t\tqualifiers.addObject(qualifier);\n\t\t\t\tqualifiers.addObject(inverseQualifier);\n\t\t\t\tfullQualifier = new EOAndQualifier(qualifiers);\n\t\t\t}\n\t\t\tresults = Paycheck.fetchPaychecks(editingContext(), fullQualifier, sortOrderings);\n\t\t}\n\t\telse {\n\n\t\t\tresults = paychecks();\n\t\t\tif (qualifier != null) {\n\t\t\t\tresults = EOQualifier.filteredArrayWithQualifier(results, qualifier);\n\t\t\t}\n\t\t\tif (sortOrderings != null) {\n\t\t\t\tresults = EOSortOrdering.sortedArrayUsingKeyOrderArray(results, sortOrderings);\n\t\t\t}\n\n\t\t}\n\n\t\treturn results;\n\t}","id":37003,"modified_method":"public NSArray<Paycheck> paychecks(EOQualifier qualifier, NSArray<EOSortOrdering> sortOrderings, boolean fetch) {\n\t\tNSArray<Paycheck> results;\n\n\t\tif (fetch) {\n\t\t\tEOQualifier fullQualifier;\n\t\t\tEOQualifier inverseQualifier = new EOKeyValueQualifier(Paycheck.EMPLOYEE_KEY, EOQualifier.QualifierOperatorEqual, this);\n\t\t\tif (qualifier == null) {\n\t\t\t\tfullQualifier = inverseQualifier;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tNSMutableArray qualifiers = new NSMutableArray();\n\t\t\t\tqualifiers.addObject(qualifier);\n\t\t\t\tqualifiers.addObject(inverseQualifier);\n\t\t\t\tfullQualifier = new EOAndQualifier(qualifiers);\n\t\t\t}\n\t\t\tresults = Paycheck.fetchPaychecks(editingContext(), fullQualifier, sortOrderings);\n\t\t}\n\t\telse {\n\n\t\t\tresults = paychecks();\n\t\t\tif (qualifier != null) {\n\t\t\t\tresults = (NSArray<Paycheck>)EOQualifier.filteredArrayWithQualifier(results, qualifier);\n\t\t\t}\n\t\t\tif (sortOrderings != null) {\n\t\t\t\tresults = (NSArray<Paycheck>)EOSortOrdering.sortedArrayUsingKeyOrderArray(results, sortOrderings);\n\t\t\t}\n\n\t\t}\n\n\t\treturn results;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Paycheck createPaycheck(EOEditingContext editingContext, Number amount, java.lang.Boolean cashed, NSTimestamp paymentDate, Employee employee) {\n\t\tPaycheck eoObject = (Paycheck)EOUtilities.createAndInsertInstance(editingContext, _Paycheck.ENTITY_NAME);\n\t\teoObject.setAmount(amount);\n\t\teoObject.setCashed(cashed);\n\t\teoObject.setPaymentDate(paymentDate);\n\t\teoObject.setEmployeeRelationship(employee);\n\t\treturn eoObject;\n\t}","id":37004,"modified_method":"public static Paycheck createPaycheck(EOEditingContext editingContext, Double amount, java.lang.Boolean cashed, NSTimestamp paymentDate, Employee employee) {\n\t\tPaycheck eoObject = (Paycheck)EOUtilities.createAndInsertInstance(editingContext, _Paycheck.ENTITY_NAME);\n\t\teoObject.setAmount(amount);\n\t\teoObject.setCashed(cashed);\n\t\teoObject.setPaymentDate(paymentDate);\n\t\teoObject.setEmployeeRelationship(employee);\n\t\treturn eoObject;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public Number amount() {\n\t\treturn (Number) storedValueForKey(\"amount\");\n\t}","id":37005,"modified_method":"public Double amount() {\n\t\treturn (Double) storedValueForKey(\"amount\");\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Paycheck localInstanceOfPaycheck(EOEditingContext editingContext, Paycheck eo) {\n\t\treturn (eo == null) ? null : (Paycheck)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t}","id":37006,"modified_method":"public static Paycheck localInstanceOfPaycheck(EOEditingContext editingContext, Paycheck eo) {\n\t\tPaycheck localInstance = (eo == null) ? null : (Paycheck)EOUtilities.localInstanceOfObject(editingContext, eo);\n\t\tif (localInstance == null && eo != null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + eo + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\t\t\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static NSArray fetchPaychecks(EOEditingContext editingContext, EOQualifier qualifier, NSArray sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Paycheck.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray eoObjects = editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","id":37007,"modified_method":"public static NSArray<Paycheck> fetchPaychecks(EOEditingContext editingContext, EOQualifier qualifier, NSArray<EOSortOrdering> sortOrderings) {\n\t\tEOFetchSpecification fetchSpec = new EOFetchSpecification(_Paycheck.ENTITY_NAME, qualifier, sortOrderings);\n\t\tfetchSpec.setIsDeep(true);\n\t\tNSArray<Paycheck> eoObjects = (NSArray<Paycheck>)editingContext.objectsWithFetchSpecification(fetchSpec);\n\t\treturn eoObjects;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static NSArray fetchAllPaychecks(EOEditingContext editingContext, NSArray sortOrderings) {\n\t\treturn _Paycheck.fetchPaychecks(editingContext, null, sortOrderings);\n\t}","id":37008,"modified_method":"public static NSArray<Paycheck> fetchAllPaychecks(EOEditingContext editingContext, NSArray<EOSortOrdering> sortOrderings) {\n\t\treturn _Paycheck.fetchPaychecks(editingContext, null, sortOrderings);\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public Paycheck localInstanceOfPaycheck(EOEditingContext editingContext) {\n\t\treturn (Paycheck)EOUtilities.localInstanceOfObject(editingContext, this);\n\t}","id":37009,"modified_method":"public Paycheck localInstanceOfPaycheck(EOEditingContext editingContext) {\n\t\tPaycheck localInstance = (Paycheck)EOUtilities.localInstanceOfObject(editingContext, this);\n\t\tif (localInstance == null) {\n\t\t\tthrow new IllegalStateException(\"You attempted to localInstance \" + this + \", which has not yet committed.\");\n\t\t}\n\t\treturn localInstance;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"public static Paycheck fetchPaycheck(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray eoObjects = _Paycheck.fetchPaychecks(editingContext, qualifier, null);\n\t\tPaycheck eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Paycheck)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Paycheck that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","id":37010,"modified_method":"public static Paycheck fetchPaycheck(EOEditingContext editingContext, EOQualifier qualifier) {\n\t\tNSArray<Paycheck> eoObjects = _Paycheck.fetchPaychecks(editingContext, qualifier, null);\n\t\tPaycheck eoObject;\n\t\tint count = eoObjects.count();\n\t\tif (count == 0) {\n\t\t\teoObject = null;\n\t\t}\n\t\telse if (count == 1) {\n\t\t\teoObject = (Paycheck)eoObjects.objectAtIndex(0);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"There was more than one Paycheck that matched the qualifier '\" + qualifier + \"'.\");\n\t\t}\n\t\treturn eoObject;\n\t}","commit_id":"c47e8745b85f96ed87e6f6b0dd42fc8e6d89e51d","url":"https://github.com/wocommunity/wonder"},{"original_method":"/**\n   * Issue on a disabled rule (uninstalled plugin or rule deactivated from quality profile) must \n   * be CLOSED with resolution REMOVED\n   */\n  @Test\n  public void issue_is_closed_as_removed_when_rule_is_disabled() throws Exception {\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueWorkflowTest/xoo-one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"workflow\", \"Workflow\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"workflow\", \"xoo\", \"xoo-one-issue-per-line-profile\");\n\n    SonarRunner analysis = SonarRunner.create(projectDir(\"issue/workflow\"));\n    orchestrator.executeBuild(analysis);\n\n    IssueClient issueClient = orchestrator.getServer().wsClient().issueClient();\n    List<Issue> issues = issueClient.find(IssueQuery.create().rules(\"xoo:OneIssuePerLine\")).list();\n    assertThat(issues).isNotEmpty();\n\n    // re-analyze with profile \"empty\". The rule is disabled so the issues must be closed\n    orchestrator.getServer().associateProjectToQualityProfile(\"workflow\", \"xoo\", \"empty\");\n    analysis = SonarRunner.create(projectDir(\"issue/workflow\"));\n    orchestrator.executeBuild(analysis);\n    issues = issueClient.find(IssueQuery.create().rules(\"xoo:OneIssuePerLine\").componentRoots(\"workflow\")).list();\n    assertThat(issues).isNotEmpty();\n    for (Issue issue : issues) {\n      assertThat(issue.status()).isEqualTo(\"CLOSED\");\n      assertThat(issue.resolution()).isEqualTo(\"REMOVED\");\n    }\n  }","id":37011,"modified_method":"/**\n   * Issue on a disabled rule (uninstalled plugin or rule deactivated from quality profile) must \n   * be CLOSED with resolution REMOVED\n   */\n  @Test\n  public void issue_is_closed_as_removed_when_rule_is_disabled() throws Exception {\n    List<Issue> issues = searchIssues(IssueQuery.create().rules(\"xoo:OneIssuePerLine\"));\n    assertThat(issues).isNotEmpty();\n\n    // re-analyze with profile \"empty\". The rule is disabled so the issues must be closed\n    orchestrator.getServer().associateProjectToQualityProfile(\"workflow\", \"xoo\", \"empty\");\n    orchestrator.executeBuild(scan);\n    issues = searchIssues(IssueQuery.create().rules(\"xoo:OneIssuePerLine\"));\n    assertThat(issues).isNotEmpty();\n    for (Issue issue : issues) {\n      assertThat(issue.status()).isEqualTo(\"CLOSED\");\n      assertThat(issue.resolution()).isEqualTo(\"REMOVED\");\n    }\n  }","commit_id":"18c1eac42c17d11e296d6065112736732e2f76f2","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@BeforeClass\n  public static void setUp() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/CommonRulesTest/xoo-common-rules-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"common-rules-project\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"common-rules-project\", \"xoo\", \"xoo-common-rules\");\n    SonarRunner analysis = SonarRunner.create(projectDir(\"issue/common-rules\"),\n      \"sonar.cpd.xoo.minimumTokens\", \"2\",\n      \"sonar.cpd.xoo.minimumLines\", \"2\");\n    orchestrator.executeBuild(analysis);\n  }","id":37012,"modified_method":"@BeforeClass\n  public static void setUp() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/CommonRulesTest/xoo-common-rules-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"common-rules-project\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"common-rules-project\", \"xoo\", \"xoo-common-rules\");\n    runProjectAnalysis(orchestrator, \"issue/common-rules\",\n      \"sonar.cpd.xoo.minimumTokens\", \"2\",\n      \"sonar.cpd.xoo.minimumLines\", \"2\");\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private List<Issue> findIssues(String componentKey, String ruleKey) {\n    return orchestrator.getServer().wsClient().issueClient().find(IssueQuery.create().components(componentKey).rules(ruleKey)).list();\n  }","id":37013,"modified_method":"private List<Issue> findIssues(String componentKey, String ruleKey) {\n    return searchIssues(IssueQuery.create().components(componentKey).rules(ruleKey));\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void analyzeProjectWithCustomRules() throws Exception {\n\n    orchestrator.getServer().adminWsClient().post(\"api/rules/create\",\n      \"template_key\", \"xoo:TemplateRule\",\n      \"custom_key\", \"MyCustomRule\",\n      \"markdown_description\", \"My description\",\n      \"name\", \"My custom rule\",\n      \"severity\", \"BLOCKER\",\n      \"params\", \"line=2\");\n\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/CustomRulesTest/custom.xml\"));\n\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"Custom\");\n\n    orchestrator.executeBuild(SonarRunner.create().setProjectDir(ItUtils.projectDir(\"shared/xoo-sample\")));\n\n    List<Issue> issues = orchestrator.getServer().adminWsClient().issueClient().find(IssueQuery.create()).list();\n    assertThat(issues).hasSize(1);\n\n    Issue issue = issues.get(0);\n    assertThat(issue.ruleKey()).isEqualTo(\"xoo:MyCustomRule\");\n    assertThat(issue.line()).isEqualTo(2);\n    // Overriden in quality profile\n    assertThat(issue.severity()).isEqualTo(\"CRITICAL\");\n  }","id":37014,"modified_method":"@Test\n  public void analyzeProjectWithCustomRules() throws Exception {\n\n    orchestrator.getServer().adminWsClient().post(\"api/rules/create\",\n      \"template_key\", \"xoo:TemplateRule\",\n      \"custom_key\", \"MyCustomRule\",\n      \"markdown_description\", \"My description\",\n      \"name\", \"My custom rule\",\n      \"severity\", \"BLOCKER\",\n      \"params\", \"line=2\");\n\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/CustomRulesTest/custom.xml\"));\n\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"Custom\");\n\n    runProjectAnalysis(orchestrator, \"shared/xoo-sample\");\n\n    List<Issue> issues = searchIssues();\n    assertThat(issues).hasSize(1);\n\n    Issue issue = issues.get(0);\n    assertThat(issue.ruleKey()).isEqualTo(\"xoo:MyCustomRule\");\n    assertThat(issue.line()).isEqualTo(2);\n    // Overriden in quality profile\n    assertThat(issue.severity()).isEqualTo(\"CRITICAL\");\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n   * SONAR-4287\n   */\n  @Test\n  public void assign() {\n    assertThat(issue.assignee()).isNull();\n    Issues issues = search(IssueQuery.create().issues(issue.key()));\n    assertThat(issues.users()).isEmpty();\n\n    adminIssueClient().assign(issue.key(), \"admin\");\n    assertThat(search(IssueQuery.create().assignees(\"admin\")).list()).hasSize(1);\n\n    orchestrator.executeBuild(scan);\n    Issue reloaded = searchIssueByKey(issue.key());\n    assertThat(reloaded.assignee()).isEqualTo(\"admin\");\n    assertThat(reloaded.creationDate()).isEqualTo(issue.creationDate());\n\n    issues = search(IssueQuery.create().issues(issue.key()));\n    assertThat(issues.user(\"admin\")).isNotNull();\n    assertThat(issues.user(\"admin\").name()).isEqualTo(\"Administrator\");\n\n    // unassign\n    adminIssueClient().assign(issue.key(), null);\n    reloaded = searchIssueByKey(issue.key());\n    assertThat(reloaded.assignee()).isNull();\n    assertThat(issueClient().find(IssueQuery.create().assignees(\"admin\")).list()).isEmpty();\n  }","id":37015,"modified_method":"/**\n   * SONAR-4287\n   */\n  @Test\n  public void assign() {\n    assertThat(issue.assignee()).isNull();\n    Issues issues = search(IssueQuery.create().issues(issue.key()));\n    assertThat(issues.users()).isEmpty();\n\n    adminIssueClient().assign(issue.key(), \"admin\");\n    assertThat(searchIssues(IssueQuery.create().assignees(\"admin\"))).hasSize(1);\n\n    orchestrator.executeBuild(scan);\n    Issue reloaded = searchIssueByKey(issue.key());\n    assertThat(reloaded.assignee()).isEqualTo(\"admin\");\n    assertThat(reloaded.creationDate()).isEqualTo(issue.creationDate());\n\n    issues = search(IssueQuery.create().issues(issue.key()));\n    assertThat(issues.user(\"admin\")).isNotNull();\n    assertThat(issues.user(\"admin\").name()).isEqualTo(\"Administrator\");\n\n    // unassign\n    adminIssueClient().assign(issue.key(), null);\n    reloaded = searchIssueByKey(issue.key());\n    assertThat(reloaded.assignee()).isNull();\n    assertThat(searchIssues(IssueQuery.create().assignees(\"admin\"))).isEmpty();\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void resetData() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueActionTest/xoo-one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"xoo-one-issue-per-line-profile\");\n\n    scan = SonarRunner.create(projectDir(\"shared/xoo-sample\"));\n    orchestrator.executeBuild(scan);\n    issue = searchRandomIssue();\n  }","id":37016,"modified_method":"@Before\n  public void resetData() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueActionTest/xoo-one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"xoo-one-issue-per-line-profile\");\n\n    scan = runProjectAnalysis(orchestrator, \"shared/xoo-sample\");\n    issue = searchRandomIssue();\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n   * SONAR-4315\n   */\n  @Test\n  public void apply_action_from_plugin() {\n    // The condition on the action defined by the plugin is that the status must be resolved\n    adminIssueClient().doTransition(issue.key(), \"resolve\");\n    assertThat(adminIssueClient().actions(issue.key())).contains(\"fake\");\n\n    adminIssueClient().doAction(issue.key(), \"fake\");\n\n    // reload issue\n    Issue reloaded = searchIssueByKey(issue.key());\n\n    assertThat(reloaded.comments()).hasSize(1);\n    assertThat(reloaded.comments().get(0).htmlText()).isEqualTo(\"New Comment from fake action\");\n\n    // The action is no more available when already executed (because an issue attribute is used to check if the action is available or not)\n    assertThat(adminIssueClient().actions(issue.key())).doesNotContain(\"fake\");\n  }","id":37017,"modified_method":"/**\n   * SONAR-4315\n   */\n  @Test\n  public void apply_action_from_plugin() {\n    // The condition on the action defined by the plugin is that the status must be resolved\n    adminIssueClient().doTransition(issue.key(), \"resolve\");\n    assertThat(adminIssueClient().actions(issue.key())).contains(\"fake\");\n\n    adminIssueClient().doAction(issue.key(), \"fake\");\n\n    // reload issue\n    Issue reloaded = searchIssues(issue.key(), true).iterator().next();\n\n    assertThat(reloaded.comments()).hasSize(1);\n    assertThat(reloaded.comments().get(0).htmlText()).isEqualTo(\"New Comment from fake action\");\n\n    // The action is no more available when already executed (because an issue attribute is used to check if the action is available or not)\n    assertThat(adminIssueClient().actions(issue.key())).doesNotContain(\"fake\");\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void add_comment() throws Exception {\n    IssueComment comment = adminIssueClient().addComment(issue.key(), \"this is my *comment*\");\n    assertThat(comment.key()).isNotNull();\n    assertThat(comment.htmlText()).isEqualTo(\"this is my <em>comment<\/em>\");\n    assertThat(comment.login()).isEqualTo(\"admin\");\n    assertThat(comment.createdAt()).isNotNull();\n\n    // reload issue\n    Issue reloaded = searchIssueByKey(issue.key());\n\n    assertThat(reloaded.comments()).hasSize(1);\n    assertThat(reloaded.comments().get(0).key()).isEqualTo(comment.key());\n    assertThat(reloaded.comments().get(0).htmlText()).isEqualTo(\"this is my <em>comment<\/em>\");\n    assertThat(reloaded.updateDate().before(issue.creationDate())).isFalse();\n  }","id":37018,"modified_method":"@Test\n  public void add_comment() throws Exception {\n    IssueComment comment = adminIssueClient().addComment(issue.key(), \"this is my *comment*\");\n    assertThat(comment.key()).isNotNull();\n    assertThat(comment.htmlText()).isEqualTo(\"this is my <em>comment<\/em>\");\n    assertThat(comment.login()).isEqualTo(\"admin\");\n    assertThat(comment.createdAt()).isNotNull();\n\n    // reload issue\n    Issue reloaded = searchIssues(issue.key(), true).iterator().next();\n\n    assertThat(reloaded.comments()).hasSize(1);\n    assertThat(reloaded.comments().get(0).key()).isEqualTo(comment.key());\n    assertThat(reloaded.comments().get(0).htmlText()).isEqualTo(\"this is my <em>comment<\/em>\");\n    assertThat(reloaded.updateDate().before(issue.creationDate())).isFalse();\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private static void assertIssueStatus(String[] issueKeys, String expectedStatus) {\n    for (Issue issue : searchIssues(issueKeys)) {\n      assertThat(issue.status()).isEqualTo(expectedStatus);\n    }\n  }","id":37019,"modified_method":"private static void assertIssueStatus(String[] issueKeys, String expectedStatus) {\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys)) {\n      assertThat(issue.status()).isEqualTo(expectedStatus);\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private static void assertIssueSeverity(String[] issueKeys, String expectedSeverity) {\n    for (Issue issue : searchIssues(issueKeys)) {\n      assertThat(issue.severity()).isEqualTo(expectedSeverity);\n    }\n  }","id":37020,"modified_method":"private static void assertIssueSeverity(String[] issueKeys, String expectedSeverity) {\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys)) {\n      assertThat(issue.severity()).isEqualTo(expectedSeverity);\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_setSeverity_add_comment_in_single_WS_call() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String newSeverity = \"BLOCKER\";\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"set_severity\", \"comment\")\n        .actionParameter(\"set_severity\", \"severity\", newSeverity)\n        .actionParameter(\"comment\", \"comment\", COMMENT_AS_MARKDOWN)\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : searchIssues(issueKeys, true)) {\n      assertThat(issue.comments()).hasSize(1);\n      assertThat(issue.comments().get(0).htmlText()).isEqualTo(COMMENT_AS_HTML);\n    }\n  }","id":37021,"modified_method":"@Test\n  public void should_setSeverity_add_comment_in_single_WS_call() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String newSeverity = \"BLOCKER\";\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"set_severity\", \"comment\")\n        .actionParameter(\"set_severity\", \"severity\", newSeverity)\n        .actionParameter(\"comment\", \"comment\", COMMENT_AS_MARKDOWN)\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys, true)) {\n      assertThat(issue.comments()).hasSize(1);\n      assertThat(issue.comments().get(0).htmlText()).isEqualTo(COMMENT_AS_HTML);\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_plan() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    // Create action plan\n    ActionPlan newActionPlan = adminActionPlanClient().create(\n      NewActionPlan.create().name(\"Short term\").project(\"sample\").description(\"Short term issues\").deadLine(ItUtils.toDate(\"2113-01-31\")));\n\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"plan\")\n        .actionParameter(\"plan\", \"plan\", newActionPlan.key())\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : searchIssues(issueKeys)) {\n      assertThat(issue.actionPlan()).isEqualTo(newActionPlan.key());\n    }\n  }","id":37022,"modified_method":"@Test\n  public void should_plan() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    // Create action plan\n    ActionPlan newActionPlan = adminActionPlanClient().create(\n      NewActionPlan.create().name(\"Short term\").project(\"sample\").description(\"Short term issues\").deadLine(ItUtils.toDate(\"2113-01-31\")));\n\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"plan\")\n        .actionParameter(\"plan\", \"plan\", newActionPlan.key())\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys)) {\n      assertThat(issue.actionPlan()).isEqualTo(newActionPlan.key());\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private static String[] searchIssueKeys(int limit) {\n    return getIssueKeys(searchIssues(), limit);\n  }","id":37023,"modified_method":"private static String[] searchIssueKeys(int limit) {\n    return getIssueKeys(IssueTestSuite.searchIssues(), limit);\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_assign() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n    BulkChange bulkChange = buldChangeAssigneeOfIssues(issueKeys, \"admin\");\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : searchIssues(issueKeys)) {\n      assertThat(issue.assignee()).isEqualTo(\"admin\");\n    }\n  }","id":37024,"modified_method":"@Test\n  public void should_assign() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n    BulkChange bulkChange = buldChangeAssigneeOfIssues(issueKeys, \"admin\");\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys)) {\n      assertThat(issue.assignee()).isEqualTo(\"admin\");\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void analyzeSampleProjectWillSmallNumberOfIssues() {\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueBulkChangeTest/one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"one-issue-per-line\");\n    orchestrator.executeBuild(SonarRunner.create(projectDir(\"shared/xoo-sample\")));\n  }","id":37025,"modified_method":"private void analyzeSampleProjectWillSmallNumberOfIssues() {\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueBulkChangeTest/one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"one-issue-per-line\");\n    runProjectAnalysis(orchestrator, \"shared/xoo-sample\");\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_apply_bulk_change_on_many_actions() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String newSeverity = \"BLOCKER\";\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"do_transition\", \"assign\", \"set_severity\")\n        .actionParameter(\"do_transition\", \"transition\", \"confirm\")\n        .actionParameter(\"assign\", \"assignee\", \"admin\")\n        .actionParameter(\"set_severity\", \"severity\", newSeverity)\n        .comment(COMMENT_AS_MARKDOWN)\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : searchIssues(issueKeys, true)) {\n      assertThat(issue.status()).isEqualTo(\"CONFIRMED\");\n      assertThat(issue.assignee()).isEqualTo(\"admin\");\n      assertThat(issue.severity()).isEqualTo(newSeverity);\n      assertThat(issue.comments()).hasSize(1);\n      assertThat(issue.comments().get(0).htmlText()).isEqualTo(COMMENT_AS_HTML);\n    }\n  }","id":37026,"modified_method":"@Test\n  public void should_apply_bulk_change_on_many_actions() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n\n    String newSeverity = \"BLOCKER\";\n    String[] issueKeys = searchIssueKeys(BULK_EDITED_ISSUE_COUNT);\n\n    BulkChange bulkChange = adminIssueClient().bulkChange(\n      BulkChangeQuery.create()\n        .issues(issueKeys)\n        .actions(\"do_transition\", \"assign\", \"set_severity\")\n        .actionParameter(\"do_transition\", \"transition\", \"confirm\")\n        .actionParameter(\"assign\", \"assignee\", \"admin\")\n        .actionParameter(\"set_severity\", \"severity\", newSeverity)\n        .comment(COMMENT_AS_MARKDOWN)\n      );\n\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(BULK_EDITED_ISSUE_COUNT);\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys, true)) {\n      assertThat(issue.status()).isEqualTo(\"CONFIRMED\");\n      assertThat(issue.assignee()).isEqualTo(\"admin\");\n      assertThat(issue.severity()).isEqualTo(newSeverity);\n      assertThat(issue.comments()).hasSize(1);\n      assertThat(issue.comments().get(0).htmlText()).isEqualTo(COMMENT_AS_HTML);\n    }\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Test\n  public void should_add_comment_only_on_issues_that_will_be_changed() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n    int nbIssues = BULK_EDITED_ISSUE_COUNT;\n    String[] issueKeys = searchIssueKeys(nbIssues);\n\n    // Confirm an issue\n    adminIssueClient().doTransition(searchIssues().iterator().next().key(), \"confirm\");\n\n    // Apply a bulk change on unconfirm transition\n    BulkChangeQuery query = (BulkChangeQuery.create()\n      .issues(issueKeys)\n      .actions(\"do_transition\")\n      .actionParameter(\"do_transition\", \"transition\", \"unconfirm\")\n      .comment(\"this is my comment\")\n      );\n    BulkChange bulkChange = adminIssueClient().bulkChange(query);\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(1);\n\n    int nbIssuesWithComment = 0;\n    for (Issue issue : searchIssues(issueKeys, true)) {\n      if (!issue.comments().isEmpty()) {\n        nbIssuesWithComment++;\n      }\n    }\n    // Only one issue should have the comment\n    assertThat(nbIssuesWithComment).isEqualTo(1);\n  }","id":37027,"modified_method":"@Test\n  public void should_add_comment_only_on_issues_that_will_be_changed() {\n    analyzeSampleProjectWillSmallNumberOfIssues();\n    int nbIssues = BULK_EDITED_ISSUE_COUNT;\n    String[] issueKeys = searchIssueKeys(nbIssues);\n\n    // Confirm an issue\n    adminIssueClient().doTransition(IssueTestSuite.searchIssues().iterator().next().key(), \"confirm\");\n\n    // Apply a bulk change on unconfirm transition\n    BulkChangeQuery query = (BulkChangeQuery.create()\n      .issues(issueKeys)\n      .actions(\"do_transition\")\n      .actionParameter(\"do_transition\", \"transition\", \"unconfirm\")\n      .comment(\"this is my comment\")\n      );\n    BulkChange bulkChange = adminIssueClient().bulkChange(query);\n    assertThat(bulkChange.totalIssuesChanged()).isEqualTo(1);\n\n    int nbIssuesWithComment = 0;\n    for (Issue issue : IssueTestSuite.searchIssues(issueKeys, true)) {\n      if (!issue.comments().isEmpty()) {\n        nbIssuesWithComment++;\n      }\n    }\n    // Only one issue should have the comment\n    assertThat(nbIssuesWithComment).isEqualTo(1);\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Before\n  public void resetData() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueChangelogTest/one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"one-issue-per-line\");\n    scan = SonarRunner.create(projectDir(\"shared/xoo-sample\"));\n    orchestrator.executeBuild(scan);\n    issue = searchRandomIssue();\n  }","id":37028,"modified_method":"@Before\n  public void resetData() {\n    orchestrator.resetData();\n    orchestrator.getServer().restoreProfile(FileLocation.ofClasspath(\"/issue/suite/IssueChangelogTest/one-issue-per-line-profile.xml\"));\n    orchestrator.getServer().provisionProject(\"sample\", \"Sample\");\n    orchestrator.getServer().associateProjectToQualityProfile(\"sample\", \"xoo\", \"one-issue-per-line\");\n    scan = runProjectAnalysis(orchestrator, \"shared/xoo-sample\");\n    issue = searchRandomIssue();\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"static List<Issue> searchIssues(IssueQuery issueQuery) {\n    return search(issueQuery).list();\n  }","id":37029,"modified_method":"static List<Issue> searchIssues(IssueQuery issueQuery) {\n    return issueClient().find(issueQuery).list();\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n   * Locate the pom file of a sample project\n   *\n   * @param relativePath project path related to the directory it/it-projects, for example \"qualitygate/xoo-sample\"\n   */\n  public static File projectPom(String projectName) {\n    File pom = new File(projectDir(projectName), \"pom.xml\");\n    if (!pom.exists() || !pom.isFile()) {\n      throw new IllegalStateException(\"pom file does not exist: \" + pom.getAbsolutePath());\n    }\n    return pom;\n  }","id":37030,"modified_method":"/**\n   * Locate the pom file of a sample project\n   *\n   * @param projectName project path related to the directory it/it-projects, for example \"qualitygate/xoo-sample\"\n   */\n  public static File projectPom(String projectName) {\n    File pom = new File(projectDir(projectName), \"pom.xml\");\n    if (!pom.exists() || !pom.isFile()) {\n      throw new IllegalStateException(\"pom file does not exist: \" + pom.getAbsolutePath());\n    }\n    return pom;\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n   * Concatenates a vararg to a String array.\n   *\n   * Useful when using {@link #runProjectAnalysis(Orchestrator, String, String...)}, eg.:\n   * <pre>\n   * ItUtils.runProjectAnalysis(orchestrator, \"project_name\",\n   *    ItUtils.concat(properties, \"sonar.scm.disabled\", \"false\")\n   *    );\n   * <\/pre>\n   */\n  public static String[] concat(String[] properties, String... str) {\n    if (properties == null || properties.length == 0) {\n      return str;\n    }\n    return from(Iterables.concat(asList(properties), asList(str))).toArray(String.class);\n  }","id":37031,"modified_method":"/**\n   * Concatenates a vararg to a String array.\n   *\n   * Useful when using {@link #runVerboseProjectAnalysis(Orchestrator, String, String...)}, eg.:\n   * <pre>\n   * ItUtils.runProjectAnalysis(orchestrator, \"project_name\",\n   *    ItUtils.concat(properties, \"sonar.scm.disabled\", \"false\")\n   *    );\n   * <\/pre>\n   */\n  public static String[] concat(String[] properties, String... str) {\n    if (properties == null || properties.length == 0) {\n      return str;\n    }\n    return from(Iterables.concat(asList(properties), asList(str))).toArray(String.class);\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public static void runProjectAnalysis(Orchestrator orchestrator, String projectRelativePath, String... properties) {\n    SonarRunner sonarRunner = SonarRunner.create(projectDir(projectRelativePath));\n    ImmutableMap.Builder<String, String> builder = ImmutableMap.builder();\n    for (int i = 0; i < properties.length; i+=2) {\n      builder.put(properties[i], properties[i+1]);\n    }\n    orchestrator.executeBuild(sonarRunner.setDebugLogs(true).setProperties(builder.build()));\n  }","id":37032,"modified_method":"public static SonarRunner runProjectAnalysis(Orchestrator orchestrator, String projectRelativePath, String... properties) {\n    return runProjectAnalysis(orchestrator, projectRelativePath, false, properties);\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void runSampleProjectAnalysis(String projectVersion, String... properties) {\n    ItUtils.runProjectAnalysis(\n      NewDebtRatioMeasureTest.orchestrator,\n      \"measure/xoo-new-debt-ratio-\" + projectVersion,\n      ItUtils.concat(properties,\n        // disable standard scm support so that it does not interfere with Xoo Scm sensor\n        \"sonar.scm.disabled\", \"false\")\n      );\n  }","id":37033,"modified_method":"private void runSampleProjectAnalysis(String projectVersion, String... properties) {\n    ItUtils.runVerboseProjectAnalysis(\n        NewDebtRatioMeasureTest.orchestrator,\n        \"measure/xoo-new-debt-ratio-\" + projectVersion,\n        ItUtils.concat(properties,\n            // disable standard scm support so that it does not interfere with Xoo Scm sensor\n            \"sonar.scm.disabled\", \"false\")\n    );\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void runSampleProjectAnalysis(String... properties) {\n    ItUtils.runProjectAnalysis(TechnicalDebtMeasureVariationTest.orchestrator, \"shared/xoo-sample\", properties);\n  }","id":37034,"modified_method":"private void runSampleProjectAnalysis(String... properties) {\n    ItUtils.runVerboseProjectAnalysis(TechnicalDebtMeasureVariationTest.orchestrator, \"shared/xoo-sample\", properties);\n  }","commit_id":"0235ff6fffe8a45bfb5b82eb4c6d8aeb2b7eccf9","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public void doLeftInserts(ConditionalBranchNode branchNode,\n                              ConditionalBranchMemory cbm,\n                              LeftTupleSink sink,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              RuleExecutor executor) {\n        ConditionalBranchEvaluator branchEvaluator = branchNode.getBranchEvaluator();\n\n        RuleAgendaItem ruleAgendaItem = executor.getRuleAgendaItem();\n        int salienceInt = 0;\n        Salience salience = ruleAgendaItem.getRule().getSalience();\n        if ( !salience.isDynamic() ) {\n            salienceInt = ruleAgendaItem.getRule().getSalience().getValue();\n            salience = null;\n        }\n\n        for (LeftTuple leftTuple = srcLeftTuples.getInsertFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n            boolean breaking = false;\n            ConditionalExecution conditionalExecution = branchEvaluator.evaluate(leftTuple, wm, cbm.context);\n\n            boolean useLeftMemory = RuleNetworkEvaluator.useLeftMemory(branchNode, leftTuple);\n\n            if (conditionalExecution != null) {\n                RuleTerminalNode rtn = (RuleTerminalNode) conditionalExecution.getSink().getFirstLeftTupleSink();\n                LeftTuple branchedLeftTuple = rtn.createLeftTuple(leftTuple,\n                                                                  rtn,\n                                                                  leftTuple.getPropagationContext(), useLeftMemory);\n                PhreakRuleTerminalNode.doLeftTupleInsert( rtn, executor, (InternalAgenda) wm.getAgenda(),\n                                                          executor.getRuleAgendaItem(), salienceInt, salience, branchedLeftTuple, wm) ;\n                breaking = conditionalExecution.isBreaking();\n            }\n\n            if (!breaking) {\n                trgLeftTuples.addInsert(sink.createLeftTuple(leftTuple,\n                                                             sink,\n                                                             leftTuple.getPropagationContext(), useLeftMemory));\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","id":37035,"modified_method":"public void doLeftInserts(ConditionalBranchNode branchNode,\n                              ConditionalBranchMemory cbm,\n                              LeftTupleSink sink,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              RuleExecutor executor) {\n        ConditionalBranchEvaluator branchEvaluator = branchNode.getBranchEvaluator();\n\n        RuleAgendaItem ruleAgendaItem = executor.getRuleAgendaItem();\n        int salienceInt = 0;\n        Salience salience = ruleAgendaItem.getRule().getSalience();\n        if ( !salience.isDynamic() ) {\n            salienceInt = ruleAgendaItem.getRule().getSalience().getValue();\n            salience = null;\n        }\n\n        for (LeftTuple leftTuple = srcLeftTuples.getInsertFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n            boolean breaking = false;\n            ConditionalExecution conditionalExecution = branchEvaluator.evaluate(leftTuple, wm, cbm.context);\n\n            boolean useLeftMemory = RuleNetworkEvaluator.useLeftMemory(branchNode, leftTuple);\n\n            if (conditionalExecution != null) {\n                RuleTerminalNode rtn = (RuleTerminalNode) conditionalExecution.getSink().getFirstLeftTupleSink();\n                LeftTuple branchedLeftTuple = rtn.createLeftTuple(leftTuple,\n                                                                  rtn,\n                                                                  leftTuple.getPropagationContext(), useLeftMemory);\n                PhreakRuleTerminalNode.doLeftTupleInsert( rtn, executor, wm.getAgenda(),\n                                                          executor.getRuleAgendaItem(), salienceInt, salience, branchedLeftTuple, wm) ;\n                breaking = conditionalExecution.isBreaking();\n            }\n\n            if (!breaking) {\n                trgLeftTuples.addInsert(sink.createLeftTuple(leftTuple,\n                                                             sink,\n                                                             leftTuple.getPropagationContext(), useLeftMemory));\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","commit_id":"f9c7bbf234bde0ea4e906853930aa121c79febf7","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void doLeftUpdates(ConditionalBranchNode branchNode,\n                              ConditionalBranchMemory cbm,\n                              LeftTupleSink sink,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              TupleSets<LeftTuple> stagedLeftTuples,\n                              RuleExecutor executor) {\n        ConditionalBranchEvaluator branchEvaluator = branchNode.getBranchEvaluator();\n        RuleAgendaItem ruleAgendaItem = executor.getRuleAgendaItem();\n        int salienceInt = 0;\n        Salience salience = ruleAgendaItem.getRule().getSalience();\n        if ( !salience.isDynamic() ) {\n            salienceInt = ruleAgendaItem.getRule().getSalience().getValue();\n            salience = null;\n        }\n\n        for (LeftTuple leftTuple = srcLeftTuples.getUpdateFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n\n            LeftTuple rtnLeftTuple = null;\n            LeftTuple mainLeftTuple = null;\n            LeftTuple child = leftTuple.getFirstChild();\n            if ( child != null ) {\n                // assigns the correct main or rtn LeftTuple based on the identified sink\n                if ( child.getTupleSink() == sink ) {\n                    mainLeftTuple = child;\n                } else {\n                    rtnLeftTuple = child;\n                }\n                child = child.getHandleNext();\n                if ( child != null ) {\n                    if ( child.getTupleSink() == sink ) {\n                        mainLeftTuple = child;\n                    } else {\n                        rtnLeftTuple = child;\n                    }\n                }\n            }\n\n            RuleTerminalNode oldRtn = null;\n            if (rtnLeftTuple != null) {\n                oldRtn = (RuleTerminalNode) rtnLeftTuple.getTupleSink();\n            }\n\n            ConditionalExecution conditionalExecution = branchEvaluator.evaluate(leftTuple, wm, cbm.context);\n\n            RuleTerminalNode newRtn = null;\n            boolean breaking = false;\n            if (conditionalExecution != null) {\n                newRtn = (RuleTerminalNode) conditionalExecution.getSink().getFirstLeftTupleSink();\n                breaking = conditionalExecution.isBreaking();\n            }\n\n            // Handle conditional branches\n            if (oldRtn != null) {\n                if (newRtn == null) {\n                    // old exits, new does not, so delete\n                    if ( rtnLeftTuple.getMemory() != null ) {\n                        executor.removeLeftTuple(rtnLeftTuple);\n                    }\n                    PhreakRuleTerminalNode.doLeftDelete(wm, executor, rtnLeftTuple);\n\n                } else if (newRtn == oldRtn) {\n                    // old and new on same branch, so update\n                    PhreakRuleTerminalNode.doLeftTupleUpdate(newRtn, executor, (InternalAgenda) wm.getAgenda(), salienceInt, salience, rtnLeftTuple, wm) ;\n\n                } else {\n                    // old and new on different branches, delete one and insert the other\n                    if ( rtnLeftTuple.getMemory() != null ) {\n                        executor.removeLeftTuple(rtnLeftTuple);\n                    }\n                    PhreakRuleTerminalNode.doLeftDelete(wm, executor, rtnLeftTuple);\n\n                    rtnLeftTuple = newRtn.createLeftTuple(leftTuple,\n                                                          newRtn,\n                                                          leftTuple.getPropagationContext(), true);\n                    PhreakRuleTerminalNode.doLeftTupleInsert( newRtn, executor, (InternalAgenda) wm.getAgenda(),\n                                                              executor.getRuleAgendaItem(), salienceInt, salience, rtnLeftTuple, wm) ;\n                }\n\n            } else if (newRtn != null) {\n                // old does not exist, new exists, so insert\n                rtnLeftTuple = newRtn.createLeftTuple(leftTuple, newRtn,\n                                                                     leftTuple.getPropagationContext(), true);\n                PhreakRuleTerminalNode.doLeftTupleInsert( newRtn, executor, (InternalAgenda) wm.getAgenda(),\n                                                          executor.getRuleAgendaItem(), salienceInt, salience, rtnLeftTuple, wm) ;\n            }\n\n            // Handle main branch\n            if (mainLeftTuple != null) {\n                switch (mainLeftTuple.getStagedType()) {\n                    // handle clash with already staged entries\n                    case LeftTuple.INSERT:\n                        stagedLeftTuples.removeInsert(mainLeftTuple);\n                        break;\n                    case LeftTuple.UPDATE:\n                        stagedLeftTuples.removeUpdate(mainLeftTuple);\n                        break;\n                }\n\n                if (!breaking) {\n                    // child exist, new one does, so update\n                    trgLeftTuples.addUpdate(mainLeftTuple);\n                } else {\n                    // child exist, new one does not, so delete\n                    trgLeftTuples.addDelete(mainLeftTuple);\n                }\n            } else if (!breaking) {\n                // child didn't exist, new one does, so insert\n                trgLeftTuples.addInsert(sink.createLeftTuple(leftTuple,\n                                                             sink,\n                                                             leftTuple.getPropagationContext(), true));\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","id":37036,"modified_method":"public void doLeftUpdates(ConditionalBranchNode branchNode,\n                              ConditionalBranchMemory cbm,\n                              LeftTupleSink sink,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              TupleSets<LeftTuple> stagedLeftTuples,\n                              RuleExecutor executor) {\n        ConditionalBranchEvaluator branchEvaluator = branchNode.getBranchEvaluator();\n        RuleAgendaItem ruleAgendaItem = executor.getRuleAgendaItem();\n        int salienceInt = 0;\n        Salience salience = ruleAgendaItem.getRule().getSalience();\n        if ( !salience.isDynamic() ) {\n            salienceInt = ruleAgendaItem.getRule().getSalience().getValue();\n            salience = null;\n        }\n\n        for (LeftTuple leftTuple = srcLeftTuples.getUpdateFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n\n            BranchTuples branchTuples = getBranchTuples(sink, leftTuple);\n\n            RuleTerminalNode oldRtn = null;\n            if (branchTuples.rtnLeftTuple != null) {\n                oldRtn = branchTuples.rtnLeftTuple.getTupleSink();\n            }\n\n            ConditionalExecution conditionalExecution = branchEvaluator.evaluate(leftTuple, wm, cbm.context);\n\n            RuleTerminalNode newRtn = null;\n            boolean breaking = false;\n            if (conditionalExecution != null) {\n                newRtn = (RuleTerminalNode) conditionalExecution.getSink().getFirstLeftTupleSink();\n                breaking = conditionalExecution.isBreaking();\n            }\n\n            // Handle conditional branches\n            if (oldRtn != null) {\n                if (newRtn == null) {\n                    // old exits, new does not, so delete\n                    if ( branchTuples.rtnLeftTuple.getMemory() != null ) {\n                        executor.removeLeftTuple(branchTuples.rtnLeftTuple);\n                    }\n                    PhreakRuleTerminalNode.doLeftDelete(wm, executor, branchTuples.rtnLeftTuple);\n\n                } else if (newRtn == oldRtn) {\n                    // old and new on same branch, so update\n                    PhreakRuleTerminalNode.doLeftTupleUpdate(newRtn, executor, wm.getAgenda(), salienceInt, salience, branchTuples.rtnLeftTuple, wm) ;\n\n                } else {\n                    // old and new on different branches, delete one and insert the other\n                    if ( branchTuples.rtnLeftTuple.getMemory() != null ) {\n                        executor.removeLeftTuple(branchTuples.rtnLeftTuple);\n                    }\n                    PhreakRuleTerminalNode.doLeftDelete(wm, executor, branchTuples.rtnLeftTuple);\n\n                    branchTuples.rtnLeftTuple = newRtn.createLeftTuple(leftTuple,\n                                                                       newRtn,\n                                                                       leftTuple.getPropagationContext(), true);\n                    PhreakRuleTerminalNode.doLeftTupleInsert( newRtn, executor, wm.getAgenda(),\n                                                              executor.getRuleAgendaItem(), salienceInt, salience, branchTuples.rtnLeftTuple, wm) ;\n                }\n\n            } else if (newRtn != null) {\n                // old does not exist, new exists, so insert\n                branchTuples.rtnLeftTuple = newRtn.createLeftTuple(leftTuple, newRtn,\n                                                                   leftTuple.getPropagationContext(), true);\n                PhreakRuleTerminalNode.doLeftTupleInsert( newRtn, executor, wm.getAgenda(),\n                                                          executor.getRuleAgendaItem(), salienceInt, salience, branchTuples.rtnLeftTuple, wm) ;\n            }\n\n            // Handle main branch\n            if (branchTuples.mainLeftTuple != null) {\n                switch (branchTuples.mainLeftTuple.getStagedType()) {\n                    // handle clash with already staged entries\n                    case LeftTuple.INSERT:\n                        stagedLeftTuples.removeInsert(branchTuples.mainLeftTuple);\n                        break;\n                    case LeftTuple.UPDATE:\n                        stagedLeftTuples.removeUpdate(branchTuples.mainLeftTuple);\n                        break;\n                }\n\n                if (!breaking) {\n                    // child exist, new one does, so update\n                    trgLeftTuples.addUpdate(branchTuples.mainLeftTuple);\n                } else {\n                    // child exist, new one does not, so delete\n                    trgLeftTuples.addDelete(branchTuples.mainLeftTuple);\n                }\n            } else if (!breaking) {\n                // child didn't exist, new one does, so insert\n                trgLeftTuples.addInsert(sink.createLeftTuple(leftTuple,\n                                                             sink,\n                                                             leftTuple.getPropagationContext(), true));\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","commit_id":"f9c7bbf234bde0ea4e906853930aa121c79febf7","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void doLeftDeletes(ConditionalBranchNode branchNode,\n                              ConditionalBranchMemory cbm,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              TupleSets<LeftTuple> stagedLeftTuples,\n                              RuleExecutor executor) {\n        for (LeftTuple leftTuple = srcLeftTuples.getDeleteFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n            Tuple rtnLeftTuple = (Tuple) leftTuple.getContextObject();\n            LeftTuple mainLeftTuple = leftTuple.getFirstChild();\n\n            if (rtnLeftTuple != null) {\n                if ( rtnLeftTuple.getMemory() != null ) {\n                    executor.removeLeftTuple(rtnLeftTuple);\n                }\n                PhreakRuleTerminalNode.doLeftDelete(wm, executor, rtnLeftTuple);\n            }\n\n            if (mainLeftTuple != null) {\n                RuleNetworkEvaluator.deleteChildLeftTuple(mainLeftTuple, trgLeftTuples, stagedLeftTuples);\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","id":37037,"modified_method":"public void doLeftDeletes(LeftTupleSink sink,\n                              InternalWorkingMemory wm,\n                              TupleSets<LeftTuple> srcLeftTuples,\n                              TupleSets<LeftTuple> trgLeftTuples,\n                              TupleSets<LeftTuple> stagedLeftTuples,\n                              RuleExecutor executor) {\n        for (LeftTuple leftTuple = srcLeftTuples.getDeleteFirst(); leftTuple != null; ) {\n            LeftTuple next = leftTuple.getStagedNext();\n\n            BranchTuples branchTuples = getBranchTuples(sink, leftTuple);\n\n            if (branchTuples.rtnLeftTuple != null) {\n                if ( branchTuples.rtnLeftTuple.getMemory() != null ) {\n                    executor.removeLeftTuple(branchTuples.rtnLeftTuple);\n                }\n                PhreakRuleTerminalNode.doLeftDelete(wm, executor, branchTuples.rtnLeftTuple);\n            }\n\n            if (branchTuples.mainLeftTuple != null) {\n                RuleNetworkEvaluator.deleteChildLeftTuple(branchTuples.mainLeftTuple, trgLeftTuples, stagedLeftTuples);\n            }\n\n            leftTuple.clearStaged();\n            leftTuple = next;\n        }\n    }","commit_id":"f9c7bbf234bde0ea4e906853930aa121c79febf7","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void doNode(ConditionalBranchNode branchNode,\n                       ConditionalBranchMemory cbm,\n                       LeftTupleSink sink,\n                       InternalWorkingMemory wm,\n                       TupleSets<LeftTuple> srcLeftTuples,\n                       TupleSets<LeftTuple> trgLeftTuples,\n                       TupleSets<LeftTuple> stagedLeftTuples,\n                       RuleExecutor executor) {\n\n        if (srcLeftTuples.getDeleteFirst() != null) {\n            doLeftDeletes(branchNode, cbm, wm, srcLeftTuples, trgLeftTuples, stagedLeftTuples, executor);\n        }\n\n        if (srcLeftTuples.getUpdateFirst() != null) {\n            doLeftUpdates(branchNode, cbm, sink, wm, srcLeftTuples, trgLeftTuples, stagedLeftTuples, executor);\n        }\n\n        if (srcLeftTuples.getInsertFirst() != null) {\n            doLeftInserts(branchNode, cbm, sink, wm, srcLeftTuples, trgLeftTuples, executor);\n        }\n\n        srcLeftTuples.resetAll();\n    }","id":37038,"modified_method":"public void doNode(ConditionalBranchNode branchNode,\n                       ConditionalBranchMemory cbm,\n                       LeftTupleSink sink,\n                       InternalWorkingMemory wm,\n                       TupleSets<LeftTuple> srcLeftTuples,\n                       TupleSets<LeftTuple> trgLeftTuples,\n                       TupleSets<LeftTuple> stagedLeftTuples,\n                       RuleExecutor executor) {\n\n        if (srcLeftTuples.getDeleteFirst() != null) {\n            doLeftDeletes(sink, wm, srcLeftTuples, trgLeftTuples, stagedLeftTuples, executor);\n        }\n\n        if (srcLeftTuples.getUpdateFirst() != null) {\n            doLeftUpdates(branchNode, cbm, sink, wm, srcLeftTuples, trgLeftTuples, stagedLeftTuples, executor);\n        }\n\n        if (srcLeftTuples.getInsertFirst() != null) {\n            doLeftInserts(branchNode, cbm, sink, wm, srcLeftTuples, trgLeftTuples, executor);\n        }\n\n        srcLeftTuples.resetAll();\n    }","commit_id":"f9c7bbf234bde0ea4e906853930aa121c79febf7","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\r\n        id  = (AtomicInteger) in.readObject();\r\n        counter = (AtomicLong) in.readObject();\r\n    }","id":37039,"modified_method":"public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\r\n        this.id = new AtomicInteger( in.readInt() );\r\n        this.counter = new AtomicLong( in.readLong() );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void writeExternal(ObjectOutput out) throws IOException {\r\n        out.writeObject(id);\r\n        out.writeObject(counter);\r\n    }","id":37040,"modified_method":"public void writeExternal(ObjectOutput out) throws IOException {\r\n        out.writeInt(id.get());\r\n        out.writeLong(counter.get());\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void readFactHandles(WMSerialisationInContext context) throws IOException,\r\n                                                                        ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        \r\n        PlaceholderResolverStrategyFactory resolverStrategyFactory = context.resolverStrategyFactory;\r\n\r\n        ReteooFactHandleFactory factHandleFactory = new ReteooFactHandleFactory();\r\n        factHandleFactory.readExternal( stream );\r\n        context.wm = new ReteooWorkingMemory( 0,\r\n                                              ruleBase,\r\n                                              factHandleFactory );\r\n\r\n        int size = stream.readInt();\r\n\r\n        if ( size == 0 ) {\r\n            return;\r\n        }\r\n\r\n        // load the handles\r\n        InternalFactHandle[] handles = new InternalFactHandle[size];\r\n        for ( int i = 0; i < size; i++ ) {\r\n            int id = stream.readInt();\r\n            long recency = stream.readLong();\r\n            PlaceholderResolverStrategy strategy = resolverStrategyFactory.get( null );\r\n//            ObjectPlaceholder placeHolder = strategy.read( stream );\r\n//\r\n//            Object object = placeHolder.resolveObject();\r\n            Object object = null;\r\n            InternalFactHandle handle = new DefaultFactHandle( id,\r\n                                                               object,\r\n                                                               recency );\r\n            context.handles.put( id,\r\n                                 handle );\r\n            handles[i] = handle;\r\n\r\n            context.wm.getObjectStore().addHandle( handle,\r\n                                                   object );\r\n\r\n            int type = stream.readInt();\r\n            if ( type == PersisterEnums.RIGHT_TUPLE ) {\r\n                type = PersisterEnums.REPEAT;\r\n                while ( type == PersisterEnums.REPEAT ) {\r\n                    readRightTuple( context,\r\n                                    handle );\r\n                    type = stream.readInt();\r\n                }\r\n            }\r\n        }\r\n\r\n        EntryPointNode node = ruleBase.getRete().getEntryPointNode( EntryPoint.DEFAULT );\r\n        Map<ObjectType, ObjectTypeNode> objectTypeNodes = node.getObjectTypeNodes();\r\n\r\n        // add handles to object type nodes\r\n        for ( InternalFactHandle handle : handles ) {\r\n            Object object = handle.getObject();\r\n            ClassObjectType objectType = new ClassObjectType( object.getClass() );\r\n            ObjectTypeNode objectTypeNode = objectTypeNodes.get( objectType );\r\n            ObjectHashSet set = (ObjectHashSet) context.wm.getNodeMemory( objectTypeNode );\r\n            set.add( handle,\r\n                     false );\r\n        }\r\n\r\n        //        type = stream.readInt();\r\n        //        if ( type == PersisterEnums.LEFT_TUPLE ) {\r\n        //            type = PersisterEnums.REPEAT;\r\n        //            while ( type == PersisterEnums.REPEAT ) {\r\n        //                LeftTupleSink sink = (LeftTupleSink) sinks.get( stream.readInt() );\r\n        //                int factHandleId = stream.readInt();\r\n        //                LeftTuple leftTuple = new LeftTuple( context.handles[factHandleId],\r\n        //                                                     sink,\r\n        //                                                     true );\r\n        //                readLeftTuple( leftTuple,\r\n        //                               context );\r\n        //            }\r\n        //        }\r\n        //\r\n        //        readPropagationContexts( context );\r\n\r\n        //        readActivations( context );        \r\n    }","id":37041,"modified_method":"public static void readFactHandles(WMSerialisationInContext context) throws IOException,\r\n                                                                        ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n\r\n        PlaceholderResolverStrategyFactory resolverStrategyFactory = context.resolverStrategyFactory;\r\n\r\n        ReteooFactHandleFactory factHandleFactory = new ReteooFactHandleFactory();\r\n        factHandleFactory.readExternal( stream );\r\n        context.wm = new ReteooWorkingMemory( 0,\r\n                                              ruleBase,\r\n                                              factHandleFactory );\r\n\r\n        int size = stream.readInt();\r\n\r\n        if ( size == 0 ) {\r\n            return;\r\n        }\r\n\r\n        // load the handles\r\n        InternalFactHandle[] handles = new InternalFactHandle[size];\r\n        for ( int i = 0; i < size; i++ ) {\r\n            int id = stream.readInt();\r\n            long recency = stream.readLong();\r\n            PlaceholderResolverStrategy strategy = resolverStrategyFactory.get( null );\r\n            ObjectPlaceholder placeHolder = strategy.read( stream );\r\n\r\n            Object object = placeHolder.resolveObject();\r\n\r\n            InternalFactHandle handle = new DefaultFactHandle( id,\r\n                                                               object,\r\n                                                               recency );\r\n            context.handles.put( id,\r\n                                 handle );\r\n            handles[i] = handle;\r\n\r\n            context.wm.getObjectStore().addHandle( handle,\r\n                                                   object );\r\n\r\n            int type = stream.readInt();\r\n            if ( type == PersisterEnums.RIGHT_TUPLE ) {\r\n                type = PersisterEnums.REPEAT;\r\n                while ( type == PersisterEnums.REPEAT ) {\r\n                    readRightTuple( context,\r\n                                    handle );\r\n                    type = stream.readInt();\r\n                }\r\n            }\r\n        }\r\n\r\n        EntryPointNode node = ruleBase.getRete().getEntryPointNode( EntryPoint.DEFAULT );\r\n        Map<ObjectType, ObjectTypeNode> objectTypeNodes = node.getObjectTypeNodes();\r\n\r\n        // add handles to object type nodes\r\n        for ( InternalFactHandle handle : handles ) {\r\n            Object object = handle.getObject();\r\n            ClassObjectType objectType = new ClassObjectType( object.getClass() );\r\n            ObjectTypeNode objectTypeNode = objectTypeNodes.get( objectType );\r\n            ObjectHashSet set = (ObjectHashSet) context.wm.getNodeMemory( objectTypeNode );\r\n            set.add( handle,\r\n                     false );\r\n        }\r\n\r\n        readLeftTuples( context );\r\n\r\n        readPropagationContexts( context );\r\n\r\n        readActivations( context );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void readActivations(WMSerialisationInContext context) throws IOException,\r\n                                                                        ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n\r\n        int type = stream.readInt();\r\n        if ( type == PersisterEnums.ACTIVATION ) {\r\n            type = PersisterEnums.REPEAT;\r\n            while ( type == PersisterEnums.REPEAT ) {\r\n                readActivation( context );\r\n            }\r\n        }\r\n    }","id":37042,"modified_method":"public static void readActivations(WMSerialisationInContext context) throws IOException {\r\n        ObjectInputStream stream = context.stream;\r\n\r\n        while ( stream.readInt() == PersisterEnums.ACTIVATION ) {\r\n            readActivation( context );\r\n        }\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void readLeftTuple(LeftTuple parentLeftTuple,\r\n                                     WMSerialisationInContext context) throws IOException,\r\n                                                                      ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n        Map<Integer, BaseNode> sinks = context.sinks;\r\n\r\n        LeftTupleSink sink = parentLeftTuple.getLeftTupleSink();\r\n\r\n        if ( sink instanceof JoinNode ) {\r\n            BetaMemory memory = (BetaMemory) context.wm.getNodeMemory( (BetaNode) sink );\r\n            memory.getLeftTupleMemory().add( parentLeftTuple );\r\n\r\n            int type = stream.readInt();\r\n            if ( type == PersisterEnums.RIGHT_TUPLE ) {\r\n                type = PersisterEnums.REPEAT;\r\n                while ( type == PersisterEnums.REPEAT ) {\r\n                    LeftTupleSink childSink = (LeftTupleSink) sinks.get( stream.readInt() );\r\n                    int factHandleId = stream.readInt();\r\n                    RightTupleKey key = new RightTupleKey( factHandleId,\r\n                                                           sink );\r\n                    RightTuple rightTuple = context.rightTuples.get( key );\r\n                    LeftTuple childLeftTuple = new LeftTuple( parentLeftTuple,\r\n                                                              rightTuple,\r\n                                                              childSink,\r\n                                                              true );\r\n                    readLeftTuple( childLeftTuple,\r\n                                   context );\r\n                }\r\n            }\r\n        } else if ( sink instanceof NotNode ) {\r\n            BetaMemory memory = (BetaMemory) context.wm.getNodeMemory( (BetaNode) sink );\r\n            int type = stream.readInt();\r\n            if ( type == PersisterEnums.LEFT_TUPLE_NOT_BLOCKED ) {\r\n                memory.getLeftTupleMemory().add( parentLeftTuple );\r\n\r\n                type = stream.readInt();\r\n                if ( type == PersisterEnums.LEFT_TUPLE ) {\r\n                    type = PersisterEnums.REPEAT;\r\n                    while ( type == PersisterEnums.REPEAT ) {\r\n                        LeftTupleSink childSink = (LeftTupleSink) sinks.get( stream.readInt() );\r\n                        LeftTuple childLeftTuple = new LeftTuple( parentLeftTuple,\r\n                                                                  childSink,\r\n                                                                  true );\r\n                        readLeftTuple( childLeftTuple,\r\n                                       context );\r\n                    }\r\n                }\r\n            } else {\r\n                int factHandleId = stream.readInt();\r\n                RightTupleKey key = new RightTupleKey( factHandleId,\r\n                                                       sink );\r\n                RightTuple rightTuple = context.rightTuples.get( key );\r\n\r\n                LeftTuple blockedPrevious = rightTuple.getBlocked();\r\n                if ( blockedPrevious != null ) {\r\n                    parentLeftTuple.setBlockedNext( blockedPrevious );\r\n                    blockedPrevious.setBlockedPrevious( parentLeftTuple );\r\n                }\r\n                rightTuple.setBlocked( parentLeftTuple );\r\n            }\r\n        } else if ( sink instanceof RuleTerminalNode ) {\r\n            RuleTerminalNode ruleTerminalNode = (RuleTerminalNode) sink;\r\n            TerminalNodeMemory memory = (TerminalNodeMemory) wm.getNodeMemory( ruleTerminalNode );\r\n            memory.getTupleMemory().add( parentLeftTuple );\r\n\r\n            int pos = context.terminalTupleMap.size();\r\n            context.terminalTupleMap.put( pos,\r\n                                          parentLeftTuple );\r\n        }\r\n    }","id":37043,"modified_method":"public static void readLeftTuple(LeftTuple parentLeftTuple,\r\n                                     WMSerialisationInContext context) throws IOException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n        Map<Integer, BaseNode> sinks = context.sinks;\r\n\r\n        LeftTupleSink sink = parentLeftTuple.getLeftTupleSink();\r\n\r\n        if ( sink instanceof JoinNode ) {\r\n            BetaMemory memory = (BetaMemory) context.wm.getNodeMemory( (BetaNode) sink );\r\n            memory.getLeftTupleMemory().add( parentLeftTuple );\r\n\r\n            while ( stream.readInt() == PersisterEnums.RIGHT_TUPLE ) {\r\n                LeftTupleSink childSink = (LeftTupleSink) sinks.get( stream.readInt() );\r\n                int factHandleId = stream.readInt();\r\n                RightTupleKey key = new RightTupleKey( factHandleId,\r\n                                                       sink );\r\n                RightTuple rightTuple = context.rightTuples.get( key );\r\n                LeftTuple childLeftTuple = new LeftTuple( parentLeftTuple,\r\n                                                          rightTuple,\r\n                                                          childSink,\r\n                                                          true );\r\n                readLeftTuple( childLeftTuple,\r\n                               context );\r\n            }\r\n\r\n        } else if ( sink instanceof NotNode ) {\r\n            BetaMemory memory = (BetaMemory) context.wm.getNodeMemory( (BetaNode) sink );\r\n            int type = stream.readInt();\r\n            if ( type == PersisterEnums.LEFT_TUPLE_NOT_BLOCKED ) {\r\n                memory.getLeftTupleMemory().add( parentLeftTuple );\r\n\r\n                while ( stream.readInt() == PersisterEnums.LEFT_TUPLE ) {\r\n                    LeftTupleSink childSink = (LeftTupleSink) sinks.get( stream.readInt() );\r\n                    LeftTuple childLeftTuple = new LeftTuple( parentLeftTuple,\r\n                                                              childSink,\r\n                                                              true );\r\n                    readLeftTuple( childLeftTuple,\r\n                                   context );\r\n                }\r\n\r\n            } else {\r\n                int factHandleId = stream.readInt();\r\n                RightTupleKey key = new RightTupleKey( factHandleId,\r\n                                                       sink );\r\n                RightTuple rightTuple = context.rightTuples.get( key );\r\n\r\n                LeftTuple blockedPrevious = rightTuple.getBlocked();\r\n                if ( blockedPrevious != null ) {\r\n                    parentLeftTuple.setBlockedNext( blockedPrevious );\r\n                    blockedPrevious.setBlockedPrevious( parentLeftTuple );\r\n                }\r\n                rightTuple.setBlocked( parentLeftTuple );\r\n            }\r\n        } else if ( sink instanceof RuleTerminalNode ) {\r\n            RuleTerminalNode ruleTerminalNode = (RuleTerminalNode) sink;\r\n            TerminalNodeMemory memory = (TerminalNodeMemory) wm.getNodeMemory( ruleTerminalNode );\r\n            memory.getTupleMemory().add( parentLeftTuple );\r\n\r\n            int pos = context.terminalTupleMap.size();\r\n            context.terminalTupleMap.put( pos,\r\n                                          parentLeftTuple );\r\n        }\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static Activation readActivation(WMSerialisationInContext context) throws IOException,\r\n                                                                             ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n\r\n        long activationNumber = stream.readLong();\r\n\r\n        LeftTuple leftTuple = context.terminalTupleMap.get( stream.readInt() );\r\n\r\n        int salience = stream.readInt();\r\n\r\n        //PropagationContext context,\r\n        String pkgName = (String) stream.readObject();\r\n        String ruleName = (String) stream.readObject();\r\n        Package pkg = ruleBase.getPackage( pkgName );\r\n        Rule rule = pkg.getRule( ruleName );\r\n\r\n        RuleTerminalNode ruleTerminalNode = (RuleTerminalNode) context.sinks.get( stream.readInt() );\r\n        GroupElement subRule = ruleTerminalNode.getSubRule();\r\n\r\n        PropagationContext pc = context.propagationContexts.get( stream.readLong() );\r\n\r\n        AgendaItem activation = new AgendaItem( activationNumber,\r\n                                                leftTuple,\r\n                                                salience,\r\n                                                pc,\r\n                                                rule,\r\n                                                subRule );\r\n\r\n        boolean activated = stream.readBoolean();\r\n        activation.setActivated( activated );\r\n        if ( activated ) {\r\n            String agendaGroupName = (String) stream.readObject();\r\n            BinaryHeapQueue agendaGroup = (BinaryHeapQueue) ((DefaultAgenda) wm.getAgenda()).getAgendaGroup( agendaGroupName );\r\n            agendaGroup.enqueue( activation );\r\n        }\r\n\r\n        return activation;\r\n    }","id":37044,"modified_method":"public static Activation readActivation(WMSerialisationInContext context) throws IOException {\r\n        ObjectInputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n\r\n        long activationNumber = stream.readLong();\r\n\r\n        LeftTuple leftTuple = context.terminalTupleMap.get( stream.readInt() );\r\n\r\n        int salience = stream.readInt();\r\n\r\n        //PropagationContext context,\r\n        String pkgName = stream.readUTF();\r\n        String ruleName = stream.readUTF();\r\n        Package pkg = ruleBase.getPackage( pkgName );\r\n        Rule rule = pkg.getRule( ruleName );\r\n\r\n        RuleTerminalNode ruleTerminalNode = (RuleTerminalNode) leftTuple.getLeftTupleSink();\r\n        GroupElement subRule = ruleTerminalNode.getSubRule();\r\n\r\n        PropagationContext pc = context.propagationContexts.get( stream.readLong() );\r\n\r\n        AgendaItem activation = new AgendaItem( activationNumber,\r\n                                                leftTuple,\r\n                                                salience,\r\n                                                pc,\r\n                                                rule,\r\n                                                subRule );\r\n\r\n        boolean activated = stream.readBoolean();\r\n        activation.setActivated( activated );\r\n        if ( activated ) {\r\n            InternalAgendaGroup agendaGroup;\r\n            if ( rule.getAgendaGroup() == null || rule.getAgendaGroup().equals( \"\" ) || rule.getAgendaGroup().equals( AgendaGroup.MAIN ) ) {\r\n                // Is the Rule AgendaGroup undefined? If it is use MAIN,\r\n                // which is added to the Agenda by default\r\n                agendaGroup = (InternalAgendaGroup) wm.getAgenda().getAgendaGroup( AgendaGroup.MAIN );\r\n            } else {\r\n                // AgendaGroup is defined, so try and get the AgendaGroup\r\n                // from the Agenda\r\n                agendaGroup = (InternalAgendaGroup) wm.getAgenda().getAgendaGroup( rule.getAgendaGroup() );\r\n            }\r\n\r\n            agendaGroup.add( activation );\r\n        }\r\n\r\n        return activation;\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void readPropagationContexts(WMSerialisationInContext context) throws IOException,\r\n                                                                                ClassNotFoundException {\r\n        ObjectInputStream stream = context.stream;\r\n\r\n        int type = stream.readInt();\r\n        if ( type == PersisterEnums.PROPAGATION_CONTEXT ) {\r\n            type = PersisterEnums.REPEAT;\r\n            while ( type == PersisterEnums.REPEAT ) {\r\n                readPropagationContext( context );\r\n            }\r\n        }\r\n    }","id":37045,"modified_method":"public static void readPropagationContexts(WMSerialisationInContext context) throws IOException {\r\n        ObjectInputStream stream = context.stream;\r\n\r\n        while ( stream.readInt() == PersisterEnums.PROPAGATION_CONTEXT ) {\r\n            readPropagationContext( context );\r\n        }\r\n\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public InternalWorkingMemory read() throws IOException,\r\n                                       ClassNotFoundException {\r\n        readFactHandles( context );\r\n        return context.wm;\r\n    }","id":37046,"modified_method":"public InternalWorkingMemory read() throws IOException,\r\n                                       ClassNotFoundException {\r\n        readFactHandles( context );\r\n        context.stream.close();\r\n        return context.wm;\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writeActivations(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n        if ( !tuples.isEmpty() ) {\r\n            stream.writeInt( PersisterEnums.ACTIVATION );\r\n        }\r\n\r\n        int i = 0;\r\n        for ( LeftTuple leftTuple : tuples.keySet() ) {\r\n            if ( i != 0 ) {\r\n                stream.writeInt( PersisterEnums.REPEAT );\r\n            }\r\n            writeActivation( context,\r\n                             leftTuple,\r\n                             (AgendaItem) leftTuple.getActivation(),\r\n                             (RuleTerminalNode) leftTuple.getLeftTupleSink() );\r\n            i++;\r\n        }\r\n    }","id":37047,"modified_method":"public static void writeActivations(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n        if ( !tuples.isEmpty() ) {\r\n            for ( LeftTuple leftTuple : tuples.keySet() ) {\r\n                stream.writeInt( PersisterEnums.ACTIVATION );\r\n                writeActivation( context,\r\n                                 leftTuple,\r\n                                 (AgendaItem) leftTuple.getActivation(),\r\n                                 (RuleTerminalNode) leftTuple.getLeftTupleSink() );\r\n            }\r\n        }\r\n        stream.writeInt( PersisterEnums.END );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writePropagationContexts(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n        if ( !tuples.isEmpty() ) {\r\n            stream.writeInt( PersisterEnums.PROPAGATION_CONTEXT );\r\n        }\r\n\r\n        Map<Long, PropagationContext> pcMap = new HashMap<Long, PropagationContext>();\r\n\r\n        int i = 0;\r\n        for ( LeftTuple leftTuple : tuples.keySet() ) {\r\n            if ( i != 0 ) {\r\n                stream.writeInt( PersisterEnums.REPEAT );\r\n            }\r\n            PropagationContext pc = leftTuple.getActivation().getPropagationContext();\r\n            if ( !pcMap.containsKey( pc.getPropagationNumber() ) ) {\r\n                writePropagationContext( context,\r\n                                         pc );\r\n                pcMap.put( pc.getPropagationNumber(),\r\n                           pc );\r\n            }\r\n            i++;\r\n        }\r\n\r\n        stream.writeInt( PersisterEnums.END );\r\n    }","id":37048,"modified_method":"public static void writePropagationContexts(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n        if ( !tuples.isEmpty() ) {\r\n            Map<Long, PropagationContext> pcMap = new HashMap<Long, PropagationContext>();\r\n\r\n            for ( LeftTuple leftTuple : tuples.keySet() ) {\r\n                PropagationContext pc = leftTuple.getActivation().getPropagationContext();\r\n                if ( !pcMap.containsKey( pc.getPropagationNumber() ) ) {\r\n                    stream.writeInt( PersisterEnums.PROPAGATION_CONTEXT );\r\n                    writePropagationContext( context,\r\n                                             pc );\r\n                    pcMap.put( pc.getPropagationNumber(),\r\n                               pc );\r\n                }\r\n            }\r\n        }\r\n\r\n        stream.writeInt( PersisterEnums.END );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writePropagationContext(WMSerialisationOutContext context,\r\n                                               PropagationContext pc) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n\r\n        stream.writeInt( pc.getType() );\r\n\r\n        Rule ruleOrigin = pc.getRuleOrigin();\r\n        if ( ruleOrigin != null ) {\r\n            stream.writeBoolean( true );\r\n            stream.writeUTF( ruleOrigin.getPackage() );\r\n            stream.writeUTF( ruleOrigin.getName() );\r\n        } else {\r\n            stream.writeBoolean( false );\r\n        }\r\n\r\n        LeftTuple tupleOrigin = pc.getLeftTupleOrigin();\r\n        if ( tupleOrigin != null ) {\r\n            stream.writeBoolean( true );\r\n            stream.writeInt( tuples.get( tupleOrigin ) );\r\n        } else {\r\n            stream.writeBoolean( false );\r\n        }\r\n\r\n        stream.writeInt( pc.getFactHandleOrigin().getId() );\r\n\r\n        stream.writeInt( pc.getActiveActivations() );\r\n        stream.writeInt( pc.getDormantActivations() );\r\n\r\n        stream.writeUTF( pc.getEntryPoint().getEntryPointId() );\r\n    }","id":37049,"modified_method":"public static void writePropagationContext(WMSerialisationOutContext context,\r\n                                               PropagationContext pc) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        Map<LeftTuple, Integer> tuples = context.terminalTupleMap;\r\n\r\n        stream.writeInt( pc.getType() );\r\n\r\n        Rule ruleOrigin = pc.getRuleOrigin();\r\n        if ( ruleOrigin != null ) {\r\n            stream.writeBoolean( true );\r\n            stream.writeUTF( ruleOrigin.getPackage() );\r\n            stream.writeUTF( ruleOrigin.getName() );\r\n        } else {\r\n            stream.writeBoolean( false );\r\n        }\r\n\r\n        LeftTuple tupleOrigin = pc.getLeftTupleOrigin();\r\n        if ( tupleOrigin != null ) {\r\n            stream.writeBoolean( true );\r\n            stream.writeInt( tuples.get( tupleOrigin ) );\r\n        } else {\r\n            stream.writeBoolean( false );\r\n        }\r\n\r\n        stream.writeLong( pc.getPropagationNumber() );\r\n        stream.writeInt( pc.getFactHandleOrigin().getId() );\r\n\r\n        stream.writeInt( pc.getActiveActivations() );\r\n        stream.writeInt( pc.getDormantActivations() );\r\n\r\n        stream.writeUTF( pc.getEntryPoint().getEntryPointId() );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writeFactHandles(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        InternalWorkingMemory wm = context.wm;\r\n        PlaceholderResolverStrategyFactory resolverStrategyFactory = context.resolverStrategyFactory;\r\n\r\n        ((AbstractFactHandleFactory) wm.getFactHandleFactory()).writeExternal( stream );\r\n\r\n        stream.writeInt( wm.getObjectStore().size() );\r\n\r\n        // Write out FactHandles\r\n        for ( Iterator it = wm.getObjectStore().iterateFactHandles(); it.hasNext(); ) {\r\n            //stream.writeInt( PersisterEnums.FACT_HANDLE );\r\n            InternalFactHandle handle = (InternalFactHandle) it.next();\r\n            stream.writeInt( handle.getId() );\r\n            stream.writeLong( handle.getRecency() );\r\n\r\n            PlaceholderResolverStrategy strategy = resolverStrategyFactory.get( handle.getObject() );\r\n            //stream.writeInt( strategy.getId() );\r\n\r\n            Object object = handle.getObject();\r\n            if ( object instanceof ShadowProxy ) {\r\n                object = ((ShadowProxy) object).getShadowedObject();\r\n            }\r\n            strategy.write( stream,\r\n                            object );\r\n\r\n            // Write out RightTuples for FactHandle\r\n            if ( handle.getRightTuple() != null ) {\r\n                stream.writeInt( PersisterEnums.RIGHT_TUPLE );\r\n                int i = 0;\r\n                for ( RightTuple rightTuple = handle.getRightTuple(); rightTuple != null; rightTuple = (RightTuple) rightTuple.getHandleNext() ) {\r\n                    if ( i != 0 ) {\r\n                        stream.writeInt( PersisterEnums.REPEAT );\r\n                    }\r\n                    writeRightTuple( rightTuple,\r\n                                     context );\r\n                    i++;\r\n                }\r\n            }\r\n            stream.writeInt( PersisterEnums.END );\r\n        }\r\n\r\n        // Write out LeftTuples\r\n        for ( Iterator it = wm.getObjectStore().iterateFactHandles(); it.hasNext(); ) {\r\n            InternalFactHandle handle = (InternalFactHandle) it.next();\r\n\r\n            if ( handle.getLeftTuple() != null ) {\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE );\r\n                int i = 0;\r\n                for ( LeftTuple leftTuple = handle.getLeftTuple(); leftTuple != null; leftTuple = (LeftTuple) leftTuple.getLeftParentNext() ) {\r\n                    if ( i != 0 ) {\r\n                        stream.writeInt( PersisterEnums.REPEAT );\r\n                    }\r\n\r\n                    stream.writeInt( leftTuple.getLeftTupleSink().getId() );\r\n                    stream.writeInt( leftTuple.getLastHandle().getId() );\r\n\r\n                    writeLeftTuple( leftTuple,\r\n                                    context );\r\n                }\r\n                stream.writeInt( PersisterEnums.END );\r\n            }\r\n        }\r\n\r\n        writePropagationContexts( context );\r\n\r\n        writeActivations( context );\r\n\r\n        stream.writeInt( PersisterEnums.END );\r\n    }","id":37050,"modified_method":"public static void writeFactHandles(WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        InternalWorkingMemory wm = context.wm;\r\n        PlaceholderResolverStrategyFactory resolverStrategyFactory = context.resolverStrategyFactory;\r\n\r\n        ((AbstractFactHandleFactory) wm.getFactHandleFactory()).writeExternal( stream );\r\n\r\n        stream.writeInt( wm.getObjectStore().size() );\r\n\r\n        // Write out FactHandles\r\n        for ( Iterator it = wm.getObjectStore().iterateFactHandles(); it.hasNext(); ) {\r\n            //stream.writeInt( PersisterEnums.FACT_HANDLE );\r\n            InternalFactHandle handle = (InternalFactHandle) it.next();\r\n            stream.writeInt( handle.getId() );\r\n            stream.writeLong( handle.getRecency() );\r\n\r\n            PlaceholderResolverStrategy strategy = resolverStrategyFactory.get( handle.getObject() );\r\n            //stream.writeInt( strategy.getId() );\r\n\r\n            Object object = handle.getObject();\r\n            if ( object instanceof ShadowProxy ) {\r\n                object = ((ShadowProxy) object).getShadowedObject();\r\n            }\r\n            strategy.write( stream,\r\n                            object );\r\n\r\n            // Write out RightTuples for FactHandle\r\n            if ( handle.getRightTuple() != null ) {\r\n                stream.writeInt( PersisterEnums.RIGHT_TUPLE );\r\n                int i = 0;\r\n                for ( RightTuple rightTuple = handle.getRightTuple(); rightTuple != null; rightTuple = (RightTuple) rightTuple.getHandleNext() ) {\r\n                    if ( i != 0 ) {\r\n                        stream.writeInt( PersisterEnums.REPEAT );\r\n                    }\r\n                    writeRightTuple( rightTuple,\r\n                                     context );\r\n                    i++;\r\n                }\r\n            } else {\r\n                stream.writeInt( PersisterEnums.END );\r\n            }\r\n        }\r\n\r\n        writeLeftTuples( context );\r\n\r\n        writePropagationContexts( context );\r\n\r\n        writeActivations( context );\r\n\r\n        stream.writeInt( PersisterEnums.END );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writeLeftTuple(LeftTuple leftTuple,\r\n                                      WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n\r\n        LeftTupleSink sink = leftTuple.getLeftTupleSink();\r\n        stream.writeInt( sink.getId() );\r\n\r\n        if ( sink instanceof JoinNode ) {\r\n            if ( leftTuple.getBetaChildren() != null ) {\r\n                stream.writeInt( PersisterEnums.RIGHT_TUPLE );\r\n            }\r\n            int i = 0;\r\n            for ( LeftTuple childLeftTuple = leftTuple.getBetaChildren(); leftTuple != null; childLeftTuple = (LeftTuple) leftTuple.getLeftParentNext() ) {\r\n                if ( i != 0 ) {\r\n                    stream.writeInt( PersisterEnums.REPEAT );\r\n                }\r\n                stream.writeInt( childLeftTuple.getLeftTupleSink().getId() );\r\n                stream.writeInt( childLeftTuple.getRightParent().getFactHandle().getId() );\r\n                writeLeftTuple( childLeftTuple,\r\n                                context );\r\n            }\r\n            stream.writeInt( PersisterEnums.END );\r\n        } else if ( sink instanceof NotNode ) {\r\n            if ( leftTuple.getBlocker() == null ) {\r\n                // is blocked so has children\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE_NOT_BLOCKED );\r\n\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE );\r\n                int i = 0;\r\n                for ( LeftTuple childLeftTuple = leftTuple.getBetaChildren(); leftTuple != null; childLeftTuple = (LeftTuple) leftTuple.getLeftParentNext() ) {\r\n                    if ( i != 0 ) {\r\n                        stream.writeInt( PersisterEnums.REPEAT );\r\n                    }\r\n                    stream.writeInt( childLeftTuple.getLeftTupleSink().getId() );\r\n                    writeLeftTuple( childLeftTuple,\r\n                                    context );\r\n                }\r\n                stream.writeInt( PersisterEnums.END );\r\n\r\n            } else {\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE_BLOCKED );\r\n                stream.writeInt( leftTuple.getBlocker().getFactHandle().getId() );\r\n            }\r\n        } else if ( sink instanceof RuleTerminalNode ) {\r\n            int pos = context.terminalTupleMap.size();\r\n            context.terminalTupleMap.put( leftTuple,\r\n                                          pos );\r\n        }\r\n\r\n    }","id":37051,"modified_method":"public static void writeLeftTuple(LeftTuple leftTuple,\r\n                                      WMSerialisationOutContext context) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n        InternalRuleBase ruleBase = context.ruleBase;\r\n        InternalWorkingMemory wm = context.wm;\r\n\r\n        LeftTupleSink sink = leftTuple.getLeftTupleSink();\r\n\r\n        if ( sink instanceof JoinNode ) {\r\n            for ( LeftTuple childLeftTuple = leftTuple.getBetaChildren(); leftTuple != null; childLeftTuple = (LeftTuple) leftTuple.getLeftParentNext() ) {\r\n                stream.writeInt( PersisterEnums.RIGHT_TUPLE );\r\n                stream.writeInt( childLeftTuple.getLeftTupleSink().getId() );\r\n                stream.writeInt( childLeftTuple.getRightParent().getFactHandle().getId() );\r\n                writeLeftTuple( childLeftTuple,\r\n                                context );\r\n            }\r\n            stream.writeInt( PersisterEnums.END );\r\n        } else if ( sink instanceof NotNode ) {\r\n            if ( leftTuple.getBlocker() == null ) {\r\n                // is blocked so has children\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE_NOT_BLOCKED );\r\n\r\n                for ( LeftTuple childLeftTuple = leftTuple.getBetaChildren(); leftTuple != null; childLeftTuple = (LeftTuple) leftTuple.getLeftParentNext() ) {\r\n                    stream.writeInt( PersisterEnums.LEFT_TUPLE );\r\n                    stream.writeInt( childLeftTuple.getLeftTupleSink().getId() );\r\n                    writeLeftTuple( childLeftTuple,\r\n                                    context );\r\n                }\r\n                stream.writeInt( PersisterEnums.END );\r\n\r\n            } else {\r\n                stream.writeInt( PersisterEnums.LEFT_TUPLE_BLOCKED );\r\n                stream.writeInt( leftTuple.getBlocker().getFactHandle().getId() );\r\n            }\r\n        } else if ( sink instanceof RuleTerminalNode ) {\r\n            int pos = context.terminalTupleMap.size();\r\n            context.terminalTupleMap.put( leftTuple,\r\n                                          pos );\r\n        }\r\n\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public static void writeActivation(WMSerialisationOutContext context,\r\n                                       LeftTuple leftTuple,\r\n                                       AgendaItem agendaItem,\r\n                                       RuleTerminalNode ruleTerminalNode) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        stream.writeLong( agendaItem.getActivationNumber() );\r\n\r\n        stream.writeInt( context.terminalTupleMap.get( leftTuple ) );\r\n\r\n        stream.writeInt( agendaItem.getSalience() );\r\n\r\n        Rule rule = agendaItem.getRule();\r\n        stream.writeChars( rule.getPackage() );\r\n        stream.writeChars( rule.getName() );\r\n\r\n        stream.writeLong( agendaItem.getPropagationContext().getPropagationNumber() );\r\n\r\n        stream.writeInt( ruleTerminalNode.getId() );\r\n\r\n        stream.writeBoolean( agendaItem.isActivated() );\r\n    }","id":37052,"modified_method":"public static void writeActivation(WMSerialisationOutContext context,\r\n                                       LeftTuple leftTuple,\r\n                                       AgendaItem agendaItem,\r\n                                       RuleTerminalNode ruleTerminalNode) throws IOException {\r\n        ObjectOutputStream stream = context.stream;\r\n\r\n        stream.writeLong( agendaItem.getActivationNumber() );\r\n\r\n        stream.writeInt( context.terminalTupleMap.get( leftTuple ) );\r\n\r\n        stream.writeInt( agendaItem.getSalience() );\r\n\r\n        Rule rule = agendaItem.getRule();\r\n        stream.writeUTF( rule.getPackage() );\r\n        stream.writeUTF( rule.getName() );\r\n\r\n        stream.writeLong( agendaItem.getPropagationContext().getPropagationNumber() );\r\n\r\n        stream.writeBoolean( agendaItem.isActivated() );\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void write() throws IOException {\r\n        writeFactHandles( context );\r\n    }","id":37053,"modified_method":"public void write() throws IOException {\r\n        writeFactHandles( context );\r\n        context.stream.close();\r\n    }","commit_id":"72bdbf3b18bfd6411826fab967c843078dfebc54","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\n   * Returns the absolute path to this application, or {@code null} if the\n   * path cannot be evaluated.\n   * @return application path.\n   */\n  private static String applicationPath() {\n    final ProtectionDomain pd = Prop.class.getProtectionDomain();\n    if(pd == null) return null;\n    // raw application path\n    final String path = pd.getCodeSource().getLocation().getPath();\n    // decode path; URLDecode returns wrong results\n    final TokenBuilder tb = new TokenBuilder();\n    final int pl = path.length();\n    for(int p = 0; p < pl; ++p) {\n      final char ch = path.charAt(p);\n      if(ch == '%' && p + 2 < pl) {\n        tb.addByte((byte) Integer.parseInt(path.substring(p + 1, p + 3), 16));\n        p += 2;\n      } else {\n        tb.add(ch);\n      }\n    }\n    try {\n      // return path, using the correct encoding\n      return new String(tb.finish(), Prop.ENCODING);\n    } catch(final Exception ex) {\n      // use default path; not expected to occur\n      Util.stack(ex);\n      return tb.toString();\n    }\n  }","id":37054,"modified_method":"/**\n   * Returns the absolute path to this application, or {@code null} if the\n   * path cannot be evaluated.\n   * @return application path.\n   */\n  private static String applicationPath() {\n    final ProtectionDomain pd = Prop.class.getProtectionDomain();\n    if(pd == null) return null;\n    // code source (may be null)\n    final CodeSource cs = pd.getCodeSource();\n    if(cs == null) return null;\n    // raw application path\n    final String path = cs.getLocation().getPath();\n    // decode path; URLDecode returns wrong results\n    final TokenBuilder tb = new TokenBuilder();\n    final int pl = path.length();\n    for(int p = 0; p < pl; ++p) {\n      final char ch = path.charAt(p);\n      if(ch == '%' && p + 2 < pl) {\n        tb.addByte((byte) Integer.parseInt(path.substring(p + 1, p + 3), 16));\n        p += 2;\n      } else {\n        tb.add(ch);\n      }\n    }\n    try {\n      // return path, using the correct encoding\n      return new String(tb.finish(), Prop.ENCODING);\n    } catch(final Exception ex) {\n      // use default path; not expected to occur\n      Util.stack(ex);\n      return tb.toString();\n    }\n  }","commit_id":"bf3e779a4e3f4eb69e67f619ace1d4751ae6769d","url":"https://github.com/BaseXdb/basex"},{"original_method":"@Override\n\tpublic void init(\n\t\tJspCompilationContext ctxt, ErrorDispatcher errDispatcher,\n\t\tboolean suppressLogging) {\n\n\t\tsuper.init(ctxt, errDispatcher, suppressLogging);\n\n\t\tServletContext servletContext = ctxt.getServletContext();\n\n\t\t_bundle = (Bundle)servletContext.getAttribute(\"osgi-bundle\");\n\n\t\tinitClassPath(servletContext);\n\t\tinitTLDMappings(servletContext);\n\t}","id":37055,"modified_method":"@Override\n\tpublic void init(\n\t\tJspCompilationContext jspCompilationContext,\n\t\tErrorDispatcher errorDispatcher, boolean suppressLogging) {\n\n\t\tsuper.init(jspCompilationContext, errorDispatcher, suppressLogging);\n\n\t\tServletContext servletContext =\n\t\t\tjspCompilationContext.getServletContext();\n\n\t\t_bundle = (Bundle)servletContext.getAttribute(\"osgi-bundle\");\n\n\t\tinitClassPath(servletContext);\n\t\tinitTLDMappings(servletContext);\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override\n\tprotected JavaFileManager getJavaFileManager(\n\t\tJavaFileManager javaFileManager) {\n\n\t\tif (javaFileManager instanceof StandardJavaFileManager) {\n\t\t\tStandardJavaFileManager standardJavaFileManager =\n\t\t\t\t(StandardJavaFileManager)javaFileManager;\n\n\t\t\ttry {\n\t\t\t\tstandardJavaFileManager.setLocation(\n\t\t\t\t\tStandardLocation.CLASS_PATH, _classpath);\n\n\t\t\t\tBundleJavaManager bundleJavaManager = new BundleJavaManager(\n\t\t\t\t\t_bundle, standardJavaFileManager, options, true);\n\n\t\t\t\tbundleJavaManager.setResourceResolver(\n\t\t\t\t\tJspResolverFactory.getResourceResolver());\n\n\t\t\t\tjavaFileManager = bundleJavaManager;\n\t\t\t}\n\t\t\tcatch (IOException e) {\n\t\t\t\t_log.error(e, e);\n\t\t\t}\n\t\t}\n\n\t\treturn super.getJavaFileManager(javaFileManager);\n\t}","id":37056,"modified_method":"@Override\n\tprotected JavaFileManager getJavaFileManager(\n\t\tJavaFileManager javaFileManager) {\n\n\t\tif (javaFileManager instanceof StandardJavaFileManager) {\n\t\t\tStandardJavaFileManager standardJavaFileManager =\n\t\t\t\t(StandardJavaFileManager)javaFileManager;\n\n\t\t\ttry {\n\t\t\t\tstandardJavaFileManager.setLocation(\n\t\t\t\t\tStandardLocation.CLASS_PATH, _classPath);\n\n\t\t\t\tBundleJavaManager bundleJavaManager = new BundleJavaManager(\n\t\t\t\t\t_bundle, standardJavaFileManager, options, true);\n\n\t\t\t\tbundleJavaManager.setResourceResolver(\n\t\t\t\t\tJspResolverFactory.getResourceResolver());\n\n\t\t\t\tjavaFileManager = bundleJavaManager;\n\t\t\t}\n\t\t\tcatch (IOException ioe) {\n\t\t\t\t_log.error(ioe, ioe);\n\t\t\t}\n\t\t}\n\n\t\treturn super.getJavaFileManager(javaFileManager);\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void addDependencyToClassPath(Class<?> clazz) {\n\t\tProtectionDomain protectionDomain = clazz.getProtectionDomain();\n\n\t\tif (protectionDomain == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tURL location = protectionDomain.getCodeSource().getLocation();\n\n\t\ttry {\n\t\t\tFile file = new File(processJarLocation(location));\n\n\t\t\tif (file.exists() && file.canRead()) {\n\n\t\t\t\t// Make sure it's added at the beginning.\n\n\t\t\t\tif (_classpath.contains(file)) {\n\t\t\t\t\t_classpath.remove(file);\n\t\t\t\t}\n\n\t\t\t\t_classpath.add(0, file);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception use) {\n\t\t\t_log.error(use, use);\n\t\t}\n\t}","id":37057,"modified_method":"protected void addDependencyToClassPath(Class<?> clazz) {\n\t\tProtectionDomain protectionDomain = clazz.getProtectionDomain();\n\n\t\tif (protectionDomain == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tCodeSource codeSource = protectionDomain.getCodeSource();\n\n\t\tURL url = codeSource.getLocation();\n\n\t\ttry {\n\t\t\tFile file = new File(toURI(url));\n\n\t\t\tif (file.exists() && file.canRead()) {\n\t\t\t\tif (_classPath.contains(file)) {\n\t\t\t\t\t_classPath.remove(file);\n\t\t\t\t}\n\n\t\t\t\t_classPath.add(0, file);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception use) {\n\t\t\t_log.error(use, use);\n\t\t}\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void addDependenciesToClassPath() {\n\t\tfor (String dependency : PortletPropsValues.JSP_COMPILER_DEPENDENCIES) {\n\n\t\t\tFile file = new File(dependency);\n\n\t\t\tif (file.exists() && file.canRead()) {\n\t\t\t\tif (_classpath.contains(file)) {\n\t\t\t\t\t_classpath.remove(file);\n\t\t\t\t}\n\n\t\t\t\t_classpath.add(0, file);\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tClass<?> clazz = Class.forName(\n\t\t\t\t\tdependency, true, ClassLoaderUtil.getPortalClassLoader());\n\n\t\t\t\taddDependencyToClassPath(clazz);\n\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException e) {\n\t\t\t}\n\n\t\t\tif (_log.isErrorEnabled()) {\n\t\t\t\t_log.error(\n\t\t\t\t\t\"Could not add depedency {\" + dependency +\n\t\t\t\t\t\t\"} to the classpath\");\n\t\t\t}\n\t\t}\n\t}","id":37058,"modified_method":"protected void addDependenciesToClassPath() {\n\t\tfor (String className : _JSP_COMPILER_DEPENDENCIES) {\n\t\t\tFile file = new File(className);\n\n\t\t\tif (file.exists() && file.canRead()) {\n\t\t\t\tif (_classPath.contains(file)) {\n\t\t\t\t\t_classPath.remove(file);\n\t\t\t\t}\n\n\t\t\t\t_classPath.add(0, file);\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tClass<?> clazz = Class.forName(\n\t\t\t\t\tclassName, true, ClassLoaderUtil.getPortalClassLoader());\n\n\t\t\t\taddDependencyToClassPath(clazz);\n\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException e) {\n\t\t\t}\n\n\t\t\tif (_log.isErrorEnabled()) {\n\t\t\t\t_log.error(\n\t\t\t\t\t\"Could not add depedency {\" + className +\n\t\t\t\t\t\t\"} to the classpath\");\n\t\t\t}\n\t\t}\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void initTLDMappings(ServletContext servletContext) {\n\t\tMap<String, String[]> mappings =\n\t\t\t(Map<String, String[]>)servletContext.getAttribute(\n\t\t\t\tConstants.JSP_TLD_URI_TO_LOCATION_MAP);\n\n\t\tif (mappings != null) {\n\t\t\treturn;\n\t\t}\n\n\t\tmappings = new HashMap<String, String[]>();\n\n\t\tmappings.put(\n\t\t\t\"http://java.sun.com/jsp/jstl/core\",\n\t\t\tnew String[] {\"/WEB-INF/tld/c.tld\", null});\n\n\t\tservletContext.setAttribute(\n\t\t\tConstants.JSP_TLD_URI_TO_LOCATION_MAP, mappings);\n\t}","id":37059,"modified_method":"protected void initTLDMappings(ServletContext servletContext) {\n\t\tMap<String, String[]> tldMappings =\n\t\t\t(Map<String, String[]>)servletContext.getAttribute(\n\t\t\t\tConstants.JSP_TLD_URI_TO_LOCATION_MAP);\n\n\t\tif (tldMappings != null) {\n\t\t\treturn;\n\t\t}\n\n\t\ttldMappings = new HashMap<String, String[]>();\n\n\t\ttldMappings.put(\n\t\t\t\"http://java.sun.com/jsp/jstl/core\",\n\t\t\tnew String[] {\"/WEB-INF/tld/c.tld\", null});\n\n\t\tservletContext.setAttribute(\n\t\t\tConstants.JSP_TLD_URI_TO_LOCATION_MAP, tldMappings);\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"protected void initClassPath(ServletContext servletContext) {\n\t\t_reentrantLock.lock();\n\n\t\ttry {\n\t\t\t_classpath = (ArrayList<File>)servletContext.getAttribute(\n\t\t\t\t_JSP_COMPILER_CLASSPATH);\n\n\t\t\tif (_classpath != null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t_classpath = new ArrayList<File>();\n\n\t\t\taddDependenciesToClassPath();\n\n\t\t\tservletContext.setAttribute(_JSP_COMPILER_CLASSPATH, _classpath);\n\t\t}\n\t\tfinally {\n\t\t\t_reentrantLock.unlock();\n\t\t}\n\t}","id":37060,"modified_method":"protected void initClassPath(ServletContext servletContext) {\n\t\t_lock.lock();\n\n\t\ttry {\n\t\t\t_classPath = (ArrayList<File>)servletContext.getAttribute(\n\t\t\t\t_JSP_COMPILER_CLASS_PATH);\n\n\t\t\tif (_classPath != null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t_classPath = new ArrayList<File>();\n\n\t\t\taddDependenciesToClassPath();\n\n\t\t\tservletContext.setAttribute(_JSP_COMPILER_CLASS_PATH, _classPath);\n\t\t}\n\t\tfinally {\n\t\t\t_lock.unlock();\n\t\t}\n\t}","commit_id":"edb5645b98f2a21b4802b11b3712550d0daf1dd3","url":"https://github.com/liferay/liferay-plugins"},{"original_method":"@Override @SuppressForbidden(reason = \"fast equals check is desired\")\n    public boolean implies(ProtectionDomain domain, Permission permission) {\n        // run groovy scripts with no permissions\n        if (\"/groovy/script\".equals(domain.getCodeSource().getLocation().getFile())) {\n            return false;\n        }\n        return template.implies(domain, permission) || dynamic.implies(permission);\n    }","id":37061,"modified_method":"@Override @SuppressForbidden(reason = \"fast equals check is desired\")\n    public boolean implies(ProtectionDomain domain, Permission permission) {        \n        CodeSource codeSource = domain.getCodeSource();\n        // codesource can be null when reducing privileges via doPrivileged()\n        if (codeSource != null) {\n            URL location = codeSource.getLocation();\n            // location can be null... ??? nobody knows\n            // https://bugs.openjdk.java.net/browse/JDK-8129972\n            if (location != null) {\n                // run groovy scripts with no permissions\n                if (\"/groovy/script\".equals(location.getFile())) {\n                    return false;\n                }\n            }\n        }\n\n        // otherwise defer to template + dynamic file permissions\n        return template.implies(domain, permission) || dynamic.implies(permission);\n    }","commit_id":"a58c5dba89017746b2de0d54c345e2489e5a251e","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private static CompactSyntaxTokenManager createTokenManager(int initialState, EscapePreprocessor preprocessor) {\n    try {\n      return new CompactSyntaxTokenManager(new SimpleCharStream(preprocessor, 1, 1), initialState);\n    } catch (NoSuchMethodError e) {\n      final Class<CompactSyntaxTokenManager> managerClass = CompactSyntaxTokenManager.class;\n      LOG.error(\"Unsupported version of RNGOM in classpath\", e,\n                \"Actual parameter types: \" + Arrays.toString(managerClass.getConstructors()[0].getParameterTypes()),\n                \"Location of \" + managerClass.getName() + \": \" + managerClass.getProtectionDomain().getCodeSource().getLocation(),\n                \"Location of \" + CharStream.class.getName() + \": \" + CharStream.class.getProtectionDomain().getCodeSource().getLocation());\n      throw e;\n    }\n  }","id":37062,"modified_method":"private static CompactSyntaxTokenManager createTokenManager(int initialState, EscapePreprocessor preprocessor) {\n    try {\n      return new CompactSyntaxTokenManager(new SimpleCharStream(preprocessor, 1, 1), initialState);\n    } catch (NoSuchMethodError e) {\n      final Class<CompactSyntaxTokenManager> managerClass = CompactSyntaxTokenManager.class;\n      LOG.error(\"Unsupported version of RNGOM in classpath\", e,\n                \"Actual parameter types: \" + Arrays.toString(managerClass.getConstructors()[0].getParameterTypes()),\n                \"Location of \" + managerClass.getName() + \": \" + managerClass.getProtectionDomain().getCodeSource(),\n                \"Location of \" + CharStream.class.getName() + \": \" + CharStream.class.getProtectionDomain().getCodeSource());\n      throw e;\n    }\n  }","commit_id":"a13ec124d67da1d9b7322889b6ffa9c63db018cf","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void evaluateAndAskForReturnType(String expression, Object expectedValue, Class<?> expectedResultType) {\n\t\ttry {\n\t\t\tSpelExpression expr = (SpelExpression) parser.parseExpression(expression);\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tif (DEBUG) {\n\t\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, expr);\n\t\t\t}\n\t\t\t// Class<?> expressionType = expr.getValueType();\n\t\t\t// assertEquals(\"Type of the expression is not as expected. Should be '\"+expectedResultType+\"' but is\n\t\t\t// '\"+expressionType+\"'\",\n\t\t\t// expectedResultType,expressionType);\n\n\t\t\tObject value = expr.getValue(eContext, expectedResultType);\n\t\t\tif (value == null) {\n\t\t\t\tif (expectedValue == null)\n\t\t\t\t\treturn; // no point doing other checks\n\t\t\t\tassertEquals(\"Expression returned null value, but expected '\" + expectedValue + \"'\", expectedValue,\n\t\t\t\t\t\tnull);\n\t\t\t}\n\n\t\t\tClass<?> resultType = value.getClass();\n\t\t\tassertEquals(\"Type of the actual result was not as expected.  Expected '\" + expectedResultType\n\t\t\t\t\t+ \"' but result was of type '\" + resultType + \"'\", expectedResultType, resultType);\n\t\t\t// .equals/* isAssignableFrom */(resultType), truers);\n\t\t\tassertEquals(\"Did not get expected value for expression '\" + expression + \"'.\", expectedValue, value);\n\t\t\t// isAssignableFrom would allow some room for compatibility\n\t\t\t// in the above expression...\n\t\t} catch (EvaluationException ee) {\n\t\t\tSpelException ex = (SpelException) ee;\n\t\t\tex.printStackTrace();\n\t\t\tfail(\"Unexpected EvaluationException: \" + ex.getMessage());\n\t\t} catch (ParseException pe) {\n\t\t\tfail(\"Unexpected ParseException: \" + pe.getMessage());\n\t\t}\n\t}","id":37063,"modified_method":"public void evaluateAndAskForReturnType(String expression, Object expectedValue, Class<?> expectedResultType) {\n\t\ttry {\n\t\t\tSpelExpression expr = parser.parseExpression(expression);\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tif (DEBUG) {\n\t\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, expr);\n\t\t\t}\n\t\t\t// Class<?> expressionType = expr.getValueType();\n\t\t\t// assertEquals(\"Type of the expression is not as expected. Should be '\"+expectedResultType+\"' but is\n\t\t\t// '\"+expressionType+\"'\",\n\t\t\t// expectedResultType,expressionType);\n\n\t\t\tObject value = expr.getValue(eContext, expectedResultType);\n\t\t\tif (value == null) {\n\t\t\t\tif (expectedValue == null)\n\t\t\t\t\treturn; // no point doing other checks\n\t\t\t\tassertEquals(\"Expression returned null value, but expected '\" + expectedValue + \"'\", expectedValue,\n\t\t\t\t\t\tnull);\n\t\t\t}\n\n\t\t\tClass<?> resultType = value.getClass();\n\t\t\tassertEquals(\"Type of the actual result was not as expected.  Expected '\" + expectedResultType\n\t\t\t\t\t+ \"' but result was of type '\" + resultType + \"'\", expectedResultType, resultType);\n\t\t\t// .equals/* isAssignableFrom */(resultType), truers);\n\t\t\tassertEquals(\"Did not get expected value for expression '\" + expression + \"'.\", expectedValue, value);\n\t\t\t// isAssignableFrom would allow some room for compatibility\n\t\t\t// in the above expression...\n\t\t} catch (EvaluationException ee) {\n\t\t\tSpelException ex = (SpelException) ee;\n\t\t\tex.printStackTrace();\n\t\t\tfail(\"Unexpected EvaluationException: \" + ex.getMessage());\n\t\t} catch (ParseException pe) {\n\t\t\tfail(\"Unexpected ParseException: \" + pe.getMessage());\n\t\t}\n\t}","commit_id":"cfdb8e01ebecb92abf87b3b68abd3e4c5dfb4d03","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Evaluate the specified expression and ensure the expected message comes out. The message may have inserts and\n\t * they will be checked if otherProperties is specified. The first entry in otherProperties should always be the\n\t * position.\n\t * @param expression The expression to evaluate\n\t * @param expectedMessage The expected message\n\t * @param otherProperties The expected inserts within the message\n\t */\n\tprotected void evaluateAndCheckError(String expression, SpelMessages expectedMessage, Object... otherProperties) {\n\t\ttry {\n\t\t\tExpression expr = (Expression) parser.parseExpression(expression);\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\t@SuppressWarnings(\"unused\")\n\t\t\tObject value = expr.getValue(eContext);\n\t\t\tfail(\"Should have failed with message \" + expectedMessage);\n\t\t} catch (EvaluationException ee) {\n\t\t\tSpelException ex = (SpelException) ee;\n\t\t\tif (ex.getMessageUnformatted() != expectedMessage) {\n\t\t\t\tSystem.out.println(ex.getMessage());\n\t\t\t\tex.printStackTrace();\n\t\t\t\tassertEquals(\"Failed to get expected message\", expectedMessage, ex.getMessageUnformatted());\n\t\t\t}\n\t\t\tif (otherProperties != null && otherProperties.length != 0) {\n\t\t\t\t// first one is expected position of the error within the string\n\t\t\t\tint pos = ((Integer) otherProperties[0]).intValue();\n\t\t\t\tassertEquals(\"Did not get correct position reported in error \", pos, ex.getPosition());\n\t\t\t\tif (otherProperties.length > 1) {\n\t\t\t\t\t// Check inserts match\n\t\t\t\t\tObject[] inserts = ex.getInserts();\n\t\t\t\t\tif (inserts == null) {\n\t\t\t\t\t\tinserts = new Object[0];\n\t\t\t\t\t}\n\t\t\t\t\tif (inserts.length < otherProperties.length - 1) {\n\t\t\t\t\t\tex.printStackTrace();\n\t\t\t\t\t\tfail(\"Cannot check \" + (otherProperties.length - 1)\n\t\t\t\t\t\t\t\t+ \" properties of the exception, it only has \" + inserts.length + \" inserts\");\n\t\t\t\t\t}\n\t\t\t\t\tfor (int i = 1; i < otherProperties.length; i++) {\n\t\t\t\t\t\tif (!inserts[i - 1].equals(otherProperties[i])) {\n\t\t\t\t\t\t\tex.printStackTrace();\n\t\t\t\t\t\t\tfail(\"Insert does not match, expected '\" + otherProperties[i] + \"' but insert value was '\"\n\t\t\t\t\t\t\t\t\t+ inserts[i - 1] + \"'\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (ParseException pe) {\n\t\t\tpe.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + pe.getMessage());\n\t\t}\n\t}","id":37064,"modified_method":"/**\n\t * Evaluate the specified expression and ensure the expected message comes out. The message may have inserts and\n\t * they will be checked if otherProperties is specified. The first entry in otherProperties should always be the\n\t * position.\n\t * @param expression The expression to evaluate\n\t * @param expectedMessage The expected message\n\t * @param otherProperties The expected inserts within the message\n\t */\n\tprotected void evaluateAndCheckError(String expression, SpelMessages expectedMessage, Object... otherProperties) {\n\t\ttry {\n\t\t\tExpression expr = parser.parseExpression(expression);\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\t@SuppressWarnings(\"unused\")\n\t\t\tObject value = expr.getValue(eContext);\n\t\t\tfail(\"Should have failed with message \" + expectedMessage);\n\t\t} catch (EvaluationException ee) {\n\t\t\tSpelException ex = (SpelException) ee;\n\t\t\tif (ex.getMessageUnformatted() != expectedMessage) {\n\t\t\t\tSystem.out.println(ex.getMessage());\n\t\t\t\tex.printStackTrace();\n\t\t\t\tassertEquals(\"Failed to get expected message\", expectedMessage, ex.getMessageUnformatted());\n\t\t\t}\n\t\t\tif (otherProperties != null && otherProperties.length != 0) {\n\t\t\t\t// first one is expected position of the error within the string\n\t\t\t\tint pos = ((Integer) otherProperties[0]).intValue();\n\t\t\t\tassertEquals(\"Did not get correct position reported in error \", pos, ex.getPosition());\n\t\t\t\tif (otherProperties.length > 1) {\n\t\t\t\t\t// Check inserts match\n\t\t\t\t\tObject[] inserts = ex.getInserts();\n\t\t\t\t\tif (inserts == null) {\n\t\t\t\t\t\tinserts = new Object[0];\n\t\t\t\t\t}\n\t\t\t\t\tif (inserts.length < otherProperties.length - 1) {\n\t\t\t\t\t\tex.printStackTrace();\n\t\t\t\t\t\tfail(\"Cannot check \" + (otherProperties.length - 1)\n\t\t\t\t\t\t\t\t+ \" properties of the exception, it only has \" + inserts.length + \" inserts\");\n\t\t\t\t\t}\n\t\t\t\t\tfor (int i = 1; i < otherProperties.length; i++) {\n\t\t\t\t\t\tif (!inserts[i - 1].equals(otherProperties[i])) {\n\t\t\t\t\t\t\tex.printStackTrace();\n\t\t\t\t\t\t\tfail(\"Insert does not match, expected '\" + otherProperties[i] + \"' but insert value was '\"\n\t\t\t\t\t\t\t\t\t+ inserts[i - 1] + \"'\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (ParseException pe) {\n\t\t\tpe.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + pe.getMessage());\n\t\t}\n\t}","commit_id":"cfdb8e01ebecb92abf87b3b68abd3e4c5dfb4d03","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Evaluate an expression and check that the actual result matches the expectedValue and the class of the result\n\t * matches the expectedClassOfResult. This method can also check if the expression is writable (for example, it is a\n\t * variable or property reference).\n\t * \n\t * @param expression The expression to evaluate\n\t * @param expectedValue the expected result for evaluating the expression\n\t * @param expectedClassOfResult the expected class of the evaluation result\n\t * @param shouldBeWritable should the parsed expression be writable?\n\t */\n\tpublic void eval(String expression, Object expectedValue, Class<?> expectedClassOfResult, boolean shouldBeWritable) {\n\t\ttry {\n\t\t\tSpelExpression e = (SpelExpression) parser.parseExpression(expression);\n\t\t\tif (e == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tif (DEBUG) {\n\t\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, e);\n\t\t\t}\n\t\t\tObject value = e.getValue(eContext);\n\t\t\tif (value == null) {\n\t\t\t\tif (expectedValue == null)\n\t\t\t\t\treturn; // no point doing other\n\t\t\t\t// checks\n\t\t\t\tassertEquals(\"Expression returned null value, but expected '\" + expectedValue + \"'\", expectedValue,\n\t\t\t\t\t\tnull);\n\t\t\t}\n\t\t\tClass<? extends Object> resultType = value.getClass();\n\t\t\tassertEquals(\"Did not get expected value for expression '\" + expression + \"'.\", expectedValue,\n\t\t\t\t\tExpressionTestCase.stringValueOf(value));\n\t\t\tassertEquals(\"Type of the result was not as expected.  Expected '\" + expectedClassOfResult\n\t\t\t\t\t+ \"' but result was of type '\" + resultType + \"'\", expectedClassOfResult\n\t\t\t\t\t.equals/* isAssignableFrom */(resultType), true);\n\t\t\t// TODO 4 isAssignableFrom would allow some room for compatibility\n\t\t\t// in the above expression...\n\n\t\t\tboolean isWritable = e.isWritable(eContext);\n\t\t\tif (isWritable != shouldBeWritable) {\n\t\t\t\tif (shouldBeWritable)\n\t\t\t\t\tfail(\"Expected the expression to be writable but it is not\");\n\t\t\t\telse\n\t\t\t\t\tfail(\"Expected the expression to be readonly but it is not\");\n\t\t\t}\n\t\t} catch (EvaluationException ee) {\n\t\t\tee.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + ee.getMessage());\n\t\t} catch (ParseException pe) {\n\t\t\tpe.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + pe.getMessage());\n\t\t}\n\t}","id":37065,"modified_method":"/**\n\t * Evaluate an expression and check that the actual result matches the expectedValue and the class of the result\n\t * matches the expectedClassOfResult. This method can also check if the expression is writable (for example, it is a\n\t * variable or property reference).\n\t * \n\t * @param expression The expression to evaluate\n\t * @param expectedValue the expected result for evaluating the expression\n\t * @param expectedClassOfResult the expected class of the evaluation result\n\t * @param shouldBeWritable should the parsed expression be writable?\n\t */\n\tpublic void eval(String expression, Object expectedValue, Class<?> expectedClassOfResult, boolean shouldBeWritable) {\n\t\ttry {\n\t\t\tSpelExpression e = parser.parseExpression(expression);\n\t\t\tif (e == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tif (DEBUG) {\n\t\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, e);\n\t\t\t}\n\t\t\tObject value = e.getValue(eContext);\n\t\t\tif (value == null) {\n\t\t\t\tif (expectedValue == null)\n\t\t\t\t\treturn; // no point doing other\n\t\t\t\t// checks\n\t\t\t\tassertEquals(\"Expression returned null value, but expected '\" + expectedValue + \"'\", expectedValue,\n\t\t\t\t\t\tnull);\n\t\t\t}\n\t\t\tClass<? extends Object> resultType = value.getClass();\n\t\t\tassertEquals(\"Did not get expected value for expression '\" + expression + \"'.\", expectedValue,\n\t\t\t\t\tExpressionTestCase.stringValueOf(value));\n\t\t\tassertEquals(\"Type of the result was not as expected.  Expected '\" + expectedClassOfResult\n\t\t\t\t\t+ \"' but result was of type '\" + resultType + \"'\", expectedClassOfResult\n\t\t\t\t\t.equals/* isAssignableFrom */(resultType), true);\n\t\t\t// TODO 4 isAssignableFrom would allow some room for compatibility\n\t\t\t// in the above expression...\n\n\t\t\tboolean isWritable = e.isWritable(eContext);\n\t\t\tif (isWritable != shouldBeWritable) {\n\t\t\t\tif (shouldBeWritable)\n\t\t\t\t\tfail(\"Expected the expression to be writable but it is not\");\n\t\t\t\telse\n\t\t\t\t\tfail(\"Expected the expression to be readonly but it is not\");\n\t\t\t}\n\t\t} catch (EvaluationException ee) {\n\t\t\tee.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + ee.getMessage());\n\t\t} catch (ParseException pe) {\n\t\t\tpe.printStackTrace();\n\t\t\tfail(\"Unexpected Exception: \" + pe.getMessage());\n\t\t}\n\t}","commit_id":"cfdb8e01ebecb92abf87b3b68abd3e4c5dfb4d03","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Testing that using a resolver/executor split for constructor invocation (ie. just doing the reflection once to\n\t * find the constructor then executing it over and over) is faster than redoing the reflection and execution every\n\t * time.\n\t * \n\t * MacBook speeds: 4-Aug-08 <br>\n\t * Fresh parse every time, ITERATIONS iterations = 373ms <br>\n\t * Reuse SpelExpression, ITERATIONS iterations = 1ms <br>\n\t * Reuse SpelExpression (caching off), ITERATIONS iterations = 188ms <br>\n\t */\n\tpublic void testConstructorResolverExecutorBenefit01() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"new Integer(5)\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"new Integer(5)\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr = (Expression) parser.parseExpression(\"new Integer(5)\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tConstructorReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tConstructorReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr = (Expression) parser.parseExpression(\"new Integer(5)\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for constructor execution 'new Integer(5)'\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","id":37066,"modified_method":"/**\n\t * Testing that using a resolver/executor split for constructor invocation (ie. just doing the reflection once to\n\t * find the constructor then executing it over and over) is faster than redoing the reflection and execution every\n\t * time.\n\t * \n\t * MacBook speeds: 4-Aug-08 <br>\n\t * Fresh parse every time, ITERATIONS iterations = 373ms <br>\n\t * Reuse SpelExpression, ITERATIONS iterations = 1ms <br>\n\t * Reuse SpelExpression (caching off), ITERATIONS iterations = 188ms <br>\n\t */\n\tpublic void testConstructorResolverExecutorBenefit01() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = parser.parseExpression(\"new Integer(5)\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = parser.parseExpression(\"new Integer(5)\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr =  parser.parseExpression(\"new Integer(5)\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tConstructorReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tConstructorReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr =  parser.parseExpression(\"new Integer(5)\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for constructor execution 'new Integer(5)'\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","commit_id":"49bef5a39fd05bc7b6d38a828ed5907870a76083","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Testing that using a resolver/executor split for property writing is faster than redoing the reflection and\n\t * execution every time.\n\t * \n\t * MacBook speeds: <br>\n\t */\n\tpublic void testPropertyResolverExecutorBenefit_Writing() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"randomField='Andy'\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"randomField='Andy'\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr = (Expression) parser.parseExpression(\"randomField='Andy'\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tPropertyOrFieldReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tPropertyOrFieldReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr = (Expression) parser.parseExpression(\"randomField='Andy'\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for property writing execution 'randomField='Andy''\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","id":37067,"modified_method":"/**\n\t * Testing that using a resolver/executor split for property writing is faster than redoing the reflection and\n\t * execution every time.\n\t * \n\t * MacBook speeds: <br>\n\t */\n\tpublic void testPropertyResolverExecutorBenefit_Writing() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr =  parser.parseExpression(\"randomField='Andy'\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = parser.parseExpression(\"randomField='Andy'\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr = parser.parseExpression(\"randomField='Andy'\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tPropertyOrFieldReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tPropertyOrFieldReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr = parser.parseExpression(\"randomField='Andy'\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for property writing execution 'randomField='Andy''\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","commit_id":"49bef5a39fd05bc7b6d38a828ed5907870a76083","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Testing that using a resolver/executor split for property access is faster than redoing the reflection and\n\t * execution every time.\n\t * \n\t * MacBook speeds: <br>\n\t */\n\tpublic void testPropertyResolverExecutorBenefit_Reading() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr = (Expression) parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tPropertyOrFieldReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tPropertyOrFieldReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr = (Expression) parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for property reader execution 'getPlaceOfBirth().city'\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","id":37068,"modified_method":"/**\n\t * Testing that using a resolver/executor split for property access is faster than redoing the reflection and\n\t * execution every time.\n\t * \n\t * MacBook speeds: <br>\n\t */\n\tpublic void testPropertyResolverExecutorBenefit_Reading() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\t// warmup\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr =  parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\n\t\t// ITERATIONS calls, parsing fresh each time\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr =  parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\t\tif (expr == null) {\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\t}\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\tExpression expr =  parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\ttry {\n\t\t\tPropertyOrFieldReference.useCaching = false;\n\t\t\tstarttime = System.currentTimeMillis();\n\t\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\t\tObject value = expr.getValue(eContext);\n\t\t\t}\n\t\t} finally {\n\t\t\tPropertyOrFieldReference.useCaching = true;\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong cachingOffReuseTime = endtime - starttime;\n\n\t\t// ITERATIONS calls, parsing once and using cached executor\n\t\texpr =  parser.parseExpression(\"getPlaceOfBirth().city\");\n\t\tif (expr == null) {\n\t\t\tfail(\"Parser returned null for expression\");\n\t\t}\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (report) {\n\t\t\tSystem.out.println(\"Timings for property reader execution 'getPlaceOfBirth().city'\");\n\t\t\tSystem.out.println(\"Fresh parse every time, \" + ITERATIONS + \" iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression (caching off), \" + ITERATIONS + \" iterations = \"\n\t\t\t\t\t+ cachingOffReuseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, \" + ITERATIONS + \" iterations = \" + reuseTime + \"ms\");\n\t\t}\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tfail(\"Should have been quicker to reuse a parsed expression!\");\n\t\t}\n\t\tif (reuseTime > cachingOffReuseTime) {\n\t\t\tfail(\"Should have been quicker to reuse cached!\");\n\t\t}\n\t}","commit_id":"49bef5a39fd05bc7b6d38a828ed5907870a76083","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public void testPerformanceOfSimpleAccess() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = (Expression) parser.parseExpression(\"getPlaceOfBirth().getCity()\");\n\t\t\tif (expr == null)\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\tExpression expr = (Expression) parser.parseExpression(\"getPlaceOfBirth().getCity()\");\n\t\tif (expr == null)\n\t\t\tfail(\"Parser returned null for expression\");\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tSystem.out.println(\"Fresh parse every time, ITERATIONS iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, ITERATIONS iterations = \" + reuseTime + \"ms\");\n\t\t\tfail(\"Should have been quicker to reuse!\");\n\t\t}\n\t}","id":37069,"modified_method":"public void testPerformanceOfSimpleAccess() throws Exception {\n\t\tlong starttime = 0;\n\t\tlong endtime = 0;\n\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tExpression expr = parser.parseExpression(\"getPlaceOfBirth().getCity()\");\n\t\t\tif (expr == null)\n\t\t\t\tfail(\"Parser returned null for expression\");\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong freshParseTime = endtime - starttime;\n\n\t\tExpression expr = parser.parseExpression(\"getPlaceOfBirth().getCity()\");\n\t\tif (expr == null)\n\t\t\tfail(\"Parser returned null for expression\");\n\t\tstarttime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < ITERATIONS; i++) {\n\t\t\tObject value = expr.getValue(eContext);\n\t\t}\n\t\tendtime = System.currentTimeMillis();\n\t\tlong reuseTime = endtime - starttime;\n\t\tif (reuseTime > freshParseTime) {\n\t\t\tSystem.out.println(\"Fresh parse every time, ITERATIONS iterations = \" + freshParseTime + \"ms\");\n\t\t\tSystem.out.println(\"Reuse SpelExpression, ITERATIONS iterations = \" + reuseTime + \"ms\");\n\t\t\tfail(\"Should have been quicker to reuse!\");\n\t\t}\n\t}","commit_id":"49bef5a39fd05bc7b6d38a828ed5907870a76083","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public <T> T convertValue(TypedValue value, TypeDescriptor targetTypeDescriptor) throws EvaluationException {\r\n\t\treturn this.relatedContext.getTypeConverter().convertValue(value.getValue(), targetTypeDescriptor);\r\n\t}","id":37070,"modified_method":"public Object convertValue(TypedValue value, TypeDescriptor targetTypeDescriptor) throws EvaluationException {\r\n\t\treturn this.relatedContext.getTypeConverter().convertValue(value.getValue(), targetTypeDescriptor);\r\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public <T> T convertValue(Object value, TypeDescriptor targetTypeDescriptor) throws EvaluationException {\r\n\t\treturn this.relatedContext.getTypeConverter().convertValue(value, targetTypeDescriptor);\r\n\t}","id":37071,"modified_method":"public Object convertValue(Object value, TypeDescriptor targetTypeDescriptor) throws EvaluationException {\r\n\t\treturn this.relatedContext.getTypeConverter().convertValue(value, targetTypeDescriptor);\r\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@SuppressWarnings(\"unchecked\")\n\t\tpublic <T> T convertValue(Object value, TypeDescriptor typeDescriptor)\n\t\t\t\tthrows EvaluationException {\n\t\t\treturn (T)super.executeConversion(value, typeDescriptor);\n\t\t}","id":37072,"modified_method":"@SuppressWarnings(\"unchecked\")\n\t\tpublic Object convertValue(Object value, TypeDescriptor typeDescriptor)\n\t\t\t\tthrows EvaluationException {\n\t\t\treturn super.executeConversion(value, typeDescriptor);\n\t\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Override\n\tpublic TypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tTypedValue context = state.getActiveContextObject();\n\t\tObject targetObject = context.getValue();\n\t\tTypeDescriptor targetObjectTypeDescriptor = context.getTypeDescriptor();\n\t\tTypedValue indexValue =  getChild(0).getValueInternal(state);\n\t\tObject index = indexValue.getValue();\n\n\t\t// Indexing into a Map\n\t\tif (targetObject instanceof Map) {\n\t\t\tObject possiblyConvertedKey = state.convertValue(indexValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapKeyType()));\n\t\t\tObject o = ((Map<?, ?>) targetObject).get(possiblyConvertedKey);\n\t\t\treturn new TypedValue(o,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapValueType()));\n\t\t}\n\n\t\tint idx = state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\n\t\tif (targetObject == null) {\n\t\t\tthrow new SpelException(SpelMessages.CANNOT_INDEX_INTO_NULL_VALUE);\n\t\t}\n\t\t\n\t\tif (targetObject.getClass().isArray()) {\n\t\t\treturn new TypedValue(accessArrayElement(targetObject, idx),TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t} else if (targetObject instanceof Collection) {\n\t\t\tCollection<?> c = (Collection<?>) targetObject;\n\t\t\tif (idx >= c.size()) {\n\t\t\t\tthrow new SpelException(SpelMessages.COLLECTION_INDEX_OUT_OF_BOUNDS, c.size(), idx);\n\t\t\t}\n\t\t\tint pos = 0;\n\t\t\tfor (Object o : c) {\n\t\t\t\tif (pos == idx) {\n\t\t\t\t\treturn new TypedValue(o,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t\t\t}\n\t\t\t\tpos++;\n\t\t\t}\n\t\t} else if (targetObject instanceof String) {\n\t\t\tString ctxString = (String) targetObject;\n\t\t\tif (idx >= ctxString.length()) {\n\t\t\t\tthrow new SpelException(SpelMessages.STRING_INDEX_OUT_OF_BOUNDS, ctxString.length(), idx);\n\t\t\t}\n\t\t\treturn new TypedValue(String.valueOf(ctxString.charAt(idx)),STRING_TYPE_DESCRIPTOR);\n\t\t}\n\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, targetObjectTypeDescriptor.asString());\n\t}","id":37073,"modified_method":"@Override\n\tpublic TypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tTypedValue context = state.getActiveContextObject();\n\t\tObject targetObject = context.getValue();\n\t\tTypeDescriptor targetObjectTypeDescriptor = context.getTypeDescriptor();\n\t\tTypedValue indexValue =  getChild(0).getValueInternal(state);\n\t\tObject index = indexValue.getValue();\n\n\t\t// Indexing into a Map\n\t\tif (targetObject instanceof Map) {\n\t\t\tObject possiblyConvertedKey = state.convertValue(indexValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapKeyType()));\n\t\t\tObject o = ((Map<?, ?>) targetObject).get(possiblyConvertedKey);\n\t\t\treturn new TypedValue(o,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapValueType()));\n\t\t}\n\n\t\tint idx = (Integer)state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\n\t\tif (targetObject == null) {\n\t\t\tthrow new SpelException(SpelMessages.CANNOT_INDEX_INTO_NULL_VALUE);\n\t\t}\n\t\t\n\t\tif (targetObject.getClass().isArray()) {\n\t\t\treturn new TypedValue(accessArrayElement(targetObject, idx),TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t} else if (targetObject instanceof Collection) {\n\t\t\tCollection<?> c = (Collection<?>) targetObject;\n\t\t\tif (idx >= c.size()) {\n\t\t\t\tthrow new SpelException(SpelMessages.COLLECTION_INDEX_OUT_OF_BOUNDS, c.size(), idx);\n\t\t\t}\n\t\t\tint pos = 0;\n\t\t\tfor (Object o : c) {\n\t\t\t\tif (pos == idx) {\n\t\t\t\t\treturn new TypedValue(o,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t\t\t}\n\t\t\t\tpos++;\n\t\t\t}\n\t\t} else if (targetObject instanceof String) {\n\t\t\tString ctxString = (String) targetObject;\n\t\t\tif (idx >= ctxString.length()) {\n\t\t\t\tthrow new SpelException(SpelMessages.STRING_INDEX_OUT_OF_BOUNDS, ctxString.length(), idx);\n\t\t\t}\n\t\t\treturn new TypedValue(String.valueOf(ctxString.charAt(idx)),STRING_TYPE_DESCRIPTOR);\n\t\t}\n\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, targetObjectTypeDescriptor.asString());\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@SuppressWarnings(\"unchecked\")\n\t@Override\n\tpublic void setValue(ExpressionState state, Object newValue) throws EvaluationException {\n\t\tTypedValue contextObject = state.getActiveContextObject();\n\t\tObject targetObject = contextObject.getValue();\n\t\tTypeDescriptor targetObjectTypeDescriptor = contextObject.getTypeDescriptor();\n\t\tTypedValue index = getChild(0).getValueInternal(state);\n\n\t\tif (targetObject == null) {\n\t\t\tthrow new SpelException(SpelMessages.CANNOT_INDEX_INTO_NULL_VALUE);\n\t\t}\n\t\t// Indexing into a Map\n\t\tif (targetObjectTypeDescriptor.isMap()) {\n\t\t\tMap map = (Map)targetObject;\n\t\t\tObject possiblyConvertedKey = state.convertValue(index.getValue(),TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapKeyType()));\n\t\t\tObject possiblyConvertedValue = state.convertValue(newValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapValueType()));\n\t\t\tmap.put(possiblyConvertedKey,possiblyConvertedValue);\n\t\t\treturn;\n\t\t}\n\n\t\tif (targetObjectTypeDescriptor.isArray()) {\n\t\t\tint idx = state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\t\t\tsetArrayElement(state, contextObject.getValue(), idx, newValue, targetObjectTypeDescriptor.getElementType());\n\t\t} else if (targetObjectTypeDescriptor.isCollection()) {\n\t\t\tint idx = state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\t\t\tCollection c = (Collection) targetObject;\n\t\t\tif (idx >= c.size()) {\n\t\t\t\tthrow new SpelException(SpelMessages.COLLECTION_INDEX_OUT_OF_BOUNDS, c.size(), idx);\n\t\t\t}\n\t\t\tif (targetObject instanceof List) {\n\t\t\t\tList list = (List)targetObject;\n\t\t\t\tObject possiblyConvertedValue = state.convertValue(newValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t\t\tlist.set(idx,possiblyConvertedValue);\n\t\t\t} else {\n\t\t\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, contextObject.getClass().getName());\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, contextObject.getClass().getName());\n\t\t}\n\t}","id":37074,"modified_method":"@SuppressWarnings(\"unchecked\")\n\t@Override\n\tpublic void setValue(ExpressionState state, Object newValue) throws EvaluationException {\n\t\tTypedValue contextObject = state.getActiveContextObject();\n\t\tObject targetObject = contextObject.getValue();\n\t\tTypeDescriptor targetObjectTypeDescriptor = contextObject.getTypeDescriptor();\n\t\tTypedValue index = getChild(0).getValueInternal(state);\n\n\t\tif (targetObject == null) {\n\t\t\tthrow new SpelException(SpelMessages.CANNOT_INDEX_INTO_NULL_VALUE);\n\t\t}\n\t\t// Indexing into a Map\n\t\tif (targetObjectTypeDescriptor.isMap()) {\n\t\t\tMap map = (Map)targetObject;\n\t\t\tObject possiblyConvertedKey = state.convertValue(index.getValue(),TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapKeyType()));\n\t\t\tObject possiblyConvertedValue = state.convertValue(newValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getMapValueType()));\n\t\t\tmap.put(possiblyConvertedKey,possiblyConvertedValue);\n\t\t\treturn;\n\t\t}\n\n\t\tif (targetObjectTypeDescriptor.isArray()) {\n\t\t\tint idx = (Integer)state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\t\t\tsetArrayElement(state, contextObject.getValue(), idx, newValue, targetObjectTypeDescriptor.getElementType());\n\t\t} else if (targetObjectTypeDescriptor.isCollection()) {\n\t\t\tint idx = (Integer)state.convertValue(index, INTEGER_TYPE_DESCRIPTOR);\n\t\t\tCollection c = (Collection) targetObject;\n\t\t\tif (idx >= c.size()) {\n\t\t\t\tthrow new SpelException(SpelMessages.COLLECTION_INDEX_OUT_OF_BOUNDS, c.size(), idx);\n\t\t\t}\n\t\t\tif (targetObject instanceof List) {\n\t\t\t\tList list = (List)targetObject;\n\t\t\t\tObject possiblyConvertedValue = state.convertValue(newValue,TypeDescriptor.valueOf(targetObjectTypeDescriptor.getElementType()));\n\t\t\t\tlist.set(idx,possiblyConvertedValue);\n\t\t\t} else {\n\t\t\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, contextObject.getClass().getName());\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new SpelException(SpelMessages.INDEXING_NOT_SUPPORTED_FOR_TYPE, contextObject.getClass().getName());\n\t\t}\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"private void setArrayElement(ExpressionState state, Object ctx, int idx, Object newValue, Class clazz) throws EvaluationException {\n\t\tClass<?> arrayComponentType = clazz;\n\t\tif (arrayComponentType == Integer.TYPE) {\n\t\t\tint[] array = (int[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, INTEGER_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Boolean.TYPE) {\n\t\t\tboolean[] array = (boolean[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, BOOLEAN_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Character.TYPE) {\n\t\t\tchar[] array = (char[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, CHARACTER_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Long.TYPE) {\n\t\t\tlong[] array = (long[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, LONG_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Short.TYPE) {\n\t\t\tshort[] array = (short[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, SHORT_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Double.TYPE) {\n\t\t\tdouble[] array = (double[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, DOUBLE_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Float.TYPE) {\n\t\t\tfloat[] array = (float[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, FLOAT_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Byte.TYPE) {\n\t\t\tbyte[] array = (byte[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, BYTE_TYPE_DESCRIPTOR);\n\t\t} else {\n\t\t\tObject[] array = (Object[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, TypeDescriptor.valueOf(clazz));\n\t\t}\t\t\n\t}","id":37075,"modified_method":"private void setArrayElement(ExpressionState state, Object ctx, int idx, Object newValue, Class clazz) throws EvaluationException {\n\t\tClass<?> arrayComponentType = clazz;\n\t\tif (arrayComponentType == Integer.TYPE) {\n\t\t\tint[] array = (int[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Integer)state.convertValue(newValue, INTEGER_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Boolean.TYPE) {\n\t\t\tboolean[] array = (boolean[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Boolean)state.convertValue(newValue, BOOLEAN_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Character.TYPE) {\n\t\t\tchar[] array = (char[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Character)state.convertValue(newValue, CHARACTER_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Long.TYPE) {\n\t\t\tlong[] array = (long[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Long)state.convertValue(newValue, LONG_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Short.TYPE) {\n\t\t\tshort[] array = (short[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Short)state.convertValue(newValue, SHORT_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Double.TYPE) {\n\t\t\tdouble[] array = (double[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Double)state.convertValue(newValue, DOUBLE_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Float.TYPE) {\n\t\t\tfloat[] array = (float[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Float)state.convertValue(newValue, FLOAT_TYPE_DESCRIPTOR);\n\t\t} else if (arrayComponentType == Byte.TYPE) {\n\t\t\tbyte[] array = (byte[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = (Byte)state.convertValue(newValue, BYTE_TYPE_DESCRIPTOR);\n\t\t} else {\n\t\t\tObject[] array = (Object[]) ctx;\n\t\t\tcheckAccess(array.length, idx);\n\t\t\tarray[idx] = state.convertValue(newValue, TypeDescriptor.valueOf(clazz));\n\t\t}\t\t\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Override\n\tpublic TypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tboolean leftValue;\n\t\tboolean rightValue;\n\n\t\ttry {\n\t\t\tleftValue = state.convertValue(getLeftOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException ee) {\n\t\t\tee.setPosition(getLeftOperand().getCharPositionInLine());\n\t\t\tthrow ee;\n\t\t}\n\n\t\tif (leftValue == false) {\n\t\t\treturn BooleanTypedValue.forValue(false); // no need to evaluate right operand\n\t\t}\n\n\t\ttry {\n\t\t\trightValue = state.convertValue(getRightOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException ee) {\n\t\t\tee.setPosition(getRightOperand().getCharPositionInLine());\n\t\t\tthrow ee;\n\t\t}\n\n\t\treturn /* leftValue && */BooleanTypedValue.forValue(rightValue);\n\t}","id":37076,"modified_method":"@Override\n\tpublic TypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tboolean leftValue;\n\t\tboolean rightValue;\n\n\t\ttry {\n\t\t\tleftValue = (Boolean)state.convertValue(getLeftOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException ee) {\n\t\t\tee.setPosition(getLeftOperand().getCharPositionInLine());\n\t\t\tthrow ee;\n\t\t}\n\n\t\tif (leftValue == false) {\n\t\t\treturn BooleanTypedValue.forValue(false); // no need to evaluate right operand\n\t\t}\n\n\t\ttry {\n\t\t\trightValue = (Boolean)state.convertValue(getRightOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException ee) {\n\t\t\tee.setPosition(getRightOperand().getCharPositionInLine());\n\t\t\tthrow ee;\n\t\t}\n\n\t\treturn /* leftValue && */BooleanTypedValue.forValue(rightValue);\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Override\n\tpublic BooleanTypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\ttry {\n\t\t\tboolean value = state.convertValue(getChild(0).getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t\treturn BooleanTypedValue.forValue(!value);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getChild(0).getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\t}","id":37077,"modified_method":"@Override\n\tpublic BooleanTypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\ttry {\n\t\t\tboolean value = (Boolean)state.convertValue(getChild(0).getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t\treturn BooleanTypedValue.forValue(!value);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getChild(0).getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Override\n\tpublic BooleanTypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tboolean leftValue;\n\t\tboolean rightValue;\n\t\ttry {\n\t\t\tleftValue = state.convertValue(getLeftOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getLeftOperand().getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\n\t\tif (leftValue == true) {\n\t\t\treturn BooleanTypedValue.True; // no need to evaluate right operand\n\t\t}\n\n\t\ttry {\n\t\t\trightValue = state.convertValue(getRightOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getRightOperand().getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\n\t\treturn BooleanTypedValue.forValue(leftValue || rightValue);\n\t}","id":37078,"modified_method":"@Override\n\tpublic BooleanTypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tboolean leftValue;\n\t\tboolean rightValue;\n\t\ttry { \n\t\t\tleftValue = (Boolean)state.convertValue(getLeftOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getLeftOperand().getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\n\t\tif (leftValue == true) {\n\t\t\treturn BooleanTypedValue.True; // no need to evaluate right operand\n\t\t}\n\n\t\ttry {\n\t\t\trightValue = (Boolean)state.convertValue(getRightOperand().getValueInternal(state), BOOLEAN_TYPE_DESCRIPTOR);\n\t\t}\n\t\tcatch (SpelException see) {\n\t\t\tsee.setPosition(getRightOperand().getCharPositionInLine());\n\t\t\tthrow see;\n\t\t}\n\n\t\treturn BooleanTypedValue.forValue(leftValue || rightValue);\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@SuppressWarnings(\"unchecked\")\r\n\tpublic <T> T convertValue(Object value, TypeDescriptor typeDescriptor) throws EvaluationException {\r\n// For activation when conversion service available - this replaces the rest of the method (probably...)\r\n//\t\ttry {\r\n//\t\t\treturn (T)conversionService.executeConversion(value, typeDescriptor);\r\n//\t\t} catch (ConversionExecutorNotFoundException cenfe) {\r\n//\t\t\tthrow new SpelException(cenfe, SpelMessages.TYPE_CONVERSION_ERROR, value.getClass(), typeDescriptor.asString());\r\n//\t\t} catch (ConversionException ce) {\r\n//\t\t\tthrow new SpelException(ce, SpelMessages.TYPE_CONVERSION_ERROR, value.getClass(), typeDescriptor.asString());\r\n//\t\t}\r\n\t\treturn (T)convertValue(value,typeDescriptor.getType());\r\n\t}","id":37079,"modified_method":"@SuppressWarnings(\"unchecked\")\r\n\tpublic Object convertValue(Object value, TypeDescriptor typeDescriptor) throws EvaluationException {\r\n// For activation when conversion service available - this replaces the rest of the method (probably...)\r\n//\t\ttry {\r\n//\t\t\treturn (T)conversionService.executeConversion(value, typeDescriptor);\r\n//\t\t} catch (ConversionExecutorNotFoundException cenfe) {\r\n//\t\t\tthrow new SpelException(cenfe, SpelMessages.TYPE_CONVERSION_ERROR, value.getClass(), typeDescriptor.asString());\r\n//\t\t} catch (ConversionException ce) {\r\n//\t\t\tthrow new SpelException(ce, SpelMessages.TYPE_CONVERSION_ERROR, value.getClass(), typeDescriptor.asString());\r\n//\t\t}\r\n\t\treturn convertValue(value,typeDescriptor.getType());\r\n\t}","commit_id":"707d2ed72a67bad783ef0a456cf800a777166602","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToString(java.lang.Object,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic String convertToString(Object value, Locale locale)\n\t\t{\n\t\t\tif (value == null || \"\".equals(value))\n\t\t\t{\n\t\t\t\treturn \"\";\n\t\t\t}\n\n\t\t\tfinal Object converted = Objects.convertValue(value, String.class);\n\t\t\tif (converted == null)\n\t\t\t{\n\t\t\t\t// object was converted to null\n\t\t\t\treturn \"\";\n\t\t\t}\n\t\t\telse if (converted instanceof String)\n\t\t\t{\n\t\t\t\t// object was successfully converted to a string\n\t\t\t\treturn (String)converted;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// object could not be converted to a string, hardcast to string\n\t\t\t\tthrow new ConversionException(\"Could not convert object of type: \" +\n\t\t\t\t\tvalue.getClass() + \" to string. Possible its #toString() returned null. \" +\n\t\t\t\t\t\"Either install a custom converter (see IConverterLocator) or \" +\n\t\t\t\t\t\"override #toString() to return a non-null value.\");\n\t\t\t}\n\t\t}","id":37080,"modified_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToString(java.lang.Object,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic String convertToString(Object value, Locale locale)\n\t\t{\n\t\t\tif (value == null || \"\".equals(value))\n\t\t\t{\n\t\t\t\treturn \"\";\n\t\t\t}\n\n\t\t\ttry\n\t\t\t{\n\t\t\t\treturn (String)Objects.convertValue(value, String.class);\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\tthrow new ConversionException(\"Could not convert object of type: \" +\n\t\t\t\t\tvalue.getClass() + \" to string. Possible its #toString() returned null. \" +\n\t\t\t\t\t\"Either install a custom converter (see IConverterLocator) or \" +\n\t\t\t\t\t\"override #toString() to return a non-null value.\").setSourceValue(value)\n\t\t\t\t\t.setConverter(this);\n\t\t\t}\n\t\t}","commit_id":"a69a4d92c645cc70fdc02130819140599a51365a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic X convertToObject(String value, Locale locale)\n\t\t{\n\t\t\tif (value == null)\n\t\t\t{\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tClass<X> theType = type.get();\n\t\t\tif (\"\".equals(value))\n\t\t\t{\n\t\t\t\tif (theType.equals(String.class))\n\t\t\t\t{\n\t\t\t\t\treturn theType.cast(\"\");\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\ttry\n\t\t\t{\n\t\t\t\treturn Objects.convertValue(value, theType);\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\tthrow new ConversionException(e.getMessage(), e).setSourceValue(value);\n\t\t\t}\n\t\t}","id":37081,"modified_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic X convertToObject(String value, Locale locale)\n\t\t{\n\t\t\tif (value == null)\n\t\t\t{\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tClass<X> theType = type.get();\n\t\t\tif (\"\".equals(value))\n\t\t\t{\n\t\t\t\tif (theType.equals(String.class))\n\t\t\t\t{\n\t\t\t\t\treturn theType.cast(\"\");\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\ttry\n\t\t\t{\n\t\t\t\t// FIXME figure out what to do here. if the object cannot be converted to the type\n\t\t\t\t// then either it becomes null or classcastexception. see WICKET-1706. */\n\t\t\t\treturn (X)Objects.convertValue(value, theType);\n\t\t\t}\n\t\t\tcatch (Exception e)\n\t\t\t{\n\t\t\t\tthrow new ConversionException(e.getMessage(), e).setSourceValue(value);\n\t\t\t}\n\t\t}","commit_id":"b7aa86a48b2f09147ee4af57c6afd646929b44e6","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToString(java.lang.Object,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic String convertToString(X value, Locale locale)\n\t\t{\n\t\t\tif (value == null || \"\".equals(value))\n\t\t\t{\n\t\t\t\treturn \"\";\n\t\t\t}\n\n\t\t\treturn Objects.convertValue(value, String.class);\n\t\t}","id":37082,"modified_method":"/**\n\t\t * @see org.apache.wicket.util.convert.IConverter#convertToString(java.lang.Object,\n\t\t *      java.util.Locale)\n\t\t */\n\t\tpublic String convertToString(X value, Locale locale)\n\t\t{\n\t\t\tif (value == null || \"\".equals(value))\n\t\t\t{\n\t\t\t\treturn \"\";\n\t\t\t}\n\n\t\t\treturn (String)Objects.convertValue(value, String.class);\n\t\t}","commit_id":"b7aa86a48b2f09147ee4af57c6afd646929b44e6","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * Returns the value converted numerically to the given class type\n\t * \n\t * This method also detects when arrays are being converted and converts the components of one\n\t * array to the type of the other.\n\t * \n\t * @param <T>\n\t *            type to convert to\n\t * \n\t * @param value\n\t *            an object to be converted to the given type\n\t * @param toType\n\t *            class type to be converted to\n\t * @return converted value of the type given, or value if the value cannot be converted to the\n\t *         given type.\n\t */\n\tpublic static <T> T convertValue(Object value, Class<T> toType)\n\t{\n\t\tObject result = null;\n\n\t\tif (value != null)\n\t\t{\n\t\t\t/* If array -> array then convert components of array individually */\n\t\t\tif (value.getClass().isArray() && toType.isArray())\n\t\t\t{\n\t\t\t\tClass<?> componentType = toType.getComponentType();\n\n\t\t\t\tresult = Array.newInstance(componentType, Array.getLength(value));\n\t\t\t\tfor (int i = 0, icount = Array.getLength(value); i < icount; i++)\n\t\t\t\t{\n\t\t\t\t\tArray.set(result, i, convertValue(Array.get(value, i), componentType));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif ((toType == Integer.class) || (toType == Integer.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Integer((int)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Double.class) || (toType == Double.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Double(doubleValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Boolean.class) || (toType == Boolean.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = booleanValue(value) ? Boolean.TRUE : Boolean.FALSE;\n\t\t\t\t}\n\t\t\t\tif ((toType == Byte.class) || (toType == Byte.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Byte((byte)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Character.class) || (toType == Character.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Character((char)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Short.class) || (toType == Short.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Short((short)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Long.class) || (toType == Long.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Long(longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Float.class) || (toType == Float.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Float(doubleValue(value));\n\t\t\t\t}\n\t\t\t\tif (toType == BigInteger.class)\n\t\t\t\t{\n\t\t\t\t\tresult = bigIntValue(value);\n\t\t\t\t}\n\t\t\t\tif (toType == BigDecimal.class)\n\t\t\t\t{\n\t\t\t\t\tresult = bigDecValue(value);\n\t\t\t\t}\n\t\t\t\tif (toType == String.class)\n\t\t\t\t{\n\t\t\t\t\tresult = stringValue(value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (toType.isPrimitive())\n\t\t\t{\n\t\t\t\tresult = primitiveDefaults.get(toType);\n\t\t\t}\n\t\t}\n\t\treturn toType.cast(result);\n\t}","id":37083,"modified_method":"/**\n\t * Returns the value converted numerically to the given class type\n\t * \n\t * This method also detects when arrays are being converted and converts the components of one\n\t * array to the type of the other.\n\t * \n\t * @param value\n\t *            an object to be converted to the given type\n\t * @param toType\n\t *            class type to be converted to\n\t * @return converted value of the type given, or value if the value cannot be converted to the\n\t *         given type.\n\t */\n\tpublic static Object convertValue(final Object value, final Class<?> toType)\n\t{\n\t\tObject result = null;\n\n\t\tif (value != null)\n\t\t{\n\t\t\t/* If array -> array then convert components of array individually */\n\t\t\tif (value.getClass().isArray() && toType.isArray())\n\t\t\t{\n\t\t\t\tClass<?> componentType = toType.getComponentType();\n\n\t\t\t\tresult = Array.newInstance(componentType, Array.getLength(value));\n\t\t\t\tfor (int i = 0, icount = Array.getLength(value); i < icount; i++)\n\t\t\t\t{\n\t\t\t\t\tArray.set(result, i, convertValue(Array.get(value, i), componentType));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif ((toType == Integer.class) || (toType == Integer.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Integer((int)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Double.class) || (toType == Double.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Double(doubleValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Boolean.class) || (toType == Boolean.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = booleanValue(value) ? Boolean.TRUE : Boolean.FALSE;\n\t\t\t\t}\n\t\t\t\tif ((toType == Byte.class) || (toType == Byte.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Byte((byte)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Character.class) || (toType == Character.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Character((char)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Short.class) || (toType == Short.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Short((short)longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Long.class) || (toType == Long.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Long(longValue(value));\n\t\t\t\t}\n\t\t\t\tif ((toType == Float.class) || (toType == Float.TYPE))\n\t\t\t\t{\n\t\t\t\t\tresult = new Float(doubleValue(value));\n\t\t\t\t}\n\t\t\t\tif (toType == BigInteger.class)\n\t\t\t\t{\n\t\t\t\t\tresult = bigIntValue(value);\n\t\t\t\t}\n\t\t\t\tif (toType == BigDecimal.class)\n\t\t\t\t{\n\t\t\t\t\tresult = bigDecValue(value);\n\t\t\t\t}\n\t\t\t\tif (toType == String.class)\n\t\t\t\t{\n\t\t\t\t\tresult = stringValue(value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (toType.isPrimitive())\n\t\t\t{\n\t\t\t\tresult = primitiveDefaults.get(toType);\n\t\t\t}\n\t\t}\n\t\treturn (result != null) ? result : value;\n\t}","commit_id":"b7aa86a48b2f09147ee4af57c6afd646929b44e6","url":"https://github.com/apache/wicket"},{"original_method":"public LoggingConfiguration configure() {\n    Logback.configure(\"/org/sonar/batch/bootstrapper/logback.xml\", substitutionVariables);\n    return this;\n  }","id":37084,"modified_method":"LoggingConfiguration configure() {\n    Logback.configure(\"/org/sonar/batch/bootstrapper/logback.xml\", substitutionVariables);\n    return this;\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public LoggingConfiguration setProperties(Map<String, String> properties) {\n    setShowSql(\"true\".equals(properties.get(\"sonar.showSql\")));\n    setVerbose(\"true\".equals(properties.get(\"sonar.verbose\")));\n    return this;\n  }","id":37085,"modified_method":"public LoggingConfiguration setProperties(Map<String, String> properties) {\n    setShowSql(\"true\".equals(properties.get(\"sonar.showSql\")));\n    setShowSqlResults(\"true\".equals(properties.get(\"sonar.showSqlResults\")));\n    setVerbose(\"true\".equals(properties.get(\"sonar.verbose\")));\n    return this;\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public LoggingConfiguration configure(File logbackFile) {\n    Logback.configure(logbackFile, substitutionVariables);\n    return this;\n  }","id":37086,"modified_method":"LoggingConfiguration configure(File logbackFile) {\n    Logback.configure(logbackFile, substitutionVariables);\n    return this;\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public static LoggingConfiguration create() {\n    return new LoggingConfiguration();\n  }","id":37087,"modified_method":"static LoggingConfiguration create() {\n    return new LoggingConfiguration();\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public LoggingConfiguration configure(String classloaderPath) {\n    Logback.configure(classloaderPath, substitutionVariables);\n    return this;\n  }","id":37088,"modified_method":"LoggingConfiguration configure(String classloaderPath) {\n    Logback.configure(classloaderPath, substitutionVariables);\n    return this;\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public void execute() throws MojoExecutionException, MojoFailureException {\n    configureLogging();\n    executeBatch();\n  }","id":37089,"modified_method":"public void execute() throws MojoExecutionException, MojoFailureException {\n    ProjectDefinition def = MavenProjectConverter.convert(session.getSortedProjects(), project);\n    ProjectReactor reactor = new ProjectReactor(def);\n\n    Batch batch = Batch.builder()\n      .setEnvironment(getEnvironmentInformation())\n      .setProjectReactor(reactor)\n      .addComponents(\n        session, getLog(), lifecycleExecutor, pluginManager, artifactFactory,\n        localRepository, artifactMetadataSource, artifactCollector, dependencyTreeBuilder,\n        projectBuilder, Maven2PluginExecutor.class)\n      .build();\n\n    configureLogging(batch.getLoggingConfiguration());\n    batch.execute();\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void executeBatch() throws MojoExecutionException {\n    ProjectDefinition def = MavenProjectConverter.convert(session.getSortedProjects(), project);\n    ProjectReactor reactor = new ProjectReactor(def);\n\n    Batch batch = new Batch(reactor, session, getLog(), lifecycleExecutor, pluginManager, artifactFactory,\n      localRepository, artifactMetadataSource, artifactCollector, dependencyTreeBuilder,\n      projectBuilder, getEnvironmentInformation(), Maven2PluginExecutor.class);\n    batch.execute();\n  }","id":37090,"modified_method":"private void configureLogging(LoggingConfiguration logging) {\n    logging.setProperties((Map) session.getExecutionProperties());\n    logging.setFormat(LoggingConfiguration.FORMAT_MAVEN);\n    if (getLog().isDebugEnabled()) {\n      logging.setVerbose(true);\n    }\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"public void execute() throws MojoExecutionException, MojoFailureException {\n    configureLogging();\n    executeBatch();\n  }","id":37091,"modified_method":"public void execute() throws MojoExecutionException, MojoFailureException {\n    ProjectDefinition def = MavenProjectConverter.convert(session.getSortedProjects(), project);\n    ProjectReactor reactor = new ProjectReactor(def);\n\n    Batch batch = Batch.builder()\n      .setEnvironment(getEnvironmentInformation())\n      .setProjectReactor(reactor)\n      .addComponents(\n        session, getLog(), lifecycleExecutor, artifactFactory, localRepository, artifactMetadataSource, artifactCollector,\n        dependencyTreeBuilder, projectBuilder, Maven3PluginExecutor.class)\n      .build();\n\n    configureLogging(batch.getLoggingConfiguration());\n    batch.execute();\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void executeBatch() throws MojoExecutionException {\n    ProjectDefinition def = MavenProjectConverter.convert(session.getSortedProjects(), project);\n    ProjectReactor reactor = new ProjectReactor(def);\n\n    Batch batch = new Batch(reactor, session, getLog(), lifecycleExecutor, artifactFactory,\n      localRepository, artifactMetadataSource, artifactCollector, dependencyTreeBuilder,\n      projectBuilder, getEnvironmentInformation(), Maven3PluginExecutor.class);\n    batch.execute();\n  }","id":37092,"modified_method":"private void configureLogging(LoggingConfiguration logging) {\n    logging.setProperties((Map) session.getSystemProperties());\n    logging.setFormat(LoggingConfiguration.FORMAT_MAVEN);\n    if (getLog().isDebugEnabled()) {\n      logging.setVerbose(true);\n    }\n  }","commit_id":"82e006da834823718fb6ac0b579dff772db2d599","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@Override\n    public VolumeInfo createVolumeOnPrimaryStorage(VirtualMachine vm, VolumeInfo volume, HypervisorType rootDiskHyperType, StoragePool storagePool) throws NoTransitionException {\n        VirtualMachineTemplate rootDiskTmplt = _entityMgr.findById(VirtualMachineTemplate.class, vm.getTemplateId());\n        DataCenter dcVO = _entityMgr.findById(DataCenter.class, vm.getDataCenterId());\n        Pod pod = _entityMgr.findById(Pod.class, vm.getPodIdToDeployIn());\n\n        ServiceOffering svo = _entityMgr.findById(ServiceOffering.class, vm.getServiceOfferingId());\n        DiskOffering diskVO = _entityMgr.findById(DiskOffering.class, volume.getDiskOfferingId());\n        Long clusterId = (storagePool == null ? null : storagePool.getClusterId());\n\n        VolumeInfo vol = null;\n        if (volume.getState() == Volume.State.Allocated) {\n            vol = createVolume(volume, vm, rootDiskTmplt, dcVO, pod, clusterId, svo, diskVO, new ArrayList<StoragePool>(), volume.getSize(), rootDiskHyperType);\n        } else if (volume.getState() == Volume.State.Uploaded) {\n            vol = copyVolume(storagePool, volume, vm, rootDiskTmplt, dcVO, pod, diskVO, svo, rootDiskHyperType);\n            if (vol != null) {\n                // Moving of Volume is successful, decrement the volume resource count from secondary for an account and increment it into primary storage under same account.\n                _resourceLimitMgr.decrementResourceCount(volume.getAccountId(), ResourceType.secondary_storage, volume.getSize());\n                _resourceLimitMgr.incrementResourceCount(volume.getAccountId(), ResourceType.primary_storage, volume.getSize());\n            }\n        }\n\n        if (vol == null) {\n            throw new CloudRuntimeException(\"Volume shouldn't be null \" + volume.getId());\n        }\n        VolumeVO volVO = _volsDao.findById(vol.getId());\n        volVO.setFormat(getSupportedImageFormatForCluster(rootDiskHyperType));\n        _volsDao.update(volVO.getId(), volVO);\n        return volFactory.getVolume(volVO.getId());\n    }","id":37093,"modified_method":"@Override\n    public VolumeInfo createVolumeOnPrimaryStorage(VirtualMachine vm, VolumeInfo volume, HypervisorType rootDiskHyperType, StoragePool storagePool) throws NoTransitionException {\n        VirtualMachineTemplate rootDiskTmplt = _entityMgr.findById(VirtualMachineTemplate.class, vm.getTemplateId());\n        DataCenter dcVO = _entityMgr.findById(DataCenter.class, vm.getDataCenterId());\n        Pod pod = _entityMgr.findById(Pod.class, vm.getPodIdToDeployIn());\n\n        ServiceOffering svo = _entityMgr.findById(ServiceOffering.class, vm.getServiceOfferingId());\n        DiskOffering diskVO = _entityMgr.findById(DiskOffering.class, volume.getDiskOfferingId());\n        Long clusterId = (storagePool == null ? null : storagePool.getClusterId());\n\n        VolumeInfo vol = null;\n        if (volume.getState() == Volume.State.Allocated) {\n            vol = createVolume(volume, vm, rootDiskTmplt, dcVO, pod, clusterId, svo, diskVO, new ArrayList<StoragePool>(), volume.getSize(), rootDiskHyperType);\n        } else if (volume.getState() == Volume.State.Uploaded) {\n            vol = copyVolume(storagePool, volume, vm, rootDiskTmplt, dcVO, pod, diskVO, svo, rootDiskHyperType);\n            if (vol != null) {\n                // Moving of Volume is successful, decrement the volume resource count from secondary for an account and increment it into primary storage under same account.\n                _resourceLimitMgr.decrementResourceCount(volume.getAccountId(), ResourceType.secondary_storage, volume.getSize());\n                _resourceLimitMgr.incrementResourceCount(volume.getAccountId(), ResourceType.primary_storage, volume.getSize());\n            }\n        }\n\n        if (vol == null) {\n            throw new CloudRuntimeException(\"Volume shouldn't be null \" + volume.getId());\n        }\n        VolumeVO volVO = _volsDao.findById(vol.getId());\n        if (volVO.getFormat() == null) {\n            volVO.setFormat(getSupportedImageFormatForCluster(rootDiskHyperType));\n        }\n        _volsDao.update(volVO.getId(), volVO);\n        return volFactory.getVolume(volVO.getId());\n    }","commit_id":"66d1eb92f03c39734dcaf83e20639cd9a338e388","url":"https://github.com/apache/cloudstack"},{"original_method":"public void stop() {\n    startBroadcast = false;\n    if (recorder != null) {\n\n      try {\n        recorder.stop();\n        recorder.release();\n        grabber.stop();\n      } catch (Exception e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n      }\n    }\n  }","id":37094,"modified_method":"public void stop() {\n    startBroadcast = false;\n    if (mainRecorder != null) {\n\n      try {\n        mainRecorder.stop();\n        mainRecorder.release();\n        grabber.stop();\n      } catch (Exception e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n      }\n    }\n  }","commit_id":"d64f20cb631e54f62a2c336258950fe1304b98f3","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private FFmpegFrameGrabber setupMacOsXGrabber(int width, int height, int x, int y) {\n    \n    //ffmpeg -f avfoundation -i \"Capture screen 0\" test.mkv\n    String inputDevice = \"Capture screen 0\";     \n    String videoSize = new Integer(width).toString().concat(\"x\").concat(new Integer(height).toString());\n\n    System.out.println(\"Setting up grabber for linux.\");\n    System.out.println(\"input:\" + inputDevice + \" videoSize:\" + videoSize);\n    \n    FFmpegFrameGrabber macGrabber = new FFmpegFrameGrabber(inputDevice);\n    macGrabber.setOption(\"video_size\", videoSize); \n    macGrabber.setFormat(\"avfoundation\");\n    return macGrabber;\n  }","id":37095,"modified_method":"private FFmpegFrameGrabber setupMacOsXGrabber(int width, int height, int x, int y) {\n    \n    //ffmpeg -f avfoundation -i \"Capture screen 0\" test.mkv\n    String inputDevice = \"Capture screen 0:none\";     \n    String videoSize = new Integer(width).toString().concat(\"x\").concat(new Integer(height).toString());\n\n    System.out.println(\"Setting up grabber for macosx.\");\n    System.out.println(\"input:\" + inputDevice + \" videoSize:\" + videoSize);\n    \n    FFmpegFrameGrabber macGrabber = new FFmpegFrameGrabber(inputDevice);\n    macGrabber.setImageWidth(width);\n    macGrabber.setImageHeight(height);\n    macGrabber.setFrameRate(frameRate);\n    macGrabber.setPixelFormat(AV_PIX_FMT_BGR0);\n    macGrabber.setFormat(\"avfoundation\");\n    macGrabber.setOption(\"capture_cursor\", \"1\");\n    macGrabber.setOption(\"capture_mouse_clicks\", \"1\");\n    return macGrabber;\n  }","commit_id":"d64f20cb631e54f62a2c336258950fe1304b98f3","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private void captureScreen() {\n    long now = System.currentTimeMillis();\n\n    Frame frame;\n    try {\n      frame = grabber.grabImage();\n      if (frame != null) {\n        try {\n          recorder.record(frame);\n        } catch (Exception e) {\n          // TODO Auto-generated catch block\n          e.printStackTrace();\n        }\n      }\n    } catch (Exception e1) {\n      // TODO Auto-generated catch block\n      e1.printStackTrace();\n    }\n\n\n    long sleepFramerate = (long) (1000 / frameRate);\n    long timestamp = now - startTime;\n    recorder.setTimestamp(timestamp * 1000);\n\n    //        System.out.println(\"i=[\" + i + \"] timestamp=[\" + timestamp + \"]\");\n    recorder.setFrameNumber(frameNumber);\n\n//    System.out.println(\"[ENCODER] encoded image \" + frameNumber + \" in \" + (System.currentTimeMillis() - now));\n    frameNumber++;\n\n    long execDuration = (System.currentTimeMillis() - now);\n    long sleepDuration = Math.max(sleepFramerate - execDuration, 0);\n    pause(sleepDuration);\n\n  }","id":37096,"modified_method":"private void captureScreen() {\n    long now = System.currentTimeMillis();\n\n    Frame frame;\n    try {\n      frame = grabber.grabImage();\n      if (frame != null) {\n        try {\n          mainRecorder.record(frame);\n        } catch (Exception e) {\n          // TODO Auto-generated catch block\n          e.printStackTrace();\n        }\n      }\n    } catch (Exception e1) {\n      // TODO Auto-generated catch block\n      e1.printStackTrace();\n    }\n\n\n    long sleepFramerate = (long) (1000 / frameRate);\n    long timestamp = now - startTime;\n    mainRecorder.setTimestamp(timestamp * 1000);\n\n    //        System.out.println(\"i=[\" + i + \"] timestamp=[\" + timestamp + \"]\");\n    mainRecorder.setFrameNumber(frameNumber);\n\n//    System.out.println(\"[ENCODER] encoded image \" + frameNumber + \" in \" + (System.currentTimeMillis() - now));\n    frameNumber++;\n\n    long execDuration = (System.currentTimeMillis() - now);\n    long sleepDuration = Math.max(sleepFramerate - execDuration, 0);\n    pause(sleepDuration);\n\n  }","commit_id":"d64f20cb631e54f62a2c336258950fe1304b98f3","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"public void go(String URL, int x, int y, int width, int height) throws IOException, BBBFrameRecorder.Exception, \n                  AWTException, InterruptedException {\n  \n    System.out.println(\"Java temp dir : \" + System.getProperty(\"java.io.tmpdir\"));\n    System.out.println(\"Java name : \" + System.getProperty(\"java.vm.name\"));\n    System.out.println(\"OS name : \" + System.getProperty(\"os.name\"));\n    System.out.println(\"OS arch : \" + System.getProperty(\"os.arch\"));\n    System.out.println(\"JNA Path : \" + System.getProperty(\"jna.library.path\"));\n    System.out.println(\"Platform : \" + Loader.getPlatform());\n    System.out.println(\"Capturing w=[\" + width + \"] h=[\" + height + \"] at x=[\" + x + \"] y=[\" + y + \"]\");\n    \n    Map<String, String> codecOptions = splitToMap(ssi.codecOptions, \"&\", \"=\");\n    Double frameRate = parseFrameRate(codecOptions.get(FRAMERATE_KEY));\n    \n    String platform = Loader.getPlatform();\n    String osName = System.getProperty(\"os.name\").toLowerCase();\n    if (platform.startsWith(\"windows\")) {\n      grabber = setupWindowsGrabber(width, height, x, y);\n    } else if (osName.startsWith(\"linux\")) {\n      grabber = setupLinuxGrabber(width, height, x, y);\n    } else if (platform.startsWith(\"macosx\")) {\n      grabber = setupMacOsXGrabber(width, height, x, y);\n    }\n    \n\n    grabber.setFrameRate(frameRate);\n    try {\n      grabber.start();\n    } catch (org.bytedeco.javacv.FrameGrabber.Exception e) {\n      // TODO Auto-generated catch block\n      e.printStackTrace();\n    }\n    \n    recorder = new FFmpegFrameRecorder(URL, grabber.getImageWidth(), grabber.getImageHeight());\n    \n    useH264(recorder, codecOptions);\n    \n    startTime = System.currentTimeMillis();\n    \n    try {\n      recorder.start();\n    } catch (Exception e1) {\n      // TODO Auto-generated catch block\n      e1.printStackTrace();\n    }\n  }","id":37097,"modified_method":"public void go(String URL, int x, int y, int width, int height) throws IOException, BBBFrameRecorder.Exception, \n                  AWTException, InterruptedException {\n  \n    System.out.println(\"Java temp dir : \" + System.getProperty(\"java.io.tmpdir\"));\n    System.out.println(\"Java name : \" + System.getProperty(\"java.vm.name\"));\n    System.out.println(\"OS name : \" + System.getProperty(\"os.name\"));\n    System.out.println(\"OS arch : \" + System.getProperty(\"os.arch\"));\n    System.out.println(\"JNA Path : \" + System.getProperty(\"jna.library.path\"));\n    System.out.println(\"Platform : \" + Loader.getPlatform());\n    System.out.println(\"Capturing w=[\" + width + \"] h=[\" + height + \"] at x=[\" + x + \"] y=[\" + y + \"]\");\n    \n    Map<String, String> codecOptions = splitToMap(ssi.codecOptions, \"&\", \"=\");\n    Double frameRate = parseFrameRate(codecOptions.get(FRAMERATE_KEY));\n    \n    String platform = Loader.getPlatform();\n    String osName = System.getProperty(\"os.name\").toLowerCase();\n    if (platform.startsWith(\"windows\")) {\n      grabber = setupWindowsGrabber(width, height, x, y);\n      mainRecorder = setupWindowsRecorder(URL, width, height, codecOptions);\n    } else if (platform.startsWith(\"linux\")) {\n      grabber = setupLinuxGrabber(width, height, x, y);\n      mainRecorder = setupLinuxRecorder(URL, width, height, codecOptions);\n    } else if (platform.startsWith(\"macosx-x86_64\")) {\n      grabber = setupMacOsXGrabber(width, height, x, y);\n      mainRecorder = setupMacOsXRecorder(URL, width, height, codecOptions);\n    }\n    \n    grabber.setFrameRate(frameRate);\n    try {\n      grabber.start();\n    } catch (org.bytedeco.javacv.FrameGrabber.Exception e) {\n      // TODO Auto-generated catch block\n      e.printStackTrace();\n    }\n    \n    \n    \n//    useH264(recorder, codecOptions);\n    \n    startTime = System.currentTimeMillis();\n    \n    try {\n      mainRecorder.start();\n    } catch (Exception e1) {\n      // TODO Auto-generated catch block\n      e1.printStackTrace();\n    }\n  }","commit_id":"d64f20cb631e54f62a2c336258950fe1304b98f3","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"private FFmpegFrameGrabber setupLinuxGrabber(int width, int height, int x, int y) {\n    // ffmpeg -video_size 1024x768 -framerate 25 -f x11grab -i :0.0+100,200 output.mp4\n    // This will grab the image from desktop, starting with the upper-left corner at (x=100, y=200) \n    // with the width and height of 1024x768.\n\n    String inputDevice = \":\"; \n    if (ssi.fullScreen) {\n      inputDevice.concat(new Integer(0).toString()).concat(\".\").concat(new Integer(0).toString());\n      inputDevice.concat(\"+\").concat(new Integer(0).toString()).concat(\",\").concat(new Integer(0).toString());     \n    } else {\n      inputDevice.concat(new Integer(0).toString()).concat(\".\").concat(new Integer(0).toString());\n      inputDevice.concat(\"+\").concat(new Integer(x).toString()).concat(\",\").concat(new Integer(y).toString());      \n    }\n    \n    String videoSize = new Integer(width).toString().concat(\"x\").concat(new Integer(height).toString());\n    \n    System.out.println(\"Setting up grabber for linux.\");\n    System.out.println(\"input:\" + inputDevice + \" videoSize:\" + videoSize);\n    \n    FFmpegFrameGrabber linuxGrabber = new FFmpegFrameGrabber(inputDevice);\n    linuxGrabber.setImageWidth(width);\n    linuxGrabber.setImageHeight(height);\n    linuxGrabber.setOption(\"video_size\", videoSize); \n    linuxGrabber.setFormat(\"x11grab\");    \n    return linuxGrabber;\n  }","id":37098,"modified_method":"private FFmpegFrameGrabber setupLinuxGrabber(int width, int height, int x, int y) {\n    // ffmpeg -video_size 1024x768 -framerate 25 -f x11grab -i :0.0+100,200 output.mp4\n    // This will grab the image from desktop, starting with the upper-left corner at (x=100, y=200) \n    // with the width and height of 1024x768.\n\n    String inputDevice = \":\"; \n    if (ssi.fullScreen) {\n      inputDevice = inputDevice.concat(new Integer(0).toString()).concat(\".\").concat(new Integer(0).toString());\n      inputDevice = inputDevice.concat(\"+\").concat(new Integer(0).toString()).concat(\",\").concat(new Integer(0).toString());     \n    } else {\n      inputDevice = inputDevice.concat(new Integer(0).toString()).concat(\".\").concat(new Integer(0).toString());\n      inputDevice = inputDevice.concat(\"+\").concat(new Integer(x).toString()).concat(\",\").concat(new Integer(y).toString());      \n    }\n    \n    String videoSize = new Integer(width).toString().concat(\"x\").concat(new Integer(height).toString());\n    \n    System.out.println(\"Setting up grabber for linux.\");\n    System.out.println(\"input:\" + inputDevice + \" videoSize:\" + videoSize);\n    \n    FFmpegFrameGrabber linuxGrabber = new FFmpegFrameGrabber(inputDevice);\n    linuxGrabber.setImageWidth(width);\n    linuxGrabber.setImageHeight(height);\n    linuxGrabber.setOption(\"video_size\", videoSize); \n    linuxGrabber.setFormat(\"x11grab\");    \n    return linuxGrabber;\n  }","commit_id":"d64f20cb631e54f62a2c336258950fe1304b98f3","url":"https://github.com/bigbluebutton/bigbluebutton"},{"original_method":"ImageEditorImpl(@NotNull Project project, @NotNull VirtualFile file) {\n        this.project = project;\n        this.file = file;\n\n        // Options\n        Options options = OptionsManager.getInstance().getOptions();\n        editorUI = new ImageEditorUI(this, options.getEditorOptions());\n        options.addPropertyChangeListener(optionsChangeListener);\n\n        VirtualFileManager.getInstance().addVirtualFileListener(this);\n\n        setValue(file);\n    }","id":37099,"modified_method":"ImageEditorImpl(@NotNull Project project, @NotNull final ImageContentProvider contentProvider) {\n    this.project = project;\n    this.contentProvider = contentProvider;\n\n    // Options\n    Options options = OptionsManager.getInstance().getOptions();\n    editorUI = new ImageEditorUI(this, options.getEditorOptions());\n    options.addPropertyChangeListener(optionsChangeListener);\n\n    contentProvider.addContentChangeListener(new ImageContentProvider.ContentChangeListener() {\n      public void contentChanged() {\n        setValue(contentProvider.getContent());\n      }\n    });\n    setValue(contentProvider.getContent());\n  }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n    public VirtualFile getFile() {\n        return file;\n    }","id":37100,"modified_method":"@Nullable\n  public VirtualFile getFile() {\n    return contentProvider.getVirtualFile();\n  }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void dispose() {\n        Options options = OptionsManager.getInstance().getOptions();\n        options.removePropertyChangeListener(optionsChangeListener);\n        editorUI.dispose();\n        VirtualFileManager.getInstance().removeVirtualFileListener(this);\n        disposed = true;\n    }","id":37101,"modified_method":"public void dispose() {\n        Options options = OptionsManager.getInstance().getOptions();\n        options.removePropertyChangeListener(optionsChangeListener);\n        editorUI.dispose();\n        disposed = true;\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * Create image viewer editor. Don't forget release editor by {@link #releaseImageEditor(ImageEditor)} method.\n   *\n   * @param project Project\n   * @param file    File\n   * @return Image editor for file\n   */\n  @NotNull\n  public static ImageEditor createImageEditor(@NotNull Project project, @NotNull VirtualFile file) {\n    return new ImageEditorImpl(project, file);\n  }","id":37102,"modified_method":"/**\n   * Create image viewer editor. Don't forget release editor by {@link #releaseImageEditor(ImageEditor)} method.\n   *\n   * @param project Project\n   * @param file    File\n   * @return Image editor for file\n   */\n  @NotNull\n  public static ImageEditor createImageEditor(@NotNull Project project, @NotNull ImageContentProvider contentProvider) {\n    return new ImageEditorImpl(project, contentProvider);\n  }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void updateInfo() {\n        ImageDocument document = imageComponent.getDocument();\n        BufferedImage image = document.getValue();\n        if (image != null) {\n            ColorModel colorModel = image.getColorModel();\n            String format = document.getFormat();\n            if (format == null) {\n                format = ImagesBundle.message(\"unknown.format\");\n            } else {\n                format = format.toUpperCase();\n            }\n            VirtualFile file = editor.getFile();\n            infoLabel.setText(\n                    ImagesBundle.message(\"image.info\",\n                            image.getWidth(), image.getHeight(), format,\n                            colorModel.getPixelSize(), file != null ? StringUtil.formatFileSize(file.getLength()) : \"\"));\n        } else {\n            infoLabel.setText(null);\n        }\n    }","id":37103,"modified_method":"private void updateInfo() {\n        ImageDocument document = imageComponent.getDocument();\n        BufferedImage image = document.getValue();\n        if (image != null) {\n            ColorModel colorModel = image.getColorModel();\n            String format = document.getFormat();\n            if (format == null) {\n                format = ImagesBundle.message(\"unknown.format\");\n            } else {\n                format = format.toUpperCase();\n            }\n            infoLabel.setText(\n                    ImagesBundle.message(\"image.info\",\n                            image.getWidth(), image.getHeight(), format,\n                            colorModel.getPixelSize(), StringUtil.formatFileSize(editor.getFileLength())));\n        } else {\n            infoLabel.setText(null);\n        }\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n    public Object getData(String dataId) {\n\n        if (PlatformDataKeys.PROJECT.is(dataId)) {\n            return editor.getProject();\n        } else if (PlatformDataKeys.VIRTUAL_FILE.is(dataId)) {\n            return editor.getFile();\n        } else if (PlatformDataKeys.VIRTUAL_FILE_ARRAY.is(dataId)) {\n            return new VirtualFile[]{editor.getFile()};\n        } else if (LangDataKeys.PSI_FILE.is(dataId)) {\n            return getData(LangDataKeys.PSI_ELEMENT.getName());\n        } else if (LangDataKeys.PSI_ELEMENT.is(dataId)) {\n            VirtualFile file = editor.getFile();\n            return file != null && file.isValid() ? PsiManager.getInstance(editor.getProject()).findFile(file) : null;\n        } else if (LangDataKeys.PSI_ELEMENT_ARRAY.is(dataId)) {\n            return new PsiElement[]{(PsiElement) getData(LangDataKeys.PSI_ELEMENT.getName())};\n        } else if (PlatformDataKeys.COPY_PROVIDER.is(dataId)) {\n            return copyPasteSupport.getCopyProvider();\n        } else if (PlatformDataKeys.CUT_PROVIDER.is(dataId)) {\n            return copyPasteSupport.getCutProvider();\n        } else if (PlatformDataKeys.DELETE_ELEMENT_PROVIDER.is(dataId)) {\n            return deleteProvider;\n        } else if (ImageComponentDecorator.DATA_KEY.is(dataId)) {\n            return editor;\n        }\n\n        return null;\n    }","id":37104,"modified_method":"@Nullable\n    public Object getData(String dataId) {\n\n        if (PlatformDataKeys.PROJECT.is(dataId)) {\n            return editor.getProject();\n        } else if (PlatformDataKeys.VIRTUAL_FILE.is(dataId)) {\n            return editor.getFile();\n        } else if (PlatformDataKeys.VIRTUAL_FILE_ARRAY.is(dataId)) {\n          final VirtualFile file = editor.getFile();\n          return file != null ? new VirtualFile[]{file} : null;\n        } else if (LangDataKeys.PSI_FILE.is(dataId)) {\n            return getData(LangDataKeys.PSI_ELEMENT.getName());\n        } else if (LangDataKeys.PSI_ELEMENT.is(dataId)) {\n            VirtualFile file = editor.getFile();\n            return file != null && file.isValid() ? PsiManager.getInstance(editor.getProject()).findFile(file) : null;\n        } else if (LangDataKeys.PSI_ELEMENT_ARRAY.is(dataId)) {\n            return new PsiElement[]{(PsiElement) getData(LangDataKeys.PSI_ELEMENT.getName())};\n        } else if (PlatformDataKeys.COPY_PROVIDER.is(dataId)) {\n            return copyPasteSupport.getCopyProvider();\n        } else if (PlatformDataKeys.CUT_PROVIDER.is(dataId)) {\n            return copyPasteSupport.getCutProvider();\n        } else if (PlatformDataKeys.DELETE_ELEMENT_PROVIDER.is(dataId)) {\n            return deleteProvider;\n        } else if (ImageComponentDecorator.DATA_KEY.is(dataId)) {\n            return editor;\n        }\n\n        return null;\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void dispose() {\n        VirtualFileManager.getInstance().removeVirtualFileListener(imageEditor);\n        ImageEditorManagerImpl.releaseImageEditor(imageEditor);\n    }","id":37105,"modified_method":"public void dispose() {\n        ImageEditorManagerImpl.releaseImageEditor(imageEditor);\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"ImageFileEditorImpl(@NotNull Project project, @NotNull VirtualFile file) {\n        imageEditor = ImageEditorManagerImpl.createImageEditor(project, file);\n\n        // Append file listener\n        VirtualFileManager.getInstance().addVirtualFileListener(imageEditor);\n\n        // Set background and grid default options\n        Options options = OptionsManager.getInstance().getOptions();\n        EditorOptions editorOptions = options.getEditorOptions();\n        GridOptions gridOptions = editorOptions.getGridOptions();\n        TransparencyChessboardOptions transparencyChessboardOptions = editorOptions.getTransparencyChessboardOptions();\n        imageEditor.setGridVisible(gridOptions.isShowDefault());\n        imageEditor.setTransparencyChessboardVisible(transparencyChessboardOptions.isShowDefault());\n    }","id":37106,"modified_method":"ImageFileEditorImpl(@NotNull Project project, @NotNull ImageContentProvider contentProvider) {\n        imageEditor = ImageEditorManagerImpl.createImageEditor(project, contentProvider);\n\n        // Set background and grid default options\n        Options options = OptionsManager.getInstance().getOptions();\n        EditorOptions editorOptions = options.getEditorOptions();\n        GridOptions gridOptions = editorOptions.getGridOptions();\n        TransparencyChessboardOptions transparencyChessboardOptions = editorOptions.getTransparencyChessboardOptions();\n        imageEditor.setGridVisible(gridOptions.isShowDefault());\n        imageEditor.setTransparencyChessboardVisible(transparencyChessboardOptions.isShowDefault());\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n    public FileEditor createEditor(@NotNull Project project, @NotNull VirtualFile file) {\n        return new ImageFileEditorImpl(project, file);\n    }","id":37107,"modified_method":"@NotNull\n    public FileEditor createEditor(@NotNull Project project, @NotNull VirtualFile file) {\n      ImageContentProvider contentProvider = new VirtualFileImageContentProvider(file);\n      ImageFileEditorImpl editor = new ImageFileEditorImpl(project, contentProvider);\n      Disposer.register(editor, contentProvider);\n      return editor;\n    }","commit_id":"be7434a2905cc8f0a119b7de28279b9fe05ebf49","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n     * Thread entry point.\n     */\n    public void run()\n    {\n        final RGBFormat format = (RGBFormat) getFormat();\n        Dimension formatSize = format.getSize();\n        final int width = (int)formatSize.getWidth();\n        final int height = (int)formatSize.getHeight();\n\n        if(desktopInteract == null)\n        {\n            try\n            {\n                desktopInteract = new DesktopInteractImpl();\n            }\n            catch(Exception e)\n            {\n                logger.warn(\"Cannot create DesktopInteract object!\");\n                started = false;\n                return;\n            }\n        }\n\n        while(started)\n        {\n            byte data[] = null;\n            BufferedImage scaledScreen = null;\n            BufferedImage screen = null;\n\n            /* get desktop screen and resize it */\n            screen = desktopInteract.captureScreen();\n            scaledScreen = ImageStreamingUtils.getScaledImage(screen, \n                    width, height, BufferedImage.TYPE_INT_ARGB);\n\n            /* get raw bytes */\n            data = ImageStreamingUtils.getImageByte(scaledScreen);\n\n            /* notify JMF that new data is available */\n            synchronized (buf)\n            {\n                buf.setData(data);\n                buf.setOffset(0);\n                buf.setLength(data.length);\n                buf.setFormat(format);\n                buf.setHeader(null);\n                buf.setTimeStamp(System.nanoTime());\n                buf.setSequenceNumber(seqNo++);\n                buf.setFlags(Buffer.FLAG_LIVE_DATA | Buffer.FLAG_SYSTEM_TIME);\n            }\n\n            /* pass to JMF handler */\n            BufferTransferHandler transferHandler = this.transferHandler;\n\n            if(transferHandler != null)\n            {\n                transferHandler.transferData(this);\n                Thread.yield();\n            }\n\n            /* cleanup */\n            screen = null;\n            scaledScreen = null;\n            data = null;\n\n            try\n            {\n                /* 100 ms */\n                Thread.sleep(100);\n            }\n            catch(InterruptedException e)\n            {\n                /* do nothing */\n            }\n        }\n    }","id":37108,"modified_method":"/**\n     * Thread entry point.\n     */\n    public void run()\n    {\n        VideoFormat format = (VideoFormat) getFormat();\n        Dimension formatSize = format.getSize();\n        int width = (int) formatSize.getWidth();\n        int height = (int) formatSize.getHeight();\n\n        if(desktopInteract == null)\n        {\n            try\n            {\n                desktopInteract = new DesktopInteractImpl();\n            }\n            catch(Exception e)\n            {\n                logger.warn(\"Cannot create DesktopInteract object!\");\n                started = false;\n                return;\n            }\n        }\n\n        while(started)\n        {\n            byte data[] = null;\n            BufferedImage scaledScreen = null;\n            BufferedImage screen = null;\n\n            /* get desktop screen and resize it */\n            screen = desktopInteract.captureScreen();\n            scaledScreen\n                = ImageStreamingUtils\n                    .getScaledImage(\n                        screen,\n                        width,\n                        height,\n                        BufferedImage.TYPE_INT_ARGB);\n\n            /* get raw bytes */\n            data = ImageStreamingUtils.getImageBytes(scaledScreen);\n\n            /* notify JMF that new data is available */\n            synchronized (buf)\n            {\n                buf.setData(data);\n                buf.setOffset(0);\n                buf.setLength(data.length);\n                buf.setFormat(format);\n                buf.setHeader(null);\n                buf.setTimeStamp(System.nanoTime());\n                buf.setSequenceNumber(seqNo++);\n                buf.setFlags(Buffer.FLAG_LIVE_DATA | Buffer.FLAG_SYSTEM_TIME);\n            }\n\n            /* pass to JMF handler */\n            BufferTransferHandler transferHandler = this.transferHandler;\n\n            if(transferHandler != null)\n            {\n                transferHandler.transferData(this);\n                Thread.yield();\n            }\n\n            /* cleanup */\n            screen = null;\n            scaledScreen = null;\n            data = null;\n\n            try\n            {\n                /* 100 ms */\n                Thread.sleep(100);\n            }\n            catch(InterruptedException e)\n            {\n                /* do nothing */\n            }\n        }\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Add capture devices.\n     *\n     * @throws Exception if problem when adding capture devices\n     */\n    public ImageStreamingAuto() throws Exception\n    {\n        String name = \"Desktop streaming\";\n        CaptureDeviceInfo devInfo = new CaptureDeviceInfo(name, \n            new MediaLocator(ImageStreamingUtils.LOCATOR_PREFIX + \":\" + name),\n            DataSource.getFormats());\n            \n        /* add to JMF device manager */\n        CaptureDeviceManager.addDevice(devInfo);\n        CaptureDeviceManager.commit();\n    }","id":37109,"modified_method":"/**\n     * Add capture devices.\n     *\n     * @throws Exception if problem when adding capture devices\n     */\n    public ImageStreamingAuto() throws Exception\n    {\n        String name = \"Desktop streaming\";\n        CaptureDeviceInfo devInfo\n            = new CaptureDeviceInfo(\n                    name,\n                    new MediaLocator(\n                            ImageStreamingUtils.LOCATOR_PROTOCOL + \":\" + name),\n                    DataSource.getFormats());\n            \n        /* add to JMF device manager */\n        CaptureDeviceManager.addDevice(devInfo);\n        CaptureDeviceManager.commit();\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Get raw bytes from ARGB <tt>BufferedImage<\/tt>.\n     *\n     * @param src ARGB <BufferImage<\/tt>\n     * @return raw bytes or null if src is not an ARGB\n     * <tt>BufferedImage<\/tt>\n     */\n    public static byte[] getImageByte(BufferedImage src)\n    {\n        if(src.getType() != BufferedImage.TYPE_INT_ARGB)\n        {\n            return null;\n        }\n\n        WritableRaster raster = src.getRaster();\n        byte data[] = null;\n        int pixel[] = new int[4];\n        int width = src.getWidth();\n        int height = src.getHeight();\n        int off = 0;\n\n        /* allocate our bytes array */\n        data = new byte[width * height * 4];\n        \n        for(int y = 0 ; y < height ; y++)\n        {\n            for(int x = 0 ; x < width ; x++)\n            {\n                raster.getPixel(x, y, pixel);\n                data[off++] = (byte)pixel[0];\n                data[off++] = (byte)pixel[1];\n                data[off++] = (byte)pixel[2];\n                data[off++] = (byte)pixel[3];\n            }\n        }\n\n        raster = null;\n        pixel = null;\n        return data;\n    }","id":37110,"modified_method":"/**\n     * Get raw bytes from ARGB <tt>BufferedImage<\/tt>.\n     *\n     * @param src ARGB <BufferImage<\/tt>\n     * @return raw bytes or null if src is not an ARGB\n     * <tt>BufferedImage<\/tt>\n     */\n    public static byte[] getImageBytes(BufferedImage src)\n    {\n        if(src.getType() != BufferedImage.TYPE_INT_ARGB)\n            throw new IllegalArgumentException(\"src.type\");\n\n        WritableRaster raster = src.getRaster();\n        int width = src.getWidth();\n        int height = src.getHeight();\n\n        /* allocate our bytes array */\n        byte[] data = new byte[width * height * 4];\n        int off = 0;\n        int pixel[] = new int[4];\n\n        for(int y = 0 ; y < height ; y++)\n            for(int x = 0 ; x < width ; x++)\n            {\n                raster.getPixel(x, y, pixel);\n                data[off++] = (byte)pixel[0];\n                data[off++] = (byte)pixel[1];\n                data[off++] = (byte)pixel[2];\n                data[off++] = (byte)pixel[3];\n            }\n\n        return data;\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Get a scaled <tt>BufferedImage<\/tt>.\n     *\n     * Mainly inspired by:\n     * http://java.developpez.com/faq/gui/?page=graphique_general_images\n     * #GRAPHIQUE_IMAGE_redimensionner\n     *\n     * @param src source image\n     * @param width width of scaled image\n     * @param height height of scaled image\n     * @return scaled <tt>BufferedImage<\/tt>\n     */\n    public static BufferedImage getScaledImage(BufferedImage src,\n                                               int width,\n                                               int height,\n                                               int type)\n    {\n        AffineTransform tx = new AffineTransform();\n        AffineTransformOp op = null;\n        double scaleWidth = ((double)width) / ((double)src.getWidth());\n        double scaleHeight = ((double)height) / ((double)src.getHeight());\n        BufferedImage dst = null;\n\n        /* skip rescaling if input and output size are the same */\n        if(scaleWidth != 1 || scaleHeight != 1)\n        {\n            tx.scale(scaleWidth, scaleHeight);\n        }\n\n        op = new AffineTransformOp(tx, AffineTransformOp.TYPE_BILINEAR);\n        dst = new BufferedImage(width, height, type);\n\n        return op.filter(src, dst);\n    }","id":37111,"modified_method":"/**\n     * Get a scaled <tt>BufferedImage<\/tt>.\n     *\n     * Mainly inspired by:\n     * http://java.developpez.com/faq/gui/?page=graphique_general_images\n     * #GRAPHIQUE_IMAGE_redimensionner\n     *\n     * @param src source image\n     * @param width width of scaled image\n     * @param height height of scaled image\n     * @param type\n     * @return scaled <tt>BufferedImage<\/tt>\n     */\n    public static BufferedImage getScaledImage(BufferedImage src,\n                                               int width,\n                                               int height,\n                                               int type)\n    {\n        double scaleWidth = width / ((double)src.getWidth());\n        double scaleHeight = height / ((double)src.getHeight());\n        AffineTransform tx = new AffineTransform();\n\n        // Skip rescaling if input and output size are the same.\n        if ((Double.compare(scaleWidth, 1) != 0)\n                || (Double.compare(scaleHeight, 1) != 0))\n            tx.scale(scaleWidth, scaleHeight);\n\n        AffineTransformOp op\n            = new AffineTransformOp(tx, AffineTransformOp.TYPE_BILINEAR);\n        BufferedImage dst = new BufferedImage(width, height, type);\n\n        return op.filter(src, dst);\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\r\n     * Creates preview for the device(video) in the video container.\r\n     * @param device the device\r\n     * @param videoContainer the container\r\n     * @throws IOException a problem accessing the device.\r\n     * @throws MediaException a problem getting preview.\r\n     */\r\n    private void createPreview(CaptureDeviceInfo device,\r\n                               final Container videoContainer)\r\n        throws IOException,\r\n               MediaException\r\n    {\r\n        videoContainer.removeAll();\r\n        if (videoPlayerInPreview != null)\r\n            disposePlayer(videoPlayerInPreview);\r\n\r\n        if (device == null)\r\n            return;\r\n\r\n        DataSource dataSource = Manager.createDataSource(device.getLocator());\r\n\r\n        Dimension size = videoContainer.getPreferredSize();\r\n        VideoMediaStreamImpl\r\n            .selectVideoSize(dataSource, size.width, size.height);\r\n\r\n        Player player = Manager.createPlayer(dataSource);\r\n\r\n        videoPlayerInPreview = player;\r\n\r\n        player.addControllerListener(new ControllerListener()\r\n        {\r\n            public void controllerUpdate(ControllerEvent event)\r\n            {\r\n                controllerUpdateForPreview(event, videoContainer);\r\n            }\r\n        });\r\n        player.start();\r\n    }","id":37112,"modified_method":"/**\r\n     * Creates preview for the device(video) in the video container.\r\n     * @param device the device\r\n     * @param videoContainer the container\r\n     * @throws IOException a problem accessing the device.\r\n     * @throws MediaException a problem getting preview.\r\n     */\r\n    private void createPreview(CaptureDeviceInfo device,\r\n                               final Container videoContainer)\r\n        throws IOException,\r\n               MediaException\r\n    {\r\n        videoContainer.removeAll();\r\n        if (videoPlayerInPreview != null)\r\n            disposePlayer(videoPlayerInPreview);\r\n\r\n        if (device == null)\r\n            return;\r\n\r\n        DataSource dataSource = Manager.createDataSource(device.getLocator());\r\n        Dimension size = videoContainer.getPreferredSize();\r\n\r\n        /*\r\n         * Don't let the size be uselessly small just because the videoContainer\r\n         * has too small a preferred size.\r\n         */\r\n        if ((size.width < 128) || (size.height < 96))\r\n        {\r\n            size.width = 128;\r\n            size.height = 96;\r\n        }\r\n        VideoMediaStreamImpl\r\n                .selectVideoSize(dataSource, size.width, size.height);\r\n\r\n        Player player = Manager.createPlayer(dataSource);\r\n\r\n        videoPlayerInPreview = player;\r\n\r\n        player.addControllerListener(new ControllerListener()\r\n        {\r\n            public void controllerUpdate(ControllerEvent event)\r\n            {\r\n                controllerUpdateForPreview(event, videoContainer);\r\n            }\r\n        });\r\n        player.start();\r\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates the <tt>DataSource<\/tt> that this instance is to read captured\n     * media from.\n     *\n     * @return the <tt>DataSource<\/tt> that this instance is to read captured\n     * media from\n     */\n    @Override\n    protected DataSource createCaptureDevice()\n    {\n        /*\n         * Create our DataSource as SourceCloneable so we can use it to both\n         * display local video and stream to remote peer.\n         */\n        DataSource captureDevice = super.createCaptureDevice();\n\n        if (captureDevice != null)\n        {\n            MediaLocator locator = captureDevice.getLocator();\n            \n            /*\n             * FIXME There is no video in calls when using the QuickTime/QTKit\n             * CaptureDevice and desktop streaming, so the local video support \n             * is disabled for them now.\n             */\n            if ((locator == null)\n                    || (!QuickTimeAuto.LOCATOR_PROTOCOL\n                            .equals(locator.getProtocol()) &&\n                        !ImageStreamingUtils.LOCATOR_PREFIX\n                            .equals(locator.getProtocol())))\n            {\n                DataSource cloneableDataSource\n                    = Manager.createCloneableDataSource(captureDevice);\n\n                if (cloneableDataSource != null)\n                    captureDevice = cloneableDataSource;\n            }\n        }\n        return captureDevice;\n    }","id":37113,"modified_method":"/**\n     * Creates the <tt>DataSource<\/tt> that this instance is to read captured\n     * media from.\n     *\n     * @return the <tt>DataSource<\/tt> that this instance is to read captured\n     * media from\n     */\n    @Override\n    protected DataSource createCaptureDevice()\n    {\n        /*\n         * Create our DataSource as SourceCloneable so we can use it to both\n         * display local video and stream to remote peer.\n         */\n        DataSource captureDevice = super.createCaptureDevice();\n\n        if (captureDevice != null)\n        {\n            MediaLocator locator = captureDevice.getLocator();\n            String protocol = (locator == null) ? null : locator.getProtocol();\n\n            /*\n             * We'll probably have the frame size, frame size and such quality\n             * and/or bandwidth preferences controlled by the user (e.g. through\n             * a dumbed down present scale). But for now we try to make sure\n             * that our codecs are as generic as possible and we select the\n             * default preset here.\n             */\n            if (ImageStreamingUtils.LOCATOR_PROTOCOL.equals(protocol))\n            {\n                /*\n                 * It is not clear at this time what the default frame rate for\n                 * desktop streaming should be but at least we establish that it\n                 * is good to have a control from the outside rather than have a\n                 * hardcoded value in the imgstreaming CaptureDevice.\n                 */\n                FrameRateControl frameRateControl\n                    = (FrameRateControl)\n                        captureDevice\n                            .getControl(FrameRateControl.class.getName());\n                float defaultFrameRate = 10;\n\n                if ((frameRateControl != null)\n                        && (defaultFrameRate\n                                <= frameRateControl.getMaxSupportedFrameRate()))\n                    frameRateControl.setFrameRate(defaultFrameRate);\n            }\n            else\n            {\n                VideoMediaStreamImpl.selectVideoSize(captureDevice, 640, 480);\n            }\n\n            /*\n             * FIXME There is no video in calls when using the QuickTime/QTKit\n             * CaptureDevice so the local video support is disabled for it.\n             */\n            if (!QuickTimeAuto.LOCATOR_PROTOCOL.equals(protocol))\n            {\n                DataSource cloneableDataSource\n                    = Manager.createCloneableDataSource(captureDevice);\n\n                if (cloneableDataSource != null)\n                    captureDevice = cloneableDataSource;\n            }\n        }\n        return captureDevice;\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Selects the <tt>VideoFormat<\/tt> from the list of supported formats of a\n     * specific video <tt>DataSource<\/tt> which has a size as close as possible\n     * to a specific size and sets it as the format of the specified video\n     * <tt>DataSource<\/tt>.\n     *\n     * @param videoDS the video <tt>DataSource<\/tt> which is to have its\n     * supported formats examined and its format changed to the\n     * <tt>VideoFormat<\/tt> which is as close as possible to the specified\n     * <tt>preferredWidth<\/tt> and <tt>preferredHeight<\/tt>\n     * @param preferredWidth the width of the <tt>VideoFormat<\/tt> to be\n     * selected\n     * @param preferredHeight the height of the <tt>VideoFormat<\/tt> to be\n     * selected\n     * @return the size of the <tt>VideoFormat<\/tt> from the list of supported\n     * formats of <tt>videoDS<\/tt> which is as close as possible to\n     * <tt>preferredWidth<\/tt> and <tt>preferredHeight<\/tt> and which has been\n     * set as the format of <tt>videoDS<\/tt>\n     */\n    public static Dimension selectVideoSize(\n            DataSource videoDS,\n            final int preferredWidth,\n            final int preferredHeight)\n    {\n        if (videoDS == null)\n            return null;\n\n        FormatControl formatControl\n            = (FormatControl) videoDS.getControl(FormatControl.class.getName());\n\n        if (formatControl == null)\n            return null;\n\n        Format[] formats = formatControl.getSupportedFormats();\n        final int count = formats.length;\n\n        if (count < 1)\n            return null;\n\n        VideoFormat selectedFormat = null;\n\n        if (count == 1)\n            selectedFormat = (VideoFormat) formats[0];\n        else\n        {\n            class FormatInfo\n            {\n                public final VideoFormat format;\n\n                public final double difference;\n\n                public FormatInfo(VideoFormat format)\n                {\n                    this.format = format;\n\n                    Dimension size = format.getSize();\n\n                    int width = (size == null) ? 0 : size.width;\n                    double xScale;\n\n                    if (width == 0)\n                        xScale = Double.POSITIVE_INFINITY;\n                    else if (width == preferredWidth)\n                        xScale = 1;\n                    else\n                        xScale = (preferredWidth / (double) width);\n\n                    int height = (size == null) ? 0 : size.height;\n                    double yScale;\n\n                    if (height == 0)\n                        yScale = Double.POSITIVE_INFINITY;\n                    else if (height == preferredHeight)\n                        yScale = 1;\n                    else\n                        yScale = (preferredHeight / (double) height);\n\n                    difference = Math.abs(1 - Math.min(xScale, yScale));\n                }\n            }\n\n            FormatInfo[] infos = new FormatInfo[count];\n\n            for (int i = 0; i < count; i++)\n            {\n                FormatInfo info\n                    = infos[i] = new FormatInfo((VideoFormat) formats[i]);\n\n                if (info.difference == 0)\n                {\n                    selectedFormat = info.format;\n                    break;\n                }\n            }\n            if (selectedFormat == null)\n            {\n                Arrays.sort(infos, new Comparator<FormatInfo>()\n                {\n                    public int compare(FormatInfo info0, FormatInfo info1)\n                    {\n                        return\n                            Double.compare(info0.difference, info1.difference);\n                    }\n                });\n                selectedFormat = infos[0].format;\n            }\n//            if ((selectedFormat != null)\n//                    && (selectedFormat.getSize() == null))\n//                selectedFormat\n//                    = (VideoFormat)\n//                        selectedFormat\n//                            .intersects(\n//                                new VideoFormat(\n//                                        null,\n//                                        new Dimension(\n//                                                preferredWidth,\n//                                                preferredHeight),\n//                                        Format.NOT_SPECIFIED,\n//                                        null,\n//                                        Format.NOT_SPECIFIED));\n        }\n\n        formatControl.setFormat(selectedFormat);\n        return selectedFormat.getSize();\n    }","id":37114,"modified_method":"/**\n     * Selects the <tt>VideoFormat<\/tt> from the list of supported formats of a\n     * specific video <tt>DataSource<\/tt> which has a size as close as possible\n     * to a specific size and sets it as the format of the specified video\n     * <tt>DataSource<\/tt>.\n     *\n     * @param videoDS the video <tt>DataSource<\/tt> which is to have its\n     * supported formats examined and its format changed to the\n     * <tt>VideoFormat<\/tt> which is as close as possible to the specified\n     * <tt>preferredWidth<\/tt> and <tt>preferredHeight<\/tt>\n     * @param preferredWidth the width of the <tt>VideoFormat<\/tt> to be\n     * selected\n     * @param preferredHeight the height of the <tt>VideoFormat<\/tt> to be\n     * selected\n     * @return the size of the <tt>VideoFormat<\/tt> from the list of supported\n     * formats of <tt>videoDS<\/tt> which is as close as possible to\n     * <tt>preferredWidth<\/tt> and <tt>preferredHeight<\/tt> and which has been\n     * set as the format of <tt>videoDS<\/tt>\n     */\n    public static Dimension selectVideoSize(\n            DataSource videoDS,\n            final int preferredWidth,\n            final int preferredHeight)\n    {\n        if (videoDS == null)\n            return null;\n\n        FormatControl formatControl\n            = (FormatControl) videoDS.getControl(FormatControl.class.getName());\n\n        if (formatControl == null)\n            return null;\n\n        Format[] formats = formatControl.getSupportedFormats();\n        final int count = formats.length;\n\n        if (count < 1)\n            return null;\n\n        VideoFormat selectedFormat = null;\n\n        if (count == 1)\n            selectedFormat = (VideoFormat) formats[0];\n        else\n        {\n            class FormatInfo\n            {\n                public final VideoFormat format;\n\n                public final double difference;\n\n                public FormatInfo(VideoFormat format)\n                {\n                    this.format = format;\n\n                    Dimension size = format.getSize();\n\n                    int width = (size == null) ? 0 : size.width;\n                    double xScale;\n\n                    if (width == 0)\n                        xScale = Double.POSITIVE_INFINITY;\n                    else if (width == preferredWidth)\n                        xScale = 1;\n                    else\n                        xScale = (preferredWidth / (double) width);\n\n                    int height = (size == null) ? 0 : size.height;\n                    double yScale;\n\n                    if (height == 0)\n                        yScale = Double.POSITIVE_INFINITY;\n                    else if (height == preferredHeight)\n                        yScale = 1;\n                    else\n                        yScale = (preferredHeight / (double) height);\n\n                    difference = Math.abs(1 - Math.min(xScale, yScale));\n                }\n            }\n\n            FormatInfo[] infos = new FormatInfo[count];\n\n            for (int i = 0; i < count; i++)\n            {\n                FormatInfo info\n                    = infos[i] = new FormatInfo((VideoFormat) formats[i]);\n\n                if (info.difference == 0)\n                {\n                    selectedFormat = info.format;\n                    break;\n                }\n            }\n            if (selectedFormat == null)\n            {\n                Arrays.sort(infos, new Comparator<FormatInfo>()\n                {\n                    public int compare(FormatInfo info0, FormatInfo info1)\n                    {\n                        return\n                            Double.compare(info0.difference, info1.difference);\n                    }\n                });\n                selectedFormat = infos[0].format;\n            }\n\n            // If videoDS states to support any size, use the preferred one.\n            if ((selectedFormat != null)\n                    && (selectedFormat.getSize() == null))\n            {\n                VideoFormat currentFormat\n                    = (VideoFormat) formatControl.getFormat();\n                int width = preferredWidth;\n                int height = preferredHeight;\n\n                // Try to preserve the aspect ratio\n                if (currentFormat != null)\n                {\n                    Dimension currentSize = currentFormat.getSize();\n\n                    if ((currentSize != null)\n                            && (currentSize.width > 0)\n                            && (currentSize.height > 0))\n                        height\n                            = (int)\n                                (width\n                                    * (currentSize.width\n                                        / (double) currentSize.height));\n                }\n\n                selectedFormat\n                    = (VideoFormat)\n                        selectedFormat\n                            .intersects(\n                                new VideoFormat(\n                                        null,\n                                        new Dimension(width, height),\n                                        Format.NOT_SPECIFIED,\n                                        null,\n                                        Format.NOT_SPECIFIED));\n            }\n        }\n\n        Format setFormat = formatControl.setFormat(selectedFormat);\n\n        return\n            (setFormat instanceof VideoFormat)\n                ? ((VideoFormat) setFormat).getSize()\n                : null;\n    }","commit_id":"4cf60f6f019052458b1d8131274038b4d64b58b8","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n   * Sets the given type for the {@link DataType} to be built. See {@link DataType#getType()}.\n   * \n   * @param type the java type to set.\n   * @return this builder.\n   */\n  @Override\n  public DataTypeParamsBuilder type(Class<?> type) {\n    validateAlreadyBuilt();\n\n    checkNotNull(type, \"'type' cannot be null.\");\n    this.type = handleProxy(type);\n\n    return this;\n  }","id":37115,"modified_method":"/**\n   * Sets the given typeRef for the {@link DataType} to be built. See {@link DataType#getType()}.\n   * \n   * @param type the java typeRef to set.\n   * @return this builder.\n   */\n  @Override\n  public DataTypeParamsBuilder type(Class<?> type) {\n    validateAlreadyBuilt();\n\n    checkNotNull(type, \"'type' cannot be null.\");\n    this.typeRef = new WeakReference<>(handleProxy(type));\n\n    return this;\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"protected DataType doBuild() {\n    if (Collection.class.isAssignableFrom(type) || Iterator.class.isAssignableFrom(type)) {\n      return new DefaultCollectionDataType(type, itemTypeBuilder != null ? itemTypeBuilder.build() : DataType.OBJECT, mediaType,\n                                           isConsumable(type));\n    } else {\n      return new SimpleDataType(type, mediaType, isConsumable(type));\n    }\n  }","id":37116,"modified_method":"protected DataType doBuild() {\n    Class<?> type = this.typeRef.get();\n    if (Collection.class.isAssignableFrom(type) || Iterator.class.isAssignableFrom(type)) {\n      return new DefaultCollectionDataType(type, itemTypeBuilder != null ? itemTypeBuilder.build() : DataType.OBJECT, mediaType,\n                                           isConsumable(type));\n    } else {\n      return new SimpleDataType(type, mediaType, isConsumable(type));\n    }\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"public DefaultDataTypeBuilder(DataType dataType) {\n    if (dataType instanceof CollectionDataType) {\n      this.type = dataType.getType();\n      this.itemTypeBuilder = DataType.builder(((CollectionDataType) dataType).getItemDataType());\n    } else {\n      this.type = dataType.getType();\n    }\n    this.mediaType = dataType.getMediaType();\n  }","id":37117,"modified_method":"public DefaultDataTypeBuilder(DataType dataType) {\n    if (dataType instanceof CollectionDataType) {\n      this.typeRef = new WeakReference<>(dataType.getType());\n      this.itemTypeBuilder = DataType.builder(((CollectionDataType) dataType).getItemDataType());\n    } else {\n      this.typeRef = new WeakReference<>(dataType.getType());\n    }\n    this.mediaType = dataType.getMediaType();\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"@Override\n  public int hashCode() {\n    return Objects.hash(type, itemTypeBuilder, mediaType);\n  }","id":37118,"modified_method":"@Override\n  public int hashCode() {\n    return Objects.hash(typeRef.get(), itemTypeBuilder, mediaType);\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"/**\n   * Sets the given type for the {@link DefaultCollectionDataType} to be built. See {@link DefaultCollectionDataType#getType()}.\n   * \n   * @param collectionType the java collection type to set.\n   * @return this builder.\n   * @throws IllegalArgumentException if the given collectionType is not a descendant of {@link Collection}.\n   */\n  @Override\n  public DataTypeCollectionTypeBuilder collectionType(Class<? extends Collection> collectionType) {\n    validateAlreadyBuilt();\n\n    checkNotNull(collectionType, \"'collectionType' cannot be null.\");\n    if (!Collection.class.isAssignableFrom(collectionType)) {\n      throw new IllegalArgumentException(\"collectionType \" + collectionType.getName() + \" is not a Collection type\");\n    }\n\n    this.type = handleProxy(collectionType);\n\n    if (this.itemTypeBuilder == null) {\n      this.itemTypeBuilder = DataType.builder();\n    }\n    final Class<?> itemType = getCollectionType((Class<? extends Iterable<?>>) type);\n    if (itemType != null) {\n      this.itemTypeBuilder.type(itemType);\n    }\n\n    return asCollectionTypeBuilder();\n  }","id":37119,"modified_method":"/**\n   * Sets the given type for the {@link DefaultCollectionDataType} to be built. See\n   * {@link DefaultCollectionDataType#getType()}.\n   * \n   * @param collectionType the java collection type to set.\n   * @return this builder.\n   * @throws IllegalArgumentException if the given collectionType is not a descendant of {@link Collection}.\n   */\n  @Override\n  public DataTypeCollectionTypeBuilder collectionType(Class<? extends Collection> collectionType) {\n    validateAlreadyBuilt();\n\n    checkNotNull(collectionType, \"'collectionType' cannot be null.\");\n    if (!Collection.class.isAssignableFrom(collectionType)) {\n      throw new IllegalArgumentException(\"collectionType \" + collectionType.getName() + \" is not a Collection type\");\n    }\n\n    this.typeRef = new WeakReference<>(handleProxy(collectionType));\n\n    if (this.itemTypeBuilder == null) {\n      this.itemTypeBuilder = DataType.builder();\n    }\n    final Class<?> itemType = getCollectionType((Class<? extends Iterable<?>>) typeRef.get());\n    if (itemType != null) {\n      this.itemTypeBuilder.type(itemType);\n    }\n\n    return asCollectionTypeBuilder();\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"@Override\n  public boolean equals(Object obj) {\n    if (obj == null) {\n      return false;\n    }\n    if (obj == this) {\n      return true;\n    }\n    if (obj.getClass() != getClass()) {\n      return false;\n    }\n    DefaultDataTypeBuilder other = (DefaultDataTypeBuilder) obj;\n\n    return Objects.equals(type, other.type) && Objects.equals(itemTypeBuilder, other.itemTypeBuilder)\n        && Objects.equals(mediaType, other.mediaType);\n  }","id":37120,"modified_method":"@Override\n  public boolean equals(Object obj) {\n    if (obj == null) {\n      return false;\n    }\n    if (obj == this) {\n      return true;\n    }\n    if (obj.getClass() != getClass()) {\n      return false;\n    }\n    DefaultDataTypeBuilder other = (DefaultDataTypeBuilder) obj;\n\n    return Objects.equals(typeRef.get(), other.typeRef.get()) && Objects.equals(itemTypeBuilder, other.itemTypeBuilder)\n        && Objects.equals(mediaType, other.mediaType);\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"@Override\n  public DataTypeCollectionTypeBuilder streamType(Class<? extends Iterator> iteratorType) {\n    validateAlreadyBuilt();\n\n    checkNotNull(iteratorType, \"'iteratorType' cannot be null.\");\n    if (!Iterator.class.isAssignableFrom(iteratorType)) {\n      throw new IllegalArgumentException(\"iteratorType \" + iteratorType.getName() + \" is not an Iterator type\");\n    }\n\n    this.type = handleProxy(iteratorType);\n\n    if (this.itemTypeBuilder == null) {\n      this.itemTypeBuilder = DataType.builder();\n    }\n\n    return asCollectionTypeBuilder();\n  }","id":37121,"modified_method":"@Override\n  public DataTypeCollectionTypeBuilder streamType(Class<? extends Iterator> iteratorType) {\n    validateAlreadyBuilt();\n\n    checkNotNull(iteratorType, \"'iteratorType' cannot be null.\");\n    if (!Iterator.class.isAssignableFrom(iteratorType)) {\n      throw new IllegalArgumentException(\"iteratorType \" + iteratorType.getName() + \" is not an Iterator type\");\n    }\n\n    this.typeRef = new WeakReference<>(handleProxy(iteratorType));\n\n    if (this.itemTypeBuilder == null) {\n      this.itemTypeBuilder = DataType.builder();\n    }\n\n    return asCollectionTypeBuilder();\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"/**\n   * Builds a new {@link DataType} with the values set in this builder.\n   * \n   * @return a newly built {@link DataType}.\n   */\n  @Override\n  public DataType build() {\n    if (built) {\n      throwAlreadyBuilt();\n    }\n\n    built = true;\n    //TODO(pablo.kraan): MULE-10452 - re-add the dataType cache but avoiding the memory-leak\n    return this.doBuild();\n  }","id":37122,"modified_method":"/**\n   * Builds a new {@link DataType} with the values set in this builder.\n   * \n   * @return a newly built {@link DataType}.\n   */\n  @Override\n  public DataType build() {\n    if (built) {\n      throwAlreadyBuilt();\n    }\n\n    built = true;\n    return dataTypeCache.getUnchecked(this);\n  }","commit_id":"f875e09307e53cbd921e0f22f08f6913be037d84","url":"https://github.com/mulesoft/mule"},{"original_method":"private static boolean canFix(PsiClass psiClass) {\n    final Project project = psiClass.getProject();\n    final PsiFile psiFile = psiClass.getContainingFile();\n    LOG.assertTrue(psiFile != null);\n    final Module module = ModuleUtil.findModuleForFile(psiFile.getVirtualFile(), project);\n    return module != null && PluginModuleType.isPluginModuleOrDependency(module);\n  }","id":37123,"modified_method":"private static boolean canFix(PsiClass psiClass) {\n    final Project project = psiClass.getProject();\n    final PsiFile psiFile = psiClass.getContainingFile();\n    LOG.assertTrue(psiFile != null);\n    final Module module = ModuleUtilCore.findModuleForFile(psiFile.getVirtualFile(), project);\n    return PluginModuleType.isPluginModuleOrDependency(module);\n  }","commit_id":"db3de8cf3004fe3d61d655f856119d126b1f8aad","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void update(final AnActionEvent e) {\n    super.update(e);\n    final Presentation presentation = e.getPresentation();\n    if (presentation.isEnabled()) {\n      final DataContext context = e.getDataContext();\n      Module module = LangDataKeys.MODULE.getData(context);\n      if (module == null || !PluginModuleType.isPluginModuleOrDependency(module)) {\n        presentation.setEnabled(false);\n        presentation.setVisible(false);\n      }\n      final IdeView view = LangDataKeys.IDE_VIEW.getData(e.getDataContext());\n      final Project project = CommonDataKeys.PROJECT.getData(e.getDataContext());\n      if (view != null && project != null) {\n        // from com.intellij.ide.actions.CreateClassAction.update()\n        ProjectFileIndex projectFileIndex = ProjectRootManager.getInstance(project).getFileIndex();\n        PsiDirectory[] dirs = view.getDirectories();\n        for (PsiDirectory dir : dirs) {\n          if (projectFileIndex.isUnderSourceRootOfType(dir.getVirtualFile(), JavaModuleSourceRootTypes.SOURCES) && JavaDirectoryService.getInstance().getPackage(dir) != null) {\n            return;\n          }\n        }\n\n        presentation.setEnabled(false);\n        presentation.setVisible(false);\n      }\n    }\n  }","id":37124,"modified_method":"public void update(final AnActionEvent e) {\n    super.update(e);\n\n    final Presentation presentation = e.getPresentation();\n    if (presentation.isEnabled()) {\n      final DataContext context = e.getDataContext();\n      final Module module = LangDataKeys.MODULE.getData(context);\n      if (PluginModuleType.isPluginModuleOrDependency(module)) {\n        final IdeView view = LangDataKeys.IDE_VIEW.getData(e.getDataContext());\n        final Project project = CommonDataKeys.PROJECT.getData(e.getDataContext());\n        if (view != null && project != null) {\n          // from com.intellij.ide.actions.CreateClassAction.update()\n          ProjectFileIndex projectFileIndex = ProjectRootManager.getInstance(project).getFileIndex();\n          PsiDirectory[] dirs = view.getDirectories();\n          for (PsiDirectory dir : dirs) {\n            if (projectFileIndex.isUnderSourceRootOfType(dir.getVirtualFile(), JavaModuleSourceRootTypes.SOURCES) &&\n                JavaDirectoryService.getInstance().getPackage(dir) != null) {\n              return;\n            }\n          }\n        }\n      }\n\n      presentation.setEnabled(false);\n      presentation.setVisible(false);\n    }\n  }","commit_id":"db3de8cf3004fe3d61d655f856119d126b1f8aad","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static boolean isAllowed(ProblemsHolder holder) {\n    if (PsiUtil.isIdeaProject(holder.getProject())) {\n      return true;\n    }\n\n    Module module = ModuleUtilCore.findModuleForPsiElement(holder.getFile());\n    if (module != null && PluginModuleType.isPluginModuleOrDependency(module)) {\n      return true;\n    }\n\n    return false;\n  }","id":37125,"modified_method":"private static boolean isAllowed(ProblemsHolder holder) {\n    if (PsiUtil.isIdeaProject(holder.getProject())) {\n      return true;\n    }\n\n    Module module = ModuleUtilCore.findModuleForPsiElement(holder.getFile());\n    if (PluginModuleType.isPluginModuleOrDependency(module)) {\n      return true;\n    }\n\n    return false;\n  }","commit_id":"db3de8cf3004fe3d61d655f856119d126b1f8aad","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static boolean isPluginModuleOrDependency(@NotNull Module module) {\n    if (isOfType(module)) return true;\n\n    return getCandidateModules(module).size() > 0;\n  }","id":37126,"modified_method":"public static boolean isPluginModuleOrDependency(@Nullable Module module) {\n    if (module == null) return false;\n    if (isOfType(module)) return true;\n    return getCandidateModules(module).size() > 0;\n  }","commit_id":"db3de8cf3004fe3d61d655f856119d126b1f8aad","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void nextLambda(final GLMIterationTask glmt, double [] newBeta, GLMValidation val){\n    currentLambdaIter = 0;\n    boolean improved = _model.setAndTestValidation(_lambdaIdx,val);\n    _model.clone().update(self());\n    if((improved || _runAllLambdas) && _lambdaIdx < (lambda.length-1) ){ // continue with next lambda value?\n      ++_lambdaIdx;\n      _model.setLambdaSubmodel(_lambdaIdx,newBeta,newBeta,_iter);\n      glmt._val = null;\n      new Iteration().callback(glmt);\n    } else    // nope, we're done\n      GLM2.this.complete(); // signal we're done to anyone waiting for the job\n  }","id":37127,"modified_method":"protected void nextLambda(final GLMIterationTask glmt, double [] newBeta, GLMValidation val){\n    currentLambdaIter = 0;\n    boolean improved = _model.setAndTestValidation(_lambdaIdx,val);\n    _model.clone().update(self());\n    if((improved || _runAllLambdas) && _lambdaIdx < (lambda.length-1) ){ // continue with next lambda value?\n      ++_lambdaIdx;\n//      _model.setLambdaSubmodel(_lambdaIdx,newBeta,newBeta,_iter);\n      glmt._val = null;\n      new Iteration().callback(glmt);\n    } else    // nope, we're done\n      GLM2.this.complete(); // signal we're done to anyone waiting for the job\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private void xvalidate(final GLMModel model, int lambdaIxd,final H2OCountedCompleter cmp){\n    final Key [] keys = new Key[n_folds];\n    GLM2 [] glms = new GLM2[n_folds];\n    for(int i = 0; i < n_folds; ++i)\n      glms[i] = new GLM2(this.description + \"xval \" + i, self(), keys[i] = Key.make(destination_key + \"_\" + _lambdaIdx + \"_xval\" + i), _dinfo.getFold(i, n_folds),_glm,new double[]{lambda[_lambdaIdx]},model.alpha,0, model.beta_eps,self(),model.norm_beta(lambdaIxd),higher_accuracy,0);\n    H2O.submitTask(new ParallelGLMs(GLM2.this,glms,H2O.CLOUD.size(),new H2OCallback(GLM2.this) {\n      @Override public void callback(H2OCountedCompleter t) {\n        GLMModel [] models = new GLMModel[keys.length];\n        // we got the xval models, now compute their validations...\n        for(int i = 0; i < models.length; ++i)models[i] = DKV.get(keys[i]).get();\n        new GLMXValidationTask(model,_lambdaIdx,models, cmp).asyncExec(_dinfo._adaptedFrame);\n      }\n    }));\n  }","id":37128,"modified_method":"private void xvalidate(final GLMModel model, int lambdaIxd,final H2OCountedCompleter cmp){\n    final Key [] keys = new Key[n_folds];\n    GLM2 [] glms = new GLM2[n_folds];\n    for(int i = 0; i < n_folds; ++i)\n      glms[i] = new GLM2(this.description + \"xval \" + i, self(), keys[i] = Key.make(destination_key + \"_\" + _lambdaIdx + \"_xval\" + i), _dinfo.getFold(i, n_folds),_glm,new double[]{lambda[_lambdaIdx]},model.alpha,0, model.beta_eps,self(),model.norm_beta(lambdaIxd),higher_accuracy,prior,0);\n    H2O.submitTask(new ParallelGLMs(GLM2.this,glms,H2O.CLOUD.size(),new H2OCallback(GLM2.this) {\n      @Override public void callback(H2OCountedCompleter t) {\n        GLMModel [] models = new GLMModel[keys.length];\n        // we got the xval models, now compute their validations...\n        for(int i = 0; i < models.length; ++i)models[i] = DKV.get(keys[i]).get();\n        new GLMXValidationTask(model,_lambdaIdx,models, cmp).asyncExec(_dinfo._adaptedFrame);\n      }\n    }));\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - start) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we dont wan to run with that\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);//.store();\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err) err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged with max |subgradient| = \" + err);\n          if(n_folds > 1) nextLambda(glmt, glmt._beta);\n          else nextLambda(glmt, glmt._beta,glmt._val);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._n + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              return;\n            }\n          }\n          new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,glmt._n,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_dinfo._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      double [] newBetaDeNorm = null;\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n        nextLambda(glmt,glmt._beta);\n        return;\n      } else {\n        if(_dinfo._standardize) {\n          newBetaDeNorm = newBeta.clone();\n          double norm = 0.0;        // Reverse any normalization on the intercept\n          // denormalize only the numeric coefs (categoricals are not normalized)\n          final int numoff = newBeta.length - _dinfo._nums - 1;\n          for( int i=numoff; i< newBeta.length-1; i++ ) {\n            double b = newBetaDeNorm[i]*_dinfo._normMul[i-numoff];\n            norm += b*_dinfo._normSub[i-numoff]; // Also accumulate the intercept adjustment\n            newBetaDeNorm[i] = b;\n          }\n          newBetaDeNorm[newBetaDeNorm.length-1] -= norm;\n        }\n        _model.setLambdaSubmodel(_lambdaIdx,newBetaDeNorm == null?newBeta:newBetaDeNorm, newBetaDeNorm==null?null:newBeta, (_iter+1));\n        if(_glm.family == Family.gaussian) { // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          nextLambda(glmt,newBeta);\n        } else if( beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter){\n          // Done, we need to verify gradient for non-gaussian, than validate and move to the next lambda\n          if(!glmt._validate || !glmt._computeGradient) { // Need 2 compute validation and gradient first\n            new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,_glm.family != Family.gaussian,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>() {\n              @Override public void callback(GLMIterationTask glmt2){\n                if(!highAccuracy() && !(glmt2._val.residual_deviance < glmt2._val.null_deviance)){\n                  Log.info(\"GLM2 failed completely without high-accuracy mode, re-running in high-accuracy mode\");\n                  setHighAccuracy();\n                  _iter = 0;\n                  new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n                  return;\n                }\n                checkGradient(newBeta, glmt2.gradient(l2pen()));\n                if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n                else  nextLambda(glmt, newBeta, glmt2._val);\n              }\n            }).asyncExec(_dinfo._adaptedFrame);\n          } else { // already got all the info\n            checkGradient(newBeta,glmt.gradient(l2pen()));\n            if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n            else nextLambda(glmt, glmt._beta, glmt._val);\n          }\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n        }\n      }\n    }","id":37129,"modified_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - start) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we dont wan to run with that\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);//.store();\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err) err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged with max |subgradient| = \" + err);\n          if(n_folds > 1) nextLambda(glmt, glmt._beta);\n          else nextLambda(glmt, glmt._beta,glmt._val);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._n + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              return;\n            }\n          }\n          new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,glmt._n,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_dinfo._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n        nextLambda(glmt,glmt._beta);\n        return;\n      } else {\n        final double [] modelBeta = MemoryManager.arrayCopyOf(newBeta,newBeta.length);\n        modelBeta[modelBeta.length-1] += _iceptAdjust;\n        double [] modelBetaDeNorm = null;\n        if(_dinfo._standardize) {\n          modelBetaDeNorm = modelBeta.clone();\n          double norm = 0.0;        // Reverse any normalization on the intercept\n          // denormalize only the numeric coefs (categoricals are not normalized)\n          final int numoff = newBeta.length - _dinfo._nums - 1;\n          for( int i=numoff; i< newBeta.length-1; i++ ) {\n            double b = modelBetaDeNorm[i]*_dinfo._normMul[i-numoff];\n            norm += b*_dinfo._normSub[i-numoff]; // Also accumulate the intercept adjustment\n            modelBetaDeNorm[i] = b;\n          }\n          modelBetaDeNorm[modelBetaDeNorm.length-1] -= norm;\n        }\n        _model.setLambdaSubmodel(_lambdaIdx,modelBetaDeNorm == null?modelBeta:modelBetaDeNorm, modelBetaDeNorm==null?null:modelBeta, (_iter+1));\n        if(_glm.family == Family.gaussian) { // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          nextLambda(glmt,newBeta);\n        } else if( beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter){\n          // Done, we need to verify gradient for non-gaussian, than validate and move to the next lambda\n          if(!glmt._validate || !glmt._computeGradient) { // Need 2 compute validation and gradient first\n            new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,_glm.family != Family.gaussian,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>() {\n              @Override public void callback(GLMIterationTask glmt2){\n                if(!highAccuracy() && !(glmt2._val.residual_deviance < glmt2._val.null_deviance)){\n                  Log.info(\"GLM2 failed completely without high-accuracy mode, re-running in high-accuracy mode\");\n                  setHighAccuracy();\n                  _iter = 0;\n                  new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n                  return;\n                }\n                checkGradient(newBeta, glmt2.gradient(l2pen()));\n                nextLambda(glmt,newBeta); // need to call xval first\n              }\n            }).asyncExec(_dinfo._adaptedFrame);\n          } else { // already got all the info\n            checkGradient(newBeta,glmt.gradient(l2pen()));\n            nextLambda(glmt,newBeta);\n          }\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n        }\n      }\n    }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private void nextLambda(final GLMIterationTask glmt, final double [] newBeta){\n    if(n_folds > 1){\n      xvalidate(_model,_lambdaIdx,new H2OCallback<GLMModel.GLMValidationTask>(GLM2.this) {\n        @Override public void callback(GLMModel.GLMValidationTask v){ nextLambda(glmt, newBeta, v._res);}\n      });\n    } else {\n      new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,false,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>(GLM2.this){\n        @Override public void callback(GLMIterationTask glmt2){nextLambda(glmt, newBeta,glmt2._val);}\n      }).asyncExec(_dinfo._adaptedFrame);\n    }\n  }","id":37130,"modified_method":"private void nextLambda(final GLMIterationTask glmt, final double [] newBeta){\n    if(n_folds > 1){\n      xvalidate(_model,_lambdaIdx,new H2OCallback<GLMModel.GLMValidationTask>(GLM2.this) {\n        @Override public void callback(GLMModel.GLMValidationTask v){ nextLambda(glmt, newBeta, v._res);}\n      });\n    } else {\n      new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,false,_model.submodels[_lambdaIdx].norm_beta,prior,_reg,new H2OCallback<GLMIterationTask>(GLM2.this){\n        @Override public void callback(GLMIterationTask glmt2){nextLambda(glmt, newBeta,glmt2._val);}\n      }).asyncExec(_dinfo._adaptedFrame);\n    }\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public void run(final boolean doLog){\n    if(doLog)logStart();\n    assert alpha.length == 1;\n    start = System.currentTimeMillis();\n    final double lambda_min = lambda[lambda.length-1];\n    if(lambda_search){ // run as GLMNet - regularization path over several lambdas staring at lambda-max\n      new YMUTask(this, _dinfo, new H2OCallback<YMUTask>() {\n        @Override public void callback(final YMUTask ymut){\n          if(ymut._ymin == ymut._ymax){\n            String msg = \"Attempting to run GLM on column with constant value = \" + ymut._ymin;\n            GLM2.this.cancel(msg);\n            GLM2.this._fjtask.completeExceptionally(new JobCancelledException(msg));\n          }\n          new LMAXTask(GLM2.this, _dinfo, _glm, ymut.ymu(),alpha[0],new H2OCallback<LMAXTask>(){\n            @Override public void callback(LMAXTask t){\n              final double lmax = lambda_max = t.lmax();\n              String [] warns = null;\n              if(lambda == null || lambda_search){\n                lambda = new double[]{lmax,lmax*0.9,lmax*0.75,lmax*0.66,lmax*0.5,lmax*0.33,lmax*0.25,lmax*1e-1,lmax*1e-2,lmax*1e-3,lmax*1e-4,lmax*1e-5,lmax*1e-6,lmax*1e-7,lmax*1e-8}; // todo - make it a sequence of 100 lamdbas\n                _runAllLambdas = false;\n              } else if(alpha[0] > 0) { // make sure we start with lambda max (and discard all lambda > lambda max)\n                int i = 0; while(i < lambda.length && lambda[i] > lmax)++i;\n                if(i != 0) {\n                  Log.info(\"GLM: removing \" + i + \" lambdas > lambda_max: \" + Arrays.toString(Arrays.copyOf(lambda,i)));\n                  warns = i == lambda.length?new String[] {\"Removed \" + i + \" lambdas > lambda_max\",\"No lambdas < lambda_max, returning null model.\"}:new String[] {\"Removed \" + i + \" lambdas > lambda_max\"};\n                }\n                lambda = i == lambda.length?new double [] {lambda_max}:Arrays.copyOfRange(lambda, i, lambda.length);\n              }\n              _model = new GLMModel(GLM2.this,dest(),_dinfo, _glm,beta_epsilon,alpha[0],lambda_max,lambda,ymut.ymu());\n              _model.warnings = warns;\n              _model.clone().delete_and_lock(self());\n              if(lambda[0] == lambda_max && alpha[0] > 0){ // fill-in trivial solution for lambda max\n                _beta = MemoryManager.malloc8d(_dinfo.fullN()+1);\n                _beta[_beta.length-1] = _glm.link(ymut.ymu());\n                _model.setLambdaSubmodel(0,_beta,_beta,0);\n                if(t._val != null)\n                  _model.setAndTestValidation(0,t._val);\n                _lambdaIdx = 1;\n              }\n              if(_lambdaIdx == lambda.length) // ran only with one lambda > lambda_max => return null model\n                GLM2.this.complete(); // signal we're done to anyone waiting for the job\n              else {\n                ++_iter;\n                Log.info(\"GLM2 staring GLM after \" + (System.currentTimeMillis()-start) + \"ms of preprocessing (mean/lmax computation)\");\n                new GLMIterationTask(GLM2.this,_dinfo,_glm,true,false,false,null,_ymu = ymut.ymu(),_reg = 1.0/ymut.nobs(), new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              }\n            }\n            @Override public boolean onExceptionalCompletion(Throwable ex, CountedCompleter cc){\n              GLM2.this.cancel(ex);\n              return true;\n            }\n          }).asyncExec(_dinfo._adaptedFrame);\n        }\n        @Override public boolean onExceptionalCompletion(Throwable ex, CountedCompleter cc){\n          GLM2.this.cancel(ex);\n          return true;\n        }\n      }).asyncExec(_dinfo._adaptedFrame);\n    } else {\n      Log.info(\"GLM2: staring GLM after \" + (System.currentTimeMillis()-start) + \"ms of preprocessing (mean/lmax computation)\");\n      double ymu = _dinfo._adaptedFrame.lastVec().mean();\n      _model = new GLMModel(GLM2.this,dest(),_dinfo, _glm,beta_epsilon,alpha[0],lambda_max,lambda,ymu);\n      _model.warnings = new String[0];\n      _model.clone().delete_and_lock(self());\n      new GLMIterationTask(GLM2.this,_dinfo,_glm,true,false,false,null,_ymu = ymu,_reg = 1.0/_dinfo._adaptedFrame.numRows(), new Iteration()).asyncExec(_dinfo._adaptedFrame);\n    }\n  }","id":37131,"modified_method":"public void run(final boolean doLog){\n    if(doLog)logStart();\n    assert alpha.length == 1;\n    start = System.currentTimeMillis();\n    if(highAccuracy() || lambda_search) // shortcut for fast & simple mode\n      new YMUTask(GLM2.this,_dinfo,new H2OCallback<YMUTask>(GLM2.this) {\n        @Override public void callback(final YMUTask ymut){ run(ymut.ymu(),ymut.nobs());}\n      }).asyncExec(_dinfo._adaptedFrame);\n    else {\n      double ymu = _dinfo._adaptedFrame.lastVec().mean();\n      run(ymu, _dinfo._adaptedFrame.numRows()); // shortcut for quick & simple\n    }\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public GLM2(String desc, Key jobKey, Key dest, DataInfo dinfo, GLMParams glm, double [] lambda, double alpha, int nfolds, double betaEpsilon, Key parentJob){\n    this(desc,jobKey,dest,dinfo,glm,lambda,alpha,nfolds,betaEpsilon,parentJob, null,false,0);\n  }","id":37132,"modified_method":"public GLM2(String desc, Key jobKey, Key dest, DataInfo dinfo, GLMParams glm, double [] lambda, double alpha, int nfolds, double betaEpsilon, Key parentJob){\n    this(desc,jobKey,dest,dinfo,glm,lambda,alpha,nfolds,betaEpsilon,parentJob, null,false,-1,0);\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public GLM2(String desc, Key jobKey, Key dest, DataInfo dinfo, GLMParams glm, double [] lambda, double alpha, int nfolds, double betaEpsilon, Key parentJob, double [] beta, boolean highAccuracy, double proximalPenalty) {\n    assert beta == null || beta.length == (dinfo.fullN()+1):\"unexpected size of beta, got length \" + beta.length + \", expected \" + dinfo.fullN();\n    job_key = jobKey;\n    description = desc;\n    destination_key = dest;\n    beta_epsilon = betaEpsilon;\n    _beta = beta;\n    _dinfo = dinfo;\n    _glm = glm;\n    this.lambda = lambda;\n    _beta = beta;\n    if((_proximalPenalty = proximalPenalty) != 0)\n      _wgiven = beta;\n    this.alpha= new double[]{alpha};\n    n_folds = nfolds;\n    source = dinfo._adaptedFrame;\n    response = dinfo._adaptedFrame.lastVec();\n    _jobName = dest.toString() + ((nfolds > 1)?(\"[\" + dinfo._foldId + \"]\"):\"\");\n    higher_accuracy = highAccuracy;\n  }","id":37133,"modified_method":"public GLM2(String desc, Key jobKey, Key dest, DataInfo dinfo, GLMParams glm, double [] lambda, double alpha, int nfolds, double betaEpsilon, Key parentJob, double [] beta, boolean highAccuracy, double prior, double proximalPenalty) {\n    assert beta == null || beta.length == (dinfo.fullN()+1):\"unexpected size of beta, got length \" + beta.length + \", expected \" + dinfo.fullN();\n    job_key = jobKey;\n    description = desc;\n    destination_key = dest;\n    beta_epsilon = betaEpsilon;\n    _beta = beta;\n    _dinfo = dinfo;\n    _glm = glm;\n    this.lambda = lambda;\n    _beta = beta;\n    if((_proximalPenalty = proximalPenalty) != 0)\n      _wgiven = beta;\n    this.alpha= new double[]{alpha};\n    n_folds = nfolds;\n    source = dinfo._adaptedFrame;\n    response = dinfo._adaptedFrame.lastVec();\n    _jobName = dest.toString() + ((nfolds > 1)?(\"[\" + dinfo._foldId + \"]\"):\"\");\n    higher_accuracy = highAccuracy;\n    this.prior = prior;\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public GLMModel(GLM2 job, Key selfKey, DataInfo dinfo, GLMParams glm, double beta_eps, double alpha, double lambda_max, double [] lambda, double ymu) {\n    super(selfKey,null,dinfo._adaptedFrame);\n    parameters = job;\n    job_key = job.self();\n    this.ymu = ymu;\n    this.glm = glm;\n    threshold = 0.5;\n    this.data_info = dinfo;\n    this.warnings = null;\n    this.alpha = alpha;\n    this.lambda_max = lambda_max;\n    this.lambdas = lambda;\n    this.beta_eps = beta_eps;\n    submodels = new Submodel[lambda.length];\n    for(int i = 0; i < submodels.length; ++i)\n      submodels[i] = new Submodel(null, null, 0, 0);\n    run_time = 0;\n    start_time = System.currentTimeMillis();\n    coefficients_names = coefNames();\n  }","id":37134,"modified_method":"public GLMModel(GLM2 job, Key selfKey, DataInfo dinfo, GLMParams glm, double beta_eps, double alpha, double lambda_max, double [] lambda, double ymu, double prior) {\n    super(selfKey,null,dinfo._adaptedFrame);\n    parameters = job;\n    job_key = job.self();\n    this.ymu = ymu;\n    this.prior = prior;\n    this.glm = glm;\n    threshold = 0.5;\n    this.data_info = dinfo;\n    this.warnings = null;\n    this.alpha = alpha;\n    this.lambda_max = lambda_max;\n    this.lambdas = lambda;\n    this.beta_eps = beta_eps;\n    submodels = new Submodel[lambda.length];\n    for(int i = 0; i < submodels.length; ++i)\n      submodels[i] = new Submodel(null, null, 0, 0);\n    run_time = 0;\n    start_time = System.currentTimeMillis();\n    coefficients_names = coefNames();\n  }","commit_id":"f2d8cfdfb35f394309083ea4bdd97449cf17fa10","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - start) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we dont wan to run with that\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);//.store();\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err)err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged with max |subgradient| = \" + err);\n          nextLambda(glmt, glmt._beta, glmt._val);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._n + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              return;\n            }\n          }\n          new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,glmt._n,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_dinfo._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      double [] newBetaDeNorm = null;\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n      } else {\n        if(_dinfo._standardize) {\n          newBetaDeNorm = newBeta.clone();\n          double norm = 0.0;        // Reverse any normalization on the intercept\n          // denormalize only the numeric coefs (categoricals are not normalized)\n          final int numoff = newBeta.length - _dinfo._nums - 1;\n          for( int i=numoff; i< newBeta.length-1; i++ ) {\n            double b = newBetaDeNorm[i]*_dinfo._normMul[i-numoff];\n            norm += b*_dinfo._normSub[i-numoff]; // Also accumulate the intercept adjustment\n            newBetaDeNorm[i] = b;\n          }\n          newBetaDeNorm[newBetaDeNorm.length-1] -= norm;\n        }\n        _model.setLambdaSubmodel(_lambdaIdx,newBetaDeNorm == null?newBeta:newBetaDeNorm, newBetaDeNorm==null?null:newBeta, (_iter+1));\n        if(_glm.family == Family.gaussian) { // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          nextLambda(glmt,newBeta);\n        } else if( beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter){\n          // Done, we need to verify gradient for non-gaussian, than validate and move to the next lambda\n          if(!glmt._validate || !glmt._computeGradient) { // Need 2 compute validation and gradient first\n            new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,_glm.family != Family.gaussian,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>() {\n              @Override public void callback(GLMIterationTask glmt2){\n                if(!highAccuracy() && !(glmt2._val.residual_deviance < glmt2._val.null_deviance)){\n                  Log.info(\"GLM2 failed completely without high-accuracy mode, re-running in high-accuracy mode\");\n                  setHighAccuracy();\n                  _iter = 0;\n                  new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n                  return;\n                }\n                checkGradient(newBeta, glmt2.gradient(l2pen()));\n                if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n                else  nextLambda(glmt, newBeta, glmt2._val);\n              }\n            }).asyncExec(_dinfo._adaptedFrame);\n          } else { // already got all the info\n            checkGradient(newBeta,glmt.gradient(l2pen()));\n            if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n            else nextLambda(glmt, glmt._beta, glmt._val);\n          }\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n        }\n      }\n    }","id":37135,"modified_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - start) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we dont wan to run with that\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);//.store();\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err) err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged with max |subgradient| = \" + err);\n          if(n_folds > 1) nextLambda(glmt, glmt._beta);\n          else nextLambda(glmt, glmt._beta,glmt._val);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._n + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              return;\n            }\n          }\n          new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,glmt._n,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_dinfo._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      double [] newBetaDeNorm = null;\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n      } else {\n        if(_dinfo._standardize) {\n          newBetaDeNorm = newBeta.clone();\n          double norm = 0.0;        // Reverse any normalization on the intercept\n          // denormalize only the numeric coefs (categoricals are not normalized)\n          final int numoff = newBeta.length - _dinfo._nums - 1;\n          for( int i=numoff; i< newBeta.length-1; i++ ) {\n            double b = newBetaDeNorm[i]*_dinfo._normMul[i-numoff];\n            norm += b*_dinfo._normSub[i-numoff]; // Also accumulate the intercept adjustment\n            newBetaDeNorm[i] = b;\n          }\n          newBetaDeNorm[newBetaDeNorm.length-1] -= norm;\n        }\n        _model.setLambdaSubmodel(_lambdaIdx,newBetaDeNorm == null?newBeta:newBetaDeNorm, newBetaDeNorm==null?null:newBeta, (_iter+1));\n        if(_glm.family == Family.gaussian) { // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          nextLambda(glmt,newBeta);\n        } else if( beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter){\n          // Done, we need to verify gradient for non-gaussian, than validate and move to the next lambda\n          if(!glmt._validate || !glmt._computeGradient) { // Need 2 compute validation and gradient first\n            new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,_glm.family != Family.gaussian,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>() {\n              @Override public void callback(GLMIterationTask glmt2){\n                if(!highAccuracy() && !(glmt2._val.residual_deviance < glmt2._val.null_deviance)){\n                  Log.info(\"GLM2 failed completely without high-accuracy mode, re-running in high-accuracy mode\");\n                  setHighAccuracy();\n                  _iter = 0;\n                  new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n                  return;\n                }\n                checkGradient(newBeta, glmt2.gradient(l2pen()));\n                if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n                else  nextLambda(glmt, newBeta, glmt2._val);\n              }\n            }).asyncExec(_dinfo._adaptedFrame);\n          } else { // already got all the info\n            checkGradient(newBeta,glmt.gradient(l2pen()));\n            if(n_folds > 1) nextLambda(glmt,newBeta); // need to call xval first\n            else nextLambda(glmt, glmt._beta, glmt._val);\n          }\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          new GLMIterationTask(GLM2.this,_dinfo,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);\n        }\n      }\n    }","commit_id":"79df10e924ee7dc8de66dd5b5cfc6ef918046267","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public void run(){\n    logStart();\n    assert alpha.length == 1;\n    start = System.currentTimeMillis();\n    if(lambda == null){ // run as GLMNet - regularization path over several lmabdas staring at lambda-max\n      new YMUTask(this, _dinfo, new H2OCallback<YMUTask>() {\n        @Override public void callback(final YMUTask ymut){\n          if(ymut._ymin == ymut._ymax){\n            String msg = \"Attempting to run GLM on column with constant value = \" + ymut._ymin;\n            GLM2.this.cancel(msg);\n            GLM2.this._fjtask.completeExceptionally(new JobCancelledException(msg));\n          }\n          new LMAXTask(GLM2.this, _dinfo, _glm, ymut.ymu(),alpha[0],new H2OCallback<LMAXTask>(){\n            @Override public void callback(LMAXTask t){\n              final double lmax = lambda_max = t.lmax();\n              String [] warns = null;\n              if(lambda == null){\n                lambda = new double[]{lmax,lmax*0.9,lmax*0.75,lmax*0.66,lmax*0.5,lmax*0.33,lmax*0.25,lmax*1e-1,lmax*1e-2,lmax*1e-3,lmax*1e-4,lmax*1e-5,lmax*1e-6,lmax*1e-7,lmax*1e-8}; // todo - make it a sequence of 100 lamdbas\n                _runAllLambdas = false;\n              } else if(alpha[0] > 0) { // make sure we start with lambda max (and discard all lambda > lambda max)\n                int i = 0; while(i < lambda.length && lambda[i] > lmax)++i;\n                if(i != 0) {\n                  Log.info(\"GLM: removing \" + i + \" lambdas > lambda_max: \" + Arrays.toString(Arrays.copyOf(lambda,i)));\n                  warns = i == lambda.length?new String[] {\"Removed \" + i + \" lambdas > lambda_max\",\"No lambdas < lambda_max, returning null model.\"}:new String[] {\"Removed \" + i + \" lambdas > lambda_max\"};\n                }\n                lambda = i == lambda.length?new double [] {lambda_max}:Arrays.copyOfRange(lambda, i, lambda.length);\n              }\n              _model = new GLMModel(GLM2.this,dest(),_dinfo, _glm,beta_epsilon,alpha[0],lambda_max,lambda,ymut.ymu());\n              _model.warnings = warns;\n              _model.clone().delete_and_lock(self());\n              if(lambda[0] == lambda_max && alpha[0] > 0){ // fill-in trivial solution for lambda max\n                _beta = MemoryManager.malloc8d(_dinfo.fullN()+1);\n                _beta[_beta.length-1] = _glm.link(ymut.ymu());\n                _model.setLambdaSubmodel(0,_beta,_beta,0);\n                if(t._val != null)\n                  _model.setAndTestValidation(0,t._val);\n                _lambdaIdx = 1;\n              }\n              if(_lambdaIdx == lambda.length) // ran only with one lambda > lambda_max => return null model\n                GLM2.this.complete(); // signal we're done to anyone waiting for the job\n              else {\n                ++_iter;\n                Log.info(\"GLM2 staring GLM after \" + (System.currentTimeMillis()-start) + \"ms of preprocessing (mean/lmax computation)\");\n                new GLMIterationTask(GLM2.this,_dinfo,_glm,true,false,false,null,_ymu = ymut.ymu(),_reg = 1.0/ymut.nobs(), new Iteration()).asyncExec(_dinfo._adaptedFrame);\n              }\n            }\n            @Override public boolean onExceptionalCompletion(Throwable ex, CountedCompleter cc){\n              GLM2.this.cancel(ex);\n              return true;\n            }\n          }).asyncExec(_dinfo._adaptedFrame);\n        }\n        @Override public boolean onExceptionalCompletion(Throwable ex, CountedCompleter cc){\n          GLM2.this.cancel(ex);\n          return true;\n        }\n      }).asyncExec(_dinfo._adaptedFrame);\n    } else {\n      Log.info(\"GLM2: staring GLM after \" + (System.currentTimeMillis()-start) + \"ms of preprocessing (mean/lmax computation)\");\n      double ymu = _dinfo._adaptedFrame.lastVec().mean();\n      _model = new GLMModel(GLM2.this,dest(),_dinfo, _glm,beta_epsilon,alpha[0],lambda_max,lambda,ymu);\n      _model.warnings = new String[0];\n      _model.clone().delete_and_lock(self());\n      new GLMIterationTask(GLM2.this,_dinfo,_glm,true,false,false,null,_ymu = ymu,_reg = 1.0/_dinfo._adaptedFrame.numRows(), new Iteration()).asyncExec(_dinfo._adaptedFrame);\n    }\n  }","id":37136,"modified_method":"public void run(){run(false);}","commit_id":"79df10e924ee7dc8de66dd5b5cfc6ef918046267","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override\n  public GLM2 fork(){\n    start(new H2O.H2OEmptyCompleter());\n\n    run();\n    return this;\n  }","id":37137,"modified_method":"@Override\n  public GLM2 fork(){\n    start(new H2O.H2OEmptyCompleter());\n    run(true);\n    return this;\n  }","commit_id":"79df10e924ee7dc8de66dd5b5cfc6ef918046267","url":"https://github.com/h2oai/h2o-2"},{"original_method":"private void nextLambda(final GLMIterationTask glmt, final double [] newBeta){\n    final double [] fullBeta;\n    if(_activeCols != null){\n      fullBeta = MemoryManager.malloc8d(_dinfo.fullN()+1);\n      fullBeta[fullBeta.length-1] = newBeta[newBeta.length-1]; // intercept\n      int j = 0;\n      for(int i:_activeCols)\n        fullBeta[i] = newBeta[j++];\n    } else fullBeta = newBeta;\n    new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,true,fullBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>(GLM2.this){\n      @Override public void callback(final GLMIterationTask glmt2){\n        final double [] grad = glmt2.gradient(l2pen());\n        // check the KKT conditions and filter data for next lambda\n        // check the gradient\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], fullBeta, grad);\n        double err = 0;\n\n        if(_activeCols != null){\n          for(int c:_activeCols)\n            if(grad[c] > err) err = grad[c];\n            else if(grad[c] < -err) err = -grad[c];\n          int [] failedCols = new int[64];\n          int fcnt = 0;\n          for(int i = 0; i < grad.length-1; ++i){\n            if(Arrays.binarySearch(_activeCols,i) >= 0)continue;\n            if(grad[i] >= err || -grad[i] <= -err){\n              if(fcnt == failedCols.length)\n                failedCols = Arrays.copyOf(failedCols,failedCols.length << 1);\n              failedCols[fcnt++] = i;\n            }\n          }\n          if(fcnt > 0){\n            Log.info(\"GLM2: \" + fcnt + \" variables failed KKT conditions check! Adding them to the model and continuing computation...\");\n            final int n = _activeCols.length;\n            final int [] oldActiveCols = _activeCols;\n            _activeCols = Arrays.copyOf(_activeCols,_activeCols.length+fcnt);\n            for(int i = 0; i < fcnt; ++i)\n              _activeCols[n+i] = failedCols[i];\n            Arrays.sort(_activeCols);\n            _activeData = _dinfo.filterExpandedColumns(_activeCols);\n            new GLMIterationTask(GLM2.this, _activeData,_glm,true,true,true,expandVec(glmt._beta,_activeCols,oldActiveCols),glmt._ymu,glmt._reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            return;\n          }\n        } else {\n          for(double d:grad)\n            if(d > err) err = d;\n            else if(d < -err) err = -d;\n        }\n        Log.info(\"GLM converged with max |subgradient| = \" + err);\n        final GLMIterationTask glmt3;\n        // now filter out the cols for the next lambda...\n        if(lambda.length > 1 && _lambdaIdx < lambda.length-1 && _activeCols != null){\n          activeCols(lambda[_lambdaIdx+1],lambda[_lambdaIdx],glmt2.gradient(l2pen()));\n          // epxand the beta\n          final double [] fullBeta = glmt2._beta;\n          final double [] newBeta;\n          if(_activeCols != null){\n            newBeta = MemoryManager.malloc8d(_activeCols.length+1);\n            newBeta[newBeta.length-1] = fullBeta[fullBeta.length-1];\n            int j = 0;\n            for(int c:_activeCols)\n              newBeta[j++] = fullBeta[c];\n            assert j == newBeta.length-1;\n          } else\n            newBeta = fullBeta;\n          // public GLMIterationTask(Job job, DataInfo dinfo, GLMParams glm, boolean computeGram, boolean validate, boolean computeGradient, double [] beta, double ymu, double reg, H2OCountedCompleter cmp) {\n          glmt3 = new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,glmt._validate,glmt._computeGradient,newBeta,glmt._ymu,glmt._reg,new Iteration());\n        } else glmt3 = glmt;\n        if(n_folds > 1)\n          xvalidate(_model,_lambdaIdx,new H2OCallback<GLMModel.GLMValidationTask>(GLM2.this) {\n            @Override public void callback(GLMModel.GLMValidationTask v){ nextLambda(glmt3,v._res);}\n          });\n        else  nextLambda(glmt3,glmt2._val);\n      }\n    }).asyncExec(_dinfo._adaptedFrame);\n  }","id":37138,"modified_method":"private void nextLambda(final GLMIterationTask glmt, final double [] newBeta){\n    final double [] fullBeta;\n    if(_activeCols != null){\n      fullBeta = MemoryManager.malloc8d(_dinfo.fullN()+1);\n      fullBeta[fullBeta.length-1] = newBeta[newBeta.length-1]; // intercept\n      int j = 0;\n      for(int i:_activeCols)\n        fullBeta[i] = newBeta[j++];\n    } else fullBeta = newBeta;\n    new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,true,fullBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>(GLM2.this){\n      @Override public void callback(final GLMIterationTask glmt2){\n        final double [] grad = glmt2.gradient(l2pen());\n        if(_lastResult != null)\n          _lastResult._fullGrad = grad;\n        // check the KKT conditions and filter data for next lambda\n        // check the gradient\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], fullBeta, grad);\n        double err = 0;\n        if(_activeCols != null){\n          for(int c:_activeCols)\n            if(grad[c] > err) err = grad[c];\n            else if(grad[c] < -err) err = -grad[c];\n          int [] failedCols = new int[64];\n          int fcnt = 0;\n          for(int i = 0; i < grad.length-1; ++i){\n            if(Arrays.binarySearch(_activeCols,i) >= 0)continue;\n            if(grad[i] > GLM_GRAD_EPS || -grad[i] < -GLM_GRAD_EPS){\n              if(fcnt == failedCols.length)\n                failedCols = Arrays.copyOf(failedCols,failedCols.length << 1);\n              failedCols[fcnt++] = i;\n            }\n          }\n          if(fcnt > 0){\n            Log.info(\"GLM2: \" + fcnt + \" variables failed KKT conditions check! Adding them to the model and continuing computation...\");\n            final int n = _activeCols.length;\n            final int [] oldActiveCols = _activeCols;\n            _activeCols = Arrays.copyOf(_activeCols,_activeCols.length+fcnt);\n            for(int i = 0; i < fcnt; ++i)\n              _activeCols[n+i] = failedCols[i];\n            Arrays.sort(_activeCols);\n            _activeData = _dinfo.filterExpandedColumns(_activeCols);\n            new GLMIterationTask(GLM2.this, _activeData,_glm,true,true,true,expandVec(glmt._beta,_activeCols,oldActiveCols),glmt._ymu,glmt._reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            return;\n          }\n        } else {\n          for(double d:grad)\n            if(d > err) err = d;\n            else if(d < -err) err = -d;\n        }\n        Log.info(\"GLM converged with max |subgradient| = \" + err);\n        final GLMIterationTask glmt3;\n        // now filter out the cols for the next lambda...\n        if(lambda.length > 1 && _lambdaIdx < lambda.length-1 && _activeCols != null){\n          final int [] oldCols = _activeCols;\n          activeCols(lambda[_lambdaIdx+1],lambda[_lambdaIdx],glmt2.gradient(l2pen()));\n          // epxand the beta\n          final double [] fullBeta = glmt2._beta;\n          final double [] newBeta;\n          if(_activeCols != null){\n            newBeta = MemoryManager.malloc8d(_activeCols.length+1);\n            newBeta[newBeta.length-1] = fullBeta[fullBeta.length-1];\n            int j = 0;\n            for(int c:_activeCols)\n              newBeta[j++] = fullBeta[c];\n            assert j == newBeta.length-1;\n          } else\n            newBeta = fullBeta;\n          if(Arrays.equals(oldCols,_activeCols)) // set of coefficients did not change\n            glmt3 = glmt;\n          else\n            glmt3 = new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,glmt._validate,glmt._computeGradient,newBeta,glmt._ymu,glmt._reg,new Iteration());\n        } else glmt3 = glmt;\n        if(n_folds > 1)\n          xvalidate(_model,_lambdaIdx,new H2OCallback<GLMModel.GLMValidationTask>(GLM2.this) {\n            @Override public void callback(GLMModel.GLMValidationTask v){ nextLambda(glmt3,v._res);}\n          });\n        else  nextLambda(glmt3,glmt2._val);\n      }\n    }).asyncExec(_dinfo._adaptedFrame);\n  }","commit_id":"4ac62e29d2e20712defd57279f5011af62f451f1","url":"https://github.com/h2oai/h2o-2"},{"original_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - _iterationStartTime) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we dont wan to run with that\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);//.store();\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err) err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged with max |subgradient| = \" + err);\n          setNewBeta(glmt._beta);\n          nextLambda(glmt, glmt._beta);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._nobs + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              final double [] prevBeta = _lastResult._activeCols != _activeCols?expandVec(_lastResult._glmt._beta,_activeCols,_lastResult._activeCols):_lastResult._glmt._beta;\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, prevBeta, _ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n              return;\n            }\n          }\n          final double [] b = expandVec(_lastResult._glmt._beta, _activeCols, _lastResult._activeCols);\n          assert (b.length == glmt._beta.length):b.length + \" != \" + glmt._beta.length + \", activeCols = \" + _activeCols.length;\n          new GLMTask.GLMLineSearchTask(GLM2.this,_activeData,_glm,expandVec(_lastResult._glmt._beta,_activeCols,_lastResult._activeCols),glmt._beta,1e-8,glmt._nobs,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_activeData._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt,_activeCols);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n        nextLambda(glmt,glmt._beta);\n      } else {\n        setNewBeta(newBeta);\n        final double bdiff = beta_diff(glmt._beta,newBeta);\n        if(_glm.family == Family.gaussian || bdiff < beta_epsilon || _iter == max_iter){ // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          int diff = (int)Math.log10(bdiff);\n          Log.info(\"GLM2 (lambda_\" + _lambdaIdx + \") converged (reached a fixed point with ~ 1e\" + diff + \" precision) after \" + _iter + \"iterations\");\n          nextLambda(glmt,newBeta);\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n        }\n      }\n    }","id":37139,"modified_method":"@Override public void callback(final GLMIterationTask glmt) {\n      Log.info(\"GLM2 iteration(\" + _iter + \") done in \" + (System.currentTimeMillis() - _iterationStartTime) + \"ms\");\n      if( !isRunning(self()) )  throw new JobCancelledException();\n      currentLambdaIter++;\n      if(glmt._val != null){\n        if(!(glmt._val.residual_deviance < glmt._val.null_deviance)){ // complete fail, look if we can restart with higher_accuracy on\n          if(!highAccuracy()){\n            Log.info(\"GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.\");\n            setHighAccuracy();\n            if(_lastResult != null)\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, _lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            else if(_lambdaIdx > 2) // > 2 because 0 is null model, we don't wan to run with that\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, _model.submodels[_lambdaIdx-1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            else // no sane solution to go back to, start from scratch!\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, false, false, null,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n            _lastResult = null;\n            return;\n          }\n        }\n        _model.setAndTestValidation(_lambdaIdx,glmt._val);\n        _model.clone().update(self());\n      }\n\n      if(glmt._val != null && glmt._computeGradient){ // check gradient\n        final double [] grad = glmt.gradient(l2pen());\n        ADMMSolver.subgrad(alpha[0], lambda[_lambdaIdx], glmt._beta, grad);\n        double err = 0;\n        for(double d:grad)\n          if(d > err) err = d;\n          else if(d < -err) err = -d;\n        Log.info(\"GLM2 gradient after \" + _iter + \" iterations = \" + err);\n        if(err <= GLM_GRAD_EPS){\n          Log.info(\"GLM2 converged by reaching small enough gradient, with max |subgradient| = \" + err);\n          setNewBeta(glmt._beta);\n          nextLambda(glmt, glmt._beta);\n          return;\n        }\n      }\n      if(glmt._beta != null && glmt._val!=null && glmt._computeGradient && _glm.family != Family.tweedie){\n        double objval = glmt._val.residual_deviance/glmt._nobs + 0.5*l2pen()*l2norm(glmt._beta) + l1pen()*l1norm(glmt._beta);\n        if(_lastResult != null && needLineSearch(glmt._beta,objval,1)){\n          if(!highAccuracy()){\n            setHighAccuracy();\n            if(_lastResult._iter < (_iter-2)){ // there is a gap form last result...return to it and start again\n              final double [] prevBeta = _lastResult._activeCols != _activeCols?expandVec(_lastResult._glmt._beta,_activeCols,_lastResult._activeCols):_lastResult._glmt._beta;\n              new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, true, true, prevBeta, _ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n              return;\n            }\n          }\n          final double [] b = expandVec(_lastResult._glmt._beta, _activeCols, _lastResult._activeCols);\n          assert (b.length == glmt._beta.length):b.length + \" != \" + glmt._beta.length + \", activeCols = \" + _activeCols.length;\n          new GLMTask.GLMLineSearchTask(GLM2.this,_activeData,_glm,expandVec(_lastResult._glmt._beta,_activeCols,_lastResult._activeCols),glmt._beta,1e-3,glmt._nobs,alpha[0],lambda[_lambdaIdx], new LineSearchIteration()).asyncExec(_activeData._adaptedFrame);\n          return;\n        }\n        _lastResult = new IterationInfo(GLM2.this._iter-1, objval, glmt,_activeCols);\n      }\n      final double [] newBeta = glmt._beta != null?glmt._beta.clone():MemoryManager.malloc8d(glmt._xy.length);\n      ADMMSolver slvr = new ADMMSolver(lambda[_lambdaIdx],alpha[0], ADMM_GRAD_EPS, _addedL2);\n      slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);\n      _addedL2 = slvr._addedL2;\n      if(Utils.hasNaNsOrInfs(newBeta)){\n        Log.info(\"GLM2 forcibly converged by getting NaNs and/or Infs in beta\");\n        nextLambda(glmt,glmt._beta);\n      } else {\n        setNewBeta(newBeta);\n        final double bdiff = beta_diff(glmt._beta,newBeta);\n        if(_glm.family == Family.gaussian || bdiff < beta_epsilon || _iter == max_iter){ // Gaussian is non-iterative and gradient is ADMMSolver's gradient => just validate and move on to the next lambda\n          int diff = (int)Math.log10(bdiff);\n          int nzs = 0;\n          for(int i = 0; i < newBeta.length; ++i)\n            if(newBeta[i] != 0) ++nzs;\n          if(newBeta.length < 20)System.out.println(\"beta = \" + Arrays.toString(newBeta));\n          Log.info(\"GLM2 (lambda_\" + _lambdaIdx + \"=\" + lambda[_lambdaIdx] + \") converged (reached a fixed point with ~ 1e\" + diff + \" precision) after \" + _iter + \"iterations, got \" + nzs + \" nzs\");\n          nextLambda(glmt,newBeta);\n        } else { // not done yet, launch next iteration\n          final boolean validate = higher_accuracy || (currentLambdaIter % 5) == 0;\n          ++_iter;\n          System.out.println(\"Iter = \" + _iter);\n          new GLMIterationTask(GLM2.this,_activeData,glmt._glm, true, validate, validate, newBeta,_ymu,_reg,new Iteration()).asyncExec(_activeData._adaptedFrame);\n        }\n      }\n    }","commit_id":"4ac62e29d2e20712defd57279f5011af62f451f1","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public void run(final boolean doLog){\n    if(doLog)logStart();\n    _activeData = _dinfo;\n    assert alpha.length == 1;\n    start = System.currentTimeMillis();\n\n    if(highAccuracy() || lambda_search) // shortcut for fast & simple mode\n      new YMUTask(GLM2.this,_dinfo,new H2OCallback<YMUTask>(GLM2.this) {\n        @Override public void callback(final YMUTask ymut){\n          run(ymut.ymu(),ymut.nobs());\n        }\n      }).asyncExec(_dinfo._adaptedFrame);\n    else {\n      double ymu = _dinfo._adaptedFrame.lastVec().mean();\n      run(ymu, _dinfo._adaptedFrame.numRows()); // shortcut for quick & simple\n    }\n  }","id":37140,"modified_method":"public void run(final boolean doLog){\n    if(doLog)logStart();\n    System.out.println(\"running with \" + _dinfo.fullN() + \" predictors\");\n    _activeData = _dinfo;\n    assert alpha.length == 1;\n    start = System.currentTimeMillis();\n\n    if(highAccuracy() || lambda_search) // shortcut for fast & simple mode\n      new YMUTask(GLM2.this,_dinfo,new H2OCallback<YMUTask>(GLM2.this) {\n        @Override public void callback(final YMUTask ymut){\n          run(ymut.ymu(),ymut.nobs());\n        }\n      }).asyncExec(_dinfo._adaptedFrame);\n    else {\n      double ymu = _dinfo._adaptedFrame.lastVec().mean();\n      run(ymu, _dinfo._adaptedFrame.numRows()); // shortcut for quick & simple\n    }\n  }","commit_id":"4ac62e29d2e20712defd57279f5011af62f451f1","url":"https://github.com/h2oai/h2o-2"},{"original_method":"protected boolean needLineSearch(double [] beta,double objval, double step){\n    if(Double.isNaN(objval))return true; // needed for gamma (and possibly others...)\n    final double [] fullBeta = expandVec(beta,_activeCols);\n    // line search\n    double f_hat = 0;\n    final double [] grad = expandVec(_lastResult._glmt.gradient(l2pen()),_lastResult._activeCols);\n    ADMMSolver.subgrad(alpha[0],lambda[_lambdaIdx],fullBeta,grad);\n    final double [] oldBeta = expandVec(_lastResult._glmt._beta, _lastResult._activeCols);\n    for(int i = 0; i < beta.length; ++i){\n      double diff = fullBeta[i] - oldBeta[i];\n      f_hat += grad[i]*diff;\n    }\n    f_hat = _lastResult._objval + 0.5*step*f_hat;\n    return objval > f_hat;\n  }","id":37141,"modified_method":"protected boolean needLineSearch(double [] b,double objval, double step){\n    if(Double.isNaN(objval))return true; // needed for gamma (and possibly others...)\n    final double [] beta, grad;\n    if(_activeCols != _lastResult._activeCols){\n      beta = expandVec(b,_activeCols);\n      grad = _lastResult._fullGrad;\n    } else {\n      beta = b;\n      grad = _lastResult._glmt.gradient(l2pen());\n    }\n    // line search\n    double f_hat = 0;\n    ADMMSolver.subgrad(alpha[0],lambda[_lambdaIdx],beta,grad);\n    final double [] oldBeta = expandVec(_lastResult._glmt._beta, _lastResult._activeCols);\n    for(int i = 0; i < beta.length; ++i){\n      double diff = beta[i] - oldBeta[i];\n      f_hat += grad[i]*diff;\n    }\n    f_hat = _lastResult._objval + 0.5*step*f_hat;\n    return objval > f_hat;\n  }","commit_id":"4ac62e29d2e20712defd57279f5011af62f451f1","url":"https://github.com/h2oai/h2o-2"},{"original_method":"public boolean solve(Gram gram, double [] xy, double yy, double[] res, double objVal) {\n      double d = gram._diagAdded;\n      final int N = xy.length;\n      Arrays.fill(res, 0);\n      if(_lambda>0 || _addedL2 > 0)\n        gram.addDiag(_lambda*(1-_alpha) + _addedL2);\n      double rho = _rho;\n      if(_alpha > 0 && _lambda > 0){\n        if(Double.isNaN(_rho)) rho = _lambda*_alpha;// find rho value as min diag element + constant\n        System.out.println(\"rho = \" + rho);\n        gram.addDiag(rho);\n      }\n      if(_proximalPenalty > 0 && _wgiven != null){\n        gram.addDiag(_proximalPenalty, true);\n        xy = xy.clone();\n        for(int i = 0; i < xy.length; ++i)\n          xy[i] += _proximalPenalty*_wgiven[i];\n      }\n      int attempts = 0;\n      long t1 = System.currentTimeMillis();\n      Cholesky chol = gram.cholesky(null,true,_id);\n      long t2 = System.currentTimeMillis();\n      while(!chol.isSPD() && attempts < 10){\n        if(_addedL2 == 0) _addedL2 = 1e-5;\n        else _addedL2 *= 10;\n        Log.info(\"GLM ADMM: BUMPED UP RHO TO \" + rho + _addedL2);\n        ++attempts;\n        gram.addDiag(_addedL2); // try to add L2 penalty to make the Gram issp\n        gram.cholesky(chol);\n      }\n      long decompTIme = (t2-t1);\n\n      if(!chol.isSPD()){\n        System.out.println(\"can not solve, got non-spd matrix and adding regularization did not help, matrix = \\n\" + gram);\n        throw new NonSPDMatrixException(gram);\n      }\n      _rho = rho;\n      if(_alpha == 0 || _lambda == 0){ // no l1 penalty\n        System.arraycopy(xy, 0, res, 0, xy.length);\n        chol.solve(res);\n        gram.addDiag(-gram._diagAdded + d);\n        return true;\n      }\n      long t = System.currentTimeMillis();\n      final double ABSTOL = Math.sqrt(N) * 1e-4;\n      final double RELTOL = 1e-2;\n      double[] u = MemoryManager.malloc8d(N);\n      double [] xyPrime = xy.clone();\n      double kappa = _lambda*_alpha/rho;\n      double [] grad = null;\n      int i;\n      int k = 10;\n      double gradientErr = Double.POSITIVE_INFINITY;\n\n      double gerr = Double.POSITIVE_INFINITY;\n      double [] z = res.clone();\n      for(i = 0; i < 2500; ++i ) {\n        // first compute the x update\n        // add rho*(z-u) to A'*y\n        for( int j = 0; j < N-1; ++j )xyPrime[j] = xy[j] + rho*(z[j] - u[j]);\n        xyPrime[N-1] = xy[N-1];\n        // updated x\n        chol.solve(xyPrime);\n        // compute u and z update\n        for( int j = 0; j < N-1; ++j ) {\n          double x_hat = xyPrime[j];\n          x_hat = x_hat * _orlx + (1 - _orlx) * z[j];\n          double zold = z[j];\n          z[j] = shrinkage(x_hat + u[j], kappa);\n          u[j] += x_hat - z[j];\n        }\n        z[N-1] = xyPrime[N-1];\n        if(i == k){\n          gerr = getGrad(i,gram,z,xy);\n          if(gerr < _gradientEps){\n            _converged = true;\n            System.arraycopy(z,0,res,0,z.length);\n            break;\n          }\n          // did not converge, check if we can converge in reasonable time\n          double diff = gradientErr - gerr;\n          if(diff < 0 || (gerr/diff) > 1e3){ // we won't ever converge with this setup (maybe change rho and try again?)\n            if(_orlx < 1.8 && gerr > 5e-4){ //\n              _orlx = Math.min(1.8,_orlx*1.25); // try if over-relaxation helps...\n              Log.info(\"trying over-relaxation of \" + _orlx + \" after \" + i + \" iteartions and gerr = \" + gerr);\n            } else {\n              _converged = gerr < 1e-4;\n              break;\n            }\n          } else {\n            System.arraycopy(z,0,res,0,z.length);\n            gradientErr = gerr;\n          }\n          k = i + 10; // test gradient every 10 iterations\n        }\n      }\n      gram.addDiag(-gram._diagAdded + d);\n      assert gram._diagAdded == d;\n      long solveTime = System.currentTimeMillis()-t;\n      if(Double.isInfinite(gerr)) gerr = getGrad(i,gram,res,xy);\n      Log.info(\"ADMM finished in \" + i + \" iterations and (\" + decompTIme + \" + \" + solveTime+ \")ms, max |subgradient| = \" + gerr);\n      return _converged;\n    }","id":37142,"modified_method":"public boolean solve(Gram gram, double [] xy, double yy, double[] res, double objVal) {\n      double d = gram._diagAdded;\n      final int N = xy.length;\n      Arrays.fill(res, 0);\n      if(_lambda>0 || _addedL2 > 0)\n        gram.addDiag(_lambda*(1-_alpha) + _addedL2);\n      double rho = _rho;\n      if(_alpha > 0 && _lambda > 0){\n        if(Double.isNaN(_rho)) rho = _lambda*_alpha;// find rho value as min diag element + constant\n        System.out.println(\"rho = \" + rho);\n        gram.addDiag(rho);\n      }\n      if(_proximalPenalty > 0 && _wgiven != null){\n        gram.addDiag(_proximalPenalty, true);\n        xy = xy.clone();\n        for(int i = 0; i < xy.length; ++i)\n          xy[i] += _proximalPenalty*_wgiven[i];\n      }\n      int attempts = 0;\n      long t1 = System.currentTimeMillis();\n      Cholesky chol = gram.cholesky(null,true,_id);\n      long t2 = System.currentTimeMillis();\n      while(!chol.isSPD() && attempts < 10){\n        if(_addedL2 == 0) _addedL2 = 1e-5;\n        else _addedL2 *= 10;\n        Log.info(\"GLM ADMM: BUMPED UP RHO TO \" + rho + _addedL2);\n        ++attempts;\n        gram.addDiag(_addedL2); // try to add L2 penalty to make the Gram issp\n        gram.cholesky(chol);\n      }\n      long decompTIme = (t2-t1);\n\n      if(!chol.isSPD()){\n        System.out.println(\"can not solve, got non-spd matrix and adding regularization did not help, matrix = \\n\" + gram);\n        throw new NonSPDMatrixException(gram);\n      }\n      _rho = rho;\n      if(_alpha == 0 || _lambda == 0){ // no l1 penalty\n        System.arraycopy(xy, 0, res, 0, xy.length);\n        chol.solve(res);\n        gram.addDiag(-gram._diagAdded + d);\n        return true;\n      }\n      long t = System.currentTimeMillis();\n      final double ABSTOL = Math.sqrt(N) * 1e-4;\n      final double RELTOL = 1e-2;\n      double[] u = MemoryManager.malloc8d(N);\n      double [] xyPrime = xy.clone();\n      double kappa = _lambda*_alpha/rho;\n      double [] grad = null;\n      int i;\n      int k = 10;\n      double gradientErr = Double.POSITIVE_INFINITY;\n\n      double gerr = Double.POSITIVE_INFINITY;\n      double [] z = res.clone();\n      for(i = 0; i < 2500; ++i ) {\n        // first compute the x update\n        // add rho*(z-u) to A'*y\n        for( int j = 0; j < N-1; ++j )xyPrime[j] = xy[j] + rho*(z[j] - u[j]);\n        xyPrime[N-1] = xy[N-1];\n        // updated x\n        chol.solve(xyPrime);\n        // compute u and z update\n        for( int j = 0; j < N-1; ++j ) {\n          double x_hat = xyPrime[j];\n          x_hat = x_hat * _orlx + (1 - _orlx) * z[j];\n          double zold = z[j];\n          z[j] = shrinkage(x_hat + u[j], kappa);\n          u[j] += x_hat - z[j];\n        }\n        z[N-1] = xyPrime[N-1];\n        if(i == k){\n          gerr = getGrad(i,gram,z,xy);\n          if(gerr < _gradientEps){\n            _converged = true;\n            System.arraycopy(z,0,res,0,z.length);\n            break;\n          }\n          // did not converge, check if we can converge in reasonable time\n          double diff = gradientErr - gerr;\n          if(diff < 0 || (gerr/diff) > 1e3){ // we won't ever converge with this setup (maybe change rho and try again?)\n            if(_orlx < 1.8 && gerr > 5e-4){ //\n              _orlx = 1.8; // try if over-relaxation helps...\n              Log.info(\"trying over-relaxation of \" + _orlx + \" after \" + i + \" iteartions and gerr = \" + gerr);\n            } else {\n              _converged = gerr < 1e-4;\n              break;\n            }\n          } else {\n            System.arraycopy(z,0,res,0,z.length);\n            gradientErr = gerr;\n          }\n          k = i + 10; // test gradient every 10 iterations\n        }\n      }\n      gram.addDiag(-gram._diagAdded + d);\n      assert gram._diagAdded == d;\n      long solveTime = System.currentTimeMillis()-t;\n      if(Double.isInfinite(gradientErr)) gradientErr = getGrad(i,gram,res,xy);\n      Log.info(\"ADMM finished in \" + i + \" iterations and (\" + decompTIme + \" + \" + solveTime+ \")ms, max |subgradient| = \" + gradientErr);\n      return _converged;\n    }","commit_id":"4ac62e29d2e20712defd57279f5011af62f451f1","url":"https://github.com/h2oai/h2o-2"},{"original_method":"/**\n   * Returns a snapshot of the current HMemcache with a known HLog \n   * sequence number at the same time.\n   *\n   * We need to prevent any writing to the cache during this time,\n   * so we obtain a write lock for the duration of the operation.\n   * \n   * <p>If this method returns non-null, client must call\n   * {@link #deleteSnapshot()} to clear 'snapshot-in-progress'\n   * state when finished with the returned {@link Snapshot}.\n   * \n   * @return frozen HMemcache TreeMap and HLog sequence number.\n   */\n  public Snapshot snapshotMemcacheForLog(HLog log) throws IOException {\n    Snapshot retval = new Snapshot();\n\n    this.lock.writeLock().lock();\n    try {\n      if(snapshot != null) {\n        throw new IOException(\"Snapshot in progress!\");\n      }\n      if(memcache.size() == 0) {\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"memcache empty. Skipping snapshot\");\n        }\n        return retval;\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"starting memcache snapshot\");\n      }\n      \n      retval.memcacheSnapshot = memcache;\n      this.snapshot = memcache;\n      history.add(memcache);\n      memcache = new TreeMap<HStoreKey, BytesWritable>();\n      retval.sequenceId = log.startCacheFlush();\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"memcache snapshot complete\");\n      }\n      \n      return retval;\n      \n    } finally {\n      this.lock.writeLock().unlock();\n    }\n  }","id":37143,"modified_method":"/**\n   * Returns a snapshot of the current HMemcache with a known HLog \n   * sequence number at the same time.\n   *\n   * We need to prevent any writing to the cache during this time,\n   * so we obtain a write lock for the duration of the operation.\n   * \n   * <p>If this method returns non-null, client must call\n   * {@link #deleteSnapshot()} to clear 'snapshot-in-progress'\n   * state when finished with the returned {@link Snapshot}.\n   * \n   * @return frozen HMemcache TreeMap and HLog sequence number.\n   */\n  public Snapshot snapshotMemcacheForLog(HLog log) throws IOException {\n    Snapshot retval = new Snapshot();\n\n    this.lock.obtainWriteLock();\n    try {\n      if(snapshot != null) {\n        throw new IOException(\"Snapshot in progress!\");\n      }\n      if(memcache.size() == 0) {\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"memcache empty. Skipping snapshot\");\n        }\n        return retval;\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"starting memcache snapshot\");\n      }\n      \n      retval.memcacheSnapshot = memcache;\n      this.snapshot = memcache;\n      history.add(memcache);\n      memcache = new TreeMap<HStoreKey, BytesWritable>();\n      retval.sequenceId = log.startCacheFlush();\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"memcache snapshot complete\");\n      }\n      \n      return retval;\n      \n    } finally {\n      this.lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Store a value.  \n   *\n   * Operation uses a write lock.\n   */\n  public void add(Text row, TreeMap<Text, BytesWritable> columns, long timestamp) {\n    this.lock.writeLock().lock();\n    try {\n      for (Map.Entry<Text, BytesWritable> es: columns.entrySet()) {\n        HStoreKey key = new HStoreKey(row, es.getKey(), timestamp);\n        memcache.put(key, es.getValue());\n      }\n    } finally {\n      this.lock.writeLock().unlock();\n    }\n  }","id":37144,"modified_method":"/**\n   * Store a value.  \n   *\n   * Operation uses a write lock.\n   */\n  public void add(Text row, TreeMap<Text, BytesWritable> columns, long timestamp) {\n    this.lock.obtainWriteLock();\n    try {\n      for (Map.Entry<Text, BytesWritable> es: columns.entrySet()) {\n        HStoreKey key = new HStoreKey(row, es.getKey(), timestamp);\n        memcache.put(key, es.getValue());\n      }\n    } finally {\n      this.lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Delete the snapshot, remove from history.\n   *\n   * Modifying the structure means we need to obtain a writelock.\n   */\n  public void deleteSnapshot() throws IOException {\n    this.lock.writeLock().lock();\n\n    try {\n      if(snapshot == null) {\n        throw new IOException(\"Snapshot not present!\");\n      }\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"deleting snapshot\");\n      }\n      \n      for(Iterator<TreeMap<HStoreKey, BytesWritable>> it = history.iterator(); \n          it.hasNext(); ) {\n        \n        TreeMap<HStoreKey, BytesWritable> cur = it.next();\n        if(snapshot == cur) {\n          it.remove();\n          break;\n        }\n      }\n      this.snapshot = null;\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"snapshot deleted\");\n      }\n      \n    } finally {\n      this.lock.writeLock().unlock();\n    }\n  }","id":37145,"modified_method":"/**\n   * Delete the snapshot, remove from history.\n   *\n   * Modifying the structure means we need to obtain a writelock.\n   */\n  public void deleteSnapshot() throws IOException {\n    this.lock.obtainWriteLock();\n\n    try {\n      if(snapshot == null) {\n        throw new IOException(\"Snapshot not present!\");\n      }\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"deleting snapshot\");\n      }\n      \n      for(Iterator<TreeMap<HStoreKey, BytesWritable>> it = history.iterator(); \n          it.hasNext(); ) {\n        \n        TreeMap<HStoreKey, BytesWritable> cur = it.next();\n        if(snapshot == cur) {\n          it.remove();\n          break;\n        }\n      }\n      this.snapshot = null;\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"snapshot deleted\");\n      }\n      \n    } finally {\n      this.lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Return all the available columns for the given key.  The key indicates a \n   * row and timestamp, but not a column name.\n   *\n   * The returned object should map column names to byte arrays (byte[]).\n   */\n  public TreeMap<Text, BytesWritable> getFull(HStoreKey key) {\n    TreeMap<Text, BytesWritable> results = new TreeMap<Text, BytesWritable>();\n    this.lock.readLock().lock();\n    try {\n      internalGetFull(memcache, key, results);\n      for(int i = history.size()-1; i >= 0; i--) {\n        TreeMap<HStoreKey, BytesWritable> cur = history.elementAt(i);\n        internalGetFull(cur, key, results);\n      }\n      return results;\n      \n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37146,"modified_method":"/**\n   * Return all the available columns for the given key.  The key indicates a \n   * row and timestamp, but not a column name.\n   *\n   * The returned object should map column names to byte arrays (byte[]).\n   */\n  public TreeMap<Text, BytesWritable> getFull(HStoreKey key) {\n    TreeMap<Text, BytesWritable> results = new TreeMap<Text, BytesWritable>();\n    this.lock.obtainReadLock();\n    try {\n      internalGetFull(memcache, key, results);\n      for(int i = history.size()-1; i >= 0; i--) {\n        TreeMap<HStoreKey, BytesWritable> cur = history.elementAt(i);\n        internalGetFull(cur, key, results);\n      }\n      return results;\n      \n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/** Shut down map iterators, and release the lock */\n    public void close() {\n      if(! scannerClosed) {\n        try {\n          for(int i = 0; i < keys.length; i++) {\n            if(keyIterators[i] != null) {\n              closeSubScanner(i);\n            }\n          }\n          \n        } finally {\n          lock.readLock().unlock();\n          scannerClosed = true;\n        }\n      }\n    }","id":37147,"modified_method":"/** Shut down map iterators, and release the lock */\n    public void close() {\n      if(! scannerClosed) {\n        try {\n          for(int i = 0; i < keys.length; i++) {\n            if(keyIterators[i] != null) {\n              closeSubScanner(i);\n            }\n          }\n          \n        } finally {\n          lock.releaseReadLock();\n          scannerClosed = true;\n        }\n      }\n    }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"@SuppressWarnings(\"unchecked\")\n    public HMemcacheScanner(long timestamp, Text targetCols[], Text firstRow)\n        throws IOException {\n      \n      super(timestamp, targetCols);\n      \n      lock.readLock().lock();\n      try {\n        this.backingMaps = new TreeMap[history.size() + 1];\n        \n        //NOTE: Since we iterate through the backing maps from 0 to n, we need\n        //      to put the memcache first, the newest history second, ..., etc.\n        \n        backingMaps[0] = memcache;\n        for(int i = history.size() - 1; i > 0; i--) {\n          backingMaps[i] = history.elementAt(i);\n        }\n      \n        this.keyIterators = new Iterator[backingMaps.length];\n        this.keys = new HStoreKey[backingMaps.length];\n        this.vals = new BytesWritable[backingMaps.length];\n\n        // Generate list of iterators\n\n        HStoreKey firstKey = new HStoreKey(firstRow);\n        for(int i = 0; i < backingMaps.length; i++) {\n          if(firstRow.getLength() != 0) {\n            keyIterators[i] = backingMaps[i].tailMap(firstKey).keySet().iterator();\n            \n          } else {\n            keyIterators[i] = backingMaps[i].keySet().iterator();\n          }\n          \n          while(getNext(i)) {\n            if(! findFirstRow(i, firstRow)) {\n              continue;\n            }\n            if(columnMatch(i)) {\n              break;\n            }\n          }\n        }\n        \n      } catch(IOException ex) {\n        LOG.error(ex);\n        close();\n        throw ex;\n      }\n    }","id":37148,"modified_method":"@SuppressWarnings(\"unchecked\")\n    public HMemcacheScanner(long timestamp, Text targetCols[], Text firstRow)\n        throws IOException {\n      \n      super(timestamp, targetCols);\n      \n      lock.obtainReadLock();\n      try {\n        this.backingMaps = new TreeMap[history.size() + 1];\n        \n        //NOTE: Since we iterate through the backing maps from 0 to n, we need\n        //      to put the memcache first, the newest history second, ..., etc.\n        \n        backingMaps[0] = memcache;\n        for(int i = history.size() - 1; i > 0; i--) {\n          backingMaps[i] = history.elementAt(i);\n        }\n      \n        this.keyIterators = new Iterator[backingMaps.length];\n        this.keys = new HStoreKey[backingMaps.length];\n        this.vals = new BytesWritable[backingMaps.length];\n\n        // Generate list of iterators\n\n        HStoreKey firstKey = new HStoreKey(firstRow);\n        for(int i = 0; i < backingMaps.length; i++) {\n          if(firstRow.getLength() != 0) {\n            keyIterators[i] = backingMaps[i].tailMap(firstKey).keySet().iterator();\n            \n          } else {\n            keyIterators[i] = backingMaps[i].keySet().iterator();\n          }\n          \n          while(getNext(i)) {\n            if(! findFirstRow(i, firstRow)) {\n              continue;\n            }\n            if(columnMatch(i)) {\n              break;\n            }\n          }\n        }\n        \n      } catch(IOException ex) {\n        LOG.error(ex);\n        close();\n        throw ex;\n      }\n    }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Look back through all the backlog TreeMaps to find the target.\n   *\n   * We only need a readlock here.\n   */\n  public BytesWritable[] get(HStoreKey key, int numVersions) {\n    Vector<BytesWritable> results = new Vector<BytesWritable>();\n    this.lock.readLock().lock();\n    try {\n      Vector<BytesWritable> result = get(memcache, key, numVersions-results.size());\n      results.addAll(0, result);\n\n      for(int i = history.size()-1; i >= 0; i--) {\n        if(numVersions > 0 && results.size() >= numVersions) {\n          break;\n        }\n        \n        result = get(history.elementAt(i), key, numVersions-results.size());\n        results.addAll(results.size(), result);\n      }\n      \n      return (results.size() == 0)?\n        null: results.toArray(new BytesWritable[results.size()]);\n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37149,"modified_method":"/**\n   * Look back through all the backlog TreeMaps to find the target.\n   *\n   * We only need a readlock here.\n   */\n  public BytesWritable[] get(HStoreKey key, int numVersions) {\n    Vector<BytesWritable> results = new Vector<BytesWritable>();\n    this.lock.obtainReadLock();\n    try {\n      Vector<BytesWritable> result = get(memcache, key, numVersions-results.size());\n      results.addAll(0, result);\n\n      for(int i = history.size()-1; i >= 0; i--) {\n        if(numVersions > 0 && results.size() >= numVersions) {\n          break;\n        }\n        \n        result = get(history.elementAt(i), key, numVersions-results.size());\n        results.addAll(results.size(), result);\n      }\n      \n      return (results.size() == 0)?\n        null: results.toArray(new BytesWritable[results.size()]);\n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Return an iterator that scans over the HRegion, returning the indicated \n   * columns.  This Iterator must be closed by the caller.\n   */\n  public HInternalScannerInterface getScanner(Text[] cols, Text firstRow) throws IOException {\n    lock.readLock().lock();\n    try {\n      TreeSet<Text> families = new TreeSet<Text>();\n      for(int i = 0; i < cols.length; i++) {\n        families.add(HStoreKey.extractFamily(cols[i]));\n      }\n\n      HStore[] storelist = new HStore[families.size()];\n      int i = 0;\n      for(Iterator<Text> it = families.iterator(); it.hasNext(); ) {\n        Text family = it.next();\n        storelist[i++] = stores.get(family);\n      }\n      return new HScanner(cols, firstRow, memcache, storelist);\n      \n    } finally {\n      lock.readLock().unlock();\n    }\n  }","id":37150,"modified_method":"/**\n   * Return an iterator that scans over the HRegion, returning the indicated \n   * columns.  This Iterator must be closed by the caller.\n   */\n  public HInternalScannerInterface getScanner(Text[] cols, Text firstRow) throws IOException {\n    lock.obtainReadLock();\n    try {\n      TreeSet<Text> families = new TreeSet<Text>();\n      for(int i = 0; i < cols.length; i++) {\n        families.add(HStoreKey.extractFamily(cols[i]));\n      }\n\n      HStore[] storelist = new HStore[families.size()];\n      int i = 0;\n      for(Iterator<Text> it = families.iterator(); it.hasNext(); ) {\n        Text family = it.next();\n        storelist[i++] = stores.get(family);\n      }\n      return new HScanner(cols, firstRow, memcache, storelist);\n      \n    } finally {\n      lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * The caller wants to apply a series of writes to a single row in the HRegion.\n   * The caller will invoke startUpdate(), followed by a series of calls to \n   * put/delete, then finally either abort() or commit().\n   *\n   * Note that we rely on the external caller to properly abort() or commit() \n   * every transaction.  If the caller is a network client, there should be a \n   * lease-system in place that automatically aborts() transactions after a \n   * specified quiet period.\n   */\n  public long startUpdate(Text row) throws IOException {\n\n    // We obtain a per-row lock, so other clients will\n    // block while one client performs an update.\n\n    lock.readLock().lock();\n    try {\n      return obtainLock(row);\n    } finally {\n      lock.readLock().unlock();\n    }\n  }","id":37151,"modified_method":"/**\n   * The caller wants to apply a series of writes to a single row in the HRegion.\n   * The caller will invoke startUpdate(), followed by a series of calls to \n   * put/delete, then finally either abort() or commit().\n   *\n   * Note that we rely on the external caller to properly abort() or commit() \n   * every transaction.  If the caller is a network client, there should be a \n   * lease-system in place that automatically aborts() transactions after a \n   * specified quiet period.\n   */\n  public long startUpdate(Text row) throws IOException {\n\n    // We obtain a per-row lock, so other clients will\n    // block while one client performs an update.\n\n    lock.obtainReadLock();\n    try {\n      return obtainLock(row);\n    } finally {\n      lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Fetch all the columns for the indicated row.\n   * Returns a TreeMap that maps column names to values.\n   *\n   * We should eventually use Bloom filters here, to reduce running time.  If \n   * the database has many column families and is very sparse, then we could be \n   * checking many files needlessly.  A small Bloom for each row would help us \n   * determine which column groups are useful for that row.  That would let us \n   * avoid a bunch of disk activity.\n   */\n  public TreeMap<Text, BytesWritable> getFull(Text row) throws IOException {\n    HStoreKey key = new HStoreKey(row, System.currentTimeMillis());\n\n    lock.readLock().lock();\n    try {\n      TreeMap<Text, BytesWritable> memResult = memcache.getFull(key);\n      for(Iterator<Text> it = stores.keySet().iterator(); it.hasNext(); ) {\n        Text colFamily = it.next();\n        HStore targetStore = stores.get(colFamily);\n        targetStore.getFull(key, memResult);\n      }\n      return memResult;\n      \n    } finally {\n      lock.readLock().unlock();\n    }\n  }","id":37152,"modified_method":"/**\n   * Fetch all the columns for the indicated row.\n   * Returns a TreeMap that maps column names to values.\n   *\n   * We should eventually use Bloom filters here, to reduce running time.  If \n   * the database has many column families and is very sparse, then we could be \n   * checking many files needlessly.  A small Bloom for each row would help us \n   * determine which column groups are useful for that row.  That would let us \n   * avoid a bunch of disk activity.\n   */\n  public TreeMap<Text, BytesWritable> getFull(Text row) throws IOException {\n    HStoreKey key = new HStoreKey(row, System.currentTimeMillis());\n\n    lock.obtainReadLock();\n    try {\n      TreeMap<Text, BytesWritable> memResult = memcache.getFull(key);\n      for(Iterator<Text> it = stores.keySet().iterator(); it.hasNext(); ) {\n        Text colFamily = it.next();\n        HStore targetStore = stores.get(colFamily);\n        targetStore.getFull(key, memResult);\n      }\n      return memResult;\n      \n    } finally {\n      lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * @return true if the region should be compacted.\n   */\n  public boolean needsCompaction() {\n    boolean needsCompaction = false;\n    lock.readLock().lock();\n    try {\n      for(Iterator<HStore> i = stores.values().iterator(); i.hasNext(); ) {\n        if(i.next().getNMaps() > compactionThreshold) {\n          needsCompaction = true;\n          break;\n        }\n      }\n    } finally {\n      lock.readLock().unlock();\n    }\n    return needsCompaction;\n  }","id":37153,"modified_method":"/**\n   * @return true if the region should be compacted.\n   */\n  public boolean needsCompaction() {\n    boolean needsCompaction = false;\n    lock.obtainReadLock();\n    try {\n      for(Iterator<HStore> i = stores.values().iterator(); i.hasNext(); ) {\n        if(i.next().getNMaps() > compactionThreshold) {\n          needsCompaction = true;\n          break;\n        }\n      }\n    } finally {\n      lock.releaseReadLock();\n    }\n    return needsCompaction;\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Close down this HRegion.  Flush the cache, shut down each HStore, don't \n   * service any more calls.\n   *\n   * The returned Vector is a list of all the storage files that the HRegion's \n   * component HStores make use of.  It's a list of HStoreFile objects.\n   *\n   * This method could take some time to execute, so don't call it from a \n   * time-sensitive thread.\n   */\n  public Vector<HStoreFile> close() throws IOException {\n    lock.writeLock().lock();\n    try {\n      boolean shouldClose = false;\n      synchronized(writestate) {\n        if(writestate.closed) {\n          LOG.info(\"region \" + this.regionInfo.regionName + \" closed\");\n          return new Vector<HStoreFile>();\n        }\n        while(writestate.writesOngoing) {\n          try {\n            writestate.wait();\n          } catch (InterruptedException iex) {\n          }\n        }\n        writestate.writesOngoing = true;\n        shouldClose = true;\n      }\n\n      if(! shouldClose) {\n        return null;\n\n      } else {\n        LOG.info(\"closing region \" + this.regionInfo.regionName);\n        Vector<HStoreFile> allHStoreFiles = internalFlushcache();\n        for(Iterator<HStore> it = stores.values().iterator(); it.hasNext(); ) {\n          HStore store = it.next();\n          store.close();\n        }\n        try {\n          return allHStoreFiles;\n\n        } finally {\n          synchronized(writestate) {\n            writestate.closed = true;\n            writestate.writesOngoing = false;\n          }\n          LOG.info(\"region \" + this.regionInfo.regionName + \" closed\");\n        }\n      }\n    } finally {\n      lock.writeLock().unlock();\n    }\n  }","id":37154,"modified_method":"/**\n   * Close down this HRegion.  Flush the cache, shut down each HStore, don't \n   * service any more calls.\n   *\n   * The returned Vector is a list of all the storage files that the HRegion's \n   * component HStores make use of.  It's a list of HStoreFile objects.\n   *\n   * This method could take some time to execute, so don't call it from a \n   * time-sensitive thread.\n   */\n  public Vector<HStoreFile> close() throws IOException {\n    lock.obtainWriteLock();\n    try {\n      boolean shouldClose = false;\n      synchronized(writestate) {\n        if(writestate.closed) {\n          LOG.info(\"region \" + this.regionInfo.regionName + \" closed\");\n          return new Vector<HStoreFile>();\n        }\n        while(writestate.writesOngoing) {\n          try {\n            writestate.wait();\n          } catch (InterruptedException iex) {\n          }\n        }\n        writestate.writesOngoing = true;\n        shouldClose = true;\n      }\n\n      if(! shouldClose) {\n        return null;\n\n      } else {\n        LOG.info(\"closing region \" + this.regionInfo.regionName);\n        Vector<HStoreFile> allHStoreFiles = internalFlushcache();\n        for(Iterator<HStore> it = stores.values().iterator(); it.hasNext(); ) {\n          HStore store = it.next();\n          store.close();\n        }\n        try {\n          return allHStoreFiles;\n\n        } finally {\n          synchronized(writestate) {\n            writestate.closed = true;\n            writestate.writesOngoing = false;\n          }\n          LOG.info(\"region \" + this.regionInfo.regionName + \" closed\");\n        }\n      }\n    } finally {\n      lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Iterates through all the HStores and finds the one with the largest MapFile\n   * size. If the size is greater than the (currently hard-coded) threshold,\n   * returns true indicating that the region should be split. The midKey for the\n   * largest MapFile is returned through the midKey parameter.\n   * \n   * @param midKey      - (return value) midKey of the largest MapFile\n   * @return            - true if the region should be split\n   */\n  public boolean needsSplit(Text midKey) {\n    lock.readLock().lock();\n\n    try {\n      Text key = new Text();\n      long maxSize = 0;\n\n      for(Iterator<HStore> i = stores.values().iterator(); i.hasNext(); ) {\n        long size = i.next().getLargestFileSize(key);\n\n        if(size > maxSize) {                      // Largest so far\n          maxSize = size;\n          midKey.set(key);\n        }\n      }\n\n      return (maxSize > (DESIRED_MAX_FILE_SIZE + (DESIRED_MAX_FILE_SIZE / 2)));\n      \n    } finally {\n      lock.readLock().unlock();\n    }\n  }","id":37155,"modified_method":"/**\n   * Iterates through all the HStores and finds the one with the largest MapFile\n   * size. If the size is greater than the (currently hard-coded) threshold,\n   * returns true indicating that the region should be split. The midKey for the\n   * largest MapFile is returned through the midKey parameter.\n   * \n   * @param midKey      - (return value) midKey of the largest MapFile\n   * @return            - true if the region should be split\n   */\n  public boolean needsSplit(Text midKey) {\n    lock.obtainReadLock();\n\n    try {\n      Text key = new Text();\n      long maxSize = 0;\n\n      for(Iterator<HStore> i = stores.values().iterator(); i.hasNext(); ) {\n        long size = i.next().getLargestFileSize(key);\n\n        if(size > maxSize) {                      // Largest so far\n          maxSize = size;\n          midKey.set(key);\n        }\n      }\n\n      return (maxSize > (DESIRED_MAX_FILE_SIZE + (DESIRED_MAX_FILE_SIZE / 2)));\n      \n    } finally {\n      lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"private BytesWritable[] get(HStoreKey key, int numVersions) throws IOException {\n\n    lock.readLock().lock();\n    try {\n      // Check the memcache\n\n      BytesWritable[] result = memcache.get(key, numVersions);\n      if(result != null) {\n        return result;\n      }\n\n      // If unavailable in memcache, check the appropriate HStore\n\n      Text colFamily = HStoreKey.extractFamily(key.getColumn());\n      HStore targetStore = stores.get(colFamily);\n      if(targetStore == null) {\n        return null;\n      }\n\n      return targetStore.get(key, numVersions);\n      \n    } finally {\n      lock.readLock().unlock();\n    }\n  }","id":37156,"modified_method":"private BytesWritable[] get(HStoreKey key, int numVersions) throws IOException {\n\n    lock.obtainReadLock();\n    try {\n      // Check the memcache\n\n      BytesWritable[] result = memcache.get(key, numVersions);\n      if(result != null) {\n        return result;\n      }\n\n      // If unavailable in memcache, check the appropriate HStore\n\n      Text colFamily = HStoreKey.extractFamily(key.getColumn());\n      HStore targetStore = stores.get(colFamily);\n      if(targetStore == null) {\n        return null;\n      }\n\n      return targetStore.get(key, numVersions);\n      \n    } finally {\n      lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Compact all the stores.  This should be called periodically to make sure \n   * the stores are kept manageable.  \n   *\n   * This operation could block for a long time, so don't call it from a \n   * time-sensitive thread.\n   *\n   * If it returns TRUE, the compaction has completed.\n   * \n   * If it returns FALSE, the compaction was not carried out, because the \n   * HRegion is busy doing something else storage-intensive (like flushing the \n   * cache).  The caller should check back later.\n   */\n  public boolean compactStores() throws IOException {\n    boolean shouldCompact = false;\n    lock.readLock().lock();\n    try {\n      synchronized(writestate) {\n        if((! writestate.writesOngoing)\n            && writestate.writesEnabled\n            && (! writestate.closed)\n            && recentCommits > MIN_COMMITS_FOR_COMPACTION) {\n\n          writestate.writesOngoing = true;\n          shouldCompact = true;\n        }\n      }\n    } finally {\n      lock.readLock().unlock();\n    }\n\n    if(! shouldCompact) {\n      LOG.info(\"not compacting region \" + this.regionInfo.regionName);\n      return false;\n      \n    } else {\n      lock.writeLock().lock();\n      try {\n        LOG.info(\"starting compaction on region \" + this.regionInfo.regionName);\n        for(Iterator<HStore> it = stores.values().iterator(); it.hasNext(); ) {\n          HStore store = it.next();\n          store.compact();\n        }\n        LOG.info(\"compaction completed on region \" + this.regionInfo.regionName);\n        return true;\n        \n      } finally {\n        synchronized(writestate) {\n          writestate.writesOngoing = false;\n          recentCommits = 0;\n          writestate.notifyAll();\n        }\n        lock.writeLock().unlock();\n      }\n    }\n  }","id":37157,"modified_method":"/**\n   * Compact all the stores.  This should be called periodically to make sure \n   * the stores are kept manageable.  \n   *\n   * This operation could block for a long time, so don't call it from a \n   * time-sensitive thread.\n   *\n   * If it returns TRUE, the compaction has completed.\n   * \n   * If it returns FALSE, the compaction was not carried out, because the \n   * HRegion is busy doing something else storage-intensive (like flushing the \n   * cache).  The caller should check back later.\n   */\n  public boolean compactStores() throws IOException {\n    boolean shouldCompact = false;\n    lock.obtainReadLock();\n    try {\n      synchronized(writestate) {\n        if((! writestate.writesOngoing)\n            && writestate.writesEnabled\n            && (! writestate.closed)\n            && recentCommits > MIN_COMMITS_FOR_COMPACTION) {\n\n          writestate.writesOngoing = true;\n          shouldCompact = true;\n        }\n      }\n    } finally {\n      lock.releaseReadLock();\n    }\n\n    if(! shouldCompact) {\n      LOG.info(\"not compacting region \" + this.regionInfo.regionName);\n      return false; \n    }\n    lock.obtainWriteLock();\n    try {\n      LOG.info(\"starting compaction on region \" + this.regionInfo.regionName);\n      for (Iterator<HStore> it = stores.values().iterator(); it.hasNext();) {\n        HStore store = it.next();\n        store.compact();\n      }\n      LOG.info(\"compaction completed on region \" + this.regionInfo.regionName);\n      return true;\n\n    } finally {\n      synchronized (writestate) {\n        writestate.writesOngoing = false;\n        recentCommits = 0;\n        writestate.notifyAll();\n      }\n      lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Return all the available columns for the given key.  The key indicates a \n   * row and timestamp, but not a column name.\n   *\n   * The returned object should map column names to byte arrays (byte[]).\n   */\n  public void getFull(HStoreKey key, TreeMap<Text, BytesWritable> results) throws IOException {\n    this.lock.readLock().lock();\n    try {\n      MapFile.Reader[] maparray \n        = maps.values().toArray(new MapFile.Reader[maps.size()]);\n      \n      for(int i = maparray.length-1; i >= 0; i--) {\n        MapFile.Reader map = maparray[i];\n\n        synchronized(map) {\n          BytesWritable readval = new BytesWritable();\n          map.reset();\n          HStoreKey readkey = (HStoreKey)map.getClosest(key, readval);\n          \n          do {\n            Text readcol = readkey.getColumn();\n            if(results.get(readcol) == null\n                && key.matchesWithoutColumn(readkey)) {\n              results.put(new Text(readcol), readval);\n              readval = new BytesWritable();\n              \n            } else if(key.getRow().compareTo(readkey.getRow()) > 0) {\n              break;\n            }\n            \n          } while(map.next(readkey, readval));\n        }\n      }\n      \n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37158,"modified_method":"/**\n   * Return all the available columns for the given key.  The key indicates a \n   * row and timestamp, but not a column name.\n   *\n   * The returned object should map column names to byte arrays (byte[]).\n   */\n  public void getFull(HStoreKey key, TreeMap<Text, BytesWritable> results) throws IOException {\n    this.lock.obtainReadLock();\n    try {\n      MapFile.Reader[] maparray \n        = maps.values().toArray(new MapFile.Reader[maps.size()]);\n      \n      for(int i = maparray.length-1; i >= 0; i--) {\n        MapFile.Reader map = maparray[i];\n\n        synchronized(map) {\n          BytesWritable readval = new BytesWritable();\n          map.reset();\n          HStoreKey readkey = (HStoreKey)map.getClosest(key, readval);\n          \n          do {\n            Text readcol = readkey.getColumn();\n            if(results.get(readcol) == null\n                && key.matchesWithoutColumn(readkey)) {\n              results.put(new Text(readcol), readval);\n              readval = new BytesWritable();\n              \n            } else if(key.getRow().compareTo(readkey.getRow()) > 0) {\n              break;\n            }\n            \n          } while(map.next(readkey, readval));\n        }\n      }\n      \n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"Vector<HStoreFile> flushCacheHelper(TreeMap<HStoreKey, BytesWritable> inputCache,\n      long logCacheFlushId, boolean addToAvailableMaps) throws IOException {\n    \n    synchronized(flushLock) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"flushing HStore \" + this.regionName + \"/\" + this.colFamily);\n      }\n      \n      // A. Write the TreeMap out to the disk\n\n      HStoreFile flushedFile \n        = HStoreFile.obtainNewHStoreFile(conf, dir, regionName, colFamily, fs);\n      \n      Path mapfile = flushedFile.getMapFilePath();\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"map file is: \" + mapfile.toString());\n      }\n      \n      MapFile.Writer out = new MapFile.Writer(conf, fs, mapfile.toString(), \n          HStoreKey.class, BytesWritable.class);\n      \n      try {\n        for (Map.Entry<HStoreKey, BytesWritable> es: inputCache.entrySet()) {\n          HStoreKey curkey = es.getKey();\n          if (this.colFamily.equals(HStoreKey.extractFamily(curkey.getColumn()))) {\n            out.append(curkey, es.getValue());\n          }\n        }\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"HStore \" + this.regionName + \"/\" + this.colFamily + \" flushed\");\n        }\n        \n      } finally {\n        out.close();\n      }\n\n      // B. Write out the log sequence number that corresponds to this output\n      // MapFile.  The MapFile is current up to and including the log seq num.\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"writing log cache flush id\");\n      }\n      flushedFile.writeInfo(fs, logCacheFlushId);\n\n      // C. Finally, make the new MapFile available.\n\n      if(addToAvailableMaps) {\n        this.lock.writeLock().lock();\n        \n        try {\n          maps.put(logCacheFlushId, new MapFile.Reader(fs, mapfile.toString(), conf));\n          mapFiles.put(logCacheFlushId, flushedFile);\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"HStore available for \" + this.regionName + \"/\"\n                + this.colFamily + \" flush id=\" + logCacheFlushId);\n          }\n        \n        } finally {\n          this.lock.writeLock().unlock();\n        }\n      }\n      return getAllMapFiles();\n    }\n  }","id":37159,"modified_method":"Vector<HStoreFile> flushCacheHelper(TreeMap<HStoreKey, BytesWritable> inputCache,\n      long logCacheFlushId, boolean addToAvailableMaps) throws IOException {\n    \n    synchronized(flushLock) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"flushing HStore \" + this.regionName + \"/\" + this.colFamily);\n      }\n      \n      // A. Write the TreeMap out to the disk\n\n      HStoreFile flushedFile \n        = HStoreFile.obtainNewHStoreFile(conf, dir, regionName, colFamily, fs);\n      \n      Path mapfile = flushedFile.getMapFilePath();\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"map file is: \" + mapfile.toString());\n      }\n      \n      MapFile.Writer out = new MapFile.Writer(conf, fs, mapfile.toString(), \n          HStoreKey.class, BytesWritable.class);\n      \n      try {\n        for (Map.Entry<HStoreKey, BytesWritable> es: inputCache.entrySet()) {\n          HStoreKey curkey = es.getKey();\n          if (this.colFamily.equals(HStoreKey.extractFamily(curkey.getColumn()))) {\n            out.append(curkey, es.getValue());\n          }\n        }\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"HStore \" + this.regionName + \"/\" + this.colFamily + \" flushed\");\n        }\n        \n      } finally {\n        out.close();\n      }\n\n      // B. Write out the log sequence number that corresponds to this output\n      // MapFile.  The MapFile is current up to and including the log seq num.\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"writing log cache flush id\");\n      }\n      flushedFile.writeInfo(fs, logCacheFlushId);\n\n      // C. Finally, make the new MapFile available.\n\n      if(addToAvailableMaps) {\n        this.lock.obtainWriteLock();\n        \n        try {\n          maps.put(logCacheFlushId, new MapFile.Reader(fs, mapfile.toString(), conf));\n          mapFiles.put(logCacheFlushId, flushedFile);\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"HStore available for \" + this.regionName + \"/\"\n                + this.colFamily + \" flush id=\" + logCacheFlushId);\n          }\n        \n        } finally {\n          this.lock.releaseWriteLock();\n        }\n      }\n      return getAllMapFiles();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * @return    Returns the number of map files currently in use\n   */\n  public int getNMaps() {\n    this.lock.readLock().lock();\n    try {\n      return maps.size();\n      \n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37160,"modified_method":"/**\n   * @return    Returns the number of map files currently in use\n   */\n  public int getNMaps() {\n    this.lock.obtainReadLock();\n    try {\n      return maps.size();\n      \n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Get the value for the indicated HStoreKey.  Grab the target value and the \n   * previous 'numVersions-1' values, as well.\n   *\n   * If 'numVersions' is negative, the method returns all available versions.\n   */\n  public BytesWritable[] get(HStoreKey key, int numVersions) throws IOException {\n    if(numVersions <= 0) {\n      throw new IllegalArgumentException(\"Number of versions must be > 0\");\n    }\n    \n    Vector<BytesWritable> results = new Vector<BytesWritable>();\n    this.lock.readLock().lock();\n    try {\n      MapFile.Reader[] maparray \n        = maps.values().toArray(new MapFile.Reader[maps.size()]);\n      \n      for(int i = maparray.length-1; i >= 0; i--) {\n        MapFile.Reader map = maparray[i];\n\n        synchronized(map) {\n          BytesWritable readval = new BytesWritable();\n          map.reset();\n          HStoreKey readkey = (HStoreKey)map.getClosest(key, readval);\n          \n          if(readkey.matchesRowCol(key)) {\n            results.add(readval);\n            readval = new BytesWritable();\n\n            while(map.next(readkey, readval) && readkey.matchesRowCol(key)) {\n              if(numVersions > 0 && (results.size() >= numVersions)) {\n                break;\n                \n              } else {\n                results.add(readval);\n                readval = new BytesWritable();\n              }\n            }\n          }\n        }\n        if(results.size() >= numVersions) {\n          break;\n        }\n      }\n\n      if(results.size() == 0) {\n        return null;\n        \n      } else {\n        return results.toArray(new BytesWritable[results.size()]);\n      }\n      \n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37161,"modified_method":"/**\n   * Get the value for the indicated HStoreKey.  Grab the target value and the \n   * previous 'numVersions-1' values, as well.\n   *\n   * If 'numVersions' is negative, the method returns all available versions.\n   */\n  public BytesWritable[] get(HStoreKey key, int numVersions) throws IOException {\n    if(numVersions <= 0) {\n      throw new IllegalArgumentException(\"Number of versions must be > 0\");\n    }\n    \n    Vector<BytesWritable> results = new Vector<BytesWritable>();\n    this.lock.obtainReadLock();\n    try {\n      MapFile.Reader[] maparray \n        = maps.values().toArray(new MapFile.Reader[maps.size()]);\n      \n      for(int i = maparray.length-1; i >= 0; i--) {\n        MapFile.Reader map = maparray[i];\n\n        synchronized(map) {\n          BytesWritable readval = new BytesWritable();\n          map.reset();\n          HStoreKey readkey = (HStoreKey)map.getClosest(key, readval);\n          \n          if(readkey.matchesRowCol(key)) {\n            results.add(readval);\n            readval = new BytesWritable();\n\n            while(map.next(readkey, readval) && readkey.matchesRowCol(key)) {\n              if(numVersions > 0 && (results.size() >= numVersions)) {\n                break;\n                \n              } else {\n                results.add(readval);\n                readval = new BytesWritable();\n              }\n            }\n          }\n        }\n        if(results.size() >= numVersions) {\n          break;\n        }\n      }\n\n      if(results.size() == 0) {\n        return null;\n        \n      } else {\n        return results.toArray(new BytesWritable[results.size()]);\n      }\n      \n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Gets the size of the largest MapFile and its mid key.\n   * \n   * @param midKey      - the middle key for the largest MapFile\n   * @return            - size of the largest MapFile\n   */\n  public long getLargestFileSize(Text midKey) {\n    long maxSize = 0L;\n    if (this.mapFiles.size() <= 0) {\n      return maxSize;\n    }\n    \n    this.lock.readLock().lock();\n    try {\n      long mapIndex = 0L;\n\n      // Iterate through all the MapFiles\n\n      for(Iterator<Map.Entry<Long, HStoreFile>> it = mapFiles.entrySet().iterator();\n          it.hasNext(); ) {\n\n        Map.Entry<Long, HStoreFile> e = it.next();\n        HStoreFile curHSF = e.getValue();\n        long size = fs.getLength(new Path(curHSF.getMapFilePath(), MapFile.DATA_FILE_NAME));\n\n        if(size > maxSize) {              // This is the largest one so far\n          maxSize = size;\n          mapIndex = e.getKey();\n        }\n      }\n\n      MapFile.Reader r = maps.get(mapIndex);\n\n      midKey.set(((HStoreKey)r.midKey()).getRow());\n\n    } catch(IOException e) {\n      LOG.warn(e);\n\n    } finally {\n      this.lock.readLock().unlock();\n    }\n    return maxSize;\n  }","id":37162,"modified_method":"/**\n   * Gets the size of the largest MapFile and its mid key.\n   * \n   * @param midKey      - the middle key for the largest MapFile\n   * @return            - size of the largest MapFile\n   */\n  public long getLargestFileSize(Text midKey) {\n    long maxSize = 0L;\n    if (this.mapFiles.size() <= 0) {\n      return maxSize;\n    }\n    \n    this.lock.obtainReadLock();\n    try {\n      long mapIndex = 0L;\n\n      // Iterate through all the MapFiles\n\n      for(Iterator<Map.Entry<Long, HStoreFile>> it = mapFiles.entrySet().iterator();\n          it.hasNext(); ) {\n\n        Map.Entry<Long, HStoreFile> e = it.next();\n        HStoreFile curHSF = e.getValue();\n        long size = fs.getLength(new Path(curHSF.getMapFilePath(), MapFile.DATA_FILE_NAME));\n\n        if(size > maxSize) {              // This is the largest one so far\n          maxSize = size;\n          mapIndex = e.getKey();\n        }\n      }\n\n      MapFile.Reader r = maps.get(mapIndex);\n\n      midKey.set(((HStoreKey)r.midKey()).getRow());\n\n    } catch(IOException e) {\n      LOG.warn(e);\n\n    } finally {\n      this.lock.releaseReadLock();\n    }\n    return maxSize;\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/** Shut it down! */\n    public void close() {\n      if(! scannerClosed) {\n        try {\n          for(int i = 0; i < readers.length; i++) {\n            if(readers[i] != null) {\n              try {\n                readers[i].close();\n                \n              } catch(IOException e) {\n                LOG.error(e);\n              }\n            }\n          }\n          \n        } finally {\n          lock.readLock().unlock();\n          scannerClosed = true;\n        }\n      }\n    }","id":37163,"modified_method":"/** Shut it down! */\n    public void close() {\n      if(! scannerClosed) {\n        try {\n          for(int i = 0; i < readers.length; i++) {\n            if(readers[i] != null) {\n              try {\n                readers[i].close();\n                \n              } catch(IOException e) {\n                LOG.error(e);\n              }\n            }\n          }\n          \n        } finally {\n          lock.releaseReadLock();\n          scannerClosed = true;\n        }\n      }\n    }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * It's assumed that the compactLock  will be acquired prior to calling this \n   * method!  Otherwise, it is not thread-safe!\n   *\n   * It works by processing a compaction that's been written to disk.\n   * \n   * It is usually invoked at the end of a compaction, but might also be invoked\n   * at HStore startup, if the prior execution died midway through.\n   */\n  void processReadyCompaction() throws IOException {\n\n    // Move the compacted TreeMap into place.\n    // That means:\n    // 1) Acquiring the write-lock\n    // 2) Figuring out what MapFiles are going to be replaced\n    // 3) Unloading all the replaced MapFiles.\n    // 4) Deleting all the old MapFile files.\n    // 5) Moving the new MapFile into place\n    // 6) Loading the new TreeMap.\n    // 7) Releasing the write-lock\n\n    // 1. Acquiring the write-lock\n\n\n    Path curCompactStore = HStoreFile.getHStoreDir(compactdir, regionName, colFamily);\n    this.lock.writeLock().lock();\n    try {\n      Path doneFile = new Path(curCompactStore, COMPACTION_DONE);\n      if(! fs.exists(doneFile)) {\n        \n        // The last execution didn't finish the compaction, so there's nothing \n        // we can do.  We'll just have to redo it. Abandon it and return.\n        \n        return;\n      }\n\n      // OK, there's actually compaction work that needs to be put into place.\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"compaction starting\");\n      }\n      \n      // 2. Load in the files to be deleted.\n      //    (Figuring out what MapFiles are going to be replaced)\n      \n      Vector<HStoreFile> toCompactFiles = new Vector<HStoreFile>();\n      Path filesToReplace = new Path(curCompactStore, COMPACTION_TO_REPLACE);\n      DataInputStream in = new DataInputStream(fs.open(filesToReplace));\n      try {\n        int numfiles = in.readInt();\n        for(int i = 0; i < numfiles; i++) {\n          HStoreFile hsf = new HStoreFile(conf);\n          hsf.readFields(in);\n          toCompactFiles.add(hsf);\n        }\n        \n      } finally {\n        in.close();\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"loaded files to be deleted\");\n      }\n      \n      // 3. Unload all the replaced MapFiles.\n      \n      Iterator<HStoreFile> it2 = mapFiles.values().iterator();\n      for(Iterator<MapFile.Reader> it = maps.values().iterator(); it.hasNext(); ) {\n        MapFile.Reader curReader = it.next();\n        HStoreFile curMapFile = it2.next();\n        if(toCompactFiles.contains(curMapFile)) {\n          curReader.close();\n          it.remove();\n        }\n      }\n      \n      for(Iterator<HStoreFile> it = mapFiles.values().iterator(); it.hasNext(); ) {\n        HStoreFile curMapFile = it.next();\n        if(toCompactFiles.contains(curMapFile)) {\n          it.remove();\n        }\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"unloaded existing MapFiles\");\n      }\n      \n      // What if we crash at this point?  No big deal; we will restart\n      // processReadyCompaction(), and nothing has been lost.\n\n      // 4. Delete all the old files, no longer needed\n      \n      for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n        HStoreFile hsf = it.next();\n        fs.delete(hsf.getMapFilePath());\n        fs.delete(hsf.getInfoFilePath());\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"old files deleted\");\n      }\n      \n      // What if we fail now?  The above deletes will fail silently. We'd better\n      // make sure not to write out any new files with the same names as \n      // something we delete, though.\n\n      // 5. Moving the new MapFile into place\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"moving new MapFile into place\");\n      }\n      \n      HStoreFile compactedFile \n        = new HStoreFile(conf, compactdir, regionName, colFamily, -1);\n      \n      HStoreFile finalCompactedFile \n        = HStoreFile.obtainNewHStoreFile(conf, dir, regionName, colFamily, fs);\n      \n      fs.rename(compactedFile.getMapFilePath(), finalCompactedFile.getMapFilePath());\n      \n      // Fail here?  No problem.\n      \n      fs.rename(compactedFile.getInfoFilePath(), finalCompactedFile.getInfoFilePath());\n\n      // Fail here?  No worries.\n      \n      long orderVal = finalCompactedFile.loadInfo(fs);\n\n      // 6. Loading the new TreeMap.\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"loading new TreeMap\");\n      }\n      \n      mapFiles.put(orderVal, finalCompactedFile);\n      maps.put(orderVal, new MapFile.Reader(fs, \n          finalCompactedFile.getMapFilePath().toString(), conf));\n      \n    } finally {\n      \n      // 7. Releasing the write-lock\n      \n      this.lock.writeLock().unlock();\n    }\n  }","id":37164,"modified_method":"/**\n   * It's assumed that the compactLock  will be acquired prior to calling this \n   * method!  Otherwise, it is not thread-safe!\n   *\n   * It works by processing a compaction that's been written to disk.\n   * \n   * It is usually invoked at the end of a compaction, but might also be invoked\n   * at HStore startup, if the prior execution died midway through.\n   */\n  void processReadyCompaction() throws IOException {\n\n    // Move the compacted TreeMap into place.\n    // That means:\n    // 1) Acquiring the write-lock\n    // 2) Figuring out what MapFiles are going to be replaced\n    // 3) Unloading all the replaced MapFiles.\n    // 4) Deleting all the old MapFile files.\n    // 5) Moving the new MapFile into place\n    // 6) Loading the new TreeMap.\n    // 7) Releasing the write-lock\n\n    // 1. Acquiring the write-lock\n\n\n    Path curCompactStore = HStoreFile.getHStoreDir(compactdir, regionName, colFamily);\n    this.lock.obtainWriteLock();\n    try {\n      Path doneFile = new Path(curCompactStore, COMPACTION_DONE);\n      if(! fs.exists(doneFile)) {\n        \n        // The last execution didn't finish the compaction, so there's nothing \n        // we can do.  We'll just have to redo it. Abandon it and return.\n        \n        return;\n      }\n\n      // OK, there's actually compaction work that needs to be put into place.\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"compaction starting\");\n      }\n      \n      // 2. Load in the files to be deleted.\n      //    (Figuring out what MapFiles are going to be replaced)\n      \n      Vector<HStoreFile> toCompactFiles = new Vector<HStoreFile>();\n      Path filesToReplace = new Path(curCompactStore, COMPACTION_TO_REPLACE);\n      DataInputStream in = new DataInputStream(fs.open(filesToReplace));\n      try {\n        int numfiles = in.readInt();\n        for(int i = 0; i < numfiles; i++) {\n          HStoreFile hsf = new HStoreFile(conf);\n          hsf.readFields(in);\n          toCompactFiles.add(hsf);\n        }\n        \n      } finally {\n        in.close();\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"loaded files to be deleted\");\n      }\n      \n      // 3. Unload all the replaced MapFiles.\n      \n      Iterator<HStoreFile> it2 = mapFiles.values().iterator();\n      for(Iterator<MapFile.Reader> it = maps.values().iterator(); it.hasNext(); ) {\n        MapFile.Reader curReader = it.next();\n        HStoreFile curMapFile = it2.next();\n        if(toCompactFiles.contains(curMapFile)) {\n          curReader.close();\n          it.remove();\n        }\n      }\n      \n      for(Iterator<HStoreFile> it = mapFiles.values().iterator(); it.hasNext(); ) {\n        HStoreFile curMapFile = it.next();\n        if(toCompactFiles.contains(curMapFile)) {\n          it.remove();\n        }\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"unloaded existing MapFiles\");\n      }\n      \n      // What if we crash at this point?  No big deal; we will restart\n      // processReadyCompaction(), and nothing has been lost.\n\n      // 4. Delete all the old files, no longer needed\n      \n      for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n        HStoreFile hsf = it.next();\n        fs.delete(hsf.getMapFilePath());\n        fs.delete(hsf.getInfoFilePath());\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"old files deleted\");\n      }\n      \n      // What if we fail now?  The above deletes will fail silently. We'd better\n      // make sure not to write out any new files with the same names as \n      // something we delete, though.\n\n      // 5. Moving the new MapFile into place\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"moving new MapFile into place\");\n      }\n      \n      HStoreFile compactedFile \n        = new HStoreFile(conf, compactdir, regionName, colFamily, -1);\n      \n      HStoreFile finalCompactedFile \n        = HStoreFile.obtainNewHStoreFile(conf, dir, regionName, colFamily, fs);\n      \n      fs.rename(compactedFile.getMapFilePath(), finalCompactedFile.getMapFilePath());\n      \n      // Fail here?  No problem.\n      \n      fs.rename(compactedFile.getInfoFilePath(), finalCompactedFile.getInfoFilePath());\n\n      // Fail here?  No worries.\n      \n      long orderVal = finalCompactedFile.loadInfo(fs);\n\n      // 6. Loading the new TreeMap.\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"loading new TreeMap\");\n      }\n      \n      mapFiles.put(orderVal, finalCompactedFile);\n      maps.put(orderVal, new MapFile.Reader(fs, \n          finalCompactedFile.getMapFilePath().toString(), conf));\n      \n    } finally {\n      \n      // 7. Releasing the write-lock\n      \n      this.lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"void compactHelper(boolean deleteSequenceInfo) throws IOException {\n    synchronized(compactLock) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"started compaction of \" + this.regionName + \"/\" + this.colFamily);\n      }\n      \n      Path curCompactStore = HStoreFile.getHStoreDir(compactdir, regionName, colFamily);\n      fs.mkdirs(curCompactStore);\n      \n      try {\n        \n        // Grab a list of files to compact.\n        \n        Vector<HStoreFile> toCompactFiles = null;\n        this.lock.writeLock().lock();\n        try {\n          toCompactFiles = new Vector<HStoreFile>(mapFiles.values());\n          \n        } finally {\n          this.lock.writeLock().unlock();\n        }\n\n        // Compute the max-sequenceID seen in any of the to-be-compacted TreeMaps\n\n        long maxSeenSeqID = -1;\n        for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n          HStoreFile hsf = it.next();\n          long seqid = hsf.loadInfo(fs);\n          if(seqid > 0) {\n            if(seqid > maxSeenSeqID) {\n              maxSeenSeqID = seqid;\n            }\n          }\n        }\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"max sequence id =\" + maxSeenSeqID);\n        }\n        \n        HStoreFile compactedOutputFile \n          = new HStoreFile(conf, compactdir, regionName, colFamily, -1);\n        \n        if(toCompactFiles.size() == 1) {\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"nothing to compact for \" + this.regionName + \"/\" + this.colFamily);\n          }\n          \n          HStoreFile hsf = toCompactFiles.elementAt(0);\n          if(hsf.loadInfo(fs) == -1) {\n            return;\n          }\n        }\n\n        // Step through them, writing to the brand-new TreeMap\n\n        MapFile.Writer compactedOut = new MapFile.Writer(conf, fs, \n            compactedOutputFile.getMapFilePath().toString(), HStoreKey.class, \n            BytesWritable.class);\n        \n        try {\n\n          // We create a new set of MapFile.Reader objects so we don't screw up \n          // the caching associated with the currently-loaded ones.\n          //\n          // Our iteration-based access pattern is practically designed to ruin \n          // the cache.\n          //\n          // We work by opening a single MapFile.Reader for each file, and \n          // iterating through them in parallel.  We always increment the \n          // lowest-ranked one.  Updates to a single row/column will appear \n          // ranked by timestamp.  This allows us to throw out deleted values or\n          // obsolete versions.\n\n          MapFile.Reader[] readers = new MapFile.Reader[toCompactFiles.size()];\n          HStoreKey[] keys = new HStoreKey[toCompactFiles.size()];\n          BytesWritable[] vals = new BytesWritable[toCompactFiles.size()];\n          boolean[] done = new boolean[toCompactFiles.size()];\n          int pos = 0;\n          for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n            HStoreFile hsf = it.next();\n            readers[pos] = new MapFile.Reader(fs, hsf.getMapFilePath().toString(), conf);\n            keys[pos] = new HStoreKey();\n            vals[pos] = new BytesWritable();\n            done[pos] = false;\n            pos++;\n          }\n\n          // Now, advance through the readers in order.  This will have the\n          // effect of a run-time sort of the entire dataset.\n\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"processing HStoreFile readers\");\n          }\n          \n          int numDone = 0;\n          for(int i = 0; i < readers.length; i++) {\n            readers[i].reset();\n            done[i] = ! readers[i].next(keys[i], vals[i]);\n            if(done[i]) {\n              numDone++;\n            }\n          }\n          \n          int timesSeen = 0;\n          Text lastRow = new Text();\n          Text lastColumn = new Text();\n          while(numDone < done.length) {\n\n            // Find the reader with the smallest key\n\n            int smallestKey = -1;\n            for(int i = 0; i < readers.length; i++) {\n              if(done[i]) {\n                continue;\n              }\n              \n              if(smallestKey < 0) {\n                smallestKey = i;\n              \n              } else {\n                if(keys[i].compareTo(keys[smallestKey]) < 0) {\n                  smallestKey = i;\n                }\n              }\n            }\n\n            // Reflect the current key/val in the output\n\n            HStoreKey sk = keys[smallestKey];\n            if(lastRow.equals(sk.getRow())\n                && lastColumn.equals(sk.getColumn())) {\n              \n              timesSeen++;\n              \n            } else {\n              timesSeen = 1;\n            }\n            \n            if(timesSeen <= maxVersions) {\n\n              // Keep old versions until we have maxVersions worth.\n              // Then just skip them.\n\n              if(sk.getRow().getLength() != 0\n                  && sk.getColumn().getLength() != 0) {\n                \n                // Only write out objects which have a non-zero length key and value\n\n                compactedOut.append(sk, vals[smallestKey]);\n              }\n              \n            }\n\n            //TODO: I don't know what to do about deleted values.  I currently \n            // include the fact that the item was deleted as a legitimate \n            // \"version\" of the data.  Maybe it should just drop the deleted val?\n\n            // Update last-seen items\n\n            lastRow.set(sk.getRow());\n            lastColumn.set(sk.getColumn());\n\n            // Advance the smallest key.  If that reader's all finished, then \n            // mark it as done.\n\n            if(! readers[smallestKey].next(keys[smallestKey], vals[smallestKey])) {\n              done[smallestKey] = true;\n              readers[smallestKey].close();\n              numDone++;\n            }\n          }\n          \n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"all HStores processed\");\n          }\n          \n        } finally {\n          compactedOut.close();\n        }\n\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"writing new compacted HStore\");\n        }\n\n        // Now, write out an HSTORE_LOGINFOFILE for the brand-new TreeMap.\n\n        if((! deleteSequenceInfo) && maxSeenSeqID >= 0) {\n          compactedOutputFile.writeInfo(fs, maxSeenSeqID);\n          \n        } else {\n          compactedOutputFile.writeInfo(fs, -1);\n        }\n\n        // Write out a list of data files that we're replacing\n\n        Path filesToReplace = new Path(curCompactStore, COMPACTION_TO_REPLACE);\n        DataOutputStream out = new DataOutputStream(fs.create(filesToReplace));\n        try {\n          out.writeInt(toCompactFiles.size());\n          for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n            HStoreFile hsf = it.next();\n            hsf.write(out);\n          }\n          \n        } finally {\n          out.close();\n        }\n\n        // Indicate that we're done.\n\n        Path doneFile = new Path(curCompactStore, COMPACTION_DONE);\n        out = new DataOutputStream(fs.create(doneFile));\n        \n        try {\n        } finally {\n          out.close();\n        }\n\n        // Move the compaction into place.\n\n        processReadyCompaction();\n        \n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"compaction complete for \" + this.regionName + \"/\" + this.colFamily);\n        }\n\n      } finally {\n        fs.delete(compactdir);\n      }\n    }\n  }","id":37165,"modified_method":"void compactHelper(boolean deleteSequenceInfo) throws IOException {\n    synchronized(compactLock) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"started compaction of \" + this.regionName + \"/\" + this.colFamily);\n      }\n      \n      Path curCompactStore = HStoreFile.getHStoreDir(compactdir, regionName, colFamily);\n      fs.mkdirs(curCompactStore);\n      \n      try {\n        \n        // Grab a list of files to compact.\n        \n        Vector<HStoreFile> toCompactFiles = null;\n        this.lock.obtainWriteLock();\n        try {\n          toCompactFiles = new Vector<HStoreFile>(mapFiles.values());\n          \n        } finally {\n          this.lock.releaseWriteLock();\n        }\n\n        // Compute the max-sequenceID seen in any of the to-be-compacted TreeMaps\n\n        long maxSeenSeqID = -1;\n        for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n          HStoreFile hsf = it.next();\n          long seqid = hsf.loadInfo(fs);\n          if(seqid > 0) {\n            if(seqid > maxSeenSeqID) {\n              maxSeenSeqID = seqid;\n            }\n          }\n        }\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"max sequence id =\" + maxSeenSeqID);\n        }\n        \n        HStoreFile compactedOutputFile \n          = new HStoreFile(conf, compactdir, regionName, colFamily, -1);\n        \n        if(toCompactFiles.size() == 1) {\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"nothing to compact for \" + this.regionName + \"/\" + this.colFamily);\n          }\n          \n          HStoreFile hsf = toCompactFiles.elementAt(0);\n          if(hsf.loadInfo(fs) == -1) {\n            return;\n          }\n        }\n\n        // Step through them, writing to the brand-new TreeMap\n\n        MapFile.Writer compactedOut = new MapFile.Writer(conf, fs, \n            compactedOutputFile.getMapFilePath().toString(), HStoreKey.class, \n            BytesWritable.class);\n        \n        try {\n\n          // We create a new set of MapFile.Reader objects so we don't screw up \n          // the caching associated with the currently-loaded ones.\n          //\n          // Our iteration-based access pattern is practically designed to ruin \n          // the cache.\n          //\n          // We work by opening a single MapFile.Reader for each file, and \n          // iterating through them in parallel.  We always increment the \n          // lowest-ranked one.  Updates to a single row/column will appear \n          // ranked by timestamp.  This allows us to throw out deleted values or\n          // obsolete versions.\n\n          MapFile.Reader[] readers = new MapFile.Reader[toCompactFiles.size()];\n          HStoreKey[] keys = new HStoreKey[toCompactFiles.size()];\n          BytesWritable[] vals = new BytesWritable[toCompactFiles.size()];\n          boolean[] done = new boolean[toCompactFiles.size()];\n          int pos = 0;\n          for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n            HStoreFile hsf = it.next();\n            readers[pos] = new MapFile.Reader(fs, hsf.getMapFilePath().toString(), conf);\n            keys[pos] = new HStoreKey();\n            vals[pos] = new BytesWritable();\n            done[pos] = false;\n            pos++;\n          }\n\n          // Now, advance through the readers in order.  This will have the\n          // effect of a run-time sort of the entire dataset.\n\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"processing HStoreFile readers\");\n          }\n          \n          int numDone = 0;\n          for(int i = 0; i < readers.length; i++) {\n            readers[i].reset();\n            done[i] = ! readers[i].next(keys[i], vals[i]);\n            if(done[i]) {\n              numDone++;\n            }\n          }\n          \n          int timesSeen = 0;\n          Text lastRow = new Text();\n          Text lastColumn = new Text();\n          while(numDone < done.length) {\n\n            // Find the reader with the smallest key\n\n            int smallestKey = -1;\n            for(int i = 0; i < readers.length; i++) {\n              if(done[i]) {\n                continue;\n              }\n              \n              if(smallestKey < 0) {\n                smallestKey = i;\n              \n              } else {\n                if(keys[i].compareTo(keys[smallestKey]) < 0) {\n                  smallestKey = i;\n                }\n              }\n            }\n\n            // Reflect the current key/val in the output\n\n            HStoreKey sk = keys[smallestKey];\n            if(lastRow.equals(sk.getRow())\n                && lastColumn.equals(sk.getColumn())) {\n              \n              timesSeen++;\n              \n            } else {\n              timesSeen = 1;\n            }\n            \n            if(timesSeen <= maxVersions) {\n\n              // Keep old versions until we have maxVersions worth.\n              // Then just skip them.\n\n              if(sk.getRow().getLength() != 0\n                  && sk.getColumn().getLength() != 0) {\n                \n                // Only write out objects which have a non-zero length key and value\n\n                compactedOut.append(sk, vals[smallestKey]);\n              }\n              \n            }\n\n            //TODO: I don't know what to do about deleted values.  I currently \n            // include the fact that the item was deleted as a legitimate \n            // \"version\" of the data.  Maybe it should just drop the deleted val?\n\n            // Update last-seen items\n\n            lastRow.set(sk.getRow());\n            lastColumn.set(sk.getColumn());\n\n            // Advance the smallest key.  If that reader's all finished, then \n            // mark it as done.\n\n            if(! readers[smallestKey].next(keys[smallestKey], vals[smallestKey])) {\n              done[smallestKey] = true;\n              readers[smallestKey].close();\n              numDone++;\n            }\n          }\n          \n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"all HStores processed\");\n          }\n          \n        } finally {\n          compactedOut.close();\n        }\n\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"writing new compacted HStore\");\n        }\n\n        // Now, write out an HSTORE_LOGINFOFILE for the brand-new TreeMap.\n\n        if((! deleteSequenceInfo) && maxSeenSeqID >= 0) {\n          compactedOutputFile.writeInfo(fs, maxSeenSeqID);\n          \n        } else {\n          compactedOutputFile.writeInfo(fs, -1);\n        }\n\n        // Write out a list of data files that we're replacing\n\n        Path filesToReplace = new Path(curCompactStore, COMPACTION_TO_REPLACE);\n        DataOutputStream out = new DataOutputStream(fs.create(filesToReplace));\n        try {\n          out.writeInt(toCompactFiles.size());\n          for(Iterator<HStoreFile> it = toCompactFiles.iterator(); it.hasNext(); ) {\n            HStoreFile hsf = it.next();\n            hsf.write(out);\n          }\n          \n        } finally {\n          out.close();\n        }\n\n        // Indicate that we're done.\n\n        Path doneFile = new Path(curCompactStore, COMPACTION_DONE);\n        out = new DataOutputStream(fs.create(doneFile));\n        \n        try {\n        } finally {\n          out.close();\n        }\n\n        // Move the compaction into place.\n\n        processReadyCompaction();\n        \n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"compaction complete for \" + this.regionName + \"/\" + this.colFamily);\n        }\n\n      } finally {\n        fs.delete(compactdir);\n      }\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"public HStoreScanner(long timestamp, Text[] targetCols, Text firstRow)\n        throws IOException {\n      \n      super(timestamp, targetCols);\n\n      lock.readLock().lock();\n      try {\n        this.readers = new MapFile.Reader[mapFiles.size()];\n        \n        // Most recent map file should be first\n        \n        int i = readers.length - 1;\n        for(Iterator<HStoreFile> it = mapFiles.values().iterator(); it.hasNext(); ) {\n          HStoreFile curHSF = it.next();\n          readers[i--] = new MapFile.Reader(fs, curHSF.getMapFilePath().toString(), conf);\n        }\n        \n        this.keys = new HStoreKey[readers.length];\n        this.vals = new BytesWritable[readers.length];\n\n        // Advance the readers to the first pos.\n\n        for(i = 0; i < readers.length; i++) {\n          keys[i] = new HStoreKey();\n          vals[i] = new BytesWritable();\n\n          if(firstRow.getLength() != 0) {\n            if(findFirstRow(i, firstRow)) {\n              continue;\n            }\n          }\n          \n          while(getNext(i)) {\n            if(columnMatch(i)) {\n              break;\n            }\n          }\n        }\n        \n      } catch (Exception ex) {\n        LOG.error(ex);\n        close();\n      }\n    }","id":37166,"modified_method":"public HStoreScanner(long timestamp, Text[] targetCols, Text firstRow)\n        throws IOException {\n      \n      super(timestamp, targetCols);\n\n      lock.obtainReadLock();\n      try {\n        this.readers = new MapFile.Reader[mapFiles.size()];\n        \n        // Most recent map file should be first\n        \n        int i = readers.length - 1;\n        for(Iterator<HStoreFile> it = mapFiles.values().iterator(); it.hasNext(); ) {\n          HStoreFile curHSF = it.next();\n          readers[i--] = new MapFile.Reader(fs, curHSF.getMapFilePath().toString(), conf);\n        }\n        \n        this.keys = new HStoreKey[readers.length];\n        this.vals = new BytesWritable[readers.length];\n\n        // Advance the readers to the first pos.\n\n        for(i = 0; i < readers.length; i++) {\n          keys[i] = new HStoreKey();\n          vals[i] = new BytesWritable();\n\n          if(firstRow.getLength() != 0) {\n            if(findFirstRow(i, firstRow)) {\n              continue;\n            }\n          }\n          \n          while(getNext(i)) {\n            if(columnMatch(i)) {\n              break;\n            }\n          }\n        }\n        \n      } catch (Exception ex) {\n        LOG.error(ex);\n        close();\n      }\n    }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"public Vector<HStoreFile> getAllMapFiles() {\n    this.lock.readLock().lock();\n    try {\n      return new Vector<HStoreFile>(mapFiles.values());\n      \n    } finally {\n      this.lock.readLock().unlock();\n    }\n  }","id":37167,"modified_method":"public Vector<HStoreFile> getAllMapFiles() {\n    this.lock.obtainReadLock();\n    try {\n      return new Vector<HStoreFile>(mapFiles.values());\n      \n    } finally {\n      this.lock.releaseReadLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"/** Turn off all the MapFile readers */\n  public void close() throws IOException {\n    LOG.info(\"closing HStore for \" + this.regionName + \"/\" + this.colFamily);\n    this.lock.writeLock().lock();\n    try {\n      for (MapFile.Reader map: maps.values()) {\n        map.close();\n      }\n      maps.clear();\n      mapFiles.clear();\n      \n      LOG.info(\"HStore closed for \" + this.regionName + \"/\" + this.colFamily);\n    } finally {\n      this.lock.writeLock().unlock();\n    }\n  }","id":37168,"modified_method":"/** Turn off all the MapFile readers */\n  public void close() throws IOException {\n    LOG.info(\"closing HStore for \" + this.regionName + \"/\" + this.colFamily);\n    this.lock.obtainWriteLock();\n    try {\n      for (MapFile.Reader map: maps.values()) {\n        map.close();\n      }\n      maps.clear();\n      mapFiles.clear();\n      \n      LOG.info(\"HStore closed for \" + this.regionName + \"/\" + this.colFamily);\n    } finally {\n      this.lock.releaseWriteLock();\n    }\n  }","commit_id":"23f836454d9c5a495111b068f45d6aa89a2a724a","url":"https://github.com/apache/hbase"},{"original_method":"private static boolean isCheckForNull(PsiElement parent, PsiElement element) {\n    if (!(parent instanceof GrBinaryExpression)) return false;\n\n    final IElementType tokenType = ((GrBinaryExpression)parent).getOperationTokenType();\n    if (!(tokenType == GroovyTokenTypes.mEQUAL || tokenType == GroovyTokenTypes.mNOT_EQUAL)) return false;\n    if (element == ((GrBinaryExpression)parent).getLeftOperand()) {\n      return GrInspectionUtil.isNull(((GrBinaryExpression)parent).getRightOperand());\n    }\n    else {\n      return GrInspectionUtil.isNull(((GrBinaryExpression)parent).getLeftOperand());\n    }\n  }","id":37169,"modified_method":"private static boolean isCheckForNull(PsiElement parent, PsiElement element) {\n    if (!(parent instanceof GrBinaryExpression)) return false;\n\n    final IElementType tokenType = ((GrBinaryExpression)parent).getOperationTokenType();\n    if (!(tokenType == GroovyTokenTypes.mEQUAL || tokenType == GroovyTokenTypes.mNOT_EQUAL)) return false;\n    if (element == ((GrBinaryExpression)parent).getLeftOperand()) {\n      final GrExpression rightOperand = ((GrBinaryExpression)parent).getRightOperand();\n      return rightOperand != null && GrInspectionUtil.isNull(rightOperand);\n    }\n    else {\n      return GrInspectionUtil.isNull(((GrBinaryExpression)parent).getLeftOperand());\n    }\n  }","commit_id":"3a0697ae4095ac2492c6e890b5d68db67e2f6109","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\tBasicEList<XExpression> result = new BasicEList<XExpression>(2);\n\t\tresult.add(getAssignable());\n\t\tresult.add(getValue());\n\t\treturn result;\n\t}","id":37170,"modified_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\treturn asArguments(getAssignable(), getValue());\n\t}","commit_id":"17354bdf64d0589aad66bc871bec5cc58a04d5fe","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\tBasicEList<XExpression> result = new BasicEList<XExpression>(2);\n\t\tresult.add(getLeftOperand());\n\t\tresult.add(getRightOperand());\n\t\treturn result;\n\t}","id":37171,"modified_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\treturn asArguments(getLeftOperand(), getRightOperand());\n\t}","commit_id":"17354bdf64d0589aad66bc871bec5cc58a04d5fe","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\tBasicEList<XExpression> result = new BasicEList<XExpression>(getMemberCallArguments().size()+1);\n\t\tresult.add(getMemberCallTarget());\n\t\tresult.addAll(getMemberCallArguments());\n\t\treturn result;\n\t}","id":37172,"modified_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\tEList<XExpression> args = asArguments(getMemberCallTarget());\n\t\targs.addAll(getMemberCallArguments());\n\t\treturn args;\n\t}","commit_id":"17354bdf64d0589aad66bc871bec5cc58a04d5fe","url":"https://github.com/eclipse/xtext"},{"original_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\tBasicEList<XExpression> result = new BasicEList<XExpression>(1);\n\t\tresult.add(getOperand());\n\t\treturn result;\n\t}","id":37173,"modified_method":"@Override\n\tpublic EList<XExpression> getArguments() {\n\t\treturn asArguments(getOperand());\n\t}","commit_id":"17354bdf64d0589aad66bc871bec5cc58a04d5fe","url":"https://github.com/eclipse/xtext"},{"original_method":"protected boolean isFeatureCallScope(EReference reference) {\n\t\treturn reference == XbasePackage.Literals.XABSTRACT_FEATURE_CALL__FEATURE;\n\t}","id":37174,"modified_method":"protected boolean isFeatureCallScope(EReference reference) {\n\t\treturn reference == XbasePackage.Literals.XABSTRACT_FEATURE_CALL__FEATURE || reference == XbasePackage.Literals.XCONSTRUCTOR_CALL__CONSTRUCTOR;\n\t}","commit_id":"17354bdf64d0589aad66bc871bec5cc58a04d5fe","url":"https://github.com/eclipse/xtext"},{"original_method":"/**\n     * Updates the recalibration data for the base at offset in the read, associated with readGroup rg.\n     * Correctly handles machine orientation of the read.  I.e., it adds data not by offset in the read\n     * but by implied machine cycle associated with the offset.\n     *\n     * TODO: this whole system is 0-based and therefore inconsisent with the rest of the GATK, where pos is 1-based\n     * TODO: and offset is 0-based.  How very annoying.\n     *\n     * @param rg\n     * @param read\n     * @param offset\n     * @param ref\n     * @return\n     */\n    public int updateDataFromRead( String rg, SAMRecord read, int offset, char ref ) {\n        if ( offset == 0 )\n            throw new RuntimeException(\"Illegal read offset \" + offset + \" in read \" + read.getReadName());\n\n        int cycle = offset;\n        byte[] bases = read.getReadBases();\n        byte[] quals = read.getBaseQualities();\n\n        char base = (char)bases[offset];\n        char prevBase = (char)bases[offset - 1];\n\n        if (read.getReadNegativeStrandFlag()) {\n            ref = (char)BaseUtils.simpleComplement(ref);\n            base = (char)BaseUtils.simpleComplement(base);\n            prevBase = (char)BaseUtils.simpleComplement((char)bases[offset+1]);\n            cycle = read.getReadLength() - (offset + 1);\n        }\n\n        int qual = quals[offset];\n        if ( qual > 0 ) {\n            RecalData datum = getRecalData(rg, cycle, qual, prevBase, base);\n            if (datum != null) datum.inc(base,ref);\n            return 1;\n        } else {\n            return 0;\n        }\n    }","id":37175,"modified_method":"/**\n     * Updates the recalibration data for the base at offset in the read, associated with readGroup rg.\n     * Correctly handles machine orientation of the read.  I.e., it adds data not by offset in the read\n     * but by implied machine cycle associated with the offset.\n     *\n     * TODO: this whole system is 0-based and therefore inconsisent with the rest of the GATK, where pos is 1-based\n     * TODO: and offset is 0-based.  How very annoying.\n     *\n     * @param rg\n     * @param read\n     * @param offset\n     * @param ref\n     * @return\n     */\n    public int updateDataFromRead( String rg, SAMRecord read, int offset, char ref ) {\n        if ( offset == 0 )\n            throw new RuntimeException(\"Illegal read offset \" + offset + \" in read \" + read.getReadName());\n\n        int cycle = offset;\n        byte[] bases = read.getReadBases();\n        byte[] quals = read.getBaseQualities();\n\n        char base = (char)bases[offset];\n        char prevBase = (char)bases[offset - 1];\n\n        if (read.getReadNegativeStrandFlag()) {\n            ref = BaseUtils.simpleComplement(ref);\n            base = BaseUtils.simpleComplement(base);\n            prevBase = BaseUtils.simpleComplement((char)bases[offset+1]);\n            cycle = read.getReadLength() - (offset + 1);\n        }\n\n        int qual = quals[offset];\n        if ( qual > 0 ) {\n            RecalData datum = getRecalData(rg, cycle, qual, prevBase, base);\n            if (datum != null) datum.inc(base,ref);\n            return 1;\n        } else {\n            return 0;\n        }\n    }","commit_id":"7cf9a54b6485ea7319c3eddf098a3b7106c499ad","url":"https://github.com/broadgsa/gatk"},{"original_method":"@Override\n    public void fileMoved(@NotNull VirtualFileMoveEvent event) {\n      final VirtualFile oldParent = event.getOldParent();\n      final VirtualFile newParent = event.getNewParent();\n      final String dirName = event.getFileName();\n      final String ancestorPath = oldParent.getPath() + \"/\" + dirName;\n      final String moduleFilePath = getModuleFilePath();\n      if (VfsUtilCore.isAncestor(new File(ancestorPath), new File(moduleFilePath), true)) {\n        final String relativePath = FileUtil.getRelativePath(ancestorPath, moduleFilePath, '/');\n        setModuleFilePath(moduleFilePath, newParent.getPath() + \"/\" + dirName + \"/\" + relativePath);\n      }\n    }","id":37176,"modified_method":"@Override\n    public void fileMoved(@NotNull VirtualFileMoveEvent event) {\n      String dirName = event.getFileName();\n      String ancestorPath = event.getOldParent().getPath() + \"/\" + dirName;\n      String moduleFilePath = getModuleFilePath();\n      if (VfsUtilCore.isAncestor(new File(ancestorPath), new File(moduleFilePath), true)) {\n        setModuleFilePath(moduleFilePath, event.getNewParent().getPath() + \"/\" + dirName + \"/\" + FileUtil.getRelativePath(ancestorPath, moduleFilePath, '/'));\n      }\n    }","commit_id":"442a2acb1726f1e463e706a4e7e2e7f49ea2b62a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    public void propertyChanged(@NotNull VirtualFilePropertyEvent event) {\n      if (!isModuleAdded) return;\n      final Object requestor = event.getRequestor();\n      if (MODULE_RENAMING_REQUESTOR.equals(requestor)) return;\n      if (!VirtualFile.PROP_NAME.equals(event.getPropertyName())) return;\n\n      final VirtualFile parent = event.getParent();\n      if (parent != null) {\n        final String parentPath = parent.getPath();\n        final String ancestorPath = parentPath + \"/\" + event.getOldValue();\n        final String moduleFilePath = getModuleFilePath();\n        if (VfsUtilCore.isAncestor(new File(ancestorPath), new File(moduleFilePath), true)) {\n          final String newValue = (String)event.getNewValue();\n          final String relativePath = FileUtil.getRelativePath(ancestorPath, moduleFilePath, '/');\n          final String newFilePath = parentPath + \"/\" + newValue + \"/\" + relativePath;\n          setModuleFilePath(moduleFilePath, newFilePath);\n        }\n      }\n\n      final VirtualFile moduleFile = getModuleFile();\n      if (moduleFile == null) return;\n      if (moduleFile.equals(event.getFile())) {\n        String oldName = myName;\n        myName = moduleNameByFileName(moduleFile.getName());\n        ModuleManagerImpl.getInstanceImpl(getProject()).fireModuleRenamedByVfsEvent(ModuleImpl.this, oldName);\n      }\n    }","id":37177,"modified_method":"@Override\n    public void propertyChanged(@NotNull VirtualFilePropertyEvent event) {\n      if (!isModuleAdded || MODULE_RENAMING_REQUESTOR.equals(event.getRequestor()) || !VirtualFile.PROP_NAME.equals(event.getPropertyName())) {\n        return;\n      }\n\n      VirtualFile parent = event.getParent();\n      if (parent != null) {\n        String parentPath = parent.getPath();\n        String ancestorPath = parentPath + \"/\" + event.getOldValue();\n        String moduleFilePath = getModuleFilePath();\n        if (VfsUtilCore.isAncestor(new File(ancestorPath), new File(moduleFilePath), true)) {\n          setModuleFilePath(moduleFilePath, parentPath + \"/\" + event.getNewValue() + \"/\" + FileUtil.getRelativePath(ancestorPath, moduleFilePath, '/'));\n        }\n      }\n\n      VirtualFile moduleFile = getModuleFile();\n      if (moduleFile != null && moduleFile.equals(event.getFile())) {\n        String oldName = myName;\n        myName = moduleNameByFileName(moduleFile.getName());\n        ModuleManagerImpl.getInstanceImpl(getProject()).fireModuleRenamedByVfsEvent(ModuleImpl.this, oldName);\n      }\n    }","commit_id":"442a2acb1726f1e463e706a4e7e2e7f49ea2b62a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n         * {@inheritDoc}\n         */\n        public void propertyChange(PropertyChangeEvent event)\n        {\n            if (OperationSetVideoTelephony.LOCAL_VIDEO_STREAMING\n                    .equals(event.getPropertyName()))\n            {\n                boolean oldValue = (Boolean) event.getOldValue();\n                boolean newValue = (Boolean) event.getNewValue();\n\n                // We ensure that when the local video property changes to\n                // false our related buttons would be disabled.\n                if (oldValue && !newValue)\n                {\n                    CallDialog callDialog = callRenderer.getCallDialog();\n\n                    callDialog.setVideoButtonSelected(false);\n                    callDialog.setDesktopSharingButtonSelected(false);\n                }\n\n                handleLocalVideoStreamingChange(this);\n            }\n        }","id":37178,"modified_method":"/**\n         * {@inheritDoc}\n         */\n        public void propertyChange(PropertyChangeEvent event)\n        {\n            if (OperationSetVideoTelephony.LOCAL_VIDEO_STREAMING\n                    .equals(event.getPropertyName()))\n            {\n                // We ensure that when the local video property changes to\n                // false our related buttons would be disabled.\n                if (event.getOldValue().equals(MediaDirection.SENDRECV)\n                    && event.getNewValue().equals(MediaDirection.RECVONLY))\n                {\n                    CallDialog callDialog = callRenderer.getCallDialog();\n\n                    callDialog.setVideoButtonSelected(false);\n                    callDialog.setDesktopSharingButtonSelected(false);\n                }\n\n                handleLocalVideoStreamingChange(this);\n            }\n        }","commit_id":"8d5d83c215416ca66bd7b00d65d5d0823c1ae15c","url":"https://github.com/jitsi/jitsi"},{"original_method":"public void processValueChange(ValueChangeEvent ae)\r\n\t{\r\n    if(((Boolean)ae.getNewValue()).booleanValue() == false && ae.getOldValue() == null)\r\n      return;\r\n    else if(((Boolean)ae.getNewValue()).booleanValue() == ((Boolean)ae.getOldValue()).booleanValue())\r\n      return;\r\n    \r\n  \tUIComponent sourceComp = (UIComponent)ae.getSource();\r\n  \tUIComponent hideDivComp = null;\r\n  \twhile(sourceComp.getParent() != null)\r\n  \t{\r\n  \t\thideDivComp = sourceComp.getParent();\r\n  \t\tif(hideDivComp.getRendererType().equalsIgnoreCase(\"HideDivision\"))\r\n  \t\t{\r\n  \t\t\tbreak;\r\n  \t\t}\r\n  \t\telse\r\n  \t\t{\r\n  \t\t\tsourceComp = sourceComp.getParent();\r\n  \t\t}\r\n  \t}\r\n  \tif(hideDivComp != null)\r\n  \t{\r\n  \t\tString hideDivId = hideDivComp.getId(); \r\n      ToolSession session = SessionManager.getCurrentToolSession();\r\n      session.setAttribute(\"sam_expande_hide_div_id\", hideDivId);\r\n  \t}\r\n  \t\r\n  \treturn;\r\n  }","id":37179,"modified_method":"public void processValueChange(ValueChangeEvent ae)\r\n\t{\r\n\t    \r\n\t    //fix bug SAK-4439\r\n            if(ae.getOldValue()==null && ae.getNewValue().equals(\"false\"))\r\n\t\treturn;\r\n\t    else if(ae.getOldValue().equals(ae.getNewValue()))\r\n\t\treturn;\r\n\r\n\t    //  if(((Boolean)ae.getNewValue()).booleanValue() == false && ae.getOldValue() == null)\r\n\t    //  return;\r\n\t    //else if(((Boolean)ae.getNewValue()).booleanValue() == ((Boolean)ae.getOldValue()).booleanValue())\r\n\t    //return;\r\n    \r\n  \tUIComponent sourceComp = (UIComponent)ae.getSource();\r\n  \tUIComponent hideDivComp = null;\r\n  \twhile(sourceComp.getParent() != null)\r\n  \t{\r\n  \t\thideDivComp = sourceComp.getParent();\r\n  \t\tif(hideDivComp.getRendererType().equalsIgnoreCase(\"HideDivision\"))\r\n  \t\t{\r\n  \t\t\tbreak;\r\n  \t\t}\r\n  \t\telse\r\n  \t\t{\r\n  \t\t\tsourceComp = sourceComp.getParent();\r\n  \t\t}\r\n  \t}\r\n  \tif(hideDivComp != null)\r\n  \t{\r\n  \t\tString hideDivId = hideDivComp.getId(); \r\n      ToolSession session = SessionManager.getCurrentToolSession();\r\n      session.setAttribute(\"sam_expande_hide_div_id\", hideDivId);\r\n  \t}\r\n  \t\r\n  \treturn;\r\n  }","commit_id":"2f7a2b48c6c758eeac08394ec83aabfb4b54a726","url":"https://github.com/sakaiproject/sakai"},{"original_method":"/**\n     * Creates and dispatches a <tt>CallEvent<\/tt> notifying registered\n     * listeners that an event with id <tt>eventID<\/tt> has occurred on\n     * <tt>sourceCall<\/tt>.\n     *\n     * @param eventID the ID of the event to dispatch\n     * @param sourceCall the call on which the event has occurred.\n     */\n    public void fireCallEvent(int eventID, Call sourceCall)\n    {\n        CallEvent cEvent = new CallEvent(sourceCall, eventID);\n\n        logger.debug(\"Dispatching a CallEvent to \" + callListeners.size()\n            + \" listeners. event is: \" + cEvent.toString());\n\n        Iterator listeners = null;\n        synchronized (callListeners)\n        {\n            listeners = new ArrayList(callListeners).iterator();\n        }\n\n        while (listeners.hasNext())\n        {\n            CallListener listener = (CallListener) listeners.next();\n\n            if (eventID == CallEvent.CALL_INITIATED)\n                listener.outgoingCallCreated(cEvent);\n            else if (eventID == CallEvent.CALL_RECEIVED)\n                listener.incomingCallReceived(cEvent);\n            else if (eventID == CallEvent.CALL_ENDED)\n                listener.callEnded(cEvent);\n        }\n    }","id":37180,"modified_method":"/**\n     * Creates and dispatches a <tt>CallEvent<\/tt> notifying registered\n     * listeners that an event with id <tt>eventID<\/tt> has occurred on\n     * <tt>sourceCall<\/tt>.\n     *\n     * @param eventID the ID of the event to dispatch\n     * @param sourceCall the call on which the event has occurred.\n     */\n    public void fireCallEvent(int eventID, Call sourceCall)\n    {\n        CallEvent cEvent = new CallEvent(sourceCall, eventID);\n        List<CallListener> listeners;\n\n        synchronized (callListeners)\n        {\n            listeners = new ArrayList<CallListener>(callListeners);\n        }\n\n        logger.debug(\"Dispatching a CallEvent to \" + listeners.size()\n            + \" listeners. event is: \" + cEvent);\n\n        for (Iterator<CallListener> listenerIter = listeners.iterator(); listenerIter.hasNext();)\n        {\n            CallListener listener = listenerIter.next();\n\n            switch (eventID)\n            {\n            case CallEvent.CALL_INITIATED:\n                listener.outgoingCallCreated(cEvent);\n                break;\n            case CallEvent.CALL_RECEIVED:\n                listener.incomingCallReceived(cEvent);\n                break;\n            case CallEvent.CALL_ENDED:\n                listener.callEnded(cEvent);\n                break;\n            }\n        }\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * If <tt>evt<\/tt> indicates that the call has been ended we remove it from\n     * the repository.\n     * @param evt the <tt>CallChangeEvent<\/tt> instance containing the source\n     * calls and its old and new state.\n     */\n    public void callStateChanged(CallChangeEvent evt)\n    {\n        if(evt.getEventType().equals(CallChangeEvent.CALL_STATE_CHANGE)\n           && ((CallState)evt.getNewValue()).equals(CallState.CALL_ENDED))\n        {\n            CallSipImpl sourceCall = (CallSipImpl)this.activeCalls\n                .remove(evt.getSourceCall().getCallID());\n\n            logger.trace(  \"Removing call \" + sourceCall + \" from the list of \"\n                         + \"active calls because it entered an ENDED state\");\n\n            this.parentOperationSet.fireCallEvent(\n                CallEvent.CALL_ENDED, sourceCall);\n        }\n    }","id":37181,"modified_method":"/**\n     * If <tt>evt<\/tt> indicates that the call has been ended we remove it from\n     * the repository.\n     * @param evt the <tt>CallChangeEvent<\/tt> instance containing the source\n     * calls and its old and new state.\n     */\n    public void callStateChanged(CallChangeEvent evt)\n    {\n        if(evt.getEventType().equals(CallChangeEvent.CALL_STATE_CHANGE)\n           && evt.getNewValue().equals(CallState.CALL_ENDED))\n        {\n            CallSipImpl sourceCall =\n                this.activeCalls.remove(evt.getSourceCall().getCallID());\n\n            logger.trace(\"Removing call \" + sourceCall + \" from the list of \"\n                         + \"active calls because it entered an ENDED state\");\n\n            this.parentOperationSet.fireCallEvent(\n                CallEvent.CALL_ENDED, sourceCall);\n        }\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Returns the call participant whose associated jain sip dialog matches\n     * <tt>dialog<\/tt>.\n     *\n     * @param dialog the jain sip dialog whose corresponding participant we're\n     * looking for.\n     * @return the call participant whose jain sip dialog is the same as the\n     * specified or null if no such call participant was found.\n     */\n    public CallParticipantSipImpl findCallParticipant(Dialog dialog)\n    {\n        Iterator<CallSipImpl> activeCalls = getActiveCalls();\n\n        if(dialog == null)\n        {\n            logger.debug(\"Cannot find a participant with a null dialog. \"\n                         +\"Returning null\");\n            return null;\n        }\n\n        if(logger.isTraceEnabled())\n        {\n            logger.trace(\"Looking for participant with dialog: \" + dialog\n                         + \" among \" + this.activeCalls.size() + \" calls\");\n        }\n\n        while(activeCalls.hasNext())\n        {\n            CallSipImpl call = activeCalls.next();\n            CallParticipantSipImpl callParticipant\n                = call.findCallParticipant(dialog);\n            if(callParticipant != null)\n            {\n                logger.trace(\"Returning participant \" + callParticipant);\n                return callParticipant;\n            }\n        }\n\n        return null;\n    }","id":37182,"modified_method":"/**\n     * Returns the call participant whose associated jain sip dialog matches\n     * <tt>dialog<\/tt>.\n     *\n     * @param dialog the jain sip dialog whose corresponding participant we're\n     * looking for.\n     * @return the call participant whose jain sip dialog is the same as the\n     * specified or null if no such call participant was found.\n     */\n    public CallParticipantSipImpl findCallParticipant(Dialog dialog)\n    {\n        if(dialog == null)\n        {\n            logger.debug(\"Cannot find a participant with a null dialog. \"\n                         +\"Returning null\");\n            return null;\n        }\n\n        if(logger.isTraceEnabled())\n        {\n            logger.trace(\"Looking for participant with dialog: \" + dialog\n                         + \" among \" + this.activeCalls.size() + \" calls\");\n        }\n\n        for (Iterator<CallSipImpl> activeCalls = getActiveCalls();\n                 activeCalls.hasNext();)\n        {\n            CallSipImpl call = activeCalls.next();\n            CallParticipantSipImpl callParticipant\n                = call.findCallParticipant(dialog);\n            if(callParticipant != null)\n            {\n                logger.trace(\"Returning participant \" + callParticipant);\n                return callParticipant;\n            }\n        }\n\n        return null;\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Create a new call and invite the specified CallParticipant to it.\n     *\n     * @param callee the sip address of the callee that we should invite to a\n     *            new call.\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     * @throws ParseException if <tt>callee<\/tt> is not a valid sip address\n     *             string.\n     */\n    public Call createCall(String callee)\n        throws OperationFailedException,\n        ParseException\n    {\n        Address toAddress = protocolProvider.parseAddressString(callee);\n\n        return createOutgoingCall(toAddress);\n    }","id":37183,"modified_method":"/**\n     * Create a new call and invite the specified CallParticipant to it.\n     *\n     * @param callee the sip address of the callee that we should invite to a\n     *            new call.\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     * @throws ParseException if <tt>callee<\/tt> is not a valid sip address\n     *             string.\n     */\n    public Call createCall(String callee)\n        throws OperationFailedException,\n        ParseException\n    {\n        Address toAddress = protocolProvider.parseAddressString(callee);\n\n        return createOutgoingCall(toAddress, null);\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Create a new call and invite the specified CallParticipant to it.\n     *\n     * @param callee the address of the callee that we should invite to a new\n     *            call.\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     */\n    public Call createCall(Contact callee) throws OperationFailedException\n    {\n        Address toAddress = null;\n\n        try\n        {\n            toAddress = protocolProvider.parseAddressString(callee.getAddress());\n        }\n        catch (ParseException ex)\n        {\n            // couldn't happen\n            logger.error(ex.getMessage(), ex);\n            throw new IllegalArgumentException(ex.getMessage());\n        }\n\n        return createOutgoingCall(toAddress);\n    }","id":37184,"modified_method":"/**\n     * Create a new call and invite the specified CallParticipant to it.\n     *\n     * @param callee the address of the callee that we should invite to a new\n     *            call.\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     */\n    public Call createCall(Contact callee) throws OperationFailedException\n    {\n        Address toAddress = null;\n\n        try\n        {\n            toAddress = protocolProvider.parseAddressString(callee.getAddress());\n        }\n        catch (ParseException ex)\n        {\n            // couldn't happen\n            logger.error(ex.getMessage(), ex);\n            throw new IllegalArgumentException(ex.getMessage());\n        }\n\n        return createOutgoingCall(toAddress, null);\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates an invite request destined for <tt>callee<\/tt>.\n     *\n     * @param toAddress the sip address of the callee that the request is meant\n     *            for.\n     * @return a newly created sip <tt>Request<\/tt> destined for <tt>callee<\/tt>\n     *         .\n     * @throws OperationFailedException with the corresponding code if creating\n     *             the request fails.\n     */\n    private Request createInviteRequest(Address toAddress)\n        throws OperationFailedException\n    {\n        // Call ID\n        CallIdHeader callIdHeader =\n            protocolProvider.getDefaultJainSipProvider().getNewCallId();\n\n        // CSeq\n        CSeqHeader cSeqHeader = null;\n        try\n        {\n            cSeqHeader =\n                protocolProvider.getHeaderFactory().createCSeqHeader(1l,\n                    Request.INVITE);\n        }\n        catch (InvalidArgumentException ex)\n        {\n            // Shouldn't happen\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the CSeqHeadder\", ex);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the CSeqHeadder\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n        catch (ParseException exc)\n        {\n            // shouldn't happen\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the CSeqHeadder\", exc);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the CSeqHeadder\",\n                OperationFailedException.INTERNAL_ERROR, exc);\n        }\n\n        // FromHeader\n        String localTag = ProtocolProviderServiceSipImpl.generateLocalTag();\n        FromHeader fromHeader = null;\n        ToHeader toHeader = null;\n        try\n        {\n            // FromHeader\n            fromHeader =\n                protocolProvider.getHeaderFactory().createFromHeader(\n                    protocolProvider.getOurSipAddress(toAddress), localTag);\n\n            // ToHeader\n            toHeader =\n                protocolProvider.getHeaderFactory().createToHeader(toAddress,\n                    null);\n        }\n        catch (ParseException ex)\n        {\n            // these two should never happen.\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the ToHeader\", ex);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the ToHeader\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // ViaHeaders\n        ArrayList<ViaHeader> viaHeaders =\n            protocolProvider.getLocalViaHeaders(toAddress);\n\n        // MaxForwards\n        MaxForwardsHeader maxForwards = protocolProvider.getMaxForwardsHeader();\n\n        // Contact\n        ContactHeader contactHeader\n            = protocolProvider.getContactHeader(toHeader.getAddress());\n\n        Request invite = null;\n        try\n        {\n            invite =\n                protocolProvider.getMessageFactory().createRequest(\n                    toHeader.getAddress().getURI(), Request.INVITE,\n                    callIdHeader, cSeqHeader, fromHeader, toHeader, viaHeaders,\n                    maxForwards);\n\n        }\n        catch (ParseException ex)\n        {\n            // shouldn't happen\n            logger.error(\"Failed to create invite Request!\", ex);\n            throw new OperationFailedException(\n                \"Failed to create invite Request!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // User Agent\n        UserAgentHeader userAgentHeader =\n            protocolProvider.getSipCommUserAgentHeader();\n        if (userAgentHeader != null)\n            invite.addHeader(userAgentHeader);\n\n        // add the contact header.\n        invite.addHeader(contactHeader);\n\n        return invite;\n    }","id":37185,"modified_method":"/**\n     * Creates an invite request destined for <tt>callee<\/tt>.\n     *\n     * @param toAddress the sip address of the callee that the request is meant\n     *            for.\n     * @return a newly created sip <tt>Request<\/tt> destined for <tt>callee<\/tt>\n     *         .\n     * @throws OperationFailedException with the corresponding code if creating\n     *             the request fails.\n     */\n    private Request createInviteRequest(Address toAddress)\n        throws OperationFailedException\n    {\n        // Call ID\n        CallIdHeader callIdHeader =\n            protocolProvider.getDefaultJainSipProvider().getNewCallId();\n\n        // CSeq\n        HeaderFactory headerFactory = protocolProvider.getHeaderFactory();\n        CSeqHeader cSeqHeader = null;\n        try\n        {\n            cSeqHeader = headerFactory.createCSeqHeader(1l, Request.INVITE);\n        }\n        catch (InvalidArgumentException ex)\n        {\n            // Shouldn't happen\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the CSeqHeadder\", ex);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the CSeqHeadder\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n        catch (ParseException exc)\n        {\n            // shouldn't happen\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the CSeqHeadder\", exc);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the CSeqHeadder\",\n                OperationFailedException.INTERNAL_ERROR, exc);\n        }\n\n        // ReplacesHeader\n        Header replacesHeader = stripReplacesHeader(toAddress);\n\n        // FromHeader\n        String localTag = ProtocolProviderServiceSipImpl.generateLocalTag();\n        FromHeader fromHeader = null;\n        ToHeader toHeader = null;\n        try\n        {\n            // FromHeader\n            fromHeader =\n                headerFactory.createFromHeader(\n                    protocolProvider.getOurSipAddress(toAddress), localTag);\n\n            // ToHeader\n            toHeader = headerFactory.createToHeader(toAddress, null);\n        }\n        catch (ParseException ex)\n        {\n            // these two should never happen.\n            logger.error(\"An unexpected erro occurred while\"\n                + \"constructing the ToHeader\", ex);\n            throw new OperationFailedException(\n                \"An unexpected erro occurred while\"\n                    + \"constructing the ToHeader\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // ViaHeaders\n        ArrayList<ViaHeader> viaHeaders =\n            protocolProvider.getLocalViaHeaders(toAddress);\n\n        // MaxForwards\n        MaxForwardsHeader maxForwards = protocolProvider.getMaxForwardsHeader();\n\n        // Contact\n        ContactHeader contactHeader\n            = protocolProvider.getContactHeader(toHeader.getAddress());\n\n        Request invite = null;\n        try\n        {\n            invite =\n                protocolProvider.getMessageFactory().createRequest(\n                    toHeader.getAddress().getURI(), Request.INVITE,\n                    callIdHeader, cSeqHeader, fromHeader, toHeader, viaHeaders,\n                    maxForwards);\n\n        }\n        catch (ParseException ex)\n        {\n            // shouldn't happen\n            logger.error(\"Failed to create invite Request!\", ex);\n            throw new OperationFailedException(\n                \"Failed to create invite Request!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // User Agent\n        UserAgentHeader userAgentHeader =\n            protocolProvider.getSipCommUserAgentHeader();\n        if (userAgentHeader != null)\n            invite.addHeader(userAgentHeader);\n\n        // add the contact header.\n        invite.addHeader(contactHeader);\n\n        // Add the ReplacesHeader if any.\n        if (replacesHeader != null)\n        {\n            invite.setHeader(replacesHeader);\n        }\n\n        return invite;\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates a new call and sends a RINGING response.\n     *\n     * @param sourceProvider the provider containing <tt>sourceTransaction<\/tt>.\n     * @param serverTransaction the transaction containing the received request.\n     * @param invite the Request that we've just received.\n     */\n    private void processInvite(SipProvider sourceProvider,\n                               ServerTransaction serverTransaction,\n                               Request invite)\n    {\n        Dialog dialog = serverTransaction.getDialog();\n        CallParticipantSipImpl callParticipant =\n            activeCallsRepository.findCallParticipant(dialog);\n        int statusCode;\n        if (callParticipant == null)\n        {\n            statusCode = Response.RINGING;\n\n            logger.trace(\"Creating call participant.\");\n            callParticipant =\n                createCallParticipantFor(serverTransaction, sourceProvider);\n            logger.trace(\"call participant created = \" + callParticipant);\n        }\n        else\n            statusCode = Response.OK;\n\n        // sdp description may be in acks - bug report Laurent Michel\n        ContentLengthHeader cl = invite.getContentLength();\n        if (cl != null && cl.getContentLength() > 0)\n        {\n            callParticipant\n                .setSdpDescription(new String(invite.getRawContent()));\n        }\n\n        logger.trace(\"Will verify whether INVITE is properly addressed.\");\n        // Are we the one they are looking for?\n        javax.sip.address.URI calleeURI = dialog.getLocalParty().getURI();\n\n        if (calleeURI.isSipURI())\n        {\n            boolean assertUserMatch =\n                Boolean.valueOf(\n                    SipActivator.getConfigurationService().getString(\n                        FAIL_CALLS_ON_DEST_USER_MISMATCH)).booleanValue();\n\n            if (assertUserMatch)\n            {\n                // user info is case sensitive according to rfc3261\n                String calleeUser = ((SipURI) calleeURI).getUser();\n                String localUser = protocolProvider.getAccountID().getUserID();\n\n                if (calleeUser != null && !calleeUser.equals(localUser))\n                {\n                    callParticipant\n                        .setState(\n                            CallParticipantState.FAILED,\n                            \"A call was received here while it appeared \"\n                          + \"destined to someone else. The call was rejected.\");\n\n                    Response notFound = null;\n                    try\n                    {\n                        notFound =\n                            protocolProvider.getMessageFactory()\n                                .createResponse(Response.NOT_FOUND, invite);\n\n                        // attach a to tag\n                        protocolProvider.attachToTag(notFound, dialog);\n                        notFound.setHeader(protocolProvider\n                            .getSipCommUserAgentHeader());\n                    }\n                    catch (ParseException ex)\n                    {\n                        logger.error(\"Error while trying to create a response\",\n                            ex);\n                        callParticipant.setState(CallParticipantState.FAILED,\n                            \"InernalError: \" + ex.getMessage());\n                        return;\n                    }\n                    try\n                    {\n                        serverTransaction.sendResponse(notFound);\n                        logger.debug(\"sent a not found response: \" + notFound);\n                    }\n                    catch (Exception ex)\n                    {\n                        logger.error(\"Error while trying to send a response\",\n                            ex);\n                        callParticipant.setState(CallParticipantState.FAILED,\n                            \"Internal Error: \" + ex.getMessage());\n                        return;\n                    }\n                    return;\n                }\n            }\n        }\n\n        // Send statusCode\n        String statusCodeString =\n            (statusCode == Response.RINGING) ? \"RINGING\" : \"OK\";\n        logger.debug(\"Invite seems ok, we'll say \" + statusCodeString + \".\");\n        Response response = null;\n        try\n        {\n            response =\n                protocolProvider.getMessageFactory().createResponse(statusCode,\n                    invite);\n            protocolProvider.attachToTag(response, dialog);\n            response.setHeader(protocolProvider.getSipCommUserAgentHeader());\n\n            // set our display name\n            ((ToHeader) response.getHeader(ToHeader.NAME)).getAddress()\n                .setDisplayName(protocolProvider.getOurDisplayName());\n\n            // extract our intended destination which should be in the from\n            Address callerAddress\n                = ((FromHeader) response.getHeader(FromHeader.NAME))\n                    .getAddress();\n            response.addHeader(protocolProvider.getContactHeader(callerAddress));\n\n            if (statusCode != Response.RINGING)\n            {\n                try\n                {\n                    processInviteSendingResponse(callParticipant, response);\n                }\n                catch (OperationFailedException ex)\n                {\n                    logger.error(\"Error while trying to send a request\", ex);\n                    callParticipant.setState(CallParticipantState.FAILED,\n                        \"Internal Error: \" + ex.getMessage());\n                    return;\n                }\n            }\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\"Error while trying to send a request\", ex);\n            callParticipant.setState(CallParticipantState.FAILED,\n                \"Internal Error: \" + ex.getMessage());\n            return;\n        }\n        try\n        {\n            logger.trace(\"will send \" + statusCodeString + \" response: \");\n            serverTransaction.sendResponse(response);\n            logger.debug(\"sent a \" + statusCodeString + \" response: \"\n                + response);\n        }\n        catch (Exception ex)\n        {\n            logger.error(\"Error while trying to send a request\", ex);\n            callParticipant.setState(CallParticipantState.FAILED,\n                \"Internal Error: \" + ex.getMessage());\n            return;\n        }\n\n        if (statusCode != Response.RINGING)\n        {\n            try\n            {\n                processInviteSentResponse(callParticipant, response);\n            }\n            catch (OperationFailedException ex)\n            {\n                logger.error(\"Error after sending a request\", ex);\n            }\n        }\n    }","id":37186,"modified_method":"/**\n     * Creates a new call and sends a RINGING response.\n     *\n     * @param sourceProvider the provider containing <tt>sourceTransaction<\/tt>.\n     * @param serverTransaction the transaction containing the received request.\n     * @param invite the Request that we've just received.\n     */\n    private void processInvite(SipProvider sourceProvider,\n                               ServerTransaction serverTransaction,\n                               Request invite)\n    {\n        Dialog dialog = serverTransaction.getDialog();\n        CallParticipantSipImpl callParticipant =\n            activeCallsRepository.findCallParticipant(dialog);\n        int statusCode;\n        CallParticipantSipImpl callParticipantToReplace = null;\n\n        if (callParticipant == null)\n        {\n            ReplacesHeader replacesHeader =\n                (ReplacesHeader) invite.getHeader(ReplacesHeader.NAME);\n\n            if (replacesHeader == null)\n            {\n                statusCode = Response.RINGING;\n            }\n            else\n            {\n                List<CallParticipantSipImpl> callParticipantsToReplace =\n                    activeCallsRepository.findCallParticipants(\n                        replacesHeader.getCallId(), replacesHeader.getToTag(),\n                        replacesHeader.getFromTag());\n\n                if (callParticipantsToReplace.size() == 1)\n                {\n                    statusCode = Response.OK;\n                    callParticipantToReplace = callParticipantsToReplace.get(0);\n                }\n                else\n                {\n                    statusCode = Response.CALL_OR_TRANSACTION_DOES_NOT_EXIST;\n                }\n            }\n\n            logger.trace(\"Creating call participant.\");\n            callParticipant =\n                createCallParticipantFor(serverTransaction, sourceProvider);\n            logger.trace(\"call participant created = \" + callParticipant);\n        }\n        else\n        {\n            statusCode = Response.OK;\n        }\n\n        // sdp description may be in acks - bug report Laurent Michel\n        ContentLengthHeader cl = invite.getContentLength();\n        if (cl != null && cl.getContentLength() > 0)\n        {\n            callParticipant\n                .setSdpDescription(new String(invite.getRawContent()));\n        }\n\n        if (!isInviteProperlyAddressed(dialog))\n        {\n            callParticipant.setState(CallParticipantState.FAILED,\n                \"A call was received here while it appeared \"\n                    + \"destined to someone else. The call was rejected.\");\n\n            statusCode = Response.NOT_FOUND;\n        }\n\n        // INVITE w/ Replaces\n        if ((statusCode == Response.OK) && (callParticipantToReplace != null))\n        {\n            boolean sayBye = false;\n\n            try\n            {\n                answerCallParticipant(callParticipant);\n                sayBye = true;\n            }\n            catch (OperationFailedException ex)\n            {\n                logger.error(\n                    \"Failed to auto-answer the referred call participant \"\n                        + callParticipant, ex);\n                /*\n                 * RFC 3891 says an appropriate error response MUST be returned\n                 * and callParticipantToReplace must be left unchanged.\n                 */\n            }\n            if (sayBye)\n            {\n                try\n                {\n                    hangupCallParticipant(callParticipantToReplace);\n                }\n                catch (OperationFailedException ex)\n                {\n                    logger.error(\"Failed to hangup the referer \"\n                        + callParticipantToReplace, ex);\n                    callParticipantToReplace.setState(\n                        CallParticipantState.FAILED, \"Internal Error: \" + ex);\n                }\n            }\n            // Even if there was a failure, we cannot just send Response.OK.\n            return;\n        }\n\n        // Send statusCode\n        String statusCodeString;\n        switch (statusCode)\n        {\n        case Response.RINGING:\n            statusCodeString = \"RINGING\";\n            break;\n        case Response.NOT_FOUND:\n            statusCodeString = \"NOT_FOUND\";\n            break;\n        case Response.CALL_OR_TRANSACTION_DOES_NOT_EXIST:\n            statusCodeString = \"CALL_OR_TRANSACTION_DOES_NOT_EXIST\";\n            break;\n        default:\n            statusCodeString = \"OK\";\n            break;\n        }\n        Response response = null;\n\n        logger.debug(\"Invite seems ok, we'll say \" + statusCodeString + \".\");\n        try\n        {\n            response =\n                protocolProvider.getMessageFactory().createResponse(statusCode,\n                    invite);\n            protocolProvider.attachToTag(response, dialog);\n            response.setHeader(protocolProvider.getSipCommUserAgentHeader());\n\n            if (statusCode != Response.NOT_FOUND)\n            {\n                // set our display name\n                ((ToHeader) response.getHeader(ToHeader.NAME)).getAddress()\n                    .setDisplayName(protocolProvider.getOurDisplayName());\n\n                // extract our intended destination which should be in the from\n                Address callerAddress =\n                    ((FromHeader) response.getHeader(FromHeader.NAME))\n                        .getAddress();\n                response.addHeader(protocolProvider\n                    .getContactHeader(callerAddress));\n\n                if (statusCode == Response.OK)\n                {\n                    try\n                    {\n                        processInviteSendingResponse(callParticipant, response);\n                    }\n                    catch (OperationFailedException ex)\n                    {\n                        logger.error(\"Error while trying to send response \"\n                            + response, ex);\n                        callParticipant.setState(CallParticipantState.FAILED,\n                            \"Internal Error: \" + ex.getMessage());\n                        return;\n                    }\n                }\n            }\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\"Error while trying to send a response\", ex);\n            callParticipant.setState(CallParticipantState.FAILED,\n                \"Internal Error: \" + ex.getMessage());\n            return;\n        }\n        try\n        {\n            logger.trace(\"will send \" + statusCodeString + \" response: \");\n            serverTransaction.sendResponse(response);\n            logger.debug(\"sent a \" + statusCodeString + \" response: \"\n                + response);\n        }\n        catch (Exception ex)\n        {\n            logger.error(\"Error while trying to send a request\", ex);\n            callParticipant.setState(CallParticipantState.FAILED,\n                \"Internal Error: \" + ex.getMessage());\n            return;\n        }\n\n        if (statusCode == Response.OK)\n        {\n            try\n            {\n                processInviteSentResponse(callParticipant, response);\n            }\n            catch (OperationFailedException ex)\n            {\n                logger.error(\"Error after sending response \" + response, ex);\n            }\n        }\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Processes a specific REFER request i.e. attempts to transfer the\n     * call/call participant receiving the request to a specific transfer\n     * target.\n     *\n     * @param serverTransaction the <code>ServerTransaction<\/code> containing\n     *            the REFER request\n     * @param referRequest the very REFER request\n     * @param sipProvider the provider containing <code>serverTransaction<\/code>\n     */\n    private void processRefer(ServerTransaction serverTransaction,\n        final Request referRequest, final SipProvider sipProvider)\n    {\n        ReferToHeader referToHeader =\n            (ReferToHeader) referRequest.getHeader(ReferToHeader.NAME);\n        if (referToHeader == null)\n        {\n            logger.error(\"No Refer-To header in REFER request:\\n\"\n                + referRequest);\n            return;\n        }\n        Address referToAddress = referToHeader.getAddress();\n        if (referToAddress == null)\n        {\n            logger.error(\"No address in REFER request Refer-To header:\\n\"\n                + referRequest);\n            return;\n        }\n\n        // Accepted\n        final Dialog dialog = serverTransaction.getDialog();\n        Response accepted = null;\n        try\n        {\n            accepted =\n                protocolProvider.getMessageFactory().createResponse(\n                    Response.ACCEPTED, referRequest);\n            protocolProvider.attachToTag(accepted, dialog);\n            accepted.setHeader(protocolProvider.getSipCommUserAgentHeader());\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\n                \"Failed to create Accepted response to REFER request:\\n\"\n                    + referRequest, ex);\n            /*\n             * TODO Should the call transfer not be attempted because the\n             * Accepted couldn't be sent?\n             */\n        }\n        boolean removeSubscription = false;\n        if (accepted != null)\n        {\n            Throwable failure = null;\n            try\n            {\n                serverTransaction.sendResponse(accepted);\n            }\n            catch (InvalidArgumentException ex)\n            {\n                failure = ex;\n            }\n            catch (SipException ex)\n            {\n                failure = ex;\n            }\n            if (failure != null)\n            {\n                accepted = null;\n\n                logger.error(\n                    \"Failed to send Accepted response to REFER request:\\n\"\n                        + referRequest, failure);\n                /*\n                 * TODO Should the call transfer not be attempted because the\n                 * Accepted couldn't be sent?\n                 */\n            }\n            else\n            {\n\n                /*\n                 * The REFER request has created a subscription. Take it into\n                 * consideration in order to not disconnect on BYE but rather\n                 * when the last subscription terminates.\n                 */\n                try\n                {\n                    removeSubscription =\n                        DialogUtils.addSubscription(dialog, referRequest);\n                }\n                catch (SipException ex)\n                {\n                    logger.error(\n                        \"Failed to make the REFER request keep the dialog alive after BYE:\\n\"\n                            + referRequest, ex);\n                }\n\n                // NOTIFY Trying\n                try\n                {\n                    sendReferNotifyRequest(dialog,\n                        SubscriptionStateHeader.ACTIVE, null,\n                        \"SIP/2.0 100 Trying\", sipProvider);\n                }\n                catch (OperationFailedException ex)\n                {\n                    /*\n                     * TODO Determine whether the failure to send the Trying\n                     * refer NOTIFY should prevent the sending of the\n                     * session-terminating refer NOTIFY.\n                     */\n                }\n            }\n        }\n\n        /*\n         * Regardless of whether the Accepted, NOTIFY, etc. succeeded, try to\n         * transfer the call because it's the most important goal.\n         */\n        Call referToCall;\n        try\n        {\n            referToCall = createOutgoingCall(referToAddress);\n        }\n        catch (OperationFailedException ex)\n        {\n            referToCall = null;\n\n            logger.error(\"Failed to create outgoing call to \" + referToAddress,\n                ex);\n        }\n\n        /*\n         * Start monitoring the call in order to discover when the\n         * subscription-terminating NOTIFY with the final result of the REFER is\n         * to be sent.\n         */\n        final Call referToCallListenerSource = referToCall;\n        final boolean sendNotifyRequest = (accepted != null);\n        final Object subscription = (removeSubscription ? referRequest : null);\n        CallChangeListener referToCallListener = new CallChangeAdapter()\n        {\n\n            /**\n             * The indicator which determines whether the job of this listener\n             * has been done i.e. whether a single subscription-terminating\n             * NOTIFY with the final result of the REFER has been sent.\n             */\n            private boolean done;\n\n            public synchronized void callStateChanged(CallChangeEvent evt)\n            {\n                if (!done\n                    && referToCallStateChanged(referToCallListenerSource,\n                        sendNotifyRequest, dialog, sipProvider, subscription))\n                {\n                    done = true;\n                    if (referToCallListenerSource != null)\n                    {\n                        referToCallListenerSource\n                            .removeCallChangeListener(this);\n                    }\n                }\n            }\n        };\n        if (referToCall != null)\n        {\n            referToCall.addCallChangeListener(referToCallListener);\n        }\n        referToCallListener.callStateChanged(null);\n    }","id":37187,"modified_method":"/**\n     * Processes a specific REFER request i.e. attempts to transfer the\n     * call/call participant receiving the request to a specific transfer\n     * target.\n     *\n     * @param serverTransaction the <code>ServerTransaction<\/code> containing\n     *            the REFER request\n     * @param referRequest the very REFER request\n     * @param sipProvider the provider containing <code>serverTransaction<\/code>\n     */\n    private void processRefer(ServerTransaction serverTransaction,\n        final Request referRequest, final SipProvider sipProvider)\n    {\n        ReferToHeader referToHeader =\n            (ReferToHeader) referRequest.getHeader(ReferToHeader.NAME);\n        if (referToHeader == null)\n        {\n            logger.error(\"No Refer-To header in REFER request:\\n\"\n                + referRequest);\n            return;\n        }\n        Address referToAddress = referToHeader.getAddress();\n        if (referToAddress == null)\n        {\n            logger.error(\"No address in REFER request Refer-To header:\\n\"\n                + referRequest);\n            return;\n        }\n\n        // Accepted\n        final Dialog dialog = serverTransaction.getDialog();\n        Response accepted = null;\n        try\n        {\n            accepted =\n                protocolProvider.getMessageFactory().createResponse(\n                    Response.ACCEPTED, referRequest);\n            protocolProvider.attachToTag(accepted, dialog);\n            accepted.setHeader(protocolProvider.getSipCommUserAgentHeader());\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\n                \"Failed to create Accepted response to REFER request:\\n\"\n                    + referRequest, ex);\n            /*\n             * TODO Should the call transfer not be attempted because the\n             * Accepted couldn't be sent?\n             */\n        }\n        boolean removeSubscription = false;\n        if (accepted != null)\n        {\n            Throwable failure = null;\n            try\n            {\n                serverTransaction.sendResponse(accepted);\n            }\n            catch (InvalidArgumentException ex)\n            {\n                failure = ex;\n            }\n            catch (SipException ex)\n            {\n                failure = ex;\n            }\n            if (failure != null)\n            {\n                accepted = null;\n\n                logger.error(\n                    \"Failed to send Accepted response to REFER request:\\n\"\n                        + referRequest, failure);\n                /*\n                 * TODO Should the call transfer not be attempted because the\n                 * Accepted couldn't be sent?\n                 */\n            }\n            else\n            {\n\n                /*\n                 * The REFER request has created a subscription. Take it into\n                 * consideration in order to not disconnect on BYE but rather\n                 * when the last subscription terminates.\n                 */\n                try\n                {\n                    removeSubscription =\n                        DialogUtils.addSubscription(dialog, referRequest);\n                }\n                catch (SipException ex)\n                {\n                    logger.error(\n                        \"Failed to make the REFER request keep the dialog alive after BYE:\\n\"\n                            + referRequest, ex);\n                }\n\n                // NOTIFY Trying\n                try\n                {\n                    sendReferNotifyRequest(dialog,\n                        SubscriptionStateHeader.ACTIVE, null,\n                        \"SIP/2.0 100 Trying\", sipProvider);\n                }\n                catch (OperationFailedException ex)\n                {\n                    /*\n                     * TODO Determine whether the failure to send the Trying\n                     * refer NOTIFY should prevent the sending of the\n                     * session-terminating refer NOTIFY.\n                     */\n                }\n            }\n        }\n\n        /*\n         * Regardless of whether the Accepted, NOTIFY, etc. succeeded, try to\n         * transfer the call because it's the most important goal.\n         */\n        Call referToCall;\n        try\n        {\n            referToCall = createOutgoingCall(referToAddress, referRequest);\n        }\n        catch (OperationFailedException ex)\n        {\n            referToCall = null;\n\n            logger.error(\"Failed to create outgoing call to \" + referToAddress,\n                ex);\n        }\n\n        /*\n         * Start monitoring the call in order to discover when the\n         * subscription-terminating NOTIFY with the final result of the REFER is\n         * to be sent.\n         */\n        final Call referToCallListenerSource = referToCall;\n        final boolean sendNotifyRequest = (accepted != null);\n        final Object subscription = (removeSubscription ? referRequest : null);\n        CallChangeListener referToCallListener = new CallChangeAdapter()\n        {\n\n            /**\n             * The indicator which determines whether the job of this listener\n             * has been done i.e. whether a single subscription-terminating\n             * NOTIFY with the final result of the REFER has been sent.\n             */\n            private boolean done;\n\n            public synchronized void callStateChanged(CallChangeEvent evt)\n            {\n                if (!done\n                    && referToCallStateChanged(referToCallListenerSource,\n                        sendNotifyRequest, dialog, sipProvider, subscription))\n                {\n                    done = true;\n                    if (referToCallListenerSource != null)\n                    {\n                        referToCallListenerSource\n                            .removeCallChangeListener(this);\n                    }\n                }\n            }\n        };\n        if (referToCall != null)\n        {\n            referToCall.addCallChangeListener(referToCallListener);\n        }\n        referToCallListener.callStateChanged(null);\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Init and establish the specified call.\n     *\n     * @param calleeAddress the address of the callee that we'd like to connect\n     *            with.\n     *\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     *\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     */\n    private synchronized CallSipImpl createOutgoingCall(Address calleeAddress)\n        throws OperationFailedException\n    {\n        if(!protocolProvider.isRegistered())\n        {\n            throw new OperationFailedException(\n                \"The protocol provider should be registered \"\n                +\"before placing an outgoing call.\",\n                OperationFailedException.PROVIDER_NOT_REGISTERED);\n        }\n\n        // create the invite request\n        Request invite = createInviteRequest(calleeAddress);\n\n        // Content\n        ContentTypeHeader contentTypeHeader = null;\n        try\n        {\n            // content type should be application/sdp (not applications)\n            // reported by Oleg Shevchenko (Miratech)\n            contentTypeHeader =\n                protocolProvider.getHeaderFactory().createContentTypeHeader(\n                    \"application\", \"sdp\");\n        }\n        catch (ParseException ex)\n        {\n            // Shouldn't happen\n            logger.error(\n                \"Failed to create a content type header for the INVITE \"\n                    + \"request\", ex);\n            throw new OperationFailedException(\n                \"Failed to create a content type header for the INVITE \"\n                    + \"request\", OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // check whether there's a cached authorization header for this\n        // call id and if so - attach it to the request.\n        // add authorization header\n        CallIdHeader call = (CallIdHeader) invite.getHeader(CallIdHeader.NAME);\n        String callid = call.getCallId();\n\n        AuthorizationHeader authorization =\n            protocolProvider.getSipSecurityManager()\n                .getCachedAuthorizationHeader(callid);\n\n        if (authorization != null)\n            invite.addHeader(authorization);\n\n        // Transaction\n        ClientTransaction inviteTransaction;\n        SipProvider jainSipProvider =\n            protocolProvider.getDefaultJainSipProvider();\n        try\n        {\n            inviteTransaction = jainSipProvider.getNewClientTransaction(invite);\n        }\n        catch (TransactionUnavailableException ex)\n        {\n            logger.error(\"Failed to create inviteTransaction.\\n\"\n                + \"This is most probably a network connection error.\", ex);\n            throw new OperationFailedException(\n                \"Failed to create inviteTransaction.\\n\"\n                    + \"This is most probably a network connection error.\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // create the call participant\n        CallParticipantSipImpl callParticipant =\n            createCallParticipantFor(inviteTransaction, jainSipProvider);\n\n        // invite content\n        try\n        {\n            CallSession callSession =\n                SipActivator.getMediaService().createCallSession(\n                    callParticipant.getCall());\n            ((CallSipImpl) callParticipant.getCall())\n                .setMediaCallSession(callSession);\n\n            // if possible try to indicate the address of the callee so\n            // that the media service can choose the most proper local\n            // address to advertise.\n            javax.sip.address.URI calleeURI = calleeAddress.getURI();\n            InetAddress intendedDestination = null;\n            if (calleeURI.isSipURI())\n            {\n                String host = ((SipURI) calleeURI).getHost();\n\n                intendedDestination = protocolProvider\n                        .resolveSipAddress(host).getAddress();\n                invite.setContent(callSession\n                            .createSdpOffer(intendedDestination),\n                            contentTypeHeader);\n            }\n        }\n        catch (UnknownHostException ex)\n        {\n            logger.warn(\"Failed to obtain an InetAddress.\" + ex.getMessage(),\n                ex);\n            throw new OperationFailedException(\n                            \"Failed to obtain an InetAddress for \"\n                            + ex.getMessage(),\n                            OperationFailedException.NETWORK_FAILURE,\n                            ex);\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\n                \"Failed to parse sdp data while creating invite request!\", ex);\n            throw new OperationFailedException(\n                \"Failed to parse sdp data while creating invite request!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n        catch (MediaException ex)\n        {\n            logger.error(\"Could not access media devices!\", ex);\n            throw new OperationFailedException(\n                \"Could not access media devices!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        try\n        {\n            inviteTransaction.sendRequest();\n            if (logger.isDebugEnabled())\n                logger.debug(\"sent request: \" + invite);\n        }\n        catch (SipException ex)\n        {\n            logger.error(\"An error occurred while sending invite request\", ex);\n            throw new OperationFailedException(\n                \"An error occurred while sending invite request\",\n                OperationFailedException.NETWORK_FAILURE, ex);\n        }\n\n        return (CallSipImpl) callParticipant.getCall();\n    }","id":37188,"modified_method":"/**\n     * Init and establish the specified call.\n     *\n     * @param calleeAddress the address of the callee that we'd like to connect\n     *            with.\n     * @param cause the <code>Message<\/code>, if any, which is the cause for the\n     *            outgoing call to be placed and which carries additional\n     *            information to be included in the call initiation (e.g. a\n     *            Referred-To header and token)\n     * @return CallParticipant the CallParticipant that will represented by the\n     *         specified uri. All following state change events will be\n     *         delivered through that call participant. The Call that this\n     *         participant is a member of could be retrieved from the\n     *         CallParticipatn instance with the use of the corresponding\n     *         method.\n     *\n     * @throws OperationFailedException with the corresponding code if we fail\n     *             to create the call.\n     */\n    private synchronized CallSipImpl createOutgoingCall(Address calleeAddress,\n        javax.sip.message.Message cause) throws OperationFailedException\n    {\n        if(!protocolProvider.isRegistered())\n        {\n            throw new OperationFailedException(\n                \"The protocol provider should be registered \"\n                +\"before placing an outgoing call.\",\n                OperationFailedException.PROVIDER_NOT_REGISTERED);\n        }\n\n        // create the invite request\n        Request invite = createInviteRequest(calleeAddress);\n\n        // Content\n        ContentTypeHeader contentTypeHeader = null;\n        try\n        {\n            // content type should be application/sdp (not applications)\n            // reported by Oleg Shevchenko (Miratech)\n            contentTypeHeader =\n                protocolProvider.getHeaderFactory().createContentTypeHeader(\n                    \"application\", \"sdp\");\n        }\n        catch (ParseException ex)\n        {\n            // Shouldn't happen\n            logger.error(\n                \"Failed to create a content type header for the INVITE \"\n                    + \"request\", ex);\n            throw new OperationFailedException(\n                \"Failed to create a content type header for the INVITE \"\n                    + \"request\", OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // check whether there's a cached authorization header for this\n        // call id and if so - attach it to the request.\n        // add authorization header\n        CallIdHeader call = (CallIdHeader) invite.getHeader(CallIdHeader.NAME);\n        String callid = call.getCallId();\n\n        AuthorizationHeader authorization =\n            protocolProvider.getSipSecurityManager()\n                .getCachedAuthorizationHeader(callid);\n\n        if (authorization != null)\n            invite.addHeader(authorization);\n\n        /*\n         * Whatever the cause of the outgoing call is, reflect the appropriate\n         * information from it into the INVITE request (and do it elsewhere\n         * because this method is already long enough and difficult to grasp).\n         */\n        if (cause != null)\n        {\n            reflectCauseOnEffect(cause, invite);\n        }\n\n        // Transaction\n        ClientTransaction inviteTransaction;\n        SipProvider jainSipProvider =\n            protocolProvider.getDefaultJainSipProvider();\n        try\n        {\n            inviteTransaction = jainSipProvider.getNewClientTransaction(invite);\n        }\n        catch (TransactionUnavailableException ex)\n        {\n            logger.error(\"Failed to create inviteTransaction.\\n\"\n                + \"This is most probably a network connection error.\", ex);\n            throw new OperationFailedException(\n                \"Failed to create inviteTransaction.\\n\"\n                    + \"This is most probably a network connection error.\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        // create the call participant\n        CallParticipantSipImpl callParticipant =\n            createCallParticipantFor(inviteTransaction, jainSipProvider);\n\n        // invite content\n        try\n        {\n            CallSession callSession =\n                SipActivator.getMediaService().createCallSession(\n                    callParticipant.getCall());\n            ((CallSipImpl) callParticipant.getCall())\n                .setMediaCallSession(callSession);\n\n            // if possible try to indicate the address of the callee so\n            // that the media service can choose the most proper local\n            // address to advertise.\n            javax.sip.address.URI calleeURI = calleeAddress.getURI();\n            InetAddress intendedDestination = null;\n            if (calleeURI.isSipURI())\n            {\n                String host = ((SipURI) calleeURI).getHost();\n\n                intendedDestination = protocolProvider\n                        .resolveSipAddress(host).getAddress();\n                invite.setContent(callSession\n                            .createSdpOffer(intendedDestination),\n                            contentTypeHeader);\n            }\n        }\n        catch (UnknownHostException ex)\n        {\n            logger.warn(\"Failed to obtain an InetAddress.\" + ex.getMessage(),\n                ex);\n            throw new OperationFailedException(\n                            \"Failed to obtain an InetAddress for \"\n                            + ex.getMessage(),\n                            OperationFailedException.NETWORK_FAILURE,\n                            ex);\n        }\n        catch (ParseException ex)\n        {\n            logger.error(\n                \"Failed to parse sdp data while creating invite request!\", ex);\n            throw new OperationFailedException(\n                \"Failed to parse sdp data while creating invite request!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n        catch (MediaException ex)\n        {\n            logger.error(\"Could not access media devices!\", ex);\n            throw new OperationFailedException(\n                \"Could not access media devices!\",\n                OperationFailedException.INTERNAL_ERROR, ex);\n        }\n\n        try\n        {\n            inviteTransaction.sendRequest();\n            if (logger.isDebugEnabled())\n                logger.debug(\"sent request: \" + invite);\n        }\n        catch (SipException ex)\n        {\n            logger.error(\"An error occurred while sending invite request\", ex);\n            throw new OperationFailedException(\n                \"An error occurred while sending invite request\",\n                OperationFailedException.NETWORK_FAILURE, ex);\n        }\n\n        return (CallSipImpl) callParticipant.getCall();\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Tracks the state changes of a specific <code>Call<\/code> and sends a\n     * session-terminating NOTIFY request to the <code>Dialog<\/code> which\n     * referred to the call in question as soon as the outcome of the refer is\n     * determined.\n     *\n     * @param referToCall the <code>Call<\/code> to track and send a NOTIFY\n     *            request for\n     * @param sendNotifyRequest <tt>true<\/tt> if a session-terminating NOTIFY\n     *            request should be sent to the <code>Dialog<\/code> which\n     *            referred to <code>referToCall<\/code>; <tt>false<\/tt> to send\n     *            no such NOTIFY request\n     * @param dialog the <code>Dialog<\/code> which initiated the specified call\n     *            as part of processing a REFER request\n     * @param sipProvider the <code>SipProvider<\/code> to send the NOTIFY\n     *            request through\n     * @param subscription the subscription to be terminated when the NOTIFY\n     *            request is sent\n     * @return <tt>true<\/tt> if a session-terminating NOTIFY request was sent\n     *         and the state of <code>referToCall<\/code> should no longer be\n     *         tracked; <tt>false<\/tt> if it's too early to send a\n     *         session-terminating NOTIFY request and the tracking of the state\n     *         of <code>referToCall<\/code> should continue\n     */\n    private boolean referToCallStateChanged(Call referToCall,\n        boolean sendNotifyRequest, Dialog dialog, SipProvider sipProvider,\n        Object subscription)\n    {\n        CallState referToCallState =\n            (referToCall == null) ? null : referToCall.getCallState();\n        if (CallState.CALL_INITIALIZATION.equals(referToCallState))\n        {\n            return false;\n        }\n\n        /*\n         * NOTIFY OK/Declined\n         *\n         * It doesn't sound like sending NOTIFY Service Unavailable is\n         * appropriate because the REFER request has (presumably) already been\n         * accepted.\n         */\n        if (sendNotifyRequest)\n        {\n            String referStatus =\n                CallState.CALL_IN_PROGRESS.equals(referToCallState) ? \"SIP/2.0 200 OK\"\n                    : \"SIP/2.0 603 Declined\";\n            try\n            {\n                sendReferNotifyRequest(dialog,\n                    SubscriptionStateHeader.TERMINATED,\n                    SubscriptionStateHeader.NO_RESOURCE, referStatus,\n                    sipProvider);\n            }\n            catch (OperationFailedException ex)\n            {\n                // The exception has already been logged.\n            }\n        }\n\n        /*\n         * Whatever the status of the REFER is, the subscription created by it\n         * is terminated with the final NOTIFY.\n         */\n        if (DialogUtils.removeSubscriptionThenIsDialogAlive(dialog,\n            subscription) == false)\n        {\n            CallParticipantSipImpl callParticipant =\n                activeCallsRepository.findCallParticipant(dialog);\n            if (callParticipant != null)\n            {\n                callParticipant.setState(CallParticipantState.DISCONNECTED);\n            }\n        }\n        return true;\n    }","id":37189,"modified_method":"/**\n     * Tracks the state changes of a specific <code>Call<\/code> and sends a\n     * session-terminating NOTIFY request to the <code>Dialog<\/code> which\n     * referred to the call in question as soon as the outcome of the refer is\n     * determined.\n     *\n     * @param referToCall the <code>Call<\/code> to track and send a NOTIFY\n     *            request for\n     * @param sendNotifyRequest <tt>true<\/tt> if a session-terminating NOTIFY\n     *            request should be sent to the <code>Dialog<\/code> which\n     *            referred to <code>referToCall<\/code>; <tt>false<\/tt> to send\n     *            no such NOTIFY request\n     * @param dialog the <code>Dialog<\/code> which initiated the specified call\n     *            as part of processing a REFER request\n     * @param sipProvider the <code>SipProvider<\/code> to send the NOTIFY\n     *            request through\n     * @param subscription the subscription to be terminated when the NOTIFY\n     *            request is sent\n     * @return <tt>true<\/tt> if a session-terminating NOTIFY request was sent\n     *         and the state of <code>referToCall<\/code> should no longer be\n     *         tracked; <tt>false<\/tt> if it's too early to send a\n     *         session-terminating NOTIFY request and the tracking of the state\n     *         of <code>referToCall<\/code> should continue\n     */\n    private boolean referToCallStateChanged(Call referToCall,\n        boolean sendNotifyRequest, Dialog dialog, SipProvider sipProvider,\n        Object subscription)\n    {\n        CallState referToCallState =\n            (referToCall == null) ? null : referToCall.getCallState();\n        if (CallState.CALL_INITIALIZATION.equals(referToCallState))\n        {\n            return false;\n        }\n\n        /*\n         * NOTIFY OK/Declined\n         *\n         * It doesn't sound like sending NOTIFY Service Unavailable is\n         * appropriate because the REFER request has (presumably) already been\n         * accepted.\n         */\n        if (sendNotifyRequest)\n        {\n            String referStatus =\n                CallState.CALL_IN_PROGRESS.equals(referToCallState) ? \"SIP/2.0 200 OK\"\n                    : \"SIP/2.0 603 Declined\";\n            try\n            {\n                sendReferNotifyRequest(dialog,\n                    SubscriptionStateHeader.TERMINATED,\n                    SubscriptionStateHeader.NO_RESOURCE, referStatus,\n                    sipProvider);\n            }\n            catch (OperationFailedException ex)\n            {\n                // The exception has already been logged.\n            }\n        }\n\n        /*\n         * Whatever the status of the REFER is, the subscription created by it\n         * is terminated with the final NOTIFY.\n         */\n        if (!DialogUtils.removeSubscriptionThenIsDialogAlive(dialog,\n            subscription))\n        {\n            CallParticipantSipImpl callParticipant =\n                activeCallsRepository.findCallParticipant(dialog);\n            if (callParticipant != null)\n            {\n                callParticipant.setState(CallParticipantState.DISCONNECTED);\n            }\n        }\n        return true;\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Processes a specific <code>Request.NOTIFY<\/code> request for the purposes\n     * of telephony.\n     *\n     * @param serverTransaction the <code>ServerTransaction<\/code> containing\n     *            the <code>Request.NOTIFY<\/code> request\n     * @param notifyRequest the <code>Request.NOTIFY<\/code> request to be\n     *            processed\n     */\n    private boolean processNotify(ServerTransaction serverTransaction,\n        Request notifyRequest)\n    {\n\n        /*\n         * We're only handling NOTIFY as part of call transfer (i.e. refer)\n         * right now.\n         */\n        EventHeader eventHeader =\n            (EventHeader) notifyRequest.getHeader(EventHeader.NAME);\n        if ((eventHeader == null)\n            || !\"refer\".equals(eventHeader.getEventType()))\n        {\n            return false;\n        }\n\n        SubscriptionStateHeader ssHeader =\n            (SubscriptionStateHeader) notifyRequest\n                .getHeader(SubscriptionStateHeader.NAME);\n        if (ssHeader == null)\n        {\n            logger\n                .error(\"NOTIFY of refer event type with no Subscription-State header.\");\n            return false;\n        }\n\n        Dialog dialog = serverTransaction.getDialog();\n        CallParticipantSipImpl participant = activeCallsRepository.findCallParticipant(dialog);\n\n        if (participant == null)\n        {\n            logger.debug(\"Received a stray refer NOTIFY request.\");\n            return false;\n        }\n\n        // OK\n        Response ok;\n        try\n        {\n            ok = createOKResponse(notifyRequest, dialog);\n        }\n        catch (ParseException ex)\n        {\n            String message =\n                \"Failed to create OK response to refer NOTIFY request.\";\n\n            logger.error(message, ex);\n            participant.setState(CallParticipantState.DISCONNECTED, message);\n            return false;\n        }\n        try\n        {\n            serverTransaction.sendResponse(ok);\n        }\n        catch (Exception ex)\n        {\n            String message =\n                \"Failed to send OK response to refer NOTIFY request.\";\n\n            logger.error(message, ex);\n            participant.setState(CallParticipantState.DISCONNECTED, message);\n            return false;\n        }\n\n        if (SubscriptionStateHeader.TERMINATED.equals(ssHeader.getState())\n            && (DialogUtils\n                .removeSubscriptionThenIsDialogAlive(dialog, \"refer\") == false))\n        {\n            participant.setState(CallParticipantState.DISCONNECTED);\n        }\n\n        if ((CallParticipantState.DISCONNECTED.equals(participant.getState()) == false)\n            && (DialogUtils.isByeProcessed(dialog) == false))\n        {\n            boolean dialogIsAlive;\n            try\n            {\n                dialogIsAlive = sayBye(participant);\n            }\n            catch (OperationFailedException ex)\n            {\n                logger.error(\n                    \"Failed to send BYE in response to refer NOTIFY request.\",\n                    ex);\n                dialogIsAlive = false;\n            }\n            if (dialogIsAlive == false)\n            {\n                participant.setState(CallParticipantState.DISCONNECTED);\n            }\n        }\n\n        return true;\n    }","id":37190,"modified_method":"/**\n     * Processes a specific <code>Request.NOTIFY<\/code> request for the purposes\n     * of telephony.\n     *\n     * @param serverTransaction the <code>ServerTransaction<\/code> containing\n     *            the <code>Request.NOTIFY<\/code> request\n     * @param notifyRequest the <code>Request.NOTIFY<\/code> request to be\n     *            processed\n     */\n    private boolean processNotify(ServerTransaction serverTransaction,\n        Request notifyRequest)\n    {\n\n        /*\n         * We're only handling NOTIFY as part of call transfer (i.e. refer)\n         * right now.\n         */\n        EventHeader eventHeader =\n            (EventHeader) notifyRequest.getHeader(EventHeader.NAME);\n        if ((eventHeader == null)\n            || !\"refer\".equals(eventHeader.getEventType()))\n        {\n            return false;\n        }\n\n        SubscriptionStateHeader ssHeader =\n            (SubscriptionStateHeader) notifyRequest\n                .getHeader(SubscriptionStateHeader.NAME);\n        if (ssHeader == null)\n        {\n            logger\n                .error(\"NOTIFY of refer event type with no Subscription-State header.\");\n            return false;\n        }\n\n        Dialog dialog = serverTransaction.getDialog();\n        CallParticipantSipImpl participant = activeCallsRepository.findCallParticipant(dialog);\n\n        if (participant == null)\n        {\n            logger.debug(\"Received a stray refer NOTIFY request.\");\n            return false;\n        }\n\n        // OK\n        Response ok;\n        try\n        {\n            ok = createOKResponse(notifyRequest, dialog);\n        }\n        catch (ParseException ex)\n        {\n            String message =\n                \"Failed to create OK response to refer NOTIFY request.\";\n\n            logger.error(message, ex);\n            participant.setState(CallParticipantState.DISCONNECTED, message);\n            return false;\n        }\n        try\n        {\n            serverTransaction.sendResponse(ok);\n        }\n        catch (Exception ex)\n        {\n            String message =\n                \"Failed to send OK response to refer NOTIFY request.\";\n\n            logger.error(message, ex);\n            participant.setState(CallParticipantState.DISCONNECTED, message);\n            return false;\n        }\n\n        if (SubscriptionStateHeader.TERMINATED.equals(ssHeader.getState())\n            && !DialogUtils\n                .removeSubscriptionThenIsDialogAlive(dialog, \"refer\"))\n        {\n            participant.setState(CallParticipantState.DISCONNECTED);\n        }\n\n        if (!CallParticipantState.DISCONNECTED.equals(participant.getState())\n            && !DialogUtils.isByeProcessed(dialog))\n        {\n            boolean dialogIsAlive;\n            try\n            {\n                dialogIsAlive = sayBye(participant);\n            }\n            catch (OperationFailedException ex)\n            {\n                logger.error(\n                    \"Failed to send BYE in response to refer NOTIFY request.\",\n                    ex);\n                dialogIsAlive = false;\n            }\n            if (!dialogIsAlive)\n            {\n                participant.setState(CallParticipantState.DISCONNECTED);\n            }\n        }\n\n        return true;\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates a new call and call participant associated with\n     * <tt>containingTransaction<\/tt>\n     *\n     * @param containingTransaction the transaction that created the call.\n     * @param sourceProvider the provider that the containingTransaction belongs\n     *            to.\n     *\n     * @return a new instance of a <tt>CallParticipantSipImpl<\/tt> corresponding\n     *         to the <tt>containingTransaction<\/tt>.\n     */\n    private CallParticipantSipImpl createCallParticipantFor(\n        Transaction containingTransaction, SipProvider sourceProvider)\n    {\n        CallSipImpl call = new CallSipImpl(protocolProvider);\n        CallParticipantSipImpl callParticipant =\n            new CallParticipantSipImpl(containingTransaction.getDialog()\n                .getRemoteParty(), call);\n\n        if (containingTransaction instanceof ServerTransaction)\n            callParticipant.setState(CallParticipantState.INCOMING_CALL);\n        else\n            callParticipant.setState(CallParticipantState.INITIATING_CALL);\n\n        callParticipant.setDialog(containingTransaction.getDialog());\n        callParticipant.setFirstTransaction(containingTransaction);\n        callParticipant.setJainSipProvider(sourceProvider);\n\n        activeCallsRepository.addCall(call);\n\n        // notify everyone\n        if (containingTransaction instanceof ServerTransaction)\n            fireCallEvent(CallEvent.CALL_RECEIVED, call);\n        else\n            fireCallEvent(CallEvent.CALL_INITIATED, call);\n\n        return callParticipant;\n    }","id":37191,"modified_method":"/**\n     * Creates a new call and call participant associated with\n     * <tt>containingTransaction<\/tt>\n     *\n     * @param containingTransaction the transaction that created the call.\n     * @param sourceProvider the provider that the containingTransaction belongs\n     *            to.\n     *\n     * @return a new instance of a <tt>CallParticipantSipImpl<\/tt> corresponding\n     *         to the <tt>containingTransaction<\/tt>.\n     */\n    private CallParticipantSipImpl createCallParticipantFor(\n        Transaction containingTransaction, SipProvider sourceProvider)\n    {\n        CallSipImpl call = new CallSipImpl(protocolProvider);\n        CallParticipantSipImpl callParticipant =\n            new CallParticipantSipImpl(\n                containingTransaction.getDialog().getRemoteParty(),\n                call);\n        boolean incomingCall =\n            (containingTransaction instanceof ServerTransaction);\n\n        callParticipant.setState(\n             incomingCall ?\n                 CallParticipantState.INCOMING_CALL :\n                 CallParticipantState.INITIATING_CALL);\n\n        callParticipant.setDialog(containingTransaction.getDialog());\n        callParticipant.setFirstTransaction(containingTransaction);\n        callParticipant.setJainSipProvider(sourceProvider);\n\n        activeCallsRepository.addCall(call);\n\n        // notify everyone\n        fireCallEvent(\n            incomingCall ? CallEvent.CALL_RECEIVED : CallEvent.CALL_INITIATED,\n            call);\n\n        return callParticipant;\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Transfers (in the sense of call transfer) a specific\n     * <code>CallParticipant<\/code> to a specific callee address.\n     *\n     * @param participant the <code>CallParticipant<\/code> to be transfered to\n     *            the specified callee address\n     * @param target the address of the callee to transfer\n     *            <code>participant<\/code> to\n     * @throws OperationFailedException\n     */\n    public void transfer(CallParticipant participant, String target)\n        throws OperationFailedException\n    {\n        Address targetAddress = null;\n        try\n        {\n            targetAddress = protocolProvider.parseAddressString(target);\n        }\n        catch (ParseException ex)\n        {\n            throwOperationFailedException(\n                \"Failed to parse target address string.\",\n                OperationFailedException.ILLEGAL_ARGUMENT, ex);\n        }\n\n        CallParticipantSipImpl sipParticipant =\n            (CallParticipantSipImpl) participant;\n        Dialog dialog = sipParticipant.getDialog();\n        Request refer = createRequest(dialog, Request.REFER);\n\n        refer.addHeader(protocolProvider.getHeaderFactory()\n            .createReferToHeader(targetAddress));\n\n        sendRequest(sipParticipant.getJainSipProvider(), refer, dialog);\n    }","id":37192,"modified_method":"public void transfer(CallParticipant participant, String target)\n        throws OperationFailedException\n    {\n        transfer(participant, parseAddressString(target));\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Handles actions performed on this button on behalf of a specific\n     * <code>ActionListener<\/code>.\n     * \n     * @param listener the <code>ActionListener<\/code> notified about the\n     *            performing of the action\n     * @param evt the <code>ActionEvent<\/code> containing the data associated\n     *            with the action and the act of its performing\n     */\n    private void actionPerformed(ActionListener listener, ActionEvent evt)\n    {\n        final Call call = callParticipant.getCall();\n\n        if (call != null)\n        {\n            OperationSetAdvancedTelephony telephony =\n                (OperationSetAdvancedTelephony) call.getProtocolProvider()\n                    .getOperationSet(OperationSetAdvancedTelephony.class);\n\n            if (telephony != null)\n            {\n                final TransferCallDialog dialog =\n                    new TransferCallDialog(getFrame());\n\n                /*\n                 * Transferring a call works only when the call is in progress\n                 * so close the dialog (if it's not already closed, of course)\n                 * once the dialog ends.\n                 */\n                CallChangeListener callChangeListener = new CallChangeAdapter()\n                {\n\n                    /*\n                     * (non-Javadoc)\n                     * \n                     * @see net.java.sip.communicator.service.protocol.event.\n                     * CallChangeAdapter\n                     * #callStateChanged(net.java.sip.communicator\n                     * .service.protocol.event.CallChangeEvent)\n                     */\n                    public void callStateChanged(CallChangeEvent evt)\n                    {\n                        if (!CallState.CALL_IN_PROGRESS.equals(call\n                            .getCallState()))\n                        {\n                            dialog.setVisible(false);\n                            dialog.dispose();\n                        }\n                    }\n                };\n                call.addCallChangeListener(callChangeListener);\n                try\n                {\n                    dialog.setModal(true);\n                    dialog.pack();\n                    dialog.setVisible(true);\n                }\n                finally\n                {\n                    call.removeCallChangeListener(callChangeListener);\n                }\n\n                String target = dialog.getTarget();\n                if ((target != null) && (target.length() > 0))\n                {\n                    try\n                    {\n                        telephony.transfer(callParticipant, target);\n                    }\n                    catch (OperationFailedException ex)\n                    {\n                        logger.error(\"Failed to transfer call \" + call + \" to \"\n                            + target, ex);\n                    }\n                }\n            }\n        }\n    }","id":37193,"modified_method":"/**\n     * Handles actions performed on this button on behalf of a specific\n     * <code>ActionListener<\/code>.\n     * \n     * @param listener the <code>ActionListener<\/code> notified about the\n     *            performing of the action\n     * @param evt the <code>ActionEvent<\/code> containing the data associated\n     *            with the action and the act of its performing\n     */\n    private void actionPerformed(ActionListener listener, ActionEvent evt)\n    {\n        final Call call = callParticipant.getCall();\n\n        if (call != null)\n        {\n            OperationSetAdvancedTelephony telephony =\n                (OperationSetAdvancedTelephony) call.getProtocolProvider()\n                    .getOperationSet(OperationSetAdvancedTelephony.class);\n\n            if (telephony != null)\n            {\n                final TransferCallDialog dialog =\n                    new TransferCallDialog(getFrame());\n\n                /*\n                 * Transferring a call works only when the call is in progress\n                 * so close the dialog (if it's not already closed, of course)\n                 * once the dialog ends.\n                 */\n                CallChangeListener callChangeListener = new CallChangeAdapter()\n                {\n\n                    /*\n                     * (non-Javadoc)\n                     * \n                     * @see net.java.sip.communicator.service.protocol.event.\n                     * CallChangeAdapter\n                     * #callStateChanged(net.java.sip.communicator\n                     * .service.protocol.event.CallChangeEvent)\n                     */\n                    public void callStateChanged(CallChangeEvent evt)\n                    {\n                        if (!CallState.CALL_IN_PROGRESS.equals(call\n                            .getCallState()))\n                        {\n                            dialog.setVisible(false);\n                            dialog.dispose();\n                        }\n                    }\n                };\n                call.addCallChangeListener(callChangeListener);\n                try\n                {\n                    dialog.setModal(true);\n                    dialog.pack();\n                    dialog.setVisible(true);\n                }\n                finally\n                {\n                    call.removeCallChangeListener(callChangeListener);\n                }\n\n                String target = dialog.getTarget();\n                if ((target != null) && (target.length() > 0))\n                {\n                    try\n                    {\n                        CallParticipant targetParticipant =\n                            findCallParticipant(target);\n\n                        if (targetParticipant == null)\n                        {\n                            telephony.transfer(callParticipant, target);\n                        }\n                        else\n                        {\n                            telephony.transfer(callParticipant,\n                                targetParticipant);\n                        }\n                    }\n                    catch (OperationFailedException ex)\n                    {\n                        logger.error(\"Failed to transfer call \" + call + \" to \"\n                            + target, ex);\n                    }\n                }\n            }\n        }\n    }","commit_id":"fce24e42566cffc4227d83d3ff8e914d6ada85c9","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\r\n     * Creates a BetaMemory for the BetaNode's memory.\r\n     */\r\n    public Object createMemory(final RuleBaseConfiguration config) {\r\n        // iterate over all the constraints untill we find one that is indexeable. When we find it we remove it from the list and create the \r\n        // BetaMemory for it. If we don't find one, we create a normal beta memory. We don't need the constraint as we can assume that \r\n        // anything  returned by the memory already passes that test.\r\n        LinkedList constraints = this.constraints.getConstraints();\r\n        for ( LinkedListEntry entry = ( LinkedListEntry ) constraints.getFirst(); entry != null; entry = ( LinkedListEntry ) entry.getNext() ) {\r\n            FieldConstraint constraint = ( FieldConstraint ) entry.getObject();            \r\n            if ( constraint.getClass() == VariableConstraint.class ) {\r\n                VariableConstraint variableConstraint = ( VariableConstraint ) constraint;\r\n                FieldExtractor extractor = variableConstraint.getFieldExtractor();\r\n                Evaluator evaluator = variableConstraint.getEvaluator();\r\n                if ( evaluator.getOperator() == Operator.EQUAL ) {\r\n                    // remove this entry                    \r\n                    constraints.remove( entry );                    \r\n                    BetaMemory memory = new BetaMemory( new TupleHashTable(),\r\n                                                        new FieldIndexHashTable(extractor, variableConstraint.getRequiredDeclarations()[0]) );\r\n                    return memory;\r\n                    \r\n                }\r\n            }\r\n        }\r\n        \r\n        BetaMemory memory = new BetaMemory( new TupleHashTable(),\r\n                                            new FactHashTable() );                \r\n        return memory;\r\n    }","id":37194,"modified_method":"/**\r\n     * Creates a BetaMemory for the BetaNode's memory.\r\n     */\r\n    public Object createMemory(final RuleBaseConfiguration config) {\r\n        // iterate over all the constraints untill we find one that is indexeable. When we find it we remove it from the list and create the \r\n        // BetaMemory for it. If we don't find one, we create a normal beta memory. We don't need the constraint as we can assume that \r\n        // anything  returned by the memory already passes that test.\r\n        LinkedList constraints = this.constraints.getConstraints();\r\n        BetaMemory memory = null;\r\n        \r\n        if ( constraints != null ) {\r\n            for ( LinkedListEntry entry = (LinkedListEntry) constraints.getFirst(); entry != null; entry = (LinkedListEntry) entry.getNext() ) {\r\n                FieldConstraint constraint = (FieldConstraint) entry.getObject();\r\n                if ( constraint.getClass() == VariableConstraint.class ) {\r\n                    VariableConstraint variableConstraint = (VariableConstraint) constraint;\r\n                    FieldExtractor extractor = variableConstraint.getFieldExtractor();\r\n                    Evaluator evaluator = variableConstraint.getEvaluator();\r\n                    if ( evaluator.getOperator() == Operator.EQUAL ) {\r\n                        // remove this entry                    \r\n                        constraints.remove( entry );\r\n                        memory = new BetaMemory( new TupleHashTable(),\r\n                                                 new FieldIndexHashTable( extractor,\r\n                                                                          variableConstraint.getRequiredDeclarations()[0] ) );\r\n                        break;\r\n\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        \r\n        if ( memory == null )  {\r\n            memory = new BetaMemory( new TupleHashTable(),\r\n                                     new FactHashTable() );            \r\n        }\r\n        \r\n        return memory;\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public boolean isAllowed(final InternalFactHandle handle,\r\n                             final Tuple tuple,\r\n                             final WorkingMemory workingMemory) {\r\n        if ( this.constraints == null ) {\r\n            return true;\r\n        }\r\n                \r\n        for ( LinkedListEntry entry = ( LinkedListEntry ) this.constraints.getFirst(); entry != null; entry = ( LinkedListEntry ) entry.getNext() ) {\r\n            FieldConstraint constraint = (FieldConstraint) entry.getObject();\r\n            if ( constraint.isAllowed( handle.getObject(),\r\n                                       tuple,\r\n                                       workingMemory ) ) {\r\n                return false;\r\n            }            \r\n        }\r\n        return true;\r\n    }","id":37195,"modified_method":"public boolean isAllowed(final InternalFactHandle handle,\r\n                             final Tuple tuple,\r\n                             final WorkingMemory workingMemory) {\r\n        if ( this.constraints == null ) {\r\n            return true;\r\n        }\r\n                \r\n        for ( LinkedListEntry entry = ( LinkedListEntry ) this.constraints.getFirst(); entry != null; entry = ( LinkedListEntry ) entry.getNext() ) {\r\n            FieldConstraint constraint = (FieldConstraint) entry.getObject();\r\n            if ( !constraint.isAllowed( handle.getObject(),\r\n                                       tuple,\r\n                                       workingMemory ) ) {\r\n                return false;\r\n            }            \r\n        }\r\n        return true;\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public InstrumentedReteTuple(final Tuple left,\r\n                                 final FactHandle handle) {\r\n        super( left,\r\n               (DefaultFactHandle) handle );\r\n    }","id":37196,"modified_method":"public InstrumentedReteTuple(final ReteTuple left,\r\n                                 final FactHandle handle) {\r\n        super( left,\r\n               (InternalFactHandle) handle );\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\r\n     * Test just object assertions\r\n     * \r\n     * @throws Exception\r\n     */\r\n    public void testAssertObject() throws Exception {\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n\r\n        // assert object, should add one to right memory\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        assertEquals( 0,\r\n                      this.memory.getLeftTupleMemory().size() );\r\n        assertEquals( 1,\r\n                      this.memory.getRightObjectMemory().size() );\r\n\r\n        // check new objects/handles still assert\r\n        final DefaultFactHandle f1 = (DefaultFactHandle) this.workingMemory.assertObject( \"test1\" );\r\n        this.node.assertObject( f1,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        assertEquals( 2,\r\n                      this.memory.getRightObjectMemory().size() );\r\n\r\n        final BetaRightMemory rightMemory = this.memory.getRightObjectMemory();\r\n        final Iterator it = rightMemory.iterator( this.workingMemory,\r\n                                                  new ReteTuple( f0 ) );\r\n\r\n        final DefaultFactHandle rf0 = ((ObjectMatches) it.next()).getFactHandle();\r\n        final DefaultFactHandle rf1 = ((ObjectMatches) it.next()).getFactHandle();\r\n\r\n        assertEquals( f0,\r\n                      rf0 );\r\n        assertEquals( f1,\r\n                      rf1 );\r\n    }","id":37197,"modified_method":"/**\r\n     * Test just object assertions\r\n     * \r\n     * @throws Exception\r\n     */\r\n    public void testAssertObject() throws Exception {\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n\r\n        // assert object, should add one to right memory\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        assertEquals( 0,\r\n                      this.memory.getTupleMemory().size() );\r\n        assertEquals( 1,\r\n                      this.memory.getObjectMemory().size() );\r\n\r\n        // check new objects/handles still assert\r\n        final DefaultFactHandle f1 = (DefaultFactHandle) this.workingMemory.assertObject( \"test1\" );\r\n        this.node.assertObject( f1,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        assertEquals( 2,\r\n                      this.memory.getObjectMemory().size() );\r\n\r\n        final Iterator it = this.memory.getObjectMemory().iterator( new ReteTuple( f0 ) );\r\n\r\n        final InternalFactHandle rf0 = ((FactEntry) it.next()).getFactHandle();\r\n        final InternalFactHandle rf1 = ((FactEntry) it.next()).getFactHandle();\r\n\r\n        assertEquals( f0,\r\n                      rf0 );\r\n        assertEquals( f1,\r\n                      rf1 );\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\r\n     * Setup the BetaNode used in each of the tests\r\n     */\r\n    public void setUp() {\r\n        this.rule = new Rule( \"test-rule\" );\r\n        this.context = new PropagationContextImpl( 0,\r\n                                                   PropagationContext.ASSERTION,\r\n                                                   null,\r\n                                                   null );\r\n        this.workingMemory = new ReteooWorkingMemory( 1,\r\n                                                      (ReteooRuleBase) RuleBaseFactory.newRuleBase() );\r\n\r\n        this.tupleSource = new MockTupleSource( 4 );\r\n        this.objectSource = new MockObjectSource( 4 );\r\n        this.sink = new MockTupleSink();\r\n\r\n        this.node = new JoinNode( 15,\r\n                                  this.tupleSource,\r\n                                  this.objectSource,\r\n                                  new BetaNodeConstraints( new FieldConstraint[]{this.constraint} ) );\r\n\r\n        this.node.addTupleSink( this.sink );\r\n\r\n        this.memory = (BetaMemory) this.workingMemory.getNodeMemory( this.node );\r\n\r\n        // check memories are empty\r\n        assertEquals( 0,\r\n                      this.memory.getLeftTupleMemory().size() );\r\n        assertEquals( 0,\r\n                      this.memory.getRightObjectMemory().size() );\r\n\r\n    }","id":37198,"modified_method":"/**\r\n     * Setup the BetaNode used in each of the tests\r\n     */\r\n    public void setUp() {\r\n        this.rule = new Rule( \"test-rule\" );\r\n        this.context = new PropagationContextImpl( 0,\r\n                                                   PropagationContext.ASSERTION,\r\n                                                   null,\r\n                                                   null );\r\n        this.workingMemory = new ReteooWorkingMemory( 1,\r\n                                                      (ReteooRuleBase) RuleBaseFactory.newRuleBase() );\r\n\r\n        this.tupleSource = new MockTupleSource( 4 );\r\n        this.objectSource = new MockObjectSource( 4 );\r\n        this.sink = new MockTupleSink();\r\n\r\n        this.node = new JoinNode( 15,\r\n                                  this.tupleSource,\r\n                                  this.objectSource,\r\n                                  new BetaNodeConstraints( new FieldConstraint[]{this.constraint} ) );\r\n\r\n        this.node.addTupleSink( this.sink );\r\n\r\n        this.memory = (BetaMemory) this.workingMemory.getNodeMemory( this.node );\r\n\r\n        // check memories are empty\r\n        assertEquals( 0,\r\n                      this.memory.getTupleMemory().size() );\r\n        assertEquals( 0,\r\n                      this.memory.getObjectMemory().size() );\r\n\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\r\n     * Test just tuple assertions\r\n     * \r\n     * @throws AssertionException\r\n     */\r\n    public void testAssertTuple() throws Exception {\r\n        final DefaultFactHandle f0 = new DefaultFactHandle( 0,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple0 = new ReteTuple( f0 );\r\n\r\n        // assert tuple, should add one to left memory\r\n        this.node.assertTuple( tuple0,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        // check memories are empty\r\n        assertEquals( 1,\r\n                      this.memory.getLeftTupleMemory().size() );\r\n        assertEquals( 0,\r\n                      this.memory.getRightObjectMemory().size() );\r\n\r\n        // assert tuple, should add left memory should be 2\r\n        final DefaultFactHandle f1 = new DefaultFactHandle( 1,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        assertEquals( 2,\r\n                      this.memory.getLeftTupleMemory().size() );\r\n\r\n        final ReteTuple tuple = (ReteTuple) this.memory.getLeftTupleMemory().iterator( this.workingMemory,\r\n                                                                                       f0 ).next();\r\n        assertEquals( tuple0,\r\n                      tuple );\r\n        assertEquals( tuple1,\r\n                      tuple.getNext() );\r\n    }","id":37199,"modified_method":"/**\r\n     * Test just tuple assertions\r\n     * \r\n     * @throws AssertionException\r\n     */\r\n    public void testAssertTuple() throws Exception {\r\n        final DefaultFactHandle f0 = new DefaultFactHandle( 0,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple0 = new ReteTuple( f0 );\r\n\r\n        // assert tuple, should add one to left memory\r\n        this.node.assertTuple( tuple0,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        // check memories are empty\r\n        assertEquals( 1,\r\n                      this.memory.getTupleMemory().size() );\r\n        assertEquals( 0,\r\n                      this.memory.getObjectMemory().size() );\r\n\r\n        // assert tuple, should add left memory should be 2\r\n        final DefaultFactHandle f1 = new DefaultFactHandle( 1,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        assertEquals( 2,\r\n                      this.memory.getTupleMemory().size() );        \r\n        \r\n        Iterator it = this.memory.getTupleMemory().iterator();\r\n        assertEquals( tuple0,\r\n                      it.next() );\r\n        assertEquals( tuple1,\r\n                      it.next() );\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\r\n     * Test Tuple retraction\r\n     * \r\n     * @throws Exception\r\n     * @throws RetractionException\r\n     */\r\n    public void testRetractTuple() throws Exception {\r\n        // setup 2 tuples 3 fact handles\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        final DefaultFactHandle f1 = (DefaultFactHandle) this.workingMemory.assertObject( \"test1\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        final DefaultFactHandle f2 = (DefaultFactHandle) this.workingMemory.assertObject( \"test2\" );\r\n        final ReteTuple tuple2 = new ReteTuple( f2 );\r\n        this.node.assertTuple( tuple2,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        final DefaultFactHandle f3 = (DefaultFactHandle) this.workingMemory.assertObject( \"test3\" );\r\n        this.node.assertObject( f3,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        final DefaultFactHandle f4 = (DefaultFactHandle) this.workingMemory.assertObject( \"test4\" );\r\n        this.node.assertObject( f4,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        assertLength( 6,\r\n                      this.sink.getAsserted() );\r\n\r\n        // Retract an object and make sure its removed from the previous\r\n        // matching ReteTuples\r\n        this.node.retractObject( f0,\r\n                                 this.context,\r\n                                 this.workingMemory );\r\n        assertLength( 2,\r\n                      this.sink.getRetracted() );\r\n\r\n        //assertNull( this.memory.getRightFactHandleMemory().get( f0 ) );\r\n        assertNull( tuple1.getTupleMatches().get( f0 ) );\r\n        assertNull( tuple2.getTupleMatches().get( f0 ) );\r\n\r\n        this.node.retractTuple( tuple2,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        ObjectMatches matches = this.getMatchesFor( tuple2,\r\n                                                    f3 );\r\n        for ( CompositeTupleMatch match = matches.getFirstTupleMatch(); match != null; match = (CompositeTupleMatch) match.getNext() ) {\r\n            assertNotSame( tuple2,\r\n                           match.getTuple() );\r\n        }\r\n\r\n        matches = this.getMatchesFor( tuple2,\r\n                                      f4 );\r\n        for ( CompositeTupleMatch match = matches.getFirstTupleMatch(); match != null; match = (CompositeTupleMatch) match.getNext() ) {\r\n            assertNotSame( tuple2,\r\n                           match.getTuple() );\r\n        }\r\n        assertLength( 4,\r\n                      this.sink.getRetracted() );\r\n    }","id":37200,"modified_method":"/**\r\n     * Test Tuple retraction\r\n     * \r\n     * @throws Exception\r\n     * @throws RetractionException\r\n     */\r\n    public void testRetractTuple() throws Exception {\r\n        // setup 2 tuples 3 fact handles\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        final DefaultFactHandle f1 = (DefaultFactHandle) this.workingMemory.assertObject( \"test1\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        final DefaultFactHandle f2 = (DefaultFactHandle) this.workingMemory.assertObject( \"test2\" );\r\n        final ReteTuple tuple2 = new ReteTuple( f2 );\r\n        this.node.assertTuple( tuple2,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        final DefaultFactHandle f3 = (DefaultFactHandle) this.workingMemory.assertObject( \"test3\" );\r\n        this.node.assertObject( f3,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        final DefaultFactHandle f4 = (DefaultFactHandle) this.workingMemory.assertObject( \"test4\" );\r\n        this.node.assertObject( f4,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        assertLength( 6,\r\n                      this.sink.getAsserted() );\r\n\r\n        \r\n        // Double check the item is in memory\r\n        BetaMemory memory = ( BetaMemory ) this.workingMemory.getNodeMemory( this.node );\r\n        assertTrue( memory.getObjectMemory().contains( f0 ) );\r\n        \r\n        // Retract an object, check propagations  and memory\r\n        this.node.retractObject( f0,\r\n                                 this.context,\r\n                                 this.workingMemory );\r\n        assertLength( 2,\r\n                      this.sink.getRetracted() );\r\n        \r\n        List tuples = new  ArrayList();\r\n        tuples.add( ((Object[]) this.sink.getRetracted().get( 0 ))[0] );\r\n        tuples.add( ((Object[]) this.sink.getRetracted().get( 1 ))[0] );\r\n        \r\n        assertTrue( tuples.contains(  new ReteTuple( tuple1, f0) ) );\r\n        assertTrue( tuples.contains(  new ReteTuple( tuple1, f0) ) );\r\n          \r\n        // Now check the item  is no longer in memory\r\n        assertFalse( memory.getObjectMemory().contains( f0 ) );\r\n\r\n\r\n        this.node.retractTuple( tuple2,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        assertEquals( 4,\r\n                      this.sink.getRetracted().size() );     \r\n      \r\n        tuples = new  ArrayList();\r\n        tuples.add( ((Object[]) this.sink.getRetracted().get( 2 ))[0] );\r\n        tuples.add( ((Object[]) this.sink.getRetracted().get( 3 ))[0] );\r\n      \r\n        assertTrue( tuples.contains(  new ReteTuple( tuple2, f3) ) );\r\n        assertTrue( tuples.contains(  new ReteTuple( tuple2, f4) ) );             \r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void testAttach() throws Exception {\r\n        assertEquals( 15,\r\n                      this.node.getId() );\r\n\r\n        assertLength( 0,\r\n                      this.objectSource.getObjectSinksAsList() );\r\n\r\n        assertLength( 0,\r\n                      this.tupleSource.getTupleSinks() );\r\n\r\n        this.node.attach();\r\n\r\n        assertLength( 1,\r\n                      this.objectSource.getObjectSinksAsList() );\r\n\r\n        assertLength( 1,\r\n                      this.tupleSource.getTupleSinks() );\r\n\r\n        assertSame( this.node,\r\n                    this.objectSource.getObjectSinks().getLastObjectSink() );\r\n\r\n        assertSame( this.node,\r\n                    this.tupleSource.getTupleSinks().get( 0 ) );\r\n    }","id":37201,"modified_method":"public void testAttach() throws Exception {\r\n        Field objectFfield =  ObjectSource.class.getDeclaredField( \"sink\" );\r\n        objectFfield.setAccessible( true );\r\n        ObjectSinkPropagator objectSink = ( ObjectSinkPropagator ) objectFfield.get( this.objectSource );\r\n\r\n        Field tupleField =  TupleSource.class.getDeclaredField( \"sink\" );\r\n        tupleField.setAccessible( true );\r\n        TupleSinkPropagator tupleSink = ( TupleSinkPropagator ) tupleField.get( this.tupleSource );\r\n        \r\n        assertEquals( 15,\r\n                      this.node.getId() );\r\n\r\n        assertNull( objectSink );\r\n        assertNull( tupleSink );\r\n\r\n        this.node.attach();\r\n\r\n        objectSink = ( ObjectSinkPropagator ) objectFfield.get( this.objectSource );\r\n        tupleSink = ( TupleSinkPropagator ) tupleField.get( this.tupleSource );\r\n        \r\n        assertEquals( 1,\r\n                      objectSink.getSinks().length );\r\n\r\n        assertEquals( 1,\r\n                      tupleSink.getSinks().length );\r\n\r\n        assertSame( this.node,\r\n                    objectSink.getSinks()[0]);\r\n\r\n        assertSame( this.node,\r\n                    tupleSink.getSinks()[0] );\r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"/**\r\n     * Test assertion with both Objects and Tuples\r\n     * \r\n     * @throws Exception\r\n     */\r\n    public void testAssertPropagations() throws Exception {\r\n        // assert first right object\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        // assert tuple, should add left memory should be 2\r\n        final DefaultFactHandle f1 = new DefaultFactHandle( 1,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        // check bi directional match to resulting TupleMatch\r\n        final Map map = tuple1.getTupleMatches();\r\n        final TupleMatch match = (TupleMatch) map.get( f0 );\r\n\r\n        ObjectMatches matches = (ObjectMatches) this.memory.rightObjectIterator( this.workingMemory,\r\n                                                                                 tuple1 ).next();\r\n        assertSame( match,\r\n                    matches.getFirstTupleMatch() );\r\n\r\n        // check reference form TupleMatch to propgated ReteTuple\r\n        assertSame( match.getJoinedTuples().get( 0 ),\r\n                    ((Object[]) this.sink.getAsserted().get( 0 ))[0] );\r\n\r\n        // check objectmatches correct references second asserted tuple\r\n        final DefaultFactHandle f2 = new DefaultFactHandle( 2,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple2 = new ReteTuple( f2 );\r\n        this.node.assertTuple( tuple2,\r\n                               this.context,\r\n                               this.workingMemory );\r\n\r\n        assertSame( (tuple2.getTupleMatches()).get( f0 ),\r\n                    matches.getFirstTupleMatch().getNext() );\r\n\r\n        final DefaultFactHandle f3 = (DefaultFactHandle) this.workingMemory.assertObject( \"test2\" );\r\n        this.node.assertObject( f3,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        matches = getMatchesFor( tuple1,\r\n                                 f3 );\r\n        assertSame( (tuple1.getTupleMatches()).get( f3 ),\r\n                    matches.getFirstTupleMatch() );\r\n        assertSame( (tuple2.getTupleMatches()).get( f3 ),\r\n                    matches.getFirstTupleMatch().getNext() );\r\n    }","id":37202,"modified_method":"/**\r\n     * Test assertion with both Objects and Tuples\r\n     * \r\n     * @throws Exception\r\n     */\r\n    public void testAssertPropagations() throws Exception {\r\n        // assert first right object\r\n        final DefaultFactHandle f0 = (DefaultFactHandle) this.workingMemory.assertObject( \"test0\" );\r\n        this.node.assertObject( f0,\r\n                                this.context,\r\n                                this.workingMemory );\r\n\r\n        // assert tuple, should add left memory should be 2\r\n        final DefaultFactHandle f1 = new DefaultFactHandle( 1,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple1 = new ReteTuple( f1 );\r\n        this.node.assertTuple( tuple1,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        \r\n        assertEquals( 1, this.sink.getAsserted().size() );\r\n\r\n        assertEquals(  new ReteTuple( tuple1, f0), ((Object[]) this.sink.getAsserted().get( 0 ))[0]);\r\n        \r\n        \r\n        final DefaultFactHandle f2 = new DefaultFactHandle( 2,\r\n                                                            \"cheese\" );\r\n        final ReteTuple tuple2 = new ReteTuple( f2 );\r\n        this.node.assertTuple( tuple2,\r\n                               this.context,\r\n                               this.workingMemory );\r\n        \r\n        assertEquals( 2, this.sink.getAsserted().size() );  \r\n        assertEquals(  new ReteTuple( tuple2, f0), ((Object[]) this.sink.getAsserted().get( 1 ))[0]);\r\n\r\n        \r\n        final DefaultFactHandle f3 = (DefaultFactHandle) this.workingMemory.assertObject( \"test2\" );\r\n        this.node.assertObject( f3,\r\n                                this.context,\r\n                                this.workingMemory );\r\n        \r\n        assertEquals( 4, this.sink.getAsserted().size() );                 \r\n        \r\n        List tuples = new  ArrayList();\r\n        tuples.add( ((Object[]) this.sink.getAsserted().get( 2 ))[0] );\r\n        tuples.add( ((Object[]) this.sink.getAsserted().get( 3 ))[0] );\r\n        \r\n        assertTrue( tuples.contains(  new ReteTuple( tuple1, f3) ) );\r\n        assertTrue( tuples.contains(  new ReteTuple( tuple2, f3) ) );     \r\n    }","commit_id":"a797f5ec874531c93db0ed6dea2a54b1f6253950","url":"https://github.com/droolsjbpm/drools"},{"original_method":"public void testNotWithConstraint() throws Exception {\n        RuleParser parser = parseResource( \"not_with_constraint.drl\" );\n        parser.compilation_unit();\n        \n        PackageDescr pack = parser.getPackageDescr();\n        assertEquals(1, pack.getRules().size());\n        \n        RuleDescr rule = (RuleDescr) pack.getRules().get( 0 );\n        \n        assertEquals(1, rule.getLhs().getDescrs().size());\n        NotDescr not = (NotDescr) rule.getLhs().getDescrs().get( 0 );\n        ColumnDescr column = (ColumnDescr) not.getDescrs().get( 0 );\n        assertEquals( 1, column.getDescrs().size() );\n        \n        BoundVariableDescr boundVariable = (BoundVariableDescr) column.getDescrs().get( 0 );\n        assertEquals( \"price\", boundVariable.getFieldName() );\n        assertEquals( \"==\", boundVariable.getEvaluator() );\n        assertEquals( \"five\", boundVariable.getIdentifier() );\n        \n        \n    }","id":37203,"modified_method":"public void testNotWithConstraint() throws Exception {\n        RuleParser parser = parseResource( \"not_with_constraint.drl\" );\n        parser.compilation_unit();\n        \n        PackageDescr pack = parser.getPackageDescr();\n        assertEquals(1, pack.getRules().size());\n        \n        RuleDescr rule = (RuleDescr) pack.getRules().get( 0 );\n        assertEquals(2, rule.getLhs().getDescrs().size());\n        \n        \n        ColumnDescr column = (ColumnDescr) rule.getLhs().getDescrs().get( 0 );\n        FieldBindingDescr fieldBinding = (FieldBindingDescr) column.getDescrs().get( 0 );\n        assertEquals( \"$likes\", fieldBinding.getIdentifier() );\n        \n        NotDescr not = (NotDescr) rule.getLhs().getDescrs().get( 1 );\n        column = (ColumnDescr) not.getDescrs().get( 0 );\n        BoundVariableDescr boundVariable = (BoundVariableDescr) column.getDescrs().get( 0 );\n        assertEquals( \"type\", boundVariable.getFieldName() );\n        assertEquals( \"==\", boundVariable.getEvaluator() );\n        assertEquals( \"$likes\", boundVariable.getIdentifier() );\n        \n        \n    }","commit_id":"edaa3ba0765740f90df8bb43dfcb32764536a216","url":"https://github.com/droolsjbpm/drools"},{"original_method":"@Override\n        public void put( Expression target, FieldReference field, Expression value )\n        {\n            callSuperIfNecessary( );\n\n            target.accept( expressionVisitor );\n            value.accept( expressionVisitor );\n            methodVisitor.visitFieldInsn(PUTFIELD, byteCodeName(field.owner().name()) , field.name(), typeName( field.type() ));\n\n        }","id":37204,"modified_method":"@Override\n        public void put( Expression target, FieldReference field, Expression value )\n        {\n            callSuperIfNecessary( );\n\n            target.accept( expressionVisitor );\n            value.accept( expressionVisitor );\n            methodVisitor\n                    .visitFieldInsn( PUTFIELD, byteCodeName( field.owner() ), field.name(), typeName( field.type() ) );\n\n        }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n        public void returns( Expression value )\n        {\n            callSuperIfNecessary( );\n        }","id":37205,"modified_method":"@Override\n        public void returns( Expression value )\n        {\n            callSuperIfNecessary( );\n\n            value.accept( expressionVisitor );\n            switch ( declaration.returnType().simpleName() )\n            {\n            case \"int\":\n            case \"byte\":\n            case \"short\":\n            case \"char\":\n                methodVisitor.visitInsn( IRETURN );\n                break;\n            case \"long\":\n                methodVisitor.visitInsn( LRETURN );\n                break;\n            case \"float\":\n                methodVisitor.visitInsn( FRETURN );\n                break;\n            case \"double\":\n                methodVisitor.visitInsn( DRETURN );\n                break;\n            default:\n                methodVisitor.visitInsn( ARETURN );\n            }\n        }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"private void callSuper()\n        {\n            methodVisitor.visitVarInsn( ALOAD, 0 );\n            methodVisitor.visitMethodInsn( INVOKESPECIAL, byteCodeName( base.name() ), \"<init>\", \"()V\", false );\n            calledSuper = true;\n        }","id":37206,"modified_method":"private void callSuper()\n        {\n            methodVisitor.visitVarInsn( ALOAD, 0 );\n            methodVisitor.visitMethodInsn( INVOKESPECIAL, byteCodeName( base ), \"<init>\", \"()V\", false );\n            calledSuper = true;\n        }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n        public void invoke( Expression target, MethodReference method, Expression[] arguments )\n        {\n            target.accept( this );\n            for ( Expression argument : arguments )\n            {\n                argument.accept( this );\n            }\n            methodVisitor.visitMethodInsn(INVOKESPECIAL, byteCodeName( method.owner().name() ), method.name(), desc(method), false);\n        }","id":37207,"modified_method":"@Override\n        public void invoke( Expression target, MethodReference method, Expression[] arguments )\n        {\n            target.accept( this );\n            for ( Expression argument : arguments )\n            {\n                argument.accept( this );\n            }\n            methodVisitor.visitMethodInsn( INVOKESPECIAL, byteCodeName( method.owner() ), method.name(), desc( method ),\n                    false );\n        }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"ClassByteCodeWriter(TypeReference type, TypeReference base, TypeReference[] interfaces)\n    {\n        this.classWriter = new ClassWriter( ClassWriter.COMPUTE_MAXS );\n        String[] iNames = new String[interfaces.length];\n        for ( int i = 0; i < interfaces.length; i++ )\n        {\n            iNames[i] = byteCodeName( interfaces[i].name() );\n        }\n        classWriter.visit( V1_8, ACC_PUBLIC + ACC_SUPER, byteCodeName( type.name() ), signature( type ),\n                byteCodeName( base.name() ), iNames.length != 0 ? iNames : null );\n        this.type = type;\n        this.base = base;\n    }","id":37208,"modified_method":"ClassByteCodeWriter( TypeReference type, TypeReference base, TypeReference[] interfaces )\n    {\n        this.classWriter = new ClassWriter( ClassWriter.COMPUTE_MAXS );\n        String[] iNames = new String[interfaces.length];\n        for ( int i = 0; i < interfaces.length; i++ )\n        {\n            iNames[i] = byteCodeName( interfaces[i].name() );\n        }\n        classWriter.visit( V1_8, ACC_PUBLIC + ACC_SUPER, byteCodeName( type ), signature( type ),\n                byteCodeName( base ), iNames.length != 0 ? iNames : null );\n        this.type = type;\n        this.base = base;\n    }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    public void done()\n    {\n        if ( !staticFields.isEmpty() )\n        {\n            MethodVisitor methodVisitor = classWriter.visitMethod( ACC_STATIC, \"<clinit>\", \"()V\", null, null );\n            ByteCodeExpressionVisitor expressionVisitor = new ByteCodeExpressionVisitor( methodVisitor );\n            methodVisitor.visitCode();\n            for ( Map.Entry<FieldReference,Expression> entry : staticFields.entrySet() )\n            {\n                FieldReference field = entry.getKey();\n                entry.getValue().accept( expressionVisitor );\n                methodVisitor.visitFieldInsn(PUTSTATIC, byteCodeName( field.owner().name() ),\n                        field.name(), signature( field.type() ));\n            }\n            methodVisitor.visitInsn( RETURN );\n            methodVisitor.visitMaxs( 0, 0 );\n            methodVisitor.visitEnd();\n        }\n        classWriter.visitEnd();\n    }","id":37209,"modified_method":"@Override\n    public void done()\n    {\n        if ( !staticFields.isEmpty() )\n        {\n            MethodVisitor methodVisitor = classWriter.visitMethod( ACC_STATIC, \"<clinit>\", \"()V\", null, null );\n            ByteCodeExpressionVisitor expressionVisitor = new ByteCodeExpressionVisitor( methodVisitor );\n            methodVisitor.visitCode();\n            for ( Map.Entry<FieldReference,Expression> entry : staticFields.entrySet() )\n            {\n                FieldReference field = entry.getKey();\n                entry.getValue().accept( expressionVisitor );\n                methodVisitor.visitFieldInsn( PUTSTATIC, byteCodeName( field.owner() ),\n                        field.name(), signature( field.type() ) );\n            }\n            methodVisitor.visitInsn( RETURN );\n            methodVisitor.visitMaxs( 0, 0 );\n            methodVisitor.visitEnd();\n        }\n        classWriter.visitEnd();\n    }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n        public void getField( Expression target, FieldReference field )\n        {\n\n        }","id":37210,"modified_method":"@Override\n        public void getField( Expression target, FieldReference field )\n        {\n            target.accept( this );\n            methodVisitor\n                    .visitFieldInsn( GETFIELD, byteCodeName( field.owner() ), field.name(), typeName( field.type() ) );\n\n        }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void shouldGenerateMethodReturningFieldValue() throws Throwable\n    {\n        // given\n        ClassHandle handle;\n        try ( ClassGenerator simple = generateClass( \"SimpleClass\" ) )\n        {\n            FieldReference value = simple.field( String.class, \"value\" );\n            try ( CodeBlock ctor = simple.generateConstructor( param( String.class, \"value\" ) ) )\n            {\n                ctor.put( ctor.self(), value, ctor.load( \"value\" ) );\n            }\n            simple.generate( MethodTemplate.method( String.class, \"value\" )\n                    .returns( ExpressionTemplate.get( self(), String.class, \"value\" ) )\n                    .build() );\n            handle = simple.handle();\n        }\n\n        // when\n        Object instance = constructor( handle.loadClass(), String.class ).invoke( \"Hello World\" );\n\n        // then\n        assertEquals( \"Hello World\", instanceMethod( instance, \"value\" ).invoke() );\n    }","id":37211,"modified_method":"@Test\n    public void shouldGenerateMethodReturningFieldValue() throws Throwable\n    {\n        assertMethodReturningField( byte.class, (byte) 42 );\n        assertMethodReturningField( short.class, (short) 42 );\n        assertMethodReturningField( char.class, (char) 42 );\n        assertMethodReturningField( int.class, 42 );\n        assertMethodReturningField( long.class, 42L );\n        assertMethodReturningField( float.class, 42F );\n        assertMethodReturningField( double.class, 42D );\n        assertMethodReturningField( String.class, \"42\" );\n        assertMethodReturningField( int[].class, new int[]{42} );\n    }","commit_id":"32b85b23e1ad7fb83a612a52265338e168f41fb1","url":"https://github.com/neo4j/neo4j"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n\n        final String eventID = post.get(\"eventID\", \"\");\n        final boolean authenticated = sb.adminAuthenticated(header) >= 2;\n        final int item = post.getInt(\"item\", -1);\n        final RequestHeader.FileType fileType = header.fileType();\n\n        // default settings for blank item\n        prop.put(\"content\", \"0\");\n        prop.put(\"rss\", \"0\");\n        prop.put(\"references\", \"0\");\n        prop.put(\"rssreferences\", \"0\");\n        prop.put(\"dynamic\", \"0\");\n\n        // find search event\n        final SearchEvent theSearch = SearchEventCache.getEvent(eventID);\n        if (theSearch == null) {\n            // the event does not exist, show empty page\n            return prop;\n        }\n\n        // dynamically update count values\n        prop.put(\"offset\", theSearch.query.neededResults() - theSearch.query.itemsPerPage() + 1);\n        prop.put(\"itemscount\", Formatter.number(Math.min((item < 0) ? theSearch.query.neededResults() : item + 1, theSearch.getResultCount())));\n        prop.put(\"itemsperpage\", Formatter.number(theSearch.query.itemsPerPage));\n        prop.put(\"totalcount\", Formatter.number(theSearch.getResultCount(), true));\n        prop.put(\"localResourceSize\", Formatter.number(theSearch.local_rwi_stored.get() + theSearch.local_solr_stored.get(), true));\n        prop.put(\"remoteResourceSize\", Formatter.number(theSearch.remote_rwi_stored.get() + theSearch.remote_solr_stored.get(), true));\n        prop.put(\"remoteIndexCount\", Formatter.number(theSearch.remote_rwi_available.get() + theSearch.remote_solr_available.get(), true));\n        prop.put(\"remotePeerCount\", Formatter.number(theSearch.remote_rwi_peerCount.get() + theSearch.remote_solr_peerCount.get(), true));\n        prop.put(\"navurlBase\", QueryParams.navurlBase(RequestHeader.FileType.HTML, theSearch.query, null, false).toString());\n        final String target_special_pattern = sb.getConfig(SwitchboardConstants.SEARCH_TARGET_SPECIAL_PATTERN, \"\");\n\n        long timeout = item == 0 ? 10000 : (theSearch.query.isLocal() ? 1000 : 3000);\n        \n        if (theSearch.query.contentdom == Classification.ContentDomain.TEXT || theSearch.query.contentdom == Classification.ContentDomain.ALL) {\n            // text search\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item, timeout);\n            if (result == null) return prop; // no content\n            final String resultUrlstring = result.urlstring();\n            final DigestURL resultURL = result.url();\n            final String target = sb.getConfig(resultUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n\n            final int port = resultURL.getPort();\n            DigestURL faviconURL = null;\n            if ((fileType == FileType.HTML || fileType == FileType.JSON) && !sb.isIntranetMode()) try {\n                faviconURL = new DigestURL(resultURL.getProtocol() + \"://\" + resultURL.getHost() + ((port != -1) ? (\":\" + port) : \"\") + \"/favicon.ico\");\n            } catch (final MalformedURLException e1) {\n                ConcurrentLog.logException(e1);\n                faviconURL = null;\n            }\n            final String resource = theSearch.query.domType.toString();\n            final String origQ = theSearch.query.getQueryGoal().getQueryString(true);\n            prop.put(\"content\", 1); // switch on specific content\n            prop.put(\"content_authorized\", authenticated ? \"1\" : \"0\");\n            final String urlhash = ASCII.String(result.hash());\n            prop.put(\"content_authorized_bookmark\", sb.tables.bookmarks.hasBookmark(\"admin\", urlhash) ? \"0\" : \"1\");\n            prop.putHTML(\"content_authorized_bookmark_bookmarklink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&bookmarkref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_recommend\", (sb.peers.newsPool.getSpecific(NewsPool.OUTGOING_DB, NewsPool.CATEGORY_SURFTIPP_ADD, \"url\", resultUrlstring) == null) ? \"1\" : \"0\");\n            prop.putHTML(\"content_authorized_recommend_deletelink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&deleteref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.putHTML(\"content_authorized_recommend_recommendlink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&recommendref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_urlhash\", urlhash);\n            prop.putHTML(\"content_title\", result.title());\n            prop.putXML(\"content_title-xml\", result.title());\n            prop.putJSON(\"content_title-json\", result.title());\n            prop.putHTML(\"content_showPictures_link\", resultUrlstring);\n            //prop.putHTML(\"content_link\", resultUrlstring);\n\n// START interaction\n            String modifyURL = resultUrlstring;\n\t\t\tif (sb.getConfigBool(\"proxyURL.useforresults\", false) && sb.getConfigBool(\"proxyURL\", false)) {\n\t\t\t\t// check if url is allowed to view\n\t\t\t\tif (sb.getConfig(\"proxyURL.rewriteURLs\", \"all\").equals(\"all\")) {\n\t\t\t\t\tmodifyURL = \"./proxy.html?url=\"+modifyURL;\n\t\t\t\t}\n\n\t\t\t\t// check if url is allowed to view\n\t\t\t\tif (sb.getConfig(\"proxyURL.rewriteURLs\", \"all\").equals(\"domainlist\")) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif (sb.crawlStacker.urlInAcceptedDomain(new DigestURL (modifyURL)) == null) {\n\t\t\t\t\t\t\tmodifyURL = \"./proxy.html?url=\"+modifyURL;\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (final MalformedURLException e) {\n\t\t\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (sb.getConfig(\"proxyURL.rewriteURLs\", \"all\").equals(\"yacy\")) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif ((new DigestURL (modifyURL).getHost().endsWith(\".yacy\"))) {\n\t\t\t\t\t\t\tmodifyURL = \"./proxy.html?url=\"+modifyURL;\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (final MalformedURLException e) {\n\t\t\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\t\t\te.printStackTrace();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n            prop.putXML(\"content_link\", modifyURL); // putXML for rss\n//            prop.putHTML(\"content_value\", Interaction.TripleGet(result.urlstring(), \"http://virtual.x/hasvalue\", \"anonymous\"));\n// END interaction\n\n            boolean isAtomFeed = header.get(HeaderFramework.CONNECTION_PROP_EXT, \"\").equals(\"atom\");\n            String resultFileName = resultURL.getFileName();\n            prop.putHTML(\"content_target\", target);\n            //if (faviconURL != null && fileType == FileType.HTML) sb.loader.loadIfNotExistBackground(faviconURL, 1024 * 1024 * 10, null, ClientIdentification.yacyIntranetCrawlerAgent);\n            prop.putHTML(\"content_faviconCode\", URLLicense.aquireLicense(faviconURL)); // acquire license for favicon url loading\n            prop.put(\"content_urlhash\", urlhash);\n            prop.put(\"content_ranking\", Float.toString(result.score()));\n            if (fileType == FileType.HTML) { // html template specific settings\n                prop.put(\"content_showDate\", sb.getConfigBool(\"search.result.show.date\", true) ? 1 : 0);\n                prop.put(\"content_showSize\", sb.getConfigBool(\"search.result.show.size\", true) ? 1 : 0);\n                prop.put(\"content_showMetadata\", sb.getConfigBool(\"search.result.show.metadata\", true) ? 1 : 0);\n                prop.put(\"content_showParser\", sb.getConfigBool(\"search.result.show.parser\", true) ? 1 : 0);\n                prop.put(\"content_showCitation\", sb.getConfigBool(\"search.result.show.citation\", true) ? 1 : 0);\n                prop.put(\"content_showPictures\", sb.getConfigBool(\"search.result.show.pictures\", true) ? 1 : 0);\n                prop.put(\"content_showCache\", sb.getConfigBool(\"search.result.show.cache\", true) && Cache.has(resultURL.hash()) ? 1 : 0);\n                prop.put(\"content_showProxy\", sb.getConfigBool(\"search.result.show.proxy\", true) ? 1 : 0);\n                prop.put(\"content_showHostBrowser\", sb.getConfigBool(\"search.result.show.hostbrowser\", true) ? 1 : 0);\n                prop.put(\"content_showVocabulary\", sb.getConfigBool(\"search.result.show.vocabulary\", true) ? 1 : 0);\n\n                prop.put(\"content_showDate_date\", GenericFormatter.RFC1123_SHORT_FORMATTER.format(result.modified()));\n                prop.putHTML(\"content_showSize_sizename\", RSSMessage.sizename(result.filesize()));\n                prop.put(\"content_showMetadata_urlhash\", urlhash);\n                prop.put(\"content_showParser_urlhash\", urlhash);\n                prop.put(\"content_showCitation_urlhash\", urlhash);\n                prop.putHTML(\"content_showPictures_former\", origQ);\n                prop.put(\"content_showCache_link\", resultUrlstring);\n                prop.put(\"content_showProxy_link\", resultUrlstring);\n                prop.put(\"content_showHostBrowser_link\", resultUrlstring);\n                if (sb.getConfigBool(\"search.result.show.vocabulary\", true)) {\n                    URIMetadataNode node = result.getNode();\n                    int c = 0;\n                    for (Map.Entry<String, Object> entry: node.entrySet()) {\n                        String key = entry.getKey();\n                        if (key.startsWith(\"vocabulary_\") && key.endsWith(\"_sxt\")) {\n                            @SuppressWarnings(\"unchecked\")\n                            Collection<String> terms = (Collection<String>) entry.getValue();\n                            prop.putHTML(\"content_showVocabulary_vocabulary_\" + c + \"_name\", key.substring(11, key.length() - 4));\n                            prop.putHTML(\"content_showVocabulary_vocabulary_\" + c + \"_terms\", terms.toString());\n                            c++;\n                        }\n                    }\n                    prop.put(\"content_showVocabulary_vocabulary\", c);\n                    prop.put(\"content_showVocabulary\", 1);\n                } else {\n                    prop.put(\"content_showVocabulary_vocabulary\", 0);\n                    prop.put(\"content_showVocabulary\", 0);\n                }\n            }\n            prop.put(\"content_urlhexhash\", Seed.b64Hash2hexHash(urlhash));\n            prop.putHTML(\"content_urlname\", nxTools.shortenURLString(result.urlname(), MAX_URL_LENGTH));\n            prop.put(\"content_date822\", isAtomFeed ? ISO8601Formatter.FORMATTER.format(result.modified()) : HeaderFramework.formatRFC1123(result.modified()));\n            //prop.put(\"content_ybr\", RankingProcess.ybr(result.hash()));\n            prop.putHTML(\"content_size\", Integer.toString(result.filesize())); // we don't use putNUM here because that number shall be usable as sorting key. To print the size, use 'sizename'\n            prop.putHTML(\"content_sizename\", RSSMessage.sizename(result.filesize()));            \n            prop.putHTML(\"content_host\", resultURL.getHost() == null ? \"\" : resultURL.getHost());\n            prop.putXML(\"content_file\", resultFileName); // putXML for rss\n            prop.putXML(\"content_path\", resultURL.getPath()); // putXML for rss\n            prop.put(\"content_nl\", (item == theSearch.query.offset) ? 0 : 1);\n            prop.putHTML(\"content_publisher\", result.publisher());\n            prop.putHTML(\"content_creator\", result.creator());// author\n            prop.putHTML(\"content_subject\", result.subject());\n            final Iterator<String> query = theSearch.query.getQueryGoal().getIncludeStrings();\n            final StringBuilder s = new StringBuilder(theSearch.query.getQueryGoal().getIncludeSize() * 20);\n            while (query.hasNext()) s.append('+').append(query.next());\n            final String words = (s.length() > 0) ? s.substring(1) : \"\";\n            prop.putHTML(\"content_words\", words);\n            prop.putHTML(\"content_showParser_words\", words);\n            prop.putHTML(\"content_former\", origQ);\n            final TextSnippet snippet = result.textSnippet();\n            final String desc = (snippet == null) ? \"\" : snippet.descriptionline(theSearch.query.getQueryGoal());\n            prop.put(\"content_description\", desc);\n            prop.putXML(\"content_description-xml\", desc);\n            prop.putJSON(\"content_description-json\", desc);\n            prop.put(\"content_mimetype\",result.getNode().mime()); // for atom <link> type attribute\n            final HeuristicResult heuristic = theSearch.getHeuristic(result.hash());\n            if (heuristic == null) {\n                prop.put(\"content_heuristic\", 0);\n            } else {\n                if (heuristic.redundant) {\n                    prop.put(\"content_heuristic\", 1);\n                } else {\n                    prop.put(\"content_heuristic\", 2);\n                }\n                prop.put(\"content_heuristic_name\", heuristic.heuristicName);\n            }\n            EventTracker.update(EventTracker.EClass.SEARCH, new ProfilingGraph.EventSearch(theSearch.query.id(true), SearchEventType.FINALIZATION, \"\" + item, 0, 0), false);\n            final String ext = MultiProtocolURL.getFileExtension(resultFileName);\n            if (MultiProtocolURL.isImage(ext)) {\n                final String license = URLLicense.aquireLicense(resultURL);\n                prop.put(\"content_code\", license);\n            } else {\n                prop.put(\"content_code\", \"\");\n            }\n            if (result.lat() == 0.0d || result.lon() == 0.0d) {\n                prop.put(\"content_loc\", 0);\n            } else {\n                prop.put(\"content_loc\", 1);\n                prop.put(\"content_loc_lat\", result.lat());\n                prop.put(\"content_loc_lon\", result.lon());\n            }\n            final boolean clustersearch = sb.isRobinsonMode() && sb.getConfig(SwitchboardConstants.CLUSTER_MODE, \"\").equals(SwitchboardConstants.CLUSTER_MODE_PUBLIC_CLUSTER);\n            final boolean indexReceiveGranted = sb.getConfigBool(SwitchboardConstants.INDEX_RECEIVE_ALLOW_SEARCH, true) || clustersearch;\n            boolean p2pmode = sb.peers != null && sb.peers.sizeConnected() > 0 && indexReceiveGranted;\n            boolean stealthmode = p2pmode && theSearch.query.isLocal();\n            if ((sb.getConfigBool(SwitchboardConstants.HEURISTIC_SEARCHRESULTS, false) ||\n                (sb.getConfigBool(SwitchboardConstants.GREEDYLEARNING_ACTIVE, false) && sb.getConfigBool(SwitchboardConstants.GREEDYLEARNING_ENABLED, false) && Memory.load() < 1.0)) &&\n                !stealthmode) sb.heuristicSearchResults(resultUrlstring);\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        if (theSearch.query.contentdom == Classification.ContentDomain.IMAGE) {\n            // image search; shows thumbnails\n\n            prop.put(\"content\", theSearch.query.contentdom.getCode() + 1); // switch on specific content\n            SearchEvent.ImageResult image = null;\n            try {\n                image = theSearch.oneImageResult(item, timeout);\n                final String imageUrlstring = image.imageUrl.toNormalform(true);\n                final String target = sb.getConfig(imageUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n\n                final String license = URLLicense.aquireLicense(image.imageUrl); // this is just the license key to get the image forwarded through the YaCy thumbnail viewer, not an actual lawful license\n                //sb.loader.loadIfNotExistBackground(image.imageUrl, 1024 * 1024 * 10, null, ClientIdentification.yacyIntranetCrawlerAgent);\n                prop.putHTML(\"content_item_hrefCache\", \"/ViewImage.png?maxwidth=128&maxheight=128&isStatic=true&quadratic=&url=\" + imageUrlstring);\n                prop.putHTML(\"content_item_href\", imageUrlstring);\n                prop.putHTML(\"content_item_target\", target);\n                prop.put(\"content_item_code\", license);\n                prop.putHTML(\"content_item_name\", shorten(image.imagetext, MAX_NAME_LENGTH));\n                prop.put(\"content_item_mimetype\", image.mimetype);\n                prop.put(\"content_item_fileSize\", 0);\n                prop.put(\"content_item_width\", image.width);\n                prop.put(\"content_item_height\", image.height);\n                prop.put(\"content_item_attr\", \"\"/*(ms.attr.equals(\"-1 x -1\")) ? \"\" : \"(\" + ms.attr + \")\"*/); // attributes, here: original size of image\n                prop.put(\"content_item_urlhash\", ASCII.String(image.imageUrl.hash()));\n                prop.put(\"content_item_source\", image.sourceUrl.toNormalform(true));\n                prop.putXML(\"content_item_source-xml\", image.sourceUrl.toNormalform(true));\n                prop.put(\"content_item_sourcedom\", image.sourceUrl.getHost());\n                prop.put(\"content_item_nl\", (item == theSearch.query.offset) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            } catch (MalformedURLException e) {\n                prop.put(\"content_item\", \"0\");\n            }\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        if ((theSearch.query.contentdom == ContentDomain.AUDIO) ||\n            (theSearch.query.contentdom == ContentDomain.VIDEO) ||\n            (theSearch.query.contentdom == ContentDomain.APP)) {\n            // any other media content\n\n            // generate result object\n            final ResultEntry ms = theSearch.oneResult(item, timeout);\n            prop.put(\"content\", theSearch.query.contentdom.getCode() + 1); // switch on specific content\n            if (ms == null) {\n                prop.put(\"content_item\", \"0\");\n            } else {\n                final String resultUrlstring = ms.url().toNormalform(true);\n                final String target = sb.getConfig(resultUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n                prop.putHTML(\"content_item_href\", resultUrlstring);\n                prop.putHTML(\"content_item_hrefshort\", nxTools.shortenURLString(resultUrlstring, MAX_URL_LENGTH));\n                prop.putHTML(\"content_item_target\", target);\n                prop.putHTML(\"content_item_name\", shorten(ms.title(), MAX_NAME_LENGTH));\n                prop.put(\"content_item_col\", (item % 2 == 0) ? \"0\" : \"1\");\n                prop.put(\"content_item_nl\", (item == theSearch.query.offset) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            }\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        return prop;\n    }","id":37212,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n\n        final String eventID = post.get(\"eventID\", \"\");\n        final boolean authenticated = sb.adminAuthenticated(header) >= 2;\n        final int item = post.getInt(\"item\", -1);\n        final RequestHeader.FileType fileType = header.fileType();\n\n        // default settings for blank item\n        prop.put(\"content\", \"0\");\n        prop.put(\"rss\", \"0\");\n        prop.put(\"references\", \"0\");\n        prop.put(\"rssreferences\", \"0\");\n        prop.put(\"dynamic\", \"0\");\n\n        // find search event\n        final SearchEvent theSearch = SearchEventCache.getEvent(eventID);\n        if (theSearch == null) {\n            // the event does not exist, show empty page\n            return prop;\n        }\n\n        // dynamically update count values\n        prop.put(\"offset\", theSearch.query.neededResults() - theSearch.query.itemsPerPage() + 1);\n        prop.put(\"itemscount\", Formatter.number(Math.min((item < 0) ? theSearch.query.neededResults() : item + 1, theSearch.getResultCount())));\n        prop.put(\"itemsperpage\", Formatter.number(theSearch.query.itemsPerPage));\n        prop.put(\"totalcount\", Formatter.number(theSearch.getResultCount(), true));\n        prop.put(\"localResourceSize\", Formatter.number(theSearch.local_rwi_stored.get() + theSearch.local_solr_stored.get(), true));\n        prop.put(\"remoteResourceSize\", Formatter.number(theSearch.remote_rwi_stored.get() + theSearch.remote_solr_stored.get(), true));\n        prop.put(\"remoteIndexCount\", Formatter.number(theSearch.remote_rwi_available.get() + theSearch.remote_solr_available.get(), true));\n        prop.put(\"remotePeerCount\", Formatter.number(theSearch.remote_rwi_peerCount.get() + theSearch.remote_solr_peerCount.get(), true));\n        prop.put(\"navurlBase\", QueryParams.navurlBase(RequestHeader.FileType.HTML, theSearch.query, null, false).toString());\n        final String target_special_pattern = sb.getConfig(SwitchboardConstants.SEARCH_TARGET_SPECIAL_PATTERN, \"\");\n\n        long timeout = item == 0 ? 10000 : (theSearch.query.isLocal() ? 1000 : 3000);\n        \n        if (theSearch.query.contentdom == Classification.ContentDomain.TEXT || theSearch.query.contentdom == Classification.ContentDomain.ALL) {\n            // text search\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item, timeout);\n            if (result == null) return prop; // no content\n            final String resultUrlstring = result.urlstring();\n            final DigestURL resultURL = result.url();\n            final String target = sb.getConfig(resultUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n\n            final int port = resultURL.getPort();\n            DigestURL faviconURL = null;\n            if ((fileType == FileType.HTML || fileType == FileType.JSON) && !sb.isIntranetMode()) try {\n                faviconURL = new DigestURL(resultURL.getProtocol() + \"://\" + resultURL.getHost() + ((port != -1) ? (\":\" + port) : \"\") + \"/favicon.ico\");\n            } catch (final MalformedURLException e1) {\n                ConcurrentLog.logException(e1);\n                faviconURL = null;\n            }\n            final String resource = theSearch.query.domType.toString();\n            final String origQ = theSearch.query.getQueryGoal().getQueryString(true);\n            prop.put(\"content\", 1); // switch on specific content\n            prop.put(\"content_authorized\", authenticated ? \"1\" : \"0\");\n            final String urlhash = ASCII.String(result.hash());\n            prop.put(\"content_authorized_bookmark\", sb.tables.bookmarks.hasBookmark(\"admin\", urlhash) ? \"0\" : \"1\");\n            prop.putHTML(\"content_authorized_bookmark_bookmarklink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&bookmarkref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_recommend\", (sb.peers.newsPool.getSpecific(NewsPool.OUTGOING_DB, NewsPool.CATEGORY_SURFTIPP_ADD, \"url\", resultUrlstring) == null) ? \"1\" : \"0\");\n            prop.putHTML(\"content_authorized_recommend_deletelink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&deleteref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.putHTML(\"content_authorized_recommend_recommendlink\", \"yacysearch.html?query=\" + origQ.replace(' ', '+') + \"&Enter=Search&count=\" + theSearch.query.itemsPerPage() + \"&offset=\" + (theSearch.query.neededResults() - theSearch.query.itemsPerPage()) + \"&order=\" + crypt.simpleEncode(theSearch.query.ranking.toExternalString()) + \"&resource=\" + resource + \"&time=3&recommendref=\" + urlhash + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_urlhash\", urlhash);\n            prop.putHTML(\"content_title\", result.title());\n            prop.putXML(\"content_title-xml\", result.title());\n            prop.putJSON(\"content_title-json\", result.title());\n            prop.putHTML(\"content_showPictures_link\", resultUrlstring);\n            //prop.putHTML(\"content_link\", resultUrlstring);\n\n// START interaction\n            if (sb.getConfigBool(\"proxyURL.useforresults\", false) && sb.getConfigBool(\"proxyURL\", false)) {\n                String modifyURL = resultUrlstring;\n                // check if url is allowed to view\n                final String tmprewritecfg = sb.getConfig(\"proxyURL.rewriteURLs\", \"all\");\n                if (tmprewritecfg.equals(\"all\")) {\n                    modifyURL = \"./proxy.html?url=\" + resultUrlstring;\n                } else if (tmprewritecfg.equals(\"domainlist\")) { // check if url is allowed to view\n                    try {\n                        if (sb.crawlStacker.urlInAcceptedDomain(new DigestURL(resultUrlstring)) == null) {\n                            modifyURL = \"./proxy.html?url=\" + resultUrlstring;\n                        }\n                    } catch (final MalformedURLException e) {\n                        ConcurrentLog.logException(e);\n                    }\n                } else if (tmprewritecfg.equals(\"yacy\")) {\n                    try {\n                        if ((new DigestURL(resultUrlstring).getHost().endsWith(\".yacy\"))) {\n                            modifyURL = \"./proxy.html?url=\" + resultUrlstring;\n                        }\n                    } catch (final MalformedURLException e) {\n                        ConcurrentLog.logException(e);\n                    }\n                }\n                prop.putXML(\"content_link\", modifyURL); // putXML for rss\n            } else {\n                prop.putXML(\"content_link\", resultUrlstring); // putXML for rss\n            }\n            \n//            prop.putHTML(\"content_value\", Interaction.TripleGet(result.urlstring(), \"http://virtual.x/hasvalue\", \"anonymous\"));\n// END interaction\n\n            boolean isAtomFeed = header.get(HeaderFramework.CONNECTION_PROP_EXT, \"\").equals(\"atom\");\n            String resultFileName = resultURL.getFileName();\n            prop.putHTML(\"content_target\", target);\n            //if (faviconURL != null && fileType == FileType.HTML) sb.loader.loadIfNotExistBackground(faviconURL, 1024 * 1024 * 10, null, ClientIdentification.yacyIntranetCrawlerAgent);\n            prop.putHTML(\"content_faviconCode\", URLLicense.aquireLicense(faviconURL)); // acquire license for favicon url loading\n            prop.put(\"content_urlhash\", urlhash);\n            prop.put(\"content_ranking\", Float.toString(result.score()));\n            if (fileType == FileType.HTML) { // html template specific settings\n                prop.put(\"content_showDate\", sb.getConfigBool(\"search.result.show.date\", true) ? 1 : 0);\n                prop.put(\"content_showSize\", sb.getConfigBool(\"search.result.show.size\", true) ? 1 : 0);\n                prop.put(\"content_showMetadata\", sb.getConfigBool(\"search.result.show.metadata\", true) ? 1 : 0);\n                prop.put(\"content_showParser\", sb.getConfigBool(\"search.result.show.parser\", true) ? 1 : 0);\n                prop.put(\"content_showCitation\", sb.getConfigBool(\"search.result.show.citation\", true) ? 1 : 0);\n                prop.put(\"content_showPictures\", sb.getConfigBool(\"search.result.show.pictures\", true) ? 1 : 0);\n                prop.put(\"content_showCache\", sb.getConfigBool(\"search.result.show.cache\", true) && Cache.has(resultURL.hash()) ? 1 : 0);\n                prop.put(\"content_showProxy\", sb.getConfigBool(\"search.result.show.proxy\", true) ? 1 : 0);\n                prop.put(\"content_showHostBrowser\", sb.getConfigBool(\"search.result.show.hostbrowser\", true) ? 1 : 0);\n                prop.put(\"content_showVocabulary\", sb.getConfigBool(\"search.result.show.vocabulary\", true) ? 1 : 0);\n\n                prop.put(\"content_showDate_date\", GenericFormatter.RFC1123_SHORT_FORMATTER.format(result.modified()));\n                prop.putHTML(\"content_showSize_sizename\", RSSMessage.sizename(result.filesize()));\n                prop.put(\"content_showMetadata_urlhash\", urlhash);\n                prop.put(\"content_showParser_urlhash\", urlhash);\n                prop.put(\"content_showCitation_urlhash\", urlhash);\n                prop.putHTML(\"content_showPictures_former\", origQ);\n                prop.put(\"content_showCache_link\", resultUrlstring);\n                prop.put(\"content_showProxy_link\", resultUrlstring);\n                prop.put(\"content_showHostBrowser_link\", resultUrlstring);\n                if (sb.getConfigBool(\"search.result.show.vocabulary\", true)) {\n                    URIMetadataNode node = result.getNode();\n                    int c = 0;\n                    for (Map.Entry<String, Object> entry: node.entrySet()) {\n                        String key = entry.getKey();\n                        if (key.startsWith(\"vocabulary_\") && key.endsWith(\"_sxt\")) {\n                            @SuppressWarnings(\"unchecked\")\n                            Collection<String> terms = (Collection<String>) entry.getValue();\n                            prop.putHTML(\"content_showVocabulary_vocabulary_\" + c + \"_name\", key.substring(11, key.length() - 4));\n                            prop.putHTML(\"content_showVocabulary_vocabulary_\" + c + \"_terms\", terms.toString());\n                            c++;\n                        }\n                    }\n                    prop.put(\"content_showVocabulary_vocabulary\", c);\n                    prop.put(\"content_showVocabulary\", 1);\n                } else {\n                    prop.put(\"content_showVocabulary_vocabulary\", 0);\n                    prop.put(\"content_showVocabulary\", 0);\n                }\n            }\n            prop.put(\"content_urlhexhash\", Seed.b64Hash2hexHash(urlhash));\n            prop.putHTML(\"content_urlname\", nxTools.shortenURLString(result.urlname(), MAX_URL_LENGTH));\n            prop.put(\"content_date822\", isAtomFeed ? ISO8601Formatter.FORMATTER.format(result.modified()) : HeaderFramework.formatRFC1123(result.modified()));\n            //prop.put(\"content_ybr\", RankingProcess.ybr(result.hash()));\n            prop.putHTML(\"content_size\", Integer.toString(result.filesize())); // we don't use putNUM here because that number shall be usable as sorting key. To print the size, use 'sizename'\n            prop.putHTML(\"content_sizename\", RSSMessage.sizename(result.filesize()));            \n            prop.putHTML(\"content_host\", resultURL.getHost() == null ? \"\" : resultURL.getHost());\n            prop.putXML(\"content_file\", resultFileName); // putXML for rss\n            prop.putXML(\"content_path\", resultURL.getPath()); // putXML for rss\n            prop.put(\"content_nl\", (item == theSearch.query.offset) ? 0 : 1);\n            prop.putHTML(\"content_publisher\", result.publisher());\n            prop.putHTML(\"content_creator\", result.creator());// author\n            prop.putHTML(\"content_subject\", result.subject());\n            final Iterator<String> query = theSearch.query.getQueryGoal().getIncludeStrings();\n            final StringBuilder s = new StringBuilder(theSearch.query.getQueryGoal().getIncludeSize() * 20);\n            while (query.hasNext()) s.append('+').append(query.next());\n            final String words = (s.length() > 0) ? s.substring(1) : \"\";\n            prop.putHTML(\"content_words\", words);\n            prop.putHTML(\"content_showParser_words\", words);\n            prop.putHTML(\"content_former\", origQ);\n            final TextSnippet snippet = result.textSnippet();\n            final String desc = (snippet == null) ? \"\" : snippet.descriptionline(theSearch.query.getQueryGoal());\n            prop.put(\"content_description\", desc);\n            prop.putXML(\"content_description-xml\", desc);\n            prop.putJSON(\"content_description-json\", desc);\n            prop.put(\"content_mimetype\",result.getNode().mime()); // for atom <link> type attribute\n            final HeuristicResult heuristic = theSearch.getHeuristic(result.hash());\n            if (heuristic == null) {\n                prop.put(\"content_heuristic\", 0);\n            } else {\n                if (heuristic.redundant) {\n                    prop.put(\"content_heuristic\", 1);\n                } else {\n                    prop.put(\"content_heuristic\", 2);\n                }\n                prop.put(\"content_heuristic_name\", heuristic.heuristicName);\n            }\n            EventTracker.update(EventTracker.EClass.SEARCH, new ProfilingGraph.EventSearch(theSearch.query.id(true), SearchEventType.FINALIZATION, \"\" + item, 0, 0), false);\n            final String ext = MultiProtocolURL.getFileExtension(resultFileName);\n            if (MultiProtocolURL.isImage(ext)) {\n                final String license = URLLicense.aquireLicense(resultURL);\n                prop.put(\"content_code\", license);\n            } else {\n                prop.put(\"content_code\", \"\");\n            }\n            if (result.lat() == 0.0d || result.lon() == 0.0d) {\n                prop.put(\"content_loc\", 0);\n            } else {\n                prop.put(\"content_loc\", 1);\n                prop.put(\"content_loc_lat\", result.lat());\n                prop.put(\"content_loc_lon\", result.lon());\n            }\n            final boolean clustersearch = sb.isRobinsonMode() && sb.getConfig(SwitchboardConstants.CLUSTER_MODE, \"\").equals(SwitchboardConstants.CLUSTER_MODE_PUBLIC_CLUSTER);\n            final boolean indexReceiveGranted = sb.getConfigBool(SwitchboardConstants.INDEX_RECEIVE_ALLOW_SEARCH, true) || clustersearch;\n            boolean p2pmode = sb.peers != null && sb.peers.sizeConnected() > 0 && indexReceiveGranted;\n            boolean stealthmode = p2pmode && theSearch.query.isLocal();\n            if ((sb.getConfigBool(SwitchboardConstants.HEURISTIC_SEARCHRESULTS, false) ||\n                (sb.getConfigBool(SwitchboardConstants.GREEDYLEARNING_ACTIVE, false) && sb.getConfigBool(SwitchboardConstants.GREEDYLEARNING_ENABLED, false) && Memory.load() < 1.0)) &&\n                !stealthmode) sb.heuristicSearchResults(resultUrlstring);\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        if (theSearch.query.contentdom == Classification.ContentDomain.IMAGE) {\n            // image search; shows thumbnails\n\n            prop.put(\"content\", theSearch.query.contentdom.getCode() + 1); // switch on specific content\n            SearchEvent.ImageResult image = null;\n            try {\n                image = theSearch.oneImageResult(item, timeout);\n                final String imageUrlstring = image.imageUrl.toNormalform(true);\n                final String target = sb.getConfig(imageUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n\n                final String license = URLLicense.aquireLicense(image.imageUrl); // this is just the license key to get the image forwarded through the YaCy thumbnail viewer, not an actual lawful license\n                //sb.loader.loadIfNotExistBackground(image.imageUrl, 1024 * 1024 * 10, null, ClientIdentification.yacyIntranetCrawlerAgent);\n                prop.putHTML(\"content_item_hrefCache\", \"/ViewImage.png?maxwidth=128&maxheight=128&isStatic=true&quadratic=&url=\" + imageUrlstring);\n                prop.putHTML(\"content_item_href\", imageUrlstring);\n                prop.putHTML(\"content_item_target\", target);\n                prop.put(\"content_item_code\", license);\n                prop.putHTML(\"content_item_name\", shorten(image.imagetext, MAX_NAME_LENGTH));\n                prop.put(\"content_item_mimetype\", image.mimetype);\n                prop.put(\"content_item_fileSize\", 0);\n                prop.put(\"content_item_width\", image.width);\n                prop.put(\"content_item_height\", image.height);\n                prop.put(\"content_item_attr\", \"\"/*(ms.attr.equals(\"-1 x -1\")) ? \"\" : \"(\" + ms.attr + \")\"*/); // attributes, here: original size of image\n                prop.put(\"content_item_urlhash\", ASCII.String(image.imageUrl.hash()));\n                prop.put(\"content_item_source\", image.sourceUrl.toNormalform(true));\n                prop.putXML(\"content_item_source-xml\", image.sourceUrl.toNormalform(true));\n                prop.put(\"content_item_sourcedom\", image.sourceUrl.getHost());\n                prop.put(\"content_item_nl\", (item == theSearch.query.offset) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            } catch (MalformedURLException e) {\n                prop.put(\"content_item\", \"0\");\n            }\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        if ((theSearch.query.contentdom == ContentDomain.AUDIO) ||\n            (theSearch.query.contentdom == ContentDomain.VIDEO) ||\n            (theSearch.query.contentdom == ContentDomain.APP)) {\n            // any other media content\n\n            // generate result object\n            final ResultEntry ms = theSearch.oneResult(item, timeout);\n            prop.put(\"content\", theSearch.query.contentdom.getCode() + 1); // switch on specific content\n            if (ms == null) {\n                prop.put(\"content_item\", \"0\");\n            } else {\n                final String resultUrlstring = ms.url().toNormalform(true);\n                final String target = sb.getConfig(resultUrlstring.matches(target_special_pattern) ? SwitchboardConstants.SEARCH_TARGET_SPECIAL : SwitchboardConstants.SEARCH_TARGET_DEFAULT, \"_self\");\n                prop.putHTML(\"content_item_href\", resultUrlstring);\n                prop.putHTML(\"content_item_hrefshort\", nxTools.shortenURLString(resultUrlstring, MAX_URL_LENGTH));\n                prop.putHTML(\"content_item_target\", target);\n                prop.putHTML(\"content_item_name\", shorten(ms.title(), MAX_NAME_LENGTH));\n                prop.put(\"content_item_col\", (item % 2 == 0) ? \"0\" : \"1\");\n                prop.put(\"content_item_nl\", (item == theSearch.query.offset) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            }\n            theSearch.query.transmitcount = item + 1;\n            return prop;\n        }\n\n        return prop;\n    }","commit_id":"7e4e9f7e328c99610fe8f7c063e11c2cc76f454a","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"private void initActiveCrawlProfiles() {\n        this.defaultProxyProfile = null;\n        this.defaultRemoteProfile = null;\n        this.defaultTextSnippetLocalProfile = null;\n        this.defaultTextSnippetGlobalProfile = null;\n        this.defaultMediaSnippetLocalProfile = null;\n        this.defaultMediaSnippetGlobalProfile = null;\n        this.defaultSurrogateProfile = null;\n        final Iterator<CrawlProfile.entry> i = this.profilesActiveCrawls.profiles(true);\n        CrawlProfile.entry profile;\n        String name;\n        try {\n            while (i.hasNext()) {\n                profile = i.next();\n                name = profile.name();\n                if (name.equals(CRAWL_PROFILE_PROXY)) this.defaultProxyProfile = profile;\n                if (name.equals(CRAWL_PROFILE_REMOTE)) this.defaultRemoteProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT)) this.defaultTextSnippetLocalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT)) this.defaultTextSnippetGlobalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA)) this.defaultMediaSnippetLocalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA)) this.defaultMediaSnippetGlobalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SURROGATE)) this.defaultSurrogateProfile = profile;\n            }\n        } catch (final Exception e) {\n            this.profilesActiveCrawls.clear();\n            this.defaultProxyProfile = null;\n            this.defaultRemoteProfile = null;\n            this.defaultTextSnippetLocalProfile = null;\n            this.defaultTextSnippetGlobalProfile = null;\n            this.defaultMediaSnippetLocalProfile = null;\n            this.defaultMediaSnippetGlobalProfile = null;\n            this.defaultSurrogateProfile = null;\n        }\n        \n        if (this.defaultProxyProfile == null) {\n            // generate new default entry for proxy crawling\n            this.defaultProxyProfile = this.profilesActiveCrawls.newEntry(\"proxy\", null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL,\n                    0 /*Integer.parseInt(getConfig(PROXY_PREFETCH_DEPTH, \"0\"))*/,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_PROXY_RECRAWL_CYCLE), -1, -1, false,\n                    true /*getConfigBool(PROXY_INDEXING_LOCAL_TEXT, true)*/,\n                    true /*getConfigBool(PROXY_INDEXING_LOCAL_MEDIA, true)*/,\n                    true, true,\n                    false /*getConfigBool(PROXY_INDEXING_REMOTE, false)*/, true, true, true,\n                    CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultRemoteProfile == null) {\n            // generate new default entry for remote crawling\n            defaultRemoteProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_REMOTE, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    -1, -1, -1, true, true, true, false, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultTextSnippetLocalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultTextSnippetLocalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT_RECRAWL_CYCLE), -1, -1, true, false, false, false, false, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultTextSnippetGlobalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultTextSnippetGlobalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT_RECRAWL_CYCLE), -1, -1, true, true, true, true, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_CACHEONLY);\n        }\n        if (this.defaultMediaSnippetLocalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultMediaSnippetLocalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA_RECRAWL_CYCLE), -1, -1, true, false, false, false, false, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFEXIST);\n        }\n        if (this.defaultMediaSnippetGlobalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultMediaSnippetGlobalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA_RECRAWL_CYCLE), -1, -1, true, false, true, true, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFEXIST);\n        }\n        if (this.defaultSurrogateProfile == null) {\n            // generate new default entry for surrogate parsing\n            defaultSurrogateProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SURROGATE, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SURROGATE_RECRAWL_CYCLE), -1, -1, true, true, false, false, false, false, true, true, false, CrawlProfile.CACHE_STRATEGY_NOCACHE);\n        }\n    }","id":37213,"modified_method":"private void initActiveCrawlProfiles() {\n        this.defaultProxyProfile = null;\n        this.defaultRemoteProfile = null;\n        this.defaultTextSnippetLocalProfile = null;\n        this.defaultTextSnippetGlobalProfile = null;\n        this.defaultMediaSnippetLocalProfile = null;\n        this.defaultMediaSnippetGlobalProfile = null;\n        this.defaultSurrogateProfile = null;\n        final Iterator<CrawlProfile.entry> i = this.profilesActiveCrawls.profiles(true);\n        CrawlProfile.entry profile;\n        String name;\n        try {\n            while (i.hasNext()) {\n                profile = i.next();\n                name = profile.name();\n                if (name.equals(CRAWL_PROFILE_PROXY)) this.defaultProxyProfile = profile;\n                if (name.equals(CRAWL_PROFILE_REMOTE)) this.defaultRemoteProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT)) this.defaultTextSnippetLocalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT)) this.defaultTextSnippetGlobalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA)) this.defaultMediaSnippetLocalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA)) this.defaultMediaSnippetGlobalProfile = profile;\n                if (name.equals(CRAWL_PROFILE_SURROGATE)) this.defaultSurrogateProfile = profile;\n            }\n        } catch (final Exception e) {\n            this.profilesActiveCrawls.clear();\n            this.defaultProxyProfile = null;\n            this.defaultRemoteProfile = null;\n            this.defaultTextSnippetLocalProfile = null;\n            this.defaultTextSnippetGlobalProfile = null;\n            this.defaultMediaSnippetLocalProfile = null;\n            this.defaultMediaSnippetGlobalProfile = null;\n            this.defaultSurrogateProfile = null;\n        }\n        \n        if (this.defaultProxyProfile == null) {\n            // generate new default entry for proxy crawling\n            this.defaultProxyProfile = this.profilesActiveCrawls.newEntry(\"proxy\", null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL,\n                    0 /*Integer.parseInt(getConfig(PROXY_PREFETCH_DEPTH, \"0\"))*/,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_PROXY_RECRAWL_CYCLE), -1, -1, false,\n                    true /*getConfigBool(PROXY_INDEXING_LOCAL_TEXT, true)*/,\n                    true /*getConfigBool(PROXY_INDEXING_LOCAL_MEDIA, true)*/,\n                    true, true,\n                    false /*getConfigBool(PROXY_INDEXING_REMOTE, false)*/, true, true, true,\n                    CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultRemoteProfile == null) {\n            // generate new default entry for remote crawling\n            defaultRemoteProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_REMOTE, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    -1, -1, -1, true, true, true, false, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultTextSnippetLocalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultTextSnippetLocalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_LOCAL_TEXT_RECRAWL_CYCLE), -1, -1, true, false, false, true, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFFRESH);\n        }\n        if (this.defaultTextSnippetGlobalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultTextSnippetGlobalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT_RECRAWL_CYCLE), -1, -1, true, true, true, true, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_CACHEONLY);\n        }\n        if (this.defaultMediaSnippetLocalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultMediaSnippetLocalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_LOCAL_MEDIA_RECRAWL_CYCLE), -1, -1, true, false, false, false, false, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFEXIST);\n        }\n        if (this.defaultMediaSnippetGlobalProfile == null) {\n            // generate new default entry for snippet fetch and optional crawling\n            defaultMediaSnippetGlobalProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SNIPPET_GLOBAL_MEDIA_RECRAWL_CYCLE), -1, -1, true, false, true, true, true, false, true, true, false, CrawlProfile.CACHE_STRATEGY_IFEXIST);\n        }\n        if (this.defaultSurrogateProfile == null) {\n            // generate new default entry for surrogate parsing\n            defaultSurrogateProfile = this.profilesActiveCrawls.newEntry(CRAWL_PROFILE_SURROGATE, null, CrawlProfile.MATCH_ALL, CrawlProfile.MATCH_BAD_URL, 0,\n                    this.profilesActiveCrawls.getRecrawlDate(CRAWL_PROFILE_SURROGATE_RECRAWL_CYCLE), -1, -1, true, true, false, false, false, false, true, true, false, CrawlProfile.CACHE_STRATEGY_NOCACHE);\n        }\n    }","commit_id":"7ab207d93aa044de969243e5c53372a241ad573f","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\r\n\r\n        final serverObjects prop = new serverObjects();\r\n        final Switchboard sb = (Switchboard)env;\r\n        \r\n        if (post == null) {\r\n            prop.put(\"display\", 1);\r\n            prop.put(\"error_display\", 0);\r\n            prop.putHTML(\"error_words\", \"\");\r\n            prop.put(\"error_vMode-sentences\", \"1\");\r\n            prop.put(\"error\", \"1\");\r\n            prop.put(\"url\", \"\");\r\n            prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n            return prop;\r\n        }\r\n        \r\n        \r\n        final int display = post.getInt(\"display\", 1);\r\n        \r\n        // get segment\r\n        Segment indexSegment = null;\r\n        if (post.containsKey(\"segment\")) {\r\n            String segmentName = post.get(\"segment\");\r\n            if (sb.indexSegments.segmentExist(segmentName)) {\r\n                indexSegment = sb.indexSegments.segment(segmentName);\r\n            }\r\n        } else {\r\n            // take default segment\r\n            indexSegment = sb.indexSegments.segment(Segments.Process.PUBLIC);\r\n        }\r\n        \r\n        prop.put(\"display\", display);\r\n        prop.put(\"error_display\", display);\r\n\r\n        if (post.containsKey(\"words\"))\r\n            prop.putHTML(\"error_words\", post.get(\"words\"));\r\n        else {\r\n            prop.putHTML(\"error_words\", \"\");\r\n        }\r\n\r\n        final String viewMode = post.get(\"viewMode\",\"parsed\");\r\n        prop.put(\"error_vMode-\" + viewMode, \"1\");\r\n        \r\n        DigestURI url = null;\r\n        String descr = \"\";\r\n        final int wordCount = 0;\r\n        int size = 0;\r\n        boolean pre = false;\r\n        \r\n        // get the url hash from which the content should be loaded\r\n        String urlHash = post.get(\"urlHash\", \"\");\r\n        URIMetadataRow urlEntry = null;\r\n        // get the urlEntry that belongs to the url hash\r\n        if (urlHash.length() > 0 && (urlEntry = indexSegment.urlMetadata().load(urlHash.getBytes(), null, 0)) != null) {\r\n            // get the url that belongs to the entry\r\n            final URIMetadataRow.Components metadata = urlEntry.metadata();\r\n            if ((metadata == null) || (metadata.url() == null)) {\r\n                prop.put(\"error\", \"3\");\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n            url = metadata.url();\r\n            descr = metadata.dc_title();\r\n            //urlEntry.wordCount();\r\n            size = urlEntry.size();\r\n            pre = urlEntry.flags().get(Condenser.flag_cat_indexof);\r\n        }\r\n\r\n        prop.put(\"error_inurldb\", urlEntry == null ? 0 : 1);\r\n        \r\n        // alternatively, get the url simply from a url String\r\n        // this can be used as a simple tool to test the text parser\r\n        final String urlString = post.get(\"url\", \"\");\r\n        if (urlString.length() > 0) try {\r\n            // this call forces the peer to download  web pages\r\n            // it is therefore protected by the admin password\r\n            \r\n            if (!sb.verifyAuthentication(header, false)) {\r\n                prop.put(\"AUTHENTICATE\", \"admin log-in\"); // force log-in\r\n                return prop;\r\n            }\r\n\r\n            // define an url by post parameter\r\n            url = new DigestURI(urlString, null);\r\n            urlHash = new String(url.hash());\r\n            pre = post.get(\"pre\", \"false\").equals(\"true\");\r\n        } catch (final MalformedURLException e) {}\r\n        \r\n        \r\n        if (url == null) {\r\n            prop.put(\"error\", \"1\");\r\n            prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n            prop.put(\"url\", \"\");\r\n            return prop;\r\n        } else {\r\n            prop.put(\"url\", url.toNormalform(false, true));\r\n        }\r\n\r\n        // loading the resource content as byte array\r\n        prop.put(\"error_incache\", Cache.has(url) ? 1 : 0);\r\n        \r\n        byte[] resource = null;\r\n        ResponseHeader responseHeader = null;\r\n        String resMime = null;\r\n        // trying to load the resource body\r\n        try {\r\n            resource = Cache.getContent(url);\r\n        } catch (IOException e) {\r\n            Log.logException(e);\r\n            resource = null;\r\n        }\r\n        responseHeader = Cache.getResponseHeader(url);\r\n\r\n        // if the resource body was not cached we try to load it from web\r\n        if (resource == null) {\r\n            Response entry = null;\r\n            try {\r\n                entry = sb.loader.load(url, true, false);\r\n            } catch (final Exception e) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n\r\n            if (entry != null) {\r\n                resource = entry.getContent();\r\n            }\r\n\r\n            if (resource == null) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.put(\"error_errorText\", \"No resource available\");\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n        }\r\n\r\n        // try to load resource metadata\r\n        if (responseHeader == null) {\r\n\r\n            // try to load the metadata from cache\r\n            try {\r\n                responseHeader = Cache.getResponseHeader(url);\r\n            } catch (final Exception e) {\r\n                /* ignore this */\r\n            }\r\n\r\n            // if the metadata was not cached try to load it from web\r\n            if (responseHeader == null) {\r\n                final String protocol = url.getProtocol();\r\n                if (!((protocol.equals(\"http\") || protocol.equals(\"https\")))) {\r\n                    prop.put(\"error\", \"6\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n\r\n                responseHeader = Client.whead(url.toString());\r\n                if (responseHeader == null) {\r\n                    prop.put(\"error\", \"4\");\r\n                    prop.put(\"error_errorText\", \"Unable to load resource metadata.\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n                resMime = responseHeader.mime();\r\n            }\r\n        } else {\r\n            resMime = responseHeader.mime();\r\n        }\r\n        \r\n        final String[] wordArray = wordArray(post.get(\"words\", null));\r\n\r\n        if (viewMode.equals(\"plain\")) {\r\n\r\n            // TODO: how to handle very large files here ?\r\n            String content;\r\n            try {\r\n                content = new String(resource, \"UTF-8\");\r\n            } catch (final Exception e) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            } finally {\r\n                resource = null;\r\n            }\r\n\r\n            prop.put(\"error\", \"0\");\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_PLAIN_TEXT);\r\n            prop.put(\"viewMode_plainText\", markup(wordArray, content).replaceAll(\"\\n\", \"<br />\").replaceAll(\"\\t\", \"&nbsp;&nbsp;&nbsp;&nbsp;\"));\r\n            \r\n        } else if (viewMode.equals(\"iframeWeb\")) {\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_IFRAME_FROM_WEB);\r\n            prop.put(\"viewMode_url\", url.toNormalform(false, true));\r\n            \r\n        } else if (viewMode.equals(\"iframeCache\")) {\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_IFRAME_FROM_CACHE);\r\n            prop.put(\"viewMode_url\", url.toNormalform(false, true));\r\n            \r\n        } else if (viewMode.equals(\"parsed\") || viewMode.equals(\"sentences\")  || viewMode.equals(\"words\") || viewMode.equals(\"links\")) {\r\n            // parsing the resource content\r\n            Document document = null;\r\n            try {\r\n                document = LoaderDispatcher.parseDocument(url, resource.length, new ByteArrayInputStream(resource), null);\r\n                if (document == null) {\r\n                    prop.put(\"error\", \"5\");\r\n                    prop.put(\"error_errorText\", \"Unknown error\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n            } catch (final ParserException e) {\r\n                prop.put(\"error\", \"5\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            } finally {\r\n                resource = null;\r\n            }\r\n\r\n            resMime = document.dc_format();\r\n            \r\n            if (viewMode.equals(\"parsed\")) {\r\n                final String content = new String(document.getTextBytes());\r\n                // content = wikiCode.replaceHTML(content); // added by Marc Nause\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_TEXT);\r\n                prop.put(\"viewMode_title\", document.dc_title());\r\n                prop.put(\"viewMode_creator\", document.dc_creator());\r\n                prop.put(\"viewMode_subject\", document.dc_subject(','));\r\n                prop.put(\"viewMode_description\", document.dc_description());\r\n                prop.put(\"viewMode_publisher\", document.dc_publisher());\r\n                prop.put(\"viewMode_format\", document.dc_format());\r\n                prop.put(\"viewMode_identifier\", document.dc_identifier());\r\n                prop.put(\"viewMode_source\", document.dc_source().toString());\r\n                prop.put(\"viewMode_parsedText\", markup(wordArray, content).replaceAll(\"\\n\", \"<br />\").replaceAll(\"\\t\", \"&nbsp;&nbsp;&nbsp;&nbsp;\"));\r\n                \r\n            } else if (viewMode.equals(\"sentences\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_SENTENCES);\r\n                final Iterator<StringBuilder> sentences = document.getSentences(pre);\r\n\r\n                boolean dark = true;\r\n                int i = 0;\r\n                String sentence;\r\n                if (sentences != null) {\r\n                    \r\n                    // Search word highlighting\r\n                    while (sentences.hasNext()) {\r\n                        sentence = sentences.next().toString();\r\n                        if (sentence.trim().length() > 0) {\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_nr\", i + 1);\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_text\", markup(wordArray, sentence));\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                            dark = !dark;\r\n                            i++;\r\n                        }\r\n                    }\r\n                }\r\n                prop.put(\"viewMode_sentences\", i);\r\n\r\n            } else if (viewMode.equals(\"words\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_WORDS);\r\n                final Iterator<StringBuilder> sentences = document.getSentences(pre);\r\n\r\n                boolean dark = true;\r\n                int i = 0;\r\n                String sentence, token;\r\n                if (sentences != null) {\r\n                    \r\n                    // Search word highlighting\r\n                    while (sentences.hasNext()) {\r\n                        sentence = sentences.next().toString();\r\n                        Enumeration<StringBuilder> tokens = Condenser.wordTokenizer(sentence, \"UTF-8\");\r\n                        while (tokens.hasMoreElements()) {\r\n                            token = tokens.nextElement().toString();\r\n                            if (token.length() > 0) {\r\n                                prop.put(\"viewMode_words_\" + i + \"_nr\", i + 1);\r\n                                prop.put(\"viewMode_words_\" + i + \"_word\", token);\r\n                                prop.put(\"viewMode_words_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                                dark = !dark;\r\n                                i++;\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                prop.put(\"viewMode_words\", i);\r\n\r\n            } else if (viewMode.equals(\"links\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_LINKLIST);\r\n                boolean dark = true;\r\n                int i = 0;\r\n                i += putMediaInfo(prop, wordArray, i, document.getVideolinks(), \"video\", (i % 2 == 0));\r\n                i += putMediaInfo(prop, wordArray, i, document.getAudiolinks(), \"audio\", (i % 2 == 0));\r\n                dark = (i % 2 == 0);\r\n                \r\n                final HashMap<String, ImageEntry> ts = document.getImages();\r\n                final Iterator<ImageEntry> tsi = ts.values().iterator();\r\n                ImageEntry entry;\r\n                while (tsi.hasNext()) {\r\n                    entry = tsi.next();\r\n                    prop.put(\"viewMode_links_\" + i + \"_nr\", i);\r\n                    prop.put(\"viewMode_links_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                    prop.put(\"viewMode_links_\" + i + \"_type\", \"image\");\r\n                    prop.put(\"viewMode_links_\" + i + \"_text\", markup(wordArray, entry.alt()));\r\n                    prop.put(\"viewMode_links_\" + i + \"_url\", entry.url().toNormalform(false, true));\r\n                    prop.put(\"viewMode_links_\" + i + \"_link\", markup(wordArray, entry.url().toNormalform(false, true)));\r\n                    if (entry.width() > 0 && entry.height() > 0)\r\n                        prop.put(\"viewMode_links_\" + i + \"_attr\", entry.width() + \"x\" + entry.height() + \" Pixel\");\r\n                    else\r\n                        prop.put(\"viewMode_links_\" + i + \"_attr\", \"unknown\");\r\n                    dark = !dark;\r\n                    i++;\r\n                }\r\n                i += putMediaInfo(prop, wordArray, i, document.getApplinks(), \"app\", (i % 2 == 0));\r\n                i += putMediaInfo(prop, wordArray, i, document.getHyperlinks(), \"link\", (i % 2 == 0));\r\n                prop.put(\"viewMode_links\", i);\r\n\r\n            }\r\n            if (document != null) document.close();\r\n        }\r\n        prop.put(\"error\", \"0\");\r\n        prop.put(\"error_url\", url.toNormalform(false, true));\r\n        prop.put(\"error_hash\", urlHash);\r\n        prop.put(\"error_wordCount\", wordCount);\r\n        prop.putHTML(\"error_desc\", descr);\r\n        prop.putNum(\"error_size\", size);\r\n        prop.put(\"error_mimeTypeAvailable\", (resMime == null) ? \"0\" : \"1\");\r\n        prop.put(\"error_mimeTypeAvailable_mimeType\", resMime);\r\n        return prop;\r\n    }","id":37214,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\r\n\r\n        final serverObjects prop = new serverObjects();\r\n        final Switchboard sb = (Switchboard)env;\r\n        \r\n        if (post == null) {\r\n            prop.put(\"display\", 1);\r\n            prop.put(\"error_display\", 0);\r\n            prop.putHTML(\"error_words\", \"\");\r\n            prop.put(\"error_vMode-sentences\", \"1\");\r\n            prop.put(\"error\", \"1\");\r\n            prop.put(\"url\", \"\");\r\n            prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n            return prop;\r\n        }\r\n        \r\n        \r\n        final int display = post.getInt(\"display\", 1);\r\n        \r\n        // get segment\r\n        Segment indexSegment = null;\r\n        if (post.containsKey(\"segment\")) {\r\n            String segmentName = post.get(\"segment\");\r\n            if (sb.indexSegments.segmentExist(segmentName)) {\r\n                indexSegment = sb.indexSegments.segment(segmentName);\r\n            }\r\n        } else {\r\n            // take default segment\r\n            indexSegment = sb.indexSegments.segment(Segments.Process.PUBLIC);\r\n        }\r\n        \r\n        prop.put(\"display\", display);\r\n        prop.put(\"error_display\", display);\r\n\r\n        if (post.containsKey(\"words\"))\r\n            prop.putHTML(\"error_words\", post.get(\"words\"));\r\n        else {\r\n            prop.putHTML(\"error_words\", \"\");\r\n        }\r\n\r\n        final String viewMode = post.get(\"viewMode\",\"parsed\");\r\n        prop.put(\"error_vMode-\" + viewMode, \"1\");\r\n        \r\n        DigestURI url = null;\r\n        String descr = \"\";\r\n        final int wordCount = 0;\r\n        int size = 0;\r\n        boolean pre = false;\r\n        \r\n        // get the url hash from which the content should be loaded\r\n        String urlHash = post.get(\"urlHash\", \"\");\r\n        URIMetadataRow urlEntry = null;\r\n        // get the urlEntry that belongs to the url hash\r\n        if (urlHash.length() > 0 && (urlEntry = indexSegment.urlMetadata().load(urlHash.getBytes(), null, 0)) != null) {\r\n            // get the url that belongs to the entry\r\n            final URIMetadataRow.Components metadata = urlEntry.metadata();\r\n            if ((metadata == null) || (metadata.url() == null)) {\r\n                prop.put(\"error\", \"3\");\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n            url = metadata.url();\r\n            descr = metadata.dc_title();\r\n            //urlEntry.wordCount();\r\n            size = urlEntry.size();\r\n            pre = urlEntry.flags().get(Condenser.flag_cat_indexof);\r\n        }\r\n\r\n        prop.put(\"error_inurldb\", urlEntry == null ? 0 : 1);\r\n        \r\n        // alternatively, get the url simply from a url String\r\n        // this can be used as a simple tool to test the text parser\r\n        final String urlString = post.get(\"url\", \"\");\r\n        if (urlString.length() > 0) try {\r\n            // this call forces the peer to download  web pages\r\n            // it is therefore protected by the admin password\r\n            \r\n            if (!sb.verifyAuthentication(header, false)) {\r\n                prop.put(\"AUTHENTICATE\", \"admin log-in\"); // force log-in\r\n                return prop;\r\n            }\r\n\r\n            // define an url by post parameter\r\n            url = new DigestURI(urlString, null);\r\n            urlHash = new String(url.hash());\r\n            pre = post.get(\"pre\", \"false\").equals(\"true\");\r\n        } catch (final MalformedURLException e) {}\r\n        \r\n        \r\n        if (url == null) {\r\n            prop.put(\"error\", \"1\");\r\n            prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n            prop.put(\"url\", \"\");\r\n            return prop;\r\n        } else {\r\n            prop.put(\"url\", url.toNormalform(false, true));\r\n        }\r\n\r\n        // loading the resource content as byte array\r\n        prop.put(\"error_incache\", Cache.has(url) ? 1 : 0);\r\n        \r\n        byte[] resource = null;\r\n        ResponseHeader responseHeader = null;\r\n        String resMime = null;\r\n        // trying to load the resource body\r\n        try {\r\n            resource = Cache.getContent(url);\r\n        } catch (IOException e) {\r\n            Log.logException(e);\r\n            resource = null;\r\n        }\r\n        responseHeader = Cache.getResponseHeader(url);\r\n\r\n        // if the resource body was not cached we try to load it from web\r\n        if (resource == null) {\r\n            Response entry = null;\r\n            try {\r\n                entry = sb.loader.load(url, true, false);\r\n            } catch (final Exception e) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n\r\n            if (entry != null) {\r\n                resource = entry.getContent();\r\n            }\r\n\r\n            if (resource == null) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.put(\"error_errorText\", \"No resource available\");\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            }\r\n        }\r\n\r\n        // try to load resource metadata\r\n        if (responseHeader == null) {\r\n\r\n            // try to load the metadata from cache\r\n            try {\r\n                responseHeader = Cache.getResponseHeader(url);\r\n            } catch (final Exception e) {\r\n                /* ignore this */\r\n            }\r\n\r\n            // if the metadata was not cached try to load it from web\r\n            if (responseHeader == null) {\r\n                final String protocol = url.getProtocol();\r\n                if (!((protocol.equals(\"http\") || protocol.equals(\"https\")))) {\r\n                    prop.put(\"error\", \"6\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n\r\n                try {\r\n                    Response response = sb.loader.load(url, true, false);\r\n                    responseHeader = response.getResponseHeader();\r\n                    resource = response.getContent();\r\n                } catch (IOException e) {\r\n                    Log.logException(e);\r\n                }\r\n                if (responseHeader == null) {\r\n                    prop.put(\"error\", \"4\");\r\n                    prop.put(\"error_errorText\", \"Unable to load resource metadata.\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n                resMime = responseHeader.mime();\r\n            }\r\n        } else {\r\n            resMime = responseHeader.mime();\r\n        }\r\n        \r\n        final String[] wordArray = wordArray(post.get(\"words\", null));\r\n\r\n        if (viewMode.equals(\"plain\")) {\r\n\r\n            // TODO: how to handle very large files here ?\r\n            String content;\r\n            try {\r\n                content = new String(resource, \"UTF-8\");\r\n            } catch (final Exception e) {\r\n                prop.put(\"error\", \"4\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            } finally {\r\n                resource = null;\r\n            }\r\n\r\n            prop.put(\"error\", \"0\");\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_PLAIN_TEXT);\r\n            prop.put(\"viewMode_plainText\", markup(wordArray, content).replaceAll(\"\\n\", \"<br />\").replaceAll(\"\\t\", \"&nbsp;&nbsp;&nbsp;&nbsp;\"));\r\n            \r\n        } else if (viewMode.equals(\"iframeWeb\")) {\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_IFRAME_FROM_WEB);\r\n            prop.put(\"viewMode_url\", url.toNormalform(false, true));\r\n            \r\n        } else if (viewMode.equals(\"iframeCache\")) {\r\n            prop.put(\"viewMode\", VIEW_MODE_AS_IFRAME_FROM_CACHE);\r\n            prop.put(\"viewMode_url\", url.toNormalform(false, true));\r\n            \r\n        } else if (viewMode.equals(\"parsed\") || viewMode.equals(\"sentences\")  || viewMode.equals(\"words\") || viewMode.equals(\"links\")) {\r\n            // parsing the resource content\r\n            Document document = null;\r\n            try {\r\n                document = LoaderDispatcher.parseDocument(url, resource.length, new ByteArrayInputStream(resource), responseHeader);\r\n                if (document == null) {\r\n                    prop.put(\"error\", \"5\");\r\n                    prop.put(\"error_errorText\", \"Unknown error\");\r\n                    prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                    return prop;\r\n                }\r\n            } catch (final ParserException e) {\r\n                prop.put(\"error\", \"5\");\r\n                prop.putHTML(\"error_errorText\", e.getMessage());\r\n                prop.put(\"viewMode\", VIEW_MODE_NO_TEXT);\r\n                return prop;\r\n            } finally {\r\n                resource = null;\r\n            }\r\n\r\n            resMime = document.dc_format();\r\n            \r\n            if (viewMode.equals(\"parsed\")) {\r\n                final String content = new String(document.getTextBytes());\r\n                // content = wikiCode.replaceHTML(content); // added by Marc Nause\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_TEXT);\r\n                prop.put(\"viewMode_title\", document.dc_title());\r\n                prop.put(\"viewMode_creator\", document.dc_creator());\r\n                prop.put(\"viewMode_subject\", document.dc_subject(','));\r\n                prop.put(\"viewMode_description\", document.dc_description());\r\n                prop.put(\"viewMode_publisher\", document.dc_publisher());\r\n                prop.put(\"viewMode_format\", document.dc_format());\r\n                prop.put(\"viewMode_identifier\", document.dc_identifier());\r\n                prop.put(\"viewMode_source\", document.dc_source().toString());\r\n                prop.put(\"viewMode_parsedText\", markup(wordArray, content).replaceAll(\"\\n\", \"<br />\").replaceAll(\"\\t\", \"&nbsp;&nbsp;&nbsp;&nbsp;\"));\r\n                \r\n            } else if (viewMode.equals(\"sentences\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_SENTENCES);\r\n                final Iterator<StringBuilder> sentences = document.getSentences(pre);\r\n\r\n                boolean dark = true;\r\n                int i = 0;\r\n                String sentence;\r\n                if (sentences != null) {\r\n                    \r\n                    // Search word highlighting\r\n                    while (sentences.hasNext()) {\r\n                        sentence = sentences.next().toString();\r\n                        if (sentence.trim().length() > 0) {\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_nr\", i + 1);\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_text\", markup(wordArray, sentence));\r\n                            prop.put(\"viewMode_sentences_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                            dark = !dark;\r\n                            i++;\r\n                        }\r\n                    }\r\n                }\r\n                prop.put(\"viewMode_sentences\", i);\r\n\r\n            } else if (viewMode.equals(\"words\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_PARSED_WORDS);\r\n                final Iterator<StringBuilder> sentences = document.getSentences(pre);\r\n\r\n                boolean dark = true;\r\n                int i = 0;\r\n                String sentence, token;\r\n                if (sentences != null) {\r\n                    \r\n                    // Search word highlighting\r\n                    while (sentences.hasNext()) {\r\n                        sentence = sentences.next().toString();\r\n                        Enumeration<StringBuilder> tokens = Condenser.wordTokenizer(sentence, \"UTF-8\");\r\n                        while (tokens.hasMoreElements()) {\r\n                            token = tokens.nextElement().toString();\r\n                            if (token.length() > 0) {\r\n                                prop.put(\"viewMode_words_\" + i + \"_nr\", i + 1);\r\n                                prop.put(\"viewMode_words_\" + i + \"_word\", token);\r\n                                prop.put(\"viewMode_words_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                                dark = !dark;\r\n                                i++;\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                prop.put(\"viewMode_words\", i);\r\n\r\n            } else if (viewMode.equals(\"links\")) {\r\n                prop.put(\"viewMode\", VIEW_MODE_AS_LINKLIST);\r\n                boolean dark = true;\r\n                int i = 0;\r\n                i += putMediaInfo(prop, wordArray, i, document.getVideolinks(), \"video\", (i % 2 == 0));\r\n                i += putMediaInfo(prop, wordArray, i, document.getAudiolinks(), \"audio\", (i % 2 == 0));\r\n                dark = (i % 2 == 0);\r\n                \r\n                final HashMap<String, ImageEntry> ts = document.getImages();\r\n                final Iterator<ImageEntry> tsi = ts.values().iterator();\r\n                ImageEntry entry;\r\n                while (tsi.hasNext()) {\r\n                    entry = tsi.next();\r\n                    prop.put(\"viewMode_links_\" + i + \"_nr\", i);\r\n                    prop.put(\"viewMode_links_\" + i + \"_dark\", dark ? \"1\" : \"0\");\r\n                    prop.put(\"viewMode_links_\" + i + \"_type\", \"image\");\r\n                    prop.put(\"viewMode_links_\" + i + \"_text\", markup(wordArray, entry.alt()));\r\n                    prop.put(\"viewMode_links_\" + i + \"_url\", entry.url().toNormalform(false, true));\r\n                    prop.put(\"viewMode_links_\" + i + \"_link\", markup(wordArray, entry.url().toNormalform(false, true)));\r\n                    if (entry.width() > 0 && entry.height() > 0)\r\n                        prop.put(\"viewMode_links_\" + i + \"_attr\", entry.width() + \"x\" + entry.height() + \" Pixel\");\r\n                    else\r\n                        prop.put(\"viewMode_links_\" + i + \"_attr\", \"unknown\");\r\n                    dark = !dark;\r\n                    i++;\r\n                }\r\n                i += putMediaInfo(prop, wordArray, i, document.getApplinks(), \"app\", (i % 2 == 0));\r\n                i += putMediaInfo(prop, wordArray, i, document.getHyperlinks(), \"link\", (i % 2 == 0));\r\n                prop.put(\"viewMode_links\", i);\r\n\r\n            }\r\n            if (document != null) document.close();\r\n        }\r\n        prop.put(\"error\", \"0\");\r\n        prop.put(\"error_url\", url.toNormalform(false, true));\r\n        prop.put(\"error_hash\", urlHash);\r\n        prop.put(\"error_wordCount\", wordCount);\r\n        prop.putHTML(\"error_desc\", descr);\r\n        prop.putNum(\"error_size\", size);\r\n        prop.put(\"error_mimeTypeAvailable\", (resMime == null) ? \"0\" : \"1\");\r\n        prop.put(\"error_mimeTypeAvailable_mimeType\", resMime);\r\n        return prop;\r\n    }","commit_id":"7ab207d93aa044de969243e5c53372a241ad573f","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        // return variable that accumulates replacements\n        final Switchboard sb = (Switchboard) env;\n        \n        final serverObjects prop = new serverObjects();\n        Segment segment = null;\n        if (post == null || !post.containsKey(\"html\")) {\n            if (post.containsKey(\"segment\") && sb.verifyAuthentication(header, false)) {\n                segment = sb.indexSegments.segment(post.get(\"segment\"));\n            }\n        }\n        if (segment == null) segment = sb.indexSegments.segment(Segments.Process.PUBLIC);\n        \n        \n        prop.put(\"dc_title\", \"\");\n        prop.put(\"dc_creator\", \"\");\n        prop.put(\"dc_description\", \"\");\n        prop.put(\"dc_subject\", \"\");\n        prop.put(\"dc_publisher\", \"\");\n        prop.put(\"dc_contributor\", \"\");\n        prop.put(\"dc_date\", \"\");\n        prop.put(\"dc_type\", \"\");\n        prop.put(\"dc_identifier\", \"\");\n        prop.put(\"dc_language\", \"\");\n\n        if (post == null) return prop;\n        \n        String urlstring = post.get(\"urlstring\", \"\").trim();\n        String urlhash = post.get(\"urlhash\", \"\").trim();\n        if (urlstring.length() == 0 && urlhash.length() == 0) return prop;\n\n        if (urlstring.length() > 0 && urlhash.length() == 0) {\n            try {\n                urlhash = new String((new DigestURI(urlstring, null)).hash());\n            } catch (MalformedURLException e) {\n                Log.logException(e);\n            }\n        }\n        if (urlhash == null || urlhash.length() == 0) return prop;\n        \n        final URIMetadataRow entry = segment.urlMetadata().load(urlhash.getBytes(), null, 0);\n        if (entry == null) return prop;\n\n        final URIMetadataRow.Components metadata = entry.metadata();\n        if (metadata.url() == null) {\n            return prop;\n        }\n        final URIMetadataRow le = (entry.referrerHash() == null || entry.referrerHash().length != Word.commonHashLength) ? null : segment.urlMetadata().load(entry.referrerHash(), null, 0);\n        \n        prop.putXML(\"dc_title\", metadata.dc_title());\n        prop.putXML(\"dc_creator\", metadata.dc_creator());\n        prop.putXML(\"dc_description\", \"\");\n        prop.putXML(\"dc_subject\", metadata.dc_subject());\n        prop.putXML(\"dc_publisher\", metadata.url().toNormalform(false, true));\n        prop.putXML(\"dc_contributor\", \"\");\n        prop.putXML(\"dc_date\", entry.moddate().toString());\n        prop.putXML(\"dc_type\", String.valueOf(entry.doctype()));\n        prop.putXML(\"dc_identifier\", urlhash);\n        prop.putXML(\"dc_language\", entry.language());\n\n        prop.putXML(\"yacy_loaddate\", entry.loaddate().toString());\n        prop.putXML(\"yacy_referrer_hash\", (le == null) ? \"\" : new String(le.hash()));\n        prop.putXML(\"yacy_referrer_url\", (le == null) ? \"\" : le.metadata().url().toNormalform(false, true));\n        prop.put(\"yacy_size\", entry.size());\n        prop.put(\"yacy_words\",entry.wordCount());\n        \n        // return rewrite properties\n        return prop;\n    }","id":37215,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        // return variable that accumulates replacements\n        final Switchboard sb = (Switchboard) env;\n        \n        final serverObjects prop = new serverObjects();\n        final Segment segment;\n        boolean html = post != null && post.containsKey(\"html\");\n        prop.setLocalized(html);\n        if (post != null && post.containsKey(\"segment\") && sb.verifyAuthentication(header, false)) {\n            segment = sb.indexSegments.segment(post.get(\"segment\"));\n        } else {\n            segment = sb.indexSegments.segment(Segments.Process.PUBLIC);\n        }\n        \n        prop.put(\"dc_title\", \"\");\n        prop.put(\"dc_creator\", \"\");\n        prop.put(\"dc_description\", \"\");\n        prop.put(\"dc_subject\", \"\");\n        prop.put(\"dc_publisher\", \"\");\n        prop.put(\"dc_contributor\", \"\");\n        prop.put(\"dc_date\", \"\");\n        prop.put(\"dc_type\", \"\");\n        prop.put(\"dc_identifier\", \"\");\n        prop.put(\"dc_language\", \"\");\n\n        if (post == null) return prop;\n        \n        String urlstring = post.get(\"urlstring\", \"\").trim();\n        String urlhash = post.get(\"urlhash\", \"\").trim();\n        if (urlstring.length() == 0 && urlhash.length() == 0) return prop;\n\n        if (urlstring.length() > 0 && urlhash.length() == 0) {\n            try {\n                DigestURI url = new DigestURI(urlstring, null);\n                urlhash = new String(url.hash());\n            } catch (MalformedURLException e) {\n                Log.logException(e);\n            }\n        }\n        if (urlhash == null || urlhash.length() == 0) return prop;\n        \n        final URIMetadataRow entry = segment.urlMetadata().load(urlhash.getBytes(), null, 0);\n        if (entry == null) return prop;\n\n        final URIMetadataRow.Components metadata = entry.metadata();\n        if (metadata.url() == null) {\n            return prop;\n        }\n        final URIMetadataRow le = (entry.referrerHash() == null || entry.referrerHash().length != Word.commonHashLength) ? null : segment.urlMetadata().load(entry.referrerHash(), null, 0);\n        \n        prop.putXML(\"dc_title\", metadata.dc_title());\n        prop.putXML(\"dc_creator\", metadata.dc_creator());\n        prop.putXML(\"dc_description\", \"\");\n        prop.putXML(\"dc_subject\", metadata.dc_subject());\n        prop.putXML(\"dc_publisher\", \"\");\n        prop.putXML(\"dc_contributor\", \"\");\n        prop.putXML(\"dc_date\", entry.moddate().toString());\n        prop.putXML(\"dc_type\", String.valueOf(entry.doctype()));\n        prop.putXML(\"dc_identifier\", metadata.url().toNormalform(false, true));\n        prop.putXML(\"dc_language\", entry.language());\n\n        prop.putXML(\"yacy_loaddate\", entry.loaddate().toString());\n        prop.putXML(\"yacy_referrer_hash\", (le == null) ? \"\" : new String(le.hash()));\n        prop.putXML(\"yacy_referrer_url\", (le == null) ? \"\" : le.metadata().url().toNormalform(false, true));\n        prop.put(\"yacy_size\", entry.size());\n        prop.put(\"yacy_words\",entry.wordCount());\n        \n        // return rewrite properties\n        return prop;\n    }","commit_id":"7ab207d93aa044de969243e5c53372a241ad573f","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final String eventID = post.get(\"eventID\", \"\");\n        final boolean authenticated = sb.adminAuthenticated(header) >= 2;\n        final int item = post.getInt(\"item\", -1);\n        final boolean auth = (header.get(HeaderFramework.CONNECTION_PROP_CLIENTIP, \"\")).equals(\"localhost\") || sb.verifyAuthentication(header, true);\n        final int display = (post == null) ? 0 : post.getInt(\"display\", 0);\n        \n        // default settings for blank item\n        prop.put(\"content\", \"0\");\n        prop.put(\"rss\", \"0\");\n        prop.put(\"references\", \"0\");\n        prop.put(\"rssreferences\", \"0\");\n        prop.put(\"dynamic\", \"0\");\n        \n        // find search event\n        final SearchEvent theSearch = SearchEventCache.getEvent(eventID);\n        if (theSearch == null) {\n            // the event does not exist, show empty page\n            return prop;\n        }\n        final QueryParams theQuery = theSearch.getQuery();\n        \n        // dynamically update count values\n        final int totalcount = theSearch.getRankingResult().getLocalIndexCount() + theSearch.getRankingResult().getRemoteResourceSize();\n        final int offset = theQuery.neededResults() - theQuery.displayResults() + 1;\n        prop.put(\"offset\", offset);\n        prop.put(\"itemscount\", Formatter.number(Math.min((item < 0) ? theQuery.neededResults() : item + 1, totalcount)));\n        prop.put(\"totalcount\", Formatter.number(totalcount, true));\n        prop.put(\"localResourceSize\", Formatter.number(theSearch.getRankingResult().getLocalIndexCount(), true));\n        prop.put(\"remoteResourceSize\", Formatter.number(theSearch.getRankingResult().getRemoteResourceSize(), true));\n        prop.put(\"remoteIndexCount\", Formatter.number(theSearch.getRankingResult().getRemoteIndexCount(), true));\n        prop.put(\"remotePeerCount\", Formatter.number(theSearch.getRankingResult().getRemotePeerCount(), true));\n        \n        if (theQuery.contentdom == ContentDomain.TEXT) {\n            // text search\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item);\n            if (result == null) return prop; // no content\n\n            \n            final int port=result.url().getPort();\n            DigestURI faviconURL = null;\n            if (!result.url().isLocal()) try {\n                faviconURL = new DigestURI(result.url().getProtocol() + \"://\" + result.url().getHost() + ((port != -1) ? (\":\" + port) : \"\") + \"/favicon.ico\", null);\n            } catch (final MalformedURLException e1) {\n                faviconURL = null;\n            }\n            \n            prop.put(\"content\", 1); // switch on specific content\n            \n            prop.put(\"content_authorized\", authenticated ? \"1\" : \"0\");\n            prop.put(\"content_authorized_recommend\", (sb.peers.newsPool.getSpecific(yacyNewsPool.OUTGOING_DB, yacyNewsPool.CATEGORY_SURFTIPP_ADD, \"url\", result.urlstring()) == null) ? \"1\" : \"0\");\n            prop.putHTML(\"content_authorized_recommend_deletelink\", \"/yacysearch.html?search=\" + theQuery.queryString + \"&Enter=Search&count=\" + theQuery.displayResults() + \"&offset=\" + (theQuery.neededResults() - theQuery.displayResults()) + \"&order=\" + crypt.simpleEncode(theQuery.ranking.toExternalString()) + \"&resource=local&time=3&deleteref=\" + new String(result.hash()) + \"&urlmaskfilter=.*\");\n            prop.putHTML(\"content_authorized_recommend_recommendlink\", \"/yacysearch.html?search=\" + theQuery.queryString + \"&Enter=Search&count=\" + theQuery.displayResults() + \"&offset=\" + (theQuery.neededResults() - theQuery.displayResults()) + \"&order=\" + crypt.simpleEncode(theQuery.ranking.toExternalString()) + \"&resource=local&time=3&recommendref=\" + new String(result.hash()) + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_urlhash\", new String(result.hash()));\n            String resulthashString = new String(result.hash());\n            prop.putHTML(\"content_title\", result.title());\n            prop.putXML(\"content_title-xml\", result.title());\n            prop.putJSON(\"content_title-json\", result.title());\n            prop.putHTML(\"content_link\", result.urlstring());\n            prop.put(\"content_display\", display);\n            prop.putHTML(\"content_faviconCode\", sb.licensedURLs.aquireLicense(faviconURL)); // aquire license for favicon url loading\n            prop.put(\"content_urlhash\", resulthashString);\n            prop.put(\"content_urlhexhash\", yacySeed.b64Hash2hexHash(resulthashString));\n            prop.putHTML(\"content_urlname\", nxTools.shortenURLString(result.urlname(), urllength));\n            prop.put(\"content_date\", Switchboard.dateString(result.modified()));\n            prop.put(\"content_date822\", Switchboard.dateString822(result.modified()));\n            prop.put(\"content_ybr\", RankingProcess.ybr(result.hash()));\n            prop.putHTML(\"content_size\", Integer.toString(result.filesize())); // we don't use putNUM here because that number shall be usable as sorting key. To print the size, use 'sizename'\n            prop.putHTML(\"content_sizename\", sizename(result.filesize()));\n            prop.putHTML(\"content_host\", result.url().getHost());\n            prop.putHTML(\"content_file\", result.url().getFile());\n            prop.putHTML(\"content_path\", result.url().getPath());\n            prop.put(\"content_nl\", (item == 0) ? 0 : 1);\n            \n            final TreeSet<String>[] query = theQuery.queryWords();\n            try {\n                prop.putHTML(\"content_words\", URLEncoder.encode(query[0].toString(),\"UTF-8\"));\n            } catch (final UnsupportedEncodingException e) {}\n            prop.putHTML(\"content_former\", theQuery.queryString);\n            final TextSnippet snippet = result.textSnippet();\n            final String desc = (snippet == null) ? \"\" : snippet.getLineMarked(theQuery.fullqueryHashes);\n            prop.put(\"content_description\", desc);\n            prop.putXML(\"content_description-xml\", desc);\n            prop.putJSON(\"content_description-json\", desc);\n            EventTracker.update(\"SEARCH\", new ProfilingGraph.searchEvent(theQuery.id(true), SearchEvent.FINALIZATION + \"-\" + item, 0, 0), false, 30000, ProfilingGraph.maxTime);\n            \n            return prop;\n        }\n        \n        if (theQuery.contentdom == ContentDomain.IMAGE) {\n            // image search; shows thumbnails\n\n            prop.put(\"content\", theQuery.contentdom.getCode() + 1); // switch on specific content\n            final MediaSnippet ms = theSearch.result().oneImage(item);\n            if (ms == null) {\n                prop.put(\"content_item\", \"0\");\n            } else {\n                prop.putHTML(\"content_item_hrefCache\", (auth) ? \"/ViewImage.png?url=\" + ms.href.toNormalform(true, false) : ms.href.toNormalform(true, false));\n                prop.putHTML(\"content_item_href\", ms.href.toNormalform(true, false));\n                prop.put(\"content_item_code\", sb.licensedURLs.aquireLicense(ms.href));\n                prop.putHTML(\"content_item_name\", shorten(ms.name, namelength));\n                prop.put(\"content_item_mimetype\", ms.mime);\n                prop.put(\"content_item_fileSize\", ms.fileSize);\n                prop.put(\"content_item_width\", ms.width);\n                prop.put(\"content_item_height\", ms.height);\n                prop.put(\"content_item_attr\", (ms.attr.equals(\"-1 x -1\")) ? \"\" : \"(\" + ms.attr + \")\"); // attributes, here: original size of image\n                prop.put(\"content_item_urlhash\", new String(ms.source.hash()));\n                prop.put(\"content_item_source\", ms.source.toNormalform(true, false));\n                prop.putXML(\"content_item_source-xml\", ms.source.toNormalform(true, false));\n                prop.put(\"content_item_sourcedom\", ms.source.getHost());\n                prop.put(\"content_item_nl\", (item == 0) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            }\n            return prop;\n        }\n        \n        if ((theQuery.contentdom == ContentDomain.AUDIO) ||\n            (theQuery.contentdom == ContentDomain.VIDEO) ||\n            (theQuery.contentdom == ContentDomain.APP)) {\n            // any other media content\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item);\n            if (result == null) return prop; // no content\n            \n            prop.put(\"content\", theQuery.contentdom.getCode() + 1); // switch on specific content\n            final ArrayList<MediaSnippet> media = result.mediaSnippets();\n            if (item == 0) col = true;\n            if (media != null) {\n                MediaSnippet ms;\n                int c = 0;\n                for (int i = 0; i < media.size(); i++) {\n                    ms = media.get(i);\n                    prop.putHTML(\"content_items_\" + i + \"_href\", ms.href.toNormalform(true, false));\n                    prop.putHTML(\"content_items_\" + i + \"_hrefshort\", nxTools.shortenURLString(ms.href.toNormalform(true, false), urllength));\n                    prop.putHTML(\"content_items_\" + i + \"_name\", shorten(ms.name, namelength));\n                    prop.put(\"content_items_\" + i + \"_col\", (col) ? \"0\" : \"1\");\n                    c++;\n                    col = !col;\n                }\n                prop.put(\"content_items\", c);\n            } else {\n                prop.put(\"content_items\", \"0\");\n            }\n            return prop;\n        }\n        \n        return prop;\n    }","id":37216,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        final serverObjects prop = new serverObjects();\n        \n        final String eventID = post.get(\"eventID\", \"\");\n        final boolean authenticated = sb.adminAuthenticated(header) >= 2;\n        final int item = post.getInt(\"item\", -1);\n        final boolean auth = (header.get(HeaderFramework.CONNECTION_PROP_CLIENTIP, \"\")).equals(\"localhost\") || sb.verifyAuthentication(header, true);\n        final int display = (post == null) ? 0 : post.getInt(\"display\", 0);\n        \n        // default settings for blank item\n        prop.put(\"content\", \"0\");\n        prop.put(\"rss\", \"0\");\n        prop.put(\"references\", \"0\");\n        prop.put(\"rssreferences\", \"0\");\n        prop.put(\"dynamic\", \"0\");\n        \n        // find search event\n        final SearchEvent theSearch = SearchEventCache.getEvent(eventID);\n        if (theSearch == null) {\n            // the event does not exist, show empty page\n            return prop;\n        }\n        final QueryParams theQuery = theSearch.getQuery();\n        \n        // dynamically update count values\n        final int totalcount = theSearch.getRankingResult().getLocalIndexCount() + theSearch.getRankingResult().getRemoteResourceSize();\n        final int offset = theQuery.neededResults() - theQuery.displayResults() + 1;\n        prop.put(\"offset\", offset);\n        prop.put(\"itemscount\", Formatter.number(Math.min((item < 0) ? theQuery.neededResults() : item + 1, totalcount)));\n        prop.put(\"totalcount\", Formatter.number(totalcount, true));\n        prop.put(\"localResourceSize\", Formatter.number(theSearch.getRankingResult().getLocalIndexCount(), true));\n        prop.put(\"remoteResourceSize\", Formatter.number(theSearch.getRankingResult().getRemoteResourceSize(), true));\n        prop.put(\"remoteIndexCount\", Formatter.number(theSearch.getRankingResult().getRemoteIndexCount(), true));\n        prop.put(\"remotePeerCount\", Formatter.number(theSearch.getRankingResult().getRemotePeerCount(), true));\n        \n        if (theQuery.contentdom == ContentDomain.TEXT) {\n            // text search\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item);\n            if (result == null) return prop; // no content\n\n            \n            final int port=result.url().getPort();\n            DigestURI faviconURL = null;\n            if (!result.url().isLocal()) try {\n                faviconURL = new DigestURI(result.url().getProtocol() + \"://\" + result.url().getHost() + ((port != -1) ? (\":\" + port) : \"\") + \"/favicon.ico\", null);\n            } catch (final MalformedURLException e1) {\n                faviconURL = null;\n            }\n            \n            prop.put(\"content\", 1); // switch on specific content\n            \n            prop.put(\"content_authorized\", authenticated ? \"1\" : \"0\");\n            prop.put(\"content_authorized_recommend\", (sb.peers.newsPool.getSpecific(yacyNewsPool.OUTGOING_DB, yacyNewsPool.CATEGORY_SURFTIPP_ADD, \"url\", result.urlstring()) == null) ? \"1\" : \"0\");\n            prop.putHTML(\"content_authorized_recommend_deletelink\", \"/yacysearch.html?search=\" + theQuery.queryString + \"&Enter=Search&count=\" + theQuery.displayResults() + \"&offset=\" + (theQuery.neededResults() - theQuery.displayResults()) + \"&order=\" + crypt.simpleEncode(theQuery.ranking.toExternalString()) + \"&resource=local&time=3&deleteref=\" + new String(result.hash()) + \"&urlmaskfilter=.*\");\n            prop.putHTML(\"content_authorized_recommend_recommendlink\", \"/yacysearch.html?search=\" + theQuery.queryString + \"&Enter=Search&count=\" + theQuery.displayResults() + \"&offset=\" + (theQuery.neededResults() - theQuery.displayResults()) + \"&order=\" + crypt.simpleEncode(theQuery.ranking.toExternalString()) + \"&resource=local&time=3&recommendref=\" + new String(result.hash()) + \"&urlmaskfilter=.*\");\n            prop.put(\"content_authorized_urlhash\", new String(result.hash()));\n            String resulthashString = new String(result.hash());\n            prop.putHTML(\"content_title\", result.title());\n            prop.putXML(\"content_title-xml\", result.title());\n            prop.putJSON(\"content_title-json\", result.title());\n            prop.putHTML(\"content_link\", result.urlstring());\n            prop.put(\"content_display\", display);\n            prop.putHTML(\"content_faviconCode\", sb.licensedURLs.aquireLicense(faviconURL)); // aquire license for favicon url loading\n            prop.put(\"content_urlhash\", resulthashString);\n            prop.put(\"content_urlhexhash\", yacySeed.b64Hash2hexHash(resulthashString));\n            prop.putHTML(\"content_urlname\", nxTools.shortenURLString(result.urlname(), urllength));\n            prop.put(\"content_date\", Switchboard.dateString(result.modified()));\n            prop.put(\"content_date822\", Switchboard.dateString822(result.modified()));\n            //prop.put(\"content_ybr\", RankingProcess.ybr(result.hash()));\n            prop.putHTML(\"content_size\", Integer.toString(result.filesize())); // we don't use putNUM here because that number shall be usable as sorting key. To print the size, use 'sizename'\n            prop.putHTML(\"content_sizename\", sizename(result.filesize()));\n            prop.putHTML(\"content_host\", result.url().getHost());\n            prop.putHTML(\"content_file\", result.url().getFile());\n            prop.putHTML(\"content_path\", result.url().getPath());\n            prop.put(\"content_nl\", (item == 0) ? 0 : 1);\n            \n            final TreeSet<String>[] query = theQuery.queryWords();\n            try {\n                prop.putHTML(\"content_words\", URLEncoder.encode(query[0].toString(),\"UTF-8\"));\n            } catch (final UnsupportedEncodingException e) {}\n            prop.putHTML(\"content_former\", theQuery.queryString);\n            final TextSnippet snippet = result.textSnippet();\n            final String desc = (snippet == null) ? \"\" : snippet.getLineMarked(theQuery.fullqueryHashes);\n            prop.put(\"content_description\", desc);\n            prop.putXML(\"content_description-xml\", desc);\n            prop.putJSON(\"content_description-json\", desc);\n            EventTracker.update(\"SEARCH\", new ProfilingGraph.searchEvent(theQuery.id(true), SearchEvent.FINALIZATION + \"-\" + item, 0, 0), false, 30000, ProfilingGraph.maxTime);\n            \n            return prop;\n        }\n        \n        if (theQuery.contentdom == ContentDomain.IMAGE) {\n            // image search; shows thumbnails\n\n            prop.put(\"content\", theQuery.contentdom.getCode() + 1); // switch on specific content\n            final MediaSnippet ms = theSearch.result().oneImage(item);\n            if (ms == null) {\n                prop.put(\"content_item\", \"0\");\n            } else {\n                prop.putHTML(\"content_item_hrefCache\", (auth) ? \"/ViewImage.png?url=\" + ms.href.toNormalform(true, false) : ms.href.toNormalform(true, false));\n                prop.putHTML(\"content_item_href\", ms.href.toNormalform(true, false));\n                prop.put(\"content_item_code\", sb.licensedURLs.aquireLicense(ms.href));\n                prop.putHTML(\"content_item_name\", shorten(ms.name, namelength));\n                prop.put(\"content_item_mimetype\", ms.mime);\n                prop.put(\"content_item_fileSize\", ms.fileSize);\n                prop.put(\"content_item_width\", ms.width);\n                prop.put(\"content_item_height\", ms.height);\n                prop.put(\"content_item_attr\", (ms.attr.equals(\"-1 x -1\")) ? \"\" : \"(\" + ms.attr + \")\"); // attributes, here: original size of image\n                prop.put(\"content_item_urlhash\", new String(ms.source.hash()));\n                prop.put(\"content_item_source\", ms.source.toNormalform(true, false));\n                prop.putXML(\"content_item_source-xml\", ms.source.toNormalform(true, false));\n                prop.put(\"content_item_sourcedom\", ms.source.getHost());\n                prop.put(\"content_item_nl\", (item == 0) ? 0 : 1);\n                prop.put(\"content_item\", 1);\n            }\n            return prop;\n        }\n        \n        if ((theQuery.contentdom == ContentDomain.AUDIO) ||\n            (theQuery.contentdom == ContentDomain.VIDEO) ||\n            (theQuery.contentdom == ContentDomain.APP)) {\n            // any other media content\n\n            // generate result object\n            final ResultEntry result = theSearch.oneResult(item);\n            if (result == null) return prop; // no content\n            \n            prop.put(\"content\", theQuery.contentdom.getCode() + 1); // switch on specific content\n            final ArrayList<MediaSnippet> media = result.mediaSnippets();\n            if (item == 0) col = true;\n            if (media != null) {\n                MediaSnippet ms;\n                int c = 0;\n                for (int i = 0; i < media.size(); i++) {\n                    ms = media.get(i);\n                    prop.putHTML(\"content_items_\" + i + \"_href\", ms.href.toNormalform(true, false));\n                    prop.putHTML(\"content_items_\" + i + \"_hrefshort\", nxTools.shortenURLString(ms.href.toNormalform(true, false), urllength));\n                    prop.putHTML(\"content_items_\" + i + \"_name\", shorten(ms.name, namelength));\n                    prop.put(\"content_items_\" + i + \"_col\", (col) ? \"0\" : \"1\");\n                    c++;\n                    col = !col;\n                }\n                prop.put(\"content_items\", c);\n            } else {\n                prop.put(\"content_items\", \"0\");\n            }\n            return prop;\n        }\n        \n        return prop;\n    }","commit_id":"7ab207d93aa044de969243e5c53372a241ad573f","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        // generate message content for open search description\n        String promoteSearchPageGreeting = env.getConfig(SwitchboardConstants.GREETING, \"\");\n        if (env.getConfigBool(SwitchboardConstants.GREETING_NETWORK_NAME, false)) promoteSearchPageGreeting = env.getConfig(\"network.unit.description\", \"\");\n\n        String thisaddress = header.get(\"Host\", Domains.LOCALHOST);\n        if (thisaddress.indexOf(':',0) == -1) thisaddress += \":\" + env.getConfig(\"port\", \"8090\");\n\n        final serverObjects prop = new serverObjects();\n        prop.put(\"compareyacy\", post != null && post.getBoolean(\"compare_yacy\") ? 1 : 0);\n        prop.putXML(\"compareyacy_thisaddress\", thisaddress);\n        prop.putXML(\"thisaddress\", thisaddress);\n        prop.putXML(\"SearchPageGreeting\", promoteSearchPageGreeting);\n        prop.putXML(\"clientname\", sb.peers.mySeed().getName());\n        prop.putXML(\"compareyacy_search_left\", post == null ? compare_yacy.defaultsearchL : post.get(\"left\", compare_yacy.defaultsearchL));\n        prop.putXML(\"compareyacy_search_right\", post == null ? compare_yacy.defaultsearchR : post.get(\"right\", compare_yacy.defaultsearchR));\n\n        // return rewrite properties\n        return prop;\n    }","id":37217,"modified_method":"public static serverObjects respond(final RequestHeader header, final serverObjects post, final serverSwitch env) {\n        final Switchboard sb = (Switchboard) env;\n        // generate message content for open search description\n        String promoteSearchPageGreeting = env.getConfig(SwitchboardConstants.GREETING, \"\");\n        if (env.getConfigBool(SwitchboardConstants.GREETING_NETWORK_NAME, false)) promoteSearchPageGreeting = env.getConfig(\"network.unit.description\", \"\");\n\n        String thisaddress = header.get(\"Host\", Domains.LOCALHOST);\n        if (thisaddress.indexOf(':',0) == -1) thisaddress += \":\" + env.getConfig(\"port\", \"8090\");\n        String thisprotocol = env.getConfigBool(\"server.https\", false) ? \"https\" : \"http\";\n        \n        final serverObjects prop = new serverObjects();\n        prop.put(\"compareyacy\", post != null && post.getBoolean(\"compare_yacy\") ? 1 : 0);\n        prop.putXML(\"thisaddress\", thisaddress);\n        prop.putXML(\"compareyacy_thisaddress\", thisaddress);\n        prop.putXML(\"thisprotocol\", thisprotocol);\n        prop.putXML(\"compareyacy_thisprotocol\", thisprotocol);\n        prop.putXML(\"SearchPageGreeting\", promoteSearchPageGreeting);\n        prop.putXML(\"clientname\", sb.peers.mySeed().getName());\n        prop.putXML(\"compareyacy_search_left\", post == null ? compare_yacy.defaultsearchL : post.get(\"left\", compare_yacy.defaultsearchL));\n        prop.putXML(\"compareyacy_search_right\", post == null ? compare_yacy.defaultsearchR : post.get(\"right\", compare_yacy.defaultsearchR));\n\n        // return rewrite properties\n        return prop;\n    }","commit_id":"805a95a98b40411ccc3caca3879e171a7bc2e47a","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"protected ResolveResult[] multiResolveImpl() {\n    String name = getReferenceName();\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PropertyResolverProcessor processor = new PropertyResolverProcessor(name, this, false);\n      resolved.processDeclarations(processor, PsiSubstitutor.EMPTY, resolved, this);\n      return processor.getCandidates();\n    }\n    return new ResolveResult[0];\n  }","id":37218,"modified_method":"protected ResolveResult[] multiResolveImpl() {\n    String name = getReferenceName();\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PropertyResolverProcessor processor = new PropertyResolverProcessor(name, this, false);\n      resolved.processDeclarations(processor, PsiSubstitutor.EMPTY, resolved, this);\n      GroovyResolveResult[] candidates = processor.getCandidates();\n      if (candidates.length == 0) {\n        MethodResolverProcessor methodProcessor = new MethodResolverProcessor(name, this, false, false, null, PsiType.EMPTY_ARRAY);\n        MethodResolverProcessor constructorProcessor = new MethodResolverProcessor(name, this, false, true, null, PsiType.EMPTY_ARRAY);\n        resolved.processDeclarations(methodProcessor, PsiSubstitutor.EMPTY, resolved, this);\n        resolved.processDeclarations(constructorProcessor, PsiSubstitutor.EMPTY, resolved, this);\n        candidates = ArrayUtil.mergeArrays(methodProcessor.getCandidates(), constructorProcessor.getCandidates(), GroovyResolveResult.class);\n        if (candidates.length > 0 ) {\n          candidates = new GroovyResolveResult[]{candidates[0]};\n        }\n      }\n      return candidates;\n    }\n    return new ResolveResult[0];\n  }","commit_id":"b43f04a68ed8496a32e0a67632df0cbfb7299a8d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public Object[] getVariants() {\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PropertyResolverProcessor propertyProcessor = new PropertyResolverProcessor(null, this, true);\n      resolved.processDeclarations(propertyProcessor, PsiSubstitutor.EMPTY, null, this);\n      PsiElement[] propertyCandidates = ResolveUtil.mapToElements(propertyProcessor.getCandidates());\n      MethodResolverProcessor methodProcessor = new MethodResolverProcessor(null, this, true, false, null, PsiType.EMPTY_ARRAY);\n      resolved.processDeclarations(methodProcessor, PsiSubstitutor.EMPTY, null, this);\n      PsiElement[] methodCandidates = ResolveUtil.mapToElements(methodProcessor.getCandidates());\n      PsiElement[] elements = ArrayUtil.mergeArrays(propertyCandidates, methodCandidates, PsiElement.class);\n\n      return ContainerUtil.map2Array(elements, new Function<PsiElement, Object>() {\n        public Object fun(PsiElement psiElement) {\n          LookupItem<PsiElement> lookupItem = null;\n          if (psiElement instanceof PsiNamedElement) {\n            if (psiElement instanceof PsiMethod) {\n              lookupItem = new LookupItem<PsiElement>(psiElement, ((PsiMethod) psiElement).getName());\n            } else {\n              String string = ((PsiNamedElement) psiElement).getName();\n              lookupItem = new LookupItem<PsiElement>(psiElement, string == null ? \"\" : string);\n            }\n            lookupItem.setAttribute(LookupItem.DO_AUTOCOMPLETE_ATTR, null);\n            lookupItem.setAttribute(LookupItem.FORCE_SHOW_SIGNATURE_ATTR, true);\n          }\n          return lookupItem != null ? lookupItem : psiElement;\n        }\n      });\n    }\n    return ArrayUtil.EMPTY_OBJECT_ARRAY;\n  }","id":37219,"modified_method":"public Object[] getVariants() {\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PropertyResolverProcessor propertyProcessor = new PropertyResolverProcessor(null, this, true);\n      resolved.processDeclarations(propertyProcessor, PsiSubstitutor.EMPTY, null, this);\n      PsiElement[] propertyCandidates = ResolveUtil.mapToElements(propertyProcessor.getCandidates());\n      MethodResolverProcessor methodProcessor = new MethodResolverProcessor(null, this, true, false, null, PsiType.EMPTY_ARRAY);\n      MethodResolverProcessor constructorProcessor = new MethodResolverProcessor(null, this, false, true, null, PsiType.EMPTY_ARRAY);\n\n      resolved.processDeclarations(methodProcessor, PsiSubstitutor.EMPTY, null, this);\n      resolved.processDeclarations(constructorProcessor, PsiSubstitutor.EMPTY, resolved, this);\n\n      PsiElement[] methodCandidates = ResolveUtil.mapToElements(methodProcessor.getCandidates());\n      PsiElement[] constructorCandidates = ResolveUtil.mapToElements(constructorProcessor.getCandidates());\n\n      PsiElement[] elements = ArrayUtil.mergeArrays(ArrayUtil.mergeArrays(propertyCandidates, methodCandidates, PsiElement.class), \n          constructorCandidates, PsiElement.class);\n\n      return ContainerUtil.map2Array(elements, new Function<PsiElement, Object>() {\n        public Object fun(PsiElement psiElement) {\n          LookupItem<PsiElement> lookupItem = null;\n          if (psiElement instanceof PsiNamedElement) {\n            if (psiElement instanceof PsiMethod) {\n              lookupItem = new LookupItem<PsiElement>(psiElement, ((PsiMethod) psiElement).getName());\n            } else {\n              String string = ((PsiNamedElement) psiElement).getName();\n              lookupItem = new LookupItem<PsiElement>(psiElement, string == null ? \"\" : string);\n            }\n            lookupItem.setAttribute(LookupItem.DO_AUTOCOMPLETE_ATTR, null);\n            lookupItem.setAttribute(LookupItem.FORCE_SHOW_SIGNATURE_ATTR, true);\n          }\n          return lookupItem != null ? lookupItem : psiElement;\n        }\n      });\n    }\n    return ArrayUtil.EMPTY_OBJECT_ARRAY;\n  }","commit_id":"b43f04a68ed8496a32e0a67632df0cbfb7299a8d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected ResolveResult[] multiResolveImpl() {\n    String name = getReferenceName();\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PsiType[] parameterTypes = getParameterList().getParameterTypes();\n      MethodResolverProcessor processor = new MethodResolverProcessor(name, this, false, false, parameterTypes, PsiType.EMPTY_ARRAY);\n      resolved.processDeclarations(processor, PsiSubstitutor.EMPTY, resolved, this);\n      return processor.getCandidates();\n    }\n    return new ResolveResult[0];\n  }","id":37220,"modified_method":"protected ResolveResult[] multiResolveImpl() {\n    String name = getReferenceName();\n    GrDocReferenceElement holder = getReferenceHolder();\n    PsiElement resolved;\n    if (holder != null) {\n      GrCodeReferenceElement referenceElement = holder.getReferenceElement();\n      resolved = referenceElement != null ? referenceElement.resolve() : null;\n    } else {\n      resolved = getEnclosingClassOrFile(this);\n    }\n    if (resolved != null) {\n      PsiType[] parameterTypes = getParameterList().getParameterTypes();\n      MethodResolverProcessor processor = new MethodResolverProcessor(name, this, false, false, parameterTypes, PsiType.EMPTY_ARRAY);\n      MethodResolverProcessor constructorProcessor = new MethodResolverProcessor(name, this, false, true, parameterTypes, PsiType.EMPTY_ARRAY);\n      resolved.processDeclarations(processor, PsiSubstitutor.EMPTY, resolved, this);\n      resolved.processDeclarations(constructorProcessor, PsiSubstitutor.EMPTY, resolved, this);\n      return ArrayUtil.mergeArrays(processor.getCandidates(), constructorProcessor.getCandidates(), GroovyResolveResult.class);\n    }\n    return new ResolveResult[0];\n  }","commit_id":"b43f04a68ed8496a32e0a67632df0cbfb7299a8d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void annotate(PsiElement element, AnnotationHolder holder) {\n    if (element instanceof GrCodeReferenceElement) {\n      checkReferenceElement(holder, (GrCodeReferenceElement) element);\n    } else if (element instanceof GrReferenceExpression) {\n      checkReferenceExpression(holder, (GrReferenceExpression) element);\n    } else if (element instanceof GrTypeDefinition) {\n      final GrTypeDefinition typeDefinition = (GrTypeDefinition) element;\n      checkTypeDefinition(holder, typeDefinition);\n      checkTypeDefinitionModifiers(holder, typeDefinition);\n      final GrTypeDefinitionBody body = typeDefinition.getBody();\n      if (body != null) checkDuplicateMethod(body.getGroovyMethods(), holder);\n      checkImplementedMethodsOfClass(holder, typeDefinition);\n    } else if (element instanceof GrMethod) {\n      final GrMethod method = (GrMethod) element;\n      checkMethodDefinitionModifiers(holder, method);\n      checkInnerMethod(holder, method);\n      checkMethodReturnExpression(holder, method);\n      addOverrideGutter(holder, method);\n    } else if (element instanceof GrVariableDeclaration) {\n      checkVariableDeclaration(holder, (GrVariableDeclaration) element);\n    } else if (element instanceof GrVariable) {\n      if (element instanceof GrMember) highlightMember(holder, ((GrMember) element));\n      checkVariable(holder, (GrVariable) element);\n    } else if (element instanceof GrAssignmentExpression) {\n      checkAssignmentExpression((GrAssignmentExpression) element, holder);\n    } else if (element instanceof GrNamedArgument) {\n      checkCommandArgument((GrNamedArgument) element, holder);\n    } else if (element instanceof GrReturnStatement) {\n      checkReturnStatement((GrReturnStatement) element, holder);\n    } else if (element instanceof GrListOrMap) {\n      checkMap(((GrListOrMap) element).getNamedArguments(), holder);\n    } else if (element instanceof GrNewExpression) {\n      checkNewExpression(holder, (GrNewExpression) element);\n    } else if (element instanceof GrConstructorInvocation) {\n      checkConstructorInvocation(holder, (GrConstructorInvocation) element);\n    } else if (element.getParent() instanceof GrDocReferenceElement) {\n      checkGrDocReferenceElement(holder, element);\n    } else if (element instanceof GrPackageDefinition) {\n      //todo: if reference isn't resolved it construct package definition \n      checkPackageReference(holder, (GrPackageDefinition) element);\n    } else if (element instanceof GroovyFile) {\n      final GroovyFile file = (GroovyFile) element;\n      if (file.isScript()) {\n        checkScriptDuplicateMethod(file.getTopLevelDefinitions(), holder);\n      }\n      if (DomainClassUtils.isDomainClassFile(element.getContainingFile().getVirtualFile())) {\n        checkDomainClass((GroovyFile) element, holder);\n      }\n    } else {\n      final ASTNode node = element.getNode();\n      if (node != null && !(element instanceof PsiWhiteSpace) &&\n          !GroovyTokenTypes.COMMENT_SET.contains(node.getElementType()) &&\n          element.getContainingFile() instanceof GroovyFile &&\n          !isDocCommentElement(element)) {\n        GroovyImportsTracker.getInstance(element.getProject()).markFileAnnotated((GroovyFile) element.getContainingFile());\n      }\n    }\n  }","id":37221,"modified_method":"public void annotate(PsiElement element, AnnotationHolder holder) {\n    if (element instanceof GrCodeReferenceElement) {\n      checkReferenceElement(holder, (GrCodeReferenceElement) element);\n    } else if (element instanceof GrReferenceExpression) {\n      checkReferenceExpression(holder, (GrReferenceExpression) element);\n    } else if (element instanceof GrTypeDefinition) {\n      final GrTypeDefinition typeDefinition = (GrTypeDefinition) element;\n      checkTypeDefinition(holder, typeDefinition);\n      checkTypeDefinitionModifiers(holder, typeDefinition);\n      final GrTypeDefinitionBody body = typeDefinition.getBody();\n      if (body != null) checkDuplicateMethod(body.getGroovyMethods(), holder);\n      checkImplementedMethodsOfClass(holder, typeDefinition);\n    } else if (element instanceof GrMethod) {\n      final GrMethod method = (GrMethod) element;\n      checkMethodDefinitionModifiers(holder, method);\n      checkInnerMethod(holder, method);\n      checkMethodReturnExpression(holder, method);\n      addOverrideGutter(holder, method);\n    } else if (element instanceof GrVariableDeclaration) {\n      checkVariableDeclaration(holder, (GrVariableDeclaration) element);\n    } else if (element instanceof GrVariable) {\n      if (element instanceof GrMember) highlightMember(holder, ((GrMember) element));\n      checkVariable(holder, (GrVariable) element);\n    } else if (element instanceof GrAssignmentExpression) {\n      checkAssignmentExpression((GrAssignmentExpression) element, holder);\n    } else if (element instanceof GrNamedArgument) {\n      checkCommandArgument((GrNamedArgument) element, holder);\n    } else if (element instanceof GrReturnStatement) {\n      checkReturnStatement((GrReturnStatement) element, holder);\n    } else if (element instanceof GrListOrMap) {\n      checkMap(((GrListOrMap) element).getNamedArguments(), holder);\n    } else if (element instanceof GrNewExpression) {\n      checkNewExpression(holder, (GrNewExpression) element);\n    } else if (element instanceof GrDocMemberReference) {\n      checkGrDocMemberReference((GrDocMemberReference) element, holder);\n    } else if (element instanceof GrConstructorInvocation) {\n      checkConstructorInvocation(holder, (GrConstructorInvocation) element);\n    } else if (element.getParent() instanceof GrDocReferenceElement) {\n      checkGrDocReferenceElement(holder, element);\n    } else if (element instanceof GrPackageDefinition) {\n      //todo: if reference isn't resolved it construct package definition \n      checkPackageReference(holder, (GrPackageDefinition) element);\n    } else if (element instanceof GroovyFile) {\n      final GroovyFile file = (GroovyFile) element;\n      if (file.isScript()) {\n        checkScriptDuplicateMethod(file.getTopLevelDefinitions(), holder);\n      }\n      if (DomainClassUtils.isDomainClassFile(element.getContainingFile().getVirtualFile())) {\n        checkDomainClass((GroovyFile) element, holder);\n      }\n    } else {\n      final ASTNode node = element.getNode();\n      if (node != null && !(element instanceof PsiWhiteSpace) &&\n          !GroovyTokenTypes.COMMENT_SET.contains(node.getElementType()) &&\n          element.getContainingFile() instanceof GroovyFile &&\n          !isDocCommentElement(element)) {\n        GroovyImportsTracker.getInstance(element.getProject()).markFileAnnotated((GroovyFile) element.getContainingFile());\n      }\n    }\n  }","commit_id":"b43f04a68ed8496a32e0a67632df0cbfb7299a8d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private static GrParameter getAppropriateParameter(final PsiElement element) {\n    if (element instanceof GrParameter) {\n      return (GrParameter)element;\n    }\n    if (element instanceof GrReferenceExpression) {\n      final GrReferenceExpression expr = (GrReferenceExpression)element;\n      final PsiElement resolved = expr.resolve();\n      LOG.assertTrue(resolved instanceof GrParameter);\n      return ((GrParameter)resolved);\n    }\n    LOG.error(\"Selected expression is not resolved to methood/closure parameter\");\n    return null;\n  }","id":37222,"modified_method":"@Nullable\n  private static GrParameter getAppropriateParameter(final PsiElement element) {\n    if (element instanceof GrParameter) {\n      return (GrParameter)element;\n    }\n    if (element instanceof GrReferenceExpression) {\n      final GrReferenceExpression expr = (GrReferenceExpression)element;\n      final PsiElement resolved = expr.resolve();\n      LOG.assertTrue(resolved instanceof GrParameter);\n      return ((GrParameter)resolved);\n    }\n    LOG.error(\"Selected expression is not resolved to method/closure parameter\");\n    return null;\n  }","commit_id":"63766ebacca0001e8e2f2883901b12337bbbbff1","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static boolean collectOwnerOccurrences(final Project project,\n                                                 final GrParametersOwner owner,\n                                                 final Collection<PsiElement> occurrences) {\n    final PsiElement namedElem = getReferencedElement(owner);\n    if (namedElem == null) return true;\n    final Ref<Boolean> result = new Ref<Boolean>(true);\n    final Task task = new Task.Modal(project, GroovyIntentionsBundle\n      .message(\"find.method.ro.closure.usages.0\", owner instanceof GrClosableBlock ? CLOSURE_CAPTION : METHOD_CAPTION), true) {\n      public void run(@NotNull final ProgressIndicator indicator) {\n        final GlobalSearchScope projectScope = GlobalSearchScope.projectScope(getProject());\n        final Query<PsiReference> query = ReferencesSearch.search(namedElem, projectScope);\n        final Collection<PsiReference> references = query.findAll();\n        for (PsiReference reference : references) {\n          final PsiElement element = reference.getElement();\n          if (element != null) {\n            occurrences.add(element);\n          }\n        }\n      }\n\n      @Override\n      public void onCancel() {\n        result.set(false);\n      }\n\n      @Override\n      public void onSuccess() {\n        result.set(true);\n      }\n    };\n    ProgressManager.getInstance().run(task);\n    return result.get().booleanValue();\n  }","id":37223,"modified_method":"private static boolean collectOwnerOccurrences(final Project project,\n                                                 final GrParametersOwner owner,\n                                                 final Collection<PsiElement> occurrences) {\n    final PsiElement namedElem = getReferencedElement(owner);\n    if (namedElem == null) return true;\n    final Ref<Boolean> result = new Ref<Boolean>(true);\n    final Task task = new Task.Modal(project, GroovyIntentionsBundle\n      .message(\"find.method.ro.closure.usages.0\", owner instanceof GrClosableBlock ? CLOSURE_CAPTION : METHOD_CAPTION), true) {\n      public void run(@NotNull final ProgressIndicator indicator) {\n        final GlobalSearchScope projectScope = GlobalSearchScope.projectScope(getProject());\n        final Collection<PsiReference> references = new ArrayList<PsiReference>();\n        final Processor<PsiReference> consumer = new Processor<PsiReference>() {\n          @Override\n          public boolean process(PsiReference psiReference) {\n            references.add(psiReference);\n            return true;\n          }\n        };\n        ReferencesSearch.search(namedElem, projectScope).forEach(consumer);\n        if (namedElem instanceof GrField && ((GrField)namedElem).isProperty()) {\n          final GrAccessorMethod[] getters = ((GrField)namedElem).getGetters();\n          for (GrAccessorMethod getter : getters) {\n            MethodReferencesSearch.search(getter).forEach(consumer);\n          }\n        }\n        for (PsiReference reference : references) {\n          final PsiElement element = reference.getElement();\n          if (element != null) {\n            occurrences.add(element);\n          }\n        }\n      }\n\n      @Override\n      public void onCancel() {\n        result.set(false);\n      }\n\n      @Override\n      public void onSuccess() {\n        result.set(true);\n      }\n    };\n    ProgressManager.getInstance().run(task);\n    return result.get().booleanValue();\n  }","commit_id":"63766ebacca0001e8e2f2883901b12337bbbbff1","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void performRefactoring(final PsiElement element,\n                                         final GrParametersOwner owner,\n                                         final Collection<PsiElement> occurrences,\n                                         final boolean createNewFirstParam,\n                                         final String mapParamName,\n                                         final boolean specifyMapType) {\n    final GrParameter param = getAppropriateParameter(element);\n    assert param != null;\n    final String paramName = param.getName();\n    final String mapName = createNewFirstParam ? mapParamName : getFirstParameter(owner).getName();\n\n\n    final Project project = element.getProject();\n    final Runnable runnable = new Runnable() {\n      public void run() {\n        final GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(project);\n\n        final GrParameterList list = owner.getParameterList();\n        assert list != null;\n        final int index = list.getParameterNumber(param);\n        if (!createNewFirstParam && index <= 0) { // bad undo\n          return;\n        }\n\n        //Remove old arguments from occurrences\n        //final List<GrCall> calls = getCallOccurrences(occurrences);\n        try {\n          for (PsiElement occurrence : occurrences) {\n            GrReferenceExpression refExpr = null;\n            if (occurrence instanceof GrReferenceExpression) {\n              final PsiElement parent = occurrence.getParent();\n              if (parent instanceof GrCall) {\n                refExpr = (GrReferenceExpression)occurrence;\n              }\n              else if (parent instanceof GrReferenceExpression) {\n                final PsiElement resolved = ((GrReferenceExpression)parent).resolve();\n                if (resolved instanceof PsiMethod && \"call\".equals(((PsiMethod)resolved).getName())) {\n                  refExpr = (GrReferenceExpression)parent;\n                }\n              }\n            }\n            if (refExpr == null) continue;\n            final GrClosureSignature signature = generateSignature(owner, refExpr);\n            if (signature == null) continue;\n            final GrCall call = (GrCall)refExpr.getParent();\n            final GrArgumentList argumentList = call.getArgumentList();\n            final GrClosableBlock[] closureArguments =\n              call instanceof GrCallExpression ? ((GrCallExpression)call).getClosureArguments() : GrClosableBlock.EMPTY_ARRAY;\n\n            final GrClosureSignatureUtil.ArgInfo<PsiElement>[] argInfos =\n              GrClosureSignatureUtil.mapParametersToArguments(signature, argumentList, argumentList, closureArguments);\n            if (argInfos == null) continue;\n            final GrClosureSignatureUtil.ArgInfo<PsiElement> argInfo = argInfos[index];\n\n            final GrNamedArgument namedArg;\n            if (argInfo.isMultiArg) {\n              if (argInfo.args.size() == 0) continue;\n              String arg = \"[\" + StringUtil.join(ContainerUtil.map(argInfo.args, new Function<PsiElement, String>() {\n                public String fun(PsiElement element) {\n                  return element.getText();\n                }\n              }), \", \") + \"]\";\n              for (PsiElement psiElement : argInfo.args) {\n                psiElement.delete();\n              }\n              namedArg = factory.createNamedArgument(paramName, factory.createExpressionFromText(arg));\n            }\n            else {\n              if (argInfo.args.size() == 0) continue;\n              final PsiElement argument = argInfo.args.iterator().next();\n              assert argument instanceof GrExpression;\n              namedArg = factory.createNamedArgument(paramName, (GrExpression)argument);\n              argument.delete();\n            }\n            ((GrCall)refExpr.getParent()).addNamedArgument(namedArg);\n          }\n        }\n        catch (IncorrectOperationException e) {\n          LOG.error(e);\n        }\n\n        //Replace of occurrences of old parameter in closure/method\n        final Collection<PsiReference> references = ReferencesSearch.search(param).findAll();\n        for (PsiReference ref : references) {\n          final PsiElement elt = ref.getElement();\n          if (elt instanceof GrReferenceExpression) {\n            GrReferenceExpression expr = (GrReferenceExpression)elt;\n            final GrExpression newExpr = factory.createExpressionFromText(mapName + \".\" + paramName);\n            expr.replaceWithExpression(newExpr, true);\n          }\n        }\n\n        //Add new map parameter to closure/method if it's necessary\n        if (createNewFirstParam) {\n          try {\n            final GrParameter newParam = factory.createParameter(mapName, specifyMapType ? MAP_TYPE_TEXT : \"\", null);\n            list.addParameterToHead(newParam);\n          }\n          catch (IncorrectOperationException e) {\n            LOG.error(e);\n          }\n        }\n\n        //Eliminate obsolete parameter from parameter list\n        param.delete();\n      }\n    };\n\n    CommandProcessor.getInstance().executeCommand(project, new Runnable() {\n      public void run() {\n        ApplicationManager.getApplication().runWriteAction(runnable);\n      }\n    }, REFACTORING_NAME, null);\n  }","id":37224,"modified_method":"private static void performRefactoring(final PsiElement element,\n                                         final GrParametersOwner owner,\n                                         final Collection<PsiElement> occurrences,\n                                         final boolean createNewFirstParam,\n                                         final String mapParamName,\n                                         final boolean specifyMapType) {\n    final GrParameter param = getAppropriateParameter(element);\n    assert param != null;\n    final String paramName = param.getName();\n    final String mapName = createNewFirstParam ? mapParamName : getFirstParameter(owner).getName();\n\n\n    final Project project = element.getProject();\n    final Runnable runnable = new Runnable() {\n      public void run() {\n        final GroovyPsiElementFactory factory = GroovyPsiElementFactory.getInstance(project);\n\n        final GrParameterList list = owner.getParameterList();\n        assert list != null;\n        final int index = list.getParameterNumber(param);\n        if (!createNewFirstParam && index <= 0) { // bad undo\n          return;\n        }\n\n        //Remove old arguments from occurrences\n        //final List<GrCall> calls = getCallOccurrences(occurrences);\n        try {\n          for (PsiElement occurrence : occurrences) {\n            GrReferenceExpression refExpr = null;\n            boolean isExplicitGetterCall = false;\n            if (occurrence instanceof GrReferenceExpression) {\n              final PsiElement parent = occurrence.getParent();\n              if (parent instanceof GrCall) {\n                refExpr = (GrReferenceExpression)occurrence;\n                final PsiElement resolved = refExpr.resolve();\n                if (resolved instanceof PsiMethod &&\n                    GroovyPropertyUtils.isSimplePropertyGetter(((PsiMethod)resolved)) &&\n                    //check for explicit getter call\n                    ((PsiMethod)resolved).getName().equals(refExpr.getName())) {\n                  isExplicitGetterCall = true;\n                }\n              }\n              else if (parent instanceof GrReferenceExpression) {\n                final PsiElement resolved = ((GrReferenceExpression)parent).resolve();\n                if (resolved instanceof PsiMethod && \"call\".equals(((PsiMethod)resolved).getName())) {\n                  refExpr = (GrReferenceExpression)parent;\n                }\n              }\n            }\n            if (refExpr == null) continue;\n            final GrClosureSignature signature = generateSignature(owner, refExpr);\n            if (signature == null) continue;\n            GrCall call;\n            if (isExplicitGetterCall) {\n              PsiElement parent = refExpr.getParent();\n              LOG.assertTrue(parent instanceof GrCall);\n              parent = parent.getParent();\n              if (parent instanceof GrReferenceExpression && \"call\".equals(((GrReferenceExpression)parent).getName())) {\n                parent = parent.getParent();\n              }\n              if (parent instanceof GrCall) {\n                call = (GrCall)parent;\n              }\n              else {\n                continue;\n              }\n            }\n            else {\n              call = (GrCall)refExpr.getParent();\n            }\n\n            if (((GrReferenceExpressionImpl)refExpr).isResolvedToGetter()) {\n              final PsiElement parent = call.getParent();\n              if (parent instanceof GrCall) {\n                call = (GrCall)parent;\n              }\n              else if (parent instanceof GrReferenceExpression && parent.getParent() instanceof GrCall) {\n                final PsiElement resolved = ((GrReferenceExpression)parent).resolve();\n                if (resolved instanceof PsiMethod && \"call\".equals(((PsiMethod)resolved).getName())) {\n                  call = (GrCall)parent.getParent();\n                }\n                else {\n                  continue;\n                }\n              }\n            }\n            final GrArgumentList argumentList = call.getArgumentList();\n            final GrClosableBlock[] closureArguments =\n              call instanceof GrCallExpression ? ((GrCallExpression)call).getClosureArguments() : GrClosableBlock.EMPTY_ARRAY;\n\n            final GrClosureSignatureUtil.ArgInfo<PsiElement>[] argInfos =\n              GrClosureSignatureUtil.mapParametersToArguments(signature, argumentList, argumentList, closureArguments);\n            if (argInfos == null) continue;\n            final GrClosureSignatureUtil.ArgInfo<PsiElement> argInfo = argInfos[index];\n\n            final GrNamedArgument namedArg;\n            if (argInfo.isMultiArg) {\n              if (argInfo.args.size() == 0) continue;\n              String arg = \"[\" + StringUtil.join(ContainerUtil.map(argInfo.args, new Function<PsiElement, String>() {\n                public String fun(PsiElement element) {\n                  return element.getText();\n                }\n              }), \", \") + \"]\";\n              for (PsiElement psiElement : argInfo.args) {\n                psiElement.delete();\n              }\n              namedArg = factory.createNamedArgument(paramName, factory.createExpressionFromText(arg));\n            }\n            else {\n              if (argInfo.args.size() == 0) continue;\n              final PsiElement argument = argInfo.args.iterator().next();\n              assert argument instanceof GrExpression;\n              namedArg = factory.createNamedArgument(paramName, (GrExpression)argument);\n              argument.delete();\n            }\n            call.addNamedArgument(namedArg);\n          }\n        }\n        catch (IncorrectOperationException e) {\n          LOG.error(e);\n        }\n\n        //Replace of occurrences of old parameter in closure/method\n        final Collection<PsiReference> references = ReferencesSearch.search(param).findAll();\n        for (PsiReference ref : references) {\n          final PsiElement elt = ref.getElement();\n          if (elt instanceof GrReferenceExpression) {\n            GrReferenceExpression expr = (GrReferenceExpression)elt;\n            final GrExpression newExpr = factory.createExpressionFromText(mapName + \".\" + paramName);\n            expr.replaceWithExpression(newExpr, true);\n          }\n        }\n\n        //Add new map parameter to closure/method if it's necessary\n        if (createNewFirstParam) {\n          try {\n            final GrParameter newParam = factory.createParameter(mapName, specifyMapType ? MAP_TYPE_TEXT : \"\", null);\n            list.addParameterToHead(newParam);\n          }\n          catch (IncorrectOperationException e) {\n            LOG.error(e);\n          }\n        }\n\n        //Eliminate obsolete parameter from parameter list\n        param.delete();\n      }\n    };\n\n    CommandProcessor.getInstance().executeCommand(project, new Runnable() {\n      public void run() {\n        ApplicationManager.getApplication().runWriteAction(runnable);\n      }\n    }, REFACTORING_NAME, null);\n  }","commit_id":"63766ebacca0001e8e2f2883901b12337bbbbff1","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private GroovyResolveResult[] resolveMethodOrProperty(boolean allVariants, GrExpression upToArgument) {\n    String name = getReferenceName();\n    if (name == null) return GroovyResolveResult.EMPTY_ARRAY;\n\n    final PsiType[] argTypes = PsiUtil.getArgumentTypes(this, false, upToArgument);\n    MethodResolverProcessor methodResolver = runMethodResolverProcessor(argTypes, allVariants);\n    assert methodResolver != null;\n\n    final String[] names = GroovyPropertyUtils.suggestGettersName(name);\n    List<GroovyResolveResult> list = new ArrayList<GroovyResolveResult>();\n    for (String getterName : names) {\n      AccessorResolverProcessor getterResolver = new AccessorResolverProcessor(getterName, this, true);\n      resolveImpl(getterResolver);\n      final GroovyResolveResult[] candidates = getterResolver.getCandidates(); //can be only one candidate\n      if (!allVariants && candidates.length == 1 && candidates[0].isStaticsOK()) {\n        if (methodResolver.hasApplicableCandidates()) return methodResolver.getCandidates();\n        putUserData(IS_RESOLVED_TO_GETTER, true);\n        return candidates;\n      }\n      else {\n        ContainerUtil.addAll(list, candidates);\n      }\n    }\n\n    PropertyResolverProcessor propertyResolver = new PropertyResolverProcessor(name, this);\n    resolveImpl(propertyResolver);\n    if (!allVariants) {\n      final GroovyResolveResult[] propertyCandidates = propertyResolver.getCandidates();\n      for (GroovyResolveResult candidate : propertyCandidates) {\n        if (candidate.isStaticsOK() && candidate.isAccessible() && candidate.getElement() instanceof GrVariable &&\n            !(candidate.getElement() instanceof GrField)) {\n          return propertyResolver.getCandidates();\n        }\n      }\n      if (methodResolver.hasApplicableCandidates()) return methodResolver.getCandidates();\n      if (propertyCandidates.length > 0) return propertyCandidates;\n    }\n\n    if (allVariants) {\n      if (list.isEmpty()) ContainerUtil.addAll(list, propertyResolver.getCandidates());\n      ContainerUtil.addAll(list, methodResolver.getCandidates());\n      return list.toArray(new GroovyResolveResult[list.size()]);\n    }\n\n    if (methodResolver.hasCandidates()) {\n      return methodResolver.getCandidates();\n    }\n    else if (list.size() > 0) {\n      putUserData(IS_RESOLVED_TO_GETTER, true);\n      return list.toArray(new GroovyResolveResult[list.size()]);\n    }\n\n    return GroovyResolveResult.EMPTY_ARRAY;\n  }","id":37225,"modified_method":"/**\n   * priority: inside class C: local variable, c.method, c.property, c.getter\n   *           in other places: local variable, c.method, c.getter, c.property\n   */\n  private GroovyResolveResult[] resolveMethodOrProperty(boolean allVariants, GrExpression upToArgument) {\n    String name = getReferenceName();\n    if (name == null) return GroovyResolveResult.EMPTY_ARRAY;\n\n    List<GroovyResolveResult> allCandidates = new ArrayList<GroovyResolveResult>();\n\n    PropertyResolverProcessor propertyResolver = new PropertyResolverProcessor(name, this);\n    resolveImpl(propertyResolver);\n    final GroovyResolveResult[] propertyCandidates = propertyResolver.getCandidates();\n\n    if (!allVariants) { //search for local variables\n      for (GroovyResolveResult candidate : propertyCandidates) {\n        if (candidate.getElement() instanceof GrVariable && !(candidate.getElement() instanceof GrField)) {\n          return propertyResolver.getCandidates();\n        }\n      }\n    }\n    ContainerUtil.addAll(allCandidates, propertyCandidates);\n\n    //search for methods\n    final PsiType[] argTypes = PsiUtil.getArgumentTypes(this, false, upToArgument);\n    MethodResolverProcessor methodResolver = runMethodResolverProcessor(argTypes, allVariants);\n    assert methodResolver != null;\n    if (!allVariants && methodResolver.hasApplicableCandidates()) {\n      return methodResolver.getCandidates();\n    }\n    ContainerUtil.addAll(allCandidates, methodResolver.getCandidates());\n\n    //search for fields inside its class\n    if (!allVariants) {\n      for (GroovyResolveResult candidate : propertyCandidates) {\n        final PsiElement element = candidate.getElement();\n        if (element instanceof GrField) {\n          final PsiClass containingClass = ((PsiField)element).getContainingClass();\n          if (containingClass != null && PsiTreeUtil.isAncestor(containingClass, this, true)) return propertyCandidates;\n        }\n      }\n    }\n\n    //search for getters\n    final String[] names = GroovyPropertyUtils.suggestGettersName(name);\n    for (String getterName : names) {\n      AccessorResolverProcessor getterResolver = new AccessorResolverProcessor(getterName, this, true);\n      resolveImpl(getterResolver);\n      final GroovyResolveResult[] candidates = getterResolver.getCandidates(); //can be only one candidate\n      if (!allVariants && candidates.length == 1) {\n        putUserData(IS_RESOLVED_TO_GETTER, true);\n        return candidates;\n      }\n      ContainerUtil.addAll(allCandidates, candidates);\n    }\n\n    if (allCandidates.size() > 0) {\n      return allCandidates.toArray(new GroovyResolveResult[allCandidates.size()]);\n    }\n    return GroovyResolveResult.EMPTY_ARRAY;\n  }","commit_id":"63766ebacca0001e8e2f2883901b12337bbbbff1","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public Object[] getVariants() {\n    ResolverProcessor processor = getResolveProcessor(this, null, true);\n    GrExpression qualifierExpression = getQualifierExpression();\n    if (qualifierExpression == null) {\n      ResolveUtil.treeWalkUp(this, processor);\n    } else {\n      PsiType qualifierType = qualifierExpression.getType();\n      if (qualifierType instanceof PsiClassType) {\n        PsiClass qualifierClass = ((PsiClassType) qualifierType).resolve();\n        if (qualifierClass != null) {\n          qualifierClass.processDeclarations(processor, PsiSubstitutor.EMPTY, null, this);\n        }\n      }\n    }\n\n    GroovyResolveResult[] candidates = processor.getCandidates();\n    if (candidates.length == 0) return PsiNamedElement.EMPTY_ARRAY;\n    return ResolveUtil.mapToElements(candidates);\n  }","id":37226,"modified_method":"public Object[] getVariants() {\n\n    Object[] propertyVariants = getVariantsImpl(getResolveProcessor(this, null, true));\n    if (getKind() == Kind.TYPE_OR_PROPERTY) {\n      ResolverProcessor classVariantsCollector = new ResolverProcessor(null, EnumSet.of(ResolveKind.CLASS), this, true);\n      GroovyResolveResult[] classVariants = classVariantsCollector.getCandidates();\n      return ArrayUtil.mergeArrays(propertyVariants, classVariants, Object.class);\n    }\n\n    return propertyVariants;\n  }","commit_id":"31385052c0b29c89ead73bf30b61c1ae87c83719","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static ResolverProcessor getResolveProcessor(GrReferenceExpressionImpl refExpr, String name, boolean forCompletion) {\n    Kind kind = refExpr.getKind();\n    ResolverProcessor processor;\n    if (kind == Kind.TYPE_OR_PROPERTY) {\n      processor = new ResolverProcessor(name, EnumSet.of(ResolveKind.PROPERTY, ResolveKind.METHOD, ResolveKind.CLASS), refExpr, forCompletion); //todo package?\n    } else if (kind == Kind.METHOD_OR_PROPERTY) {\n      processor = new MethodResolverProcessor(name, refExpr, forCompletion);\n    } else {\n      processor = new ResolverProcessor(name, EnumSet.of(ResolveKind.METHOD, ResolveKind.PROPERTY), refExpr, forCompletion);\n    }\n\n    return processor;\n  }","id":37227,"modified_method":"private static ResolverProcessor getResolveProcessor(GrReferenceExpressionImpl refExpr, String name, boolean forCompletion) {\n    Kind kind = refExpr.getKind();\n    return getMethodOrPropertyResolveProcessor(refExpr, name, forCompletion, kind);\n  }","commit_id":"31385052c0b29c89ead73bf30b61c1ae87c83719","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GroovyResolveResult[] resolve(GrReferenceExpressionImpl refExpr, boolean incompleteCode) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      String name = refExpr.getReferenceName();\n      if (name == null) return null;\n      ResolverProcessor processor = getResolveProcessor(refExpr, name, false);\n\n      if (qualifier == null) {\n        ResolveUtil.treeWalkUp(refExpr, processor);\n      } else {\n        PsiType qualifierType = qualifier.getType();\n        if (qualifierType instanceof PsiClassType) {\n          PsiClass qualifierClass = ((PsiClassType) qualifierType).resolve();\n          if (qualifierClass != null) {\n            qualifierClass.processDeclarations(processor, PsiSubstitutor.EMPTY, null, refExpr);\n          }\n        }\n      }\n\n      return processor.getCandidates();\n    }","id":37228,"modified_method":"public GroovyResolveResult[] resolve(GrReferenceExpressionImpl refExpr, boolean incompleteCode) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      String name = refExpr.getReferenceName();\n      if (name == null) return null;\n      ResolverProcessor processor = getResolveProcessor(refExpr, name, false);\n\n      resolveImpl(refExpr, qualifier, processor);\n\n      GroovyResolveResult[] propertyCandidates = processor.getCandidates();\n      if (propertyCandidates.length > 0) return propertyCandidates;\n      if (refExpr.getKind() == Kind.TYPE_OR_PROPERTY) {\n        ResolverProcessor classProcessor = new ResolverProcessor(refExpr.getReferenceName(), EnumSet.of(ResolveKind.CLASS), refExpr, false);\n        resolveImpl(refExpr, qualifier, classProcessor);\n        return classProcessor.getCandidates();\n      }\n\n      return GroovyResolveResult.EMPTY_ARRAY;\n    }","commit_id":"31385052c0b29c89ead73bf30b61c1ae87c83719","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiType getType() {\n\n    PsiElement resolved = resolve();\n    if (resolved instanceof PsiClass) {\n      return getManager().getElementFactory().createType((PsiClass) resolved);\n    } else if (resolved instanceof PsiVariable) {\n      return ((PsiVariable) resolved).getType();\n    } else if (resolved instanceof PsiMethod) {\n      //todo\n    } else if (resolved instanceof GrReferenceExpression) {\n      PsiElement parent = resolved.getParent();\n      if (parent instanceof GrAssignmentExpression) {\n        GrAssignmentExpression assignment = (GrAssignmentExpression) parent;\n        if (resolved.equals(assignment.getLValue())) {\n          GrExpression rValue = assignment.getRValue();\n          if (rValue != null) {\n            PsiType rType = rValue.getType();\n            if (rType != null) return rType;\n          }\n        }\n      }\n    }\n\n    return null;\n  }","id":37229,"modified_method":"public PsiType getType() {\n\n    PsiElement resolved = resolve();\n    if (resolved instanceof PsiClass) {\n      return getManager().getElementFactory().createType((PsiClass) resolved);\n    } else if (resolved instanceof PsiVariable) {\n      return ((PsiVariable) resolved).getType();\n    } else if (resolved instanceof PsiMethod) {\n      PsiMethod method = (PsiMethod) resolved;\n      if (PropertyUtil.isSimplePropertySetter(method)) {\n        return method.getParameterList().getParameters()[0].getType();\n      }\n      return method.getReturnType();\n    } else if (resolved instanceof GrReferenceExpression) {\n      PsiElement parent = resolved.getParent();\n      if (parent instanceof GrAssignmentExpression) {\n        GrAssignmentExpression assignment = (GrAssignmentExpression) parent;\n        if (resolved.equals(assignment.getLValue())) {\n          GrExpression rValue = assignment.getRValue();\n          if (rValue != null) {\n            PsiType rType = rValue.getType();\n            if (rType != null) return rType;\n          }\n        }\n      }\n    }\n\n    return null;\n  }","commit_id":"31385052c0b29c89ead73bf30b61c1ae87c83719","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public <T> T getHint(Class<T> hintClass) {\n    if (NameHint.class == hintClass && myName != null){\n      return (T) this;\n    }\n    else if (ClassHint.class == hintClass) {\n      return (T) this;\n    }\n\n    return null;\n  }","id":37230,"modified_method":"public <T> T getHint(Class<T> hintClass) {\n    if (NameHint.class == hintClass && myName != null){\n      return (T) this;\n    }\n    else if (ClassHint.class == hintClass) {\n      return (T) this;\n    }\n    else if (ElementClassHint.class == hintClass) {\n      return (T) this;\n    }\n\n    return null;\n  }","commit_id":"31385052c0b29c89ead73bf30b61c1ae87c83719","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void sendState() throws InterruptedException, MalformedURLException {\n            URL url = newCollectorUrl();\n            try {\n                //todo: does the connection not need to be closed?\n                HttpURLConnection connection = openConnection(url);\n                OutputStream outputStream = connection.getOutputStream();\n                try {\n                    identifier.write(outputStream);\n                    ObjectDataOutputStream out = serializationService.createObjectDataOutputStream(outputStream);\n                    TimedMemberState timedMemberState = timedMemberStateFactory.createTimedMemberState();\n                    timedMemberState.writeData(out);\n                    outputStream.flush();\n                    post(connection);\n                } finally {\n                    closeResource(outputStream);\n                }\n            } catch (ConnectException e) {\n                if (logger.isFinestEnabled()) {\n                    logger.finest(e);\n                } else {\n                    logger.info(\"Failed to connect to:\" + url);\n                }\n            } catch (Exception e) {\n                logger.warning(e);\n            }\n        }","id":37231,"modified_method":"private void sendState() throws InterruptedException, MalformedURLException {\n            URL url = newCollectorUrl();\n            try {\n                //todo: does the connection not need to be closed?\n                HttpURLConnection connection = openConnection(url);\n                OutputStream outputStream = connection.getOutputStream();\n                try {\n                    identifier.write(outputStream);\n                    ObjectDataOutputStream out = serializationService.createObjectDataOutputStream(outputStream);\n                    TimedMemberState timedMemberState = timedMemberStateFactory.createTimedMemberState();\n                    timedMemberState.writeData(out);\n                    outputStream.flush();\n                    post(connection);\n                    if (manCenterConnectionLost) {\n                        logger.info(\"Connection to management center restored.\");\n                    }\n                    manCenterConnectionLost = false;\n                } finally {\n                    closeResource(outputStream);\n                }\n            } catch (ConnectException e) {\n                if (!manCenterConnectionLost) {\n                    manCenterConnectionLost = true;\n                    log(\"Failed to connect to:\" + url, e);\n                }\n            } catch (Exception e) {\n                logger.warning(e);\n            }\n        }","commit_id":"3d9904296835b9ccf926d42492aef974434e4df6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private void processTask() {\n            ObjectDataInputStream inputStream = null;\n            try {\n                //todo: don't we need to close the connection?\n                inputStream = openTaskInputStream();\n                int taskId = inputStream.readInt();\n                if (taskId <= 0) {\n                    return;\n                }\n\n                ConsoleRequest task = newTask(inputStream);\n                processTaskAndPostResponse(taskId, task);\n            } catch (Exception e) {\n                //todo: even if there is an internal error with the task, we don't see it. That is kinda shitty\n                logger.finest(e);\n            } finally {\n                IOUtil.closeResource(inputStream);\n            }\n        }","id":37232,"modified_method":"private void processTask() {\n            ObjectDataInputStream inputStream = null;\n            try {\n                //todo: don't we need to close the connection?\n                inputStream = openTaskInputStream();\n                int taskId = inputStream.readInt();\n                if (taskId <= 0) {\n                    return;\n                }\n\n                ConsoleRequest task = newTask(inputStream);\n                processTaskAndPostResponse(taskId, task);\n                if (manCenterConnectionLost) {\n                    logger.info(\"Connection to management center restored.\");\n                }\n                manCenterConnectionLost = false;\n            } catch (ConnectException e) {\n                if (!manCenterConnectionLost) {\n                    manCenterConnectionLost = true;\n                    log(\"Failed to connect to management center\", e);\n                }\n            } catch (Exception e) {\n                //todo: even if there is an internal error with the task, we don't see it. That is kinda shitty\n                logger.finest(e);\n            } finally {\n                IOUtil.closeResource(inputStream);\n            }\n        }","commit_id":"3d9904296835b9ccf926d42492aef974434e4df6","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"/****************\n\t * Constructor.\n\t * \n\t * @param cloud .\n\t * @param template .\n\t * @param cloudFileContents .\n\t * @param cloudTemplateName .\n\t */\n\tpublic CloudifyMachineProvisioningConfig(final Cloud cloud, final CloudTemplate template,\n\t\t\tfinal String cloudTemplateName, final String managementTemplateRemoteDirectory) {\n\n\t\tsetMinimumNumberOfCpuCoresPerMachine(template.getNumberOfCores());\n\n\t\tsetReservedMemoryCapacityPerMachineInMB(cloud.getProvider().getReservedMemoryCapacityPerMachineInMB());\n\n\t\tsetCloudConfigurationDirectory(managementTemplateRemoteDirectory);\n\t\tlogger.info(\"Setting cloud configuration directory to: \" + template.getRemoteDirectory());\n\t\tsetCloudTemplateName(cloudTemplateName);\n\n\t}","id":37233,"modified_method":"/****************\n\t * Constructor.\n\t * \n\t * @param cloud .\n\t * @param template .\n\t * @param cloudFileContents .\n\t * @param cloudTemplateName .\n\t */\n\tpublic CloudifyMachineProvisioningConfig(final Cloud cloud, final CloudTemplate template,\n\t\t\tfinal String cloudTemplateName, final String managementTemplateRemoteDirectory) {\n\n\t\tsetMinimumNumberOfCpuCoresPerMachine(template.getNumberOfCores());\n\n\t\tsetReservedMemoryCapacityPerMachineInMB(cloud.getProvider().getReservedMemoryCapacityPerMachineInMB());\n\t\t\n\t\tString remoteDir = managementTemplateRemoteDirectory;\n\t\tlogger.log(Level.FINE, \"Original remote directory is: \" + remoteDir);\n\t\tif (template.getFileTransfer().equals(FileTransferModes.CIFS)) {\n\t\t\tlogger.log(Level.FINE, \"Running on windows, modifying remote directory config. Original was: \" + remoteDir);\n\t\t\tremoteDir = getWindowsRemoteDirPath(managementTemplateRemoteDirectory);\n\t\t}\n\t\tlogger.log(Level.INFO, \"Setting cloud configuration directory to: \" + remoteDir);\n\t\tsetCloudConfigurationDirectory(remoteDir);\n\t\tsetCloudTemplateName(cloudTemplateName);\n\n\t}","commit_id":"8721d1e0a57d66445f128213dd95493deac3b5d8","url":"https://github.com/CloudifySource/cloudify"},{"original_method":"@Override\n\tpublic void afterPropertiesSet()\n\t\t\tthrows Exception {\n\n\t\tlogger = java.util.logging.Logger\n\t\t\t\t.getLogger(ElasticMachineProvisioningCloudifyAdapter.class.getName());\n\n\t\tfinal String cloudConfigDirectory =\n\t\t\t\tproperties.get(CloudifyConstants.ELASTIC_PROPERTIES_CLOUD_CONFIGURATION_DIRECTORY);\n\t\tif (cloudConfigDirectory == null) {\n\t\t\tlogger.severe(\"Missing cloud configuration property. Properties are: \" + this.properties);\n\t\t\tthrow new IllegalArgumentException(\"Cloud configuration directory was not set!\");\n\t\t}\n\n\t\ttry {\n\t\t\tthis.cloud = ServiceReader.readCloudFromDirectory(cloudConfigDirectory);\n\t\t\tthis.cloudTemplateName = properties.get(CloudifyConstants.ELASTIC_PROPERTIES_CLOUD_TEMPLATE_NAME);\n\n\t\t\tif (this.cloudTemplateName == null) {\n\t\t\t\tthrow new BeanConfigurationException(\"Cloud template was not set!\");\n\t\t\t}\n\n\t\t\tfinal CloudTemplate cloudTemplate = this.cloud.getTemplates().get(this.cloudTemplateName);\n\t\t\tif (cloudTemplate == null) {\n\t\t\t\tthrow new BeanConfigurationException(\"The provided cloud template name: \" + this.cloudTemplateName\n\t\t\t\t\t\t+ \" was not found in the cloud configuration\");\n\t\t\t}\n\n\t\t\t// This code runs on the ESM in the remote machine,\n\t\t\t// so set the local directory to the value of the remote directory\n\t\t\tlogger.info(\"Remote Directory is: \" + cloudTemplate.getRemoteDirectory());\n\t\t\tif (ServiceUtils.isWindows()) {\n\t\t\t\tlogger.info(\"Windows machine - modifying local directory location\");\n\t\t\t\tString localDirectoryName = cloudTemplate.getRemoteDirectory();\n\t\t\t\tlocalDirectoryName = localDirectoryName.replace(\"$\", \"\");\n\t\t\t\tif (localDirectoryName.startsWith(\"/\")) {\n\t\t\t\t\tlocalDirectoryName = localDirectoryName.substring(1);\n\t\t\t\t}\n\t\t\t\tif (localDirectoryName.charAt(1) == '/') {\n\t\t\t\t\tlocalDirectoryName = localDirectoryName.substring(0, 1) + \":\" + localDirectoryName.substring(1);\n\t\t\t\t}\n\t\t\t\tlogger.info(\"Modified local dir name is: \" + localDirectoryName);\n\n\t\t\t\tcloudTemplate.setLocalDirectory(localDirectoryName);\n\t\t\t} else {\n\t\t\t\tcloudTemplate.setLocalDirectory(cloudTemplate.getRemoteDirectory());\n\t\t\t}\n\n\t\t\t// load the provisioning class and set it up\n\t\t\ttry {\n\t\t\t\tthis.cloudifyProvisioning =\n\t\t\t\t\t\t(ProvisioningDriver) Class.forName(this.cloud.getConfiguration().getClassName()).newInstance();\n\n\t\t\t\tif (cloudifyProvisioning instanceof ProvisioningDriverClassContextAware) {\n\t\t\t\t\tfinal ProvisioningDriverClassContext provisioningDriverContext =\n\t\t\t\t\t\t\tlazyCreateProvisioningDriverClassContext(cloudifyProvisioning);\n\t\t\t\t\tfinal ProvisioningDriverClassContextAware contextAware =\n\t\t\t\t\t\t\t(ProvisioningDriverClassContextAware) cloudifyProvisioning;\n\t\t\t\t\tcontextAware.setProvisioningDriverClassContext(provisioningDriverContext);\n\t\t\t\t}\n\n\t\t\t\t// checks if a service level configuration exists. If so, save the configuration to local file and pass\n\t\t\t\t// to cloud driver.\n\t\t\t\thandleServiceCloudConfiguration();\n\t\t\t\tthis.cloudifyProvisioning.setConfig(cloud, cloudTemplateName, false, serviceName);\n\n\t\t\t} catch (final ClassNotFoundException e) {\n\t\t\t\tthrow new BeanConfigurationException(\"Failed to load provisioning class for cloud: \"\n\t\t\t\t\t\t+ this.cloud.getName() + \". Class not found: \" + this.cloud.getConfiguration().getClassName(),\n\t\t\t\t\t\te);\n\t\t\t} catch (final Exception e) {\n\t\t\t\tthrow new BeanConfigurationException(\"Failed to load provisioning class for cloud: \"\n\t\t\t\t\t\t+ this.cloud.getName(), e);\n\t\t\t}\n\n\t\t\tthis.lookupLocatorsString = createLocatorsString();\n\n\t\t\tlogger.info(\"Locators string used for new instances will be: \" + this.lookupLocatorsString);\n\n\t\t} catch (final DSLException e) {\n\t\t\tlogger.severe(\"Could not parse the provided cloud configuration from : \" + cloudConfigDirectory + \": \"\n\t\t\t\t\t+ e.getMessage());\n\t\t\tthrow new BeanConfigurationException(\"Could not parse the prvided cloud configuration: \"\n\t\t\t\t\t+ cloudConfigDirectory\n\t\t\t\t\t+ \": \" + e.getMessage(), e);\n\t\t}\n\n\t}","id":37234,"modified_method":"@Override\n\tpublic void afterPropertiesSet()\n\t\t\tthrows Exception {\n\n\t\tlogger = java.util.logging.Logger\n\t\t\t\t.getLogger(ElasticMachineProvisioningCloudifyAdapter.class.getName());\n\n\t\tfinal String cloudConfigDirectory =\n\t\t\t\tproperties.get(CloudifyConstants.ELASTIC_PROPERTIES_CLOUD_CONFIGURATION_DIRECTORY);\n\t\tif (cloudConfigDirectory == null) {\n\t\t\tlogger.severe(\"Missing cloud configuration property. Properties are: \" + this.properties);\n\t\t\tthrow new IllegalArgumentException(\"Cloud configuration directory was not set!\");\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tthis.cloud = ServiceReader.readCloudFromDirectory(cloudConfigDirectory);\n\t\t\tthis.cloudTemplateName = properties.get(CloudifyConstants.ELASTIC_PROPERTIES_CLOUD_TEMPLATE_NAME);\n\n\t\t\tif (this.cloudTemplateName == null) {\n\t\t\t\tthrow new BeanConfigurationException(\"Cloud template was not set!\");\n\t\t\t}\n\n\t\t\tfinal CloudTemplate cloudTemplate = this.cloud.getTemplates().get(this.cloudTemplateName);\n\t\t\tif (cloudTemplate == null) {\n\t\t\t\tthrow new BeanConfigurationException(\"The provided cloud template name: \" + this.cloudTemplateName\n\t\t\t\t\t\t+ \" was not found in the cloud configuration\");\n\t\t\t}\n\n\t\t\t// This code runs on the ESM in the remote machine,\n\t\t\t// so set the local directory to the value of the remote directory\n\t\t\tlogger.info(\"Remote Directory is: \" + cloudTemplate.getRemoteDirectory());\n\t\t\t//if running a windows server.\n\t\t\tif (cloudTemplate.getFileTransfer().equals(FileTransferModes.CIFS)) {\n\t\t\t\tlogger.info(\"Windows machine - modifying local directory location\");\n\t\t\t\tString remoteDirName = cloudTemplate.getRemoteDirectory();\n\t\t\t\tString windowsLocalDirPath = getWindowsLocalDirPath(remoteDirName, cloudTemplate.getLocalDirectory());\n\t\t\t\tlogger.info(\"Modified local dir name is: \" + windowsLocalDirPath);\n\n\t\t\t\tcloudTemplate.setLocalDirectory(windowsLocalDirPath);\n\t\t\t} else {\n\t\t\t\tcloudTemplate.setLocalDirectory(cloudTemplate.getRemoteDirectory());\n\t\t\t}\n\n\t\t\t// load the provisioning class and set it up\n\t\t\ttry {\n\t\t\t\tthis.cloudifyProvisioning =\n\t\t\t\t\t\t(ProvisioningDriver) Class.forName(this.cloud.getConfiguration().getClassName()).newInstance();\n\n\t\t\t\tif (cloudifyProvisioning instanceof ProvisioningDriverClassContextAware) {\n\t\t\t\t\tfinal ProvisioningDriverClassContext provisioningDriverContext =\n\t\t\t\t\t\t\tlazyCreateProvisioningDriverClassContext(cloudifyProvisioning);\n\t\t\t\t\tfinal ProvisioningDriverClassContextAware contextAware =\n\t\t\t\t\t\t\t(ProvisioningDriverClassContextAware) cloudifyProvisioning;\n\t\t\t\t\tcontextAware.setProvisioningDriverClassContext(provisioningDriverContext);\n\t\t\t\t}\n\n\t\t\t\t// checks if a service level configuration exists. If so, save the configuration to local file and pass\n\t\t\t\t// to cloud driver.\n\t\t\t\thandleServiceCloudConfiguration();\n\t\t\t\tthis.cloudifyProvisioning.setConfig(cloud, cloudTemplateName, false, serviceName);\n\n\t\t\t} catch (final ClassNotFoundException e) {\n\t\t\t\tthrow new BeanConfigurationException(\"Failed to load provisioning class for cloud: \"\n\t\t\t\t\t\t+ this.cloud.getName() + \". Class not found: \" + this.cloud.getConfiguration().getClassName(),\n\t\t\t\t\t\te);\n\t\t\t} catch (final Exception e) {\n\t\t\t\tthrow new BeanConfigurationException(\"Failed to load provisioning class for cloud: \"\n\t\t\t\t\t\t+ this.cloud.getName(), e);\n\t\t\t}\n\n\t\t\tthis.lookupLocatorsString = createLocatorsString();\n\n\t\t\tlogger.info(\"Locators string used for new instances will be: \" + this.lookupLocatorsString);\n\n\t\t} catch (final DSLException e) {\n\t\t\tlogger.severe(\"Could not parse the provided cloud configuration from : \" + cloudConfigDirectory + \": \"\n\t\t\t\t\t+ e.getMessage());\n\t\t\tthrow new BeanConfigurationException(\"Could not parse the prvided cloud configuration: \"\n\t\t\t\t\t+ cloudConfigDirectory\n\t\t\t\t\t+ \": \" + e.getMessage(), e);\n\t\t}\n\n\t}","commit_id":"8721d1e0a57d66445f128213dd95493deac3b5d8","url":"https://github.com/CloudifySource/cloudify"},{"original_method":"/**\n     * @param config path to config file.\n     * @return Cluster configuration.\n     */\n    public static ClusterProperties from(String config) {\n        try {\n            Properties props = null;\n\n            if (config != null) {\n                props = new Properties();\n\n                props.load(new FileInputStream(config));\n            }\n\n            ClusterProperties prop = new ClusterProperties();\n\n            prop.mesosUrl = getStringProperty(MESOS_MASTER_URL, props, DEFAULT_MESOS_MASTER_URL);\n\n            prop.httpServerHost = getStringProperty(IGNITE_HTTP_SERVER_HOST, props, getNonLoopbackAddress());\n\n            String port = System.getProperty(\"PORT0\");\n\n            if (port != null && !port.isEmpty())\n                prop.httpServerPort = Integer.valueOf(port);\n            else\n                prop.httpServerPort = Integer.valueOf(getStringProperty(IGNITE_HTTP_SERVER_PORT, props,\n                    DEFAULT_HTTP_SERVER_PORT));\n\n            prop.clusterName = getStringProperty(IGNITE_CLUSTER_NAME, props, DEFAULT_CLUSTER_NAME);\n\n            prop.userLibsUrl = getStringProperty(IGNITE_USERS_LIBS_URL, props, null);\n            prop.ignitePackageUrl = getStringProperty(IGNITE_PACKAGE_URL, props, null);\n            prop.igniteCfgUrl = getStringProperty(IGNITE_CONFIG_XML_URL, props, null);\n\n            prop.cpu = getDoubleProperty(IGNITE_TOTAL_CPU, props, UNLIMITED);\n            prop.cpuPerNode = getDoubleProperty(IGNITE_RUN_CPU_PER_NODE, props, UNLIMITED);\n            prop.mem = getDoubleProperty(IGNITE_TOTAL_MEMORY, props, UNLIMITED);\n            prop.memPerNode = getDoubleProperty(IGNITE_MEMORY_PER_NODE, props, UNLIMITED);\n            prop.disk = getDoubleProperty(IGNITE_TOTAL_DISK_SPACE, props, UNLIMITED);\n            prop.diskPerNode = getDoubleProperty(IGNITE_DISK_SPACE_PER_NODE, props, 1024.0);\n            prop.nodeCnt = getDoubleProperty(IGNITE_NODE_COUNT, props, UNLIMITED);\n            prop.minCpu = getDoubleProperty(IGNITE_MIN_CPU_PER_NODE, props, DEFAULT_RESOURCE_MIN_CPU);\n            prop.minMemory = getDoubleProperty(IGNITE_MIN_MEMORY_PER_NODE, props, DEFAULT_RESOURCE_MIN_MEM);\n\n            prop.igniteVer = getStringProperty(IGNITE_VERSION, props, DEFAULT_IGNITE_VERSION);\n            prop.igniteWorkDir = getStringProperty(IGNITE_WORK_DIR, props, DEFAULT_IGNITE_WORK_DIR);\n            prop.igniteCfg = getStringProperty(IGNITE_CONFIG_XML, props, null);\n            prop.userLibs = getStringProperty(IGNITE_USERS_LIBS, props, null);\n\n            String pattern = getStringProperty(IGNITE_HOSTNAME_CONSTRAINT, props, null);\n\n            if (pattern != null) {\n                try {\n                    prop.hostnameConstraint = Pattern.compile(pattern);\n                }\n                catch (PatternSyntaxException e) {\n                    log.warn(\"IGNITE_HOSTNAME_CONSTRAINT has invalid pattern. It will be ignore.\", e);\n                }\n            }\n\n            return prop;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }","id":37235,"modified_method":"/**\n     * @param config path to config file.\n     * @return Cluster configuration.\n     */\n    public static ClusterProperties from(String config) {\n        try {\n            Properties props = null;\n\n            if (config != null) {\n                props = new Properties();\n\n                props.load(new FileInputStream(config));\n            }\n\n            ClusterProperties prop = new ClusterProperties();\n\n            prop.mesosUrl = getStringProperty(MESOS_MASTER_URL, props, DEFAULT_MESOS_MASTER_URL);\n\n            prop.httpServerHost = getStringProperty(IGNITE_HTTP_SERVER_HOST, props, getNonLoopbackAddress());\n\n            String port = System.getProperty(\"PORT0\");\n\n            if (port != null && !port.isEmpty())\n                prop.httpServerPort = Integer.valueOf(port);\n            else\n                prop.httpServerPort = Integer.valueOf(getStringProperty(IGNITE_HTTP_SERVER_PORT, props,\n                    DEFAULT_HTTP_SERVER_PORT));\n\n            prop.clusterName = getStringProperty(IGNITE_CLUSTER_NAME, props, DEFAULT_CLUSTER_NAME);\n\n            prop.userLibsUrl = getStringProperty(IGNITE_USERS_LIBS_URL, props, null);\n            prop.ignitePackageUrl = getStringProperty(IGNITE_PACKAGE_URL, props, null);\n            prop.igniteCfgUrl = getStringProperty(IGNITE_CONFIG_XML_URL, props, null);\n\n            prop.cpu = getDoubleProperty(IGNITE_TOTAL_CPU, props, UNLIMITED);\n            prop.cpuPerNode = getDoubleProperty(IGNITE_RUN_CPU_PER_NODE, props, UNLIMITED);\n            prop.mem = getDoubleProperty(IGNITE_TOTAL_MEMORY, props, UNLIMITED);\n            prop.memPerNode = getDoubleProperty(IGNITE_MEMORY_PER_NODE, props, UNLIMITED);\n            prop.disk = getDoubleProperty(IGNITE_TOTAL_DISK_SPACE, props, UNLIMITED);\n            prop.diskPerNode = getDoubleProperty(IGNITE_DISK_SPACE_PER_NODE, props, 1024.0);\n            prop.nodeCnt = getDoubleProperty(IGNITE_NODE_COUNT, props, UNLIMITED);\n            prop.minCpu = getDoubleProperty(IGNITE_MIN_CPU_PER_NODE, props, DEFAULT_RESOURCE_MIN_CPU);\n            prop.minMemory = getDoubleProperty(IGNITE_MIN_MEMORY_PER_NODE, props, DEFAULT_RESOURCE_MIN_MEM);\n\n            prop.igniteVer = getStringProperty(IGNITE_VERSION, props, DEFAULT_IGNITE_VERSION);\n            prop.igniteWorkDir = getStringProperty(IGNITE_WORK_DIR, props, DEFAULT_IGNITE_WORK_DIR);\n            prop.igniteCfg = getStringProperty(IGNITE_CONFIG_XML, props, null);\n            prop.userLibs = getStringProperty(IGNITE_USERS_LIBS, props, null);\n\n            String pattern = getStringProperty(IGNITE_HOSTNAME_CONSTRAINT, props, null);\n\n            if (pattern != null) {\n                try {\n                    prop.hostnameConstraint = Pattern.compile(pattern);\n                }\n                catch (PatternSyntaxException e) {\n                    log.log(Level.WARNING, \"IGNITE_HOSTNAME_CONSTRAINT has invalid pattern. It will be ignore.\", e);\n                }\n            }\n\n            return prop;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Main methods has only one optional parameter - path to properties files.\n     *\n     * @param args Args.\n     */\n    public static void main(String[] args) throws Exception {\n        final int frameworkFailoverTimeout = 0;\n\n        // Have Mesos fill in the current user.\n        Protos.FrameworkInfo.Builder frameworkBuilder = Protos.FrameworkInfo.newBuilder()\n            .setName(IGNITE_FRAMEWORK_NAME)\n            .setUser(\"\")\n            .setFailoverTimeout(frameworkFailoverTimeout);\n\n        if (System.getenv(\"MESOS_CHECKPOINT\") != null) {\n            log.info(\"Enabling checkpoint for the framework\");\n\n            frameworkBuilder.setCheckpoint(true);\n        }\n\n        ClusterProperties clusterProps = ClusterProperties.from(args.length >= 1 ? args[0] : null);\n\n        String baseUrl = String.format(\"http://%s:%d\", clusterProps.httpServerHost(), clusterProps.httpServerPort());\n\n        JettyServer httpServer = new JettyServer();\n\n        httpServer.start(\n            new InetSocketAddress(clusterProps.httpServerHost(), clusterProps.httpServerPort()),\n            new ResourceHandler(clusterProps.userLibs(), clusterProps.igniteCfg(), clusterProps.igniteWorkDir())\n        );\n\n        ResourceProvider provider = new ResourceProvider();\n\n        IgniteProvider igniteProvider = new IgniteProvider(clusterProps.igniteWorkDir());\n\n        provider.init(clusterProps, igniteProvider, baseUrl);\n\n        // Create the scheduler.\n        Scheduler scheduler = new IgniteScheduler(clusterProps, provider);\n\n        // create the driver\n        MesosSchedulerDriver driver;\n        if (System.getenv(\"MESOS_AUTHENTICATE\") != null) {\n            log.info(\"Enabling authentication for the framework\");\n\n            if (System.getenv(\"DEFAULT_PRINCIPAL\") == null) {\n                log.error(\"Expecting authentication principal in the environment\");\n\n                System.exit(1);\n            }\n\n            if (System.getenv(\"DEFAULT_SECRET\") == null) {\n                log.error(\"Expecting authentication secret in the environment\");\n\n                System.exit(1);\n            }\n\n            Protos.Credential credential = Protos.Credential.newBuilder()\n                .setPrincipal(System.getenv(\"DEFAULT_PRINCIPAL\"))\n                .setSecret(ByteString.copyFrom(System.getenv(\"DEFAULT_SECRET\").getBytes()))\n                .build();\n\n            frameworkBuilder.setPrincipal(System.getenv(\"DEFAULT_PRINCIPAL\"));\n\n            driver = new MesosSchedulerDriver(scheduler, frameworkBuilder.build(), clusterProps.masterUrl(),\n                credential);\n        }\n        else {\n            frameworkBuilder.setPrincipal(\"ignite-framework-java\");\n\n            driver = new MesosSchedulerDriver(scheduler, frameworkBuilder.build(), clusterProps.masterUrl());\n        }\n\n        int status = driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1;\n\n        httpServer.stop();\n\n        // Ensure that the driver process terminates.\n        driver.stop();\n\n        System.exit(status);\n    }","id":37236,"modified_method":"/**\n     * Main methods has only one optional parameter - path to properties files.\n     *\n     * @param args Args.\n     */\n    public static void main(String[] args) throws Exception {\n        final int frameworkFailoverTimeout = 0;\n\n        // Have Mesos fill in the current user.\n        Protos.FrameworkInfo.Builder frameworkBuilder = Protos.FrameworkInfo.newBuilder()\n            .setName(IGNITE_FRAMEWORK_NAME)\n            .setUser(\"\")\n            .setFailoverTimeout(frameworkFailoverTimeout);\n\n        if (System.getenv(\"MESOS_CHECKPOINT\") != null) {\n            log.info(\"Enabling checkpoint for the framework\");\n\n            frameworkBuilder.setCheckpoint(true);\n        }\n\n        ClusterProperties clusterProps = ClusterProperties.from(args.length >= 1 ? args[0] : null);\n\n        String baseUrl = String.format(\"http://%s:%d\", clusterProps.httpServerHost(), clusterProps.httpServerPort());\n\n        JettyServer httpServer = new JettyServer();\n\n        httpServer.start(\n            new InetSocketAddress(clusterProps.httpServerHost(), clusterProps.httpServerPort()),\n            new ResourceHandler(clusterProps.userLibs(), clusterProps.igniteCfg(), clusterProps.igniteWorkDir())\n        );\n\n        ResourceProvider provider = new ResourceProvider();\n\n        IgniteProvider igniteProvider = new IgniteProvider(clusterProps.igniteWorkDir());\n\n        provider.init(clusterProps, igniteProvider, baseUrl);\n\n        // Create the scheduler.\n        Scheduler scheduler = new IgniteScheduler(clusterProps, provider);\n\n        // create the driver\n        MesosSchedulerDriver driver;\n        if (System.getenv(\"MESOS_AUTHENTICATE\") != null) {\n            log.info(\"Enabling authentication for the framework\");\n\n            if (System.getenv(\"DEFAULT_PRINCIPAL\") == null) {\n                log.log(Level.SEVERE, \"Expecting authentication principal in the environment\");\n\n                System.exit(1);\n            }\n\n            if (System.getenv(\"DEFAULT_SECRET\") == null) {\n                log.log(Level.SEVERE, \"Expecting authentication secret in the environment\");\n\n                System.exit(1);\n            }\n\n            Protos.Credential credential = Protos.Credential.newBuilder()\n                .setPrincipal(System.getenv(\"DEFAULT_PRINCIPAL\"))\n                .setSecret(ByteString.copyFrom(System.getenv(\"DEFAULT_SECRET\").getBytes()))\n                .build();\n\n            frameworkBuilder.setPrincipal(System.getenv(\"DEFAULT_PRINCIPAL\"));\n\n            driver = new MesosSchedulerDriver(scheduler, frameworkBuilder.build(), clusterProps.masterUrl(),\n                credential);\n        }\n        else {\n            frameworkBuilder.setPrincipal(\"ignite-framework-java\");\n\n            driver = new MesosSchedulerDriver(scheduler, frameworkBuilder.build(), clusterProps.masterUrl());\n        }\n\n        int status = driver.run() == Protos.Status.DRIVER_STOPPED ? 0 : 1;\n\n        httpServer.stop();\n\n        // Ensure that the driver process terminates.\n        driver.stop();\n\n        System.exit(status);\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/** {@inheritDoc} */\n    @Override public void registered(SchedulerDriver schedulerDriver, Protos.FrameworkID frameworkID,\n        Protos.MasterInfo masterInfo) {\n        log.info(\"Scheduler registered. Master: {}:{}, framework={}\", masterInfo.getIp(), masterInfo.getPort(),\n            frameworkID);\n    }","id":37237,"modified_method":"/** {@inheritDoc} */\n    @Override public void registered(SchedulerDriver schedulerDriver, Protos.FrameworkID frameworkID,\n        Protos.MasterInfo masterInfo) {\n        log.log(Level.INFO, \"Scheduler registered. Master: {0}:{1}, framework={2}\", new Object[]{masterInfo.getIp(),\n            masterInfo.getPort(), frameworkID});\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/** {@inheritDoc} */\n    @Override public void resourceOffers(SchedulerDriver schedulerDriver, List<Protos.Offer> offers) {\n        log.debug(\"Offers resources: {} \", offers.size());\n\n        for (Protos.Offer offer : offers) {\n            Protos.TaskID taskId;\n            Protos.TaskInfo task;\n            IgniteTask igniteTask;\n\n            synchronized (mux) {\n                igniteTask = checkOffer(offer);\n\n                // Decline offer which doesn't match by mem or cpu.\n                if (igniteTask == null) {\n                    schedulerDriver.declineOffer(offer.getId());\n\n                    continue;\n                }\n\n                // Generate a unique task ID.\n                taskId = Protos.TaskID.newBuilder()\n                    .setValue(Integer.toString(taskIdGenerator.incrementAndGet())).build();\n\n                log.info(\"Launching task: {}\", igniteTask);\n\n                // Create task to run.\n                task = createTask(offer, igniteTask, taskId);\n            }\n\n            try {\n                schedulerDriver.launchTasks(Collections.singletonList(offer.getId()),\n                    Collections.singletonList(task),\n                    Protos.Filters.newBuilder().setRefuseSeconds(1).build());\n            }\n            catch (RuntimeException e) {\n                log.error(\"Failed launch task. Task id: {}. Task info: {}\", taskId, task);\n\n                throw e;\n            }\n\n            synchronized (mux) {\n                tasks.put(taskId.getValue(), igniteTask);\n            }\n        }\n    }","id":37238,"modified_method":"/** {@inheritDoc} */\n    @Override public synchronized void resourceOffers(SchedulerDriver schedulerDriver, List<Protos.Offer> offers) {\n        log.log(Level.FINE, \"Offers resources: {0}\", offers.size());\n\n        for (Protos.Offer offer : offers) {\n            IgniteTask igniteTask = checkOffer(offer);\n\n            // Decline offer which doesn't match by mem or cpu.\n            if (igniteTask == null) {\n                schedulerDriver.declineOffer(offer.getId());\n\n                continue;\n            }\n\n            // Generate a unique task ID.\n            Protos.TaskID taskId = Protos.TaskID.newBuilder()\n                .setValue(Integer.toString(taskIdGenerator.incrementAndGet())).build();\n\n            log.log(Level.INFO, \"Launching task: {0}\", igniteTask);\n\n            // Create task to run.\n            Protos.TaskInfo task = createTask(offer, igniteTask, taskId);\n\n            try {\n                schedulerDriver.launchTasks(Collections.singletonList(offer.getId()),\n                    Collections.singletonList(task),\n                    Protos.Filters.newBuilder().setRefuseSeconds(1).build());\n            }\n            catch (RuntimeException e) {\n                log.log(Level.SEVERE, \"Failed launch task. Task id: {0}. Task info: {1}\",\n                    new Object[]{taskId, task, e});\n\n                throw e;\n            }\n\n            tasks.put(taskId.getValue(), igniteTask);\n        }\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/** {@inheritDoc} */\n    @Override public void error(SchedulerDriver schedulerDriver, String s) {\n        log.error(\"Failed. Error message: {}\", s);\n    }","id":37239,"modified_method":"/** {@inheritDoc} */\n    @Override public void error(SchedulerDriver schedulerDriver, String s) {\n        log.log(Level.SEVERE, \"Failed. Error message: {0}\", s);\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Create Task.\n     *\n     * @param offer Offer.\n     * @param igniteTask Task description.\n     * @param taskId Task id.\n     * @return Task.\n     */\n    protected Protos.TaskInfo createTask(Protos.Offer offer, IgniteTask igniteTask, Protos.TaskID taskId) {\n        String cfgUrl = clusterProps.igniteConfigUrl() != null ?\n            clusterProps.igniteConfigUrl() : resourceProvider.igniteConfigUrl();\n\n        Protos.CommandInfo.Builder builder = Protos.CommandInfo.newBuilder()\n            .setEnvironment(Protos.Environment.newBuilder().addVariables(Protos.Environment.Variable.newBuilder()\n                .setName(\"IGNITE_TCP_DISCOVERY_ADDRESSES\")\n                .setValue(getAddress(offer.getHostname()))))\n            .addUris(Protos.CommandInfo.URI.newBuilder()\n                .setValue(clusterProps.ignitePackageUrl() != null ?\n                    clusterProps.ignitePackageUrl() : resourceProvider.igniteUrl())\n                .setExtract(true))\n            .addUris(Protos.CommandInfo.URI.newBuilder()\n                .setValue(cfgUrl));\n\n        // Collection user's libs.\n        Collection<String> usersLibs = new ArrayList<>();\n\n        if (clusterProps.usersLibsUrl() != null && !clusterProps.usersLibsUrl().isEmpty())\n            Collections.addAll(usersLibs, clusterProps.usersLibsUrl().split(DELIM));\n\n        if (resourceProvider.resourceUrl() != null && !resourceProvider.resourceUrl().isEmpty())\n            usersLibs.addAll(resourceProvider.resourceUrl());\n\n        for (String url : usersLibs)\n            builder.addUris(Protos.CommandInfo.URI.newBuilder().setValue(url));\n\n        String cfgName = resourceProvider.configName();\n\n        if (clusterProps.igniteConfigUrl() != null) {\n            String[] split = clusterProps.igniteConfigUrl().split(\"/\");\n\n            cfgName = split[split.length - 1];\n        }\n\n        builder.setValue(\"find . -maxdepth 1 -name \\\"*.jar\\\" -exec cp {} ./gridgain-community-*/libs/ \\\\; && \"\n            + \"./gridgain-community-*/bin/ignite.sh \"\n            + cfgName\n            + \" -J-Xmx\" + String.valueOf((int)igniteTask.mem() + \"m\")\n            + \" -J-Xms\" + String.valueOf((int)igniteTask.mem()) + \"m\");\n\n        return Protos.TaskInfo.newBuilder()\n            .setName(\"Ignite node \" + taskId.getValue())\n            .setTaskId(taskId)\n            .setSlaveId(offer.getSlaveId())\n            .setCommand(builder)\n            .addResources(Protos.Resource.newBuilder()\n                .setName(CPU)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.cpuCores())))\n            .addResources(Protos.Resource.newBuilder()\n                .setName(MEM)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.mem())))\n            .addResources(Protos.Resource.newBuilder()\n                .setName(DISK)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.disk())))\n            .build();\n    }","id":37240,"modified_method":"/**\n     * Create Task.\n     *\n     * @param offer Offer.\n     * @param igniteTask Task description.\n     * @param taskId Task id.\n     * @return Task.\n     */\n    private Protos.TaskInfo createTask(Protos.Offer offer, IgniteTask igniteTask, Protos.TaskID taskId) {\n        String cfgUrl = clusterProps.igniteConfigUrl() != null ?\n            clusterProps.igniteConfigUrl() : resourceProvider.igniteConfigUrl();\n\n        Protos.CommandInfo.Builder builder = Protos.CommandInfo.newBuilder()\n            .setEnvironment(Protos.Environment.newBuilder().addVariables(Protos.Environment.Variable.newBuilder()\n                .setName(\"IGNITE_TCP_DISCOVERY_ADDRESSES\")\n                .setValue(getAddress(offer.getHostname()))))\n            .addUris(Protos.CommandInfo.URI.newBuilder()\n                .setValue(clusterProps.ignitePackageUrl() != null ?\n                    clusterProps.ignitePackageUrl() : resourceProvider.igniteUrl())\n                .setExtract(true))\n            .addUris(Protos.CommandInfo.URI.newBuilder()\n                .setValue(cfgUrl));\n\n        // Collection user's libs.\n        Collection<String> usersLibs = new ArrayList<>();\n\n        if (clusterProps.usersLibsUrl() != null && !clusterProps.usersLibsUrl().isEmpty())\n            Collections.addAll(usersLibs, clusterProps.usersLibsUrl().split(DELIM));\n\n        if (resourceProvider.resourceUrl() != null && !resourceProvider.resourceUrl().isEmpty())\n            usersLibs.addAll(resourceProvider.resourceUrl());\n\n        for (String url : usersLibs)\n            builder.addUris(Protos.CommandInfo.URI.newBuilder().setValue(url));\n\n        String cfgName = resourceProvider.configName();\n\n        if (clusterProps.igniteConfigUrl() != null) {\n            String[] split = clusterProps.igniteConfigUrl().split(\"/\");\n\n            cfgName = split[split.length - 1];\n        }\n\n        builder.setValue(\"find . -maxdepth 1 -name \\\"*.jar\\\" -exec cp {} ./gridgain-community-*/libs/ \\\\; && \"\n            + \"./gridgain-community-*/bin/ignite.sh \"\n            + cfgName\n            + \" -J-Xmx\" + String.valueOf((int)igniteTask.mem() + \"m\")\n            + \" -J-Xms\" + String.valueOf((int)igniteTask.mem()) + \"m\");\n\n        return Protos.TaskInfo.newBuilder()\n            .setName(\"Ignite node \" + taskId.getValue())\n            .setTaskId(taskId)\n            .setSlaveId(offer.getSlaveId())\n            .setCommand(builder)\n            .addResources(Protos.Resource.newBuilder()\n                .setName(CPU)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.cpuCores())))\n            .addResources(Protos.Resource.newBuilder()\n                .setName(MEM)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.mem())))\n            .addResources(Protos.Resource.newBuilder()\n                .setName(DISK)\n                .setType(Protos.Value.Type.SCALAR)\n                .setScalar(Protos.Value.Scalar.newBuilder().setValue(igniteTask.disk())))\n            .build();\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/** {@inheritDoc} */\n    @Override public void statusUpdate(SchedulerDriver schedulerDriver, Protos.TaskStatus taskStatus) {\n        final String taskId = taskStatus.getTaskId().getValue();\n\n        log.info(\"Received update event task: {} is in state: {}\", taskId, taskStatus.getState());\n\n        if (taskStatus.getState().equals(Protos.TaskState.TASK_FAILED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_ERROR)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_FINISHED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_KILLED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_LOST)) {\n            IgniteTask failedTask;\n\n            synchronized (mux) {\n                failedTask = tasks.remove(taskId);\n            }\n\n            if (failedTask != null) {\n                List<Protos.Request> requests = new ArrayList<>();\n\n                Protos.Request request = Protos.Request.newBuilder()\n                    .addResources(Protos.Resource.newBuilder()\n                        .setType(Protos.Value.Type.SCALAR)\n                        .setName(MEM)\n                        .setScalar(Protos.Value.Scalar.newBuilder().setValue(failedTask.mem())))\n                    .addResources(Protos.Resource.newBuilder()\n                        .setType(Protos.Value.Type.SCALAR)\n                        .setName(CPU)\n                        .setScalar(Protos.Value.Scalar.newBuilder().setValue(failedTask.cpuCores())))\n                    .build();\n\n                requests.add(request);\n\n                schedulerDriver.requestResources(requests);\n            }\n        }\n    }","id":37241,"modified_method":"/** {@inheritDoc} */\n    @Override public synchronized void statusUpdate(SchedulerDriver schedulerDriver, Protos.TaskStatus taskStatus) {\n        final String taskId = taskStatus.getTaskId().getValue();\n\n        log.log(Level.INFO, \"Received update event task: {0} is in state: {1}\",\n            new Object[]{taskId, taskStatus.getState()});\n\n        if (taskStatus.getState().equals(Protos.TaskState.TASK_FAILED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_ERROR)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_FINISHED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_KILLED)\n            || taskStatus.getState().equals(Protos.TaskState.TASK_LOST)) {\n            IgniteTask failedTask = tasks.remove(taskId);\n\n            if (failedTask != null) {\n                List<Protos.Request> requests = new ArrayList<>();\n\n                Protos.Request request = Protos.Request.newBuilder()\n                    .addResources(Protos.Resource.newBuilder()\n                        .setType(Protos.Value.Type.SCALAR)\n                        .setName(MEM)\n                        .setScalar(Protos.Value.Scalar.newBuilder().setValue(failedTask.mem())))\n                    .addResources(Protos.Resource.newBuilder()\n                        .setType(Protos.Value.Type.SCALAR)\n                        .setName(CPU)\n                        .setScalar(Protos.Value.Scalar.newBuilder().setValue(failedTask.cpuCores())))\n                    .build();\n\n                requests.add(request);\n\n                schedulerDriver.requestResources(requests);\n            }\n        }\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * @return Address running nodes.\n     */\n    private String getAddress(String address) {\n        assert Thread.holdsLock(mux);\n\n        if (tasks.isEmpty()) {\n            if (address != null && !address.isEmpty())\n                return address + DEFAULT_PORT;\n\n            return \"\";\n        }\n\n        StringBuilder sb = new StringBuilder();\n\n        for (IgniteTask task : tasks.values())\n            sb.append(task.host()).append(DEFAULT_PORT).append(DELIM);\n\n        return sb.substring(0, sb.length() - 1);\n    }","id":37242,"modified_method":"/**\n     * @return Address running nodes.\n     */\n    private String getAddress(String address) {\n        if (tasks.isEmpty()) {\n            if (address != null && !address.isEmpty())\n                return address + DEFAULT_PORT;\n\n            return \"\";\n        }\n\n        StringBuilder sb = new StringBuilder();\n\n        for (IgniteTask task : tasks.values())\n            sb.append(task.host()).append(DEFAULT_PORT).append(DELIM);\n\n        return sb.substring(0, sb.length() - 1);\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"/**\n     * Check slave resources and return resources infos.\n     *\n     * @param offer Offer request.\n     * @return Ignite task description.\n     */\n    private IgniteTask checkOffer(Protos.Offer offer) {\n        assert Thread.holdsLock(mux);\n\n        // Check limit on running nodes.\n        if (clusterProps.instances() <= tasks.size())\n            return null;\n\n        double cpus = -1;\n        double mem = -1;\n        double disk = -1;\n\n        // Check host name\n        if (clusterProps.hostnameConstraint() != null\n            && clusterProps.hostnameConstraint().matcher(offer.getHostname()).matches())\n            return null;\n\n        // Collect resource on slave.\n        for (Protos.Resource resource : offer.getResourcesList()) {\n            if (resource.getName().equals(CPU)) {\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    cpus = resource.getScalar().getValue();\n                else\n                    log.debug(\"Cpus resource was not a scalar: {}\" + resource.getType());\n            }\n            else if (resource.getName().equals(MEM)) {\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    mem = resource.getScalar().getValue();\n                else\n                    log.debug(\"Mem resource was not a scalar: {}\", resource.getType());\n            }\n            else if (resource.getName().equals(DISK))\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    disk = resource.getScalar().getValue();\n                else\n                    log.debug(\"Disk resource was not a scalar: {}\", resource.getType());\n        }\n\n        // Check that slave satisfies min requirements.\n        if (cpus < clusterProps.minCpuPerNode() || mem < clusterProps.minMemoryPerNode()) {\n            log.debug(\"Offer not sufficient for slave request: {}\", offer.getResourcesList());\n\n            return null;\n        }\n\n        double totalCpus = 0;\n        double totalMem = 0;\n        double totalDisk = 0;\n\n        // Collect occupied resources.\n        for (IgniteTask task : tasks.values()) {\n            totalCpus += task.cpuCores();\n            totalMem += task.mem();\n            totalDisk += task.disk();\n        }\n\n        cpus = Math.min(clusterProps.cpus() - totalCpus, Math.min(cpus, clusterProps.cpusPerNode()));\n        mem = Math.min(clusterProps.memory() - totalMem, Math.min(mem, clusterProps.memoryPerNode()));\n        disk = Math.min(clusterProps.disk() - totalDisk, Math.min(disk, clusterProps.diskPerNode()));\n\n        if ((clusterProps.cpusPerNode() != ClusterProperties.UNLIMITED && clusterProps.cpusPerNode() != cpus)\n            || (clusterProps.memoryPerNode() != ClusterProperties.UNLIMITED && clusterProps.memoryPerNode() != mem)) {\n            log.debug(\"Offer not sufficient for slave request: {}\", offer.getResourcesList());\n\n            return null;\n        }\n\n        if (cpus > 0 && mem > 0)\n            return new IgniteTask(offer.getHostname(), cpus, mem, disk);\n        else {\n            log.debug(\"Offer not sufficient for slave request: {}\", offer.getResourcesList());\n\n            return null;\n        }\n    }","id":37243,"modified_method":"/**\n     * Check slave resources and return resources infos.\n     *\n     * @param offer Offer request.\n     * @return Ignite task description.\n     */\n    private IgniteTask checkOffer(Protos.Offer offer) {\n        // Check limit on running nodes.\n        if (clusterProps.instances() <= tasks.size())\n            return null;\n\n        double cpus = -1;\n        double mem = -1;\n        double disk = -1;\n\n        // Check host name\n        if (clusterProps.hostnameConstraint() != null\n            && clusterProps.hostnameConstraint().matcher(offer.getHostname()).matches())\n            return null;\n\n        // Collect resource on slave.\n        for (Protos.Resource resource : offer.getResourcesList()) {\n            if (resource.getName().equals(CPU)) {\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    cpus = resource.getScalar().getValue();\n                else\n                    log.log(Level.FINE, \"Cpus resource was not a scalar: {0}\" + resource.getType());\n            }\n            else if (resource.getName().equals(MEM)) {\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    mem = resource.getScalar().getValue();\n                else\n                    log.log(Level.FINE, \"Mem resource was not a scalar: {0}\", resource.getType());\n            }\n            else if (resource.getName().equals(DISK))\n                if (resource.getType().equals(Protos.Value.Type.SCALAR))\n                    disk = resource.getScalar().getValue();\n                else\n                    log.log(Level.FINE, \"Disk resource was not a scalar: {0}\", resource.getType());\n        }\n\n        // Check that slave satisfies min requirements.\n        if (cpus < clusterProps.minCpuPerNode() || mem < clusterProps.minMemoryPerNode()) {\n            log.log(Level.FINE, \"Offer not sufficient for slave request: {0}\", offer.getResourcesList());\n\n            return null;\n        }\n\n        double totalCpus = 0;\n        double totalMem = 0;\n        double totalDisk = 0;\n\n        // Collect occupied resources.\n        for (IgniteTask task : tasks.values()) {\n            totalCpus += task.cpuCores();\n            totalMem += task.mem();\n            totalDisk += task.disk();\n        }\n\n        cpus = Math.min(clusterProps.cpus() - totalCpus, Math.min(cpus, clusterProps.cpusPerNode()));\n        mem = Math.min(clusterProps.memory() - totalMem, Math.min(mem, clusterProps.memoryPerNode()));\n        disk = Math.min(clusterProps.disk() - totalDisk, Math.min(disk, clusterProps.diskPerNode()));\n\n        if ((clusterProps.cpusPerNode() != ClusterProperties.UNLIMITED && clusterProps.cpusPerNode() != cpus)\n            || (clusterProps.memoryPerNode() != ClusterProperties.UNLIMITED && clusterProps.memoryPerNode() != mem)) {\n            log.log(Level.FINE, \"Offer not sufficient for slave request: {0}\", offer.getResourcesList());\n\n            return null;\n        }\n\n        if (cpus > 0 && mem > 0)\n            return new IgniteTask(offer.getHostname(), cpus, mem, disk);\n        else {\n            log.log(Level.FINE, \"Offer not sufficient for slave request: {0}\", offer.getResourcesList());\n\n            return null;\n        }\n    }","commit_id":"bac7f79af721874e8d36a01471e0b0362c54e442","url":"https://github.com/apache/ignite"},{"original_method":"public JmsEndpoint createEndpoint(String uri, String path) {\n        ObjectHelper.notNull(container, \"container\");\n\n        if (path.startsWith(QUEUE_PREFIX)) {\n            template.setPubSubDomain(false);\n            path = path.substring(QUEUE_PREFIX.length());\n        }\n        else if (path.startsWith(TOPIC_PREFIX)) {\n            template.setPubSubDomain(false);\n            path = path.substring(TOPIC_PREFIX.length());\n        }\n\n        final String subject = convertPathToActualDestination(path);\n        template.setDefaultDestinationName(subject);\n\n        /*\n        Destination destination = (Destination) template.execute(new SessionCallback() {\n            public Object doInJms(Session session) throws JMSException {\n                return template.getDestinationResolver().resolveDestinationName(session, subject, template.isPubSubDomain());\n            }\n        });\n        */\n\n        AbstractMessageListenerContainer listenerContainer = createMessageListenerContainer(template);\n        listenerContainer.setDestinationName(subject);\n        listenerContainer.setPubSubDomain(template.isPubSubDomain());\n        listenerContainer.setConnectionFactory(template.getConnectionFactory());\n\n        // TODO support optional parameters\n        // selector\n        // messageConverter\n        // durableSubscriberName \n\n        return new JmsEndpoint(uri, container, template, listenerContainer);\n    }","id":37244,"modified_method":"public JmsEndpoint createEndpoint(String uri, String path) {\n        ObjectHelper.notNull(container, \"container\");\n\n        if (path.startsWith(QUEUE_PREFIX)) {\n            template.setPubSubDomain(false);\n            path = path.substring(QUEUE_PREFIX.length());\n        }\n        else if (path.startsWith(TOPIC_PREFIX)) {\n            template.setPubSubDomain(false);\n            path = path.substring(TOPIC_PREFIX.length());\n        }\n\n        final String subject = convertPathToActualDestination(path);\n        template.setDefaultDestinationName(subject);\n\n        /*\n        Destination destination = (Destination) template.execute(new SessionCallback() {\n            public Object doInJms(Session session) throws JMSException {\n                return template.getDestinationResolver().resolveDestinationName(session, subject, template.isPubSubDomain());\n            }\n        });\n        */\n\n        AbstractMessageListenerContainer listenerContainer = createMessageListenerContainer(template);\n        listenerContainer.setDestinationName(subject);\n        listenerContainer.setPubSubDomain(template.isPubSubDomain());\n        listenerContainer.setConnectionFactory(template.getConnectionFactory());\n\n        // TODO support optional parameters\n        // selector\n        // messageConverter\n        // durableSubscriberName \n\n        return new JmsEndpoint(uri, container, subject, template, listenerContainer);\n    }","commit_id":"6ef5d7fa9f92a051738ff57f2102bd7041ae3443","url":"https://github.com/apache/camel"},{"original_method":"public void onMessage(Message message) {\n        JmsExchange exchange = createExchange(message);\n        getInboundProcessor().onExchange(exchange);\n    }","id":37245,"modified_method":"public void onMessage(Message message) {\n        if (log.isDebugEnabled()) {\n            log.debug(JmsEndpoint.this + \" receiving JMS message: \" + message);\n        }\n        JmsExchange exchange = createExchange(message);\n        getInboundProcessor().onExchange(exchange);\n    }","commit_id":"6ef5d7fa9f92a051738ff57f2102bd7041ae3443","url":"https://github.com/apache/camel"},{"original_method":"public void send(final JmsExchange exchange) {\n        template.send(new MessageCreator() {\n            public Message createMessage(Session session) throws JMSException {\n                return exchange.createMessage(session);\n            }\n        });\n    }","id":37246,"modified_method":"public void send(final JmsExchange exchange) {\n        template.send(destination, new MessageCreator() {\n            public Message createMessage(Session session) throws JMSException {\n                Message message = exchange.createMessage(session);\n                if (log.isDebugEnabled()) {\n                    log.debug(JmsEndpoint.this + \" sending JMS message: \" + message);\n                }\n                return message;\n            }\n        });\n    }","commit_id":"6ef5d7fa9f92a051738ff57f2102bd7041ae3443","url":"https://github.com/apache/camel"},{"original_method":"public JmsEndpoint(String endpointUri, CamelContainer container, JmsOperations template, AbstractMessageListenerContainer listenerContainer) {\n        super(endpointUri, container);\n        this.template = template;\n        this.listenerContainer = listenerContainer;\n        this.listenerContainer.setMessageListener(this);\n    }","id":37247,"modified_method":"public JmsEndpoint(String endpointUri, CamelContainer container, String destination, JmsOperations template, AbstractMessageListenerContainer listenerContainer) {\n        super(endpointUri, container);\n        this.destination = destination;\n        this.template = template;\n        this.listenerContainer = listenerContainer;\n        this.listenerContainer.setMessageListener(this);\n    }","commit_id":"6ef5d7fa9f92a051738ff57f2102bd7041ae3443","url":"https://github.com/apache/camel"},{"original_method":"public void testJmsRoute() throws Exception {\n        CamelContainer container = new CamelContainer();\n\n        System.out.println(\"Created container: \" + container);\n        \n        // lets configure some componnets\n        ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"vm://localhost?broker.persistent=false\");\n        container.addComponent(\"activemq\", jmsComponent(connectionFactory));\n\n        // lets add some routes\n        container.routes(new RouteBuilder() {\n            public void configure() {\n                from(\"jms:activemq:FOO.BAR\").to(\"jms:activemq:FOO.BAR\");\n            }\n        });\n    }","id":37248,"modified_method":"public void testJmsRoute() throws Exception {\n        CamelContainer container = new CamelContainer();\n\n        System.out.println(\"Created container: \" + container);\n        \n        // lets configure some componnets\n        JmsTemplate template = new JmsTemplate(new ActiveMQConnectionFactory(\"vm://localhost?broker.persistent=false\"));\n        template.setSessionAcknowledgeMode(Session.AUTO_ACKNOWLEDGE);\n        template.setSessionTransacted(false);\n        \n        container.addComponent(\"activemq\", jmsComponent(template));\n\n        // lets add some routes\n        container.routes(new RouteBuilder() {\n            public void configure() {\n                from(\"jms:activemq:test.a\").to(\"jms:activemq:test.b\");\n                from(\"jms:activemq:test.b\").process(new Processor<JmsExchange>() {\n                    public void onExchange(JmsExchange exchange) {\n                        System.out.println(\"Received exchange: \" + exchange.getRequest());\n                    }\n                });\n            }\n        });\n\n        // now lets fire in a message\n        Endpoint<JmsExchange> endpoint = container.endpoint(\"jms:activemq:test.a\");\n        JmsExchange exchange2 = endpoint.createExchange();\n        //exchange2.setInBody(\"Hello there!\")\n        exchange2.setHeader(\"cheese\", 123);\n        endpoint.send(exchange2);\n\n        // now lets sleep for a while\n        Thread.sleep(3000);\n\n        // TODO\n        //container.stop();\n    }","commit_id":"6ef5d7fa9f92a051738ff57f2102bd7041ae3443","url":"https://github.com/apache/camel"},{"original_method":"/** Return the metadata for a REST API Route, specified either by number or path. */\n  // Also called through reflection by RequestServer\n  public MetadataV3 fetchRoute(int version, MetadataV3 docs) {\n    Route route = null;\n    if (null != docs.path && null != docs.http_method) {\n      try {\n        route = RequestServer.lookupRoute(new RequestUri(docs.http_method, docs.path));\n      } catch (MalformedURLException e) {\n        route = null;\n      }\n    } else {\n      // Linear scan for the route, plus each route is asked for in-order\n      // during doc-gen leading to an O(n^2) execution cost.\n      int i = 0;\n      for (Route r : RequestServer.routes())\n        if (i++ == docs.num) { route = r; break; }\n      // Crash-n-burn if route not found (old code thru an AIOOBE), so we\n      // something similarly bad.\n      docs.routes = new RouteBase[]{(RouteBase)Schema.schema(version, Route.class).fillFromImpl(route)};\n    }\n    if (route == null) return null;\n\n    Schema sinput, soutput;\n    if( route._handler_class.equals(water.api.ModelBuilderHandler.class) ||\n        route._handler_class.equals(water.api.GridSearchHandler.class)) {\n      // GridSearchHandler uses the same logic as ModelBuilderHandler because there are no separate\n      // ${ALGO}GridSearchParametersV3 classes, instead each field in ${ALGO}ParametersV3 is marked as either gridable\n      // or not.\n      String ss[] = route._url.split(\"/\");\n      String algoURLName = ss[3]; // {}/{3}/{ModelBuilders}/{gbm}/{parameters}\n      String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n      String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n      int version2 = Integer.valueOf(ss[1]);\n      try {\n        String inputSchemaName = schemaDir + algoName + \"V\" + version2;  // hex.schemas.GBMV3\n        sinput = (Schema) TypeMap.getTheFreezableOrThrow(TypeMap.onIce(inputSchemaName));\n      } catch (java.lang.ClassNotFoundException e) {\n        // Not very pretty, but for some routes such as /99/Grid/glm we want to map to GLMV3 (because GLMV99 does not\n        // exist), yet for others such as /99/Grid/svd we map to SVDV99 (because SVDV3 does not exist).\n        sinput = (Schema) TypeMap.theFreezable(TypeMap.onIce(schemaDir + algoName + \"V3\"));\n      }\n      sinput.init_meta();\n      soutput = sinput;\n    } else {\n      sinput  = Schema.newInstance(Handler.getHandlerMethodInputSchema (route._handler_method));\n      soutput = Schema.newInstance(Handler.getHandlerMethodOutputSchema(route._handler_method));\n    }\n    docs.routes[0].input_schema = sinput.getClass().getSimpleName();\n    docs.routes[0].output_schema = soutput.getClass().getSimpleName();\n    docs.routes[0].markdown = route.markdown(sinput,soutput).toString();\n    return docs;\n  }","id":37249,"modified_method":"/** Return the metadata for a REST API Route, specified either by number or path. */\n  // Also called through reflection by RequestServer\n  public MetadataV3 fetchRoute(int version, MetadataV3 docs) {\n    Route route = null;\n    if (docs.path != null && docs.http_method != null) {\n      try {\n        route = RequestServer.lookupRoute(new RequestUri(docs.http_method, docs.path));\n      } catch (MalformedURLException e) {\n        route = null;\n      }\n    } else {\n      // Linear scan for the route, plus each route is asked for in-order\n      // during doc-gen leading to an O(n^2) execution cost.\n      if (docs.path != null)\n        try { docs.num = Integer.parseInt(docs.path); }\n        catch (NumberFormatException e) { /* path is not a number, it's ok */ }\n      if (docs.num >= 0 && docs.num < RequestServer.numRoutes())\n        route = RequestServer.routes().get(docs.num);\n      // Crash-n-burn if route not found (old code thru an AIOOBE), so we\n      // something similarly bad.\n      docs.routes = new RouteBase[]{(RouteBase)Schema.schema(version, Route.class).fillFromImpl(route)};\n    }\n    if (route == null) return null;\n\n    Schema sinput, soutput;\n    if( route._handler_class.equals(water.api.ModelBuilderHandler.class) ||\n        route._handler_class.equals(water.api.GridSearchHandler.class)) {\n      // GridSearchHandler uses the same logic as ModelBuilderHandler because there are no separate\n      // ${ALGO}GridSearchParametersV3 classes, instead each field in ${ALGO}ParametersV3 is marked as either gridable\n      // or not.\n      String ss[] = route._url.split(\"/\");\n      String algoURLName = ss[3]; // {}/{3}/{ModelBuilders}/{gbm}/{parameters}\n      String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n      String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n      int version2 = Integer.valueOf(ss[1]);\n      try {\n        String inputSchemaName = schemaDir + algoName + \"V\" + version2;  // hex.schemas.GBMV3\n        sinput = (Schema) TypeMap.getTheFreezableOrThrow(TypeMap.onIce(inputSchemaName));\n      } catch (java.lang.ClassNotFoundException e) {\n        // Not very pretty, but for some routes such as /99/Grid/glm we want to map to GLMV3 (because GLMV99 does not\n        // exist), yet for others such as /99/Grid/svd we map to SVDV99 (because SVDV3 does not exist).\n        sinput = (Schema) TypeMap.theFreezable(TypeMap.onIce(schemaDir + algoName + \"V3\"));\n      }\n      sinput.init_meta();\n      soutput = sinput;\n    } else {\n      sinput  = Schema.newInstance(Handler.getHandlerMethodInputSchema (route._handler_method));\n      soutput = Schema.newInstance(Handler.getHandlerMethodOutputSchema(route._handler_method));\n    }\n    docs.routes[0].input_schema = sinput.getClass().getSimpleName();\n    docs.routes[0].output_schema = soutput.getClass().getSimpleName();\n    docs.routes[0].markdown = route.markdown(sinput,soutput).toString();\n    return docs;\n  }","commit_id":"5d7dfcc9dd639fa1a6e9f637269c8e78b4c05f98","url":"https://github.com/h2oai/h2o-3"},{"original_method":"/** Return the metadata for a REST API Route, specified either by number or path. */\n  // Also called through reflection by RequestServer\n  public MetadataV3 fetchRoute(int version, MetadataV3 docs) {\n    Route route = null;\n    if (null != docs.path && null != docs.http_method) {\n      try {\n        route = RequestServer.lookupRoute(new RequestUri(docs.http_method, docs.path));\n      } catch (MalformedURLException e) {\n        route = null;\n      }\n    } else {\n      // Linear scan for the route, plus each route is asked for in-order\n      // during doc-gen leading to an O(n^2) execution cost.\n      int i = 0;\n      for (Route r : RequestServer.routes())\n        if (i++ == docs.num) { route = r; break; }\n      // Crash-n-burn if route not found (old code thru an AIOOBE), so we\n      // something similarly bad.\n      docs.routes = new RouteBase[]{(RouteBase)Schema.schema(version, Route.class).fillFromImpl(route)};\n    }\n    if (route == null) return null;\n\n    Schema sinput, soutput;\n    if( route._handler_class.equals(water.api.ModelBuilderHandler.class) ||\n        route._handler_class.equals(water.api.GridSearchHandler.class)) {\n      // GridSearchHandler uses the same logic as ModelBuilderHandler because there are no separate\n      // ${ALGO}GridSearchParametersV3 classes, instead each field in ${ALGO}ParametersV3 is marked as either gridable\n      // or not.\n      String ss[] = route._url.split(\"/\");\n      String algoURLName = ss[3]; // {}/{3}/{ModelBuilders}/{gbm}/{parameters}\n      String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n      String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n      int version2 = Integer.valueOf(ss[1]);\n      try {\n        String inputSchemaName = schemaDir + algoName + \"V\" + version2;  // hex.schemas.GBMV3\n        sinput = (Schema) TypeMap.getTheFreezableOrThrow(TypeMap.onIce(inputSchemaName));\n      } catch (java.lang.ClassNotFoundException e) {\n        // Not very pretty, but for some routes such as /99/Grid/glm we want to map to GLMV3 (because GLMV99 does not\n        // exist), yet for others such as /99/Grid/svd we map to SVDV99 (because SVDV3 does not exist).\n        sinput = (Schema) TypeMap.theFreezable(TypeMap.onIce(schemaDir + algoName + \"V3\"));\n      }\n      sinput.init_meta();\n      soutput = sinput;\n    } else {\n      sinput  = Schema.newInstance(Handler.getHandlerMethodInputSchema (route._handler_method));\n      soutput = Schema.newInstance(Handler.getHandlerMethodOutputSchema(route._handler_method));\n    }\n    docs.routes[0].input_schema = sinput.getClass().getSimpleName();\n    docs.routes[0].output_schema = soutput.getClass().getSimpleName();\n    docs.routes[0].markdown = route.markdown(sinput,soutput).toString();\n    return docs;\n  }","id":37250,"modified_method":"/** Return the metadata for a REST API Route, specified either by number or path. */\n  // Also called through reflection by RequestServer\n  public MetadataV3 fetchRoute(int version, MetadataV3 docs) {\n    Route route = null;\n    if (docs.path != null && docs.http_method != null) {\n      try {\n        route = RequestServer.lookupRoute(new RequestUri(docs.http_method, docs.path));\n      } catch (MalformedURLException e) {\n        route = null;\n      }\n    } else {\n      // Linear scan for the route, plus each route is asked for in-order\n      // during doc-gen leading to an O(n^2) execution cost.\n      if (docs.path != null)\n        try { docs.num = Integer.parseInt(docs.path); }\n        catch (NumberFormatException e) { /* path is not a number, it's ok */ }\n      if (docs.num >= 0 && docs.num < RequestServer.numRoutes())\n        route = RequestServer.routes().get(docs.num);\n      // Crash-n-burn if route not found (old code thru an AIOOBE), so we\n      // something similarly bad.\n      docs.routes = new RouteBase[]{(RouteBase)Schema.schema(version, Route.class).fillFromImpl(route)};\n    }\n    if (route == null) return null;\n\n    Schema sinput, soutput;\n    if( route._handler_class.equals(water.api.ModelBuilderHandler.class) ||\n        route._handler_class.equals(water.api.GridSearchHandler.class)) {\n      // GridSearchHandler uses the same logic as ModelBuilderHandler because there are no separate\n      // ${ALGO}GridSearchParametersV3 classes, instead each field in ${ALGO}ParametersV3 is marked as either gridable\n      // or not.\n      String ss[] = route._url.split(\"/\");\n      String algoURLName = ss[3]; // {}/{3}/{ModelBuilders}/{gbm}/{parameters}\n      String algoName = ModelBuilder.algoName(algoURLName); // gbm -> GBM; deeplearning -> DeepLearning\n      String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\n      int version2 = Integer.valueOf(ss[1]);\n      try {\n        String inputSchemaName = schemaDir + algoName + \"V\" + version2;  // hex.schemas.GBMV3\n        sinput = (Schema) TypeMap.getTheFreezableOrThrow(TypeMap.onIce(inputSchemaName));\n      } catch (java.lang.ClassNotFoundException e) {\n        // Not very pretty, but for some routes such as /99/Grid/glm we want to map to GLMV3 (because GLMV99 does not\n        // exist), yet for others such as /99/Grid/svd we map to SVDV99 (because SVDV3 does not exist).\n        sinput = (Schema) TypeMap.theFreezable(TypeMap.onIce(schemaDir + algoName + \"V3\"));\n      }\n      sinput.init_meta();\n      soutput = sinput;\n    } else {\n      sinput  = Schema.newInstance(Handler.getHandlerMethodInputSchema (route._handler_method));\n      soutput = Schema.newInstance(Handler.getHandlerMethodOutputSchema(route._handler_method));\n    }\n    docs.routes[0].input_schema = sinput.getClass().getSimpleName();\n    docs.routes[0].output_schema = soutput.getClass().getSimpleName();\n    docs.routes[0].markdown = route.markdown(sinput,soutput).toString();\n    return docs;\n  }","commit_id":"16b2c2bccfb11bf67fb414b113a7080c8755d218","url":"https://github.com/h2oai/h2o-3"},{"original_method":"/**\n     * Handles the deployment descriptors, if specified. Note that the behavior\n     * here is slightly different since the customized entry always win, even if\n     * an overlay has already packaged a web.xml previously.\n     *\n     * @param context    the packaging context\n     * @param webinfDir  the web-inf directory\n     * @param metainfDir the meta-inf directory\n     * @throws MojoFailureException   if the web.xml is specified but does not exist\n     * @throws MojoExecutionException if an error occurred while copying the descriptors\n     */\n    protected void handleDeploymentDescriptors( WarPackagingContext context, File webinfDir, File metainfDir )\n        throws MojoFailureException, MojoExecutionException\n    {\n        try\n        {\n            if ( webXml != null && StringUtils.isNotEmpty( webXml.getName() ) )\n            {\n                if ( !webXml.exists() )\n                {\n                    throw new MojoFailureException( \"The specified web.xml file '\" + webXml + \"' does not exist\" );\n                }\n                if ( context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getMavenFileFilter().copyFile( webXml, new File( webinfDir, \"web.xml\" ), true,\n                                                           context.getFilterWrappers(), getEncoding( webXml ) );\n                }\n                else\n                {\n                    copyFile( context, webXml, new File( webinfDir, \"web.xml\" ), \"WEB-INF/web.xml\", true );\n                }\n\n                context.getWebappStructure().getFullStructure().add( WEB_INF_PATH + \"/web.xml\" );\n            }\n            else\n            {\n                // the webXml can be the default one\n                File defaultWebXml = new File( context.getWebappSourceDirectory(), WEB_INF_PATH + \"/web.xml\" );\n                // if exists we can filter it\n                if ( defaultWebXml.exists() && context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getMavenFileFilter().copyFile( defaultWebXml, new File( webinfDir, \"web.xml\" ), true,\n                                                           context.getFilterWrappers(), getEncoding( defaultWebXml ) );\n                    context.getWebappStructure().getFullStructure().add( WEB_INF_PATH + \"/web.xml\" );\n                }\n            }\n\n            if ( containerConfigXML != null && StringUtils.isNotEmpty( containerConfigXML.getName() ) )\n            {\n                String xmlFileName = containerConfigXML.getName();\n                if ( context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getMavenFileFilter().copyFile( containerConfigXML, new File( metainfDir, xmlFileName ),\n                                                           true, context.getFilterWrappers(),\n                                                           getEncoding( containerConfigXML ) );\n                }\n                else\n                {\n                    copyFile( context, containerConfigXML, new File( metainfDir, xmlFileName ),\n                              \"META-INF/\" + xmlFileName, true );\n                }\n                context.getWebappStructure().getFullStructure().add( META_INF_PATH + \"/\" + xmlFileName );\n            }\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( \"Failed to copy deployment descriptor\", e );\n        }\n        catch ( MavenFilteringException e )\n        {\n            throw new MojoExecutionException( \"Failed to copy deployment descriptor\", e );\n        }\n    }","id":37251,"modified_method":"/**\n     * Handles the deployment descriptors, if specified. Note that the behavior\n     * here is slightly different since the customized entry always win, even if\n     * an overlay has already packaged a web.xml previously.\n     *\n     * @param context    the packaging context\n     * @param webinfDir  the web-inf directory\n     * @param metainfDir the meta-inf directory\n     * @throws MojoFailureException   if the web.xml is specified but does not exist\n     * @throws MojoExecutionException if an error occurred while copying the descriptors\n     */\n    protected void handleDeploymentDescriptors( WarPackagingContext context, File webinfDir, File metainfDir )\n        throws MojoFailureException, MojoExecutionException\n    {\n        try\n        {\n            if ( webXml != null && StringUtils.isNotEmpty( webXml.getName() ) )\n            {\n                if ( !webXml.exists() )\n                {\n                    throw new MojoFailureException( \"The specified web.xml file '\" + webXml + \"' does not exist\" );\n                }\n\n                // Making sure that it won't get overlayed\n                context.getWebappStructure().registerFileForced( id, WEB_INF_PATH + \"/web.xml\" );\n\n                if ( context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getMavenFileFilter().copyFile( webXml, new File( webinfDir, \"web.xml\" ), true,\n                                                           context.getFilterWrappers(), getEncoding( webXml ) );\n                }\n                else\n                {\n                    copyFile( context, webXml, new File( webinfDir, \"web.xml\" ), \"WEB-INF/web.xml\", true );\n                }\n            }\n            else\n            {\n                // the webXml can be the default one\n                File defaultWebXml = new File( context.getWebappSourceDirectory(), WEB_INF_PATH + \"/web.xml\" );\n                // if exists we can filter it\n                if ( defaultWebXml.exists() && context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getWebappStructure().registerFile( id, WEB_INF_PATH + \"/web.xml\" );\n                    context.getMavenFileFilter().copyFile( defaultWebXml, new File( webinfDir, \"web.xml\" ), true,\n                                                           context.getFilterWrappers(), getEncoding( defaultWebXml ) );\n                }\n            }\n\n            if ( containerConfigXML != null && StringUtils.isNotEmpty( containerConfigXML.getName() ) )\n            {\n                String xmlFileName = containerConfigXML.getName();\n\n                context.getWebappStructure().registerFileForced( id, META_INF_PATH + \"/\" + xmlFileName );\n\n                if ( context.isFilteringDeploymentDescriptors() )\n                {\n                    context.getMavenFileFilter().copyFile( containerConfigXML, new File( metainfDir, xmlFileName ),\n                                                           true, context.getFilterWrappers(),\n                                                           getEncoding( containerConfigXML ) );\n                }\n                else\n                {\n                    copyFile( context, containerConfigXML, new File( metainfDir, xmlFileName ),\n                              \"META-INF/\" + xmlFileName, true );\n                }\n            }\n        }\n        catch ( IOException e )\n        {\n            throw new MojoExecutionException( \"Failed to copy deployment descriptor\", e );\n        }\n        catch ( MavenFilteringException e )\n        {\n            throw new MojoExecutionException( \"Failed to copy deployment descriptor\", e );\n        }\n    }","commit_id":"45da4f6711b5b678d0eeecf8e1cd41024f535c5c","url":"https://github.com/apache/maven-plugins"},{"original_method":"@Override\n  protected void invokeImpl(final PsiClass targetClass) {\n    final Project project = myConstructorCall.getProject();\n    PsiElementFactory elementFactory = JavaPsiFacade.getInstance(project).getElementFactory();\n\n    try {\n      PsiMethod constructor = (PsiMethod)targetClass.add(elementFactory.createConstructor());\n\n      final PsiFile file = targetClass.getContainingFile();\n      TemplateBuilderImpl templateBuilder = new TemplateBuilderImpl(constructor);\n      CreateFromUsageUtils.setupMethodParameters(constructor, templateBuilder, myConstructorCall.getArgumentList(),\n                                                 getTargetSubstitutor(myConstructorCall));\n      final PsiMethod superConstructor = CreateClassFromNewFix.setupSuperCall(targetClass, constructor, templateBuilder);\n\n      constructor = CodeInsightUtilBase.forcePsiPostprocessAndRestoreElement(constructor);\n      Template template = templateBuilder.buildTemplate();\n      final Editor editor = positionCursor(project, targetClass.getContainingFile(), targetClass);\n      if (editor == null) return;\n      final TextRange textRange = constructor.getTextRange();\n      editor.getDocument().deleteString(textRange.getStartOffset(), textRange.getEndOffset());\n      editor.getCaretModel().moveToOffset(textRange.getStartOffset());\n\n      startTemplate(editor, template, project, new TemplateEditingAdapter() {\n        @Override\n        public void templateFinished(Template template, boolean brokenOff) {\n          ApplicationManager.getApplication().runWriteAction(new Runnable() {\n            @Override\n            public void run() {\n              try {\n                PsiDocumentManager.getInstance(project).commitDocument(editor.getDocument());\n                final int offset = editor.getCaretModel().getOffset();\n                PsiMethod constructor = PsiTreeUtil.findElementOfClassAtOffset(file, offset, PsiMethod.class, false);\n                if (superConstructor == null) {\n                  CreateFromUsageUtils.setupMethodBody(constructor);\n                } else {\n                  OverrideImplementUtil.setupMethodBody(constructor, superConstructor, targetClass);\n                }\n                CreateFromUsageUtils.setupEditor(constructor, editor);\n              }\n              catch (IncorrectOperationException e) {\n                LOG.error(e);\n              }\n            }\n          });\n        }\n      });\n    }\n    catch (IncorrectOperationException e) {\n      LOG.error(e);\n    }\n  }","id":37252,"modified_method":"@Override\n  protected void invokeImpl(final PsiClass targetClass) {\n    final Project project = myConstructorCall.getProject();\n    JVMElementFactory elementFactory = JVMElementFactories.getFactory(targetClass.getLanguage(), project);\n    if (elementFactory == null) elementFactory = JavaPsiFacade.getElementFactory(project);\n\n    try {\n      PsiMethod constructor = (PsiMethod)targetClass.add(elementFactory.createConstructor());\n\n      final PsiFile file = targetClass.getContainingFile();\n      TemplateBuilderImpl templateBuilder = new TemplateBuilderImpl(constructor);\n      CreateFromUsageUtils.setupMethodParameters(constructor, templateBuilder, myConstructorCall.getArgumentList(),\n                                                 getTargetSubstitutor(myConstructorCall));\n      final PsiMethod superConstructor = CreateClassFromNewFix.setupSuperCall(targetClass, constructor, templateBuilder);\n\n      constructor = CodeInsightUtilBase.forcePsiPostprocessAndRestoreElement(constructor);\n      Template template = templateBuilder.buildTemplate();\n      final Editor editor = positionCursor(project, targetClass.getContainingFile(), targetClass);\n      if (editor == null) return;\n      final TextRange textRange = constructor.getTextRange();\n      editor.getDocument().deleteString(textRange.getStartOffset(), textRange.getEndOffset());\n      editor.getCaretModel().moveToOffset(textRange.getStartOffset());\n\n      startTemplate(editor, template, project, new TemplateEditingAdapter() {\n        @Override\n        public void templateFinished(Template template, boolean brokenOff) {\n          ApplicationManager.getApplication().runWriteAction(new Runnable() {\n            @Override\n            public void run() {\n              try {\n                PsiDocumentManager.getInstance(project).commitDocument(editor.getDocument());\n                final int offset = editor.getCaretModel().getOffset();\n                PsiMethod constructor = PsiTreeUtil.findElementOfClassAtOffset(file, offset, PsiMethod.class, false);\n                if (superConstructor == null) {\n                  CreateFromUsageUtils.setupMethodBody(constructor);\n                } else {\n                  OverrideImplementUtil.setupMethodBody(constructor, superConstructor, targetClass);\n                }\n                CreateFromUsageUtils.setupEditor(constructor, editor);\n              }\n              catch (IncorrectOperationException e) {\n                LOG.error(e);\n              }\n            }\n          });\n        }\n      });\n    }\n    catch (IncorrectOperationException e) {\n      LOG.error(e);\n    }\n  }","commit_id":"42eec1f9f6a2844981aaca03849e421413a3ec32","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void doTest() throws Throwable {\n    final List<String> stringList = TestUtils.readInput(getTestDataPath() + \"/\" + getTestName(true) + \".test\");\n    final String fileName = getTestName(true) + \".\" + getExtension();\n    myFixture.addFileToProject(fileName, stringList.get(0));\n    myFixture.configureByFile(fileName);\n\n    CompositeCompletionData.restrictCompletion(addReferenceVariants(), addKeywords());\n\n    boolean old = CodeInsightSettings.getInstance().AUTOCOMPLETE_COMMON_PREFIX;\n    CodeInsightSettings.getInstance().AUTOCOMPLETE_COMMON_PREFIX = false;\n    CodeInsightSettings.getInstance().AUTOCOMPLETE_ON_CODE_COMPLETION = false;\n\n\n    String result = \"\";\n    try {\n      myFixture.completeBasic();\n\n      final LookupImpl lookup = (LookupImpl)LookupManager.getActiveLookup(myFixture.getEditor());\n      if (lookup != null) {\n        List<LookupElement> items = lookup.getItems();\n        Collections.sort(items, new Comparator<LookupElement>() {\n          public int compare(LookupElement o1, LookupElement o2) {\n            return o1.getLookupString().compareTo(o2.getLookupString());\n          }\n        });\n        result = \"\";\n        for (LookupElement item : items) {\n          result = result + \"\\n\" + item.getLookupString();\n        }\n        result = result.trim();\n        LookupManager.getInstance(myFixture.getProject()).hideActiveLookup();\n      }\n\n    }\n    finally {\n      CodeInsightSettings.getInstance().AUTOCOMPLETE_ON_CODE_COMPLETION = true;\n      CodeInsightSettings.getInstance().AUTOCOMPLETE_COMMON_PREFIX = old;\n      CompositeCompletionData.restrictCompletion(true, true);\n    }\n    assertEquals(stringList.get(1), result);\n  }","id":37253,"modified_method":"protected void doTest() throws Throwable {\n    doTest(\"\");\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  public PsiVariable getPsi(PsiManager manager, final String containingClassName) {\n    if (myPsi != null) return myPsi;\n\n    LinkedHashSet<String> hashSet = new LinkedHashSet<String>();\n\n    Boolean isStatic = isStatic();\n    if (isStatic != null && isStatic.booleanValue()) {\n      hashSet.add(PsiModifier.STATIC);\n    }\n    myPsi = new GrDynamicImplicitProperty(manager, getName(), getType(), containingClassName, new LightModifierList(manager, hashSet)) {\n      @Override\n      public PsiElement setName(@NotNull String name) throws IncorrectOperationException {\n        DynamicManager.getInstance(getProject()).replaceDynamicPropertyName(containingClassName, getName(), name);\n        return super.setName(name);\n      }\n    };\n    return myPsi;\n  }","id":37254,"modified_method":"@NotNull\n  public PsiVariable getPsi(PsiManager manager, final String containingClassName) {\n    if (myPsi != null) return myPsi;\n\n    LinkedHashSet<String> hashSet = new LinkedHashSet<String>();\n\n    Boolean isStatic = isStatic();\n    if (isStatic != null && isStatic.booleanValue()) {\n      hashSet.add(PsiModifier.STATIC);\n    }\n    myPsi = new GrDynamicImplicitProperty(manager, getName(), getType(), containingClassName, new LightModifierList(manager, hashSet), null) {\n      @Override\n      public PsiElement setName(@NotNull String name) throws IncorrectOperationException {\n        DynamicManager.getInstance(getProject()).replaceDynamicPropertyName(containingClassName, getName(), name);\n        return super.setName(name);\n      }\n    };\n    return myPsi;\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  public PsiElement resolve() {\n    String propName = getText();\n    String setterName = PropertyUtil.suggestSetterName(propName);\n    PsiElement context = getParent().getParent();\n    if (context instanceof GrArgumentList) {\n      final PsiElement parent = context.getParent();\n      if (parent instanceof GrCallExpression) {\n        final PsiMethod resolvedMethod = ((GrCallExpression) parent).resolveMethod();\n        if (resolvedMethod != null) {\n          final PsiParameter[] parameters = resolvedMethod.getParameterList().getParameters();\n          if (parameters.length > 0) {\n            if (PsiUtil.createMapType(resolvedMethod.getManager(), resolvedMethod.getResolveScope()).isAssignableFrom(parameters[0].getType())) {\n              //call with named argument, not setting property\n              return null;\n            }\n          }\n        }\n      }\n\n      if (parent instanceof GrExpression || parent instanceof GrAnonymousClassDefinition) {\n        PsiType type =\n          parent instanceof GrExpression ? ((GrExpression)parent).getType() : ((GrAnonymousClassDefinition)parent).getBaseClassType();\n        if (type instanceof PsiClassType) {\n          PsiClass clazz = ((PsiClassType) type).resolve();\n          if (clazz != null) {\n            PsiMethod[] byName = clazz.findMethodsByName(setterName, true);\n            if (byName.length > 0) return byName[0];\n            return clazz.findFieldByName(propName, true);\n          }\n        }\n      }\n    }\n    return null;\n  }","id":37255,"modified_method":"@Nullable\n  public PsiElement resolve() {\n    String propName = getText();\n    String setterName = PropertyUtil.suggestSetterName(propName);\n    PsiElement context = getParent().getParent();\n    if (context instanceof GrArgumentList) {\n      final PsiElement parent = context.getParent();\n      if (parent instanceof GrCallExpression) {\n        final PsiMethod resolvedMethod = ((GrCallExpression) parent).resolveMethod();\n        if (resolvedMethod != null) {\n          final PsiParameter[] parameters = resolvedMethod.getParameterList().getParameters();\n          if (parameters.length > 0) {\n            if (PsiUtil.createMapType(resolvedMethod.getManager(), resolvedMethod.getResolveScope()).isAssignableFrom(parameters[0].getType())) {\n              //call with named argument, not setting property\n              return null;\n            }\n          }\n        }\n      }\n\n      if (parent instanceof GrExpression || parent instanceof GrAnonymousClassDefinition) {\n        PsiType type =\n          parent instanceof GrExpression ? ((GrExpression)parent).getType() : ((GrAnonymousClassDefinition)parent).getBaseClassType();\n        if (type instanceof PsiClassType) {\n          PsiClass clazz = ((PsiClassType) type).resolve();\n          if (clazz != null) {\n            PsiMethod[] byName = clazz.findMethodsByName(setterName, true);\n            if (byName.length > 0) return byName[0];\n            final PsiField field = clazz.findFieldByName(propName, true);\n            if (field != null) return field;\n            final PropertyResolverProcessor processor = new PropertyResolverProcessor(propName, this);\n            ResolveUtil\n              .processNonCodeMethods(JavaPsiFacade.getElementFactory(getProject()).createType(clazz), processor, getProject(), this, false);\n            final GroovyResolveResult[] candidates = processor.getCandidates();\n            if (candidates.length == 0) return null;\n            return candidates[0].getElement();\n          }\n        }\n      }\n    }\n    return null;\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean canNavigateToSource() {\n    return false;\n  }","id":37256,"modified_method":"public boolean canNavigateToSource() {\n    return myNavigationalElement != this;\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void navigate(boolean requestFocus) {\n    DynamicToolWindowWrapper.getInstance(myProject).getToolWindow().activate(new Runnable() {\n      public void run() {\n        DynamicToolWindowWrapper toolWindowWrapper = DynamicToolWindowWrapper.getInstance(myProject);\n        final TreeTable treeTable = toolWindowWrapper.getTreeTable();\n        final ListTreeTableModelOnColumns model = toolWindowWrapper.getTreeTableModel();\n\n        Object root = model.getRoot();\n\n        if (root == null || !(root instanceof DefaultMutableTreeNode)) return;\n\n        DefaultMutableTreeNode treeRoot = ((DefaultMutableTreeNode) root);\n        final PsiClass psiClass = getContainingClassElement();\n        if (psiClass == null) return;\n\n        final DefaultMutableTreeNode desiredNode;\n        DPropertyElement dynamicProperty = null;\n        PsiClass trueSuper = null;\n        for (PsiClass aSuper : PsiUtil.iterateSupers(psiClass, true)) {\n          dynamicProperty = DynamicManager.getInstance(myProject).findConcreteDynamicProperty(aSuper.getQualifiedName(), getName());\n\n          if (dynamicProperty != null) {\n            trueSuper = aSuper;\n            break;\n          }\n        }\n\n        if (trueSuper == null) return;\n\n        final DefaultMutableTreeNode classNode = TreeUtil.findNodeWithObject(treeRoot, new DClassElement(myProject, trueSuper.getQualifiedName()));\n        if (classNode == null) return;\n\n        desiredNode = TreeUtil.findNodeWithObject(classNode, dynamicProperty);\n\n        if (desiredNode == null) return;\n        final TreePath path = TreeUtil.getPathFromRoot(desiredNode);\n\n        treeTable.getTree().expandPath(path);\n        treeTable.getTree().setSelectionPath(path);\n        treeTable.getTree().fireTreeExpanded(path);\n\n        ToolWindowManager.getInstance(myProject).getFocusManager().requestFocus(treeTable, true);\n        treeTable.revalidate();\n        treeTable.repaint();\n\n      }\n    }, true);\n  }","id":37257,"modified_method":"public void navigate(boolean requestFocus) {\n    if (canNavigateToSource()) {\n      super.navigate(requestFocus);\n      return;\n    }\n    DynamicToolWindowWrapper.getInstance(myProject).getToolWindow().activate(new Runnable() {\n      public void run() {\n        DynamicToolWindowWrapper toolWindowWrapper = DynamicToolWindowWrapper.getInstance(myProject);\n        final TreeTable treeTable = toolWindowWrapper.getTreeTable();\n        final ListTreeTableModelOnColumns model = toolWindowWrapper.getTreeTableModel();\n\n        Object root = model.getRoot();\n\n        if (root == null || !(root instanceof DefaultMutableTreeNode)) return;\n\n        DefaultMutableTreeNode treeRoot = ((DefaultMutableTreeNode) root);\n        final PsiClass psiClass = getContainingClassElement();\n        if (psiClass == null) return;\n\n        final DefaultMutableTreeNode desiredNode;\n        DPropertyElement dynamicProperty = null;\n        PsiClass trueSuper = null;\n        for (PsiClass aSuper : PsiUtil.iterateSupers(psiClass, true)) {\n          dynamicProperty = DynamicManager.getInstance(myProject).findConcreteDynamicProperty(aSuper.getQualifiedName(), getName());\n\n          if (dynamicProperty != null) {\n            trueSuper = aSuper;\n            break;\n          }\n        }\n\n        if (trueSuper == null) return;\n\n        final DefaultMutableTreeNode classNode = TreeUtil.findNodeWithObject(treeRoot, new DClassElement(myProject, trueSuper.getQualifiedName()));\n        if (classNode == null) return;\n\n        desiredNode = TreeUtil.findNodeWithObject(classNode, dynamicProperty);\n\n        if (desiredNode == null) return;\n        final TreePath path = TreeUtil.getPathFromRoot(desiredNode);\n\n        treeTable.getTree().expandPath(path);\n        treeTable.getTree().setSelectionPath(path);\n        treeTable.getTree().fireTreeExpanded(path);\n\n        ToolWindowManager.getInstance(myProject).getFocusManager().requestFocus(treeTable, true);\n        treeTable.revalidate();\n        treeTable.repaint();\n\n      }\n    }, true);\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GrDynamicImplicitProperty(PsiManager manager, @NonNls String name, @NonNls String type, String containingClassName, LightModifierList modifierList) {\n    super(modifierList, manager, name, type, null);\n    myContainingClassName = containingClassName;\n    myProject = manager.getProject();\n  }","id":37258,"modified_method":"public GrDynamicImplicitProperty(PsiManager manager, @NonNls String name, @NonNls String type, String containingClassName,\n                                   LightModifierList modifierList, PsiElement navigationalElement) {\n    super(modifierList, manager, name, type, navigationalElement);\n    myContainingClassName = containingClassName;\n    myProject = manager.getProject();\n    if (navigationalElement==null) {\n      myNavigationalElement = this;\n    }\n    else {\n      myNavigationalElement = navigationalElement;\n    }\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GrImplicitVariableImpl(PsiModifierList modifierList, PsiManager manager, @NonNls String name, @NonNls String type, PsiElement referenceExpression) {\n    this(modifierList, manager, null,\n        JavaPsiFacade.getInstance(manager.getProject()).getElementFactory().\n            createTypeByFQClassName(type, ProjectScope.getAllScope(manager.getProject())), false, referenceExpression);\n    myNameIdentifier = new GrLightIdentifier(myManager, name);\n  }","id":37259,"modified_method":"public GrImplicitVariableImpl(PsiModifierList modifierList, PsiManager manager, @NonNls String name, @NonNls String type, PsiElement referenceExpression) {\n    this(modifierList, manager, null, JavaPsiFacade.getElementFactory(manager.getProject()).\n      createTypeFromText(type, referenceExpression), false, referenceExpression);\n    myNameIdentifier = new GrLightIdentifier(myManager, name);\n  }","commit_id":"ecdfef60587de7e308ca48cedb52ec82a8742006","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void processDependencyAddition(@NotNull String gradleConfigurationName,\n                                                @NotNull PsiClass dependencyHandlerClass,\n                                                @NotNull PsiScopeProcessor processor,\n                                                @NotNull ResolveState state,\n                                                @NotNull PsiElement place) {\n    GrLightMethodBuilder builder = new GrLightMethodBuilder(place.getManager(), gradleConfigurationName);\n    PsiElementFactory factory = JavaPsiFacade.getInstance(place.getManager().getProject()).getElementFactory();\n    PsiType type = new PsiArrayType(factory.createTypeByFQClassName(CommonClassNames.JAVA_LANG_OBJECT, place.getResolveScope()));\n    builder.addParameter(new GrLightParameter(\"dependencyInfo\", type, builder));\n    processor.execute(builder, state);\n\n    GrMethodCall call = PsiTreeUtil.getParentOfType(place, GrMethodCall.class);\n    if (call == null) {\n      return;\n    }\n    GrArgumentList args = call.getArgumentList();\n    if (args == null) {\n      return;\n    }\n\n    int argsCount = GradleResolverUtil.getGrMethodArumentsCount(args);\n    argsCount++; // Configuration name is delivered as an argument.\n\n    for (PsiMethod method : dependencyHandlerClass.findMethodsByName(\"add\", false)) {\n      if (method.getParameterList().getParametersCount() == argsCount) {\n        builder.setNavigationElement(method);\n      }\n    }\n  }","id":37260,"modified_method":"private static void processDependencyAddition(@NotNull String gradleConfigurationName,\n                                                @NotNull PsiClass dependencyHandlerClass,\n                                                @NotNull PsiScopeProcessor processor,\n                                                @NotNull ResolveState state,\n                                                @NotNull PsiElement place) {\n    GrLightMethodBuilder builder = new GrLightMethodBuilder(place.getManager(), gradleConfigurationName);\n    PsiElementFactory factory = JavaPsiFacade.getElementFactory(place.getManager().getProject());\n    PsiType type = new PsiArrayType(factory.createTypeByFQClassName(CommonClassNames.JAVA_LANG_OBJECT, place.getResolveScope()));\n    builder.addParameter(new GrLightParameter(\"dependencyInfo\", type, builder));\n    processor.execute(builder, state);\n\n    GrMethodCall call = PsiTreeUtil.getParentOfType(place, GrMethodCall.class);\n    if (call == null) {\n      return;\n    }\n    GrArgumentList args = call.getArgumentList();\n    if (args == null) {\n      return;\n    }\n\n    int argsCount = GradleResolverUtil.getGrMethodArumentsCount(args);\n    argsCount++; // Configuration name is delivered as an argument.\n\n    for (PsiMethod method : dependencyHandlerClass.findMethodsByName(\"add\", false)) {\n      if (method.getParameterList().getParametersCount() == argsCount) {\n        builder.setNavigationElement(method);\n      }\n    }\n  }","commit_id":"049514a9421a579c2cc79097d5714e937262999d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static GrLightMethodBuilder createMethodWithClosure(@NotNull String name, @NotNull PsiElement place, @Nullable String returnType) {\n    GrLightMethodBuilder methodWithClosure = new GrLightMethodBuilder(place.getManager(), name);\n    PsiElementFactory factory = JavaPsiFacade.getInstance(place.getManager().getProject()).getElementFactory();\n    PsiClassType closureType = factory.createTypeByFQClassName(GroovyCommonClassNames.GROOVY_LANG_CLOSURE, place.getResolveScope());\n    GrLightParameter closureParameter = new GrLightParameter(\"closure\", closureType, methodWithClosure);\n    methodWithClosure.addParameter(closureParameter);\n\n    if (returnType != null) {\n      PsiClassType retType = factory.createTypeByFQClassName(returnType, place.getResolveScope());\n      methodWithClosure.setReturnType(retType);\n    }\n    return methodWithClosure;\n  }","id":37261,"modified_method":"public static GrLightMethodBuilder createMethodWithClosure(@NotNull String name, @NotNull PsiElement place, @Nullable String returnType) {\n    GrLightMethodBuilder methodWithClosure = new GrLightMethodBuilder(place.getManager(), name);\n    PsiElementFactory factory = JavaPsiFacade.getElementFactory(place.getManager().getProject());\n    PsiClassType closureType = factory.createTypeByFQClassName(GroovyCommonClassNames.GROOVY_LANG_CLOSURE, place.getResolveScope());\n    GrLightParameter closureParameter = new GrLightParameter(\"closure\", closureType, methodWithClosure);\n    methodWithClosure.addParameter(closureParameter);\n\n    if (returnType != null) {\n      PsiClassType retType = factory.createTypeByFQClassName(returnType, place.getResolveScope());\n      methodWithClosure.setReturnType(retType);\n    }\n    return methodWithClosure;\n  }","commit_id":"049514a9421a579c2cc79097d5714e937262999d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiExpression getValue(PsiCallExpression callExpression) {\n    return JavaPsiFacade.getInstance(callExpression.getProject()).getElementFactory()\n      .createExpressionFromText(myDefaultValue, callExpression);\n  }","id":37262,"modified_method":"public PsiExpression getValue(PsiCallExpression callExpression) {\n    return JavaPsiFacade.getElementFactory(callExpression.getProject()).createExpressionFromText(getDefaultValue(), callExpression);\n  }","commit_id":"ba1ac92dee64e593e7355248d329b7bf385c40f6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void processPropertyFromField(GrField field, GroovyResolveResult resolveResult) {\n      if (field.getGetters().length == 0 && field.getSetter() == null && myPropertyNames.add(field.getName())) {\n        myConsumer\n          .consume(((LookupElementBuilder)GroovyCompletionUtil.createCompletionVariant(resolveResult)).setIcon(GroovyIcons.PROPERTY));\n      }\n    }","id":37263,"modified_method":"private void processPropertyFromField(GrField field, GroovyResolveResult resolveResult) {\n      if (field.getGetters().length != 0 || field.getSetter() != null || !myPropertyNames.add(field.getName())) return;\n\n      myConsumer.consume(((LookupElementBuilder)GroovyCompletionUtil.createCompletionVariant(resolveResult)).setIcon(GroovyIcons.PROPERTY));\n    }","commit_id":"b35f8d538bdba711a7f54e8a681325b3d5552698","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void processListenerProperties(PsiMethod method) {\n      if (method.getName().startsWith(\"add\") && method.getParameterList().getParametersCount() == 1) {\n        final PsiParameter parameter = method.getParameterList().getParameters()[0];\n        final PsiType type = parameter.getType();\n        if (type instanceof PsiClassType) {\n          final PsiClassType classType = (PsiClassType)type;\n          final PsiClass listenerClass = classType.resolve();\n          if (listenerClass != null) {\n            final PsiMethod[] listenerMethods = listenerClass.getMethods();\n            if (InheritanceUtil.isInheritorOrSelf(listenerClass, myEventListener, true)) {\n              for (PsiMethod listenerMethod : listenerMethods) {\n                final String name = listenerMethod.getName();\n                if (myPropertyNames.add(name)) {\n                  LookupElementBuilder builder = LookupElementBuilder\n                    .create(generatePropertyResolveResult(name, listenerMethod, null, null), name)\n                    .setIcon(GroovyIcons.PROPERTY);\n                  myConsumer.consume(builder);\n                }\n              }\n            }\n          }\n        }\n      }\n    }","id":37264,"modified_method":"private void processListenerProperties(PsiMethod method) {\n      if (!method.getName().startsWith(\"add\") || method.getParameterList().getParametersCount() != 1) return;\n\n      final PsiParameter parameter = method.getParameterList().getParameters()[0];\n      final PsiType type = parameter.getType();\n      if (!(type instanceof PsiClassType)) return;\n\n      final PsiClassType classType = (PsiClassType)type;\n      final PsiClass listenerClass = classType.resolve();\n      if (listenerClass == null) return;\n\n      final PsiMethod[] listenerMethods = listenerClass.getMethods();\n      if (!InheritanceUtil.isInheritorOrSelf(listenerClass, myEventListener, true)) return;\n\n      for (PsiMethod listenerMethod : listenerMethods) {\n        final String name = listenerMethod.getName();\n        if (myPropertyNames.add(name)) {\n          LookupElementBuilder builder = LookupElementBuilder\n            .create(generatePropertyResolveResult(name, listenerMethod, null, null), name)\n            .setIcon(GroovyIcons.PROPERTY);\n          myConsumer.consume(builder);\n        }\n      }\n    }","commit_id":"b35f8d538bdba711a7f54e8a681325b3d5552698","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void processIfJavaLangClass(GrReferenceExpression refExpr, ResolverProcessor consumer, PsiType type) {\n    if (type instanceof PsiClassType) {\n      final PsiClass psiClass = ((PsiClassType)type).resolve();\n      if (psiClass != null && CommonClassNames.JAVA_LANG_CLASS.equals(psiClass.getQualifiedName())) {\n        final PsiType[] params = ((PsiClassType)type).getParameters();\n        if (params.length == 1) {\n          getVariantsFromQualifierType(refExpr, consumer, params[0], refExpr.getProject());\n        }\n      }\n    }\n  }","id":37265,"modified_method":"private static void processIfJavaLangClass(GrReferenceExpression refExpr, ResolverProcessor consumer, PsiType type) {\n    if (!(type instanceof PsiClassType)) return;\n\n    final PsiClass psiClass = ((PsiClassType)type).resolve();\n    if (psiClass == null || !CommonClassNames.JAVA_LANG_CLASS.equals(psiClass.getQualifiedName())) return;\n\n    final PsiType[] params = ((PsiClassType)type).getParameters();\n    if (params.length != 1) return;\n\n    getVariantsFromQualifierType(refExpr, consumer, params[0], refExpr.getProject());\n  }","commit_id":"b35f8d538bdba711a7f54e8a681325b3d5552698","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void consume(Object o) {\n      if (o instanceof GroovyResolveResult) {\n        final GroovyResolveResult result = (GroovyResolveResult)o;\n        if (!result.isStaticsOK()) return;\n        if (mySkipPackages && result.getElement() instanceof PsiPackage) return;\n\n        addCandidate(result);\n        //myConsumer.consume(GroovyCompletionUtil.createCompletionVariant(result));\n\n\n        final PsiElement element = result.getElement();\n        if (element instanceof PsiMethod) {\n          processProperty((PsiMethod)element, result);\n        }\n        else if (element instanceof GrField) {\n          if (((GrField)element).isProperty()) {\n            processPropertyFromField((GrField)element, result);\n          }\n        }\n        else if (element instanceof GrVariable && ((GrVariable)element).getName()!=null) {\n          myLocalVars.add(((GrVariable)element).getName());\n        }\n      }\n      else {\n        myConsumer.consume(o);\n      }\n    }","id":37266,"modified_method":"public void consume(Object o) {\n      if (!(o instanceof GroovyResolveResult)) {\n        myConsumer.consume(o);\n        return;\n      }\n\n      final GroovyResolveResult result = (GroovyResolveResult)o;\n      if (!result.isStaticsOK() || !result.isAccessible()) return;\n      if (mySkipPackages && result.getElement() instanceof PsiPackage) return;\n\n      addCandidate(result);\n\n      final PsiElement element = result.getElement();\n      if (element instanceof PsiMethod) {\n        processProperty((PsiMethod)element, result);\n      }\n      else if (element instanceof GrField) {\n        if (((GrField)element).isProperty()) {\n          processPropertyFromField((GrField)element, result);\n        }\n      }\n      else if (element instanceof GrVariable && ((GrVariable)element).getName() != null) {\n        myLocalVars.add(((GrVariable)element).getName());\n      }\n    }","commit_id":"b35f8d538bdba711a7f54e8a681325b3d5552698","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void getVariantsFromQualifier(GrReferenceExpression refExpr, ResolverProcessor processor, GrExpression qualifier) {\n    Project project = qualifier.getProject();\n    PsiType qualifierType = qualifier.getType();\n    final ResolveState state = ResolveState.initial();\n    if (qualifierType == null) {\n      if (qualifier instanceof GrReferenceExpression) {\n        PsiElement resolved = ((GrReferenceExpression)qualifier).resolve();\n        if (resolved instanceof PsiPackage) {\n          resolved.processDeclarations(processor, state, null, refExpr);\n          return;\n        }\n      }\n      getVariantsFromQualifierType(refExpr, processor, GrClassImplUtil.getGroovyObjectType(refExpr), project);\n    }\n    else {\n      if (qualifierType instanceof PsiIntersectionType) {\n        for (PsiType conjunct : ((PsiIntersectionType)qualifierType).getConjuncts()) {\n          getVariantsFromQualifierType(refExpr, processor, conjunct, project);\n        }\n      }\n      else {\n        getVariantsFromQualifierType(refExpr, processor, qualifierType, project);\n        if (qualifier instanceof GrReferenceExpression) {\n          PsiElement resolved = ((GrReferenceExpression)qualifier).resolve();\n          if (resolved instanceof PsiClass) { ////omitted .class\n            GlobalSearchScope scope = refExpr.getResolveScope();\n            PsiClass javaLangClass = PsiUtil.getJavaLangClass(resolved, scope);\n            if (javaLangClass != null) {\n              PsiSubstitutor substitutor = PsiSubstitutor.EMPTY;\n              PsiTypeParameter[] typeParameters = javaLangClass.getTypeParameters();\n              if (typeParameters.length == 1) {\n                substitutor = substitutor.put(typeParameters[0], qualifierType);\n              }\n              javaLangClass.processDeclarations(processor, state, null, refExpr);\n              PsiType javaLangClassType =\n                JavaPsiFacade.getInstance(refExpr.getProject()).getElementFactory().createType(javaLangClass, substitutor);\n              ResolveUtil.processNonCodeMembers(javaLangClassType, processor, refExpr, state);\n            }\n          }\n        }\n      }\n    }\n  }","id":37267,"modified_method":"private static void getVariantsFromQualifier(GrReferenceExpression refExpr, ResolverProcessor processor, GrExpression qualifier) {\n    Project project = qualifier.getProject();\n    PsiType qualifierType = qualifier.getType();\n    final ResolveState state = ResolveState.initial();\n    if (qualifierType == null) {\n      if (qualifier instanceof GrReferenceExpression) {\n        PsiElement resolved = ((GrReferenceExpression)qualifier).resolve();\n        if (resolved instanceof PsiPackage) {\n          resolved.processDeclarations(processor, state, null, refExpr);\n          return;\n        }\n      }\n      getVariantsFromQualifierType(refExpr, processor, GrClassImplUtil.getGroovyObjectType(refExpr), project);\n    }\n    else if (qualifierType instanceof PsiIntersectionType) {\n      for (PsiType conjunct : ((PsiIntersectionType)qualifierType).getConjuncts()) {\n        getVariantsFromQualifierType(refExpr, processor, conjunct, project);\n      }\n    }\n    else {\n      getVariantsFromQualifierType(refExpr, processor, qualifierType, project);\n      if (qualifier instanceof GrReferenceExpression) {\n        PsiElement resolved = ((GrReferenceExpression)qualifier).resolve();\n        if (resolved instanceof PsiClass) { ////omitted .class\n          GlobalSearchScope scope = refExpr.getResolveScope();\n          PsiClass javaLangClass = PsiUtil.getJavaLangClass(resolved, scope);\n          if (javaLangClass != null) {\n            PsiSubstitutor substitutor = PsiSubstitutor.EMPTY;\n            PsiTypeParameter[] typeParameters = javaLangClass.getTypeParameters();\n            if (typeParameters.length == 1) {\n              substitutor = substitutor.put(typeParameters[0], qualifierType);\n            }\n            PsiType javaLangClassType = JavaPsiFacade.getElementFactory(refExpr.getProject()).createType(javaLangClass, substitutor);\n            ResolveUtil.processAllDeclarations(javaLangClassType, processor, state, refExpr);\n          }\n        }\n      }\n    }\n  }","commit_id":"b35f8d538bdba711a7f54e8a681325b3d5552698","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    public PsiType visitClassType(PsiClassType classType) {\n      final PsiClassType.ClassResolveResult resolveResult = classType.resolveGenerics();\n      final PsiClass aClass = resolveResult.getElement();\n      if (aClass == null) return classType;\n      assert aClass.isValid();\n      if (aClass instanceof PsiTypeParameter) {\n        final PsiTypeParameter typeParameter = (PsiTypeParameter)aClass;\n        if (containsInMap(typeParameter)) {\n          return substituteTypeParameter(typeParameter);\n        }\n        else {\n          return classType;\n        }\n      }\n      final Map<PsiTypeParameter, PsiType> hashMap = new HashMap<PsiTypeParameter, PsiType>(2);\n      if (!processClass(aClass, resolveResult.getSubstitutor(), hashMap)) {\n        return null;\n      }\n      return JavaPsiFacade.getInstance(aClass.getProject()).getElementFactory()\n        .createType(aClass, createSubstitutor(hashMap), classType.getLanguageLevel());\n    }","id":37268,"modified_method":"@Override\n    public PsiType visitClassType(PsiClassType classType) {\n      final PsiClassType.ClassResolveResult resolveResult = classType.resolveGenerics();\n      final PsiClass aClass = resolveResult.getElement();\n      if (aClass == null) return classType;\n      assert classType.isValid();\n      assert aClass.isValid();\n      if (aClass instanceof PsiTypeParameter) {\n        final PsiTypeParameter typeParameter = (PsiTypeParameter)aClass;\n        if (containsInMap(typeParameter)) {\n          PsiType result = substituteTypeParameter(typeParameter);\n          if (result != null) {\n            assert result.isValid();\n          }\n          return result;\n        }\n        else {\n          return classType;\n        }\n      }\n      final Map<PsiTypeParameter, PsiType> hashMap = new HashMap<PsiTypeParameter, PsiType>(2);\n      if (!processClass(aClass, resolveResult.getSubstitutor(), hashMap)) {\n        return null;\n      }\n      PsiClassType result = JavaPsiFacade.getElementFactory(aClass.getProject()).createType(aClass, createSubstitutor(hashMap), classType.getLanguageLevel());\n      assert result.isValid();\n      return result;\n    }","commit_id":"8e7bc5e89897f7088589222f310828a9590f2bce","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean equalityExpressionIsPointless(PsiExpression... lhs) {\n      for (PsiExpression expression : lhs) {\n        if (isTrue(expression) || isFalse(expression)) return true;\n      }\n      return false;\n    }","id":37269,"modified_method":"private boolean equalityExpressionIsPointless(PsiExpression... lhs) {\n      for (PsiExpression expression : lhs) {\n        if (evaluate(expression) != null) return true;\n      }\n      return false;\n    }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private String calculateSimplifiedBinaryExpression(\n    PsiBinaryExpression expression) {\n    final PsiExpression lhs = expression.getLOperand();\n\n    final PsiExpression rhs = expression.getROperand();\n    if (rhs == null) {\n      return null;\n    }\n    final IElementType tokenType = expression.getOperationTokenType();\n    final String rhsText = rhs.getText();\n    final String lhsText = lhs.getText();\n    if (tokenType.equals(JavaTokenType.ANDAND) ||\n        tokenType.equals(JavaTokenType.AND)) {\n      if (isTrue(lhs)) {\n        return rhsText;\n      }\n      else if (isFalse(lhs) || isFalse(rhs)) {\n        return \"false\";\n      }\n      else {\n        return lhsText;\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.OROR) ||\n             tokenType.equals(JavaTokenType.OR)) {\n      if (isFalse(lhs)) {\n        return rhsText;\n      }\n      else {\n        return lhsText;\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.XOR) ||\n             tokenType.equals(JavaTokenType.NE)) {\n      if (isFalse(lhs)) {\n        return rhsText;\n      }\n      else if (isFalse(rhs)) {\n        return lhsText;\n      }\n      else if (isTrue(lhs)) {\n        return createStringForNegatedExpression(rhs);\n      }\n      else {\n        return createStringForNegatedExpression(lhs);\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.EQEQ)) {\n      if (isTrue(lhs)) {\n        return rhsText;\n      }\n      else if (isTrue(rhs)) {\n        return lhsText;\n      }\n      else if (isFalse(lhs)) {\n        return createStringForNegatedExpression(rhs);\n      }\n      else {\n        return createStringForNegatedExpression(lhs);\n      }\n    }\n    else {\n      return \"\";\n    }\n  }","id":37270,"modified_method":"@Nullable\n  private String calculateSimplifiedBinaryExpression(\n    PsiBinaryExpression expression) {\n    final PsiExpression lhs = expression.getLOperand();\n\n    final PsiExpression rhs = expression.getROperand();\n    if (rhs == null) {\n      return null;\n    }\n    final IElementType tokenType = expression.getOperationTokenType();\n    final String rhsText = rhs.getText();\n    final String lhsText = lhs.getText();\n    if (tokenType.equals(JavaTokenType.ANDAND) ||\n        tokenType.equals(JavaTokenType.AND)) {\n      if (isAlwaysTrue(lhs)) {\n        return rhsText;\n      }\n      else if (isAlwaysFalse(lhs) || isAlwaysFalse(rhs)) {\n        return \"false\";\n      }\n      else {\n        return lhsText;\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.OROR) ||\n             tokenType.equals(JavaTokenType.OR)) {\n      if (isAlwaysFalse(lhs)) {\n        return rhsText;\n      }\n      else {\n        return lhsText;\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.XOR) ||\n             tokenType.equals(JavaTokenType.NE)) {\n      if (isAlwaysFalse(lhs)) {\n        return rhsText;\n      }\n      else if (isAlwaysFalse(rhs)) {\n        return lhsText;\n      }\n      else if (isAlwaysTrue(lhs)) {\n        return createStringForNegatedExpression(rhs);\n      }\n      else {\n        return createStringForNegatedExpression(lhs);\n      }\n    }\n    else if (tokenType.equals(JavaTokenType.EQEQ)) {\n      if (isAlwaysTrue(lhs)) {\n        return rhsText;\n      }\n      else if (isAlwaysTrue(rhs)) {\n        return lhsText;\n      }\n      else if (isAlwaysFalse(lhs)) {\n        return createStringForNegatedExpression(rhs);\n      }\n      else {\n        return createStringForNegatedExpression(lhs);\n      }\n    }\n    else {\n      return \"\";\n    }\n  }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean orExpressionIsPointless(PsiExpression... lhs) {\n      for (PsiExpression expression : lhs) {\n        if (isFalse(expression)) return true;\n      }\n      return false;\n    }","id":37271,"modified_method":"private boolean orExpressionIsPointless(PsiExpression... lhs) {\n      for (PsiExpression expression : lhs) {\n        if (isAlwaysFalse(expression)) return true;\n      }\n      return false;\n    }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private String calculateSimplifiedPrefixExpression(\n    PsiPrefixExpression expression) {\n    final PsiExpression operand = expression.getOperand();\n    if (isTrue(operand)) {\n      return PsiKeyword.FALSE;\n    }\n    else {\n      return PsiKeyword.TRUE;\n    }\n  }","id":37272,"modified_method":"@NotNull\n  private String calculateSimplifiedPrefixExpression(PsiPrefixExpression e) {\n    final PsiExpression expression = removeRedundantNots(e);\n\n    final Boolean value = evaluate(expression);\n\n    if (value == Boolean.TRUE) {\n      return PsiKeyword.TRUE;\n    }\n\n    if (value == Boolean.FALSE) {\n      return PsiKeyword.FALSE;\n    }\n\n    return expression != null ? expression.getText() : \"\";\n  }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean isFalse(PsiExpression expression) {\n    if (m_ignoreExpressionsContainingConstants &&\n        !(expression instanceof PsiLiteralExpression)) {\n      return false;\n    }\n    if (expression == null) {\n      return false;\n    }\n    final Boolean value =\n      (Boolean)ConstantExpressionUtil.computeCastTo(expression,\n                                                    PsiType.BOOLEAN);\n    return value != null && !value.booleanValue();\n  }","id":37273,"modified_method":"private boolean isAlwaysFalse(@Nullable PsiExpression expression) {\n    return evaluate(expression) == Boolean.FALSE;\n  }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    public void visitPrefixExpression(\n      @NotNull PsiPrefixExpression expression) {\n      super.visitPrefixExpression(expression);\n      final PsiExpression operand = expression.getOperand();\n      final IElementType tokenType = expression.getOperationTokenType();\n      if (!(!tokenType.equals(JavaTokenType.EXCL) ||\n            !notExpressionIsPointless(operand))) {\n        registerError(expression, expression);\n      }\n    }","id":37274,"modified_method":"@Override\n    public void visitPrefixExpression(@NotNull PsiPrefixExpression expression) {\n      super.visitPrefixExpression(expression);\n      final PsiExpression operand = expression.getOperand();\n      final IElementType tokenType = expression.getOperationTokenType();\n      if (JavaTokenType.EXCL.equals(tokenType) && notExpressionIsPointless(operand)) {\n        registerError(expression, expression);\n      }\n    }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean isTrue(PsiExpression expression) {\n    if (m_ignoreExpressionsContainingConstants &&\n        !(expression instanceof PsiLiteralExpression)) {\n      return false;\n    }\n\n    if (expression == null) {\n      return false;\n    }\n    final Boolean value =\n      (Boolean)ConstantExpressionUtil.computeCastTo(expression,\n                                                    PsiType.BOOLEAN);\n    return value != null && value.booleanValue();\n  }","id":37275,"modified_method":"private boolean isAlwaysTrue(@Nullable PsiExpression expression) {\n    return evaluate(expression) == Boolean.TRUE;\n  }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean notExpressionIsPointless(PsiExpression arg) {\n      return equalityExpressionIsPointless(arg);\n    }","id":37276,"modified_method":"private boolean notExpressionIsPointless(PsiExpression arg) {\n      if (arg instanceof PsiPrefixExpression) {\n        final PsiPrefixExpression prefixExpression = (PsiPrefixExpression)arg;\n        if (JavaTokenType.EXCL.equals(prefixExpression.getOperationTokenType())) {\n          return true;\n        }\n      }\n      return equalityExpressionIsPointless(arg);\n    }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private boolean processSubExpressions(Project project, PsiExpression element) {\n      if (element instanceof PsiPrefixExpression) {\n        SimplifyBooleanExpressionFix.simplifyExpression(project, element, isTrue(element));\n      }  else {\n        if (element instanceof PsiPolyadicExpression) {\n          for (PsiExpression operand :((PsiPolyadicExpression)element).getOperands()) {\n            Boolean bool = isTrue(operand) ? Boolean.TRUE : isFalse(operand) ? Boolean.FALSE : null;\n            if (bool != null) {\n              SimplifyBooleanExpressionFix.simplifyExpression(project, operand, bool);\n              return true;\n            } else {\n              if (processSubExpressions(project, operand)) return true;\n            }\n          }\n        }\n      }\n      return false;\n    }","id":37277,"modified_method":"private boolean processSubExpressions(Project project, PsiExpression element) {\n      if (element instanceof PsiPrefixExpression) {\n        return processPrefixExpression(project, (PsiPrefixExpression)element);\n      }\n\n      if (element instanceof PsiPolyadicExpression) {\n        final PsiPolyadicExpression polyadicExpression = (PsiPolyadicExpression)element;\n        for (PsiExpression operand : polyadicExpression.getOperands()) {\n          final Boolean bool = evaluate(operand);\n          if (bool != null) {\n            SimplifyBooleanExpressionFix.simplifyExpression(project, operand, bool);\n            return true;\n          }\n          if (processSubExpressions(project, operand)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void simplifyExpression(Project project, final PsiExpression subExpression, final Boolean subExpressionValue) {\n    PsiExpression expression;\n    if (subExpressionValue == null) {\n      expression = subExpression;\n    }\n    else {\n      PsiExpression constExpression = JavaPsiFacade.getInstance(project).getElementFactory()\n        .createExpressionFromText(Boolean.toString(subExpressionValue.booleanValue()), subExpression);\n      expression = (PsiExpression)subExpression.replace(constExpression);\n    }\n    while (expression.getParent() instanceof PsiExpression) {\n      expression = (PsiExpression)expression.getParent();\n    }\n    simplifyExpression(expression);\n  }","id":37278,"modified_method":"public static void simplifyExpression(Project project, final PsiExpression subExpression, final Boolean subExpressionValue) {\n    PsiExpression expression;\n    if (subExpressionValue == null) {\n      expression = subExpression;\n    }\n    else {\n      final PsiElementFactory factory = JavaPsiFacade.getElementFactory(project);\n      final PsiExpression constExpression = factory.createExpressionFromText(Boolean.toString(subExpressionValue.booleanValue()), subExpression);\n      expression = (PsiExpression)subExpression.replace(constExpression);\n    }\n    while (expression.getParent() instanceof PsiExpression) {\n      expression = (PsiExpression)expression.getParent();\n    }\n    simplifyExpression(expression);\n  }","commit_id":"7f0f06e42829c22c6c5e7706a3ac506d7b9c5254","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   *\n   * @param accessToken is the access token from Authorization header in HTTP Request\n   * @return the serialized access token identifer\n   * @throws IOException\n   */\n  public String transform(String accessToken) throws IOException {\n    byte[] decodedAccessToken = Base64.decodeBase64(accessToken);\n    AccessToken accessTokenObj = accessTokenCodec.decode(decodedAccessToken);\n    AccessTokenIdentifier accessTokenIdentifierObj = accessTokenObj.getIdentifier();\n    byte[] encodedAccessTokenIdentifier = accessTokenIdentifierCodec.encode(accessTokenIdentifierObj);\n    return Base64.encodeBase64String(encodedAccessTokenIdentifier);\n  }","id":37279,"modified_method":"/**\n   *\n   * @param accessToken is the access token from Authorization header in HTTP Request\n   * @return the serialized access token identifer\n   * @throws IOException\n   */\n  public String transform(String accessToken) throws IOException {\n    byte[] decodedAccessToken = Base64.decodeBase64(accessToken);\n    AccessToken accessTokenObj = accessTokenCodec.decode(decodedAccessToken);\n    AccessTokenIdentifier accessTokenIdentifierObj = accessTokenObj.getIdentifier();\n    byte[] encodedAccessTokenIdentifier = accessTokenIdentifierCodec.encode(accessTokenIdentifierObj);\n    return Base64.encodeBase64String(encodedAccessTokenIdentifier).trim();\n  }","commit_id":"20b31282c13bcca98ac265d826b015af277353bc","url":"https://github.com/caskdata/cdap"},{"original_method":"@Test\n    public void retrieveBinary() {\n        PostMethod post = new PostMethod(COLLECTION_ROOT_URL + \"/\" + XQUERY_FILENAME);\n\n        final String testData = \"12345\";\n\n        post.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\n        post.setRequestEntity(new ByteArrayRequestEntity(testData.getBytes()));\n\n        testRequest(post, wrapInElement(encodeBase64String(testData.getBytes())).getBytes());\n    }","id":37280,"modified_method":"@Test\n    public void retrieveBinary() {\n        PostMethod post = new PostMethod(COLLECTION_ROOT_URL + \"/\" + XQUERY_FILENAME);\n\n        final String testData = \"12345\";\n\n        post.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\n        post.setRequestEntity(new ByteArrayRequestEntity(testData.getBytes()));\n\n        testRequest(post, wrapInElement(encodeBase64String(testData.getBytes()).trim()).getBytes());\n    }","commit_id":"e0486587dc4f14fc95b1f7a9f711b7baf51ea6db","url":"https://github.com/eXist-db/exist"},{"original_method":"private Base64BinaryDocument(InputStream is) throws XPathException {\n        super(new Base64BinaryValueType(), is);\n    }","id":37281,"modified_method":"private Base64BinaryDocument(BinaryValueManager manager, InputStream is) throws XPathException {\n        super(manager, new Base64BinaryValueType(), is);\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"public static Base64BinaryDocument getInstance(BinaryValueManager manager, InputStream is) throws XPathException {\n        Base64BinaryDocument b64BinaryDocument = new Base64BinaryDocument(is);\n        manager.registerBinaryValueInstance(b64BinaryDocument);\n        return b64BinaryDocument;\n    }","id":37282,"modified_method":"public static Base64BinaryDocument getInstance(BinaryValueManager manager, InputStream is) throws XPathException {\n        Base64BinaryDocument b64BinaryDocument = new Base64BinaryDocument(manager, is);\n        manager.registerBinaryValueInstance(b64BinaryDocument);\n        return b64BinaryDocument;\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"protected BinaryValue(BinaryValueType binaryValueType) {\n        this.binaryValueType = binaryValueType;\n    }","id":37283,"modified_method":"protected BinaryValue(BinaryValueManager binaryValueManager, BinaryValueType binaryValueType) {\n        this.binaryValueManager = binaryValueManager;\n        this.binaryValueType = binaryValueType;\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"@Override\n    public AtomicValue convertTo(int requiredType) throws XPathException {\n        switch(requiredType) {\n            case Type.UNTYPED_ATOMIC:\n                //TODO still needed? Added trim() since it looks like a new line character is added\n                return new UntypedAtomicValue(getStringValue());\n            case Type.STRING:\n                //TODO still needed? Added trim() since it looks like a new line character is added\n                return new StringValue(getStringValue());\n            default:\n                throw new XPathException(\"cannot convert \" + Type.getTypeName(getType()) + \" to \" + Type.getTypeName(requiredType));\n        }\n    }","id":37284,"modified_method":"@Override\n    public AtomicValue convertTo(int requiredType) throws XPathException {\n\n        final AtomicValue result;\n\n        if(requiredType == getType()) {\n            result = this;\n        } else {\n            switch(requiredType) {\n                case Type.BASE64_BINARY:\n                    result = convertTo(new Base64BinaryValueType());\n                    break;\n                case Type.HEX_BINARY:\n                    result = convertTo(new HexBinaryValueType());\n                    break;\n                case Type.UNTYPED_ATOMIC:\n                    //TODO still needed? Added trim() since it looks like a new line character is added\n                    result = new UntypedAtomicValue(getStringValue());\n                    break;\n                case Type.STRING:\n                    //TODO still needed? Added trim() since it looks like a new line character is added\n                    result = new StringValue(getStringValue());\n                    break;\n                default:\n                    throw new XPathException(\"cannot convert \" + Type.getTypeName(getType()) + \" to \" + Type.getTypeName(requiredType));\n            }\n        }\n        return result;\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"public BinaryValueFromBinaryString(BinaryValueType binaryValueType, String value) {\n        super(binaryValueType);\n        this.value = value;\n    }","id":37285,"modified_method":"public BinaryValueFromBinaryString(BinaryValueType binaryValueType, String value) throws XPathException {\n        super(null, binaryValueType);\n        this.value = binaryValueType.verifyAndFormatString(value);\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"@Test\n    public void getInputStream() throws XPathException, IOException {\n\n        BinaryValueManager binaryValueManager = new MockBinaryValueManager();\n\n        try{\n            final String testData = \"test data\";\n\n            BinaryValue binaryValue = new BinaryValueFromBinaryString(new Base64BinaryValueType(), Base64.encodeBase64String(testData.getBytes()));\n\n            InputStream is = binaryValue.getInputStream();\n\n            int read = -1;\n            byte buf[] = new byte[1024];\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            while((read = is.read(buf)) > -1) {\n                baos.write(buf, 0, read);\n            }\n\n            assertArrayEquals(testData.getBytes(), baos.toByteArray());\n        } finally {\n            binaryValueManager.cleanupBinaryValueInstances();\n        }\n    }","id":37286,"modified_method":"@Test\n    public void getInputStream() throws XPathException, IOException {\n\n        final String testData = \"test data\";\n        final String base64TestData = Base64.encodeBase64String(testData.getBytes()).trim();\n\n        BinaryValue binaryValue = new BinaryValueFromBinaryString(new Base64BinaryValueType(), base64TestData);\n\n        InputStream is = binaryValue.getInputStream();\n\n        int read = -1;\n        byte buf[] = new byte[1024];\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        while((read = is.read(buf)) > -1) {\n            baos.write(buf, 0, read);\n        }\n\n        assertArrayEquals(testData.getBytes(), baos.toByteArray());\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"protected BinaryValueFromFile(BinaryValueType binaryValueType, File f) throws XPathException {\n        super(binaryValueType);\n        try {\n            channel = new RandomAccessFile(f, \"r\").getChannel();\n            buf = channel.map(MapMode.READ_ONLY, 0, channel.size());\n        } catch(IOException ioe) {\n            throw new XPathException(ioe.getMessage(), ioe);\n        }\n    }","id":37287,"modified_method":"protected BinaryValueFromFile(BinaryValueManager manager, BinaryValueType binaryValueType, File file) throws XPathException {\n        super(manager, binaryValueType);\n        try {\n            this.file = file;\n            this.channel = new RandomAccessFile(file, \"r\").getChannel();\n            this.buf = channel.map(MapMode.READ_ONLY, 0, channel.size());\n        } catch(IOException ioe) {\n            throw new XPathException(ioe.getMessage(), ioe);\n        }\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"public static BinaryValueFromFile getInstance(BinaryValueManager manager, BinaryValueType binaryValueType, File f) throws XPathException {\n        BinaryValueFromFile binaryFile = new BinaryValueFromFile(binaryValueType, f);\n        manager.registerBinaryValueInstance(binaryFile);\n        return binaryFile;\n    }","id":37288,"modified_method":"public static BinaryValueFromFile getInstance(BinaryValueManager manager, BinaryValueType binaryValueType, File file) throws XPathException {\n        BinaryValueFromFile binaryFile = new BinaryValueFromFile(manager, binaryValueType, file);\n        manager.registerBinaryValueInstance(binaryFile);\n        return binaryFile;\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"public static BinaryValueFromInputStream getInstance(BinaryValueManager manager, BinaryValueType binaryValueType, InputStream is) throws XPathException {\n        BinaryValueFromInputStream binaryInputStream = new BinaryValueFromInputStream(binaryValueType, is);\n        manager.registerBinaryValueInstance(binaryInputStream);\n        return binaryInputStream;\n    }","id":37289,"modified_method":"public static BinaryValueFromInputStream getInstance(BinaryValueManager manager, BinaryValueType binaryValueType, InputStream is) throws XPathException {\n        BinaryValueFromInputStream binaryInputStream = new BinaryValueFromInputStream(manager, binaryValueType, is);\n        manager.registerBinaryValueInstance(binaryInputStream);\n        return binaryInputStream;\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"protected BinaryValueFromInputStream(BinaryValueType binaryValueType, InputStream is) throws XPathException {\n        super(binaryValueType);\n\n        try {\n            this.cache = new MemoryMappedFileFilterInputStreamCache();\n            this.is = new CachingFilterInputStream(cache, is);\n\n            //TODO make sure the cache is shutdown correctly when we are done!\n\n        } catch(IOException ioe) {\n            throw new XPathException(ioe.getMessage(), ioe);\n        }\n\n        //mark the start of the stream so that we can re-read again as required\n        is.mark(Integer.MAX_VALUE);\n    }","id":37290,"modified_method":"protected BinaryValueFromInputStream(BinaryValueManager manager, BinaryValueType binaryValueType, InputStream is) throws XPathException {\n        super(manager, binaryValueType);\n\n        try {\n            this.cache = new MemoryMappedFileFilterInputStreamCache();\n            this.is = new CachingFilterInputStream(cache, is);\n            \n            //TODO make sure the cache is shutdown correctly when we are done!\n\n        } catch(IOException ioe) {\n            throw new XPathException(ioe.getMessage(), ioe);\n        }\n\n        //mark the start of the stream so that we can re-read again as required\n        is.mark(Integer.MAX_VALUE);\n    }","commit_id":"fef2e625805f61f82517ae835a7d09cb7a80b6d8","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     *  Get a child resource as identified by path. This method doesn't put\n     * a lock on the document nor does it recognize locks held by other threads.\n     * There's no guarantee that the document still exists when accessing it.\n     *\n     *@param  name  The name of the document (without collection path)\n     *@return   the document\n     */\n    public DocumentImpl getDocument(DBBroker broker, XmldbURI path) {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            DocumentImpl doc = (DocumentImpl) documents.get(path);\n            if(doc == null)\n                LOG.debug(\"Document \" + path + \" not found!\");\n            return doc;\n        } catch (LockException e) {\n            LOG.warn(e.getMessage(), e);\n            return null;\n        } finally {\n            getLock().release();\n        }\n    }","id":37291,"modified_method":"/**\n     *  Get a child resource as identified by path. This method doesn't put\n     * a lock on the document nor does it recognize locks held by other threads.\n     * There's no guarantee that the document still exists when accessing it.\n     *\n     *@param  name  The name of the document (without collection path)\n     *@return   the document\n     */\n    public DocumentImpl getDocument(DBBroker broker, XmldbURI path) {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            DocumentImpl doc = (DocumentImpl) documents.get(path.getRawCollectionPath());\n            if(doc == null)\n                LOG.debug(\"Document \" + path + \" not found!\");\n            return doc;\n        } catch (LockException e) {\n            LOG.warn(e.getMessage(), e);\n            return null;\n        } finally {\n            getLock().release();\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Retrieve a child resource after putting a read lock on it. With this method,\n     * access to the received document object is safe.\n     *\n     * @param broker\n     * @param name\n     * @return\n     * @throws LockException\n     */\n    public DocumentImpl getDocumentWithLock(DBBroker broker, XmldbURI uri, int lockMode)\n    throws LockException {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            DocumentImpl doc = (DocumentImpl) documents.get(uri);\n            if(doc == null)\n                return null;\n            Lock updateLock = doc.getUpdateLock();\n            updateLock.acquire(lockMode);\n            return doc;\n        } finally {\n            getLock().release();\n        }\n    }","id":37292,"modified_method":"/**\n     * Retrieve a child resource after putting a read lock on it. With this method,\n     * access to the received document object is safe.\n     *\n     * @param broker\n     * @param name\n     * @return\n     * @throws LockException\n     */\n    public DocumentImpl getDocumentWithLock(DBBroker broker, XmldbURI uri, int lockMode)\n    throws LockException {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            DocumentImpl doc = (DocumentImpl) documents.get(uri.getRawCollectionPath());\n            if(doc == null)\n                return null;\n            Lock updateLock = doc.getUpdateLock();\n            updateLock.acquire(lockMode);\n            return doc;\n        } finally {\n            getLock().release();\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"private DocumentSet allDocs(DBBroker broker, DocumentSet docs, boolean checkPermissions) {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            Collection child;\n            XmldbURI childName;\n            Iterator i = subcollections.iterator();\n            while (i.hasNext() ) {\n                childName = (XmldbURI) i.next();\n                child = broker.getCollection(path.append(childName));\n                if(child == null) {\n                    LOG.warn(\"child collection \" + childName + \" not found. Skipping ...\");\n                    // we always check if we have permissions to read the child collection\n                } else if (child.permissions.validate(broker.getUser(), Permission.READ)) {\n                    child.getDocuments(broker, docs, checkPermissions);\n                    if (child.getChildCollectionCount() > 0)\n                        child.allDocs(broker, docs, checkPermissions);\n                }\n            }\n        } catch (LockException e) {\n            LOG.warn(e.getMessage(), e);\n        } finally {\n            getLock().release();\n        }\n        return docs;\n    }","id":37293,"modified_method":"private DocumentSet allDocs(DBBroker broker, DocumentSet docs, boolean checkPermissions) {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            Collection child;\n            XmldbURI childName;\n            Iterator i = subcollections.iterator();\n            while (i.hasNext() ) {\n                childName = (XmldbURI) i.next();\n                child = broker.getCollection(path.appendInternal(childName));\n                if(child == null) {\n                    LOG.warn(\"child collection \" + path.appendInternal(childName) + \" not found. Skipping ...\");\n                    // we always check if we have permissions to read the child collection\n                } else if (child.permissions.validate(broker.getUser(), Permission.READ)) {\n                    child.getDocuments(broker, docs, checkPermissions);\n                    if (child.getChildCollectionCount() > 0)\n                        child.allDocs(broker, docs, checkPermissions);\n                }\n            }\n        } catch (LockException e) {\n            LOG.warn(e.getMessage(), e);\n        } finally {\n            getLock().release();\n        }\n        return docs;\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"private IndexInfo validateXMLResourceInternal(Txn transaction, DBBroker broker, XmldbURI docUri, ValidateBlock doValidate)\n    throws EXistException, PermissionDeniedException, TriggerException, SAXException, LockException {\n        \n        checkConfiguration(transaction, broker, docUri);\n\n        if (broker.isReadOnly()) throw new PermissionDeniedException(\"Database is read-only\");\n        DocumentImpl document, oldDoc = null;\n        boolean oldDocLocked = false;\n        try {\n            getLock().acquire(Lock.WRITE_LOCK);\n            oldDoc = (DocumentImpl) documents.get(docUri);\n            document = new DocumentImpl(broker, this, docUri);\n            \n            if (oldDoc == null) {\n                CollectionConfiguration config = getConfiguration(broker);\n                if (config != null) {\n                    document.setPermissions(config.getDefResPermissions());\n                }\n            } else\n                document.setPermissions(oldDoc.getPermissions().getPermissions());\n            \n            checkPermissions(transaction, broker, oldDoc);\n            manageDocumentInformation(broker, oldDoc, document );\n            \n            Indexer indexer = new Indexer(broker, transaction);\n            IndexInfo info = new IndexInfo(indexer);\n            indexer.setDocument(document);\n            addObserversToIndexer(broker, indexer);\n            indexer.setValidating(true);\n            \n            // if !triggersEnabled, setupTriggers will return null anyway, so no need to check\n            info.setTrigger(\n                    setupTriggers(broker, docUri, oldDoc != null),\n                    oldDoc == null ? Trigger.STORE_DOCUMENT_EVENT : Trigger.UPDATE_DOCUMENT_EVENT);\n            \n             info.prepareTrigger(broker, transaction, getURI().append(docUri), oldDoc);\n            \n            LOG.debug(\"Scanning document \" + getURI().append(docUri));\n            doValidate.run(info);\n            \n            document.setMaxDepth(document.getMaxDepth() + 1);\n            document.calculateTreeLevelStartPoints();\n            // new document is valid: remove old document\n            if (oldDoc != null) {\n                LOG.debug(\"removing old document \" + oldDoc.getFileURI());\n                oldDoc.getUpdateLock().acquire(Lock.WRITE_LOCK);\n                oldDocLocked = true;\n                if (oldDoc.getResourceType() == DocumentImpl.BINARY_FILE)\n                    broker.removeBinaryResource(transaction, (BinaryDocument) oldDoc);\n                else\n                    broker.removeXMLResource(transaction, oldDoc, false);\n                oldDoc.copyOf(document);\n                indexer.setDocumentObject(oldDoc);\n                oldDocLocked = false;\t\t// old has become new at this point\n                document = oldDoc;\n            } else {\n                document.getUpdateLock().acquire(Lock.WRITE_LOCK);\n                document.setDocId(broker.getNextResourceId(transaction, this));\n                addDocument(transaction, broker, document);\n            }\n            \n            indexer.setValidating(false);\n            info.postValidateTrigger();\n            return info;\n        } finally {\n            if (oldDocLocked) oldDoc.getUpdateLock().release(Lock.WRITE_LOCK);\n            getLock().release();\n        }\n    }","id":37294,"modified_method":"private IndexInfo validateXMLResourceInternal(Txn transaction, DBBroker broker, XmldbURI docUri, ValidateBlock doValidate)\n    throws EXistException, PermissionDeniedException, TriggerException, SAXException, LockException {\n        \n        checkConfiguration(transaction, broker, docUri);\n\n        if (broker.isReadOnly()) throw new PermissionDeniedException(\"Database is read-only\");\n        DocumentImpl document, oldDoc = null;\n        boolean oldDocLocked = false;\n        try {\n            getLock().acquire(Lock.WRITE_LOCK);\n            oldDoc = (DocumentImpl) documents.get(docUri.getRawCollectionPath());\n            document = new DocumentImpl(broker, this, docUri);\n            \n            if (oldDoc == null) {\n                CollectionConfiguration config = getConfiguration(broker);\n                if (config != null) {\n                    document.setPermissions(config.getDefResPermissions());\n                }\n            } else\n                document.setPermissions(oldDoc.getPermissions().getPermissions());\n            \n            checkPermissions(transaction, broker, oldDoc);\n            manageDocumentInformation(broker, oldDoc, document );\n            \n            Indexer indexer = new Indexer(broker, transaction);\n            IndexInfo info = new IndexInfo(indexer);\n            indexer.setDocument(document);\n            addObserversToIndexer(broker, indexer);\n            indexer.setValidating(true);\n            \n            // if !triggersEnabled, setupTriggers will return null anyway, so no need to check\n            info.setTrigger(\n                    setupTriggers(broker, docUri, oldDoc != null),\n                    oldDoc == null ? Trigger.STORE_DOCUMENT_EVENT : Trigger.UPDATE_DOCUMENT_EVENT);\n            \n             info.prepareTrigger(broker, transaction, getURI().append(docUri), oldDoc);\n            \n            LOG.debug(\"Scanning document \" + getURI().append(docUri));\n            doValidate.run(info);\n            \n            document.setMaxDepth(document.getMaxDepth() + 1);\n            document.calculateTreeLevelStartPoints();\n            // new document is valid: remove old document\n            if (oldDoc != null) {\n                LOG.debug(\"removing old document \" + oldDoc.getFileURI());\n                oldDoc.getUpdateLock().acquire(Lock.WRITE_LOCK);\n                oldDocLocked = true;\n                if (oldDoc.getResourceType() == DocumentImpl.BINARY_FILE)\n                    broker.removeBinaryResource(transaction, (BinaryDocument) oldDoc);\n                else\n                    broker.removeXMLResource(transaction, oldDoc, false);\n                oldDoc.copyOf(document);\n                indexer.setDocumentObject(oldDoc);\n                oldDocLocked = false;\t\t// old has become new at this point\n                document = oldDoc;\n            } else {\n                document.getUpdateLock().acquire(Lock.WRITE_LOCK);\n                document.setDocId(broker.getNextResourceId(transaction, this));\n                addDocument(transaction, broker, document);\n            }\n            \n            indexer.setValidating(false);\n            info.postValidateTrigger();\n            return info;\n        } finally {\n            if (oldDocLocked) oldDoc.getUpdateLock().release(Lock.WRITE_LOCK);\n            getLock().release();\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     *  Check if the collection has a child document.\n     *\n     *@param  name  the name (without path) of the document\n     *@return\n     */\n    public boolean hasDocument(XmldbURI uri) {\n        return documents.containsKey(uri);\n    }","id":37295,"modified_method":"/**\n     *  Check if the collection has a child document.\n     *\n     *@param  name  the name (without path) of the document\n     *@return\n     */\n    public boolean hasDocument(XmldbURI uri) {\n        return documents.containsKey(uri.getRawCollectionPath());\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"public void removeBinaryResource(Txn transaction, DBBroker broker, DocumentImpl doc)\n    throws PermissionDeniedException, LockException, TriggerException {\n        \n        if (doc == null)\n            return;\n        \n        try {\n            getLock().acquire(Lock.WRITE_LOCK);\n            if (doc.getResourceType() != DocumentImpl.BINARY_FILE)\n                throw new PermissionDeniedException(\"document \" + doc.getFileURI()\n                + \" is not a binary object\");\n            if(doc.isLockedForWrite())\n                throw new PermissionDeniedException(\"Document \" + doc.getFileURI() +\n                        \" is locked for write\");\n            if (!getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\n                        \"write access to collection denied; user=\" + broker.getUser().getName());\n            if (!doc.getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\"permission to remove document denied\");\n            \n            DocumentTrigger trigger = null;\n            if (triggersEnabled) {\n                CollectionConfiguration config = getConfiguration(broker);\n                if (config != null) {\n                    trigger = (DocumentTrigger) config.getTrigger(Trigger.REMOVE_DOCUMENT_EVENT);\n                }\n            }\n            \n            if (trigger != null)\n                trigger.prepare(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, doc.getURI(), doc);\n            \n            broker.removeBinaryResource(transaction, (BinaryDocument) doc);\n            documents.remove(doc.getFileURI());\n            \n            if (trigger != null) {\n                trigger.finish(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, null);\n            }\n        } finally {\n            getLock().release();\n        }\n    }","id":37296,"modified_method":"public void removeBinaryResource(Txn transaction, DBBroker broker, DocumentImpl doc)\n    throws PermissionDeniedException, LockException, TriggerException {\n        \n        if (doc == null)\n            return;\n        \n        try {\n            getLock().acquire(Lock.WRITE_LOCK);\n            if (doc.getResourceType() != DocumentImpl.BINARY_FILE)\n                throw new PermissionDeniedException(\"document \" + doc.getFileURI()\n                + \" is not a binary object\");\n            if(doc.isLockedForWrite())\n                throw new PermissionDeniedException(\"Document \" + doc.getFileURI() +\n                        \" is locked for write\");\n            if (!getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\n                        \"write access to collection denied; user=\" + broker.getUser().getName());\n            if (!doc.getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\"permission to remove document denied\");\n            \n            DocumentTrigger trigger = null;\n            if (triggersEnabled) {\n                CollectionConfiguration config = getConfiguration(broker);\n                if (config != null) {\n                    trigger = (DocumentTrigger) config.getTrigger(Trigger.REMOVE_DOCUMENT_EVENT);\n                }\n            }\n            \n            if (trigger != null)\n                trigger.prepare(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, doc.getURI(), doc);\n            \n            broker.removeBinaryResource(transaction, (BinaryDocument) doc);\n            documents.remove(doc.getFileURI().getRawCollectionPath());\n            \n            if (trigger != null) {\n                trigger.finish(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, null);\n            }\n        } finally {\n            getLock().release();\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     * Removes the document from the internal list of resources, but\n     * doesn't delete the document object itself.\n     *\n     * @param doc\n     */\n    public void unlinkDocument(DocumentImpl doc) {\n        documents.remove(doc.getFileURI());\n    }","id":37297,"modified_method":"/**\n     * Removes the document from the internal list of resources, but\n     * doesn't delete the document object itself.\n     *\n     * @param doc\n     */\n    public void unlinkDocument(DocumentImpl doc) {\n        documents.remove(doc.getFileURI().getRawCollectionPath());\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     *  Remove the specified document from the collection.\n     *\n     *@param  name\n     */\n    public void removeXMLResource(Txn transaction, DBBroker broker, XmldbURI docUri)\n    throws PermissionDeniedException, TriggerException, LockException {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            \n            DocumentImpl doc = getDocument(broker, docUri);\n            if (doc == null)\n                return;\n            if(doc.isLockedForWrite())\n                throw new PermissionDeniedException(\"Document \" + doc.getFileURI() +\n                        \" is locked for write\");\n            if (!getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\n                        \"Write access to collection denied; user=\" + broker.getUser().getName());\n            if (!doc.getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\"Permission to remove document denied\");\n            \n            DocumentTrigger trigger = null;\n            if (!CollectionConfiguration.DEFAULT_COLLECTION_CONFIG_FILE_URI.equals(docUri)) {\n                if (triggersEnabled) {\n                    CollectionConfiguration config = getConfiguration(broker);\n                    if (config != null)\n                        trigger = (DocumentTrigger) config.getTrigger(Trigger.REMOVE_DOCUMENT_EVENT);\n                }\n            } else {\n                // we remove a collection.xconf configuration file: tell the configuration manager to\n                // reload the configuration.\n                CollectionConfigurationManager confMgr = broker.getBrokerPool().getConfigurationManager();\n                confMgr.invalidateAll(getURI());\n            }\n            \n            if (trigger != null) {\n                trigger.prepare(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction,\n                        getURI().append(docUri), doc);\n            }\n            \n            broker.removeXMLResource(transaction, doc);\n            documents.remove(docUri);\n            \n            if (trigger != null) {\n                trigger.finish(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, doc);\n            }\n            \n            broker.getBrokerPool().getNotificationService().notifyUpdate(doc, UpdateListener.REMOVE);\n            \n        } finally {\n            getLock().release();\n        }\n    }","id":37298,"modified_method":"/**\n     *  Remove the specified document from the collection.\n     *\n     *@param  name\n     */\n    public void removeXMLResource(Txn transaction, DBBroker broker, XmldbURI docUri)\n    throws PermissionDeniedException, TriggerException, LockException {\n        try {\n            getLock().acquire(Lock.READ_LOCK);\n            \n            DocumentImpl doc = getDocument(broker, docUri);\n            if (doc == null)\n                return;\n            if(doc.isLockedForWrite())\n                throw new PermissionDeniedException(\"Document \" + doc.getFileURI() +\n                        \" is locked for write\");\n            if (!getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\n                        \"Write access to collection denied; user=\" + broker.getUser().getName());\n            if (!doc.getPermissions().validate(broker.getUser(), Permission.WRITE))\n                throw new PermissionDeniedException(\"Permission to remove document denied\");\n            \n            DocumentTrigger trigger = null;\n            if (!CollectionConfiguration.DEFAULT_COLLECTION_CONFIG_FILE_URI.equals(docUri)) {\n                if (triggersEnabled) {\n                    CollectionConfiguration config = getConfiguration(broker);\n                    if (config != null)\n                        trigger = (DocumentTrigger) config.getTrigger(Trigger.REMOVE_DOCUMENT_EVENT);\n                }\n            } else {\n                // we remove a collection.xconf configuration file: tell the configuration manager to\n                // reload the configuration.\n                CollectionConfigurationManager confMgr = broker.getBrokerPool().getConfigurationManager();\n                confMgr.invalidateAll(getURI());\n            }\n            \n            if (trigger != null) {\n                trigger.prepare(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction,\n                        getURI().append(docUri), doc);\n            }\n            \n            broker.removeXMLResource(transaction, doc);\n            documents.remove(docUri.getRawCollectionPath());\n            \n            if (trigger != null) {\n                trigger.finish(Trigger.REMOVE_DOCUMENT_EVENT, broker, transaction, doc);\n            }\n            \n            broker.getBrokerPool().getNotificationService().notifyUpdate(doc, UpdateListener.REMOVE);\n            \n        } finally {\n            getLock().release();\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n     *  Add a document to the collection.\n     *\n     *@param  doc\n     */\n    public void addDocument(Txn transaction, DBBroker broker, DocumentImpl doc) {\n        if (doc.getDocId() == DocumentImpl.UNKNOWN_DOCUMENT_ID)\n            doc.setDocId(broker.getNextResourceId(transaction, this));\n        documents.put(doc.getFileURI(), doc);\n    }","id":37299,"modified_method":"/**\n     *  Add a document to the collection.\n     *\n     *@param  doc\n     */\n    public void addDocument(Txn transaction, DBBroker broker, DocumentImpl doc) {\n        if (doc.getDocId() == DocumentImpl.UNKNOWN_DOCUMENT_ID)\n            doc.setDocId(broker.getNextResourceId(transaction, this));\n        documents.put(doc.getFileURI().getRawCollectionPath(), doc);\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"public Collection get(XmldbURI name) {\n\t\tlong key = names.get(name.toString());\n\t\tif (key < 0)\n\t\t\treturn null;\n\t\treturn (Collection) get(key);\n\t}","id":37300,"modified_method":"public Collection get(XmldbURI name) {\n\t\tlong key = names.get(name.getRawCollectionPath());\n\t\tif (key < 0)\n\t\t\treturn null;\n\t\treturn (Collection) get(key);\n\t}","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"public void add(Collection collection, int initialRefCount) {\n\t\tsuper.add(collection, initialRefCount);\n\t\tnames.put(collection.getURI().toString(), collection.getKey());\n\t}","id":37301,"modified_method":"public void add(Collection collection, int initialRefCount) {\n\t\tsuper.add(collection, initialRefCount);\n\t\tnames.put(collection.getURI().getRawCollectionPath(), collection.getKey());\n\t}","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"public void remove(Cacheable item) {\n    \tfinal Collection col = (Collection) item;\n        super.remove(item);\n        names.remove(col.getURI().toString());\n        if(pool.getConfigurationManager() != null) // might be null during db initialization\n           pool.getConfigurationManager().invalidate(col.getURI());\n    }","id":37302,"modified_method":"public void remove(Cacheable item) {\n    \tfinal Collection col = (Collection) item;\n        super.remove(item);\n        names.remove(col.getURI().getRawCollectionPath());\n        if(pool.getConfigurationManager() != null) // might be null during db initialization\n           pool.getConfigurationManager().invalidate(col.getURI());\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n\t * Overwritten to lock collections before they are removed.\n\t */\n\tprotected Cacheable removeOne(Cacheable item) {\n\t\tCollection old;\n\t\tLock lock;\n\t\tdouble rd = 0, minRd = -1;\n\t\tint bucket = -1;\t\t\n\t\tfor (int i = 0; i < items.length; i++) {\n\t\t\told = (Collection)items[i];\n\t\t\tif (old == null) {\n\t\t\t\tbucket = i;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tlock = old.getLock(); \n\t\t\t\t\t// calculate the reference density\n\t\t\t\t\trd =\n\t\t\t\t\t\told.getReferenceCount()\n\t\t\t\t\t\t\t/ (double)(totalReferences - old.getTimestamp());\n\t\t\t\t\t// attempt to acquire a read lock on the collection.\n\t\t\t\t\t// the collection is not considered for removal if the lock \n\t\t\t\t\t// cannot be acquired immediately.\n\t\t\t\t\tif(lock.attempt(Lock.READ_LOCK)) {\n\t\t\t\t\t\tif ((minRd < 0 || rd < minRd) && old.allowUnload()) {\n\t\t\t\t\t\t\tminRd = rd;\n\t\t\t\t\t\t\tbucket = i;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlock.release();\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\told = (Collection)items[bucket];\n\t\tif (old != null) {\n\t\t\tpool.getConfigurationManager().invalidate(old.getURI());\n\t\t\tmap.remove(old.getKey());\n\t\t\tnames.remove(old.getURI().toString());\n\t\t\told.sync(true);\n\t\t}\n\t\titems[bucket] = item;\n\t\tmap.put(item.getKey(), item);\n        \n        accounting.replacedPage(item);\n        if (cacheManager != null && accounting.resizeNeeded()) {\n            cacheManager.requestMem(this);\n        }\n\t\treturn old;\n\t}","id":37303,"modified_method":"/**\n\t * Overwritten to lock collections before they are removed.\n\t */\n\tprotected Cacheable removeOne(Cacheable item) {\n\t\tCollection old;\n\t\tLock lock;\n\t\tdouble rd = 0, minRd = -1;\n\t\tint bucket = -1;\t\t\n\t\tfor (int i = 0; i < items.length; i++) {\n\t\t\told = (Collection)items[i];\n\t\t\tif (old == null) {\n\t\t\t\tbucket = i;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tlock = old.getLock(); \n\t\t\t\t\t// calculate the reference density\n\t\t\t\t\trd =\n\t\t\t\t\t\told.getReferenceCount()\n\t\t\t\t\t\t\t/ (double)(totalReferences - old.getTimestamp());\n\t\t\t\t\t// attempt to acquire a read lock on the collection.\n\t\t\t\t\t// the collection is not considered for removal if the lock \n\t\t\t\t\t// cannot be acquired immediately.\n\t\t\t\t\tif(lock.attempt(Lock.READ_LOCK)) {\n\t\t\t\t\t\tif ((minRd < 0 || rd < minRd) && old.allowUnload()) {\n\t\t\t\t\t\t\tminRd = rd;\n\t\t\t\t\t\t\tbucket = i;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlock.release();\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\told = (Collection)items[bucket];\n\t\tif (old != null) {\n\t\t\tpool.getConfigurationManager().invalidate(old.getURI());\n\t\t\tmap.remove(old.getKey());\n\t\t\tnames.remove(old.getURI().getRawCollectionPath());\n\t\t\told.sync(true);\n\t\t}\n\t\titems[bucket] = item;\n\t\tmap.put(item.getKey(), item);\n        \n        accounting.replacedPage(item);\n        if (cacheManager != null && accounting.resizeNeeded()) {\n            cacheManager.requestMem(this);\n        }\n\t\treturn old;\n\t}","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"public void resize(int newSize) {\n        if (newSize < size) {\n            shrink(newSize);\n            names = new Object2LongHashMap(newSize);\n        } else {\n            LOG.debug(\"Growing cache from \" + size + \" to \" + newSize);\n            Cacheable[] newItems = new Cacheable[newSize];\n            Long2ObjectHashMap newMap = new Long2ObjectHashMap(newSize);\n            Object2LongHashMap newNames = new Object2LongHashMap(newSize);\n            for (int i = 0; i < count; i++) {\n                newItems[i] = items[i];\n                newMap.put(items[i].getKey(), items[i]);\n                newNames.put(((Collection) items[i]).getURI().toString(), items[i].getKey());\n            }\n            this.size = newSize;\n            this.map = newMap;\n            this.names = newNames;\n            accounting.reset();\n            accounting.setTotalSize(size);\n        }\n    }","id":37304,"modified_method":"public void resize(int newSize) {\n        if (newSize < size) {\n            shrink(newSize);\n            names = new Object2LongHashMap(newSize);\n        } else {\n            LOG.debug(\"Growing cache from \" + size + \" to \" + newSize);\n            Cacheable[] newItems = new Cacheable[newSize];\n            Long2ObjectHashMap newMap = new Long2ObjectHashMap(newSize);\n            Object2LongHashMap newNames = new Object2LongHashMap(newSize);\n            for (int i = 0; i < count; i++) {\n                newItems[i] = items[i];\n                newMap.put(items[i].getKey(), items[i]);\n                newNames.put(((Collection) items[i]).getURI().getRawCollectionPath(), items[i].getKey());\n            }\n            this.size = newSize;\n            this.map = newMap;\n            this.names = newNames;\n            accounting.reset();\n            accounting.setTotalSize(size);\n        }\n    }","commit_id":"051836399c650d7ecc4bdd1140cf782862f4f2c1","url":"https://github.com/eXist-db/exist"},{"original_method":"/**\n   * A Factory method for {@link Monitor}.\n   * Can be overridden by user.\n   * @param index a start index for monitor target\n   * @param args args passed from user\n   * @return a Monitor instance\n   */\n  public Monitor newMonitor(final Connection connection, int index, String[] args) {\n    Monitor monitor = null;\n    String[] monitorTargets = null;\n\n    if(index >= 0) {\n      int length = args.length - index;\n      monitorTargets = new String[length];\n      System.arraycopy(args, index, monitorTargets, 0, length);\n    }\n\n    if(this.regionServerMode) {\n      monitor = new RegionServerMonitor(\n          connection,\n          monitorTargets,\n          this.useRegExp,\n          (ExtendedSink)this.sink);\n    } else {\n      monitor = new RegionMonitor(connection, monitorTargets, this.useRegExp, this.sink);\n    }\n    return monitor;\n  }","id":37305,"modified_method":"/**\n   * A Factory method for {@link Monitor}.\n   * Can be overridden by user.\n   * @param index a start index for monitor target\n   * @param args args passed from user\n   * @return a Monitor instance\n   */\n  public Monitor newMonitor(final Connection connection, int index, String[] args) {\n    Monitor monitor = null;\n    String[] monitorTargets = null;\n\n    if(index >= 0) {\n      int length = args.length - index;\n      monitorTargets = new String[length];\n      System.arraycopy(args, index, monitorTargets, 0, length);\n    }\n\n    if (this.regionServerMode) {\n      monitor =\n          new RegionServerMonitor(connection, monitorTargets, this.useRegExp,\n              (ExtendedSink) this.sink, this.executor);\n    } else {\n      monitor =\n          new RegionMonitor(connection, monitorTargets, this.useRegExp, this.sink, this.executor);\n    }\n    return monitor;\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"public Canary() {\n    this(new RegionServerStdOutSink());\n  }","id":37306,"modified_method":"public Canary() {\n    this(new ScheduledThreadPoolExecutor(1), new RegionServerStdOutSink());\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"protected Monitor(Connection connection, String[] monitorTargets,\n        boolean useRegExp, Sink sink) {\n      if (null == connection) throw new IllegalArgumentException(\"connection shall not be null\");\n\n      this.connection = connection;\n      this.targets = monitorTargets;\n      this.useRegExp = useRegExp;\n      this.sink = sink;\n    }","id":37307,"modified_method":"protected Monitor(Connection connection, String[] monitorTargets, boolean useRegExp, Sink sink,\n        ExecutorService executor) {\n      if (null == connection) throw new IllegalArgumentException(\"connection shall not be null\");\n\n      this.connection = connection;\n      this.targets = monitorTargets;\n      this.useRegExp = useRegExp;\n      this.sink = sink;\n      this.executor = executor;\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"private void monitorRegionServers(Map<String, List<HRegionInfo>> rsAndRMap) {\n      String serverName = null;\n      TableName tableName = null;\n      HRegionInfo region = null;\n      Table table = null;\n      Get get = null;\n      byte[] startKey = null;\n      Scan scan = null;\n      StopWatch stopWatch = new StopWatch();\n      // monitor one region on every region server\n      for (Map.Entry<String, List<HRegionInfo>> entry : rsAndRMap.entrySet()) {\n        stopWatch.reset();\n        serverName = entry.getKey();\n        // always get the first region\n        region = entry.getValue().get(0);\n        try {\n          tableName = region.getTable();\n          table = admin.getConnection().getTable(tableName);\n          startKey = region.getStartKey();\n          // Can't do a get on empty start row so do a Scan of first element if any instead.\n          if(startKey.length > 0) {\n            get = new Get(startKey);\n            stopWatch.start();\n            table.get(get);\n            stopWatch.stop();\n          } else {\n            scan = new Scan();\n            scan.setCaching(1);\n            scan.setMaxResultSize(1L);\n            stopWatch.start();\n            ResultScanner s = table.getScanner(scan);\n            s.close();\n            stopWatch.stop();\n          }\n          this.getSink().publishReadTiming(tableName.getNameAsString(),\n              serverName, stopWatch.getTime());\n        } catch (TableNotFoundException tnfe) {\n          // This is ignored because it doesn't imply that the regionserver is dead\n        } catch (TableNotEnabledException tnee) {\n          // This is considered a success since we got a response.\n          LOG.debug(\"The targeted table was disabled.  Assuming success.\");\n        } catch (DoNotRetryIOException dnrioe) {\n            this.getSink().publishReadFailure(tableName.getNameAsString(), serverName);\n            LOG.error(dnrioe);\n        } catch (IOException e) {\n          this.getSink().publishReadFailure(tableName.getNameAsString(), serverName);\n          LOG.error(e);\n          this.errorCode = ERROR_EXIT_CODE;\n        } finally {\n          if (table != null) {\n            try {\n              table.close();\n            } catch (IOException e) {/* DO NOTHING */\n            }\n          }\n          scan = null;\n          get = null;\n          startKey = null;\n        }\n      }\n    }","id":37308,"modified_method":"private void monitorRegionServers(Map<String, List<HRegionInfo>> rsAndRMap) {\n      List<RegionServerTask> tasks = new ArrayList<RegionServerTask>();\n      Random rand =new Random();\n      // monitor one region on every region server\n      for (Map.Entry<String, List<HRegionInfo>> entry : rsAndRMap.entrySet()) {\n        String serverName = entry.getKey();\n        // random select a region\n        HRegionInfo region = entry.getValue().get(rand.nextInt(entry.getValue().size()));\n        tasks.add(new RegionServerTask(this.connection, serverName, region, getSink()));\n      }\n      try {\n        for (Future<Void> future : this.executor.invokeAll(tasks)) {\n          try {\n            future.get();\n          } catch (ExecutionException e) {\n            LOG.error(\"Sniff regionserver failed!\", e);\n            this.errorCode = ERROR_EXIT_CODE;\n          }\n        }\n      } catch (InterruptedException e) {\n        this.errorCode = ERROR_EXIT_CODE;\n        LOG.error(\"Sniff regionserver failed!\", e);\n      }\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"public RegionServerMonitor(Connection connection, String[] monitorTargets,\n        boolean useRegExp, ExtendedSink sink) {\n      super(connection, monitorTargets, useRegExp, sink);\n    }","id":37309,"modified_method":"public RegionServerMonitor(Connection connection, String[] monitorTargets, boolean useRegExp,\n        ExtendedSink sink, ExecutorService executor) {\n      super(connection, monitorTargets, useRegExp, sink, executor);\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"public RegionMonitor(Connection connection, String[] monitorTargets,\n        boolean useRegExp, Sink sink) {\n      super(connection, monitorTargets, useRegExp, sink);\n    }","id":37310,"modified_method":"public RegionMonitor(Connection connection, String[] monitorTargets, boolean useRegExp,\n        Sink sink, ExecutorService executor) {\n      super(connection, monitorTargets, useRegExp, sink, executor);\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"private void sniff() throws Exception {\n      for (HTableDescriptor table : admin.listTables()) {\n        Canary.sniff(admin, sink, table);\n      }\n    }","id":37311,"modified_method":"private List<Future<Void>> sniff() throws Exception {\n      List<Future<Void>> taskFutures = new LinkedList<Future<Void>>();\n      for (HTableDescriptor table : admin.listTables()) {\n        if (admin.isTableEnabled(table.getTableName())) {\n          taskFutures.addAll(Canary.sniff(admin, sink, table, executor));\n        }\n      }\n      return taskFutures;\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"public static void main(String[] args) throws Exception {\n    final Configuration conf = HBaseConfiguration.create();\n    final ChoreService choreService = new ChoreService(\"CANARY_TOOL\");\n    final ScheduledChore authChore = AuthUtil.getAuthChore(conf);\n    if (authChore != null) {\n      choreService.scheduleChore(authChore);\n    }\n\n    int exitCode = ToolRunner.run(conf, new Canary(), args);\n\n    choreService.shutdown();\n    System.exit(exitCode);\n  }","id":37312,"modified_method":"public static void main(String[] args) throws Exception {\n    final Configuration conf = HBaseConfiguration.create();\n    final ChoreService choreService = new ChoreService(\"CANARY_TOOL\");\n    final ScheduledChore authChore = AuthUtil.getAuthChore(conf);\n    if (authChore != null) {\n      choreService.scheduleChore(authChore);\n    }\n    int numThreads = conf.getInt(\"hbase.canary.threads.num\", MAX_THREADS_NUM);\n    ExecutorService executor = new ScheduledThreadPoolExecutor(numThreads);\n\n    Class<? extends Sink> sinkClass =\n        conf.getClass(\"hbase.canary.sink.class\", StdOutSink.class, Sink.class);\n    Sink sink = ReflectionUtils.newInstance(sinkClass);\n\n    int exitCode = ToolRunner.run(conf, new Canary(executor, sink), args);\n    choreService.shutdown();\n    executor.shutdown();\n    System.exit(exitCode);\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"private static void sniff(final Admin admin, final Sink sink, HTableDescriptor tableDesc)\n      throws Exception {\n    Table table = null;\n\n    try {\n      table = admin.getConnection().getTable(tableDesc.getTableName());\n    } catch (TableNotFoundException e) {\n      return;\n    }\n\n    try {\n      for (HRegionInfo region : admin.getTableRegions(tableDesc.getTableName())) {\n        try {\n          sniffRegion(admin, sink, region, table);\n        } catch (Exception e) {\n          sink.publishReadFailure(region, e);\n          LOG.debug(\"sniffRegion failed\", e);\n        }\n      }\n    } finally {\n      table.close();\n    }\n  }","id":37313,"modified_method":"private static List<Future<Void>> sniff(final Admin admin, final Sink sink,\n      HTableDescriptor tableDesc, ExecutorService executor) throws Exception {\n    Table table = null;\n    try {\n      table = admin.getConnection().getTable(tableDesc.getTableName());\n    } catch (TableNotFoundException e) {\n      return new ArrayList<Future<Void>>();\n    }\n    List<RegionTask> tasks = new ArrayList<RegionTask>();\n    try {\n      for (HRegionInfo region : admin.getTableRegions(tableDesc.getTableName())) {\n        tasks.add(new RegionTask(admin.getConnection(), region, sink));\n      }\n    } finally {\n      table.close();\n    }\n    return executor.invokeAll(tasks);\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Canary entry point for specified table.\n   * @throws Exception\n   */\n  public static void sniff(final Admin admin, TableName tableName) throws Exception {\n    sniff(admin, new StdOutSink(), tableName.getNameAsString());\n  }","id":37314,"modified_method":"/**\n   * Canary entry point for specified table.\n   * @throws Exception\n   */\n  public static void sniff(final Admin admin, TableName tableName) throws Exception {\n    List<Future<Void>> taskFutures =\n        Canary.sniff(admin, new StdOutSink(), tableName.getNameAsString(),\n          new ScheduledThreadPoolExecutor(1));\n    for (Future<Void> future : taskFutures) {\n      future.get();\n    }\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Canary entry point for specified table.\n   * @throws Exception\n   */\n  private static void sniff(final Admin admin, final Sink sink, String tableName)\n      throws Exception {\n    if (admin.isTableAvailable(TableName.valueOf(tableName))) {\n      sniff(admin, sink, admin.getTableDescriptor(TableName.valueOf(tableName)));\n    } else {\n      LOG.warn(String.format(\"Table %s is not available\", tableName));\n    }\n  }","id":37315,"modified_method":"/**\n   * Canary entry point for specified table.\n   * @throws Exception\n   */\n  private static List<Future<Void>> sniff(final Admin admin, final Sink sink, String tableName,\n      ExecutorService executor) throws Exception {\n    if (admin.isTableEnabled(TableName.valueOf(tableName))) {\n      return Canary.sniff(admin, sink, admin.getTableDescriptor(TableName.valueOf(tableName)),\n        executor);\n    } else {\n      LOG.warn(String.format(\"Table %s is not enabled\", tableName));\n    }\n    return new LinkedList<Future<Void>>();\n  }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n    public void run() {\n      if(this.initAdmin()) {\n        try {\n          if (this.targets != null && this.targets.length > 0) {\n            String[] tables = generateMonitorTables(this.targets);\n            this.initialized = true;\n            for (String table : tables) {\n              Canary.sniff(admin, sink, table);\n            }\n          } else {\n            sniff();\n          }\n        } catch (Exception e) {\n          LOG.error(\"Run regionMonitor failed\", e);\n          this.errorCode = ERROR_EXIT_CODE;\n        }\n      }\n      this.done = true;\n    }","id":37316,"modified_method":"@Override\n    public void run() {\n      if (this.initAdmin()) {\n        try {\n          List<Future<Void>> taskFutures = new LinkedList<Future<Void>>();\n          if (this.targets != null && this.targets.length > 0) {\n            String[] tables = generateMonitorTables(this.targets);\n            this.initialized = true;\n            for (String table : tables) {\n              taskFutures.addAll(Canary.sniff(admin, sink, table, executor));\n            }\n          } else {\n            taskFutures.addAll(sniff());\n          }\n          for (Future<Void> future : taskFutures) {\n            try {\n              future.get();\n            } catch (ExecutionException e) {\n              LOG.error(\"Sniff region failed!\", e);\n            }\n          }\n        } catch (Exception e) {\n          LOG.error(\"Run regionMonitor failed\", e);\n          this.errorCode = ERROR_EXIT_CODE;\n        }\n      }\n      this.done = true;\n    }","commit_id":"cf7ef936d20b98482a48926a194772c66d3234c1","url":"https://github.com/apache/hbase"},{"original_method":"/**\n\t * @see wicket.resource.StringResourceLoaderTestBase#testLoaderUnknownResources()\n\t */\n\tpublic void testLoaderUnknownResources()\n\t{\n\t\tApplication app = new Application()\n\t\t{\n\t\t\tpublic String getName()\n\t\t\t{\n\t\t\t\treturn \"MissingResourceApp\";\n\t\t\t}\n\n\t\t\tpublic ApplicationSettings getSettings()\n\t\t\t{\n\t\t\t\treturn settings;\n\t\t\t}\n            \n            public ApplicationPages getPages()\n            {\n                return pages;\n            }\n\n            private ApplicationPages pages = new ApplicationPages();\n\t\t\tprivate ApplicationSettings settings = new ApplicationSettings(this);\n\t\t};\n\n\t\tIStringResourceLoader loader = new ApplicationStringResourceLoader(app);\n\t\tAssert.assertNull(\"Unknown resource should return null\", loader.loadStringResource(component,\n\t\t\t\t\"test.string\", Locale.getDefault(), null));\n\t}","id":37317,"modified_method":"/**\n\t * @see wicket.resource.StringResourceLoaderTestBase#testLoaderUnknownResources()\n\t */\n\tpublic void testLoaderUnknownResources()\n\t{\n\t\tApplication app = new Application()\n\t\t{\n\t\t\tpublic String getName()\n\t\t\t{\n\t\t\t\treturn \"MissingResourceApp\";\n\t\t\t}\n\n\t\t\tpublic ApplicationSettings getSettings()\n\t\t\t{\n\t\t\t\treturn settings;\n\t\t\t}\n            \n            public ApplicationPages getPages()\n            {\n                return pages;\n            }\n            \n\t\t\tpublic ISessionFactory getSessionFactory()\n\t\t\t{\n\t\t\t\treturn null;\n\t\t\t}\n\n            private ApplicationPages pages = new ApplicationPages();\n\t\t\tprivate ApplicationSettings settings = new ApplicationSettings(this);\n\t\t};\n\n\t\tIStringResourceLoader loader = new ApplicationStringResourceLoader(app);\n\t\tAssert.assertNull(\"Unknown resource should return null\", loader.loadStringResource(component,\n\t\t\t\t\"test.string\", Locale.getDefault(), null));\n\t}","commit_id":"a5c37121e4fd76813874f7602b2b1b3469dfbd26","url":"https://github.com/apache/wicket"},{"original_method":"/**\n     * Gets session from request, creating a new one if it doesn't already exist\n     * \n     * @param application\n     *            The application object\n     * @param request\n     *            The http request object\n     * @return The session object\n     */\n    static HttpSession getSession(final Application application, final HttpServletRequest request)\n    {\n        // Get session, creating if it doesn't exist\n        final javax.servlet.http.HttpSession httpServletSession = request.getSession(true);\n\n        // The request session object is unique per web application, but wicket requires it\n        // to be unique per servlet. That is, there must be a 1..n relationship between\n        // HTTP sessions (JSESSIONID) and Wicket applications.\n        final String sessionAttributeName = \"session\" + request.getServletPath();\n        \n        // Get Session abstraction from httpSession attribute\n        HttpSession session = (HttpSession)httpServletSession.getAttribute(sessionAttributeName);\n\n        if (session == null)\n        {\n            // Create session\n            session = new HttpSession(application, httpServletSession);\n\n            // Set the client Locale for this session\n            session.setLocale(request.getLocale());\n\n            // Attach to httpSession\n            httpServletSession.setAttribute(sessionAttributeName, session);\n        }\n        else\n        {\n            // Reattach http servlet session\n            session.httpServletSession = httpServletSession;\n        }\n\n        // Set the current session to the session we just retrieved\n        Session.set(session);\n\n        return session;\n    }","id":37318,"modified_method":"/**\n     * Gets session from request, creating a new one if it doesn't already exist\n     * \n     * @param application\n     *            The application object\n     * @param request\n     *            The http request object\n     * @return The session object\n     */\n    static HttpSession getSession(final Application application, final HttpServletRequest request)\n    {\n        // Get session, creating if it doesn't exist\n        final javax.servlet.http.HttpSession httpServletSession = request.getSession(true);\n\n        // The request session object is unique per web application, but wicket requires it\n        // to be unique per servlet. That is, there must be a 1..n relationship between\n        // HTTP sessions (JSESSIONID) and Wicket applications.\n        final String sessionAttributeName = \"session\" + request.getServletPath();\n        \n        // Get Session abstraction from httpSession attribute\n        HttpSession httpSession = (HttpSession)httpServletSession.getAttribute(sessionAttributeName);\n\n        if (httpSession == null)\n        {\n            // Create session using session factory\n            final Session session = application.getSessionFactory().newSession();\n            if (session instanceof HttpSession)\n            {\n                httpSession = (HttpSession)session;            \t\n            }\n            else\n            {\n                throw new WicketRuntimeException(\"Session created by a WebApplication session factory must be a subclass of HttpSession\");\n            }\n            \n            // Save servlet session in there\n            httpSession.httpServletSession = httpServletSession;\n\n            // Set the client Locale for this session\n            httpSession.setLocale(request.getLocale());\n\n            // Attach to httpSession\n            httpServletSession.setAttribute(sessionAttributeName, httpSession);\n        }\n        else\n        {\n            // Reattach http servlet session\n            httpSession.httpServletSession = httpServletSession;\n        }\n\n        // Set the current session to the session we just retrieved\n        Session.set(httpSession);\n\n        return httpSession;\n    }","commit_id":"a5c37121e4fd76813874f7602b2b1b3469dfbd26","url":"https://github.com/apache/wicket"},{"original_method":"/**\n     * Constructor\n     * \n     * @param application\n     *            The application\n     * @param httpServletSession\n     *            The underlying servlet session\n     */\n    protected HttpSession(final Application application,\n            final javax.servlet.http.HttpSession httpServletSession)\n    {\n        super(application);\n        this.httpServletSession = httpServletSession;\n    }","id":37319,"modified_method":"/**\n     * Constructor\n     * \n     * @param application\n     *            The application\n     */\n    protected HttpSession(final Application application)\n    {\n        super(application);\n    }","commit_id":"a5c37121e4fd76813874f7602b2b1b3469dfbd26","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * Converts the given value to class c.\n\t * \n\t * @param value\n\t *            The value to convert\n\t * @param c\n\t *            The class to convert to\n\t * @return The converted value\n\t * \n\t * @see wicket.util.convert.IConverter#convert(java.lang.Object,\n\t *      java.lang.Class)\n\t */\n\tpublic Object convert(Object value, Class c)\n\t{\n\t\t// Null is always converted to null\n\t\tif (value == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\t// Class cannot be null\n\t\tif (c == null)\n\t\t{\n\t\t\tthrow new IllegalArgumentException(\"Class cannot be null\");\n\t\t}\n\n\t\t// Catch all cases where value is already the right type\n\t\tif (c.isAssignableFrom(value.getClass()))\n\t\t{\n\t\t\treturn value;\n\t\t}\n\n\t\t// Get type converter for class\n\t\tITypeConverter converter = get(c);\n\t\tif (converter == null)\n\t\t{\n\t\t\tif (defaultConverter instanceof ILocalizable)\n\t\t\t{\n\t\t\t\t((ILocalizable)defaultConverter).setLocale(locale);\n\t\t\t}\n\t\t\treturn defaultConverter.convert(value, c);\n\t\t}\n\n\t\t// Set locale\n\t\tif (converter instanceof ILocalizable)\n\t\t{\n\t\t\t((ILocalizable)converter).setLocale(locale);\n\t\t}\n\n\t\ttry\n\t\t{\n\t\t\t// Use type converter to convert to value\n\t\t\treturn converter.convert(value);\n\t\t}\n\t\tcatch (ConversionException e)\n\t\t{\n\t\t\tthrow e.setConverter(this).setTypeConverter(converter).setLocale(locale).setTargetType(\n\t\t\t\t\tc).setSourceValue(value);\n\t\t}\n\t\tcatch (Exception e)\n\t\t{\n\t\t\tthrow new ConversionException(e).setConverter(this).setLocale(locale).setTargetType(c)\n\t\t\t\t\t.setSourceValue(value);\n\t\t}\n\t}","id":37320,"modified_method":"/**\n\t * Converts the given value to class c.\n\t * \n\t * @param value\n\t *            The value to convert\n\t * @param c\n\t *            The class to convert to\n\t * @return The converted value\n\t * \n\t * @see wicket.util.convert.IConverter#convert(java.lang.Object,\n\t *      java.lang.Class)\n\t */\n\tpublic Object convert(Object value, Class c)\n\t{\n\t\t// Null is always converted to null\n\t\tif (value == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\t// Class cannot be null\n\t\tif (c == null)\n\t\t{\n\t\t\tthrow new IllegalArgumentException(\"Class cannot be null\");\n\t\t}\n\n\t\t// Catch all cases where value is already the right type\n\t\tif (c.isAssignableFrom(value.getClass()))\n\t\t{\n\t\t\treturn value;\n\t\t}\n\n\t\t// Get type converter for class\n\t\tITypeConverter converter = get(c);\n\t\tif (converter == null)\n\t\t{\n\t\t\tdefaultConverter.setLocale(locale);\n\t\t\treturn defaultConverter.convert(value, c);\n\t\t}\n\n\t\t// Set locale\n\t\tconverter.setLocale(locale);\n\n\t\ttry\n\t\t{\n\t\t\t// Use type converter to convert to value\n\t\t\treturn converter.convert(value);\n\t\t}\n\t\tcatch (ConversionException e)\n\t\t{\n\t\t\tthrow e.setConverter(this).setTypeConverter(converter).setLocale(locale).setTargetType(\n\t\t\t\t\tc).setSourceValue(value);\n\t\t}\n\t\tcatch (Exception e)\n\t\t{\n\t\t\tthrow new ConversionException(e).setConverter(this).setLocale(locale).setTargetType(c)\n\t\t\t\t\t.setSourceValue(value);\n\t\t}\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n     * @see wicket.util.convert.IConverterFactory#newConverter()\n     */\n    public IConverter newConverter()\n    {\n        Converter converter = new Converter();\n        converter.set(Boolean.TYPE, new BooleanConverter());\n        converter.set(Boolean.class, new BooleanConverter());\n        converter.set(Byte.TYPE, new ByteConverter());\n        converter.set(Byte.class, new ByteConverter());\n        converter.set(Character.TYPE, new CharacterConverter());\n        converter.set(Character.class, new CharacterConverter());\n        converter.set(Double.TYPE, new DoubleConverter());\n        converter.set(Double.class, new DoubleConverter());\n        converter.set(Float.TYPE, new FloatConverter());\n        converter.set(Float.class, new FloatConverter());\n        converter.set(Integer.TYPE, new IntegerConverter());\n        converter.set(Integer.class, new IntegerConverter());\n        converter.set(Long.TYPE, new LongConverter());\n        converter.set(Long.class, new LongConverter());\n        converter.set(Short.TYPE, new ShortConverter());\n        converter.set(Short.class, new ShortConverter());\n        converter.set(String.class, new StringConverter());\n        return converter;\n    }","id":37321,"modified_method":"/**\n\t * @see wicket.util.convert.IConverterFactory#newConverter()\n\t */\n\tpublic IConverter newConverter()\n\t{\n\t\tConverter converter = new Converter();\n\t\tconverter.set(Boolean.TYPE, new BooleanConverter());\n\t\tconverter.set(Boolean.class, new BooleanConverter());\n\t\tconverter.set(Byte.TYPE, new ByteConverter());\n\t\tconverter.set(Byte.class, new ByteConverter());\n\t\tconverter.set(Character.TYPE, new CharacterConverter());\n\t\tconverter.set(Character.class, new CharacterConverter());\n\t\tconverter.set(Double.TYPE, new DoubleConverter());\n\t\tconverter.set(Double.class, new DoubleConverter());\n\t\tconverter.set(Float.TYPE, new FloatConverter());\n\t\tconverter.set(Float.class, new FloatConverter());\n\t\tconverter.set(Integer.TYPE, new IntegerConverter());\n\t\tconverter.set(Integer.class, new IntegerConverter());\n\t\tconverter.set(Long.TYPE, new LongConverter());\n\t\tconverter.set(Long.class, new LongConverter());\n\t\tconverter.set(Short.TYPE, new ShortConverter());\n\t\tconverter.set(Short.class, new ShortConverter());\n\t\tconverter.set(String.class, new StringConverter());\n        converter.set(Date.class, new DateConverter());\n\t\treturn converter;\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * Gets the converter instance.\n\t * \n\t * @return the converter\n\t */\n\tpublic final IConverter getConverter()\n\t{\n\t\tif (converter == null)\n\t\t{\n\t\t\t// Get the converter factory, possibly overriden by the client\n\t\t\tIConverterFactory converterFactory = getApplication().getConverterFactory();\n\n\t\t\t// Let the factory create a new converter\n\t\t\tconverter = converterFactory.newConverter();\n\t\t\tif (converter instanceof ILocalizable)\n\t\t\t{\n\t\t\t\t((ILocalizable)converter).setLocale(locale);\n\t\t\t}\n\t\t}\n\t\treturn converter;\n\t}","id":37322,"modified_method":"/**\n\t * Gets the converter instance.\n\t * \n\t * @return the converter\n\t */\n\tpublic final IConverter getConverter()\n\t{\n\t\tif (converter == null)\n\t\t{\n\t\t\t// Get the converter factory, possibly overriden by the client\n\t\t\tIConverterFactory converterFactory = getApplication().getConverterFactory();\n\n\t\t\t// Let the factory create a new converter\n\t\t\tconverter = converterFactory.newConverter();\n\t\t\tconverter.setLocale(locale);\n\t\t}\n\t\treturn converter;\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * Set the locale.\n\t * \n\t * @param locale\n\t *            New locale\n\t */\n\tpublic final void setLocale(final Locale locale)\n\t{\n\t\tthis.locale = locale;\n\t\t// set the new locale on the converter instance\n\t\tif (converter instanceof ILocalizable)\n\t\t{\n\t\t\t((ILocalizable)getConverter()).setLocale(locale);\n\t\t}\n\t}","id":37323,"modified_method":"/**\n\t * Set the locale.\n\t * \n\t * @param locale\n\t *            New locale\n\t */\n\tpublic final void setLocale(final Locale locale)\n\t{\n\t\tthis.locale = locale;\n\n        // Set the new locale on the converter instance\n\t\tgetConverter().setLocale(locale);\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * @see wicket.util.convert.ITypeConverter#convert(java.lang.Object)\n\t */\n\tpublic Object convert(final Object value)\n\t{\n\t\t// Null is always converted to null\n\t\tif (value == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\t// Catch all cases where value is already the right type\n\t\tif (value instanceof String)\n\t\t{\n\t\t\treturn value;\n\t\t}\n\n\t\t// Get string converter for value's class\n\t\tfinal Class c = value.getClass();\n\t\tITypeConverter converter = get(c);\n\t\tif (converter == null)\n\t\t{\n\t\t\tif (defaultConverter instanceof ILocalizable)\n\t\t\t{\n\t\t\t\t((ILocalizable)defaultConverter).setLocale(getLocale());\n\t\t\t}\n\t\t\treturn defaultConverter.convert(value);\n\t\t}\n\n\t\t// Set locale\n\t\tif (converter instanceof ILocalizable)\n\t\t{\n\t\t\t((ILocalizable)converter).setLocale(getLocale());\n\t\t}\n\n\t\ttry\n\t\t{\n\t\t\t// Use type converter to convert to value\n\t\t\treturn converter.convert(value);\n\t\t}\n\t\tcatch (ConversionException e)\n\t\t{\n\t\t\tthrow e.setTypeConverter(this).setLocale(getLocale()).setTargetType(c).setSourceValue(\n\t\t\t\t\tvalue);\n\t\t}\n\t\tcatch (Exception e)\n\t\t{\n\t\t\tthrow new ConversionException(e).setTypeConverter(this).setLocale(getLocale())\n\t\t\t\t\t.setTargetType(c).setSourceValue(value);\n\t\t}\n\t}","id":37324,"modified_method":"/**\n\t * @see wicket.util.convert.ITypeConverter#convert(java.lang.Object)\n\t */\n\tpublic Object convert(final Object value)\n\t{\n\t\t// Null is always converted to null\n\t\tif (value == null)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\t// Catch all cases where value is already the right type\n\t\tif (value instanceof String)\n\t\t{\n\t\t\treturn value;\n\t\t}\n\n\t\t// Get string converter for value's class\n\t\tfinal Class c = value.getClass();\n\t\tITypeConverter converter = get(c);\n\t\tif (converter == null)\n\t\t{\n\t\t\tdefaultConverter.setLocale(getLocale());\n\t\t\treturn defaultConverter.convert(value);\n\t\t}\n\n\t\t// Set locale\n\t\tconverter.setLocale(getLocale());\n\n\t\ttry\n\t\t{\n\t\t\t// Use type converter to convert to value\n\t\t\treturn converter.convert(value);\n\t\t}\n\t\tcatch (ConversionException e)\n\t\t{\n\t\t\tthrow e.setTypeConverter(this).setLocale(getLocale()).setTargetType(c).setSourceValue(\n\t\t\t\t\tvalue);\n\t\t}\n\t\tcatch (Exception e)\n\t\t{\n\t\t\tthrow new ConversionException(e).setTypeConverter(this).setLocale(getLocale())\n\t\t\t\t\t.setTargetType(c).setSourceValue(value);\n\t\t}\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t * Validates input by trying it to convert to the given type using the\n\t * {@link wicket.util.convert.IConverter}instance of the component doing\n\t * the validation.\n\t * \n\t * @param component\n\t *            The component that wants to validate its input\n\t * @see wicket.markup.html.form.validation.IValidator#validate(wicket.markup.html.form.FormComponent)\n\t */\n\tpublic final void validate(FormComponent component)\n\t{\n\t\t// Get component value\n\t\tfinal String value = component.getRequestString();\n\n\t\t// If value is non-empty\n\t\tif (!Strings.isEmpty(value))\n\t\t{\n\t\t\t// Check value by attempting to convert it using the given locale\n\t\t\tfinal IConverter converter = component.getConverter();\n\t\t\t((ILocalizable)converter).setLocale(getLocale());\n\t\t\ttry\n\t\t\t{\n\t\t\t\tconverter.convert(value, type);\n\t\t\t}\n\t\t\tcatch (ConversionException e)\n\t\t\t{\n\t\t\t\tconversionError(value, component, e);\n\t\t\t}\n\t\t}\n\t}","id":37325,"modified_method":"/**\n\t * Validates input by trying it to convert to the given type using the\n\t * {@link wicket.util.convert.IConverter}instance of the component doing\n\t * the validation.\n\t * \n\t * @param component\n\t *            The component that wants to validate its input\n\t * @see wicket.markup.html.form.validation.IValidator#validate(wicket.markup.html.form.FormComponent)\n\t */\n\tpublic final void validate(FormComponent component)\n\t{\n\t\t// Get component value\n\t\tfinal String value = component.getRequestString();\n\n\t\t// If value is non-empty\n\t\tif (!Strings.isEmpty(value))\n\t\t{\n\t\t\t// Check value by attempting to convert it using the given locale\n\t\t\tfinal IConverter converter = component.getConverter();\n\t\t\tconverter.setLocale(getLocale());\n\t\t\ttry\n\t\t\t{\n\t\t\t\tconverter.convert(value, type);\n\t\t\t}\n\t\t\tcatch (ConversionException e)\n\t\t\t{\n\t\t\t\tconversionError(value, component, e);\n\t\t\t}\n\t\t}\n\t}","commit_id":"5d879863363cf5efd79bb40e79f1ac3a5c51a32a","url":"https://github.com/apache/wicket"},{"original_method":"@Test\n  public void testTwoPaths() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    final VirtualFile vf2 = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf2, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath()));\n    // this makes not merged for f2 path\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", new File(myBranchVcsRoot, \"folder/folder1\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder/folder1\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3*\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37326,"modified_method":"@Test\n  public void testTwoPaths() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    final VirtualFile vf2 = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf2, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath());\n    // this makes not merged for f2 path\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", new File(myBranchVcsRoot, \"folder/folder1\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder/folder1\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3*\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMixedWorkingRevisions() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    // ! no update!\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n\n    final SVNInfo f1info = wcClient.doInfo(new File(myBranchVcsRoot, \"folder/f1.txt\"), SVNRevision.WORKING);\n    assert f1info.getRevision().getNumber() == 2;\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    // and after update\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    mergeChecker.clear();\n    result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","id":37327,"modified_method":"@Test\n  public void testMixedWorkingRevisions() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    // ! no update!\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n\n    final SVNInfo f1info = wcClient.doInfo(new File(myBranchVcsRoot, \"folder/f1.txt\"), SVNRevision.UNDEFINED);\n    assert f1info.getRevision().getNumber() == 2;\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    // and after update\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    mergeChecker.clear();\n    result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testOnlyImmediateInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    // rev4\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\\n4\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3,4\", myBranchVcsRoot.getAbsolutePath()));\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && (\"/trunk:3-4\".equals(data.getValue().getString()) ||\n                                                      \"/trunk:3,4\".equals(data.getValue().getString()));\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList4 = changeListList.get(0);\n    assert changeList4.getNumber() == 4;\n    final SvnChangeList changeList3 = changeListList.get(1);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n    result = mergeChecker.checkList(changeList4, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult1 = myOneShotMergeInfoHelper.checkList(changeList4);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult1);\n  }","id":37328,"modified_method":"@Test\n  public void testOnlyImmediateInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    // rev4\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\\n4\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3,4\", myBranchVcsRoot.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && (\"/trunk:3-4\".equals(data.getValue().getString()) ||\n                                                      \"/trunk:3,4\".equals(data.getValue().getString()));\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList4 = changeListList.get(0);\n    assert changeList4.getNumber() == 4;\n    final SvnChangeList changeList3 = changeListList.get(1);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n    result = mergeChecker.checkList(changeList4, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult1 = myOneShotMergeInfoHelper.checkList(changeList4);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult1);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testNonInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3*\".equals(data.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37329,"modified_method":"@Test\n  public void testNonInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3*\".equals(data.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSimpleNotMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    \n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, myRepoUrl, myRepoUrl + \"/branch\", myRepoUrl + \"/trunk\", myRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37330,"modified_method":"@Test\n  public void testSimpleNotMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    \n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, myRepoUrl, myRepoUrl + \"/branch\", myRepoUrl + \"/trunk\", myRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testEmptyMergeinfoBlocks() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    // rev5: put blocking empty mergeinfo\n    //verify(runSvn(\"merge\", \"-c\", \"-3\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath(), \"--record-only\"));\n    verify(runSvn(\"merge\", \"-r\", \"3:2\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);  // todo\n  }","id":37331,"modified_method":"@Test\n  public void testEmptyMergeinfoBlocks() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    // rev5: put blocking empty mergeinfo\n    //runInAndVerify(\"merge\", \"-c\", \"-3\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath(), \"--record-only\"));\n    runInAndVerifyIgnoreOutput(\"merge\", \"-r\", \"3:2\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);  // todo\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testWhenInfoInRepo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File fullBranch = new File(myTempDirFixture.getTempDirPath(), \"fullBranch\");\n    fullBranch.mkdir();\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    // this will be taken as branch wc root\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", fullBranch.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch/folder/folder1\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3 : f2 changed\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch using full branch WC\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", fullBranch.getAbsolutePath(), \"--record-only\"));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", fullBranch.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    \n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","id":37332,"modified_method":"@Test\n  public void testWhenInfoInRepo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File fullBranch = new File(myTempDirFixture.getTempDirPath(), \"fullBranch\");\n    fullBranch.mkdir();\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    // this will be taken as branch wc root\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", fullBranch.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch/folder/folder1\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3 : f2 changed\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch using full branch WC\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", fullBranch.getAbsolutePath(), \"--record-only\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", fullBranch.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    \n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSimpleMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath(), \"--record-only\"));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString()); \n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n  }","id":37333,"modified_method":"@Test\n  public void testSimpleMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath(), \"--record-only\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString()); \n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testWhenInfoInRepo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File fullBranch = new File(myTempDirFixture.getTempDirPath(), \"fullBranch\");\n    fullBranch.mkdir();\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    // this will be taken as branch wc root\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", fullBranch.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch/folder/folder1\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3 : f2 changed\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch using full branch WC\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", fullBranch.getAbsolutePath(), \"--record-only\"));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", fullBranch.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    \n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","id":37334,"modified_method":"@Test\n  public void testWhenInfoInRepo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File fullBranch = new File(myTempDirFixture.getTempDirPath(), \"fullBranch\");\n    fullBranch.mkdir();\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    // this will be taken as branch wc root\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", fullBranch.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch/folder/folder1\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3 : f2 changed\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch using full branch WC\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", fullBranch.getAbsolutePath(), \"--record-only\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", fullBranch.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    \n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testEmptyMergeinfoBlocks() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    // rev5: put blocking empty mergeinfo\n    //verify(runSvn(\"merge\", \"-c\", \"-3\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath(), \"--record-only\"));\n    verify(runSvn(\"merge\", \"-r\", \"3:2\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);  // todo\n  }","id":37335,"modified_method":"@Test\n  public void testEmptyMergeinfoBlocks() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    // rev5: put blocking empty mergeinfo\n    //runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"-3\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath(), \"--record-only\"));\n    runInAndVerifyIgnoreOutput(\"merge\", \"-r\", \"3:2\", myRepoUrl + \"/trunk/folder\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);  // todo\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testTwoPaths() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    final VirtualFile vf2 = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf2, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath()));\n    // this makes not merged for f2 path\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", new File(myBranchVcsRoot, \"folder/folder1\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder/folder1\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3*\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37336,"modified_method":"@Test\n  public void testTwoPaths() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    final File folder1 = new File(folder, \"folder1\");\n    folder1.mkdir();\n    final File f2 = new File(folder1, \"f2.txt\");\n    f2.createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    final VirtualFile vf2 = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f2);\n    editFileInCommand(myProject, vf2, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath());\n    // this makes not merged for f2 path\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", new File(myBranchVcsRoot, \"folder/folder1\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder/folder1\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3*\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList3 = changeListList.get(0);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSimpleNotMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    \n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, myRepoUrl, myRepoUrl + \"/branch\", myRepoUrl + \"/trunk\", myRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37337,"modified_method":"@Test\n  public void testSimpleNotMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    \n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, myRepoUrl, myRepoUrl + \"/branch\", myRepoUrl + \"/trunk\", myRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testOnlyImmediateInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    // rev4\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\\n4\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3,4\", myBranchVcsRoot.getAbsolutePath()));\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && (\"/trunk:3-4\".equals(data.getValue().getString()) ||\n                                                      \"/trunk:3,4\".equals(data.getValue().getString()));\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList4 = changeListList.get(0);\n    assert changeList4.getNumber() == 4;\n    final SvnChangeList changeList3 = changeListList.get(1);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n    result = mergeChecker.checkList(changeList4, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult1 = myOneShotMergeInfoHelper.checkList(changeList4);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult1);\n  }","id":37338,"modified_method":"@Test\n  public void testOnlyImmediateInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    // rev4\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\\n4\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3,4\", myBranchVcsRoot.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", new File(myBranchVcsRoot, \"folder\").getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && (\"/trunk:3-4\".equals(data.getValue().getString()) ||\n                                                      \"/trunk:3,4\".equals(data.getValue().getString()));\n    final SVNPropertyData dataFolder = wcClient.doGetProperty(new File(myBranchVcsRoot, \"folder\"), \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert dataFolder != null && dataFolder.getValue() != null && \"/trunk:3\".equals(dataFolder.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList4 = changeListList.get(0);\n    assert changeList4.getNumber() == 4;\n    final SvnChangeList changeList3 = changeListList.get(1);\n    assert changeList3.getNumber() == 3;\n\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList3, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n    result = mergeChecker.checkList(changeList4, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList3);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult1 = myOneShotMergeInfoHelper.checkList(changeList4);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult1);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testMixedWorkingRevisions() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    // ! no update!\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n\n    final SVNInfo f1info = wcClient.doInfo(new File(myBranchVcsRoot, \"folder/f1.txt\"), SVNRevision.UNDEFINED);\n    assert f1info.getRevision().getNumber() == 2;\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    // and after update\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n\n    mergeChecker.clear();\n    result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","id":37339,"modified_method":"@Test\n  public void testMixedWorkingRevisions() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    // ! no update!\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString());\n\n    final SVNInfo f1info = wcClient.doInfo(new File(myBranchVcsRoot, \"folder/f1.txt\"), SVNRevision.UNDEFINED);\n    assert f1info.getRevision().getNumber() == 2;\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    // and after update\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n\n    mergeChecker.clear();\n    result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSimpleMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record as merged into branch\n    verify(runSvn(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath(), \"--record-only\"));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString()); \n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n  }","id":37340,"modified_method":"@Test\n  public void testSimpleMerged() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record as merged into branch\n    runInAndVerifyIgnoreOutput(\"merge\", \"-c\", \"3\", myRepoUrl + \"/trunk\", myBranchVcsRoot.getAbsolutePath(), \"--record-only\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3\".equals(data.getValue().getString()); \n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testNonInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    FileUtil.delete(trunk);\n    verify(runSvn(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath()));\n    verify(runSvn(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath()));\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath()));\n\n    // rev 4: record non inheritable merge\n    verify(runSvn(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", myBranchVcsRoot.getAbsolutePath()));\n    Thread.sleep(100);\n    verify(runSvn(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath()));\n\n    Thread.sleep(100);\n    verify(runSvn(\"up\", myBranchVcsRoot.getAbsolutePath()));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3*\".equals(data.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","id":37341,"modified_method":"@Test\n  public void testNonInheritableMergeinfo() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    final File f1 = new File(folder, \"f1.txt\");\n    f1.createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    FileUtil.delete(trunk);\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/trunk\", trunk.getAbsolutePath());\n    runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/branch\", myBranchVcsRoot.getAbsolutePath());\n\n    // rev 3\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(f1);\n    editFileInCommand(myProject, vf, \"123\\n456\\n123\");\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", trunk.getAbsolutePath());\n\n    // rev 4: record non inheritable merge\n    runInAndVerifyIgnoreOutput(\"propset\", \"svn:mergeinfo\", \"/trunk:3*\", myBranchVcsRoot.getAbsolutePath());\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", myBranchVcsRoot.getAbsolutePath());\n\n    Thread.sleep(100);\n    runInAndVerifyIgnoreOutput(\"up\", myBranchVcsRoot.getAbsolutePath());\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final SVNWCClient wcClient = vcs.createWCClient();\n    final SVNPropertyData data = wcClient.doGetProperty(myBranchVcsRoot, \"svn:mergeinfo\", SVNRevision.UNDEFINED, SVNRevision.WORKING);\n    assert data != null && data.getValue() != null && \"/trunk:3*\".equals(data.getValue().getString());\n\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/trunk\"), 0);\n\n    final SvnChangeList changeList = changeListList.get(0);\n    final String encodedRepoUrl = SVNURL.parseURIDecoded(myRepoUrl).toString();\n    final BranchInfo mergeChecker =\n      new BranchInfo(vcs, encodedRepoUrl, encodedRepoUrl + \"/branch\", encodedRepoUrl + \"/trunk\", encodedRepoUrl + \"/trunk\", vcs.createWCClient());\n    final SvnMergeInfoCache.MergeCheckResult result = mergeChecker.checkList(changeList, myBranchVcsRoot.getAbsolutePath());\n    assert SvnMergeInfoCache.MergeCheckResult.NOT_MERGED.equals(result);\n\n    myOneShotMergeInfoHelper.prepare();\n    final SvnMergeInfoCache.MergeCheckResult oneShotResult = myOneShotMergeInfoHelper.checkList(changeList);\n    Assert.assertEquals(SvnMergeInfoCache.MergeCheckResult.NOT_MERGED, oneShotResult);\n  }","commit_id":"1030d0db7456916ae9eabdd1df6ea7b6f2ed534b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalRootSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    myVcs.invokeRefreshSvnRoots();\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);\n    SvnFileUrlMapping workingCopies = myVcs.getSvnFileUrlMapping();\n    List<RootUrlInfo> infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(myRepoUrl + \"/trunk\", infos.get(0).getAbsoluteUrl());\n\n    verify(runSvn(\"switch\", branchUrl, myWorkingCopyDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    sleep(300);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);  //first run queries one more update\n\n    workingCopies = myVcs.getSvnFileUrlMapping();\n    infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(branchUrl, infos.get(0).getAbsoluteUrl());\n  }","id":37342,"modified_method":"@Test\n  public void testExternalRootSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    myVcs.invokeRefreshSvnRoots();\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);\n    SvnFileUrlMapping workingCopies = myVcs.getSvnFileUrlMapping();\n    List<RootUrlInfo> infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(myRepoUrl + \"/trunk\", infos.get(0).getAbsoluteUrl());\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl, myWorkingCopyDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    sleep(300);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);  //first run queries one more update\n\n    workingCopies = myVcs.getSvnFileUrlMapping();\n    infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(branchUrl, infos.get(0).getAbsoluteUrl());\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    verify(runSvn(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath()));\n    verify(runSvn(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myS1File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.myS2File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.mySourceDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetFiles.get(1)));\n  }","id":37343,"modified_method":"@Test\n  public void testExternalSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath());\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myS1File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.myS2File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.mySourceDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetFiles.get(1)));\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalCommitInExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    final File file = new File(externalDir, \"t11.txt\");\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(file);\n\n    final File mainFile = new File(myWorkingCopyDir.getPath(), \"source/s1.txt\");\n    final VirtualFile vfMain = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(mainFile);\n\n    renameFileInCommand(vf, \"tt11.txt\");\n    renameFileInCommand(vfMain, \"ss11.txt\");\n\n    myVcsDirtyScopeManager.markEverythingDirty();\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(2, clManager.getChangesIn(myWorkingCopyDir).size());\n\n    try {\n      Thread.sleep(100);\n    } catch (InterruptedException e) {\n      //\n    }\n\n    verify(runSvn(\"ci\", \"-m\", \"test\", sourceDir.getPath()));\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(0, clManager.getChangesIn(myWorkingCopyDir).size());\n  }","id":37344,"modified_method":"@Test\n  public void testExternalCommitInExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    final File file = new File(externalDir, \"t11.txt\");\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(file);\n\n    final File mainFile = new File(myWorkingCopyDir.getPath(), \"source/s1.txt\");\n    final VirtualFile vfMain = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(mainFile);\n\n    renameFileInCommand(vf, \"tt11.txt\");\n    renameFileInCommand(vfMain, \"ss11.txt\");\n\n    myVcsDirtyScopeManager.markEverythingDirty();\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(2, clManager.getChangesIn(myWorkingCopyDir).size());\n\n    try {\n      Thread.sleep(100);\n    } catch (InterruptedException e) {\n      //\n    }\n\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", sourceDir.getPath());\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(0, clManager.getChangesIn(myWorkingCopyDir).size());\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    verify(runSvn(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath()));\n    verify(runSvn(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myS1File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.myS2File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.mySourceDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetFiles.get(1)));\n  }","id":37345,"modified_method":"@Test\n  public void testExternalSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath());\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myS1File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.myS2File));\n    Assert.assertEquals(FileStatus.NOT_CHANGED, clManager.getStatus(tree.mySourceDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetDir));\n    Assert.assertEquals(FileStatus.SWITCHED, clManager.getStatus(tree.myTargetFiles.get(1)));\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalCommitInExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    final File file = new File(externalDir, \"t11.txt\");\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(file);\n\n    final File mainFile = new File(myWorkingCopyDir.getPath(), \"source/s1.txt\");\n    final VirtualFile vfMain = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(mainFile);\n\n    renameFileInCommand(vf, \"tt11.txt\");\n    renameFileInCommand(vfMain, \"ss11.txt\");\n\n    myVcsDirtyScopeManager.markEverythingDirty();\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(2, clManager.getChangesIn(myWorkingCopyDir).size());\n\n    try {\n      Thread.sleep(100);\n    } catch (InterruptedException e) {\n      //\n    }\n\n    verify(runSvn(\"ci\", \"-m\", \"test\", sourceDir.getPath()));\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(0, clManager.getChangesIn(myWorkingCopyDir).size());\n  }","id":37346,"modified_method":"@Test\n  public void testExternalCommitInExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    final File file = new File(externalDir, \"t11.txt\");\n    final VirtualFile vf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(file);\n\n    final File mainFile = new File(myWorkingCopyDir.getPath(), \"source/s1.txt\");\n    final VirtualFile vfMain = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(mainFile);\n\n    renameFileInCommand(vf, \"tt11.txt\");\n    renameFileInCommand(vfMain, \"ss11.txt\");\n\n    myVcsDirtyScopeManager.markEverythingDirty();\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(2, clManager.getChangesIn(myWorkingCopyDir).size());\n\n    try {\n      Thread.sleep(100);\n    } catch (InterruptedException e) {\n      //\n    }\n\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", sourceDir.getPath());\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    Assert.assertEquals(0, clManager.getChangesIn(myWorkingCopyDir).size());\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testExternalRootSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    myVcs.invokeRefreshSvnRoots();\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);\n    SvnFileUrlMapping workingCopies = myVcs.getSvnFileUrlMapping();\n    List<RootUrlInfo> infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(myRepoUrl + \"/trunk\", infos.get(0).getAbsoluteUrl());\n\n    verify(runSvn(\"switch\", branchUrl, myWorkingCopyDir.getPath()));\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    sleep(300);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);  //first run queries one more update\n\n    workingCopies = myVcs.getSvnFileUrlMapping();\n    infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(branchUrl, infos.get(0).getAbsoluteUrl());\n  }","id":37347,"modified_method":"@Test\n  public void testExternalRootSwitch() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    myVcs.invokeRefreshSvnRoots();\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);\n    SvnFileUrlMapping workingCopies = myVcs.getSvnFileUrlMapping();\n    List<RootUrlInfo> infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(myRepoUrl + \"/trunk\", infos.get(0).getAbsoluteUrl());\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl, myWorkingCopyDir.getPath());\n\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n    sleep(300);\n    // no dirty scope externally provided! just VFS refresh\n    clManager.ensureUpToDate(false);\n    clManager.ensureUpToDate(false);  //first run queries one more update\n\n    workingCopies = myVcs.getSvnFileUrlMapping();\n    infos = workingCopies.getAllWcInfos();\n    Assert.assertEquals(1, infos.size());\n    Assert.assertEquals(branchUrl, infos.get(0).getAbsoluteUrl());\n  }","commit_id":"724dbaa559b4436c4c4b2ba4d5fbc07ae0b6c559","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testAddListBySvn() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n\n    final String targetName = \"target\";\n    // not parralel, just test of correct detection\n    runSvn(\"changelist\", targetName, file.getPath());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n    checkFilesAreInList(new VirtualFile[] {file}, targetName, changeListManager);\n  }","id":37348,"modified_method":"@Test\n  public void testAddListBySvn() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n\n    final String targetName = \"target\";\n    // not parralel, just test of correct detection\n    runInAndVerifyIgnoreOutput(\"changelist\", targetName, file.getPath());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n    checkFilesAreInList(new VirtualFile[] {file}, targetName, changeListManager);\n  }","commit_id":"d77129b6fb197611336f8fb5844e69d6d11303a6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSwitchedFileAndFolder() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    verify(runSvn(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath()));\n    verify(runSvn(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath()));\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check);\n\n    changeListManager.ensureUpToDate(false);\n    check.run();\n\n    editFileInCommand(myProject, tree.myS1File, \"1234543534543 3543 \");\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check2 = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.MODIFIED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check2);\n\n    changeListManager.ensureUpToDate(false);\n    check2.run();\n  }","id":37349,"modified_method":"@Test\n  public void testSwitchedFileAndFolder() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath());\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath());\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    // do before refresh check\n    check.run();\n    myScheme.doTest(check);\n\n    changeListManager.ensureUpToDate(false);\n    check.run();\n\n    editFileInCommand(myProject, tree.myS1File, \"1234543534543 3543 \");\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check2 = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.MODIFIED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check2);\n\n    changeListManager.ensureUpToDate(false);\n    check2.run();\n  }","commit_id":"d77129b6fb197611336f8fb5844e69d6d11303a6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testSwitchedFileAndFolder() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    verify(runSvn(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath()));\n    verify(runSvn(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath()));\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check);\n\n    changeListManager.ensureUpToDate(false);\n    check.run();\n\n    editFileInCommand(myProject, tree.myS1File, \"1234543534543 3543 \");\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check2 = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.MODIFIED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check2);\n\n    changeListManager.ensureUpToDate(false);\n    check2.run();\n  }","id":37350,"modified_method":"@Test\n  public void testSwitchedFileAndFolder() throws Exception {\n    final String branchUrl = prepareBranchesStructure();\n\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/source/s1.txt\", tree.myS1File.getPath());\n    runInAndVerifyIgnoreOutput(\"switch\", branchUrl + \"/root/target\", tree.myTargetDir.getPath());\n\n    final ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check);\n\n    changeListManager.ensureUpToDate(false);\n    check.run();\n\n    editFileInCommand(myProject, tree.myS1File, \"1234543534543 3543 \");\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    changeListManager.ensureUpToDate(false);\n\n    final Runnable check2 = new Runnable() {\n      @Override\n      public void run() {\n        Assert.assertEquals(FileStatus.MODIFIED, changeListManager.getStatus(tree.myS1File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.myS2File));\n        Assert.assertEquals(FileStatus.NOT_CHANGED, changeListManager.getStatus(tree.mySourceDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetDir));\n        Assert.assertEquals(FileStatus.SWITCHED, changeListManager.getStatus(tree.myTargetFiles.get(1)));\n      }\n    };\n    myScheme.doTest(check2);\n\n    changeListManager.ensureUpToDate(false);\n    check2.run();\n  }","commit_id":"d77129b6fb197611336f8fb5844e69d6d11303a6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void prepareInnerCopy() throws Exception {\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    verify(runSvn(\"co\", myMainUrl));\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File innerDir = new File(sourceDir, \"inner1/inner2/inner\");\n    verify(runSvn(\"co\", myExternalURL, innerDir.getPath()));\n    sleep(100);\n    myWorkingCopyDir.refresh(false, true);\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","id":37351,"modified_method":"private void prepareInnerCopy() throws Exception {\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    runInAndVerifyIgnoreOutput(\"co\", myMainUrl);\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File innerDir = new File(sourceDir, \"inner1/inner2/inner\");\n    runInAndVerifyIgnoreOutput(\"co\", myExternalURL, innerDir.getPath());\n    sleep(100);\n    myWorkingCopyDir.refresh(false, true);\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","commit_id":"cae192c044e975e356b9093859a0f330d58c8e9d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void prepareInnerCopy() throws Exception {\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    verify(runSvn(\"co\", myMainUrl));\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File innerDir = new File(sourceDir, \"inner1/inner2/inner\");\n    verify(runSvn(\"co\", myExternalURL, innerDir.getPath()));\n    sleep(100);\n    myWorkingCopyDir.refresh(false, true);\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","id":37352,"modified_method":"private void prepareInnerCopy() throws Exception {\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    runInAndVerifyIgnoreOutput(\"co\", myMainUrl);\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File innerDir = new File(sourceDir, \"inner1/inner2/inner\");\n    runInAndVerifyIgnoreOutput(\"co\", myExternalURL, innerDir.getPath());\n    sleep(100);\n    myWorkingCopyDir.refresh(false, true);\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","commit_id":"cae192c044e975e356b9093859a0f330d58c8e9d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public AlienTree(final String base) throws IOException {\n      final String name = \"alien\";\n      myDir = new File(base, name);\n      myDir.mkdir();\n      sleep100();\n\n      myFile = new File(myDir, \"file.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      verify(runSvn(\"import\", \"-m\", \"test\", myDir.getAbsolutePath(), myRepoUrl + \"/\" + name));\n      FileUtil.delete(myDir);\n      verify(runSvn(\"co\", myRepoUrl + \"/\" + name, myDir.getAbsolutePath()));\n\n      myUnversioned = new File(myDir, \"unversioned.txt\");\n      myFile.createNewFile();\n      sleep100();\n      myIgnored = new File(myDir, \"ignored.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      // ignore\n      myClManager.setFilesToIgnore(IgnoredBeanFactory.withMask(\"ignored*\"));\n    }","id":37353,"modified_method":"public AlienTree(final String base) throws IOException {\n      final String name = \"alien\";\n      myDir = new File(base, name);\n      myDir.mkdir();\n      sleep100();\n\n      myFile = new File(myDir, \"file.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", myDir.getAbsolutePath(), myRepoUrl + \"/\" + name);\n      FileUtil.delete(myDir);\n      runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/\" + name, myDir.getAbsolutePath());\n\n      myUnversioned = new File(myDir, \"unversioned.txt\");\n      myFile.createNewFile();\n      sleep100();\n      myIgnored = new File(myDir, \"ignored.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      // ignore\n      myClManager.setFilesToIgnore(IgnoredBeanFactory.withMask(\"ignored*\"));\n    }","commit_id":"c5fef2b32e764e9e7264cdd2f56ff15d127c5bc9","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public AlienTree(final String base) throws IOException {\n      final String name = \"alien\";\n      myDir = new File(base, name);\n      myDir.mkdir();\n      sleep100();\n\n      myFile = new File(myDir, \"file.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      verify(runSvn(\"import\", \"-m\", \"test\", myDir.getAbsolutePath(), myRepoUrl + \"/\" + name));\n      FileUtil.delete(myDir);\n      verify(runSvn(\"co\", myRepoUrl + \"/\" + name, myDir.getAbsolutePath()));\n\n      myUnversioned = new File(myDir, \"unversioned.txt\");\n      myFile.createNewFile();\n      sleep100();\n      myIgnored = new File(myDir, \"ignored.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      // ignore\n      myClManager.setFilesToIgnore(IgnoredBeanFactory.withMask(\"ignored*\"));\n    }","id":37354,"modified_method":"public AlienTree(final String base) throws IOException {\n      final String name = \"alien\";\n      myDir = new File(base, name);\n      myDir.mkdir();\n      sleep100();\n\n      myFile = new File(myDir, \"file.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", myDir.getAbsolutePath(), myRepoUrl + \"/\" + name);\n      FileUtil.delete(myDir);\n      runInAndVerifyIgnoreOutput(\"co\", myRepoUrl + \"/\" + name, myDir.getAbsolutePath());\n\n      myUnversioned = new File(myDir, \"unversioned.txt\");\n      myFile.createNewFile();\n      sleep100();\n      myIgnored = new File(myDir, \"ignored.txt\");\n      myFile.createNewFile();\n      sleep100();\n\n      // ignore\n      myClManager.setFilesToIgnore(IgnoredBeanFactory.withMask(\"ignored*\"));\n    }","commit_id":"c5fef2b32e764e9e7264cdd2f56ff15d127c5bc9","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testDirAfterFile() throws Exception {\n    disableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"dir\");\n    final VirtualFile file = createFileInCommand(dir, \"a.txt\", \"content\");\n\n    verify(runSvn(\"status\"), \"? dir\");\n\n    final List<VirtualFile> files = new ArrayList<VirtualFile>();\n    files.add(file);\n    files.add(dir);\n    final List<VcsException> errors = SvnVcs.getInstance(myProject).getCheckinEnvironment().scheduleUnversionedFilesForAddition(files);\n    Assert.assertEquals(0, errors.size());\n  }","id":37355,"modified_method":"@Test\n  public void testDirAfterFile() throws Exception {\n    disableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"dir\");\n    final VirtualFile file = createFileInCommand(dir, \"a.txt\", \"content\");\n\n    runAndVerifyStatusSorted(\"? dir\");\n\n    final List<VirtualFile> files = new ArrayList<VirtualFile>();\n    files.add(file);\n    files.add(dir);\n    final List<VcsException> errors = SvnVcs.getInstance(myProject).getCheckinEnvironment().scheduleUnversionedFilesForAddition(files);\n    Assert.assertEquals(0, errors.size());\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      @Override\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","id":37356,"modified_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      @Override\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    runAndVerifyStatusSorted(\"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopy() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    copyFileInCommand(file, \"b.txt\");\n    verify(runSvn(\"status\"), \"A + b.txt\");\n  }","id":37357,"modified_method":"@Test\n  public void testCopy() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    copyFileInCommand(file, \"b.txt\");\n    runAndVerifyStatusSorted(\"A + b.txt\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testUndoAdd() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    undo();\n    verify(runSvn(\"status\"), \"D a.txt\");\n    Assert.assertFalse(new File(myWorkingCopyDir.getPath(), \"a.txt\").exists());\n  }","id":37358,"modified_method":"@Test\n  public void testUndoAdd() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    undo();\n    runAndVerifyStatusSorted(\"D a.txt\");\n    Assert.assertFalse(new File(myWorkingCopyDir.getPath(), \"a.txt\").exists());\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopy() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    copyFileInCommand(file, \"b.txt\");\n    verify(runSvn(\"status\"), \"A + b.txt\");\n  }","id":37359,"modified_method":"@Test\n  public void testCopy() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile file = createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    copyFileInCommand(file, \"b.txt\");\n    runAndVerifyStatusSorted(\"A + b.txt\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testUndoAdd() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    undo();\n    verify(runSvn(\"status\"), \"D a.txt\");\n    Assert.assertFalse(new File(myWorkingCopyDir.getPath(), \"a.txt\").exists());\n  }","id":37360,"modified_method":"@Test\n  public void testUndoAdd() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n    createFileInCommand(\"a.txt\", \"old content\");\n    checkin();\n    undo();\n    runAndVerifyStatusSorted(\"D a.txt\");\n    Assert.assertFalse(new File(myWorkingCopyDir.getPath(), \"a.txt\").exists());\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      @Override\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    final ProcessOutput result = runSvn(\"status\");\n    verify(result, \"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","id":37361,"modified_method":"@Test\n  public void testDirAndFileInCommand() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    new WriteCommandAction.Simple(myProject) {\n      @Override\n      public void run() {\n        try {\n          VirtualFile dir = myWorkingCopyDir.createChildDirectory(this, \"child\");\n          dir.createChildData(this, \"a.txt\");\n        }\n        catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    }.execute();\n    \n    runAndVerifyStatusSorted(\"A child\", \"A child\" + File.separatorChar + \"a.txt\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testDirAfterFile() throws Exception {\n    disableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"dir\");\n    final VirtualFile file = createFileInCommand(dir, \"a.txt\", \"content\");\n\n    verify(runSvn(\"status\"), \"? dir\");\n\n    final List<VirtualFile> files = new ArrayList<VirtualFile>();\n    files.add(file);\n    files.add(dir);\n    final List<VcsException> errors = SvnVcs.getInstance(myProject).getCheckinEnvironment().scheduleUnversionedFilesForAddition(files);\n    Assert.assertEquals(0, errors.size());\n  }","id":37362,"modified_method":"@Test\n  public void testDirAfterFile() throws Exception {\n    disableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final VirtualFile dir = createDirInCommand(myWorkingCopyDir, \"dir\");\n    final VirtualFile file = createFileInCommand(dir, \"a.txt\", \"content\");\n\n    runAndVerifyStatusSorted(\"? dir\");\n\n    final List<VirtualFile> files = new ArrayList<VirtualFile>();\n    files.add(file);\n    files.add(dir);\n    final List<VcsException> errors = SvnVcs.getInstance(myProject).getCheckinEnvironment().scheduleUnversionedFilesForAddition(files);\n    Assert.assertEquals(0, errors.size());\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public String prepareBranchesStructure() throws Exception {\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final String mainUrl = myRepoUrl + \"/trunk\";\n    verify(runSvn(\"mkdir\", \"-m\", \"mkdir\", mainUrl));\n    verify(runSvn(\"mkdir\", \"-m\", \"mkdir\", myRepoUrl + \"/branches\"));\n    verify(runSvn(\"mkdir\", \"-m\", \"mkdir\", myRepoUrl + \"/tags\"));\n\n    final ChangeListManagerImpl clManager = (ChangeListManagerImpl)ChangeListManager.getInstance(myProject);\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    Assert.assertTrue(FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\")));\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    verify(runSvn(\"co\", mainUrl, myWorkingCopyDir.getPath()));\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();\n    final String branchUrl = myRepoUrl + \"/branches/b1\";\n    verify(runSvn(\"copy\", \"-q\", \"-m\", \"coppy\", mainUrl, branchUrl));\n\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n\n    return branchUrl;\n  }","id":37363,"modified_method":"public String prepareBranchesStructure() throws Exception {\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final String mainUrl = myRepoUrl + \"/trunk\";\n    runInAndVerifyIgnoreOutput(\"mkdir\", \"-m\", \"mkdir\", mainUrl);\n    runInAndVerifyIgnoreOutput(\"mkdir\", \"-m\", \"mkdir\", myRepoUrl + \"/branches\");\n    runInAndVerifyIgnoreOutput(\"mkdir\", \"-m\", \"mkdir\", myRepoUrl + \"/tags\");\n\n    final ChangeListManagerImpl clManager = (ChangeListManagerImpl)ChangeListManager.getInstance(myProject);\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    Assert.assertTrue(FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\")));\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    runInAndVerifyIgnoreOutput(\"co\", mainUrl, myWorkingCopyDir.getPath());\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();\n    final String branchUrl = myRepoUrl + \"/branches/b1\";\n    runInAndVerifyIgnoreOutput(\"copy\", \"-q\", \"-m\", \"coppy\", mainUrl, branchUrl);\n\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n\n    return branchUrl;\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void update() throws IOException {\n    verify(runSvn(\"up\"));\n  }","id":37364,"modified_method":"protected void update() throws IOException {\n    runInAndVerifyIgnoreOutput(\"up\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Before\n  public void setUp() throws Exception {\n    UIUtil.invokeAndWaitIfNeeded(new Runnable() {\n      @Override\n      public void run() {\n        try {\n          final IdeaTestFixtureFactory fixtureFactory = IdeaTestFixtureFactory.getFixtureFactory();\n          myTempDirFixture = fixtureFactory.createTempDirTestFixture();\n          myTempDirFixture.setUp();\n\n          myRepoRoot = new File(myTempDirFixture.getTempDirPath(), \"svnroot\");\n          assert myRepoRoot.mkdir() || myRepoRoot.isDirectory() : myRepoRoot;\n\n          File pluginRoot = new File(PluginPathManager.getPluginHomePath(\"svn4idea\"));\n          if (!pluginRoot.isDirectory()) {\n            // try standalone mode\n            Class aClass = SvnTestCase.class;\n            String rootPath = PathManager.getResourceRoot(aClass, \"/\" + aClass.getName().replace('.', '/') + \".class\");\n            pluginRoot = new File(rootPath).getParentFile().getParentFile().getParentFile();\n          }\n\n          File svnBinDir =  new File(pluginRoot, myTestDataDir + \"/svn/bin\");\n          File svnExecutable = null;\n          if (SystemInfo.isWindows) {\n            svnExecutable = new File(svnBinDir, \"windows/svn.exe\");\n          }\n          else if (SystemInfo.isLinux) {\n            svnExecutable = new File(svnBinDir, \"linux/svn\");\n          }\n          else if (SystemInfo.isMac) {\n            svnExecutable = new File(svnBinDir, \"mac/svn\");\n          }\n          assertTrue(\"No Subversion executable was found: \" + svnExecutable + \", \" + SystemInfo.OS_NAME,\n                     svnExecutable != null && svnExecutable.canExecute());\n          myClientBinaryPath = svnExecutable.getParentFile();\n          myRunner = SystemInfo.isMac\n                     ? createClientRunner(Collections.singletonMap(\"DYLD_LIBRARY_PATH\", myClientBinaryPath.getPath()))\n                     : createClientRunner();\n\n          ZipUtil.extract(new File(pluginRoot, myTestDataDir + \"/svn/newrepo.zip\"), myRepoRoot, null);\n\n          myWcRoot = new File(myTempDirFixture.getTempDirPath(), myWcRootName);\n          assert myWcRoot.mkdir() || myWcRoot.isDirectory() : myWcRoot;\n\n          myRepoUrl = (SystemInfo.isWindows ? \"file:///\" : \"file://\") + FileUtil.toSystemIndependentName(myRepoRoot.getPath());\n\n          initProject(myWcRoot, SvnTestCase.this.getTestName());\n          activateVCS(SvnVcs.VCS_NAME);\n\n          verify(runSvn(\"co\", myRepoUrl, myWorkingCopyDir.getPath()));\n\n          myGate = new MockChangeListManagerGate(ChangeListManager.getInstance(myProject));\n\n          ((StartupManagerImpl) StartupManager.getInstance(myProject)).runPostStartupActivities();\n          refreshSvnMappingsSynchronously();\n        }\n        catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      }\n    });\n\n    // there should be kind-a waiting for after change list manager finds all changes and runs inner refresh of copies in the above method\n    if (myInitChangeListManager) {\n      ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n      VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n      changeListManager.ensureUpToDate(false);\n    }\n  }","id":37365,"modified_method":"@Before\n  public void setUp() throws Exception {\n    UIUtil.invokeAndWaitIfNeeded(new Runnable() {\n      @Override\n      public void run() {\n        try {\n          final IdeaTestFixtureFactory fixtureFactory = IdeaTestFixtureFactory.getFixtureFactory();\n          myTempDirFixture = fixtureFactory.createTempDirTestFixture();\n          myTempDirFixture.setUp();\n\n          myRepoRoot = new File(myTempDirFixture.getTempDirPath(), \"svnroot\");\n          assert myRepoRoot.mkdir() || myRepoRoot.isDirectory() : myRepoRoot;\n\n          File pluginRoot = new File(PluginPathManager.getPluginHomePath(\"svn4idea\"));\n          if (!pluginRoot.isDirectory()) {\n            // try standalone mode\n            Class aClass = SvnTestCase.class;\n            String rootPath = PathManager.getResourceRoot(aClass, \"/\" + aClass.getName().replace('.', '/') + \".class\");\n            pluginRoot = new File(rootPath).getParentFile().getParentFile().getParentFile();\n          }\n\n          File svnBinDir =  new File(pluginRoot, myTestDataDir + \"/svn/bin\");\n          File svnExecutable = null;\n          if (SystemInfo.isWindows) {\n            svnExecutable = new File(svnBinDir, \"windows/svn.exe\");\n          }\n          else if (SystemInfo.isLinux) {\n            svnExecutable = new File(svnBinDir, \"linux/svn\");\n          }\n          else if (SystemInfo.isMac) {\n            svnExecutable = new File(svnBinDir, \"mac/svn\");\n          }\n          assertTrue(\"No Subversion executable was found: \" + svnExecutable + \", \" + SystemInfo.OS_NAME,\n                     svnExecutable != null && svnExecutable.canExecute());\n          myClientBinaryPath = svnExecutable.getParentFile();\n          myRunner = SystemInfo.isMac\n                     ? createClientRunner(Collections.singletonMap(\"DYLD_LIBRARY_PATH\", myClientBinaryPath.getPath()))\n                     : createClientRunner();\n\n          ZipUtil.extract(new File(pluginRoot, myTestDataDir + \"/svn/newrepo.zip\"), myRepoRoot, null);\n\n          myWcRoot = new File(myTempDirFixture.getTempDirPath(), myWcRootName);\n          assert myWcRoot.mkdir() || myWcRoot.isDirectory() : myWcRoot;\n\n          myRepoUrl = (SystemInfo.isWindows ? \"file:///\" : \"file://\") + FileUtil.toSystemIndependentName(myRepoRoot.getPath());\n\n          verify(runSvn(\"co\", myRepoUrl, myWcRoot.getPath()));\n\n          initProject(myWcRoot, SvnTestCase.this.getTestName());\n          activateVCS(SvnVcs.VCS_NAME);\n\n          myGate = new MockChangeListManagerGate(ChangeListManager.getInstance(myProject));\n\n          ((StartupManagerImpl) StartupManager.getInstance(myProject)).runPostStartupActivities();\n          refreshSvnMappingsSynchronously();\n        }\n        catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      }\n    });\n\n    // there should be kind-a waiting for after change list manager finds all changes and runs inner refresh of copies in the above method\n    if (myInitChangeListManager) {\n      ChangeListManager changeListManager = ChangeListManager.getInstance(myProject);\n      VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n      changeListManager.ensureUpToDate(false);\n    }\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void prepareExternal(final boolean commitExternalDefinition, final boolean updateExternal,\n                              final boolean anotherRepository) throws Exception {\n    final ChangeListManagerImpl clManager = (ChangeListManagerImpl)ChangeListManager.getInstance(myProject);\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final String mainUrl = myRepoUrl + \"/root/source\";\n    final String externalURL;\n    if (anotherRepository) {\n      createAnotherRepo();\n      externalURL = myAnotherRepoUrl + \"/root/target\";\n    } else {\n      externalURL = myRepoUrl + \"/root/target\";\n    }\n\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    verify(runSvn(\"co\", mainUrl, sourceDir.getPath()));\n    CreateExternalAction.addToExternalProperty(vcs, sourceDir, \"external\", externalURL);\n    sleep(100);\n\n    if (updateExternal) {\n      verify(runSvn(\"up\", sourceDir.getPath()));\n    }\n    if (commitExternalDefinition) {\n      verify(runSvn(\"ci\", \"-m\", \"test\", sourceDir.getPath()));\n    }\n    sleep(100);\n\n    if (updateExternal) {\n      myWorkingCopyDir.refresh(false, true);\n      Assert.assertTrue(new File(sourceDir, \"external\").exists());\n    }\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","id":37366,"modified_method":"public void prepareExternal(final boolean commitExternalDefinition, final boolean updateExternal,\n                              final boolean anotherRepository) throws Exception {\n    final ChangeListManagerImpl clManager = (ChangeListManagerImpl)ChangeListManager.getInstance(myProject);\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    final String mainUrl = myRepoUrl + \"/root/source\";\n    final String externalURL;\n    if (anotherRepository) {\n      createAnotherRepo();\n      externalURL = myAnotherRepoUrl + \"/root/target\";\n    } else {\n      externalURL = myRepoUrl + \"/root/target\";\n    }\n\n    final SubTree subTree = new SubTree(myWorkingCopyDir);\n    checkin();\n    clManager.stopEveryThingIfInTestMode();\n    sleep(100);\n    final File rootFile = new File(subTree.myRootDir.getPath());\n    FileUtil.delete(rootFile);\n    FileUtil.delete(new File(myWorkingCopyDir.getPath() + File.separator + \".svn\"));\n    Assert.assertTrue(!rootFile.exists());\n    sleep(200);\n    myWorkingCopyDir.refresh(false, true);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    runInAndVerifyIgnoreOutput(\"co\", mainUrl, sourceDir.getPath());\n    CreateExternalAction.addToExternalProperty(vcs, sourceDir, \"external\", externalURL);\n    sleep(100);\n\n    if (updateExternal) {\n      runInAndVerifyIgnoreOutput(\"up\", sourceDir.getPath());\n    }\n    if (commitExternalDefinition) {\n      runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", sourceDir.getPath());\n    }\n    sleep(100);\n\n    if (updateExternal) {\n      myWorkingCopyDir.refresh(false, true);\n      Assert.assertTrue(new File(sourceDir, \"external\").exists());\n    }\n    // above is preparation\n\n    // start change list manager again\n    clManager.forceGoInTestMode();\n    refreshSvnMappingsSynchronously();\n    //clManager.ensureUpToDate(false);\n    //clManager.ensureUpToDate(false);\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void checkin() throws IOException {\n    verify(runSvn(\"ci\", \"-m\", \"test\"));\n  }","id":37367,"modified_method":"protected void checkin() throws IOException {\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\");\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void createAnotherRepo() throws Exception {\n    final File repo = FileUtil.createTempDirectory(\"anotherRepo\", \"\");\n    FileUtil.delete(repo);\n    FileUtil.copyDir(myRepoRoot, repo);\n    myAnotherRepoUrl = (SystemInfo.isWindows ? \"file:///\" : \"file://\") + FileUtil.toSystemIndependentName(repo.getPath());\n    final File tmpWc = FileUtil.createTempDirectory(\"hhh\", \"\");\n    verify(runSvn(\"co\", myAnotherRepoUrl, tmpWc.getPath()));\n    final VirtualFile tmpWcVf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(tmpWc);\n    Assert.assertNotNull(tmpWcVf);\n    final SubTree tree = new SubTree(tmpWcVf);\n    verify(myRunner.runClient(\"svn\", null, tmpWc, \"add\", \"root\"));\n    verify(myRunner.runClient(\"svn\", null, tmpWc, \"ci\", \"-m\", \"fff\"));\n    FileUtil.delete(tmpWc);\n  }","id":37368,"modified_method":"private void createAnotherRepo() throws Exception {\n    final File repo = FileUtil.createTempDirectory(\"anotherRepo\", \"\");\n    FileUtil.delete(repo);\n    FileUtil.copyDir(myRepoRoot, repo);\n    myAnotherRepoUrl = (SystemInfo.isWindows ? \"file:///\" : \"file://\") + FileUtil.toSystemIndependentName(repo.getPath());\n    final File tmpWc = FileUtil.createTempDirectory(\"hhh\", \"\");\n    runInAndVerifyIgnoreOutput(\"co\", myAnotherRepoUrl, tmpWc.getPath());\n    final VirtualFile tmpWcVf = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(tmpWc);\n    Assert.assertNotNull(tmpWcVf);\n    final SubTree tree = new SubTree(tmpWcVf);\n    runInAndVerifyIgnoreOutput(tmpWc, \"add\", \"root\");\n    runInAndVerifyIgnoreOutput(tmpWc, \"ci\", \"-m\", \"fff\");\n    FileUtil.delete(tmpWc);\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@After\n  public void tearDown() throws Exception {\n    UIUtil.invokeAndWaitIfNeeded(new Runnable() {\n      @Override\n      public void run() {\n        try {\n          tearDownProject();\n\n          if (myWcRoot != null && myWcRoot.exists()) {\n            FileUtil.delete(myWcRoot);\n          }\n          if (myRepoRoot != null && myRepoRoot.exists()) {\n            FileUtil.delete(myRepoRoot);\n          }\n\n          if (myTempDirFixture != null) {\n            myTempDirFixture.tearDown();\n            myTempDirFixture = null;\n          }\n        }\n        catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      }\n    });\n  }","id":37369,"modified_method":"@After\n  public void tearDown() throws Exception {\n    ((ChangeListManagerImpl) ChangeListManager.getInstance(myProject)).stopEveryThingIfInTestMode();\n\n    UIUtil.invokeAndWaitIfNeeded(new Runnable() {\n      @Override\n      public void run() {\n        try {\n          tearDownProject();\n\n          if (myWcRoot != null && myWcRoot.exists()) {\n            FileUtil.delete(myWcRoot);\n          }\n          if (myRepoRoot != null && myRepoRoot.exists()) {\n            FileUtil.delete(myRepoRoot);\n          }\n\n          if (myTempDirFixture != null) {\n            myTempDirFixture.tearDown();\n            myTempDirFixture = null;\n          }\n        }\n        catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      }\n    });\n  }","commit_id":"22bb19f8dc2501cef16859969a093db17eeefd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByExternalUpdate() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    update();\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","id":37370,"modified_method":"@Test\n  public void testClosedByExternalUpdate() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    update();\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByUpdateWithExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"s1.txt\");\n    final File externalFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"external\" + File.separator + \"t12.txt\");\n\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    final VirtualFile vf1 = lfs.refreshAndFindFileByIoFile(sourceFile);\n    final VirtualFile vf2 = lfs.refreshAndFindFileByIoFile(externalFile);\n\n    Assert.assertNotNull(vf1);\n    Assert.assertNotNull(vf2);\n\n    editFileInCommand(myProject, vf1, \"test externals 123\" + System.currentTimeMillis());\n    editFileInCommand(myProject, vf2, \"test externals 123\" + System.currentTimeMillis());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    final Change change1 = myChangeListManager.getChange(vf1);\n    final Change change2 = myChangeListManager.getChange(vf2);\n    Assert.assertNotNull(change1);\n    Assert.assertNotNull(change2);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    verify(runSvn(\"ci\", \"-m\", \"test\", sourceDir.getPath()));   // #3\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath())); // #4\n\n    editFileInCommand(myProject, vf2, \"test externals 12344444\" + System.currentTimeMillis());\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath())); // #5\n\n    final SvnDiffProvider diffProvider = (SvnDiffProvider) myVcs.getDiffProvider();\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    verify(runSvn(\"up\", \"-r\", \"4\", sourceDir.getPath()));\n    verify(runSvn(\"up\", \"-r\", \"4\", externalDir.getPath()));\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 4);\n\n    // then annotate both\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(vf1);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(vf1, annotation);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation);\n\n    final FileAnnotation annotation1 = myVcs.getAnnotationProvider().annotate(vf2);\n    annotation1.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed1 = true;\n        listener.unregisterAnnotation(vf1, annotation1);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation1);\n\n    //up\n    verify(runSvn(\"up\", sourceDir.getPath()));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    //verify(runSvn(\"up\", \"-r\", \"3\", externalDir.getPath()));\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    Assert.assertTrue(myIsClosed1);\n    Assert.assertFalse(myIsClosed);  // in source is not closed..\n  }","id":37371,"modified_method":"@Test\n  public void testClosedByUpdateWithExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"s1.txt\");\n    final File externalFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"external\" + File.separator + \"t12.txt\");\n\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    final VirtualFile vf1 = lfs.refreshAndFindFileByIoFile(sourceFile);\n    final VirtualFile vf2 = lfs.refreshAndFindFileByIoFile(externalFile);\n\n    Assert.assertNotNull(vf1);\n    Assert.assertNotNull(vf2);\n\n    editFileInCommand(myProject, vf1, \"test externals 123\" + System.currentTimeMillis());\n    editFileInCommand(myProject, vf2, \"test externals 123\" + System.currentTimeMillis());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    final Change change1 = myChangeListManager.getChange(vf1);\n    final Change change2 = myChangeListManager.getChange(vf2);\n    Assert.assertNotNull(change1);\n    Assert.assertNotNull(change2);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", sourceDir.getPath());   // #3\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath()); // #4\n\n    editFileInCommand(myProject, vf2, \"test externals 12344444\" + System.currentTimeMillis());\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath()); // #5\n\n    final SvnDiffProvider diffProvider = (SvnDiffProvider) myVcs.getDiffProvider();\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"4\", sourceDir.getPath());\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"4\", externalDir.getPath());\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 4);\n\n    // then annotate both\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(vf1);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(vf1, annotation);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation);\n\n    final FileAnnotation annotation1 = myVcs.getAnnotationProvider().annotate(vf2);\n    annotation1.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed1 = true;\n        listener.unregisterAnnotation(vf1, annotation1);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation1);\n\n    //up\n    runInAndVerifyIgnoreOutput(\"up\", sourceDir.getPath());\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    //verify(runSvn(\"up\", \"-r\", \"3\", externalDir.getPath()));\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    Assert.assertTrue(myIsClosed1);\n    Assert.assertFalse(myIsClosed);  // in source is not closed..\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedChangedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    imitUpdate(myProject);\n    Assert.assertTrue(myIsClosed);\n  }","id":37372,"modified_method":"@Test\n  public void testClosedChangedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    imitUpdate(myProject);\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    imitUpdate(myProject);\n    Assert.assertTrue(myIsClosed);\n  }","id":37373,"modified_method":"@Test\n  public void testClosedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    imitUpdate(myProject);\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedChangedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    ProjectLevelVcsManagerEx.getInstanceEx(myProject).getOptions(VcsConfiguration.StandardOption.UPDATE).setValue(false);\n    final CommonUpdateProjectAction action = new CommonUpdateProjectAction();\n    action.getTemplatePresentation().setText(\"1\");\n    action.actionPerformed(new AnActionEvent(null,\n                                             new DataContext() {\n                                               @Nullable\n                                               @Override\n                                               public Object getData(@NonNls String dataId) {\n                                                 if (PlatformDataKeys.PROJECT.is(dataId)) {\n                                                   return myProject;\n                                                 }\n                                                 return null;\n                                               }\n                                             }, \"test\", new Presentation(), null, 0));\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","id":37374,"modified_method":"@Test\n  public void testClosedChangedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    ProjectLevelVcsManagerEx.getInstanceEx(myProject).getOptions(VcsConfiguration.StandardOption.UPDATE).setValue(false);\n    final CommonUpdateProjectAction action = new CommonUpdateProjectAction();\n    action.getTemplatePresentation().setText(\"1\");\n    action.actionPerformed(new AnActionEvent(null,\n                                             new DataContext() {\n                                               @Nullable\n                                               @Override\n                                               public Object getData(@NonNls String dataId) {\n                                                 if (PlatformDataKeys.PROJECT.is(dataId)) {\n                                                   return myProject;\n                                                 }\n                                                 return null;\n                                               }\n                                             }, \"test\", new Presentation(), null, 0));\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByUpdateWithExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"s1.txt\");\n    final File externalFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"external\" + File.separator + \"t12.txt\");\n\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    final VirtualFile vf1 = lfs.refreshAndFindFileByIoFile(sourceFile);\n    final VirtualFile vf2 = lfs.refreshAndFindFileByIoFile(externalFile);\n\n    Assert.assertNotNull(vf1);\n    Assert.assertNotNull(vf2);\n\n    editFileInCommand(myProject, vf1, \"test externals 123\" + System.currentTimeMillis());\n    editFileInCommand(myProject, vf2, \"test externals 123\" + System.currentTimeMillis());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    final Change change1 = myChangeListManager.getChange(vf1);\n    final Change change2 = myChangeListManager.getChange(vf2);\n    Assert.assertNotNull(change1);\n    Assert.assertNotNull(change2);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    verify(runSvn(\"ci\", \"-m\", \"test\", sourceDir.getPath()));   // #3\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath())); // #4\n\n    editFileInCommand(myProject, vf2, \"test externals 12344444\" + System.currentTimeMillis());\n    verify(runSvn(\"ci\", \"-m\", \"test\", externalDir.getPath())); // #5\n\n    final SvnDiffProvider diffProvider = (SvnDiffProvider) myVcs.getDiffProvider();\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    verify(runSvn(\"up\", \"-r\", \"4\", sourceDir.getPath()));\n    verify(runSvn(\"up\", \"-r\", \"4\", externalDir.getPath()));\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 4);\n\n    // then annotate both\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(vf1);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(vf1, annotation);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation);\n\n    final FileAnnotation annotation1 = myVcs.getAnnotationProvider().annotate(vf2);\n    annotation1.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed1 = true;\n        listener.unregisterAnnotation(vf1, annotation1);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation1);\n\n    //up\n    verify(runSvn(\"up\", sourceDir.getPath()));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    //verify(runSvn(\"up\", \"-r\", \"3\", externalDir.getPath()));\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    Assert.assertTrue(myIsClosed1);\n    Assert.assertFalse(myIsClosed);  // in source is not closed..\n  }","id":37375,"modified_method":"@Test\n  public void testClosedByUpdateWithExternals() throws Exception {\n    prepareExternal();\n\n    final File sourceFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"s1.txt\");\n    final File externalFile = new File(myWorkingCopyDir.getPath(), \"source\" + File.separator + \"external\" + File.separator + \"t12.txt\");\n\n    final LocalFileSystem lfs = LocalFileSystem.getInstance();\n    final VirtualFile vf1 = lfs.refreshAndFindFileByIoFile(sourceFile);\n    final VirtualFile vf2 = lfs.refreshAndFindFileByIoFile(externalFile);\n\n    Assert.assertNotNull(vf1);\n    Assert.assertNotNull(vf2);\n\n    editFileInCommand(myProject, vf1, \"test externals 123\" + System.currentTimeMillis());\n    editFileInCommand(myProject, vf2, \"test externals 123\" + System.currentTimeMillis());\n\n    VcsDirtyScopeManager.getInstance(myProject).markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    final Change change1 = myChangeListManager.getChange(vf1);\n    final Change change2 = myChangeListManager.getChange(vf2);\n    Assert.assertNotNull(change1);\n    Assert.assertNotNull(change2);\n\n    final File sourceDir = new File(myWorkingCopyDir.getPath(), \"source\");\n    final File externalDir = new File(myWorkingCopyDir.getPath(), \"source/external\");\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", sourceDir.getPath());   // #3\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath()); // #4\n\n    editFileInCommand(myProject, vf2, \"test externals 12344444\" + System.currentTimeMillis());\n    runInAndVerifyIgnoreOutput(\"ci\", \"-m\", \"test\", externalDir.getPath()); // #5\n\n    final SvnDiffProvider diffProvider = (SvnDiffProvider) myVcs.getDiffProvider();\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"4\", sourceDir.getPath());\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"4\", externalDir.getPath());\n\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 4);\n\n    // then annotate both\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(vf1);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(vf1, annotation);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation);\n\n    final FileAnnotation annotation1 = myVcs.getAnnotationProvider().annotate(vf2);\n    annotation1.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed1 = true;\n        listener.unregisterAnnotation(vf1, annotation1);\n      }\n    });\n    listener.registerAnnotation(vf1, annotation1);\n\n    //up\n    runInAndVerifyIgnoreOutput(\"up\", sourceDir.getPath());\n    imitateEvent(lfs.refreshAndFindFileByIoFile(sourceDir));\n    imitateEvent(lfs.refreshAndFindFileByIoFile(externalDir));\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    //verify(runSvn(\"up\", \"-r\", \"3\", externalDir.getPath()));\n    assertRevision(vf1, diffProvider, 3);\n    assertRevision(vf2, diffProvider, 5);\n\n    Assert.assertTrue(myIsClosed1);\n    Assert.assertFalse(myIsClosed);  // in source is not closed..\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByExternalUpdate() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    update();\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","id":37376,"modified_method":"@Test\n  public void testClosedByExternalUpdate() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");  // take #2\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n    editFileInCommand(myProject, tree.myS1File, \"1+\\n2\\n3\\n4\\n\");\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n    Assert.assertFalse(myIsClosed);\n\n    update();\n    myWorkingCopyDir.refresh(false, true);\n    imitateEvent(myWorkingCopyDir);\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testClosedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    verify(runSvn(\"up\", \"-r\", \"2\"));\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    ProjectLevelVcsManagerEx.getInstanceEx(myProject).getOptions(VcsConfiguration.StandardOption.UPDATE).setValue(false);\n    final CommonUpdateProjectAction action = new CommonUpdateProjectAction();\n    action.getTemplatePresentation().setText(\"1\");\n    action.actionPerformed(new AnActionEvent(null,\n                                             new DataContext() {\n                                               @Nullable\n                                               @Override\n                                               public Object getData(@NonNls String dataId) {\n                                                 if (PlatformDataKeys.PROJECT.is(dataId)) {\n                                                   return myProject;\n                                                 }\n                                                 return null;\n                                               }\n                                             }, \"test\", new Presentation(), null, 0));\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","id":37377,"modified_method":"@Test\n  public void testClosedByUpdateInIdea() throws Exception {\n    final SubTree tree = new SubTree(myWorkingCopyDir);\n    checkin();  //#1\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3\\n4\\n\");\n    checkin();  //#2\n    editFileInCommand(myProject, tree.myS1File, \"1\\n2\\n3**\\n4\\n\");\n    checkin();  //#3\n    runInAndVerifyIgnoreOutput(\"up\", \"-r\", \"2\");\n\n    final VcsAnnotationLocalChangesListener listener = ProjectLevelVcsManager.getInstance(myProject).getAnnotationLocalChangesListener();\n    final FileAnnotation annotation = myVcs.getAnnotationProvider().annotate(tree.myS1File);\n    annotation.setCloser(new Runnable() {\n      @Override\n      public void run() {\n        myIsClosed = true;\n        listener.unregisterAnnotation(tree.myS1File, annotation);\n      }\n    });\n    listener.registerAnnotation(tree.myS1File, annotation);\n\n    myDirtyScopeManager.markEverythingDirty();\n    myChangeListManager.ensureUpToDate(false);\n\n    ProjectLevelVcsManagerEx.getInstanceEx(myProject).getOptions(VcsConfiguration.StandardOption.UPDATE).setValue(false);\n    final CommonUpdateProjectAction action = new CommonUpdateProjectAction();\n    action.getTemplatePresentation().setText(\"1\");\n    action.actionPerformed(new AnActionEvent(null,\n                                             new DataContext() {\n                                               @Nullable\n                                               @Override\n                                               public Object getData(@NonNls String dataId) {\n                                                 if (PlatformDataKeys.PROJECT.is(dataId)) {\n                                                   return myProject;\n                                                 }\n                                                 return null;\n                                               }\n                                             }, \"test\", new Presentation(), null, 0));\n\n    myChangeListManager.ensureUpToDate(false);\n    myChangeListManager.ensureUpToDate(false);  // wait for after-events like annotations recalculation\n    sleep(100); // zipper updater\n    Assert.assertTrue(myIsClosed);\n  }","commit_id":"2ef7ff0043cea8bcfe81dcb396e2b0d573be6dfb","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testReplaced() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String d1Path = new File(d1.getPath()).getAbsolutePath();\n    verify(runSvn(\"delete\", d1Path));\n    verify(runSvn(\"add\", d1Path));\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- replaced\")});\n  }","id":37378,"modified_method":"@Test\n  public void testReplaced() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    final String d1Path = new File(d1.getPath()).getAbsolutePath();\n    runInAndVerifyIgnoreOutput(\"delete\", d1Path);\n    runInAndVerifyIgnoreOutput(\"add\", d1Path);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- replaced\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopyAndModify() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n\n    update();\n\n    verify(runSvn(\"copy\", myWorkingCopyDir.getPath() + \"/trunk\", myWorkingCopyDir.getPath() + \"/branch\"));\n    verify(runSvn(\"propset\", \"testprop\", \"testval\", myWorkingCopyDir.getPath() + \"/branch/folder\"));\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\"),\n      new Data(new File(myWorkingCopyDir.getPath(), \"branch/folder\").getAbsolutePath(), FileStatus.MODIFIED, \"- copied from /trunk/folder\")});\n  }","id":37379,"modified_method":"@Test\n  public void testCopyAndModify() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n\n    update();\n\n    runInAndVerifyIgnoreOutput(\"copy\", myWorkingCopyDir.getPath() + \"/trunk\", myWorkingCopyDir.getPath() + \"/branch\");\n    runInAndVerifyIgnoreOutput(\"propset\", \"testprop\", \"testval\", myWorkingCopyDir.getPath() + \"/branch/folder\");\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\"),\n      new Data(new File(myWorkingCopyDir.getPath(), \"branch/folder\").getAbsolutePath(), FileStatus.MODIFIED, \"- copied from /trunk/folder\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopyDir() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\")});\n  }","id":37380,"modified_method":"@Test\n  public void testCopyDir() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopyDir() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n    verify(runSvn(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\"));\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\")});\n  }","id":37381,"modified_method":"@Test\n  public void testCopyDir() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n    runInAndVerifyIgnoreOutput(\"copy\", \"-m\", \"test\", myRepoUrl + \"/trunk\", myRepoUrl + \"/branch\");\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testCopyAndModify() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    verify(runSvn(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\"));\n\n    update();\n\n    verify(runSvn(\"copy\", myWorkingCopyDir.getPath() + \"/trunk\", myWorkingCopyDir.getPath() + \"/branch\"));\n    verify(runSvn(\"propset\", \"testprop\", \"testval\", myWorkingCopyDir.getPath() + \"/branch/folder\"));\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\"),\n      new Data(new File(myWorkingCopyDir.getPath(), \"branch/folder\").getAbsolutePath(), FileStatus.MODIFIED, \"- copied from /trunk/folder\")});\n  }","id":37382,"modified_method":"@Test\n  public void testCopyAndModify() throws Exception {\n    final File trunk = new File(myTempDirFixture.getTempDirPath(), \"trunk\");\n    trunk.mkdir();\n    Thread.sleep(100);\n    final File folder = new File(trunk, \"folder\");\n    folder.mkdir();\n    Thread.sleep(100);\n    new File(folder, \"f1.txt\").createNewFile();\n    new File(folder, \"f2.txt\").createNewFile();\n    Thread.sleep(100);\n\n    runInAndVerifyIgnoreOutput(\"import\", \"-m\", \"test\", trunk.getAbsolutePath(), myRepoUrl + \"/trunk\");\n\n    update();\n\n    runInAndVerifyIgnoreOutput(\"copy\", myWorkingCopyDir.getPath() + \"/trunk\", myWorkingCopyDir.getPath() + \"/branch\");\n    runInAndVerifyIgnoreOutput(\"propset\", \"testprop\", \"testval\", myWorkingCopyDir.getPath() + \"/branch/folder\");\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl + \"/branch\"), 0);\n    checkList(changeListList, 2, new Data[] {new Data(new File(myWorkingCopyDir.getPath(), \"branch\").getAbsolutePath(), FileStatus.ADDED, \"- copied from /trunk\"),\n      new Data(new File(myWorkingCopyDir.getPath(), \"branch/folder\").getAbsolutePath(), FileStatus.MODIFIED, \"- copied from /trunk/folder\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Test\n  public void testReplaced() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    File dir = new File(d1.getPath());\n    final String d1Path = dir.getAbsolutePath();\n    verify(runSvn(\"delete\", d1Path));\n    boolean created = dir.mkdir();\n    Assert.assertTrue(created);\n    verify(runSvn(\"add\", d1Path));\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- replaced\")});\n  }","id":37383,"modified_method":"@Test\n  public void testReplaced() throws Exception {\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.ADD);\n    enableSilentOperation(VcsConfiguration.StandardConfirmation.REMOVE);\n\n    VirtualFile d1 = createDirInCommand(myWorkingCopyDir, \"d1\");\n\n    VirtualFile f11 = createFileInCommand(d1, \"f11.txt\", \"123\\n456\");\n    VirtualFile f12 = createFileInCommand(d1, \"f12.txt\", \"----\");\n\n    // r1, addition without history\n    checkin();\n\n    File dir = new File(d1.getPath());\n    final String d1Path = dir.getAbsolutePath();\n    runInAndVerifyIgnoreOutput(\"delete\", d1Path);\n    boolean created = dir.mkdir();\n    Assert.assertTrue(created);\n    runInAndVerifyIgnoreOutput(\"add\", d1Path);\n\n    checkin();\n\n    final SvnVcs vcs = SvnVcs.getInstance(myProject);\n    vcs.invokeRefreshSvnRoots();\n    final CommittedChangesProvider<SvnChangeList,ChangeBrowserSettings> committedChangesProvider = vcs.getCommittedChangesProvider();\n    final List<SvnChangeList> changeListList =\n      committedChangesProvider.getCommittedChanges(committedChangesProvider.createDefaultSettings(),\n                                                   new SvnRepositoryLocation(myRepoUrl), 0);\n    checkList(changeListList, 2, new Data[] {new Data(absPath(d1), FileStatus.MODIFIED, \"- replaced\")});\n  }","commit_id":"c62d295e5e8e3258861a49904f83fb3282baaf60","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public String getUrl() {\n        return \"ftp://\" + RemoteClient.getServerName() + this.getFullName();\n    }","id":37384,"modified_method":"public String getUrl() {\n        return \"ftp://\"+RemoteClient.getUserName()+\":\"+RemoteClient.getPassword()+\"@\"+ RemoteClient.getServerName() + this.getFullName();\n    }","commit_id":"e9d0d2cd609a26b08347bd7768616dae9cbe02ff","url":"https://github.com/VUE/VUE"},{"original_method":"public String getUrl() {\n        return \"ftp://\" + RemoteClient.getServerName() + this.getFullName();\n    }","id":37385,"modified_method":"public String getUrl() {\n        return \"ftp://\"+RemoteClient.getUserName()+\":\"+RemoteClient.getPassword()+\"@\"+ RemoteClient.getServerName() + this.getFullName();\n    }","commit_id":"e9d0d2cd609a26b08347bd7768616dae9cbe02ff","url":"https://github.com/VUE/VUE"},{"original_method":"/** \n     *  Creates a new instance of RemoteClient.  Client is opened based on host, username,\n     *  and password provided.  These are cached in order to re-establishe the connection\n     *  should it be dropped.\n     */\n    public RemoteClient(String host, String username, String password) throws osid.filing.FilingException {\n        try {\n            FTPClientFactory factory = new FTPClientFactory(host,username,password);\n            this.client = factory.createClient();\n            this.rootBase = client.printWorkingDirectory();\n        }\n        catch (java.io.IOException ex1) {\n            throw new osid.filing.FilingException (osid.filing.FilingException.OPERATION_FAILED);\n        }\n        catch (osid.filing.FilingException ex2) {\n            throw new osid.filing.FilingException (osid.filing.FilingException.OPERATION_FAILED);\n        }\n        server = host;             //  Cache the server name.\n        username = username;       //  Cache the user name.\n        password = password;       //  Cache the password.\n    }","id":37386,"modified_method":"/** \n     *  Creates a new instance of RemoteClient.  Client is opened based on host, username,\n     *  and password provided.  These are cached in order to re-establishe the connection\n     *  should it be dropped.\n     */\n    public RemoteClient(String host, String username, String password) throws osid.filing.FilingException {\n        try {\n            FTPClientFactory factory = new FTPClientFactory(host,username,password);\n            this.client = factory.createClient();\n            this.rootBase = client.printWorkingDirectory();\n        }\n        catch (java.io.IOException ex1) {\n            throw new osid.filing.FilingException (osid.filing.FilingException.OPERATION_FAILED);\n        }\n        catch (osid.filing.FilingException ex2) {\n            throw new osid.filing.FilingException (osid.filing.FilingException.OPERATION_FAILED);\n        }\n        server = host;             //  Cache the server name.\n        this.username = username;       //  Cache the user name.\n        this.password = password;       //  Cache the password.\n    }","commit_id":"e9d0d2cd609a26b08347bd7768616dae9cbe02ff","url":"https://github.com/VUE/VUE"},{"original_method":"protected boolean checkUserDataPermissions(String pathInContext, Request request, Response response, Object constraintInfo) throws IOException\n    {\n        if (constraintInfo == null)\n            return true;\n\n        RoleInfo roleInfo = (RoleInfo)constraintInfo;\n        if (roleInfo.isForbidden())\n            return false;\n\n\n        UserDataConstraint dataConstraint = roleInfo.getUserDataConstraint();\n        if (dataConstraint == null || dataConstraint == UserDataConstraint.None)\n        {\n            return true;\n        }\n        AbstractHttpConnection connection = AbstractHttpConnection.getCurrentConnection();\n        Connector connector = connection.getConnector();\n\n        if (dataConstraint == UserDataConstraint.Integral)\n        {\n            if (connector.isIntegral(request))\n                return true;\n            if (connector.getIntegralPort() > 0)\n            {\n                String url = connector.getIntegralScheme() + \"://\" + request.getServerName() + \":\" + connector.getIntegralPort() + request.getRequestURI();\n                if (request.getQueryString() != null)\n                    url += \"?\" + request.getQueryString();\n                response.setContentLength(0);\n                response.sendRedirect(url);\n            }\n            else\n                response.sendError(Response.SC_FORBIDDEN,\"!Integral\");\n\n            request.setHandled(true);\n            return false;\n        }\n        else if (dataConstraint == UserDataConstraint.Confidential)\n        {\n            if (connector.isConfidential(request))\n                return true;\n\n            if (connector.getConfidentialPort() > 0)\n            {\n                String url = connector.getConfidentialScheme() + \"://\" + request.getServerName() + \":\" + connector.getConfidentialPort()\n                        + request.getRequestURI();\n                if (request.getQueryString() != null)\n                    url += \"?\" + request.getQueryString();\n\n                response.setContentLength(0);\n                response.sendRedirect(url);\n            }\n            else\n                response.sendError(Response.SC_FORBIDDEN,\"!Confidential\");\n\n            request.setHandled(true);\n            return false;\n        }\n        else\n        {\n            throw new IllegalArgumentException(\"Invalid dataConstraint value: \" + dataConstraint);\n        }\n\n    }","id":37387,"modified_method":"protected boolean checkUserDataPermissions(String pathInContext, Request request, Response response, Object constraintInfo) throws IOException\n    {\n        if (constraintInfo == null)\n            return true;\n\n        RoleInfo roleInfo = (RoleInfo)constraintInfo;\n        if (roleInfo.isForbidden())\n            return false;\n\n\n        UserDataConstraint dataConstraint = roleInfo.getUserDataConstraint();\n        if (dataConstraint == null || dataConstraint == UserDataConstraint.None)\n        {\n            return true;\n        }\n        AbstractHttpConnection connection = AbstractHttpConnection.getCurrentConnection();\n        Connector connector = connection.getConnector();\n\n        if (dataConstraint == UserDataConstraint.Integral)\n        {\n            if (connector.isIntegral(request))\n                return true;\n            if (connector.getIntegralPort() > 0)\n            {\n                String scheme=connector.getIntegralScheme();\n                int port=connector.getIntegralPort();\n                String url = (HttpSchemes.HTTPS.equalsIgnoreCase(scheme) && port==443)\n                    ? \"https://\"+request.getServerName()+request.getRequestURI()\n                    : scheme + \"://\" + request.getServerName() + \":\" + port + request.getRequestURI();\n                if (request.getQueryString() != null)\n                    url += \"?\" + request.getQueryString();\n                response.setContentLength(0);\n                response.sendRedirect(url);\n            }\n            else\n                response.sendError(Response.SC_FORBIDDEN,\"!Integral\");\n\n            request.setHandled(true);\n            return false;\n        }\n        else if (dataConstraint == UserDataConstraint.Confidential)\n        {\n            if (connector.isConfidential(request))\n                return true;\n\n            if (connector.getConfidentialPort() > 0)\n            {\n                String scheme=connector.getConfidentialScheme();\n                int port=connector.getConfidentialPort();\n                String url = (HttpSchemes.HTTPS.equalsIgnoreCase(scheme) && port==443)\n                    ? \"https://\"+request.getServerName()+request.getRequestURI()\n                    : scheme + \"://\" + request.getServerName() + \":\" + port + request.getRequestURI();                    \n                if (request.getQueryString() != null)\n                    url += \"?\" + request.getQueryString();\n                response.setContentLength(0);\n                response.sendRedirect(url);\n            }\n            else\n                response.sendError(Response.SC_FORBIDDEN,\"!Confidential\");\n\n            request.setHandled(true);\n            return false;\n        }\n        else\n        {\n            throw new IllegalArgumentException(\"Invalid dataConstraint value: \" + dataConstraint);\n        }\n\n    }","commit_id":"cada28e8cfc0d5b561829296977af8b29b84ad48","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Before\n    public void setupSecurity()\n    {\n        _security = new ConstraintSecurityHandler();\n        _session.setHandler(_security);\n        RequestHandler _handler = new RequestHandler();\n        _security.setHandler(_handler);\n\n        Constraint constraint0 = new Constraint();\n        constraint0.setAuthenticate(true);\n        constraint0.setName(\"forbid\");\n        ConstraintMapping mapping0 = new ConstraintMapping();\n        mapping0.setPathSpec(\"/forbid/*\");\n        mapping0.setConstraint(constraint0);\n\n        Constraint constraint1 = new Constraint();\n        constraint1.setAuthenticate(true);\n        constraint1.setName(\"auth\");\n        constraint1.setRoles(new String[]{Constraint.ANY_ROLE});\n        ConstraintMapping mapping1 = new ConstraintMapping();\n        mapping1.setPathSpec(\"/auth/*\");\n        mapping1.setConstraint(constraint1);\n\n        Constraint constraint2 = new Constraint();\n        constraint2.setAuthenticate(true);\n        constraint2.setName(\"admin\");\n        constraint2.setRoles(new String[]{\"administrator\"});\n        ConstraintMapping mapping2 = new ConstraintMapping();\n        mapping2.setPathSpec(\"/admin/*\");\n        mapping2.setConstraint(constraint2);\n        mapping2.setMethod(\"GET\");\n\n        Constraint constraint3 = new Constraint();\n        constraint3.setAuthenticate(false);\n        constraint3.setName(\"relax\");\n        ConstraintMapping mapping3 = new ConstraintMapping();\n        mapping3.setPathSpec(\"/admin/relax/*\");\n        mapping3.setConstraint(constraint3);\n\n        Constraint constraint4 = new Constraint();\n        constraint4.setAuthenticate(true);\n        constraint4.setName(\"loginpage\");\n        constraint4.setRoles(new String[]{\"administrator\"});\n        ConstraintMapping mapping4 = new ConstraintMapping();\n        mapping4.setPathSpec(\"/testLoginPage\");\n        mapping4.setConstraint(constraint4);\n\n        Constraint constraint5 = new Constraint();\n        constraint5.setAuthenticate(false);\n        constraint5.setName(\"allow forbidden POST\");\n        ConstraintMapping mapping5 = new ConstraintMapping();\n        mapping5.setPathSpec(\"/forbid/post\");\n        mapping5.setConstraint(constraint5);\n        mapping5.setMethod(\"POST\");\n        \n        \n        Set<String> knownRoles=new HashSet<String>();\n        knownRoles.add(\"user\");\n        knownRoles.add(\"administrator\");\n\n        _security.setConstraintMappings(Arrays.asList(new ConstraintMapping[]\n                {\n                        mapping0, mapping1, mapping2, mapping3, mapping4, mapping5\n                }), knownRoles);\n    }","id":37388,"modified_method":"@Before\n    public void setupSecurity()\n    {\n        _security = new ConstraintSecurityHandler();\n        _session.setHandler(_security);\n        RequestHandler _handler = new RequestHandler();\n        _security.setHandler(_handler);\n\n        Constraint constraint0 = new Constraint();\n        constraint0.setAuthenticate(true);\n        constraint0.setName(\"forbid\");\n        ConstraintMapping mapping0 = new ConstraintMapping();\n        mapping0.setPathSpec(\"/forbid/*\");\n        mapping0.setConstraint(constraint0);\n\n        Constraint constraint1 = new Constraint();\n        constraint1.setAuthenticate(true);\n        constraint1.setName(\"auth\");\n        constraint1.setRoles(new String[]{Constraint.ANY_ROLE});\n        ConstraintMapping mapping1 = new ConstraintMapping();\n        mapping1.setPathSpec(\"/auth/*\");\n        mapping1.setConstraint(constraint1);\n\n        Constraint constraint2 = new Constraint();\n        constraint2.setAuthenticate(true);\n        constraint2.setName(\"admin\");\n        constraint2.setRoles(new String[]{\"administrator\"});\n        ConstraintMapping mapping2 = new ConstraintMapping();\n        mapping2.setPathSpec(\"/admin/*\");\n        mapping2.setConstraint(constraint2);\n        mapping2.setMethod(\"GET\");\n\n        Constraint constraint3 = new Constraint();\n        constraint3.setAuthenticate(false);\n        constraint3.setName(\"relax\");\n        ConstraintMapping mapping3 = new ConstraintMapping();\n        mapping3.setPathSpec(\"/admin/relax/*\");\n        mapping3.setConstraint(constraint3);\n\n        Constraint constraint4 = new Constraint();\n        constraint4.setAuthenticate(true);\n        constraint4.setName(\"loginpage\");\n        constraint4.setRoles(new String[]{\"administrator\"});\n        ConstraintMapping mapping4 = new ConstraintMapping();\n        mapping4.setPathSpec(\"/testLoginPage\");\n        mapping4.setConstraint(constraint4);\n\n        Constraint constraint5 = new Constraint();\n        constraint5.setAuthenticate(false);\n        constraint5.setName(\"allow forbidden POST\");\n        ConstraintMapping mapping5 = new ConstraintMapping();\n        mapping5.setPathSpec(\"/forbid/post\");\n        mapping5.setConstraint(constraint5);\n        mapping5.setMethod(\"POST\");\n\n        Constraint constraint6 = new Constraint();\n        constraint6.setAuthenticate(false);\n        constraint6.setName(\"data constraint\");\n        constraint6.setDataConstraint(2);\n        ConstraintMapping mapping6 = new ConstraintMapping();\n        mapping6.setPathSpec(\"/data/*\");\n        mapping6.setConstraint(constraint6);\n        \n        Set<String> knownRoles=new HashSet<String>();\n        knownRoles.add(\"user\");\n        knownRoles.add(\"administrator\");\n\n        _security.setConstraintMappings(Arrays.asList(new ConstraintMapping[]\n                {\n                        mapping0, mapping1, mapping2, mapping3, mapping4, mapping5,mapping6\n                }), knownRoles);\n    }","commit_id":"cada28e8cfc0d5b561829296977af8b29b84ad48","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Test\n    public void testStrictFormRedirect() throws Exception\n    {\n        _security.setAuthenticator(new FormAuthenticator(\"/testLoginPage\",\"/testErrorPage\",false));\n        _server.start();\n\n        String response;\n\n        response = _connector.getResponses(\"GET /ctx/noauth/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/forbid/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403 Forbidden\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.indexOf(\" 302 Found\") > 0);\n        assertTrue(response.indexOf(\"/ctx/testLoginPage\") > 0);\n\n        String session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 31\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user&j_password=wrong\\r\\n\");\n        assertTrue(response.indexOf(\"Location\") > 0);\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 35\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n\n\n        // log in again as user2\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"testLoginPage\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 36\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user2&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n\n\n        // log in again as admin\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\\r\\n\");\n//        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n//        assertTrue(response.indexOf(\"testLoginPage\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 36\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=admin&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n    }","id":37389,"modified_method":"@Test\n    public void testStrictFormRedirect() throws Exception\n    {\n        _security.setAuthenticator(new FormAuthenticator(\"/testLoginPage\",\"/testErrorPage\",false));\n        _server.start();\n\n        String response;\n\n        response = _connector.getResponses(\"GET /ctx/noauth/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/forbid/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403 Forbidden\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\nHost:wibble.com:8888\\r\\n\\r\\n\");\n        assertTrue(response.indexOf(\" 302 Found\") > 0);\n        assertTrue(response.indexOf(\"http://wibble.com:8888/ctx/testLoginPage\") > 0);\n\n        String session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 31\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user&j_password=wrong\\r\\n\");\n        assertTrue(response.indexOf(\"Location\") > 0);\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 35\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n\n\n        // log in again as user2\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"testLoginPage\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 36\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=user2&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 403\"));\n        assertTrue(response.indexOf(\"!role\") > 0);\n\n\n\n        // log in again as admin\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\\r\\n\");\n//        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n//        assertTrue(response.indexOf(\"testLoginPage\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"POST /ctx/j_security_check HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"Content-Type: application/x-www-form-urlencoded\\r\\n\" +\n                \"Content-Length: 36\\r\\n\" +\n                \"\\r\\n\" +\n                \"j_username=admin&j_password=password\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 302 \"));\n        assertTrue(response.indexOf(\"Location\") > 0);\n        assertTrue(response.indexOf(\"/ctx/auth/info\") > 0);\n        session = response.substring(response.indexOf(\"JSESSIONID=\") + 11, response.indexOf(\";Path=/ctx\"));\n\n        response = _connector.getResponses(\"GET /ctx/auth/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n\n        response = _connector.getResponses(\"GET /ctx/admin/info HTTP/1.0\\r\\n\" +\n                \"Cookie: JSESSIONID=\" + session + \"\\r\\n\" +\n                \"\\r\\n\");\n        assertTrue(response.startsWith(\"HTTP/1.1 200 OK\"));\n    }","commit_id":"cada28e8cfc0d5b561829296977af8b29b84ad48","url":"https://github.com/eclipse/jetty.project"},{"original_method":"public static void main(String... args) throws Exception\n    {\n        Server server = new Server();\n\n        ServletContextHandler context = new ServletContextHandler(server, \"/\",ServletContextHandler.SESSIONS);\n        context.setResourceBase(\"/tmp\");\n        context.addFilter(PushCacheFilter.class,\"/*\",EnumSet.of(DispatcherType.REQUEST));\n        context.addServlet(new ServletHolder(servlet), \"/test/*\");\n        context.addServlet(DefaultServlet.class, \"/\");\n        server.setHandler(context);\n\n\n        // HTTP Configuration\n        HttpConfiguration http_config = new HttpConfiguration();\n        http_config.setSecureScheme(\"https\");\n        http_config.setSecurePort(8443);\n        http_config.setSendXPoweredBy(true);\n        http_config.setSendServerVersion(true);\n\n        // HTTP connector\n        ServerConnector http = new ServerConnector(server,new HttpConnectionFactory(http_config));        \n        http.setPort(8080);\n        server.addConnector(http);\n \n        // SSL Context Factory for HTTPS and SPDY\n        String jetty_distro = System.getProperty(\"jetty.distro\",\"../../jetty-distribution/target/distribution\");\n        SslContextFactory sslContextFactory = new SslContextFactory();\n        sslContextFactory.setKeyStorePath(jetty_distro + \"/etc/keystore\");\n        sslContextFactory.setKeyStorePassword(\"OBF:1vny1zlo1x8e1vnw1vn61x8g1zlu1vn4\");\n        sslContextFactory.setKeyManagerPassword(\"OBF:1u2u1wml1z7s1z7a1wnl1u2g\");\n\n        // HTTPS Configuration\n        HttpConfiguration https_config = new HttpConfiguration(http_config);\n        https_config.addCustomizer(new SecureRequestCustomizer());\n        \n        \n        // HTTP2 factory\n        HTTP2ServerConnectionFactory h2 = new HTTP2ServerConnectionFactory(https_config);\n        \n        NegotiatingServerConnectionFactory.checkProtocolNegotiationAvailable();\n        ALPNServerConnectionFactory alpn =\n            new ALPNServerConnectionFactory(h2.getProtocol(),http.getDefaultProtocol());\n        alpn.setDefaultProtocol(http.getDefaultProtocol());\n        \n        // SSL Factory\n        SslConnectionFactory ssl = new SslConnectionFactory(sslContextFactory,alpn.getProtocol());\n        \n        // HTTP2 Connector\n        ServerConnector http2Connector = \n            new ServerConnector(server,ssl,alpn,h2,new HttpConnectionFactory(https_config));\n        http2Connector.setPort(8443);\n        server.addConnector(http2Connector);\n        \n        ALPN.debug=true;\n        \n        server.start();\n        server.dumpStdErr();\n        server.join();\n    }","id":37390,"modified_method":"public static void main(String... args) throws Exception\n    {\n        Server server = new Server();\n\n        ServletContextHandler context = new ServletContextHandler(server, \"/\",ServletContextHandler.SESSIONS);\n        context.setResourceBase(\"/tmp\");\n        context.addFilter(PushCacheFilter.class,\"/*\",EnumSet.of(DispatcherType.REQUEST))\n        .setInitParameter(\"ports\",\"443,6443,8443\");\n        context.addServlet(new ServletHolder(servlet), \"/test/*\");\n        context.addServlet(DefaultServlet.class, \"/\");\n        server.setHandler(context);\n\n\n        // HTTP Configuration\n        HttpConfiguration http_config = new HttpConfiguration();\n        http_config.setSecureScheme(\"https\");\n        http_config.setSecurePort(8443);\n        http_config.setSendXPoweredBy(true);\n        http_config.setSendServerVersion(true);\n\n        // HTTP connector\n        ServerConnector http = new ServerConnector(server,new HttpConnectionFactory(http_config));        \n        http.setPort(8080);\n        server.addConnector(http);\n \n        // SSL Context Factory for HTTPS and SPDY\n        String jetty_distro = System.getProperty(\"jetty.distro\",\"../../jetty-distribution/target/distribution\");\n        SslContextFactory sslContextFactory = new SslContextFactory();\n        sslContextFactory.setKeyStorePath(jetty_distro + \"/etc/keystore\");\n        sslContextFactory.setKeyStorePassword(\"OBF:1vny1zlo1x8e1vnw1vn61x8g1zlu1vn4\");\n        sslContextFactory.setKeyManagerPassword(\"OBF:1u2u1wml1z7s1z7a1wnl1u2g\");\n\n        // HTTPS Configuration\n        HttpConfiguration https_config = new HttpConfiguration(http_config);\n        https_config.addCustomizer(new SecureRequestCustomizer());\n        \n        \n        // HTTP2 factory\n        HTTP2ServerConnectionFactory h2 = new HTTP2ServerConnectionFactory(https_config);\n        \n        NegotiatingServerConnectionFactory.checkProtocolNegotiationAvailable();\n        ALPNServerConnectionFactory alpn =\n            new ALPNServerConnectionFactory(h2.getProtocol(),http.getDefaultProtocol());\n        alpn.setDefaultProtocol(http.getDefaultProtocol());\n        \n        // SSL Factory\n        SslConnectionFactory ssl = new SslConnectionFactory(sslContextFactory,alpn.getProtocol());\n        \n        // HTTP2 Connector\n        ServerConnector http2Connector = \n            new ServerConnector(server,ssl,alpn,h2,new HttpConnectionFactory(https_config));\n        http2Connector.setPort(8443);\n        server.addConnector(http2Connector);\n        \n        ALPN.debug=true;\n        \n        server.start();\n        server.dumpStdErr();\n        server.join();\n    }","commit_id":"a573430840e28c3d3a759cf2916e50f12fec91f1","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n    public void init(FilterConfig config) throws ServletException\n    {\n        String associatePeriod = config.getInitParameter(\"associatePeriod\");\n        if (associatePeriod != null)\n            _associatePeriod = Long.valueOf(associatePeriod);\n    }","id":37391,"modified_method":"@Override\n    public void init(FilterConfig config) throws ServletException\n    {\n        String associatePeriod = config.getInitParameter(\"associatePeriod\");\n        if (associatePeriod != null)\n            _associatePeriod = Long.valueOf(associatePeriod);\n\n        String renew=config.getInitParameter(\"renewPath\");\n        if (renew!=null)\n            _renewPath=renew;\n        \n        String hosts = config.getInitParameter(\"hosts\");\n        if (hosts!=null)\n            for (String h:hosts.split(\",\"))\n                _hosts.add(h);\n                \n        String ports = config.getInitParameter(\"ports\");\n        if (ports!=null)\n            for (String p:ports.split(\",\"))\n                _ports.add(Integer.parseInt(p));\n\n        if (LOG.isDebugEnabled())\n            LOG.debug(\"p={} renew={} hosts={} ports={}\",_associatePeriod,_renewPath,_hosts,_ports);\n    }","commit_id":"a573430840e28c3d3a759cf2916e50f12fec91f1","url":"https://github.com/eclipse/jetty.project"},{"original_method":"@Override\n    public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws IOException, ServletException\n    {\n        long now=System.nanoTime();\n        HttpServletRequest request = (HttpServletRequest)req;\n        \n        if (Boolean.TRUE==req.getAttribute(\"org.eclipse.jetty.pushed\"))\n        {\n            LOG.debug(\"PUSH {}\", request.getRequestURI());\n            chain.doFilter(req,resp);\n            return;\n        }\n\n        // Iterating over fields is more efficient than multiple gets\n        HttpFields fields = Request.getBaseRequest(req).getHttpFields();\n        boolean conditional = false;\n        String referrer = null;\n        loop: for (int i = 0; i < fields.size(); i++)\n        {\n            HttpField field = fields.getField(i);\n            HttpHeader header = field.getHeader();\n            if (header == null)\n                continue;\n\n            switch (header)\n            {\n                case IF_MATCH:\n                case IF_MODIFIED_SINCE:\n                case IF_NONE_MATCH:\n                case IF_UNMODIFIED_SINCE:\n                    conditional = true;\n                    break loop;\n\n                case REFERER:\n                    referrer = field.getValue();\n                    break;\n\n                default:\n                    break;\n            }\n        }\n\n        if (LOG.isDebugEnabled())\n            LOG.debug(\"{} {} referrer={} conditional={}\", request.getMethod(), request.getRequestURI(), referrer, conditional);\n\n        String path = URIUtil.addPaths(request.getServletPath(), request.getPathInfo());\n        if (path.endsWith(\"__renewPushCache__\"))\n        {\n            if (LOG.isDebugEnabled())\n                LOG.debug(\"Renew {}\", now);\n            _renew=now;\n        }\n\n        if (referrer != null)\n        {\n            HttpURI referrerURI = new HttpURI(referrer);\n            if (request.getServerName().equals(referrerURI.getHost()) &&\n                    request.getServerPort() == referrerURI.getPort())\n            {\n                String referrerPath = referrerURI.getPath();\n                if (referrerPath.startsWith(request.getContextPath()))\n                {\n                    String referrerPathNoContext = referrerPath.substring(request.getContextPath().length());\n                    PrimaryResource primaryResource = _cache.get(referrerPathNoContext);\n                    if (primaryResource != null)\n                    {\n                        long primaryTimestamp = primaryResource._timestamp.get();\n                        if (primaryTimestamp != 0)\n                        {\n                            RequestDispatcher dispatcher = request.getServletContext().getRequestDispatcher(path);\n                            if (now - primaryTimestamp < TimeUnit.MILLISECONDS.toNanos(_associatePeriod))\n                            {\n                                if (primaryResource._associated.putIfAbsent(path, dispatcher) == null)\n                                {\n                                    if (LOG.isDebugEnabled())\n                                        LOG.debug(\"Associated {} -> {}\", referrerPathNoContext, dispatcher);\n                                }\n                            }\n                            else\n                            {\n                                if (LOG.isDebugEnabled())\n                                    LOG.debug(\"Not associated {} -> {}, outside associate period of {}ms\", referrerPathNoContext, dispatcher, _associatePeriod);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        // Push some resources?\n        PrimaryResource primaryResource = _cache.get(path);\n        if (primaryResource == null)\n        {\n            PrimaryResource t = new PrimaryResource();\n            primaryResource = _cache.putIfAbsent(path, t);\n            primaryResource = primaryResource == null ? t : primaryResource;\n            primaryResource._timestamp.compareAndSet(0, now);\n            if (LOG.isDebugEnabled())\n                LOG.debug(\"Cached {}\", path);\n        }\n        else \n        {\n            long last=primaryResource._timestamp.get();\n            if (last<_renew && primaryResource._timestamp.compareAndSet(last, now))\n            {\n                primaryResource._associated.clear();\n                if (LOG.isDebugEnabled())\n                    LOG.debug(\"Clear associated {}\", path);\n            }\n        }\n\n        // Push associated for non conditional\n        if (!conditional && !primaryResource._associated.isEmpty())\n        {\n            for (RequestDispatcher dispatcher : primaryResource._associated.values())\n            {\n                if (LOG.isDebugEnabled())\n                    LOG.debug(\"Pushing {} <- {}\", dispatcher, path);\n                ((Dispatcher)dispatcher).push(request);\n            }\n        }\n\n        chain.doFilter(req, resp);\n    }","id":37392,"modified_method":"@Override\n    public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws IOException, ServletException\n    {\n        long now=System.nanoTime();\n        HttpServletRequest request = (HttpServletRequest)req;\n        \n        if (Boolean.TRUE==req.getAttribute(\"org.eclipse.jetty.pushed\"))\n        {\n            if (LOG.isDebugEnabled())\n                    LOG.debug(\"PUSH {}\", request.getRequestURI());\n            chain.doFilter(req,resp);\n            return;\n        }\n\n        // Iterating over fields is more efficient than multiple gets\n        HttpFields fields = Request.getBaseRequest(req).getHttpFields();\n        boolean conditional = false;\n        String referrer = null;\n        loop: for (int i = 0; i < fields.size(); i++)\n        {\n            HttpField field = fields.getField(i);\n            HttpHeader header = field.getHeader();\n            if (header == null)\n                continue;\n\n            switch (header)\n            {\n                case IF_MATCH:\n                case IF_MODIFIED_SINCE:\n                case IF_NONE_MATCH:\n                case IF_UNMODIFIED_SINCE:\n                    conditional = true;\n                    break loop;\n\n                case REFERER:\n                    referrer = field.getValue();\n                    break;\n\n                default:\n                    break;\n            }\n        }\n\n        if (LOG.isDebugEnabled())\n            LOG.debug(\"{} {} referrer={} conditional={}\", request.getMethod(), request.getRequestURI(), referrer, conditional);\n\n        String path = URIUtil.addPaths(request.getServletPath(), request.getPathInfo());\n        if (path.endsWith(_renewPath))\n        {\n            if (LOG.isDebugEnabled())\n                LOG.debug(\"Renew {}\", now);\n            _renew=now;\n            resp.getOutputStream().print(\"PUSH CACHE RESET\");\n            resp.flushBuffer();\n            return;\n        }\n\n        if (referrer != null)\n        {\n            HttpURI referrerURI = new HttpURI(referrer);\n            String host=referrerURI.getHost();\n            int port=referrerURI.getPort();\n            if (port<=0)\n                port=request.isSecure()?443:80;\n                        \n            boolean referred_from_here=(_hosts.size()>0 )?_hosts.contains(host):request.getServerName().equals(host);\n            referred_from_here&=(_ports.size()>0)?_ports.contains(port):port==request.getServerPort();\n            \n            if (referred_from_here)\n            {\n                String referrerPath = referrerURI.getPath();\n                if (referrerPath.startsWith(request.getContextPath()))\n                {\n                    String referrerPathNoContext = referrerPath.substring(request.getContextPath().length());\n                    PrimaryResource primaryResource = _cache.get(referrerPathNoContext);\n                    if (primaryResource != null)\n                    {\n                        long primaryTimestamp = primaryResource._timestamp.get();\n                        if (primaryTimestamp != 0)\n                        {\n                            RequestDispatcher dispatcher = request.getServletContext().getRequestDispatcher(path);\n                            if (now - primaryTimestamp < TimeUnit.MILLISECONDS.toNanos(_associatePeriod))\n                            {\n                                if (primaryResource._associated.putIfAbsent(path, dispatcher) == null)\n                                {\n                                    if (LOG.isDebugEnabled())\n                                        LOG.debug(\"Associated {} -> {}\", referrerPathNoContext, dispatcher);\n                                }\n                            }\n                            else\n                            {\n                                if (LOG.isDebugEnabled())\n                                    LOG.debug(\"Not associated {} -> {}, outside associate period of {}ms\", referrerPathNoContext, dispatcher, _associatePeriod);\n                            }\n                        }\n                    }\n                }\n            }\n            else\n            {\n                if (LOG.isDebugEnabled())\n                    LOG.debug(\"External referrer {}\", referrer);\n            }\n        }\n\n        // Push some resources?\n        PrimaryResource primaryResource = _cache.get(path);\n        if (primaryResource == null)\n        {\n            PrimaryResource t = new PrimaryResource();\n            primaryResource = _cache.putIfAbsent(path, t);\n            primaryResource = primaryResource == null ? t : primaryResource;\n            primaryResource._timestamp.compareAndSet(0, now);\n            if (LOG.isDebugEnabled())\n                LOG.debug(\"Cached {}\", path);\n        }\n        else \n        {\n            long last=primaryResource._timestamp.get();\n            if (last<_renew && primaryResource._timestamp.compareAndSet(last, now))\n            {\n                primaryResource._associated.clear();\n                if (LOG.isDebugEnabled())\n                    LOG.debug(\"Clear associated {}\", path);\n            }\n        }\n\n        // Push associated for non conditional\n        if (!conditional && !primaryResource._associated.isEmpty())\n        {\n            for (RequestDispatcher dispatcher : primaryResource._associated.values())\n            {\n                if (LOG.isDebugEnabled())\n                    LOG.debug(\"Pushing {} <- {}\", dispatcher, path);\n                ((Dispatcher)dispatcher).push(request);\n            }\n        }\n\n        chain.doFilter(req, resp);\n    }","commit_id":"a573430840e28c3d3a759cf2916e50f12fec91f1","url":"https://github.com/eclipse/jetty.project"},{"original_method":"private String extractHostPath(HttpServletRequest request) {\n        final StringBuilder myHostName = new StringBuilder(request.getServerName());\n\n        if (request.getServerPort() != DEFAULT_HTTP_PORT) {\n            myHostName.append(\":\").append(request.getServerPort());\n        }\n\n        return myHostName.append(request.getContextPath()).toString();\n    }","id":37393,"modified_method":"private String extractHostPath(HttpServletRequest request) {\n        final StringBuilder myHostName = new StringBuilder(request.getScheme()).append(\"://\").append(request.getServerName());\n\n        if (request.getServerPort() != DEFAULT_HTTP_PORT) {\n            myHostName.append(\":\").append(request.getServerPort());\n        }\n\n        return myHostName.append(request.getContextPath()).toString();\n    }","commit_id":"e2ebcc0a5eb5b2e60951242db506ed258198e3ba","url":"https://github.com/rackerlabs/repose"},{"original_method":"DaughterOpener(final Server s, final RegionServerServices services,\n        final HRegion r) {\n      super(s.getServerName() + \"-daughterOpener=\" + r.getRegionInfo().getEncodedName());\n      setDaemon(true);\n      this.services = services;\n      this.server = s;\n      this.r = r;\n    }","id":37394,"modified_method":"DaughterOpener(final Server s, final RegionServerServices services,\n        final HRegion r) {\n      super((s == null? \"null-services\": s.getServerName()) +\n        \"-daughterOpener=\" + r.getRegionInfo().getEncodedName());\n      setDaemon(true);\n      this.services = services;\n      this.server = s;\n      this.r = r;\n    }","commit_id":"f54803aac22aace1cea3d8d787cd36792aff18b1","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Open daughter regions, add them to online list and update meta.\n   * @param server\n   * @param services Can be null when testing.\n   * @param daughter\n   * @throws IOException\n   * @throws KeeperException\n   */\n  void openDaughterRegion(final Server server,\n      final RegionServerServices services, final HRegion daughter)\n  throws IOException, KeeperException {\n    boolean stopping = services != null && services.isStopping();\n    if (server.isStopped() || stopping) {\n      MetaEditor.addDaughter(server.getCatalogTracker(),\n        daughter.getRegionInfo(), null);\n      LOG.info(\"Not opening daughter \" +\n        daughter.getRegionInfo().getRegionNameAsString() +\n        \" because stopping=\" + stopping + \", stopped=\" + server.isStopped());\n      return;\n    }\n    HRegionInfo hri = daughter.getRegionInfo();\n    LoggingProgressable reporter =\n      new LoggingProgressable(hri, server.getConfiguration());\n    HRegion r = daughter.openHRegion(reporter);\n    if (services != null) {\n      services.postOpenDeployTasks(r, server.getCatalogTracker(), true);\n    }\n  }","id":37395,"modified_method":"/**\n   * Open daughter regions, add them to online list and update meta.\n   * @param server\n   * @param services Can be null when testing.\n   * @param daughter\n   * @throws IOException\n   * @throws KeeperException\n   */\n  void openDaughterRegion(final Server server,\n      final RegionServerServices services, final HRegion daughter)\n  throws IOException, KeeperException {\n    boolean stopped = server != null && server.isStopped();\n    boolean stopping = services != null && services.isStopping();\n    if (stopped || stopping) {\n      MetaEditor.addDaughter(server.getCatalogTracker(),\n        daughter.getRegionInfo(), null);\n      LOG.info(\"Not opening daughter \" +\n        daughter.getRegionInfo().getRegionNameAsString() +\n        \" because stopping=\" + stopping + \", stopped=\" + server.isStopped());\n      return;\n    }\n    HRegionInfo hri = daughter.getRegionInfo();\n    LoggingProgressable reporter = server == null? null:\n      new LoggingProgressable(hri, server.getConfiguration());\n    HRegion r = daughter.openHRegion(reporter);\n    if (services != null) {\n      services.postOpenDeployTasks(r, server.getCatalogTracker(), true);\n    }\n  }","commit_id":"f54803aac22aace1cea3d8d787cd36792aff18b1","url":"https://github.com/apache/hbase"},{"original_method":"@Test(timeout = 300000)\n  public void testDisallowWritesInRecovering() throws Exception {\n    LOG.info(\"testDisallowWritesInRecovering\");\n    Configuration curConf = HBaseConfiguration.create();\n    curConf.setBoolean(HConstants.DISTRIBUTED_LOG_REPLAY_KEY, true);\n    curConf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);\n    curConf.setBoolean(HConstants.DISALLOW_WRITES_IN_RECOVERING, true);\n    startCluster(NUM_RS, curConf);\n    final int NUM_REGIONS_TO_CREATE = 40;\n    final int NUM_LOG_LINES = 30000;\n    // turn off load balancing to prevent regions from moving around otherwise\n    // they will consume recovered.edits\n    master.balanceSwitch(false);\n\n    List<RegionServerThread> rsts = cluster.getLiveRegionServerThreads();\n    final ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, \"table-creation\", null);\n    HTable ht = installTable(zkw, \"table\", \"family\", NUM_REGIONS_TO_CREATE);\n\n    HRegionServer hrs = findRSToKill(false, \"table\");\n    List<HRegionInfo> regions = ProtobufUtil.getOnlineRegions(hrs);\n    makeHLog(hrs.getWAL(), regions, \"table\", \"family\", NUM_LOG_LINES, 100);\n    \n    // abort RS\n    LOG.info(\"Aborting region server: \" + hrs.getServerName());\n    hrs.abort(\"testing\");\n    \n    // wait for abort completes\n    TEST_UTIL.waitFor(120000, 200, new Waiter.Predicate<Exception>() {\n      @Override\n      public boolean evaluate() throws Exception {\n        return (cluster.getLiveRegionServerThreads().size() <= (NUM_RS - 1));\n      }\n    });\n    \n    // wait for regions come online\n    TEST_UTIL.waitFor(180000, 100, new Waiter.Predicate<Exception>() {\n      @Override\n      public boolean evaluate() throws Exception {\n        return (getAllOnlineRegions(cluster).size() >= (NUM_REGIONS_TO_CREATE + 1));\n      }\n    });\n\n    try {\n      HRegionInfo region = regions.get(0);\n      byte[] key = region.getStartKey();\n      if (key == null || key.length == 0) {\n        key = new byte[] { 0, 0, 0, 0, 1 };\n      }\n      ht.setAutoFlush(true);\n      Put put = new Put(key);\n      put.add(Bytes.toBytes(\"family\"), Bytes.toBytes(\"c1\"), new byte[]{'b'});\n      ht.put(put);\n    } catch (IOException ioe) {\n      Assert.assertTrue(ioe instanceof RetriesExhaustedWithDetailsException);\n      RetriesExhaustedWithDetailsException re = (RetriesExhaustedWithDetailsException) ioe;\n      boolean foundRegionInRecoveryException = false;\n      for (Throwable t : re.getCauses()) {\n        if (t instanceof RegionInRecoveryException) {\n          foundRegionInRecoveryException = true;\n          break;\n        }\n      }\n      Assert.assertTrue(\n        \"No RegionInRecoveryException. Following exceptions returned=\" + re.getCauses(),\n        foundRegionInRecoveryException);\n    }\n\n    ht.close();\n    zkw.close();\n  }","id":37396,"modified_method":"@Test(timeout = 300000)\n  public void testDisallowWritesInRecovering() throws Exception {\n    LOG.info(\"testDisallowWritesInRecovering\");\n    Configuration curConf = HBaseConfiguration.create();\n    curConf.setBoolean(HConstants.DISTRIBUTED_LOG_REPLAY_KEY, true);\n    curConf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);\n    curConf.setBoolean(HConstants.DISALLOW_WRITES_IN_RECOVERING, true);\n    startCluster(NUM_RS, curConf);\n    final int NUM_REGIONS_TO_CREATE = 40;\n    // turn off load balancing to prevent regions from moving around otherwise\n    // they will consume recovered.edits\n    master.balanceSwitch(false);\n\n    List<RegionServerThread> rsts = cluster.getLiveRegionServerThreads();\n    final ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, \"table-creation\", null);\n    HTable ht = installTable(zkw, \"table\", \"family\", NUM_REGIONS_TO_CREATE);\n    final SplitLogManager slm = master.getMasterFileSystem().splitLogManager;\n\n    Set<HRegionInfo> regionSet = new HashSet<HRegionInfo>();\n    HRegionInfo region = null;\n    HRegionServer hrs = null;\n    HRegionServer dstRS = null;\n    for (int i = 0; i < NUM_RS; i++) {\n      hrs = rsts.get(i).getRegionServer();\n      List<HRegionInfo> regions = ProtobufUtil.getOnlineRegions(hrs);\n      if (regions.isEmpty()) continue;\n      region = regions.get(0);\n      regionSet.add(region);\n      dstRS = rsts.get((i+1) % NUM_RS).getRegionServer();\n      break;\n    }\n    \n    slm.markRegionsRecoveringInZK(hrs.getServerName(), regionSet);\n    // move region in order for the region opened in recovering state\n    final HRegionInfo hri = region;\n    final HRegionServer tmpRS = dstRS;\n    TEST_UTIL.getHBaseAdmin().move(region.getEncodedNameAsBytes(),\n      Bytes.toBytes(dstRS.getServerName().getServerName()));\n    // wait for region move completes\n    final RegionStates regionStates =\n        TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getRegionStates();\n    TEST_UTIL.waitFor(45000, 200, new Waiter.Predicate<Exception>() {\n      @Override\n      public boolean evaluate() throws Exception {\n        ServerName sn = regionStates.getRegionServerOfRegion(hri);\n        return (sn != null && sn.equals(tmpRS.getServerName()));\n      }\n    });\n    \n    try {\n      byte[] key = region.getStartKey();\n      if (key == null || key.length == 0) {\n        key = new byte[] { 0, 0, 0, 0, 1 };\n      }\n      ht.setAutoFlush(true);\n      Put put = new Put(key);\n      put.add(Bytes.toBytes(\"family\"), Bytes.toBytes(\"c1\"), new byte[]{'b'});\n      ht.put(put);\n    } catch (IOException ioe) {\n      Assert.assertTrue(ioe instanceof RetriesExhaustedWithDetailsException);\n      RetriesExhaustedWithDetailsException re = (RetriesExhaustedWithDetailsException) ioe;\n      boolean foundRegionInRecoveryException = false;\n      for (Throwable t : re.getCauses()) {\n        if (t instanceof RegionInRecoveryException) {\n          foundRegionInRecoveryException = true;\n          break;\n        }\n      }\n      Assert.assertTrue(\n        \"No RegionInRecoveryException. Following exceptions returned=\" + re.getCauses(),\n        foundRegionInRecoveryException);\n    }\n\n    ht.close();\n    zkw.close();\n  }","commit_id":"568bff83268df2b2fa98b9627c79e53619c7702d","url":"https://github.com/apache/hbase"},{"original_method":"private static HttpServletRequest getCurrentRequest() {\n\t\tRequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n\t\tAssert.state(requestAttributes != null, \"Could not find current request via RequestContextHolder\");\n\t\tAssert.isInstanceOf(ServletRequestAttributes.class, requestAttributes);\n\t\tHttpServletRequest servletRequest = ((ServletRequestAttributes) requestAttributes).getRequest();\n\t\tAssert.state(servletRequest != null, \"Could not find current HttpServletRequest\");\n\t\treturn servletRequest;\n\t}","id":37397,"modified_method":"/**\n\t * Obtain the request through {@link RequestContextHolder}.\n\t */\n\tprotected static HttpServletRequest getCurrentRequest() {\n\t\tRequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n\t\tAssert.state(requestAttributes != null, \"Could not find current request via RequestContextHolder\");\n\t\tAssert.isInstanceOf(ServletRequestAttributes.class, requestAttributes);\n\t\tHttpServletRequest servletRequest = ((ServletRequestAttributes) requestAttributes).getRequest();\n\t\tAssert.state(servletRequest != null, \"Could not find current HttpServletRequest\");\n\t\treturn servletRequest;\n\t}","commit_id":"153508a300772db262c6123f57fbc4bcbf89b4f4","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Prepare a builder by copying the scheme, host, port, path, and\n\t * query string of an HttpServletRequest.\n\t */\n\tpublic static ServletUriComponentsBuilder fromRequest(HttpServletRequest request) {\n\t\tString scheme = request.getScheme();\n\t\tint port = request.getServerPort();\n\n\t\tServletUriComponentsBuilder builder = new ServletUriComponentsBuilder();\n\t\tbuilder.scheme(scheme);\n\t\tbuilder.host(request.getServerName());\n\t\tif ((scheme.equals(\"http\") && port != 80) || (scheme.equals(\"https\") && port != 443)) {\n\t\t\tbuilder.port(port);\n\t\t}\n\t\tbuilder.path(request.getRequestURI());\n\t\tbuilder.query(request.getQueryString());\n\t\treturn builder;\n\t}","id":37398,"modified_method":"/**\n\t * Prepare a builder by copying the scheme, host, port, path, and\n\t * query string of an HttpServletRequest.\n\t */\n\tpublic static ServletUriComponentsBuilder fromRequest(HttpServletRequest request) {\n\t\tString scheme = request.getScheme();\n\t\tint port = request.getServerPort();\n\n\t\tString header = request.getHeader(\"X-Forwarded-Host\");\n\t\tString host = StringUtils.hasText(header) ? header: request.getServerName();\n\n\t\tServletUriComponentsBuilder builder = new ServletUriComponentsBuilder();\n\t\tbuilder.scheme(scheme);\n\t\tbuilder.host(host);\n\t\tif ((scheme.equals(\"http\") && port != 80) || (scheme.equals(\"https\") && port != 443)) {\n\t\t\tbuilder.port(port);\n\t\t}\n\t\tbuilder.path(request.getRequestURI());\n\t\tbuilder.query(request.getQueryString());\n\t\treturn builder;\n\t}","commit_id":"153508a300772db262c6123f57fbc4bcbf89b4f4","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public void start( ) {\n    this.getServiceEndpoint( ).start( );\n    ListenerRegistry.getInstance( ).register( ClockTick.class, this );\n    ListenerRegistry.getInstance( ).register( Hertz.class, this );\n  }","id":37399,"modified_method":"public void start( ) {\n    Clusters.getInstance( ).register( this );\n    this.getServiceEndpoint( ).start( );\n    ListenerRegistry.getInstance( ).register( ClockTick.class, this );\n    ListenerRegistry.getInstance( ).register( Hertz.class, this );\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"/**\n   * @param msgClass\n   * @param nextState\n   * @return\n   */\n  private TransitionAction<Cluster> newRefresh( final Class msgClass ) {\n    return new TransitionAction<Cluster>( ) {\n      private final SubjectRemoteCallbackFactory<RemoteCallback, Cluster> factory = Callbacks.newSubjectMessageFactory( msgClass, Cluster.this );\n      \n      @Override\n      public final void leave( final Cluster parent, final Callback.Completion transitionCallback ) {\n        Callback.Completion cb = new Callback.Completion( ) {\n          \n          @Override\n          public void fire( ) {\n            transitionCallback.fire( );\n          }\n          \n          @Override\n          public void fireException( Throwable t ) {\n            if ( t instanceof FailedRequestException ) {\n              if ( Cluster.this.getState( ).hasPublicAddressing( ) && PublicAddressStateCallback.class.isAssignableFrom( msgClass ) ) {\n                transitionCallback.fire( );\n              } else {\n                transitionCallback.fireException( t );\n              }\n            } else {\n              transitionCallback.fireException( t );\n            }\n          }\n        };\n        //TODO: retry.\n        try {\n          if ( ClusterLogMessageCallback.class.isAssignableFrom( msgClass ) ) {\n            Callbacks.newRequest( factory.newInstance( ) ).then( cb )\n                     .execute( parent.getServiceEndpoint( ), com.eucalyptus.component.id.Cluster.getLogClientPipeline( ) )\n                     .getResponse( ).get( );\n          } else {\n            Callbacks.newRequest( factory.newInstance( ) ).then( cb ).sendSync( parent.getServiceEndpoint( ) );\n          }\n        } catch ( ExecutionException e ) {\n          if ( e.getCause( ) instanceof FailedRequestException ) {\n            LOG.error( e.getCause( ).getMessage( ) );\n          } else if ( e.getCause( ) instanceof ConnectionException || e.getCause( ) instanceof IOException ) {\n            //REVIEW: this is LOG.error( parent.getName( ) + \": Error communicating with cluster: \" + e.getCause( ).getMessage( ) ); \n          } else {\n            LOG.error( e, e );\n          }\n        } catch ( InterruptedException e ) {\n          LOG.error( e, e );\n        }\n      }\n    };\n  }","id":37400,"modified_method":"/**\n   * @param msgClass\n   * @param nextState\n   * @return\n   */\n  private TransitionAction<Cluster> newRefresh( final Class msgClass ) {\n    return new TransitionAction<Cluster>( ) {\n      private final SubjectRemoteCallbackFactory<RemoteCallback, Cluster> factory = Callbacks.newSubjectMessageFactory( msgClass, Cluster.this );\n      \n      @Override\n      public final void leave( final Cluster parent, final Callback.Completion transitionCallback ) {\n        Callback.Completion cb = new Callback.Completion( ) {\n          \n          @Override\n          public void fire( ) {\n            transitionCallback.fire( );\n          }\n          \n          @Override\n          public void fireException( Throwable t ) {\n            if ( t instanceof FailedRequestException ) {\n              if ( Cluster.this.getState( ).hasPublicAddressing( ) && PublicAddressStateCallback.class.isAssignableFrom( msgClass ) ) {\n                transitionCallback.fire( );\n              } else {\n                transitionCallback.fireException( t );\n              }\n            } else {\n              transitionCallback.fireException( t );\n            }\n          }\n        };\n        //TODO: retry.\n        try {\n          if ( ClusterLogMessageCallback.class.isAssignableFrom( msgClass ) ) {\n            Callbacks.newRequest( this.factory.newInstance( ) ).then( cb )\n                     .execute( parent.getServiceEndpoint( ), com.eucalyptus.component.id.Cluster.getLogClientPipeline( ) )\n                     .getResponse( ).get( );\n          } else {\n            Callbacks.newRequest( this.factory.newInstance( ) ).then( cb ).sendSync( parent.getServiceEndpoint( ) );\n          }\n        } catch ( ExecutionException e ) {\n          if ( e.getCause( ) instanceof FailedRequestException ) {\n            LOG.error( e.getCause( ).getMessage( ) );\n          } else if ( e.getCause( ) instanceof ConnectionException || e.getCause( ) instanceof IOException ) {\n            //REVIEW: this is LOG.error( parent.getName( ) + \": Error communicating with cluster: \" + e.getCause( ).getMessage( ) ); \n          } else {\n            LOG.error( e, e );\n          }\n        } catch ( InterruptedException e ) {\n          LOG.error( e, e );\n        }\n      }\n    };\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public ClusterState getState( ) {\n    return state;\n  }","id":37401,"modified_method":"public ClusterState getState( ) {\n    return this.state;\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public ClusterConfiguration getConfiguration( ) {\n    return configuration;\n  }","id":37402,"modified_method":"public ClusterConfiguration getConfiguration( ) {\n    return this.configuration;\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public ClusterNodeState getNodeState( ) {\n    return nodeState;\n  }","id":37403,"modified_method":"public ClusterNodeState getNodeState( ) {\n    return this.nodeState;\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public boolean equals( Object obj ) {\n    if ( this == obj ) return true;\n    if ( obj == null ) return false;\n    if ( getClass( ) != obj.getClass( ) ) return false;\n    Cluster other = ( Cluster ) obj;\n    if ( configuration == null ) {\n      if ( other.configuration != null ) return false;\n    } else if ( !configuration.equals( other.configuration ) ) return false;\n    if ( state == null ) {\n      if ( other.state != null ) return false;\n    } else if ( !state.equals( other.state ) ) return false;\n    return true;\n  }","id":37404,"modified_method":"@Override\n  public boolean equals( Object obj ) {\n    if ( this == obj ) return true;\n    if ( obj == null ) return false;\n    if ( getClass( ) != obj.getClass( ) ) return false;\n    Cluster other = ( Cluster ) obj;\n    if ( this.configuration == null ) {\n      if ( other.configuration != null ) return false;\n    } else if ( !this.configuration.equals( other.configuration ) ) return false;\n    if ( this.state == null ) {\n      if ( other.state != null ) return false;\n    } else if ( !this.state.equals( other.state ) ) return false;\n    return true;\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public void stop( ) {\n    ListenerRegistry.getInstance( ).deregister( ClockTick.class, this );\n    ListenerRegistry.getInstance( ).deregister( Hertz.class, this );\n    this.getServiceEndpoint( ).stop( );\n  }","id":37405,"modified_method":"public void stop( ) {\n    ListenerRegistry.getInstance( ).deregister( Hertz.class, this );\n    ListenerRegistry.getInstance( ).deregister( ClockTick.class, this );\n    this.getServiceEndpoint( ).stop( );\n    Clusters.getInstance( ).registerDisabled( this );\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public String getUri( ) {\n    return configuration.getUri( );\n  }","id":37406,"modified_method":"public String getUri( ) {\n    return this.configuration.getUri( );\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public int hashCode( ) {\n    final int prime = 31;\n    int result = 1;\n    result = prime * result + ( ( configuration == null )\n      ? 0\n      : configuration.hashCode( ) );\n    result = prime * result + ( ( state == null )\n      ? 0\n      : state.hashCode( ) );\n    return result;\n  }","id":37407,"modified_method":"@Override\n  public int hashCode( ) {\n    final int prime = 31;\n    int result = 1;\n    result = prime * result + ( ( this.configuration == null )\n      ? 0\n    : this.configuration.hashCode( ) );\n    result = prime * result + ( ( this.state == null )\n      ? 0\n      : this.state.hashCode( ) );\n    return result;\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public void fireDisable( ServiceConfiguration config ) throws ServiceRegistrationException {\n    LOG.info( \"Disabling cluster: \" + config );\n    EventRecord.here( ClusterBuilder.class, EventType.COMPONENT_SERVICE_DISABLED, config.getComponentId( ).name( ), config.getName( ), config.getUri( ) ).info( );\n    try {\n      if ( Components.lookup( Eucalyptus.class ).isLocal( ) ) {\n        if ( Clusters.getInstance( ).contains( config.getName( ) ) ) {\n          try {\n            Cluster newCluster = Clusters.getInstance( ).lookup( config.getName( ) );\n            Clusters.getInstance( ).disable( newCluster.getName( ) );\n            newCluster.stop( );\n          } catch ( NoSuchElementException ex ) {\n            Cluster newCluster = Clusters.getInstance( ).lookupDisabled( config.getName( ) );\n            newCluster.stop( );\n          }\n        }\n      }\n      super.fireDisable( config );\n    } catch ( NoSuchElementException ex ) {\n      LOG.error( ex, ex );\n    }\n  }","id":37408,"modified_method":"@Override\n  public void fireDisable( ServiceConfiguration config ) throws ServiceRegistrationException {\n    LOG.info( \"Disabling cluster: \" + config );\n    EventRecord.here( ClusterBuilder.class, EventType.COMPONENT_SERVICE_DISABLED, config.getComponentId( ).name( ), config.getName( ), config.getUri( ) ).info( );\n    try {\n      if ( Components.lookup( Eucalyptus.class ).isLocal( ) ) {\n        if ( Clusters.getInstance( ).contains( config.getName( ) ) ) {\n          try {\n            Cluster newCluster = Clusters.getInstance( ).lookup( config.getName( ) );\n            newCluster.stop( );\n          } catch ( NoSuchElementException ex ) {\n            Cluster newCluster = Clusters.getInstance( ).lookupDisabled( config.getName( ) );\n            newCluster.stop( );\n          }\n        }\n      }\n      super.fireDisable( config );\n    } catch ( NoSuchElementException ex ) {\n      LOG.error( ex, ex );\n    }\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n  public void fireEnable( ServiceConfiguration config ) throws ServiceRegistrationException {\n    LOG.info( \"Enabling cluster: \" + config );\n    EventRecord.here( ClusterBuilder.class, EventType.COMPONENT_SERVICE_ENABLED, config.getComponentId( ).name( ), config.getName( ), config.getUri( ) ).info( );\n    try {\n      if ( Components.lookup( Eucalyptus.class ).isLocal( ) ) {\n        if ( !Clusters.getInstance( ).contains( config.getName( ) ) ) {\n          Cluster newCluster = new Cluster( ( ClusterConfiguration ) config );//TODO:GRZE:fix the type issue here.\n          Clusters.getInstance( ).register( newCluster );\n          newCluster.start( );\n        } else {\n          try {\n            Cluster newCluster = Clusters.getInstance( ).lookup( config.getName( ) );\n          } catch ( NoSuchElementException ex ) {\n            Cluster newCluster = Clusters.getInstance( ).lookupDisabled( config.getName( ) );\n            Clusters.getInstance( ).enable( newCluster.getName( ) );\n            newCluster.start( );\n          }\n        }\n      }\n      super.fireEnable( config );\n    } catch ( NoSuchElementException ex ) {\n      LOG.error( ex, ex );\n    }\n    \n  }","id":37409,"modified_method":"@Override\n  public void fireEnable( ServiceConfiguration config ) throws ServiceRegistrationException {\n    LOG.info( \"Enabling cluster: \" + config );\n    EventRecord.here( ClusterBuilder.class, EventType.COMPONENT_SERVICE_ENABLED, config.getComponentId( ).name( ), config.getName( ), config.getUri( ) ).info( );\n    try {\n      if ( Components.lookup( Eucalyptus.class ).isLocal( ) ) {\n        if ( !Clusters.getInstance( ).contains( config.getName( ) ) ) {\n          Cluster newCluster = new Cluster( ( ClusterConfiguration ) config );//TODO:GRZE:fix the type issue here.\n          newCluster.start( );\n        } else {\n          try {\n            Cluster newCluster = Clusters.getInstance( ).lookup( config.getName( ) );\n          } catch ( NoSuchElementException ex ) {\n            Cluster newCluster = Clusters.getInstance( ).lookupDisabled( config.getName( ) );\n            newCluster.start( );\n          }\n        }\n      }\n      super.fireEnable( config );\n    } catch ( NoSuchElementException ex ) {\n      LOG.error( ex, ex );\n    }\n    \n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"public boolean init( ) throws Exception {\n    try {\n      LogLevels.EXTREME = \"EXTREME\".equals( System.getProperty( \"euca.log.level\" ).toUpperCase( ) );\n      LogLevels.TRACE = \"TRACE\".equals( System.getProperty( \"euca.log.level\" ) ) || LogLevels.EXTREME;\n      LogLevels.DEBUG = \"DEBUG\".equals( System.getProperty( \"euca.log.level\" ) ) || LogLevels.TRACE;\n      if ( LogLevels.EXTREME ) {\n        System.setProperty( \"euca.log.level\", \"TRACE\" );\n      }\n      System.setOut( new PrintStream( System.out ) {\n        public void print( final String string ) {\n          if ( string.replaceAll( \"\\\\s*\", \"\" ).length( ) > 2 ) {\n//            SystemBootstrapper.out.println( string );\n            EventRecord.caller( SystemBootstrapper.class, EventType.STDOUT, string ).info( );\n          }\n        }\n      }\n            );\n      System.setErr( new PrintStream( System.err ) {\n        public void print( final String string ) {\n          if ( string.replaceAll( \"\\\\s*\", \"\" ).length( ) > 2 ) {\n//            SystemBootstrapper.err.println( string );\n            EventRecord.caller( SystemBootstrapper.class, EventType.STDERR, string ).error( );\n          }\n        }\n      }\n            );\n      LOG.info( LogUtil.subheader( \"Starting system with debugging set as: \" + Join.join( \"\\n\", LogLevels.class.getDeclaredFields( ) ) ) );\n      Security.addProvider( new BouncyCastleProvider( ) );\n      System.setProperty( \"euca.ws.port\", \"8773\" );\n    } catch ( Throwable t ) {\n      t.printStackTrace( );\n      System.exit( 1 );\n    }\n    try {\n      Bootstrap.initialize( );\n      Bootstrap.Stage stage = Bootstrap.transition( );\n      stage.load( );\n      return true;\n    } catch ( BootstrapException e ) {\n      e.printStackTrace( );\n      throw e;\n    } catch ( Throwable t ) {\n      t.printStackTrace( );\n      LOG.fatal( t, t );\n      System.exit( 1 );\n      return false;\n    }\n  }","id":37410,"modified_method":"public boolean init( ) throws Exception {\n    try {\n      LogLevels.EXTREME = \"EXTREME\".equals( System.getProperty( \"euca.log.level\" ).toUpperCase( ) );\n      LogLevels.TRACE = \"TRACE\".equals( System.getProperty( \"euca.log.level\" ) ) || LogLevels.EXTREME;\n      LogLevels.DEBUG = \"DEBUG\".equals( System.getProperty( \"euca.log.level\" ) ) || LogLevels.TRACE;\n      if ( LogLevels.EXTREME ) {\n        System.setProperty( \"euca.log.level\", \"TRACE\" );\n      }\n      System.setOut( new PrintStream( System.out ) {\n        public void print( final String string ) {\n          if ( string.replaceAll( \"\\\\s*\", \"\" ).length( ) > 2 ) {\n//            SystemBootstrapper.out.println( string );\n            EventRecord.caller( SystemBootstrapper.class, EventType.STDOUT, string ).info( );\n          }\n        }\n      }\n            );\n      System.setErr( new PrintStream( System.err ) {\n        public void print( final String string ) {\n          if ( string.replaceAll( \"\\\\s*\", \"\" ).length( ) > 2 ) {\n//            SystemBootstrapper.err.println( string );\n            EventRecord.caller( SystemBootstrapper.class, EventType.STDERR, string ).error( );\n          }\n        }\n      }\n            );\n      LOG.info( LogUtil.subheader( \"Starting system with debugging set as: \" + Join.join( \"\\n\", LogLevels.class.getDeclaredFields( ) ) ) );\n      Logger.getLogger( \"com.eucalyptus.entities.EntityWrapper\" ).fatal( \"Starting up\" );\n      Security.addProvider( new BouncyCastleProvider( ) );\n      System.setProperty( \"euca.ws.port\", \"8773\" );\n    } catch ( Throwable t ) {\n      t.printStackTrace( );\n      System.exit( 1 );\n    }\n    try {\n      Bootstrap.initialize( );\n      Bootstrap.Stage stage = Bootstrap.transition( );\n      stage.load( );\n      return true;\n    } catch ( BootstrapException e ) {\n      e.printStackTrace( );\n      throw e;\n    } catch ( Throwable t ) {\n      t.printStackTrace( );\n      LOG.fatal( t, t );\n      System.exit( 1 );\n      return false;\n    }\n  }","commit_id":"007a9b205d88fcd35a1302a01cf643861c80a11f","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"private synchronized void clearCache() {\n    JmxCacheBuster.clearJmxCache(true);\n    executor.getExecutor().schedule(new Runnable() {\n      @Override\n      public void run() {\n        JmxCacheBuster.clearJmxCache();\n      }\n    }, 5, TimeUnit.MINUTES);\n  }","id":37411,"modified_method":"private synchronized void clearCache() {\n    JmxCacheBuster.clearJmxCache(true);\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n  public void register(MetricsRegionSource source) {\n    Lock l = lock.writeLock();\n    l.lock();\n    try {\n      regionSources.add(source);\n      clearCache();\n    } finally {\n      l.unlock();\n    }\n  }","id":37412,"modified_method":"@Override\n  public void register(MetricsRegionSource source) {\n    regionSources.add(source);\n    clearCache();\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"/**\n   * Yes this is a get function that doesn't return anything.  Thanks Hadoop for breaking all\n   * expectations of java programmers.  Instead of returning anything Hadoop metrics expects\n   * getMetrics to push the metrics into the collector.\n   *\n   * @param collector the collector\n   * @param all       get all the metrics regardless of when they last changed.\n   */\n  @Override\n  public void getMetrics(MetricsCollector collector, boolean all) {\n    MetricsRecordBuilder mrb = collector.addRecord(metricsName);\n\n    if (regionSources != null) {\n      Lock l = lock.readLock();\n      l.lock();\n      try {\n        for (MetricsRegionSource regionMetricSource : regionSources) {\n          if (regionMetricSource instanceof MetricsRegionSourceImpl) {\n            ((MetricsRegionSourceImpl) regionMetricSource).snapshot(mrb, all);\n          }\n        }\n        mrb.addGauge(Interns.info(NUM_REGIONS, NUMBER_OF_REGIONS_DESC), regionSources.size());\n      } finally {\n        l.unlock();\n      }\n      metricsRegistry.snapshot(mrb, all);\n    }\n  }","id":37413,"modified_method":"/**\n   * Yes this is a get function that doesn't return anything.  Thanks Hadoop for breaking all\n   * expectations of java programmers.  Instead of returning anything Hadoop metrics expects\n   * getMetrics to push the metrics into the collector.\n   *\n   * @param collector the collector\n   * @param all       get all the metrics regardless of when they last changed.\n   */\n  @Override\n  public void getMetrics(MetricsCollector collector, boolean all) {\n    MetricsRecordBuilder mrb = collector.addRecord(metricsName);\n\n    if (regionSources != null) {\n      for (MetricsRegionSource regionMetricSource : regionSources) {\n        if (regionMetricSource instanceof MetricsRegionSourceImpl) {\n          ((MetricsRegionSourceImpl) regionMetricSource).snapshot(mrb, all);\n        }\n      }\n      mrb.addGauge(Interns.info(NUM_REGIONS, NUMBER_OF_REGIONS_DESC), regionSources.size());\n      metricsRegistry.snapshot(mrb, all);\n    }\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n  public void deregister(MetricsRegionSource toRemove) {\n    Lock l = lock.writeLock();\n    l.lock();\n    try {\n      regionSources.remove(toRemove);\n      clearCache();\n    } finally {\n      l.unlock();\n    }\n  }","id":37414,"modified_method":"@Override\n  public void deregister(MetricsRegionSource toRemove) {\n    regionSources.remove(toRemove);\n    clearCache();\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n    Lock lock = readWriteLock.readLock();\n\n    // Grab the read lock.\n    // This ensures that\n    lock.lock();\n    try {\n      if (closed) {\n        return;\n      }\n\n      mrb.addGauge(\n          Interns.info(regionNamePrefix + MetricsRegionServerSource.STORE_COUNT,\n              MetricsRegionServerSource.STORE_COUNT_DESC),\n          this.regionWrapper.getNumStores());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.STOREFILE_COUNT,\n              MetricsRegionServerSource.STOREFILE_COUNT_DESC),\n          this.regionWrapper.getNumStoreFiles());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.MEMSTORE_SIZE,\n              MetricsRegionServerSource.MEMSTORE_SIZE_DESC),\n          this.regionWrapper.getMemstoreSize());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.STOREFILE_SIZE,\n              MetricsRegionServerSource.STOREFILE_SIZE_DESC),\n          this.regionWrapper.getStoreFileSize());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.COMPACTIONS_COMPLETED_COUNT,\n              MetricsRegionSource.COMPACTIONS_COMPLETED_DESC),\n          this.regionWrapper.getNumCompactionsCompleted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.NUM_BYTES_COMPACTED_COUNT,\n              MetricsRegionSource.NUM_BYTES_COMPACTED_DESC),\n          this.regionWrapper.getNumBytesCompacted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.NUM_FILES_COMPACTED_COUNT,\n              MetricsRegionSource.NUM_FILES_COMPACTED_DESC),\n          this.regionWrapper.getNumFilesCompacted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionServerSource.READ_REQUEST_COUNT,\n              MetricsRegionServerSource.READ_REQUEST_COUNT_DESC),\n          this.regionWrapper.getReadRequestCount());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionServerSource.WRITE_REQUEST_COUNT,\n              MetricsRegionServerSource.WRITE_REQUEST_COUNT_DESC),\n          this.regionWrapper.getWriteRequestCount());\n\n      for (Map.Entry<String, DescriptiveStatistics> entry : this.regionWrapper\n          .getCoprocessorExecutionStatistics()\n          .entrySet()) {\n        DescriptiveStatistics ds = entry.getValue();\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Min: \"),\n            ds.getMin() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Mean: \"),\n            ds.getMean() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Max: \"),\n            ds.getMax() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"90th percentile: \"), ds\n            .getPercentile(90d) / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"95th percentile: \"), ds\n            .getPercentile(95d) / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"99th percentile: \"), ds\n            .getPercentile(99d) / 1000);\n      }\n    } finally {\n      lock.unlock();\n    }\n  }","id":37415,"modified_method":"void snapshot(MetricsRecordBuilder mrb, boolean ignored) {\n\n    // If there is a close that started be double extra sure\n    // that we're not getting any locks and not putting data\n    // into the metrics that should be removed. So early out\n    // before even getting the lock.\n    if (closed.get()) {\n      return;\n    }\n\n    // Grab the read\n    // This ensures that removes of the metrics\n    // can't happen while we are putting them back in.\n    synchronized (this) {\n\n      // It's possible that a close happened between checking\n      // the closed variable and getting the lock.\n      if (closed.get()) {\n        return;\n      }\n\n      mrb.addGauge(\n          Interns.info(regionNamePrefix + MetricsRegionServerSource.STORE_COUNT,\n              MetricsRegionServerSource.STORE_COUNT_DESC),\n          this.regionWrapper.getNumStores());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.STOREFILE_COUNT,\n              MetricsRegionServerSource.STOREFILE_COUNT_DESC),\n          this.regionWrapper.getNumStoreFiles());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.MEMSTORE_SIZE,\n              MetricsRegionServerSource.MEMSTORE_SIZE_DESC),\n          this.regionWrapper.getMemstoreSize());\n      mrb.addGauge(Interns.info(regionNamePrefix + MetricsRegionServerSource.STOREFILE_SIZE,\n              MetricsRegionServerSource.STOREFILE_SIZE_DESC),\n          this.regionWrapper.getStoreFileSize());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.COMPACTIONS_COMPLETED_COUNT,\n              MetricsRegionSource.COMPACTIONS_COMPLETED_DESC),\n          this.regionWrapper.getNumCompactionsCompleted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.NUM_BYTES_COMPACTED_COUNT,\n              MetricsRegionSource.NUM_BYTES_COMPACTED_DESC),\n          this.regionWrapper.getNumBytesCompacted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionSource.NUM_FILES_COMPACTED_COUNT,\n              MetricsRegionSource.NUM_FILES_COMPACTED_DESC),\n          this.regionWrapper.getNumFilesCompacted());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionServerSource.READ_REQUEST_COUNT,\n              MetricsRegionServerSource.READ_REQUEST_COUNT_DESC),\n          this.regionWrapper.getReadRequestCount());\n      mrb.addCounter(Interns.info(regionNamePrefix + MetricsRegionServerSource.WRITE_REQUEST_COUNT,\n              MetricsRegionServerSource.WRITE_REQUEST_COUNT_DESC),\n          this.regionWrapper.getWriteRequestCount());\n\n      for (Map.Entry<String, DescriptiveStatistics> entry : this.regionWrapper\n          .getCoprocessorExecutionStatistics()\n          .entrySet()) {\n        DescriptiveStatistics ds = entry.getValue();\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Min: \"),\n            ds.getMin() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Mean: \"),\n            ds.getMean() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                    + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n                MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"Max: \"),\n            ds.getMax() / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"90th percentile: \"), ds\n            .getPercentile(90d) / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"95th percentile: \"), ds\n            .getPercentile(95d) / 1000);\n        mrb.addGauge(Interns.info(regionNamePrefix + \" \" + entry.getKey() + \" \"\n                + MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS,\n            MetricsRegionSource.COPROCESSOR_EXECUTION_STATISTICS_DESC + \"99th percentile: \"), ds\n            .getPercentile(99d) / 1000);\n      }\n    }\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"@Override\n  public void close() {\n    Lock lock = readWriteLock.writeLock();\n    lock.lock();\n    try {\n      if (closed) {\n        return;\n      }\n\n      closed = true;\n      agg.deregister(this);\n\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Removing region Metrics: \" + regionWrapper.getRegionName());\n      }\n\n      registry.removeMetric(regionPutKey);\n      registry.removeMetric(regionDeleteKey);\n      registry.removeMetric(regionIncrementKey);\n      registry.removeMetric(regionAppendKey);\n      registry.removeMetric(regionGetKey);\n      registry.removeMetric(regionScanNextKey);\n      registry.removeHistogramMetrics(regionGetKey);\n      registry.removeHistogramMetrics(regionScanNextKey);\n\n      regionWrapper = null;\n\n      JmxCacheBuster.clearJmxCache();\n    } finally {\n      lock.unlock();\n    }\n  }","id":37416,"modified_method":"@Override\n  public void close() {\n    boolean wasClosed = closed.getAndSet(false);\n\n    // Has someone else already closed this for us?\n    if (wasClosed) {\n      return;\n    }\n\n    // Before removing the metrics remove this region from the aggregate region bean.\n    // This should mean that it's unlikely that snapshot and close happen at the same time.\n    agg.deregister(this);\n\n    // While it's un-likely that snapshot and close happen at the same time it's still possible.\n    // So grab the lock to ensure that all calls to snapshot are done before we remove the metrics\n    synchronized (this) {\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Removing region Metrics: \" + regionWrapper.getRegionName());\n      }\n\n      registry.removeMetric(regionPutKey);\n      registry.removeMetric(regionDeleteKey);\n      registry.removeMetric(regionIncrementKey);\n      registry.removeMetric(regionAppendKey);\n      registry.removeMetric(regionGetKey);\n      registry.removeMetric(regionScanNextKey);\n      registry.removeHistogramMetrics(regionGetKey);\n      registry.removeHistogramMetrics(regionScanNextKey);\n\n      regionWrapper = null;\n    }\n  }","commit_id":"bcef28eefaf192b0ad48c8011f98b8e944340da5","url":"https://github.com/apache/hbase"},{"original_method":"/**\n     * Updates any <code>SingleSignOnEntry<\/code> found under key\n     * <code>ssoId<\/code> with the given authentication data.\n     * <p>\n     * The purpose of this method is to allow an SSO entry that was\n     * established without a username/password combination (i.e. established\n     * following DIGEST or CLIENT_CERT authentication) to be updated with\n     * a username and password if one becomes available through a subsequent\n     * BASIC or FORM authentication.  The SSO entry will then be usable for\n     * reauthentication.\n     * <p>\n     * <b>NOTE:<\/b> Only updates the SSO entry if a call to\n     * <code>SingleSignOnEntry.getCanReauthenticate()<\/code> returns\n     * <code>false<\/code>; otherwise, it is assumed that the SSO entry already\n     * has sufficient information to allow reauthentication and that no update\n     * is needed.\n     *\n     * @param ssoId     identifier of Single sign to be updated\n     * @param principal the <code>Principal<\/code> returned by the latest\n     *                  call to <code>Realm.authenticate<\/code>.\n     * @param authType  the type of authenticator used (BASIC, CLIENT_CERT,\n     *                  DIGEST or FORM)\n     * @param username  the username (if any) used for the authentication\n     * @param password  the password (if any) used for the authentication\n     *\n     * @return <code>true<\/code> if the credentials were updated, otherwise\n     *         <code>false<\/code>\n     */\n    protected boolean update(String ssoId, Principal principal, String authType,\n                          String username, String password) {\n\n        SingleSignOnEntry sso = cache.get(ssoId);\n        if (sso != null && !sso.getCanReauthenticate()) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(\"Update sso id \" + ssoId + \" to auth type \" + authType);\n            }\n\n            sso.updateCredentials(principal, authType, username, password);\n            return true;\n        }\n        return false;\n    }","id":37417,"modified_method":"/**\n     * Updates any <code>SingleSignOnEntry<\/code> found under key\n     * <code>ssoId<\/code> with the given authentication data.\n     * <p>\n     * The purpose of this method is to allow an SSO entry that was\n     * established without a username/password combination (i.e. established\n     * following DIGEST or CLIENT_CERT authentication) to be updated with\n     * a username and password if one becomes available through a subsequent\n     * BASIC or FORM authentication.  The SSO entry will then be usable for\n     * reauthentication.\n     * <p>\n     * <b>NOTE:<\/b> Only updates the SSO entry if a call to\n     * <code>SingleSignOnEntry.getCanReauthenticate()<\/code> returns\n     * <code>false<\/code>; otherwise, it is assumed that the SSO entry already\n     * has sufficient information to allow reauthentication and that no update\n     * is needed.\n     *\n     * @param ssoId     identifier of Single sign to be updated\n     * @param principal the <code>Principal<\/code> returned by the latest\n     *                  call to <code>Realm.authenticate<\/code>.\n     * @param authType  the type of authenticator used (BASIC, CLIENT_CERT,\n     *                  DIGEST or FORM)\n     * @param username  the username (if any) used for the authentication\n     * @param password  the password (if any) used for the authentication\n     *\n     * @return <code>true<\/code> if the credentials were updated, otherwise\n     *         <code>false<\/code>\n     */\n    protected boolean update(String ssoId, Principal principal, String authType,\n                          String username, String password) {\n\n        SingleSignOnEntry sso = cache.get(ssoId);\n        if (sso != null && !sso.getCanReauthenticate()) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.update\", ssoId, authType));\n            }\n\n            sso.updateCredentials(principal, authType, username, password);\n            return true;\n        }\n        return false;\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Remove a single Session from a SingleSignOn.  Called when\n     * a session is timed out and no longer active.\n     *\n     * @param ssoId Single sign on identifier from which to remove the session.\n     * @param session the session to be removed.\n     */\n    protected void removeSession(String ssoId, Session session) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Removing session \" + session.toString() + \" from sso id \" +\n                ssoId );\n        }\n\n        // Get a reference to the SingleSignOn\n        SingleSignOnEntry entry = cache.get(ssoId);\n        if (entry == null) {\n            return;\n        }\n\n        // Remove the inactive session from SingleSignOnEntry\n        entry.removeSession(session);\n\n        // If there are not sessions left in the SingleSignOnEntry,\n        // deregister the entry.\n        if (entry.findSessions().size() == 0) {\n            deregister(ssoId);\n        }\n    }","id":37418,"modified_method":"/**\n     * Remove a single Session from a SingleSignOn.  Called when\n     * a session is timed out and no longer active.\n     *\n     * @param ssoId Single sign on identifier from which to remove the session.\n     * @param session the session to be removed.\n     */\n    protected void removeSession(String ssoId, Session session) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(sm.getString(\"singleSignOn.debug.removeSession\", session, ssoId));\n        }\n\n        // Get a reference to the SingleSignOn\n        SingleSignOnEntry entry = cache.get(ssoId);\n        if (entry == null) {\n            return;\n        }\n\n        // Remove the inactive session from SingleSignOnEntry\n        entry.removeSession(session);\n\n        // If there are not sessions left in the SingleSignOnEntry,\n        // deregister the entry.\n        if (entry.findSessions().size() == 0) {\n            deregister(ssoId);\n        }\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Register the specified Principal as being associated with the specified\n     * value for the single sign on identifier.\n     *\n     * @param ssoId Single sign on identifier to register\n     * @param principal Associated user principal that is identified\n     * @param authType Authentication type used to authenticate this\n     *  user principal\n     * @param username Username used to authenticate this user\n     * @param password Password used to authenticate this user\n     */\n    protected void register(String ssoId, Principal principal, String authType,\n                  String username, String password) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Registering sso id '\" + ssoId + \"' for user '\" +\n                (principal != null ? principal.getName() : \"\") + \"' with auth type '\" + authType + \"'\");\n        }\n\n        cache.put(ssoId, new SingleSignOnEntry(principal, authType, username, password));\n    }","id":37419,"modified_method":"/**\n     * Register the specified Principal as being associated with the specified\n     * value for the single sign on identifier.\n     *\n     * @param ssoId Single sign on identifier to register\n     * @param principal Associated user principal that is identified\n     * @param authType Authentication type used to authenticate this\n     *  user principal\n     * @param username Username used to authenticate this user\n     * @param password Password used to authenticate this user\n     */\n    protected void register(String ssoId, Principal principal, String authType,\n                  String username, String password) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(sm.getString(\"singleSignOn.debug.register\", ssoId,\n                    principal != null ? principal.getName() : \"\", authType));\n        }\n\n        cache.put(ssoId, new SingleSignOnEntry(principal, authType, username, password));\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Deregister the specified single sign on identifier, and invalidate\n     * any associated sessions.\n     *\n     * @param ssoId Single sign on identifier to deregister\n     */\n    protected void deregister(String ssoId) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Deregistering sso id '\" + ssoId + \"'\");\n        }\n\n        // Look up and remove the corresponding SingleSignOnEntry\n        SingleSignOnEntry sso = cache.remove(ssoId);\n\n        if (sso == null) {\n            return;\n        }\n\n        // Expire any associated sessions\n        for (SingleSignOnSessionKey ssoKey : sso.findSessions()) {\n            if (containerLog.isTraceEnabled()) {\n                containerLog.trace(\" Invalidating session \" + ssoKey);\n            }\n            // Invalidate this session\n            expire(ssoKey);\n        }\n\n        // NOTE:  Clients may still possess the old single sign on cookie,\n        // but it will be removed on the next request since it is no longer\n        // in the cache\n    }","id":37420,"modified_method":"/**\n     * Deregister the specified single sign on identifier, and invalidate\n     * any associated sessions.\n     *\n     * @param ssoId Single sign on identifier to deregister\n     */\n    protected void deregister(String ssoId) {\n\n        // Look up and remove the corresponding SingleSignOnEntry\n        SingleSignOnEntry sso = cache.remove(ssoId);\n\n        if (sso == null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.deregisterFail\", ssoId));\n            }\n            return;\n        }\n\n        // Expire any associated sessions\n        Set<SingleSignOnSessionKey> ssoKeys = sso.findSessions();\n        if (ssoKeys.size() == 0) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.deregisterNone\", ssoId));\n            }\n        }\n        for (SingleSignOnSessionKey ssoKey : ssoKeys) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.deregister\", ssoKey, ssoId));\n            }\n            // Invalidate this session\n            expire(ssoKey);\n        }\n\n        // NOTE:  Clients may still possess the old single sign on cookie,\n        // but it will be removed on the next request since it is no longer\n        // in the cache\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Perform single-sign-on support processing for this request.\n     *\n     * @param request The servlet request we are processing\n     * @param response The servlet response we are creating\n     *\n     * @exception IOException if an input/output error occurs\n     * @exception ServletException if a servlet error occurs\n     */\n    @Override\n    public void invoke(Request request, Response response)\n        throws IOException, ServletException {\n\n        request.removeNote(Constants.REQ_SSOID_NOTE);\n\n        // Has a valid user already been authenticated?\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Process request for '\" + request.getRequestURI() + \"'\");\n        }\n        if (request.getUserPrincipal() != null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(\" Principal '\" + request.getUserPrincipal().getName() +\n                    \"' has already been authenticated\");\n            }\n            getNext().invoke(request, response);\n            return;\n        }\n\n        // Check for the single sign on cookie\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\" Checking for SSO cookie\");\n        }\n        Cookie cookie = null;\n        Cookie cookies[] = request.getCookies();\n        if (cookies != null) {\n            for (int i = 0; i < cookies.length; i++) {\n                if (Constants.SINGLE_SIGN_ON_COOKIE.equals(cookies[i].getName())) {\n                    cookie = cookies[i];\n                    break;\n                }\n            }\n        }\n        if (cookie == null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(\" SSO cookie is not present\");\n            }\n            getNext().invoke(request, response);\n            return;\n        }\n\n        // Look up the cached Principal associated with this cookie value\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\" Checking for cached principal for \" + cookie.getValue());\n        }\n        SingleSignOnEntry entry = cache.get(cookie.getValue());\n        if (entry != null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(\" Found cached principal '\" +\n                    (entry.getPrincipal() != null ? entry.getPrincipal().getName() : \"\") + \"' with auth type '\" +\n                    entry.getAuthType() + \"'\");\n            }\n            request.setNote(Constants.REQ_SSOID_NOTE, cookie.getValue());\n            // Only set security elements if reauthentication is not required\n            if (!getRequireReauthentication()) {\n                request.setAuthType(entry.getAuthType());\n                request.setUserPrincipal(entry.getPrincipal());\n            }\n        } else {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(\" No cached principal found, erasing SSO cookie\");\n            }\n            // No need to return a valid SSO session ID\n            cookie.setValue(\"REMOVE\");\n            // Age of zero will trigger removal\n            cookie.setMaxAge(0);\n            // Domain and path have to match the original cookie to 'replace'\n            // the original cookie\n            cookie.setPath(\"/\");\n            String domain = getCookieDomain();\n            if (domain != null) {\n                cookie.setDomain(domain);\n            }\n            // This is going to trigger a Set-Cookie header. While the value is\n            // not security sensitive, ensure that expectations for secure and\n            // httpOnly are met\n            cookie.setSecure(request.isSecure());\n            if (request.getServletContext().getSessionCookieConfig().isHttpOnly() ||\n                    request.getContext().getUseHttpOnly()) {\n                cookie.setHttpOnly(true);\n            }\n\n            response.addCookie(cookie);\n        }\n\n        // Invoke the next Valve in our pipeline\n        getNext().invoke(request, response);\n    }","id":37421,"modified_method":"/**\n     * Perform single-sign-on support processing for this request.\n     *\n     * @param request The servlet request we are processing\n     * @param response The servlet response we are creating\n     *\n     * @exception IOException if an input/output error occurs\n     * @exception ServletException if a servlet error occurs\n     */\n    @Override\n    public void invoke(Request request, Response response)\n        throws IOException, ServletException {\n\n        request.removeNote(Constants.REQ_SSOID_NOTE);\n\n        // Has a valid user already been authenticated?\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(sm.getString(\"singleSignOn.debug.invoke\", request.getRequestURI()));\n        }\n        if (request.getUserPrincipal() != null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.hasPrincipal\",\n                        request.getUserPrincipal().getName()));\n            }\n            getNext().invoke(request, response);\n            return;\n        }\n\n        // Check for the single sign on cookie\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(sm.getString(\"singleSignOn.debug.cookieCheck\"));\n        }\n        Cookie cookie = null;\n        Cookie cookies[] = request.getCookies();\n        if (cookies != null) {\n            for (int i = 0; i < cookies.length; i++) {\n                if (Constants.SINGLE_SIGN_ON_COOKIE.equals(cookies[i].getName())) {\n                    cookie = cookies[i];\n                    break;\n                }\n            }\n        }\n        if (cookie == null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.cookieNotFound\"));\n            }\n            getNext().invoke(request, response);\n            return;\n        }\n\n        // Look up the cached Principal associated with this cookie value\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(sm.getString(\"singleSignOn.debug.principalCheck\",\n                    cookie.getValue()));\n        }\n        SingleSignOnEntry entry = cache.get(cookie.getValue());\n        if (entry != null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.principalFound\",\n                        entry.getPrincipal() != null ? entry.getPrincipal().getName() : \"\",\n                        entry.getAuthType()));\n            }\n            request.setNote(Constants.REQ_SSOID_NOTE, cookie.getValue());\n            // Only set security elements if reauthentication is not required\n            if (!getRequireReauthentication()) {\n                request.setAuthType(entry.getAuthType());\n                request.setUserPrincipal(entry.getPrincipal());\n            }\n        } else {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.principalNotFound\",\n                        cookie.getValue()));\n            }\n            // No need to return a valid SSO session ID\n            cookie.setValue(\"REMOVE\");\n            // Age of zero will trigger removal\n            cookie.setMaxAge(0);\n            // Domain and path have to match the original cookie to 'replace'\n            // the original cookie\n            cookie.setPath(\"/\");\n            String domain = getCookieDomain();\n            if (domain != null) {\n                cookie.setDomain(domain);\n            }\n            // This is going to trigger a Set-Cookie header. While the value is\n            // not security sensitive, ensure that expectations for secure and\n            // httpOnly are met\n            cookie.setSecure(request.isSecure());\n            if (request.getServletContext().getSessionCookieConfig().isHttpOnly() ||\n                    request.getContext().getUseHttpOnly()) {\n                cookie.setHttpOnly(true);\n            }\n\n            response.addCookie(cookie);\n        }\n\n        // Invoke the next Valve in our pipeline\n        getNext().invoke(request, response);\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Process a session destroyed event by removing references to that session\n     * from the caches and - if the session destruction is the result of a\n     * logout - destroy the associated SSO session.\n     *\n     * @param ssoId   The ID of the SSO session which which the destroyed\n     *                session was associated\n     * @param session The session that has been destroyed\n     */\n    public void sessionDestroyed(String ssoId, Session session) {\n\n        if (!getState().isAvailable()) {\n            return;\n        }\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Process session destroyed on \" + session);\n        }\n\n        // Was the session destroyed as the result of a timeout or context stop?\n        // If so, we'll just remove the expired session from the SSO. If the\n        // session was logged out, we'll log out of all session associated with\n        // the SSO.\n        if (((session.getMaxInactiveInterval() > 0)\n            && (System.currentTimeMillis() - session.getThisAccessedTimeInternal() >=\n                session.getMaxInactiveInterval() * 1000))\n            || (!session.getManager().getContext().getState().isAvailable())) {\n            removeSession(ssoId, session);\n        } else {\n            // The session was logged out.\n            // Deregister this single session id, invalidating\n            // associated sessions\n            deregister(ssoId);\n        }\n    }","id":37422,"modified_method":"/**\n     * Process a session destroyed event by removing references to that session\n     * from the caches and - if the session destruction is the result of a\n     * logout - destroy the associated SSO session.\n     *\n     * @param ssoId   The ID of the SSO session which which the destroyed\n     *                session was associated\n     * @param session The session that has been destroyed\n     */\n    public void sessionDestroyed(String ssoId, Session session) {\n\n        if (!getState().isAvailable()) {\n            return;\n        }\n\n        // Was the session destroyed as the result of a timeout or context stop?\n        // If so, we'll just remove the expired session from the SSO. If the\n        // session was logged out, we'll log out of all session associated with\n        // the SSO.\n        if (((session.getMaxInactiveInterval() > 0)\n            && (System.currentTimeMillis() - session.getThisAccessedTimeInternal() >=\n                session.getMaxInactiveInterval() * 1000))\n            || (!session.getManager().getContext().getState().isAvailable())) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionTimeout\",\n                        ssoId, session));\n            }\n            removeSession(ssoId, session);\n        } else {\n            // The session was logged out.\n            // Deregister this single session id, invalidating\n            // associated sessions\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionLogout\",\n                        ssoId, session));\n            }\n            deregister(ssoId);\n        }\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Associate the specified single sign on identifier with the\n     * specified Session.\n     *\n     * @param ssoId Single sign on identifier\n     * @param session Session to be associated\n     *\n     * @return <code>true<\/code> if the session was associated to the given SSO\n     *         session, otherwise <code>false<\/code>\n     */\n    protected boolean associate(String ssoId, Session session) {\n\n        if (containerLog.isDebugEnabled()) {\n            containerLog.debug(\"Associate sso id \" + ssoId + \" with session \" + session);\n        }\n\n        SingleSignOnEntry sso = cache.get(ssoId);\n        if (sso == null) {\n            return false;\n        } else {\n            sso.addSession(this, ssoId, session);\n            return true;\n        }\n    }","id":37423,"modified_method":"/**\n     * Associate the specified single sign on identifier with the\n     * specified Session.\n     *\n     * @param ssoId Single sign on identifier\n     * @param session Session to be associated\n     *\n     * @return <code>true<\/code> if the session was associated to the given SSO\n     *         session, otherwise <code>false<\/code>\n     */\n    protected boolean associate(String ssoId, Session session) {\n        SingleSignOnEntry sso = cache.get(ssoId);\n        if (sso == null) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.associateFail\",\n                        ssoId, session));\n            }\n            return false;\n        } else {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.associate\",\n                        ssoId, session));\n            }\n            sso.addSession(this, ssoId, session);\n            return true;\n        }\n    }","commit_id":"f67370e2ab5d3063948494b0095d8601d83b8461","url":"https://github.com/apache/tomcat"},{"original_method":"/**\n     * Process a session destroyed event by removing references to that session\n     * from the caches and - if the session destruction is the result of a\n     * logout - destroy the associated SSO session.\n     *\n     * @param ssoId   The ID of the SSO session which which the destroyed\n     *                session was associated\n     * @param session The session that has been destroyed\n     */\n    public void sessionDestroyed(String ssoId, Session session) {\n\n        if (!getState().isAvailable()) {\n            return;\n        }\n\n        // Was the session destroyed as the result of a timeout or context stop?\n        // If so, we'll just remove the expired session from the SSO. If the\n        // session was logged out, we'll log out of all session associated with\n        // the SSO.\n        if (((session.getMaxInactiveInterval() > 0)\n            && (session.getIdleTimeInternal() >= session.getMaxInactiveInterval() * 1000))\n            || (!session.getManager().getContext().getState().isAvailable())) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionTimeout\",\n                        ssoId, session));\n            }\n            removeSession(ssoId, session);\n        } else {\n            // The session was logged out.\n            // Deregister this single session id, invalidating\n            // associated sessions\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionLogout\",\n                        ssoId, session));\n            }\n            deregister(ssoId);\n        }\n    }","id":37424,"modified_method":"/**\n     * Process a session destroyed event by removing references to that session\n     * from the caches and - if the session destruction is the result of a\n     * logout - destroy the associated SSO session.\n     *\n     * @param ssoId   The ID of the SSO session which which the destroyed\n     *                session was associated\n     * @param session The session that has been destroyed\n     */\n    public void sessionDestroyed(String ssoId, Session session) {\n\n        if (!getState().isAvailable()) {\n            return;\n        }\n\n        // Was the session destroyed as the result of a timeout or context stop?\n        // If so, we'll just remove the expired session from the SSO. If the\n        // session was logged out, we'll log out of all session associated with\n        // the SSO.\n        if (((session.getMaxInactiveInterval() > 0)\n            && (session.getIdleTimeInternal() >= session.getMaxInactiveInterval() * 1000))\n            || (!session.getManager().getContext().getState().isAvailable())) {\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionTimeout\",\n                        ssoId, session));\n            }\n            removeSession(ssoId, session);\n        } else {\n            // The session was logged out.\n            // Deregister this single session id, invalidating\n            // associated sessions\n            if (containerLog.isDebugEnabled()) {\n                containerLog.debug(sm.getString(\"singleSignOn.debug.sessionLogout\",\n                        ssoId, session));\n            }\n            // First remove the session that we know has expired / been logged\n            // out since it has already been removed from its Manager and, if\n            // we don't remove it first, deregister() will log a warning that it\n            // can't be found\n            removeSession(ssoId, session);\n            // If the SSO session was only associated with one web app the call\n            // above will have removed the SSO session from the cache\n            if (cache.containsKey(ssoId)) {\n                deregister(ssoId);\n            }\n        }\n    }","commit_id":"f88d635727b33e77db8d29ed3c1da04ccb253459","url":"https://github.com/apache/tomcat"},{"original_method":"@Override\n  public void renameElement(final PsiElement psiElement,\n                            final String newName,\n                            final UsageInfo[] usages,\n                            final RefactoringElementListener listener) throws IncorrectOperationException {\n\n    final GrField field = (GrField)psiElement;\n    final PsiMethod getter = GroovyPropertyUtils.findGetterForField(field);\n    final PsiMethod setter = GroovyPropertyUtils.findSetterForField(field);\n    final String newGetterName = (getter != null && getter.getName().startsWith(\"is\") ? \"is\" : \"get\") + StringUtil.capitalize(newName);\n    final String newSetterName = \"set\" + StringUtil.capitalize(newName);\n\n    // rename all references\n    for (UsageInfo usage : usages) {\n      final PsiElement element = usage.getElement();\n      if (element == null) {\n        continue;\n      } else {\n        PsiReference ref = element.getReference();\n        if (ref != null) {\n          PsiElement resolved = ref.resolve();\n          if (resolved instanceof GrAccessorMethod) {\n            GrAccessorMethod method = (GrAccessorMethod)resolved;\n            if (method == getter) {\n\n              ref.handleElementRename(newGetterName);\n            } else {\n              if (method == setter) {\n                ref.handleElementRename(newSetterName);\n              }\n              else {\n              ref.handleElementRename(newName);\n            }\n            }\n          } else {\n            ref.handleElementRename(newName);\n          }\n\n        }\n      }\n    }\n    // do actual rename\n    field.setName(newName);\n    listener.elementRenamed(field);\n  }","id":37425,"modified_method":"@Override\n  public void renameElement(final PsiElement psiElement,\n                            final String newName,\n                            final UsageInfo[] usages,\n                            final RefactoringElementListener listener) throws IncorrectOperationException {\n\n    final GrField field = (GrField)psiElement;\n    final PsiMethod getter = GroovyPropertyUtils.findGetterForField(field);\n    final PsiMethod setter = GroovyPropertyUtils.findSetterForField(field);\n    final String newGetterName = (getter != null && getter.getName().startsWith(\"is\") ? \"is\" : \"get\") + StringUtil.capitalize(newName);\n    final String newSetterName = \"set\" + StringUtil.capitalize(newName);\n\n    // rename all references\n    for (UsageInfo usage : usages) {\n      final PsiElement element = usage.getElement();\n      if (element == null) {\n        continue;\n      }\n\n      PsiReference ref = element.getReference();\n      if (ref == null) continue;\n\n      PsiElement resolved = ref.resolve();\n      if (resolved instanceof GrAccessorMethod) {\n        GrAccessorMethod method = (GrAccessorMethod)resolved;\n        if (method == getter) {\n\n          ref.handleElementRename(newGetterName);\n        }\n        else {\n          if (method == setter) {\n            ref.handleElementRename(newSetterName);\n          }\n          else {\n            ref.handleElementRename(newName);\n          }\n        }\n      }\n      else {\n        final PsiElement renamed = ref.handleElementRename(newName);\n        final PsiElement newly_resolved = ref.resolve();\n        if (!field.getManager().areElementsEquivalent(newly_resolved, field)) {\n          qualify(field, renamed, newName);\n        }\n      }\n    }\n    // do actual rename\n    field.setName(newName);\n    listener.elementRenamed(field);\n  }","commit_id":"9fd71742f575b4fce3b2aea83e557e1d316ebb23","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void invoke(@NotNull final Project project, @NotNull PsiElement[] elements, final DataContext dataContext) {\n\n    // we ignore 'elements' and take current node from dataContext\n    // because Idea takes the root node as the element for our editor\n\n    final MPSProject mpsProject = project.getComponent(MPSProject.class);\n    final SRepository repository = mpsProject.getRepository();\n    ModelAccess modelAccess = repository.getModelAccess();\n\n    final SNode node = (SNode) dataContext.getData(MPSCommonDataKeys.NODE.getName());\n\n    modelAccess.runReadInEDT(new Runnable() {\n      @Override\n      public void run() {\n\n        if (node.getModel() == null) {\n          return;\n        }\n\n        // trying to apply sequentially, the first one wins and we go no further\n        for (RenameRefactoringContributorEP ep : RenameRefactoringContributorEP.EP_NAME.getExtensions()) {\n          RenameRefactoringContributor contributor = ep.getContribitor();\n          if (contributor.isAvailableFor(node)) {\n            contributor.invoke(project, node);\n            return;\n          }\n        }\n\n        // default rename logic: call jetbrains.mps.lang.core.refactorings.Rename refactoring\n        // and update psi references to the renamed node if any\n\n        String oldName = node.getName();\n\n        final String newName = RenameDialog.getNewName(project, oldName, \"node\");\n        if (newName == null) return;\n\n        if (node.getModel() == null || SNodeOperations.isDisposed(node)) {\n          return;\n        }\n\n        IRefactoring psiAwareRefactoring = new PsiRenameRefactoringWrapper();\n\n        RefactoringAccess.getInstance().getRefactoringFacade().execute(\n          RefactoringContext.createRefactoringContext(psiAwareRefactoring,\n            Arrays.asList(\"newName\"),\n            Arrays.asList(newName),\n            node,\n            mpsProject));\n      }\n    });\n  }","id":37426,"modified_method":"@Override\n  public void invoke(@NotNull final Project project, @NotNull PsiElement[] elements, final DataContext dataContext) {\n\n    // we ignore 'elements' and take current node from dataContext\n    // because Idea takes the root node as the element for our editor\n\n    final MPSProject mpsProject = project.getComponent(MPSProject.class);\n    final SRepository repository = mpsProject.getRepository();\n    ModelAccess modelAccess = repository.getModelAccess();\n\n    final SNode node = (SNode) dataContext.getData(MPSCommonDataKeys.NODE.getName());\n\n    modelAccess.runReadInEDT(new Runnable() {\n      @Override\n      public void run() {\n\n        if (node.getModel() == null) {\n          return;\n        }\n\n        // trying to apply sequentially, the first one wins and we go no further\n        for (RenameRefactoringContributorEP ep : RenameRefactoringContributorEP.EP_NAME.getExtensions()) {\n          RenameRefactoringContributor contributor = ep.getContribitor();\n          if (contributor.isAvailableFor(node)) {\n            contributor.invoke(project, node);\n            return;\n          }\n        }\n      }\n    });\n  }","commit_id":"77210a0075d816bba26b8834ec6f688764d57d98","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public void refactor(RefactoringContext refactoringContext) {\n    baseRefactoring.refactor(refactoringContext);\n\n    Project project = ProjectHelper.toIdeaProject(refactoringContext.getCurrentOperationContext().getProject());\n    PsiElement psiTarget = MPSPsiProvider.getInstance(project).getPsi(refactoringContext.getSelectedNode());\n    Collection<PsiReference> psiRefs = ReferencesSearch.search(psiTarget).findAll();\n\n    String newName = (String) refactoringContext.getParameter(\"newName\");\n\n    for (PsiReference ref : psiRefs) {\n      ref.handleElementRename(newName);\n    }\n  }","id":37427,"modified_method":"@Override\n  public void refactor(RefactoringContext refactoringContext) {\n    baseRefactoring.refactor(refactoringContext);\n\n    UsagesList usages = refactoringContext.getUsages();\n    if (!(usages instanceof SearchResults)) {\n      return;\n    }\n\n    SearchResults<SNode> searchResults = (SearchResults<SNode>) usages;\n    String newName = (String) refactoringContext.getParameter(\"newName\");\n\n    for (SearchResult<SNode> result : searchResults.getSearchResults()) {\n      if (!(result instanceof PsiSearchResult)) continue;\n      PsiReference psiRef = ((PsiSearchResult) result).getReference();\n      psiRef.handleElementRename(newName);\n    }\n  }","commit_id":"77210a0075d816bba26b8834ec6f688764d57d98","url":"https://github.com/JetBrains/MPS"},{"original_method":"@NotNull\n  public PsiReference[] createReferences(GenericDomValue<TargetResolver.Result> value, PsiElement element, ConvertContext context) {\n    final XmlElement xmlElement = value.getXmlElement();\n    if (!(xmlElement instanceof XmlAttribute)) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final XmlAttributeValue valueElement = ((XmlAttribute)xmlElement).getValueElement();\n    if (valueElement == null) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final String refsString = value.getStringValue();\n    if (refsString == null) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final List<PsiReference> refs = new ArrayList<PsiReference>();\n    final TextRange wholeStringRange = ElementManipulators.getValueTextRange(valueElement);\n    final StringTokenizer tokenizer = new StringTokenizer(refsString, \",\", false);\n    while (tokenizer.hasMoreTokens()) {\n      final String token = tokenizer.nextToken();\n      int tokenStartOffset = tokenizer.getCurrentPosition() - token.length();\n      final String ref = token.trim();\n      if (ref.length() != token.length()) {\n        for (int idx = 0; idx < token.length(); idx++) {\n          if (Character.isWhitespace(token.charAt(idx))) {\n            tokenStartOffset++;\n          }\n          else {\n            break;\n          }\n        }\n      }\n      refs.add(new AntDomTargetReference(element, TextRange.from(wholeStringRange.getStartOffset() + tokenStartOffset, ref.length())));\n    }\n    return refs.toArray(new PsiReference[refs.size()]);\n  }","id":37428,"modified_method":"@NotNull\n  public PsiReference[] createReferences(GenericDomValue<TargetResolver.Result> value, PsiElement element, ConvertContext context) {\n    final XmlElement xmlElement = value.getXmlElement();\n    if (!(xmlElement instanceof XmlAttribute)) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final XmlAttributeValue valueElement = ((XmlAttribute)xmlElement).getValueElement();\n    if (valueElement == null) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final String refsString = value.getStringValue();\n    if (refsString == null) {\n      return PsiReference.EMPTY_ARRAY;\n    }\n    final List<PsiReference> refs = new ArrayList<PsiReference>();\n    final AntDomTargetReference.ReferenceGroup group = new AntDomTargetReference.ReferenceGroup();\n    final TextRange wholeStringRange = ElementManipulators.getValueTextRange(valueElement);\n    final StringTokenizer tokenizer = new StringTokenizer(refsString, \",\", false);\n    while (tokenizer.hasMoreTokens()) {\n      final String token = tokenizer.nextToken();\n      int tokenStartOffset = tokenizer.getCurrentPosition() - token.length();\n      final String ref = token.trim();\n      if (ref.length() != token.length()) {\n        for (int idx = 0; idx < token.length(); idx++) {\n          if (Character.isWhitespace(token.charAt(idx))) {\n            tokenStartOffset++;\n          }\n          else {\n            break;\n          }\n        }\n      }\n      refs.add(new AntDomTargetReference(element, TextRange.from(wholeStringRange.getStartOffset() + tokenStartOffset, ref.length()), group));\n    }\n    return refs.toArray(new PsiReference[refs.size()]);\n  }","commit_id":"0f8753851073aab59f5a3ccbbdccedb8d0bce961","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiElement bindToElement(@NotNull PsiElement element) throws IncorrectOperationException {\n    final DomElement targetDomElement = toDomElement(element);\n    if (targetDomElement != null) {\n      final AntDomTarget pointingToTarget = targetDomElement.getParentOfType(AntDomTarget.class, false);\n      if (pointingToTarget != null) {\n          // the aim here is to receive all variants available at this particular context\n          final TargetResolver.Result result = doResolve(null);\n          if (result != null) {\n            final Map<String, AntDomTarget> variants = result.getVariants();\n            String newName = null;\n            for (Map.Entry<String, AntDomTarget> entry : variants.entrySet()) {\n              if (pointingToTarget.equals(entry.getValue())) {\n                final String candidate = entry.getKey();\n                if (newName == null) {\n                  newName = candidate;\n                }\n                else {\n                  if (candidate.length() < newName.length()) {\n                    newName = candidate; // prefer shorter names\n                  }\n                }\n              }\n            }\n            if (newName != null) {\n              handleElementRename(newName);\n            }\n          }\n      }\n    }\n    return getElement();\n  }","id":37429,"modified_method":"public PsiElement bindToElement(@NotNull PsiElement element) throws IncorrectOperationException {\n    final DomElement targetDomElement = toDomElement(element);\n    if (targetDomElement != null) {\n      final AntDomTarget pointingToTarget = targetDomElement.getParentOfType(AntDomTarget.class, false);\n      if (pointingToTarget != null) {\n          // the aim here is to receive all variants available at this particular context\n          final TargetResolver.Result result = doResolve(null);\n          if (result != null) {\n            final Map<String, AntDomTarget> variants = result.getVariants();\n            String newName = null;\n            if (!variants.isEmpty()) {\n              List<Pair<String, String>> prefixNamePairs = null;\n              for (Map.Entry<String, AntDomTarget> entry : variants.entrySet()) {\n                final AntDomTarget candidateTarget = entry.getValue();\n                if (pointingToTarget.equals(candidateTarget)) {\n                  final String candidateName = entry.getKey();\n                  final String candidateTargetName = candidateTarget.getName().getRawText();\n                  if (candidateName.endsWith(candidateTargetName)) {\n                    final String prefix = candidateName.substring(0, candidateName.length() - candidateTargetName.length());\n                    if (prefixNamePairs == null) {\n                      prefixNamePairs = new ArrayList<Pair<String, String>>(); // lazy init\n                    }\n                    prefixNamePairs.add(new Pair<String, String>(prefix, candidateName));\n                  }\n                }\n              }\n              final String currentRefText = getCanonicalText();\n              for (Pair<String, String> pair : prefixNamePairs) {\n                final String prefix = pair.getFirst();\n                final String effectiveName = pair.getSecond();\n                if (currentRefText.startsWith(prefix)) {\n                  if (newName == null || effectiveName.length() > newName.length()) {\n                    // this candidate's prefix matches current reference text and this name is longer \n                    // than the previous candidate, then prefer this name\n                    newName = effectiveName;\n                  }\n                }\n              }\n            }\n            if (newName != null) {\n              handleElementRename(newName);\n              if (myGroup != null) {\n                myGroup.textChanged(this, newName);\n              }\n            }\n          }\n      }\n    }\n    return getElement();\n  }","commit_id":"0f8753851073aab59f5a3ccbbdccedb8d0bce961","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public AntDomTargetReference(PsiElement element, TextRange range) {\n    super(element, range, true);\n  }","id":37430,"modified_method":"public AntDomTargetReference(PsiElement element, TextRange range, ReferenceGroup group) {\n    super(element, range, true);\n    myGroup = group;\n    group.addReference(this);\n  }","commit_id":"0f8753851073aab59f5a3ccbbdccedb8d0bce961","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public AntDomTargetReference(PsiElement element) {\n    super(element, true);\n  }","id":37431,"modified_method":"public AntDomTargetReference(PsiElement element) {\n    super(element, true);\n    myGroup = null;\n  }","commit_id":"0f8753851073aab59f5a3ccbbdccedb8d0bce961","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  @Override\n  public String getQualifiedName() {\n    final SRepository repository = ProjectHelper.toMPSProject(getProject()).getRepository();\n    final Ref<String> result = new Ref<String>();\n\n    repository.getModelAccess().runReadAction(new Runnable() {\n      @Override\n      public void run() {\n        SNode node = getSNodeReference().resolve(repository);\n        result.set(ClassUtil.getClassFQName(node));\n      }\n    });\n\n    return result.get();\n  }","id":37432,"modified_method":"@Nullable\n  @Override\n  public String getQualifiedName() {\n    synchronized (LOG) {\n\n      if (myFQName == null) {\n        final SRepository repository = ProjectHelper.toMPSProject(getProject()).getRepository();\n        repository.getModelAccess().runReadAction(new Runnable() {\n          @Override\n          public void run() {\n            SNode node = getSNodeReference().resolve(repository);\n            myFQName = ClassUtil.getClassFQName(node);\n          }\n        });\n\n      }\n\n      return myFQName;\n    }\n  }","commit_id":"d5d2880df75961d14d29ccabd56c40e2db0ef804","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public void refactor(RefactoringContext refactoringContext) {\n    // mps refactoring\n    baseRefactoring.refactor(refactoringContext);\n\n    // now do the PSI part of refactoring\n\n    Project project = ProjectHelper.toIdeaProject(refactoringContext.getCurrentOperationContext().getProject());\n    PsiMethod method = (PsiMethod) MPSPsiProvider.getInstance(project).getPsi(refactoringContext.getSelectedNode());\n\n    String newName = (String) refactoringContext.getParameter(\"newName\");\n\n    for (PsiReference ref : query(method)) {\n      if (ref.getElement() instanceof MPSPsiNodeBase) continue;\n      ref.handleElementRename(newName);\n    }\n\n    if (myOverriding) {\n      // rename overriding methods\n      for (PsiMethod m : OverridingMethodsSearch.search(method).findAll()) {\n        if (m instanceof MPSPsiNode) continue;\n        m.setName(newName);\n      }\n    }\n\n  }","id":37433,"modified_method":"@Override\n  public void refactor(RefactoringContext refactoringContext) {\n    // mps refactoring\n    baseRefactoring.refactor(refactoringContext);\n\n    // now do the PSI part of refactoring\n\n    Project project = ProjectHelper.toIdeaProject(refactoringContext.getCurrentOperationContext().getProject());\n    PsiMethod method = (PsiMethod) MPSPsiProvider.getInstance(project).getPsi(refactoringContext.getSelectedNode());\n\n    String newName = (String) refactoringContext.getParameter(\"newName\");\n\n    SearchResults<SNode> usages = (SearchResults<SNode>) refactoringContext.getUsages();\n\n    for (SearchResult<SNode> result : usages.getSearchResults()) {\n      if (!(result instanceof PsiSearchResult)) continue;\n      PsiReference psiRef = ((PsiSearchResult) result).getReference();\n      if (psiRef.getElement() instanceof MPSPsiNode) continue;\n      psiRef.handleElementRename(newName);\n    }\n\n    if (myOverriding) {\n      // rename overriding methods\n      for (PsiMethod m : OverridingMethodsSearch.search(method).findAll()) {\n        if (m instanceof MPSPsiNode) continue;\n        m.setName(newName);\n      }\n    }\n\n  }","commit_id":"d5d2880df75961d14d29ccabd56c40e2db0ef804","url":"https://github.com/JetBrains/MPS"},{"original_method":"/**\n   * returns true if the content should be reloaded from storage after save\n   */\n  public static boolean saveModel(SModel modelData, MultiStreamDataSource source, int persistenceVersion) throws IOException {\n    persistenceVersion = actualPersistenceVersion(persistenceVersion);\n\n    // upgrade?\n    SModelHeader modelHeader = null;\n    int oldVersion = persistenceVersion;\n    if (modelData instanceof DefaultSModel) {\n      DefaultSModel dsm = (DefaultSModel) modelData;\n      modelHeader = dsm.getSModelHeader();\n      oldVersion = modelHeader.getPersistenceVersion();\n      if (oldVersion != persistenceVersion) {\n        modelHeader.setPersistenceVersion(persistenceVersion);\n      }\n    }\n\n    // save into JDOM\n    if (persistenceVersion < 9) {\n      modelData.getImplicitImportsSupport().calculateImplicitImports();\n    }\n    Map<String, Document> result = ModelPersistence.getPersistence(persistenceVersion).getModelWriter(modelHeader).saveModelAsMultiStream(modelData);\n\n    // write to storage\n    Set<String> toRemove = new HashSet<String>();\n    for (String s : source.getAvailableStreams()) {\n      if (!result.containsKey(s)) toRemove.add(s);\n    }\n    for (Entry<String, Document> entry : result.entrySet()) {\n      //if we have a file having a name, which differs in case only, we want to remove this file before writing to the new one\n      //to sync cases in root- and filenames\n      String fnameLower = entry.getKey().toLowerCase();\n      Set<String> removed = new HashSet<String>();\n      for (String s : toRemove) {\n        if (s.toLowerCase().equals(fnameLower)){\n          source.delete(s);\n          removed.add(s);\n        }\n      }\n      toRemove.removeAll(removed);\n\n      JDOMUtil.writeDocument(entry.getValue(), source, entry.getKey());\n    }\n    for (String r : toRemove) {\n      source.delete(r);\n    }\n\n    if (oldVersion != persistenceVersion) {\n      LOG.info(\"persistence upgraded: \" + oldVersion + \"->\" + persistenceVersion + \" \" + modelData.getReference());\n      return true;\n    }\n    return false;\n  }","id":37434,"modified_method":"/**\n   * returns true if the content should be reloaded from storage after save\n   */\n  public static boolean saveModel(SModel modelData, MultiStreamDataSource source, int persistenceVersion) throws IOException {\n    persistenceVersion = actualPersistenceVersion(persistenceVersion);\n\n    // upgrade?\n    SModelHeader modelHeader = null;\n    int oldVersion = persistenceVersion;\n    if (modelData instanceof DefaultSModel) {\n      DefaultSModel dsm = (DefaultSModel) modelData;\n      modelHeader = dsm.getSModelHeader();\n      oldVersion = modelHeader.getPersistenceVersion();\n      if (oldVersion != persistenceVersion) {\n        modelHeader.setPersistenceVersion(persistenceVersion);\n      }\n    }\n\n    // save into JDOM\n    if (persistenceVersion < 9) {\n      modelData.getImplicitImportsSupport().calculateImplicitImports();\n    }\n    ModelPersistence.checkV8(persistenceVersion, modelHeader == null ? null : modelHeader.getModelReference(), source.getLocation());\n\n    IModelPersistence persistence = ModelPersistence.getPersistence(persistenceVersion);\n    if (persistence == null) {\n      return false;\n    }\n    IModelWriter writer = persistence.getModelWriter(modelHeader);\n    if (writer == null) {\n      return false;\n    }\n\n    Map<String, Document> result = writer.saveModelAsMultiStream(modelData);\n\n    // write to storage\n    Set<String> toRemove = new HashSet<String>();\n    for (String s : source.getAvailableStreams()) {\n      if (!result.containsKey(s)) {\n        toRemove.add(s);\n      }\n    }\n    for (Entry<String, Document> entry : result.entrySet()) {\n      //if we have a file having a name, which differs in case only, we want to remove this file before writing to the new one\n      //to sync cases in root- and filenames\n      String fnameLower = entry.getKey().toLowerCase();\n      Set<String> removed = new HashSet<String>();\n      for (String s : toRemove) {\n        if (s.toLowerCase().equals(fnameLower)) {\n          source.delete(s);\n          removed.add(s);\n        }\n      }\n      toRemove.removeAll(removed);\n\n      JDOMUtil.writeDocument(entry.getValue(), source, entry.getKey());\n    }\n    for (String r : toRemove) {\n      source.delete(r);\n    }\n\n    if (oldVersion != persistenceVersion) {\n      LOG.info(\"persistence upgraded: \" + oldVersion + \"->\" + persistenceVersion + \" \" + modelData.getReference());\n      return true;\n    }\n    return false;\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static ModelLoadResult readModel(SModelHeader header, MultiStreamDataSource dataSource, ModelLoadingState targetState) throws ModelReadException {\n    IModelPersistence mp = ModelPersistence.getPersistence(header.getPersistenceVersion());\n    if (mp == null) throw new ModelReadException(\"Couldn't read model because of unknown persistence version\", null);\n\n    // load .model file\n    DefaultSModel result;\n    XMLSAXHandler<ModelLoadResult> headerHandler = mp.getModelReaderHandler(targetState, header);\n    InputStream in = null;\n    try {\n      in = dataSource.openInputStream(FilePerRootDataSource.HEADER_FILE);\n      InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n      ModelPersistence.parseAndHandleExceptions(source, headerHandler);\n      if (headerHandler.getResult().getContentKind() != ContentKind.MODEL_HEADER) {\n        throw new ModelReadException(\"Couldn't read model: .model file is broken\", null);\n      }\n    } catch (Exception e) {\n      Throwable th = e.getCause() == null ? e : e.getCause();\n      throw new ModelReadException(String.format(\"Couldn't read .model file: %s\", th.getMessage()), e, header);\n    } finally {\n      FileUtil.closeFileSafe(in);\n    }\n    result = (DefaultSModel) headerHandler.getResult().getModel();\n    header = result.getSModelHeader();\n\n    // load roots\n    List<String> streams = new ArrayList<String>();\n    for (String s : dataSource.getAvailableStreams()) streams.add(s);\n    Collections.sort(streams);\n    for (String stream : streams) {\n      if (!(stream.endsWith(FilePerRootDataSource.ROOT_EXTENSION))) continue;\n\n      XMLSAXHandler<ModelLoadResult> rootHandler = mp.getModelReaderHandler(targetState, header);\n      in = null;\n      try {\n        in = dataSource.openInputStream(stream);\n        InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n        ModelPersistence.parseAndHandleExceptions(source, rootHandler);\n        if (rootHandler.getResult().getContentKind() != ContentKind.MODEL_ROOT) {\n          throw new ModelReadException(\"Couldn't read model: \" + stream + \" root file is broken\", null);\n        }\n        if (rootHandler.getResult().getState() == ModelLoadingState.INTERFACE_LOADED) {\n          headerHandler.getResult().setState(ModelLoadingState.INTERFACE_LOADED);\n        }\n        int count = 0;\n        SModel model = rootHandler.getResult().getModel();\n        model.enterUpdateMode();\n        for (SNode rootNode : model.getRootNodes()) {\n          if (count != 0) {\n            throw new ModelReadException(String.format(\"Couldn't read model from stream %s: root file is broken - contains more than one roots\", stream), null);\n          }\n          count++;\n          // detach it from its spurious model, which is just a container for this single root\n          model.removeRootNode(rootNode);\n          // now that it's detached we can safely add it to our model\n          result.addRootNode(rootNode);\n        }\n        model.leaveUpdateMode();\n      } catch (Exception e) {\n        Throwable th = e.getCause() == null ? e : e.getCause();\n        throw new ModelReadException(String.format(\"Couldn't read model from stream %s: %s\", stream, th.getMessage()), th, header);\n      } finally {\n        FileUtil.closeFileSafe(in);\n      }\n    }\n\n    return headerHandler.getResult();\n  }","id":37435,"modified_method":"public static ModelLoadResult readModel(SModelHeader header, MultiStreamDataSource dataSource, ModelLoadingState targetState) throws ModelReadException {\n    ModelPersistence.checkV8(header.getPersistenceVersion(), header.getModelReference(), dataSource.getLocation());\n\n    IModelPersistence mp = ModelPersistence.getPersistence(header.getPersistenceVersion());\n    if (mp == null) {\n      throw new ModelReadException(\"Couldn't read model because of unknown persistence version\", null);\n    }\n\n    // load .model file\n    DefaultSModel result;\n    XMLSAXHandler<ModelLoadResult> headerHandler = mp.getModelReaderHandler(targetState, header);\n    InputStream in = null;\n    try {\n      in = dataSource.openInputStream(FilePerRootDataSource.HEADER_FILE);\n      InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n      ModelPersistence.parseAndHandleExceptions(source, headerHandler);\n      if (headerHandler.getResult().getContentKind() != ContentKind.MODEL_HEADER) {\n        throw new ModelReadException(\"Couldn't read model: .model file is broken\", null);\n      }\n    } catch (Exception e) {\n      Throwable th = e.getCause() == null ? e : e.getCause();\n      throw new ModelReadException(String.format(\"Couldn't read .model file: %s\", th.getMessage()), e, header);\n    } finally {\n      FileUtil.closeFileSafe(in);\n    }\n    result = (DefaultSModel) headerHandler.getResult().getModel();\n    header = result.getSModelHeader();\n\n    // load roots\n    List<String> streams = new ArrayList<String>();\n    for (String s : dataSource.getAvailableStreams()) {\n      streams.add(s);\n    }\n    Collections.sort(streams);\n    for (String stream : streams) {\n      if (!(stream.endsWith(FilePerRootDataSource.ROOT_EXTENSION))) {\n        continue;\n      }\n\n      XMLSAXHandler<ModelLoadResult> rootHandler = mp.getModelReaderHandler(targetState, header);\n      in = null;\n      try {\n        in = dataSource.openInputStream(stream);\n        InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n        ModelPersistence.parseAndHandleExceptions(source, rootHandler);\n        if (rootHandler.getResult().getContentKind() != ContentKind.MODEL_ROOT) {\n          throw new ModelReadException(\"Couldn't read model: \" + stream + \" root file is broken\", null);\n        }\n        if (rootHandler.getResult().getState() == ModelLoadingState.INTERFACE_LOADED) {\n          headerHandler.getResult().setState(ModelLoadingState.INTERFACE_LOADED);\n        }\n        int count = 0;\n        SModel model = rootHandler.getResult().getModel();\n        model.enterUpdateMode();\n        for (SNode rootNode : model.getRootNodes()) {\n          if (count != 0) {\n            throw new ModelReadException(String.format(\"Couldn't read model from stream %s: root file is broken - contains more than one roots\", stream), null);\n          }\n          count++;\n          // detach it from its spurious model, which is just a container for this single root\n          model.removeRootNode(rootNode);\n          // now that it's detached we can safely add it to our model\n          result.addRootNode(rootNode);\n        }\n        model.leaveUpdateMode();\n      } catch (Exception e) {\n        Throwable th = e.getCause() == null ? e : e.getCause();\n        throw new ModelReadException(String.format(\"Couldn't read model from stream %s: %s\", stream, th.getMessage()), th, header);\n      } finally {\n        FileUtil.closeFileSafe(in);\n      }\n    }\n\n    return headerHandler.getResult();\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Nullable\n  public static IModelPersistence getPersistence(int version) {\n    if (version == 8) {\n      //todo remove after 3.3\n      LOG.error(\"Model Persistence 8 has limited support in MPS 3.3 and will be completely removed in the next release.\\n\" +\n          \"Please execute Main Menu->Migration->Migrations->Project Migrations->Migrate v8 Models\");\n      return new ModelPersistence8();\n    }\n\n    if (version == 9) return new ModelPersistence9();\n\n    assert !isSupported(version) : \"inconsistent ModelPersistence.isSupported and .getPersistence. Version=\" + version;\n    LOG.error(\"Unknown persistence version requested: \" + version, new Throwable());\n    return null;\n  }","id":37436,"modified_method":"@Nullable\n  public static IModelPersistence getPersistence(int version) {\n    if (version == 8) {\n      return new ModelPersistence8();\n    }\n\n    if (version == 9) {\n      return new ModelPersistence9();\n    }\n\n    assert !isSupported(version) : \"inconsistent ModelPersistence.isSupported and .getPersistence. Version=\" + version;\n    LOG.error(\"Unknown persistence version requested: \" + version, new Throwable());\n    return null;\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"/**\n   * Serialize model to xml in conformance with given persistence version.\n   *\n   * @throws java.lang.IllegalArgumentException if persistenceVersion is invalid (use {@link #LAST_VERSION} if uncertain\n   */\n  private static Document modelToXml(@NotNull SModel model, int persistenceVersion) {\n    IModelPersistence modelPersistence = getPersistence(persistenceVersion);\n    if (modelPersistence == null) {\n      throw new IllegalArgumentException(String.format(\"Unknown persistence version %d\", persistenceVersion));\n    }\n    if (persistenceVersion < 9) {\n      model.getImplicitImportsSupport().calculateImplicitImports();\n    }\n    return modelPersistence.getModelWriter(model instanceof DefaultSModel ? ((DefaultSModel) model).getSModelHeader() : null).saveModel(model);\n  }","id":37437,"modified_method":"/**\n   * Serialize model to xml in conformance with given persistence version.\n   *\n   * @throws java.lang.IllegalArgumentException if persistenceVersion is invalid (use {@link #LAST_VERSION} if uncertain\n   */\n  private static Document modelToXml(@NotNull SModel model, int persistenceVersion) {\n    IModelPersistence modelPersistence = getPersistence(persistenceVersion);\n    if (modelPersistence == null) {\n      throw new IllegalArgumentException(String.format(\"Unknown persistence version %d\", persistenceVersion));\n    }\n    SModelBase md = model.getModelDescriptor();\n    String location = md == null ? null : md.getSource().getLocation();\n    ModelPersistence.checkV8(persistenceVersion, model.getReference(), location);\n\n    if (persistenceVersion < 9) {\n      model.getImplicitImportsSupport().calculateImplicitImports();\n    }\n    IModelWriter modelWriter = modelPersistence.getModelWriter(model instanceof DefaultSModel ? ((DefaultSModel) model).getSModelHeader() : null);\n    if (modelWriter == null) {\n      throw new IllegalArgumentException(String.format(\"Unknown persistence version %d\", persistenceVersion));\n    }\n    return modelWriter.saveModel(model);\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"@NotNull\n  public static ModelLoadResult readModel(@NotNull SModelHeader header, @NotNull StreamDataSource dataSource, ModelLoadingState state) throws\n      ModelReadException {\n    InputStream in = null;\n    try {\n      in = dataSource.openInputStream();\n      InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n      return readModel(header, source, state);\n    } catch (IOException e) {\n      throw new ModelReadException(\"Couldn't read model: \" + e.getMessage(), e, header);\n    } finally {\n      FileUtil.closeFileSafe(in);\n    }\n  }","id":37438,"modified_method":"@NotNull\n  public static ModelLoadResult readModel(@NotNull SModelHeader header, @NotNull StreamDataSource dataSource, ModelLoadingState state) throws\n      ModelReadException {\n    InputStream in = null;\n    try {\n      in = dataSource.openInputStream();\n      InputSource source = new InputSource(new InputStreamReader(in, FileUtil.DEFAULT_CHARSET));\n      ModelPersistence.checkV8(header.getPersistenceVersion(), header.getModelReference(), dataSource.getLocation());\n      return readModel(header, source, state);\n    } catch (IOException e) {\n      throw new ModelReadException(\"Couldn't read model: \" + e.getMessage(), e, header);\n    } finally {\n      FileUtil.closeFileSafe(in);\n    }\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static ModelLoadResult readModel(@NotNull SModelHeader header, @NotNull InputSource source, ModelLoadingState state) throws ModelReadException {\n    int ver = header.getPersistenceVersion();\n    if (ver < 0) throw new ModelReadException(\"Couldn't read model because of unknown persistence version\", null);\n\n    IModelPersistence mp = getPersistence(ver);\n    if (mp == null) {\n      String m = \"Can not find appropriate persistence version for model %s\\n Use newer version of JetBrains MPS to load this model.\";\n      throw new PersistenceVersionNotFoundException(String.format(m, header.getModelReference()));\n    }\n\n    XMLSAXHandler<ModelLoadResult> handler = mp.getModelReaderHandler(state, header);\n    if (handler == null) {\n      String m = \"Can not find appropriate persistence version for model %s\\n Use newer version of JetBrains MPS to load this model.\";\n      throw new PersistenceVersionNotFoundException(String.format(m, header.getModelReference()));\n    }\n    try {\n      parseAndHandleExceptions(source, handler);\n      // in case persistence version could change during IModelPersistence activities, might need to update header:\n      // header.setPersistenceVersion(mp.getVersion());\n      return handler.getResult();\n    } catch (Exception ex) {\n      Throwable th = ex.getCause() == null ? ex : ex.getCause();\n      throw new ModelReadException(String.format(\"Failed to load model: %s\", th.getMessage()), th, header);\n    }\n  }","id":37439,"modified_method":"private static ModelLoadResult readModel(@NotNull SModelHeader header, @NotNull InputSource source, ModelLoadingState state) throws ModelReadException {\n    int ver = header.getPersistenceVersion();\n    if (ver < 0) {\n      throw new ModelReadException(\"Couldn't read model because of unknown persistence version\", null);\n    }\n\n    ModelPersistence.checkV8(ver, header.getModelReference(), null);\n    IModelPersistence mp = getPersistence(ver);\n    if (mp == null) {\n      String m = \"Can not find appropriate persistence version for model %s\\n Use newer version of JetBrains MPS to load this model.\";\n      throw new PersistenceVersionNotFoundException(String.format(m, header.getModelReference()));\n    }\n\n    XMLSAXHandler<ModelLoadResult> handler = mp.getModelReaderHandler(state, header);\n    if (handler == null) {\n      String m = \"Can not find appropriate persistence version for model %s\\n Use newer version of JetBrains MPS to load this model.\";\n      throw new PersistenceVersionNotFoundException(String.format(m, header.getModelReference()));\n    }\n    try {\n      parseAndHandleExceptions(source, handler);\n      // in case persistence version could change during IModelPersistence activities, might need to update header:\n      // header.setPersistenceVersion(mp.getVersion());\n      return handler.getResult();\n    } catch (Exception ex) {\n      Throwable th = ex.getCause() == null ? ex : ex.getCause();\n      throw new ModelReadException(String.format(\"Failed to load model: %s\", th.getMessage()), th, header);\n    }\n  }","commit_id":"5c36e402c4c4216822bfe0e77a76d9d83f106eac","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static void saveDebugInfo(Collection<SLanguage> languages, Collection<ImportElement> importedModels, Iterable<SNode> rootNodes, ModelOutputStream os) throws IOException {\n\n    //save used languages info\n    os.writeInt(languages.size());\n    for (SLanguage language : languages) {\n      os.writeString(IdHelper.getLanguageId(language).serialize());\n      os.writeString(language.getQualifiedName());\n    }\n\n    //  devkits??\n\n    //save used models info\n    os.writeInt(importedModels.size());\n    for (ImportElement ie : importedModels) {\n      SModelReference ref = ie.getModelReference();\n      org.jetbrains.mps.openapi.model.SModel model = ref.resolve(MPSModuleRepository.getInstance());\n      String name = model != null ? model.getModelName() : DebugRegistry.getInstance().getModelName(ref);\n\n      os.writeModelReference(ref);\n      os.writeString(name == null ? \"\" : name);\n    }\n\n    //collect all language-level info\n\n    //save concepts info\n    Map<SConceptId, String> conceptIds = new HashMap<SConceptId, String>();\n    Map<SPropertyId, String> propIds = new HashMap<SPropertyId, String>();\n    Map<SReferenceLinkId, String> refIds = new HashMap<SReferenceLinkId, String>();\n    Map<SContainmentLinkId, String> roleIds = new HashMap<SContainmentLinkId, String>();\n\n    IdInfoCollector.getDebugInfoById(rootNodes, conceptIds, propIds, refIds, roleIds);\n\n    // write concepts\n    os.writeInt(conceptIds.size());\n    for (Entry<SConceptId, String> e : conceptIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write properties\n    os.writeInt(propIds.size());\n    for (Entry<SPropertyId, String> e : propIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write reference roles\n    os.writeInt(refIds.size());\n    for (Entry<SReferenceLinkId, String> e : refIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write child roles\n    os.writeInt(roleIds.size());\n    for (Entry<SContainmentLinkId, String> e : roleIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n  }","id":37440,"modified_method":"private static void saveDebugInfo(Collection<SLanguage> languages, Collection<ImportElement> importedModels, Iterable<SNode> rootNodes, ModelOutputStream os) throws IOException {\n\n    //save used languages info\n    os.writeInt(languages.size());\n    for (SLanguage language : languages) {\n      os.writeString(IdHelper.getLanguageId(language).serialize());\n      os.writeString(language.getQualifiedName());\n    }\n\n    //  devkits??\n\n    //save used models info\n    os.writeInt(importedModels.size());\n    for (ImportElement ie : importedModels) {\n      SModelReference ref = ie.getModelReference();\n      org.jetbrains.mps.openapi.model.SModel model = ref.resolve(MPSModuleRepository.getInstance());\n      String name = model != null ? model.getModelName() : DebugRegistry.getInstance().getModelName(ref);\n\n      os.writeModelReference(ref);\n      os.writeString(name == null ? \"\" : name);\n    }\n\n    //collect all language-level info\n\n    //save concepts info\n    Map<SConceptId, String> conceptIds = new HashMap<SConceptId, String>();\n    Map<SPropertyId, String> propIds = new HashMap<SPropertyId, String>();\n    Map<SReferenceLinkId, String> refIds = new HashMap<SReferenceLinkId, String>();\n    Map<SContainmentLinkId, String> roleIds = new HashMap<SContainmentLinkId, String>();\n\n    final IdInfoCollector ic = new IdInfoCollector();\n    ic.fill(rootNodes);\n    ic.getDebugInfoById(conceptIds, propIds, refIds, roleIds);\n\n    // write concepts\n    os.writeInt(conceptIds.size());\n    for (Entry<SConceptId, String> e : conceptIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write properties\n    os.writeInt(propIds.size());\n    for (Entry<SPropertyId, String> e : propIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write reference roles\n    os.writeInt(refIds.size());\n    for (Entry<SReferenceLinkId, String> e : refIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n\n    // write child roles\n    os.writeInt(roleIds.size());\n    for (Entry<SContainmentLinkId, String> e : roleIds.entrySet()) {\n      os.writeString(e.getKey().serialize());\n      os.writeString(e.getValue() == null ? \"\" : e.getValue());\n    }\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static void getDebugInfoById(Iterable<SNode> rootNodes, Map<SConceptId, String> conceptIds, Map<SPropertyId, String> propIds,\n      Map<SReferenceLinkId, String> refIds, Map<SContainmentLinkId, String> linkIds) {\n    for (SNode root : rootNodes) {\n      for (SNode n : SNodeUtil.getDescendants(root)) {\n        SConceptId conceptId = IdHelper.getConceptId(n.getConcept());\n        if (conceptId != null) {\n          conceptIds.put(conceptId, n.getConcept().getQualifiedName());\n        }\n\n        if (n.getParent() != null) {\n          SContainmentLink link = n.getContainmentLink();\n          SContainmentLinkId linkId = IdHelper.getLinkId(link);\n          linkIds.put(linkId, link.getRoleName());\n          SConceptId linkConceptId = linkId.getConceptId();\n          if (!conceptIds.containsKey(linkConceptId)) {\n            String conceptName = getConceptName(linkConceptId);\n            if (conceptName != null) {\n              conceptIds.put(linkConceptId, conceptName);\n            }\n          }\n        }\n\n        for (SProperty prop : n.getProperties()) {\n          SPropertyId propId = IdHelper.getPropertyId(prop);\n          propIds.put(propId, prop.getName());\n          SConceptId propConceptId = propId.getConceptId();\n          if (!conceptIds.containsKey(propConceptId)) {\n            String conceptName = getConceptName(propConceptId);\n            if (conceptName != null) {\n              conceptIds.put(propConceptId, conceptName);\n            }\n          }\n        }\n\n        for (SReference ref : n.getReferences()) {\n          SReferenceLinkId refId = IdHelper.getRefId(ref.getLink());\n          refIds.put(refId, ref.getRole());\n          SConceptId refConceptId = refId.getConceptId();\n          if (!conceptIds.containsKey(refConceptId)) {\n            String conceptName = getConceptName(refConceptId);\n            if (conceptName != null) {\n              conceptIds.put(refConceptId, conceptName);\n            }\n          }\n        }\n      }\n    }\n  }","id":37441,"modified_method":"public void getDebugInfoById(Map<SConceptId, String> conceptIds, Map<SPropertyId, String> propIds,\n      Map<SReferenceLinkId, String> refIds, Map<SContainmentLinkId, String> linkIds) {\n    for (LangInfo langInfo : getLanguagesInUse()) {\n      for (ConceptInfo ci : langInfo.getConceptsInUse()) {\n        if (!MetaIdFactory.INVALID_CONCEPT_NAME.equals(ci.getName())) {\n          conceptIds.put(ci.getConceptId(), ci.getName());\n        }\n        for (PropertyInfo pi : ci.getPropertiesInUse()) {\n          propIds.put(pi.getPropertyId(), pi.getName());\n        }\n        for (AssociationLinkInfo li : ci.getAssociationsInUse()) {\n          refIds.put(li.getLinkId(), li.getName());\n        }\n        for (AggregationLinkInfo li : ci.getAggregationsInUse()) {\n          linkIds.put(li.getLinkId(), li.getName());\n        }\n      }\n    }\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public XMLSAXHandler<ModelLoadResult> getModelReaderHandler(ModelLoadingState state, SModelHeader header) {\n    return new ModelReader9Handler(state == ModelLoadingState.INTERFACE_LOADED, state == ModelLoadingState.NO_IMPLEMENTATION, header);\n  }","id":37442,"modified_method":"@Override\n  public XMLSAXHandler<ModelLoadResult> getModelReaderHandler(ModelLoadingState state, SModelHeader header) {\n    if (isConcisePersistenceOption(header)) {\n      return new ModelReader9bisHandler(state == ModelLoadingState.INTERFACE_LOADED, state == ModelLoadingState.NO_IMPLEMENTATION, header);\n    }\n    return new ModelReader9Handler(state == ModelLoadingState.INTERFACE_LOADED, state == ModelLoadingState.NO_IMPLEMENTATION, header);\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public IModelWriter getModelWriter(@Nullable SModelHeader header) {\n    return getModelWriter();\n  }","id":37443,"modified_method":"@Override\n  public IModelWriter getModelWriter(@Nullable SModelHeader header) {\n    return isConcisePersistenceOption(header) ? new ModelWriter9bis() : getModelWriter();\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void saveDebugInfo(Element debugInfoElement, SModel sourceModel) {\n    DebugRegistry debugRegistry = DebugRegistry.getInstance();\n\n    //save used languages info\n    ArrayList<SLanguage> langs = new ArrayList<SLanguage>(sourceModel.usedLanguages());\n    langs.addAll(sourceModel.implicitlyUsedLanguagesWithVersions().keySet());\n    sortLanguages(langs);\n\n    for (SLanguage id : langs) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_LANG);\n      langElement.setAttribute(ModelPersistence9.ID, IdHelper.getLanguageId(id).serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, id.getQualifiedName());\n      debugInfoElement.addContent(langElement);\n    }\n\n    //  devkits??\n\n    //save used models info\n    for (ImportElement ie : sourceModel.importedModels()) {\n      SModelReference ref = ie.getModelReference();\n      org.jetbrains.mps.openapi.model.SModel model = ref.resolve(MPSModuleRepository.getInstance());\n      String name = model != null ? model.getModelName() : debugRegistry.getModelName(ref);\n\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_MODEL);\n      langElement.setAttribute(ModelPersistence9.REF, ref.toString());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, name);\n      debugInfoElement.addContent(langElement);\n    }\n\n    //collect all language-level info\n\n    //save concepts info\n    Map<SConceptId, String> conceptIds = new HashMap<SConceptId, String>();\n    Map<SPropertyId, String> propIds = new HashMap<SPropertyId, String>();\n    Map<SReferenceLinkId, String> refIds = new HashMap<SReferenceLinkId, String>();\n    Map<SContainmentLinkId, String> roleIds = new HashMap<SContainmentLinkId, String>();\n\n    IdInfoCollector.getDebugInfoById(sourceModel.getRootNodes(), conceptIds, propIds, refIds, roleIds);\n\n    // write concepts\n    ArrayList<SConceptId> cids = new ArrayList<SConceptId>(conceptIds.keySet());\n    sortConcepts(cids);\n    for (SConceptId id : cids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_CONCEPT);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, conceptIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write properties\n    ArrayList<SPropertyId> pids = new ArrayList<SPropertyId>(propIds.keySet());\n    sortProps(pids);\n    for (SPropertyId id : pids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_PROP);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, propIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write reference roles\n    ArrayList<SReferenceLinkId> rids = new ArrayList<SReferenceLinkId>(refIds.keySet());\n    sortRefs(rids);\n    for (SReferenceLinkId id : rids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_REF_ROLE);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, refIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write child roles\n    ArrayList<SContainmentLinkId> lids = new ArrayList<SContainmentLinkId>(roleIds.keySet());\n    sortLinks(lids);\n    for (SContainmentLinkId id : lids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_CHILD_ROLE);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, roleIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n  }","id":37444,"modified_method":"private void saveDebugInfo(Element debugInfoElement, SModel sourceModel) {\n    DebugRegistry debugRegistry = DebugRegistry.getInstance();\n\n    //save used languages info\n    ArrayList<SLanguage> langs = new ArrayList<SLanguage>(sourceModel.usedLanguages());\n    langs.addAll(sourceModel.implicitlyUsedLanguagesWithVersions().keySet());\n    sortLanguages(langs);\n\n    for (SLanguage id : langs) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_LANG);\n      langElement.setAttribute(ModelPersistence9.ID, IdHelper.getLanguageId(id).serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, id.getQualifiedName());\n      debugInfoElement.addContent(langElement);\n    }\n\n    //  devkits??\n\n    //save used models info\n    for (ImportElement ie : sourceModel.importedModels()) {\n      SModelReference ref = ie.getModelReference();\n      org.jetbrains.mps.openapi.model.SModel model = ref.resolve(MPSModuleRepository.getInstance());\n      String name = model != null ? model.getModelName() : debugRegistry.getModelName(ref);\n\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_MODEL);\n      langElement.setAttribute(ModelPersistence9.REF, ref.toString());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, name);\n      debugInfoElement.addContent(langElement);\n    }\n\n    //collect all language-level info\n\n    //save concepts info\n    Map<SConceptId, String> conceptIds = new HashMap<SConceptId, String>();\n    Map<SPropertyId, String> propIds = new HashMap<SPropertyId, String>();\n    Map<SReferenceLinkId, String> refIds = new HashMap<SReferenceLinkId, String>();\n    Map<SContainmentLinkId, String> roleIds = new HashMap<SContainmentLinkId, String>();\n\n    final IdInfoCollector ic = new IdInfoCollector();\n    ic.fill(sourceModel.getRootNodes());\n    ic.getDebugInfoById(conceptIds, propIds, refIds, roleIds);\n\n    // write concepts\n    ArrayList<SConceptId> cids = new ArrayList<SConceptId>(conceptIds.keySet());\n    sortConcepts(cids);\n    for (SConceptId id : cids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_CONCEPT);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, conceptIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write properties\n    ArrayList<SPropertyId> pids = new ArrayList<SPropertyId>(propIds.keySet());\n    sortProps(pids);\n    for (SPropertyId id : pids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_PROP);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, propIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write reference roles\n    ArrayList<SReferenceLinkId> rids = new ArrayList<SReferenceLinkId>(refIds.keySet());\n    sortRefs(rids);\n    for (SReferenceLinkId id : rids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_REF_ROLE);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, refIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n\n    // write child roles\n    ArrayList<SContainmentLinkId> lids = new ArrayList<SContainmentLinkId>(roleIds.keySet());\n    sortLinks(lids);\n    for (SContainmentLinkId id : lids) {\n      Element langElement = new Element(ModelPersistence9.DEBUG_INFO_CHILD_ROLE);\n      langElement.setAttribute(ModelPersistence9.ID, id.serialize());\n      langElement.setAttribute(ModelPersistence9.DEBUG_INFO_NAME, roleIds.get(id));\n      debugInfoElement.addContent(langElement);\n    }\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected void saveNode(Element nodeElement, SNode node, boolean saveChildren) {\n    nodeElement.setAttribute(ModelPersistence9.CONCEPT_ID, myHelper.getConceptIndex(IdHelper.getConceptId(node.getConcept())));\n    nodeElement.setAttribute(ModelPersistence9.ID, node.getNodeId().toString());\n    if (node.getParent() != null) {\n      DocUtil.setNotNullAttribute(nodeElement, ModelPersistence9.ROLE_ID, myHelper.getLinkIndex(IdHelper.getLinkId(node.getContainmentLink())));\n    }\n    String info = Util9.genNodeInfo(PersistenceRegistry.getInstance().getModelEnvironmentInfo(), node);\n    DocUtil.setNotNullAttribute(nodeElement, ModelPersistence9.NODE_INFO, info);\n\n    for (SProperty pid : node.getProperties()) {\n      Element propertyElement = new Element(ModelPersistence9.PROPERTY);\n      propertyElement.setAttribute(ModelPersistence9.ROLE_ID, myHelper.getPropertyIndex(IdHelper.getPropertyId(pid)));\n      DocUtil.setNotNullAttribute(propertyElement, ModelPersistence9.VALUE, node.getProperty(pid));\n      nodeElement.addContent(propertyElement);\n    }\n\n    for (SReference reference : node.getReferences()) {\n      Element linkElement = new Element(ModelPersistence9.REFERENCE);\n      linkElement.setAttribute(ModelPersistence9.ROLE_ID, myHelper.getReferenceRoleIndex(IdHelper.getRefId(reference.getLink())));\n      linkElement.setAttribute(ModelPersistence9.TARGET_NODE_ID, myHelper.getRefTarget(reference));\n      DocUtil.setNotNullAttribute(linkElement, ModelPersistence9.RESOLVE_INFO, Util9.genResolveInfo(reference));\n      nodeElement.addContent(linkElement);\n    }\n\n    if (saveChildren) {\n      for (SNode childNode : node.getChildren()) {\n        Element childElement = new Element(ModelPersistence9.NODE);\n        saveNode(childElement, childNode, true);\n        nodeElement.addContent(childElement);\n      }\n    }\n  }","id":37445,"modified_method":"protected void saveNode(Element nodeElement, SNode node, boolean saveChildren) {\n    nodeElement.setAttribute(ModelPersistence9.CONCEPT_ID, myHelper.getConceptIndex(IdHelper.getConceptId(node.getConcept())));\n    nodeElement.setAttribute(ModelPersistence9.ID, node.getNodeId().toString());\n    if (node.getParent() != null) {\n      DocUtil.setNotNullAttribute(nodeElement, ModelPersistence9.ROLE_ID, myHelper.getLinkIndex(IdHelper.getLinkId(node.getContainmentLink())));\n    }\n    String info = Util9.genNodeInfo(PersistenceRegistry.getInstance().getModelEnvironmentInfo(), node);\n    DocUtil.setNotNullAttribute(nodeElement, ModelPersistence9.NODE_INFO, info);\n\n    for (SProperty pid : node.getProperties()) {\n      Element propertyElement = new Element(ModelPersistence9.PROPERTY);\n      propertyElement.setAttribute(ModelPersistence9.ROLE_ID, myHelper.getPropertyIndex(IdHelper.getPropertyId(pid)));\n      DocUtil.setNotNullAttribute(propertyElement, ModelPersistence9.VALUE, node.getProperty(pid));\n      nodeElement.addContent(propertyElement);\n    }\n\n    for (SReference reference : node.getReferences()) {\n      Element linkElement = new Element(ModelPersistence9.REFERENCE);\n      linkElement.setAttribute(ModelPersistence9.ROLE_ID, myHelper.getReferenceRoleIndex(IdHelper.getRefId(reference.getLink())));\n      linkElement.setAttribute(ModelPersistence9.TARGET_NODE_ID, myHelper.getRefTarget(reference));\n      DocUtil.setNotNullAttribute(linkElement, ModelPersistence9.RESOLVE_INFO, Util9.genResolveInfo(reference));\n      nodeElement.addContent(linkElement);\n    }\n\n    if (saveChildren) {\n      for (SNode childNode : node.getChildren()) {\n        Element childElement = new Element(ModelPersistence.NODE);\n        saveNode(childElement, childNode, true);\n        nodeElement.addContent(childElement);\n      }\n    }\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public Map<String, Document> saveModelAsMultiStream(SModel sourceModel) {\n    Map<String, Document> result = new HashMap<String, Document>();\n    myHelper = new MultiStreamStorageIndexHelper9(sourceModel.getReference());\n\n    // header\n    Element headerRoot = new Element(ModelPersistence.MODEL);\n    headerRoot.setAttribute(ModelPersistence9.REF, sourceModel.getReference().toString());\n    headerRoot.setAttribute(ModelPersistence9.FILE_CONTENT, \"header\");\n    saveModelProperties(sourceModel, headerRoot);\n    result.put(FilePerRootDataSource.HEADER_FILE, new Document(headerRoot));\n\n    // roots\n    Map<SNodeId, String> rootToFile = FilePerRootFormatUtil.getStreamNames(sourceModel);\n    for (SNode root : sourceModel.getRootNodes()) {\n      Element rootElement = new Element(ModelPersistence.MODEL);\n      rootElement.setAttribute(ModelPersistence9.REF, sourceModel.getReference().toString());\n      rootElement.setAttribute(ModelPersistence9.FILE_CONTENT, \"root\");\n\n      Element persistenceElement = new Element(ModelPersistence.PERSISTENCE);\n      persistenceElement.setAttribute(ModelPersistence.PERSISTENCE_VERSION, VERSION + \"\");\n      rootElement.addContent(persistenceElement);\n\n      //root\n      Element childElement = new Element(ModelPersistence9.NODE);\n      CollectConsumer<SModelReference> usedImports = new CollectConsumer<SModelReference>(new LinkedHashSet<SModelReference>());\n      CollectConsumer<SLanguageId> usedLangs = new CollectConsumer<SLanguageId>(new LinkedHashSet<SLanguageId>());\n      ((MultiStreamStorageIndexHelper9) myHelper).setUsedImportsListener(usedImports);\n      ((MultiStreamStorageIndexHelper9) myHelper).setLangConsumer(usedLangs);\n      saveNode(childElement, root, true);\n      ((MultiStreamStorageIndexHelper9) myHelper).setLangConsumer(null);\n      ((MultiStreamStorageIndexHelper9) myHelper).setUsedImportsListener(null);\n\n      //model imports\n      Element importsElement = new Element(ModelPersistence9.IMPORTS);\n      for (SModelReference modelRef : usedImports.getResult()) {\n        Element elem = new Element(ModelPersistence9.IMPORT);\n        elem.setAttribute(ModelPersistence9.IMPORT_INDEX, \"\" + myHelper.getImportIndex(modelRef));\n        elem.setAttribute(ModelPersistence9.REF, modelRef.toString());\n        elem.setAttribute(ModelPersistence9.IMPLICIT, \"true\");\n        importsElement.addContent(elem);\n      }\n      rootElement.addContent(importsElement);\n\n      //language imports\n      Element langsElement = new Element(ModelPersistence9.LANGUAGES);\n      for (SLanguageId lid : usedLangs.getResult()) {\n        Element languageElem = new Element(ModelPersistence9.USED_LANGUAGE);\n        languageElem.setAttribute(ModelPersistence9.ID, lid.serialize());\n        languageElem.setAttribute(ModelPersistence9.VERSION, \"-1\");\n        languageElem.setAttribute(ModelPersistence9.IMPLICIT, \"true\");\n        languageElem.setAttribute(ModelPersistence9.USE_INDEX, myHelper.getUsedLanguageIndex(lid));\n        langsElement.addContent(languageElem);\n      }\n      rootElement.addContent(langsElement);\n\n      //add root node, it should be added after imports/languages sections\n      Element contents = new Element(\"contents\");\n      contents.addContent(childElement);\n      rootElement.addContent(contents);\n\n      result.put(rootToFile.get(root.getNodeId()), new Document(rootElement));\n    }\n    return result;\n  }","id":37446,"modified_method":"@Override\n  public Map<String, Document> saveModelAsMultiStream(SModel sourceModel) {\n    Map<String, Document> result = new HashMap<String, Document>();\n    myHelper = new MultiStreamStorageIndexHelper9(sourceModel.getReference());\n\n    // header\n    Element headerRoot = new Element(ModelPersistence.MODEL);\n    headerRoot.setAttribute(ModelPersistence9.REF, sourceModel.getReference().toString());\n    headerRoot.setAttribute(ModelPersistence9.FILE_CONTENT, \"header\");\n    saveModelProperties(sourceModel, headerRoot);\n    result.put(FilePerRootDataSource.HEADER_FILE, new Document(headerRoot));\n\n    // roots\n    Map<SNodeId, String> rootToFile = FilePerRootFormatUtil.getStreamNames(sourceModel);\n    for (SNode root : sourceModel.getRootNodes()) {\n      Element rootElement = new Element(ModelPersistence.MODEL);\n      rootElement.setAttribute(ModelPersistence9.REF, sourceModel.getReference().toString());\n      rootElement.setAttribute(ModelPersistence9.FILE_CONTENT, \"root\");\n\n      Element persistenceElement = new Element(ModelPersistence.PERSISTENCE);\n      persistenceElement.setAttribute(ModelPersistence.PERSISTENCE_VERSION, VERSION + \"\");\n      rootElement.addContent(persistenceElement);\n\n      //root\n      Element childElement = new Element(ModelPersistence.NODE);\n      CollectConsumer<SModelReference> usedImports = new CollectConsumer<SModelReference>(new LinkedHashSet<SModelReference>());\n      CollectConsumer<SLanguageId> usedLangs = new CollectConsumer<SLanguageId>(new LinkedHashSet<SLanguageId>());\n      ((MultiStreamStorageIndexHelper9) myHelper).setUsedImportsListener(usedImports);\n      ((MultiStreamStorageIndexHelper9) myHelper).setLangConsumer(usedLangs);\n      saveNode(childElement, root, true);\n      ((MultiStreamStorageIndexHelper9) myHelper).setLangConsumer(null);\n      ((MultiStreamStorageIndexHelper9) myHelper).setUsedImportsListener(null);\n\n      //model imports\n      Element importsElement = new Element(ModelPersistence9.IMPORTS);\n      for (SModelReference modelRef : usedImports.getResult()) {\n        Element elem = new Element(ModelPersistence9.IMPORT);\n        elem.setAttribute(ModelPersistence9.IMPORT_INDEX, \"\" + myHelper.getImportIndex(modelRef));\n        elem.setAttribute(ModelPersistence9.REF, modelRef.toString());\n        elem.setAttribute(ModelPersistence9.IMPLICIT, \"true\");\n        importsElement.addContent(elem);\n      }\n      rootElement.addContent(importsElement);\n\n      //language imports\n      Element langsElement = new Element(ModelPersistence9.LANGUAGES);\n      for (SLanguageId lid : usedLangs.getResult()) {\n        Element languageElem = new Element(ModelPersistence9.USED_LANGUAGE);\n        languageElem.setAttribute(ModelPersistence9.ID, lid.serialize());\n        languageElem.setAttribute(ModelPersistence9.VERSION, \"-1\");\n        languageElem.setAttribute(ModelPersistence9.IMPLICIT, \"true\");\n        languageElem.setAttribute(ModelPersistence9.USE_INDEX, myHelper.getUsedLanguageIndex(lid));\n        langsElement.addContent(languageElem);\n      }\n      rootElement.addContent(langsElement);\n\n      //add root node, it should be added after imports/languages sections\n      Element contents = new Element(\"contents\");\n      contents.addContent(childElement);\n      rootElement.addContent(contents);\n\n      result.put(rootToFile.get(root.getNodeId()), new Document(rootElement));\n    }\n    return result;\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static String encode(String s) {\n    return s.replace(\"%\", \"%p\").replace(\":\", \"%c\").replace(\".\", \"%d\");\n  }","id":37447,"modified_method":"static String encode(String s) {\n    return s.replace(\"%\", \"%p\").replace(\":\", \"%c\").replace(\".\", \"%d\");\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static String decode(String s) {\n    return s.replace(\"%d\", \".\").replace(\"%c\", \":\").replace(\"%p\", \"%\");\n  }","id":37448,"modified_method":"static String decode(String s) {\n    return s.replace(\"%d\", \".\").replace(\"%c\", \":\").replace(\"%p\", \"%\");\n  }","commit_id":"346be6dee62876e6778f234cc2523be8b10b67eb","url":"https://github.com/JetBrains/MPS"},{"original_method":"/**\n   * Serialize model to xml in conformance with given persistence version.\n   *\n   * @throws java.lang.IllegalArgumentException if persistenceVersion is invalid (use {@link #LAST_VERSION} if uncertain\n   */\n  private static Document modelToXml(@NotNull SModel model, int persistenceVersion) {\n    IModelPersistence modelPersistence = getPersistence(persistenceVersion);\n    if (modelPersistence == null) {\n      throw new IllegalArgumentException(String.format(\"Unknown persistence version %d\", persistenceVersion));\n    }\n    if (persistenceVersion < 9) {\n      model.getImplicitImportsSupport().calculateImplicitImports();\n    }\n    return modelPersistence.getModelWriter(model instanceof DefaultSModel ? ((DefaultSModel) model).getSModelHeader() : null).saveModel(model);\n  }","id":37449,"modified_method":"/**\n   * Serialize model to xml in conformance with given persistence version.\n   *\n   * @throws java.lang.IllegalArgumentException if persistenceVersion is invalid (use {@link #LAST_VERSION} if uncertain\n   */\n  private static Document modelToXml(@NotNull SModel model, int persistenceVersion) {\n    IModelPersistence modelPersistence = getPersistence(persistenceVersion);\n    if (modelPersistence == null) {\n      throw new IllegalArgumentException(String.format(\"Unknown persistence version %d\", persistenceVersion));\n    }\n    IModelWriter writer = modelPersistence.getModelWriter(model instanceof DefaultSModel ? ((DefaultSModel) model).getSModelHeader() : null);\n    if (writer == null) {\n      throw new IllegalArgumentException(String.format(\"Persistence has no writer. Version %d\", persistenceVersion));\n    }\n    return writer.saveModel(model);\n  }","commit_id":"aae8da99bc3432b22567d1097c14766a0ab291a2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Nullable\n  public static IModelPersistence getPersistence(int version) {\n    if (version == 8) {\n      //todo remove after 3.3\n      LOG.error(\"Model Persistence 8 has limited support in MPS 3.3 and will be completely removed in the next release.\\n\" +\n          \"Please execute Main Menu->Migration->Migrations->Project Migrations->Migrate v8 Models\");\n      return new ModelPersistence8();\n    }\n\n    if (version == 9) return new ModelPersistence9();\n\n    assert !isSupported(version) : \"inconsistent ModelPersistence.isSupported and .getPersistence. Version=\" + version;\n    LOG.error(\"Unknown persistence version requested: \" + version, new Throwable());\n    return null;\n  }","id":37450,"modified_method":"@Nullable\n  public static IModelPersistence getPersistence(int version) {\n    if (version == 9) {\n      return new ModelPersistence9();\n    }\n\n    assert !isSupported(version) : \"inconsistent ModelPersistence.isSupported and .getPersistence. Version=\" + version;\n    LOG.error(\"Unknown persistence version requested: \" + version, new Throwable());\n    return null;\n  }","commit_id":"aae8da99bc3432b22567d1097c14766a0ab291a2","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Nullable\n  private static IModelPersistence getPersistence(int version) {\n    // Assert here was replaced with LOG.error before 3.3 as we've found a couple  \n    // places where this incompatibility with older version introduced new bugs \n    // Actually, these places must be fixed (see e.g. MPS-22503). Still, we  \n    // leave error here till 3.4 or later to minimize the number of real issues [MM] \n    if (version < 4) {\n      LOG.error(\"unsupported version requested \" + version, new Throwable());\n    }\n\n    if (version == 4) {\n      return new ModelPersistence4();\n    }\n    if (version == 5) {\n      return new ModelPersistence5();\n    }\n    if (version == 6) {\n      return new ModelPersistence6();\n    }\n    if (version == 7) {\n      return new ModelPersistence7();\n    }\n\n    // todo remove this after removing usages of VCSPersistenceSupport from everywhere except VCSPersistenceUtil \n    return ModelPersistence.getPersistence(version);\n  }","id":37451,"modified_method":"@Nullable\n  private static IModelPersistence getPersistence(int version) {\n    // Assert here was replaced with LOG.error before 3.3 as we've found a couple  \n    // places where this incompatibility with older version introduced new bugs \n    // Actually, these places must be fixed (see e.g. MPS-22503). Still, we  \n    // leave error here till 3.4 or later to minimize the number of real issues [MM] \n    if (version < 4) {\n      LOG.error(\"unsupported version requested \" + version, new Throwable());\n    }\n\n    if (version == 4) {\n      return new ModelPersistence4();\n    }\n    if (version == 5) {\n      return new ModelPersistence5();\n    }\n    if (version == 6) {\n      return new ModelPersistence6();\n    }\n    if (version == 7) {\n      return new ModelPersistence7();\n    }\n    if (version == 8) {\n      return new ModelPersistence8();\n    }\n\n    // todo remove this after removing usages of VCSPersistenceSupport from everywhere except VCSPersistenceUtil \n    return ModelPersistence.getPersistence(version);\n  }","commit_id":"aae8da99bc3432b22567d1097c14766a0ab291a2","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static boolean isEnabled(AnActionEvent e) {\n    PsiFile file = e.getData(DataKeys.PSI_FILE);\n    if (file == null || file.getLanguage() != GroovyFileType.GROOVY_LANGUAGE) {\n      return false;\n    }\n\n    final VirtualFile virtualFile = file.getVirtualFile();\n    return virtualFile != null && !GroovyCompilerConfiguration.getInstance(file.getProject()).getState().excludeFromStubGeneration.isExcluded(virtualFile);\n  }","id":37452,"modified_method":"private static boolean isEnabled(AnActionEvent e) {\n    PsiFile file = e.getData(DataKeys.PSI_FILE);\n    if (file == null || file.getLanguage() != GroovyFileType.GROOVY_LANGUAGE) {\n      return false;\n    }\n\n    final VirtualFile virtualFile = file.getVirtualFile();\n    return virtualFile != null && !GroovyCompilerConfiguration.getExcludeConfiguration(file.getProject()).isExcluded(virtualFile);\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void runGroovycCompiler(CompileContext compileContext, final Module module,\n                                    final List<VirtualFile> toCompile,\n                                    boolean forStubs,\n                                    VirtualFile outputDir,\n                                    OutputSink sink, boolean tests) {\n    GeneralCommandLine commandLine = new GeneralCommandLine();\n    final Sdk sdk = ModuleRootManager.getInstance(module).getSdk();\n    assert sdk != null; //verified before\n    SdkType sdkType = sdk.getSdkType();\n    assert sdkType instanceof JavaSdkType;\n    commandLine.setExePath(((JavaSdkType)sdkType).getVMExecutablePath(sdk));\n\n    final PathsList classPathBuilder = new PathsList();\n    classPathBuilder.add(PathUtil.getJarPathForClass(GroovycRunner.class));\n\n    addGroovyJars(module, classPathBuilder);\n\n    final ModuleChunk chunk = createChunk(module, compileContext);\n    final List<String> patchers = new SmartList<String>();\n    for (final GroovyCompilerExtension extension : GroovyCompilerExtension.EP_NAME.getExtensions()) {\n      extension.enhanceCompilerClassPath(chunk, classPathBuilder);\n      patchers.addAll(extension.getCompilationUnitPatchers(chunk));\n    }\n\n    if (\"true\".equals(System.getProperty(\"profile.groovy.compiler\"))) {\n      commandLine.addParameter(\"-Djava.library.path=\" + PathManager.getBinPath());\n      commandLine.addParameter(\"-Dprofile.groovy.compiler=true\");\n      commandLine.addParameter(\"-agentlib:yjpagent=disablej2ee,disablecounts,disablealloc,sessionname=GroovyCompiler\");\n      classPathBuilder.add(PathManager.findFileInLibDirectory(\"yjp-controller-api-redist.jar\").getAbsolutePath());\n    }\n\n    commandLine.addParameter(\"-cp\");\n    commandLine.addParameter(classPathBuilder.getPathsString());\n\n\n    commandLine.addParameter(\"-Xmx\" + GroovyCompilerConfiguration.getInstance(myProject).getState().heapSize + \"m\");\n    commandLine.addParameter(\"-XX:+HeapDumpOnOutOfMemoryError\");\n\n    //debug\n    //commandLine.addParameter(\"-Xdebug\"); commandLine.addParameter(\"-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5239\");\n\n    // Setting up process encoding according to locale\n    final ArrayList<String> list = new ArrayList<String>();\n    CompilerUtil.addLocaleOptions(list, false);\n    commandLine.addParameters(list);\n\n    commandLine.addParameter(GroovycRunner.class.getName());\n\n    try {\n      File fileWithParameters = File.createTempFile(\"toCompile\", \"\");\n      fillFileWithGroovycParameters(module, toCompile, fileWithParameters, compileContext, outputDir, patchers, tests);\n\n      commandLine.addParameter(forStubs ? \"stubs\" : \"groovyc\");\n      commandLine.addParameter(fileWithParameters.getPath());\n    }\n    catch (IOException e) {\n      LOG.error(e);\n    }\n\n    GroovycOSProcessHandler processHandler;\n\n    try {\n      processHandler = new GroovycOSProcessHandler(compileContext, commandLine.createProcess(), commandLine.getCommandLineString(), sink);\n\n      processHandler.startNotify();\n      processHandler.waitFor();\n\n      final List<VirtualFile> toRecompile = new ArrayList<VirtualFile>();\n      Set<File> toRecompileFiles = processHandler.getToRecompileFiles();\n      for (File toRecompileFile : toRecompileFiles) {\n        final VirtualFile vFile = LocalFileSystem.getInstance().findFileByIoFile(toRecompileFile);\n        LOG.assertTrue(vFile != null);\n        toRecompile.add(vFile);\n      }\n\n      for (CompilerMessage compilerMessage : processHandler.getCompilerMessages()) {\n        final CompilerMessageCategory category;\n        category = getMessageCategory(compilerMessage);\n\n        final String url = compilerMessage.getUrl();\n\n        compileContext.addMessage(category, compilerMessage.getMessage(), VfsUtil.pathToUrl(FileUtil.toSystemIndependentName(url)), compilerMessage.getLineNum(),\n                                  compilerMessage.getColumnNum());\n      }\n\n      StringBuffer unparsedBuffer = processHandler.getUnparsedOutput();\n      if (unparsedBuffer.length() != 0) compileContext.addMessage(CompilerMessageCategory.ERROR, unparsedBuffer.toString(), null, -1, -1);\n\n      List<OutputItem> outputItems = processHandler.getSuccessfullyCompiled();\n      if (forStubs) {\n        List<VirtualFile> stubFiles = new ArrayList<VirtualFile>();\n        for (final OutputItem outputItem : outputItems) {\n          final File stub = new File(outputItem.getOutputPath());\n          CompilerUtil.refreshIOFile(stub);\n          final VirtualFile file = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(stub);\n          ContainerUtil.addIfNotNull(file, stubFiles);\n        }\n        ((CompileContextEx)compileContext).addScope(new FileSetCompileScope(stubFiles, new Module[]{module}));\n        outputItems = Collections.emptyList();\n      }\n\n      sink.add(outputDir.getPath(), outputItems, toRecompile.toArray(new VirtualFile[toRecompile.size()]));\n    }\n    catch (ExecutionException e) {\n      LOG.error(e);\n    }\n  }","id":37453,"modified_method":"protected void runGroovycCompiler(CompileContext compileContext, final Module module,\n                                    final List<VirtualFile> toCompile,\n                                    boolean forStubs,\n                                    VirtualFile outputDir,\n                                    OutputSink sink, boolean tests) {\n    GeneralCommandLine commandLine = new GeneralCommandLine();\n    final Sdk sdk = ModuleRootManager.getInstance(module).getSdk();\n    assert sdk != null; //verified before\n    SdkType sdkType = sdk.getSdkType();\n    assert sdkType instanceof JavaSdkType;\n    commandLine.setExePath(((JavaSdkType)sdkType).getVMExecutablePath(sdk));\n\n    final PathsList classPathBuilder = new PathsList();\n    classPathBuilder.add(PathUtil.getJarPathForClass(GroovycRunner.class));\n\n    addGroovyJars(module, classPathBuilder);\n\n    final ModuleChunk chunk = createChunk(module, compileContext);\n    final List<String> patchers = new SmartList<String>();\n    for (final GroovyCompilerExtension extension : GroovyCompilerExtension.EP_NAME.getExtensions()) {\n      extension.enhanceCompilerClassPath(chunk, classPathBuilder);\n      patchers.addAll(extension.getCompilationUnitPatchers(chunk));\n    }\n\n    if (\"true\".equals(System.getProperty(\"profile.groovy.compiler\"))) {\n      commandLine.addParameter(\"-Djava.library.path=\" + PathManager.getBinPath());\n      commandLine.addParameter(\"-Dprofile.groovy.compiler=true\");\n      commandLine.addParameter(\"-agentlib:yjpagent=disablej2ee,disablecounts,disablealloc,sessionname=GroovyCompiler\");\n      classPathBuilder.add(PathManager.findFileInLibDirectory(\"yjp-controller-api-redist.jar\").getAbsolutePath());\n    }\n\n    commandLine.addParameter(\"-cp\");\n    commandLine.addParameter(classPathBuilder.getPathsString());\n\n\n    commandLine.addParameter(\"-Xmx\" + GroovyCompilerConfiguration.getInstance(myProject).getHeapSize() + \"m\");\n    commandLine.addParameter(\"-XX:+HeapDumpOnOutOfMemoryError\");\n\n    //debug\n    //commandLine.addParameter(\"-Xdebug\"); commandLine.addParameter(\"-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5239\");\n\n    // Setting up process encoding according to locale\n    final ArrayList<String> list = new ArrayList<String>();\n    CompilerUtil.addLocaleOptions(list, false);\n    commandLine.addParameters(list);\n\n    commandLine.addParameter(GroovycRunner.class.getName());\n\n    try {\n      File fileWithParameters = File.createTempFile(\"toCompile\", \"\");\n      fillFileWithGroovycParameters(module, toCompile, fileWithParameters, compileContext, outputDir, patchers, tests);\n\n      commandLine.addParameter(forStubs ? \"stubs\" : \"groovyc\");\n      commandLine.addParameter(fileWithParameters.getPath());\n    }\n    catch (IOException e) {\n      LOG.error(e);\n    }\n\n    GroovycOSProcessHandler processHandler;\n\n    try {\n      processHandler = new GroovycOSProcessHandler(compileContext, commandLine.createProcess(), commandLine.getCommandLineString(), sink);\n\n      processHandler.startNotify();\n      processHandler.waitFor();\n\n      final List<VirtualFile> toRecompile = new ArrayList<VirtualFile>();\n      Set<File> toRecompileFiles = processHandler.getToRecompileFiles();\n      for (File toRecompileFile : toRecompileFiles) {\n        final VirtualFile vFile = LocalFileSystem.getInstance().findFileByIoFile(toRecompileFile);\n        LOG.assertTrue(vFile != null);\n        toRecompile.add(vFile);\n      }\n\n      for (CompilerMessage compilerMessage : processHandler.getCompilerMessages()) {\n        final CompilerMessageCategory category;\n        category = getMessageCategory(compilerMessage);\n\n        final String url = compilerMessage.getUrl();\n\n        compileContext.addMessage(category, compilerMessage.getMessage(), VfsUtil.pathToUrl(FileUtil.toSystemIndependentName(url)), compilerMessage.getLineNum(),\n                                  compilerMessage.getColumnNum());\n      }\n\n      StringBuffer unparsedBuffer = processHandler.getUnparsedOutput();\n      if (unparsedBuffer.length() != 0) compileContext.addMessage(CompilerMessageCategory.ERROR, unparsedBuffer.toString(), null, -1, -1);\n\n      List<OutputItem> outputItems = processHandler.getSuccessfullyCompiled();\n      if (forStubs) {\n        List<VirtualFile> stubFiles = new ArrayList<VirtualFile>();\n        for (final OutputItem outputItem : outputItems) {\n          final File stub = new File(outputItem.getOutputPath());\n          CompilerUtil.refreshIOFile(stub);\n          final VirtualFile file = LocalFileSystem.getInstance().refreshAndFindFileByIoFile(stub);\n          ContainerUtil.addIfNotNull(file, stubFiles);\n        }\n        ((CompileContextEx)compileContext).addScope(new FileSetCompileScope(stubFiles, new Module[]{module}));\n        outputItems = Collections.emptyList();\n      }\n\n      sink.add(outputDir.getPath(), outputItems, toRecompile.toArray(new VirtualFile[toRecompile.size()]));\n    }\n    catch (ExecutionException e) {\n      LOG.error(e);\n    }\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private ExcludedEntriesConfigurable createExcludedConfigurable(final Project project) {\n    final ExcludedEntriesConfiguration configuration = myConfig.getState().excludeFromStubGeneration;\n    final ProjectFileIndex index = ProjectRootManager.getInstance(project).getFileIndex();\n    final FileChooserDescriptor descriptor = new FileChooserDescriptor(true, true, false, false, false, true) {\n      public boolean isFileVisible(VirtualFile file, boolean showHiddenFiles) {\n        return super.isFileVisible(file, showHiddenFiles) && !index.isIgnored(file);\n      }\n    };\n    for (final Module module: ModuleManager.getInstance(project).getModules()) {\n      for (VirtualFile file : ModuleRootManager.getInstance(module).getSourceRoots()) {\n        descriptor.addRoot(file);\n      }\n    }\n    return new ExcludedEntriesConfigurable(project, descriptor, configuration);\n  }","id":37454,"modified_method":"private ExcludedEntriesConfigurable createExcludedConfigurable(final Project project) {\n    final ExcludedEntriesConfiguration configuration = myConfig.getExcludeFromStubGeneration();\n    final ProjectFileIndex index = ProjectRootManager.getInstance(project).getFileIndex();\n    final FileChooserDescriptor descriptor = new FileChooserDescriptor(true, true, false, false, false, true) {\n      public boolean isFileVisible(VirtualFile file, boolean showHiddenFiles) {\n        return super.isFileVisible(file, showHiddenFiles) && !index.isIgnored(file);\n      }\n    };\n    for (final Module module: ModuleManager.getInstance(project).getModules()) {\n      for (VirtualFile file : ModuleRootManager.getInstance(module).getSourceRoots()) {\n        descriptor.addRoot(file);\n      }\n    }\n    return new ExcludedEntriesConfigurable(project, descriptor, configuration);\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void apply() throws ConfigurationException {\n    myExcludes.apply();\n    myConfig.getState().heapSize = myHeapSize.getText();\n  }","id":37455,"modified_method":"public void apply() throws ConfigurationException {\n    myExcludes.apply();\n    myConfig.setHeapSize(myHeapSize.getText());\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean isModified() {\n    final GroovyCompilerConfiguration.GroovyCompilerConfigurationBean state = myConfig.getState();\n    return !Comparing.equal(state.heapSize, myHeapSize.getText()) || myExcludes.isModified();\n  }","id":37456,"modified_method":"public boolean isModified() {\n    return !Comparing.equal(myConfig.getHeapSize(), myHeapSize.getText()) || myExcludes.isModified();\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void reset() {\n    myHeapSize.setText(myConfig.getState().heapSize);\n    myExcludes.reset();\n  }","id":37457,"modified_method":"public void reset() {\n    myHeapSize.setText(myConfig.getHeapSize());\n    myExcludes.reset();\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GroovyCompilerConfigurationBean getState() {\n    return myState;\n  }","id":37458,"modified_method":"public MyStateBean getState() {\n    final MyStateBean bean = new MyStateBean();\n    bean.heapSize = myHeapSize;\n    myExcludeFromStubGeneration.writeExternal(bean.excludes);\n    return bean;\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GenerationItem[] getGenerationItems(CompileContext context) {\n    myContext = context;\n\n    List<GenerationItem> generationItems = new ArrayList<GenerationItem>();\n    GenerationItem item;\n    final CompilerManager compilerManager = CompilerManager.getInstance(myProject);\n    final CompilerConfiguration compilerConfiguration = CompilerConfiguration.getInstance(myProject);\n    final ExcludedEntriesConfiguration excluded = GroovyCompilerConfiguration.getInstance(myProject).getState().excludeFromStubGeneration;\n    for (VirtualFile file : getGroovyFilesToGenerate(context)) {\n      if (compilerManager.isExcludedFromCompilation(file)) continue;\n      if (excluded.isExcluded(file)) continue;\n      if (compilerConfiguration.isResourceFile(file)) continue;\n\n      final Module module = getModuleByFile(context, file);\n      if (module == null || !(module.getModuleType() instanceof JavaModuleType)) {\n        continue;\n      }\n\n      boolean isInTestSources = ModuleRootManager.getInstance(module).getFileIndex().isInTestSourceContent(file);\n\n      final GroovyFileBase psiFile = findPsiFile(file);\n      GrTopStatement[] statements = getTopStatementsInReadAction(psiFile);\n\n      boolean needCreateTopLevelClass = !needsCreateClassFromFileName(statements);\n\n      String prefix = \"\";\n      if (statements.length > 0 && statements[0] instanceof GrPackageDefinition) {\n        prefix = getJavaClassPackage((GrPackageDefinition) statements[0]);\n      }\n\n      //top level class\n      if (needCreateTopLevelClass) {\n        generationItems.add(new GenerationItemImpl(prefix + file.getNameWithoutExtension() + \".\" + \"java\", module, new TimestampValidityState(file.getTimeStamp()), isInTestSources, file));\n      }\n\n      GrTypeDefinition[] typeDefinitions = ApplicationManager.getApplication().runReadAction(new Computable<GrTypeDefinition[]>() {\n        public GrTypeDefinition[] compute() {\n          return psiFile.getTypeDefinitions();\n        }\n      });\n\n      for (GrTypeDefinition typeDefinition : typeDefinitions) {\n        item = new GenerationItemImpl(prefix + typeDefinition.getName() + \".\" + \"java\", module, new TimestampValidityState(file.getTimeStamp()), isInTestSources, file);\n        generationItems.add(item);\n      }\n    }\n    return generationItems.toArray(new GenerationItem[generationItems.size()]);\n  }","id":37459,"modified_method":"public GenerationItem[] getGenerationItems(CompileContext context) {\n    myContext = context;\n\n    List<GenerationItem> generationItems = new ArrayList<GenerationItem>();\n    GenerationItem item;\n    final CompilerManager compilerManager = CompilerManager.getInstance(myProject);\n    final CompilerConfiguration compilerConfiguration = CompilerConfiguration.getInstance(myProject);\n    final ExcludedEntriesConfiguration excluded = GroovyCompilerConfiguration.getExcludeConfiguration(myProject);\n    for (VirtualFile file : getGroovyFilesToGenerate(context)) {\n      if (compilerManager.isExcludedFromCompilation(file)) continue;\n      if (excluded.isExcluded(file)) continue;\n      if (compilerConfiguration.isResourceFile(file)) continue;\n\n      final Module module = getModuleByFile(context, file);\n      if (module == null || !(module.getModuleType() instanceof JavaModuleType)) {\n        continue;\n      }\n\n      boolean isInTestSources = ModuleRootManager.getInstance(module).getFileIndex().isInTestSourceContent(file);\n\n      final GroovyFileBase psiFile = findPsiFile(file);\n      GrTopStatement[] statements = getTopStatementsInReadAction(psiFile);\n\n      boolean needCreateTopLevelClass = !needsCreateClassFromFileName(statements);\n\n      String prefix = \"\";\n      if (statements.length > 0 && statements[0] instanceof GrPackageDefinition) {\n        prefix = getJavaClassPackage((GrPackageDefinition) statements[0]);\n      }\n\n      //top level class\n      if (needCreateTopLevelClass) {\n        generationItems.add(new GenerationItemImpl(prefix + file.getNameWithoutExtension() + \".\" + \"java\", module, new TimestampValidityState(file.getTimeStamp()), isInTestSources, file));\n      }\n\n      GrTypeDefinition[] typeDefinitions = ApplicationManager.getApplication().runReadAction(new Computable<GrTypeDefinition[]>() {\n        public GrTypeDefinition[] compute() {\n          return psiFile.getTypeDefinitions();\n        }\n      });\n\n      for (GrTypeDefinition typeDefinition : typeDefinitions) {\n        item = new GenerationItemImpl(prefix + typeDefinition.getName() + \".\" + \"java\", module, new TimestampValidityState(file.getTimeStamp()), isInTestSources, file);\n        generationItems.add(item);\n      }\n    }\n    return generationItems.toArray(new GenerationItem[generationItems.size()]);\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void compile(CompileContext compileContext, VirtualFile[] virtualFiles, OutputSink sink) {\n    final CompileScope scope = compileContext.getCompileScope();\n    if (scope.getFiles(StdFileTypes.JAVA, true).length == 0) {\n      return;\n    }\n\n    boolean hasGroovy = false;\n    final ExcludedEntriesConfiguration excluded = GroovyCompilerConfiguration.getInstance(myProject).getState().excludeFromStubGeneration;\n    List<VirtualFile> total = new ArrayList<VirtualFile>();\n    for (final VirtualFile virtualFile : virtualFiles) {\n      if (!excluded.isExcluded(virtualFile)) {\n        total.add(virtualFile);\n        if (virtualFile.getFileType() == GroovyFileType.GROOVY_FILE_TYPE) {\n          hasGroovy = true;\n        }\n      }\n    }\n\n    if (!hasGroovy) {\n      return;\n    }\n\n    super.compile(compileContext, total.toArray(new VirtualFile[total.size()]), sink);\n  }","id":37460,"modified_method":"@Override\n  public void compile(CompileContext compileContext, VirtualFile[] virtualFiles, OutputSink sink) {\n    final CompileScope scope = compileContext.getCompileScope();\n    if (scope.getFiles(StdFileTypes.JAVA, true).length == 0) {\n      return;\n    }\n\n    boolean hasGroovy = false;\n    final ExcludedEntriesConfiguration excluded = GroovyCompilerConfiguration.getExcludeConfiguration(myProject);\n    List<VirtualFile> total = new ArrayList<VirtualFile>();\n    for (final VirtualFile virtualFile : virtualFiles) {\n      if (!excluded.isExcluded(virtualFile)) {\n        total.add(virtualFile);\n        if (virtualFile.getFileType() == GroovyFileType.GROOVY_FILE_TYPE) {\n          hasGroovy = true;\n        }\n      }\n    }\n\n    if (!hasGroovy) {\n      return;\n    }\n\n    super.compile(compileContext, total.toArray(new VirtualFile[total.size()]), sink);\n  }","commit_id":"c2c8bc2ecba8256182a502d3cdfeb5b539372818","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"protected void addBusWiringAttribute(BeanDefinitionBuilder bean, \n                                         BusWiringType type) {\n        addBusWiringAttribute(bean, type, null);\n    }","id":37461,"modified_method":"protected void addBusWiringAttribute(BeanDefinitionBuilder bean, \n                                         BusWiringType type) {\n        addBusWiringAttribute(bean, type, null, null);\n    }","commit_id":"840a797610e462f9580ca2228d7ff3ea9a0c17f2","url":"https://github.com/apache/cxf"},{"original_method":"protected boolean parseAttributes(Element element, ParserContext ctx, BeanDefinitionBuilder bean) {\n        NamedNodeMap atts = element.getAttributes();\n        boolean setBus = false;\n        for (int i = 0; i < atts.getLength(); i++) {\n            Attr node = (Attr) atts.item(i);\n            String val = node.getValue();\n            String pre = node.getPrefix();\n            String name = node.getLocalName();\n            String prefix = node.getPrefix();\n            \n            // Don't process namespaces\n            if (isNamespace(name, prefix)) {\n                continue;\n            }\n            \n            if (\"createdFromAPI\".equals(name)) {\n                bean.setAbstract(true);\n            } else if (\"abstract\".equals(name)) {\n                bean.setAbstract(true);\n            } else if (\"depends-on\".equals(name)) {\n                bean.addDependsOn(val);\n            } else if (\"name\".equals(name)) {\n                processNameAttribute(element, ctx, bean, val);\n            } else if (!\"id\".equals(name) && isAttribute(pre, name)) {\n                if (\"bus\".equals(name)) {                                     \n                    if (val != null && val.trim().length() > 0 \n                        && ctx.getRegistry().containsBeanDefinition(val)) {\n                        bean.addPropertyReference(name, val);\n                        setBus = true;                         \n                    }\n                } else {\n                    mapAttribute(bean, element, name, val);\n                }    \n            }\n        } \n        return setBus;\n    }","id":37462,"modified_method":"protected boolean parseAttributes(Element element, ParserContext ctx, BeanDefinitionBuilder bean) {\n        NamedNodeMap atts = element.getAttributes();\n        boolean setBus = false;\n        for (int i = 0; i < atts.getLength(); i++) {\n            Attr node = (Attr) atts.item(i);\n            String val = node.getValue();\n            String pre = node.getPrefix();\n            String name = node.getLocalName();\n            String prefix = node.getPrefix();\n            \n            // Don't process namespaces\n            if (isNamespace(name, prefix)) {\n                continue;\n            }\n            \n            if (\"createdFromAPI\".equals(name)) {\n                bean.setAbstract(true);\n            } else if (\"abstract\".equals(name)) {\n                bean.setAbstract(true);\n            } else if (\"depends-on\".equals(name)) {\n                bean.addDependsOn(val);\n            } else if (\"name\".equals(name)) {\n                processNameAttribute(element, ctx, bean, val);\n            } else if (!\"id\".equals(name) && isAttribute(pre, name)) {\n                if (\"bus\".equals(name)) {                                     \n                    if (val != null && val.trim().length() > 0) {\n                        if (ctx.getRegistry().containsBeanDefinition(val)) {\n                            bean.addPropertyReference(name, val);\n                        } else {\n                            addBusWiringAttribute(bean, BusWiringType.PROPERTY,\n                                                  val, ctx);\n                        }\n                        setBus = true;                         \n                    }\n                } else {\n                    mapAttribute(bean, element, name, val);\n                }    \n            }\n        } \n        return setBus;\n    }","commit_id":"840a797610e462f9580ca2228d7ff3ea9a0c17f2","url":"https://github.com/apache/cxf"},{"original_method":"protected void mapToProperty(BeanDefinitionBuilder bean, String propertyName, String val) {\n        if (ID_ATTRIBUTE.equals(propertyName)) {\n            return;\n        }\n        \n        if (StringUtils.hasText(val)) {\n            if (val.startsWith(\"#\")) {\n                bean.addPropertyReference(propertyName, val.substring(1));\n            } else {\n                bean.addPropertyValue(propertyName, val);\n            }\n        }\n    }","id":37463,"modified_method":"protected void mapToProperty(BeanDefinitionBuilder bean, String propertyName, String val) {\n        if (ID_ATTRIBUTE.equals(propertyName)) {\n            return;\n        }\n        \n        if (!StringUtils.isEmpty(val)) {\n            if (val.startsWith(\"#\")) {\n                bean.addPropertyReference(propertyName, val.substring(1));\n            } else {\n                bean.addPropertyValue(propertyName, val);\n            }\n        }\n    }","commit_id":"840a797610e462f9580ca2228d7ff3ea9a0c17f2","url":"https://github.com/apache/cxf"},{"original_method":"protected void addBusWiringAttribute(BeanDefinitionBuilder bean, \n                                         BusWiringType type,\n                                         String busName) {\n        LOG.fine(\"Adding \" + WIRE_BUS_ATTRIBUTE + \" attribute \" + type + \" to bean \" + bean);\n        bean.getRawBeanDefinition().setAttribute(WIRE_BUS_ATTRIBUTE, type);\n        if (busName != null) {\n            bean.getRawBeanDefinition().setAttribute(WIRE_BUS_NAME, busName); \n        }\n    }","id":37464,"modified_method":"protected void addBusWiringAttribute(BeanDefinitionBuilder bean, \n                                         BusWiringType type,\n                                         String busName,\n                                         ParserContext ctx) {\n        LOG.fine(\"Adding \" + WIRE_BUS_ATTRIBUTE + \" attribute \" + type + \" to bean \" + bean);\n        bean.getRawBeanDefinition().setAttribute(WIRE_BUS_ATTRIBUTE, type);\n        if (!StringUtils.isEmpty(busName)) {\n            if (busName.charAt(0) == '#') {\n                busName = busName.substring(1);\n            }\n            bean.getRawBeanDefinition().setAttribute(WIRE_BUS_NAME, busName); \n        }\n        \n        if (ctx != null \n            && !ctx.getRegistry().containsBeanDefinition(WIRE_BUS_HANDLER)) {\n            BeanDefinitionBuilder b \n                = BeanDefinitionBuilder.rootBeanDefinition(WIRE_BUS_HANDLER);\n            ctx.getRegistry().registerBeanDefinition(WIRE_BUS_HANDLER, b.getBeanDefinition());\n        }\n    }","commit_id":"840a797610e462f9580ca2228d7ff3ea9a0c17f2","url":"https://github.com/apache/cxf"},{"original_method":"protected void doParse(Element element, ParserContext ctx, BeanDefinitionBuilder bean) {\n        String bus = element.getAttribute(\"bus\");        \n        if (StringUtils.isEmpty(bus)) {\n            bus = element.getAttribute(\"name\");\n            if (StringUtils.isEmpty(bus)) {\n                element.setAttribute(\"bus\", bus);\n            }\n        }\n        element.removeAttribute(\"name\");\n        if (StringUtils.isEmpty(bus)) {\n            addBusWiringAttribute(bean, BusWiringType.PROPERTY);\n        } else {\n            addBusWiringAttribute(bean, BusWiringType.PROPERTY, bus);\n        }\n        String id = element.getAttribute(\"id\");\n        if (!StringUtils.isEmpty(id)) {\n            bean.addPropertyValue(\"id\", id);\n        }\n\n        bean.addConstructorArgValue(bus);\n        bean.setLazyInit(false);\n        super.doParse(element, ctx, bean);\n    }","id":37465,"modified_method":"protected void doParse(Element element, ParserContext ctx, BeanDefinitionBuilder bean) {\n        String bus = element.getAttribute(\"bus\");        \n        if (StringUtils.isEmpty(bus)) {\n            bus = element.getAttribute(\"name\");\n            if (StringUtils.isEmpty(bus)) {\n                element.setAttribute(\"bus\", bus);\n            }\n        }\n        element.removeAttribute(\"name\");\n        if (StringUtils.isEmpty(bus)) {\n            addBusWiringAttribute(bean, BusWiringType.PROPERTY, null, ctx);\n        } else {\n            addBusWiringAttribute(bean, BusWiringType.PROPERTY, bus, ctx);\n        }\n        String id = element.getAttribute(\"id\");\n        if (!StringUtils.isEmpty(id)) {\n            bean.addPropertyValue(\"id\", id);\n        }\n\n        bean.addConstructorArgValue(bus);\n        bean.setLazyInit(false);\n        super.doParse(element, ctx, bean);\n    }","commit_id":"840a797610e462f9580ca2228d7ff3ea9a0c17f2","url":"https://github.com/apache/cxf"},{"original_method":"/**\n\t * Expose the given target class for the specified bean.\n\t * @param beanFactory the containing ConfigurableListableBeanFactory\n\t * @param beanName the name of the bean\n\t * @param targetClass the corresponding target class\n\t * @since 4.2.3\n\t */\n\tstatic void exposeTargetClass(ConfigurableListableBeanFactory beanFactory, String beanName, Class<?> targetClass) {\n\t\tif (beanFactory.containsBeanDefinition(beanName)) {\n\t\t\tbeanFactory.getMergedBeanDefinition(beanName).setAttribute(ORIGINAL_TARGET_CLASS_ATTRIBUTE, targetClass);\n\t\t}\n\t}","id":37466,"modified_method":"/**\n\t * Expose the given target class for the specified bean, if possible.\n\t * @param beanFactory the containing ConfigurableListableBeanFactory\n\t * @param beanName the name of the bean\n\t * @param targetClass the corresponding target class\n\t * @since 4.2.3\n\t */\n\tstatic void exposeTargetClass(ConfigurableListableBeanFactory beanFactory, String beanName, Class<?> targetClass) {\n\t\tif (beanName != null && beanFactory.containsBeanDefinition(beanName)) {\n\t\t\tbeanFactory.getMergedBeanDefinition(beanName).setAttribute(ORIGINAL_TARGET_CLASS_ATTRIBUTE, targetClass);\n\t\t}\n\t}","commit_id":"90c9d96a4d432a31c6cfbb0c2e8f2ab83daeffef","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Determine whether the given bean should be proxied with its target\n\t * class rather than its interfaces. Checks the\n\t * {@link #PRESERVE_TARGET_CLASS_ATTRIBUTE \"preserveTargetClass\" attribute}\n\t * of the corresponding bean definition.\n\t * @param beanFactory the containing ConfigurableListableBeanFactory\n\t * @param beanName the name of the bean\n\t * @return whether the given bean should be proxied with its target class\n\t */\n\tpublic static boolean shouldProxyTargetClass(ConfigurableListableBeanFactory beanFactory, String beanName) {\n\t\tif (beanFactory.containsBeanDefinition(beanName)) {\n\t\t\tBeanDefinition bd = beanFactory.getBeanDefinition(beanName);\n\t\t\treturn Boolean.TRUE.equals(bd.getAttribute(PRESERVE_TARGET_CLASS_ATTRIBUTE));\n\t\t}\n\t\treturn false;\n\t}","id":37467,"modified_method":"/**\n\t * Determine whether the given bean should be proxied with its target\n\t * class rather than its interfaces. Checks the\n\t * {@link #PRESERVE_TARGET_CLASS_ATTRIBUTE \"preserveTargetClass\" attribute}\n\t * of the corresponding bean definition.\n\t * @param beanFactory the containing ConfigurableListableBeanFactory\n\t * @param beanName the name of the bean\n\t * @return whether the given bean should be proxied with its target class\n\t */\n\tpublic static boolean shouldProxyTargetClass(ConfigurableListableBeanFactory beanFactory, String beanName) {\n\t\tif (beanName != null && beanFactory.containsBeanDefinition(beanName)) {\n\t\t\tBeanDefinition bd = beanFactory.getBeanDefinition(beanName);\n\t\t\treturn Boolean.TRUE.equals(bd.getAttribute(PRESERVE_TARGET_CLASS_ATTRIBUTE));\n\t\t}\n\t\treturn false;\n\t}","commit_id":"b07b1469658e4a28b3b1b3460e86e62a54e8c86f","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"private FunctionInlineMutator(JsInvocation call, JsScope callerScope, JsFunction invokedFunction) {\n        this.call = call;\n        this.callerScope = callerScope;\n        this.invokedFunction = invokedFunction;\n    }","id":37468,"modified_method":"private FunctionInlineMutator(@NotNull JsInvocation call, @NotNull InliningContext inliningContext) {\n        FunctionContext functionContext = inliningContext.getFunctionContext();\n        invokedFunction = functionContext.getFunctionDefinition(call);\n        body = invokedFunction.getBody().deepCopy();\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public static InlineableResult getInlineableCallReplacement(\n            JsInvocation call,\n            JsScope callerScope,\n            JsFunction invokedFunction\n    ) {\n        return (new FunctionInlineMutator(call, callerScope, invokedFunction)).process();\n    }","id":37469,"modified_method":"public static InlineableResult getInlineableCallReplacement(\n            @NotNull JsInvocation call,\n            @NotNull InliningContext inliningContext\n    ) {\n        FunctionInlineMutator mutator = new FunctionInlineMutator(call, inliningContext);\n        mutator.process();\n\n        JsStatement inlineableBody = mutator.body;\n        return new InlineableResult(inlineableBody, call);\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private InlineableResult process() {\n        JsBlock inlinedBody = new JsBlock(statements);\n        JsNameRef result = callerScope.declareName(RESULT_LABEL).makeRef();\n        statements.addAll(invokedFunction.getBody().getStatements());\n        return new InlineableResult(inlinedBody, result);\n    }","id":37470,"modified_method":"private void process() {\n\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public static JsProgram process(JsProgram program) {\n        IdentityHashMap<JsName, JsFunction> functions = FunctionCollector.collectFunctions(program);\n        JsInliner inliner = new JsInliner(program, functions);\n        return inliner.process();\n    }","id":37471,"modified_method":"public static JsProgram process(JsProgram program) {\n        IdentityHashMap<JsName, JsFunction> functions = FunctionCollector.collectFunctions(program);\n        JsInliner inliner = new JsInliner(functions);\n        return inliner.accept(program);\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public void endVisit(JsFunction function, JsContext context) {\n        super.endVisit(function, context);\n        scopeStack.pop();\n    }","id":37472,"modified_method":"@Override\n    public void endVisit(JsFunction function, JsContext context) {\n        super.endVisit(function, context);\n        inliningContexts.pop();\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"JsInliner(JsProgram program, IdentityHashMap<JsName, JsFunction> functions) {\n        this.program = program;\n        this.functions = functions;\n    }","id":37473,"modified_method":"JsInliner(IdentityHashMap<JsName, JsFunction> functions) {\n        this.functions = functions;\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public boolean visit(JsFunction function, JsContext context) {\n        scopeStack.push(function.getScope());\n        return super.visit(function, context);\n    }","id":37474,"modified_method":"@Override\n    public boolean visit(JsFunction function, JsContext context) {\n        inliningContexts.push(new JsInliningContext(function));\n        return super.visit(function, context);\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private boolean canInline(@NotNull JsInvocation call) {\n        return findDeclaration(call) != null;\n    }","id":37475,"modified_method":"private boolean canInline(@NotNull JsInvocation call) {\n        FunctionContext functionContext = getFunctionContext();\n        return functionContext.hasFunctionDefinition(call);\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsFunction functionToInline = findDeclaration(call);\n        assert functionToInline != null;\n        JsContext statementLevelContext = getLastStatementLevelContext();\n        assert statementLevelContext != null;\n\n        JsScope currentScope = getCurrentFunctionScope();\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, currentScope, functionToInline);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n\n        statementLevelContext.insertAfter(statementLevelContext.getCurrentNode());\n        statementLevelContext.insertAfter(inlineableBody);\n        statementLevelContext.replaceMe(program.getEmptyStatement());\n\n        context.replaceMe(resultExpression);\n    }","id":37476,"modified_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsInliningContext inliningContext = getInliningContext();\n        FunctionContext functionContext = getFunctionContext();\n        functionContext.declareFunctionConstructorCalls(call.getArguments());\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, inliningContext);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n        StatementContext statementContext = inliningContext.getStatementContext();\n\n        /**\n         * Assumes, that resultExpression == null, when result is not needed.\n         * @see FunctionInlineMutator.isResultNeeded()\n         */\n        if (resultExpression == null) {\n            statementContext.removeCurrentStatement();\n        } else {\n            context.replaceMe(resultExpression);\n        }\n\n        statementContext.shiftCurrentStatementForward();\n        InsertionPoint<JsStatement> insertionPoint = statementContext.getInsertionPoint();\n        if (inlineableBody instanceof JsBlock) {\n            JsBlock block = (JsBlock) inlineableBody;\n            insertionPoint.insertAllAfter(block.getStatements());\n        } else {\n            insertionPoint.insertAfter(inlineableBody);\n        }\n    }","commit_id":"49718f143bd8ca368e03ad075f70a8346e472cd1","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsInliningContext inliningContext = getInliningContext();\n        FunctionContext functionContext = getFunctionContext();\n        functionContext.declareFunctionConstructorCalls(call.getArguments());\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, inliningContext);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n        JsContext<JsStatement> statementContext = inliningContext.getStatementContext();\n        // body of inline function can contain call to lambdas that need to be inlined\n        JsStatement statement = accept(inlineableBody);\n        assert inlineableBody == statement;\n\n        statementContext.addPrevious(flattenStatement(inlineableBody));\n\n        /**\n         * Assumes, that resultExpression == null, when result is not needed.\n         * @see FunctionInlineMutator.isResultNeeded()\n         */\n        if (resultExpression == null) {\n            statementContext.removeMe();\n            return;\n        }\n\n        resultExpression = accept(resultExpression);\n        context.replaceMe(resultExpression);\n    }","id":37477,"modified_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsInliningContext inliningContext = getInliningContext();\n        FunctionContext functionContext = getFunctionContext();\n        functionContext.declareFunctionConstructorCalls(call.getArguments());\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, inliningContext);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n        JsContext<JsStatement> statementContext = inliningContext.getStatementContext();\n        // body of inline function can contain call to lambdas that need to be inlined\n        JsStatement inlineableBodyWithLambdasInlined = accept(inlineableBody);\n        assert inlineableBody == inlineableBodyWithLambdasInlined;\n\n        statementContext.addPrevious(flattenStatement(inlineableBody));\n\n        /**\n         * Assumes, that resultExpression == null, when result is not needed.\n         * @see FunctionInlineMutator.isResultNeeded()\n         */\n        if (resultExpression == null) {\n            statementContext.removeMe();\n            return;\n        }\n\n        resultExpression = accept(resultExpression);\n        JsStatement currentStatement = statementContext.getCurrentNode();\n\n        if (currentStatement instanceof JsExpressionStatement &&\n            ((JsExpressionStatement) currentStatement).getExpression() == call &&\n            (resultExpression == null || !canHaveSideEffect(resultExpression))\n        ) {\n            statementContext.removeMe();\n        }\n        else {\n            context.replaceMe(resultExpression);\n        }\n    }","commit_id":"ea41bc4231204dc843fa21ee72281071e7a5593a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsInliningContext inliningContext = getInliningContext();\n        FunctionContext functionContext = getFunctionContext();\n        functionContext.declareFunctionConstructorCalls(call.getArguments());\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, inliningContext);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n        JsContext<JsStatement> statementContext = inliningContext.getStatementContext();\n        accept(inlineableBody);\n\n        /**\n         * Assumes, that resultExpression == null, when result is not needed.\n         * @see FunctionInlineMutator.isResultNeeded()\n         */\n        if (resultExpression == null) {\n            statementContext.removeCurrentStatement();\n        } else {\n            context.replaceMe(resultExpression);\n        }\n\n        /** @see #lastStatementWasShifted */\n        statementContext.shiftCurrentStatementForward();\n    }","id":37478,"modified_method":"private void inline(@NotNull JsInvocation call, @NotNull JsContext context) {\n        JsInliningContext inliningContext = getInliningContext();\n        FunctionContext functionContext = getFunctionContext();\n        functionContext.declareFunctionConstructorCalls(call.getArguments());\n        InlineableResult inlineableResult = getInlineableCallReplacement(call, inliningContext);\n\n        JsStatement inlineableBody = inlineableResult.getInlineableBody();\n        JsExpression resultExpression = inlineableResult.getResultExpression();\n        JsContext<JsStatement> statementContext = inliningContext.getStatementContext();\n        // body of inline function can contain call to lambdas that need to be inlined\n        accept(inlineableBody);\n        statementContext.addPrevious(flattenStatement(inlineableBody));\n\n        /**\n         * Assumes, that resultExpression == null, when result is not needed.\n         * @see FunctionInlineMutator.isResultNeeded()\n         */\n        if (resultExpression == null) {\n            statementContext.removeMe();\n            return;\n        }\n\n        resultExpression = accept(resultExpression);\n        context.replaceMe(resultExpression);\n    }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public boolean visit(JsInvocation call, JsContext context) {\n        if (shouldInline(call) && canInline(call)) {\n            JsFunction containingFunction = getCurrentNamedFunction();\n            if (containingFunction != null) {\n                inlineCallInfos.add(new JsCallInfo(call, containingFunction));\n            }\n\n            JsFunction definition = getFunctionContext().getFunctionDefinition(call);\n\n            if (inProcessFunctions.contains(definition))  {\n                reportInlineCycle(call, definition);\n                return false;\n            }\n\n            if (!processedFunctions.contains(definition)) {\n                accept(definition);\n            }\n\n            inline(call, context);\n        }\n\n        return !lastStatementWasShifted;\n    }","id":37479,"modified_method":"@Override\n    public boolean visit(JsInvocation call, JsContext context) {\n        if (shouldInline(call) && canInline(call)) {\n            JsFunction containingFunction = getCurrentNamedFunction();\n            if (containingFunction != null) {\n                inlineCallInfos.add(new JsCallInfo(call, containingFunction));\n            }\n\n            JsFunction definition = getFunctionContext().getFunctionDefinition(call);\n\n            if (inProcessFunctions.contains(definition))  {\n                reportInlineCycle(call, definition);\n                return false;\n            }\n\n            if (!processedFunctions.contains(definition)) {\n                accept(definition);\n            }\n\n            inline(call, context);\n        }\n\n        return true;\n    }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n        public void removeMe() {\n            collection.remove(index--);\n        }","id":37480,"modified_method":"@Override\n        public void removeMe() {\n            removed = true;\n        }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n        public <R extends T> void replaceMe(R node) {\n            checkReplacement(collection.get(index), node);\n            collection.set(index, node);\n        }","id":37481,"modified_method":"@Override\n        public <R extends T> void replaceMe(R node) {\n            checkReplacement(nodes.get(index), node);\n            nodes.set(index, node);\n            removed = false;\n        }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Nullable\n        @Override\n        public T getCurrentNode() {\n            if (index < collection.size()) {\n                return collection.get(index);\n            }\n\n            return null;\n        }","id":37482,"modified_method":"@Nullable\n        @Override\n        public T getCurrentNode() {\n            if (!removed && index < nodes.size()) {\n                return nodes.get(index);\n            }\n\n            return null;\n        }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"protected void traverse(List<T> collection) {\n            this.collection = collection;\n            for (index = 0; index < collection.size(); ++index) {\n                T node = collection.get(index);\n                doTraverse(node, this);\n            }\n        }","id":37483,"modified_method":"protected void traverse(List<T> nodes) {\n            assert previous.isEmpty(): \"addPrevious() was called before traverse()\";\n            assert next.isEmpty(): \"addNext() was called before traverse()\";\n            this.nodes = nodes;\n\n            for (index = 0; index < nodes.size(); index++) {\n                removed = false;\n                previous.clear();\n                next.clear();\n                doTraverse(getCurrentNode(), this);\n\n                if (!previous.isEmpty()) {\n                    nodes.addAll(index, previous);\n                    index += previous.size();\n                }\n\n                if (removed) {\n                    nodes.remove(index);\n                    index--;\n                }\n\n                if (!next.isEmpty()) {\n                    nodes.addAll(index + 1, next);\n                    index += next.size();\n                }\n            }\n        }","commit_id":"05c44db80f2ea7cf1c43818ce09ce91d106d9c2c","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public void deleteChildInternal(@NotNull ASTNode child) {\n    PsiElement element = child.getPsi();\n    if (element instanceof GrExpression || element instanceof GrNamedArgument) {\n      ASTNode prev = TreeUtil.skipElementsBack(child.getTreePrev(), TokenSets.WHITE_SPACES_OR_COMMENTS);\n      if (prev != null && prev.getElementType() == mCOMMA) {\n        super.deleteChildInternal(prev);\n      }\n      else {\n        ASTNode next = TreeUtil.skipElements(child.getTreeNext(), TokenSets.WHITE_SPACES_OR_COMMENTS);\n        if (next != null && next.getElementType() == mCOMMA) {\n          deleteChildInternal(next);\n        }\n      }\n    }\n    super.deleteChildInternal(child);\n  }","id":37484,"modified_method":"public void deleteChildInternal(@NotNull ASTNode child) {\n    PsiElement element = child.getPsi();\n    if (element instanceof GrExpression || element instanceof GrNamedArgument) {\n      ASTNode prev = TreeUtil.skipElementsBack(child.getTreePrev(), TokenSets.WHITE_SPACES_OR_COMMENTS);\n      if (prev != null && prev.getElementType() == mCOMMA) {\n        final ASTNode pprev = prev.getTreePrev();\n        if (pprev != null && TokenSets.WHITE_SPACES_SET.contains(pprev.getElementType())) {\n          super.deleteChildInternal(pprev);\n        }\n        super.deleteChildInternal(prev);\n      }\n      else {\n        ASTNode next = TreeUtil.skipElements(child.getTreeNext(), TokenSets.WHITE_SPACES_OR_COMMENTS);\n        if (next != null && next.getElementType() == mCOMMA) {\n          final ASTNode nnext = next.getTreeNext();\n          if (nnext != null && TokenSets.WHITE_SPACES_SET.contains(nnext.getElementType())) {\n            super.deleteChildInternal(nnext);\n          }\n          super.deleteChildInternal(next);\n        }\n      }\n    }\n    super.deleteChildInternal(child);\n  }","commit_id":"3b748a1d3d94e16e89fe078e69ee391dc9ac60c4","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void deleteChildInternal(ASTNode child) {\n    super.deleteChildInternal(child);\n    if (child.getElementType() == CODE_BLOCK){\n      final CharTable treeCharTab = SharedImplUtil.findCharTableByTree(this);\n      LeafElement semicolon = Factory.createSingleLeafElement(SEMICOLON, new char[]{';'}, 0, 1, treeCharTab, getManager());\n      this.addInternal(semicolon, semicolon, null, Boolean.TRUE);\n    }\n  }","id":37485,"modified_method":"public void deleteChildInternal(@NotNull ASTNode child) {\n    if (child.getElementType() == CODE_BLOCK){\n      final ASTNode prevWS = TreeUtil.prevLeaf(child);\n      if (prevWS != null && prevWS.getElementType() == ElementType.WHITE_SPACE) {\n        removeChild(prevWS);\n      }\n      super.deleteChildInternal(child);\n      final CharTable treeCharTab = SharedImplUtil.findCharTableByTree(this);\n      LeafElement semicolon = Factory.createSingleLeafElement(SEMICOLON, new char[]{';'}, 0, 1, treeCharTab, getManager());\n      addInternal(semicolon, semicolon, null, Boolean.TRUE);\n    }\n    else {\n      super.deleteChildInternal(child);\n    }\n  }","commit_id":"391f658374f98c216f866be3ab7ed1a2f4b03f0d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void deleteChildInternal(final ASTNode child) {\n    final PomModel model = getProject().getModel();\n    final XmlAspect aspect = model.getModelAspect(XmlAspect.class);\n\n    if(child.getElementType() == XmlElementType.XML_ATTRIBUTE){\n      try {\n        model.runTransaction(new PomTransactionBase(this, aspect) {\n          public PomModelEvent runInner() {\n            final String name = ((XmlAttribute)child).getName();\n            XmlTagImpl.super.deleteChildInternal(child);\n            return XmlAttributeSetImpl.createXmlAttributeSet(model, XmlTagImpl.this, name, null);\n          }\n        });\n      }\n      catch (IncorrectOperationException e) {\n        LOG.error(e);\n      }\n    }\n    else{\n      XmlTagImpl.super.deleteChildInternal(child);\n    }\n  }","id":37486,"modified_method":"public void deleteChildInternal(final ASTNode child) {\n    final PomModel model = getProject().getModel();\n    final XmlAspect aspect = model.getModelAspect(XmlAspect.class);\n\n    if(child.getElementType() == XmlElementType.XML_ATTRIBUTE){\n      try {\n        model.runTransaction(new PomTransactionBase(this, aspect) {\n          public PomModelEvent runInner() {\n            final String name = ((XmlAttribute)child).getName();\n            XmlTagImpl.super.deleteChildInternal(child);\n            return XmlAttributeSetImpl.createXmlAttributeSet(model, XmlTagImpl.this, name, null);\n          }\n        });\n      }\n      catch (IncorrectOperationException e) {\n        LOG.error(e);\n      }\n    }\n    else{\n      final ASTNode treePrev = child.getTreePrev();\n      final ASTNode treeNext = child.getTreeNext();\n      XmlTagImpl.super.deleteChildInternal(child);\n      if(treePrev != null && treeNext != null &&\n         treePrev.getElementType() == XmlElementType.XML_TEXT && treeNext.getElementType() == XmlElementType.XML_TEXT){\n        final XmlText prevText = (XmlText)treePrev.getPsi();\n        final XmlText nextText = (XmlText)treeNext.getPsi();\n        try {\n          prevText.setValue(prevText.getValue() + nextText.getValue());\n          nextText.delete();\n        }\n        catch (IncorrectOperationException e) {\n          LOG.error(e);\n        }\n      }\n    }\n  }","commit_id":"60403c76b7be24340b121620f259e8fc5d31360d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  static PsiElement insertAtAnchor(final PsiInstanceOfExpression instanceOfExpression, PsiElement toInsert) throws IncorrectOperationException {\n    boolean negated = isNegated(instanceOfExpression);\n    PsiStatement statement = PsiTreeUtil.getParentOfType(instanceOfExpression, PsiStatement.class);\n    PsiElementFactory factory = JavaPsiFacade.getInstance(toInsert.getProject()).getElementFactory();\n    PsiElement anchorAfter = null;\n    PsiBlockStatement emptyBlockStatement = (PsiBlockStatement)factory.createStatementFromText(\"{}\", instanceOfExpression);\n    if (statement instanceof PsiIfStatement) {\n      PsiIfStatement ifStatement = (PsiIfStatement)statement;\n      if (negated) {\n        PsiStatement elseBranch = ifStatement.getElseBranch();\n        if (elseBranch == null) {\n          anchorAfter = ifStatement;\n          CodeEditUtil.markToReformatBefore(PsiTreeUtil.getDeepestFirst(toInsert).getNode(), true);\n        }\n        else if (!(elseBranch instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(elseBranch);\n          PsiBlockStatement newBranch = (PsiBlockStatement)elseBranch.replace(emptyBlockStatement);\n          reformatNewCodeBlockBraces(ifStatement.getElseElement(), newBranch);\n          anchorAfter = newBranch.getCodeBlock().getLBrace();\n        }\n        else {\n          anchorAfter = ((PsiBlockStatement)elseBranch).getCodeBlock().getLBrace();\n        }\n      }\n      else {\n        PsiStatement thenBranch = ifStatement.getThenBranch();\n        if (thenBranch == null) {\n          ifStatement.setThenBranch(emptyBlockStatement);\n          PsiBlockStatement then = (PsiBlockStatement)ifStatement.getThenBranch();\n          reformatNewCodeBlockBraces(ifStatement.getCondition(), then);\n          anchorAfter = then.getCodeBlock().getLBrace();\n        }\n        else if (!(thenBranch instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(thenBranch);\n          PsiBlockStatement newBranch = (PsiBlockStatement)thenBranch.replace(emptyBlockStatement);\n          reformatNewCodeBlockBraces(ifStatement.getCondition(), newBranch);\n          anchorAfter = newBranch.getCodeBlock().getLBrace();\n        }\n        else {\n          anchorAfter = ((PsiBlockStatement)thenBranch).getCodeBlock().getLBrace();\n        }\n      }\n    }\n    if (statement instanceof PsiWhileStatement) {\n      PsiWhileStatement whileStatement = (PsiWhileStatement)statement;\n      LOG.assertTrue(whileStatement.getLParenth() != null);\n      LOG.assertTrue(whileStatement.getCondition() != null);\n      if (whileStatement.getRParenth() == null) {\n        PsiWhileStatement statementPattern = (PsiWhileStatement)factory.createStatementFromText(\"while (){}\", instanceOfExpression);\n        whileStatement.addAfter(statementPattern.getRParenth(), whileStatement.getCondition());\n      }\n      if (negated) {\n        anchorAfter = whileStatement;\n      }\n      else {\n        PsiStatement body = whileStatement.getBody();\n        if (body == null) {\n          whileStatement.add(emptyBlockStatement);\n        }\n        else if (!(body instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(body);\n          whileStatement.getBody().replace(emptyBlockStatement);\n        }\n        anchorAfter = ((PsiBlockStatement)whileStatement.getBody()).getCodeBlock().getLBrace();\n      }\n    }\n    if (anchorAfter == null) {\n      return null;\n    }\n    return anchorAfter.getParent().addAfter(toInsert, anchorAfter);\n  }","id":37487,"modified_method":"@Nullable\n  static PsiElement insertAtAnchor(final PsiInstanceOfExpression instanceOfExpression, PsiElement toInsert) throws IncorrectOperationException {\n    boolean negated = isNegated(instanceOfExpression);\n    PsiStatement statement = PsiTreeUtil.getParentOfType(instanceOfExpression, PsiStatement.class);\n    PsiElementFactory factory = JavaPsiFacade.getInstance(toInsert.getProject()).getElementFactory();\n    PsiElement anchorAfter = null;\n    PsiBlockStatement emptyBlockStatement = (PsiBlockStatement)factory.createStatementFromText(\"{}\", instanceOfExpression);\n    if (statement instanceof PsiIfStatement) {\n      PsiIfStatement ifStatement = (PsiIfStatement)statement;\n      if (negated) {\n        PsiStatement elseBranch = ifStatement.getElseBranch();\n        if (elseBranch == null) {\n          anchorAfter = ifStatement;\n        }\n        else if (!(elseBranch instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(elseBranch);\n          PsiBlockStatement newBranch = (PsiBlockStatement)elseBranch.replace(emptyBlockStatement);\n          reformatNewCodeBlockBraces(ifStatement.getElseElement(), newBranch);\n          anchorAfter = newBranch.getCodeBlock().getLBrace();\n        }\n        else {\n          anchorAfter = ((PsiBlockStatement)elseBranch).getCodeBlock().getLBrace();\n        }\n      }\n      else {\n        PsiStatement thenBranch = ifStatement.getThenBranch();\n        if (thenBranch == null) {\n          ifStatement.setThenBranch(emptyBlockStatement);\n          PsiBlockStatement then = (PsiBlockStatement)ifStatement.getThenBranch();\n          reformatNewCodeBlockBraces(ifStatement.getCondition(), then);\n          anchorAfter = then.getCodeBlock().getLBrace();\n        }\n        else if (!(thenBranch instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(thenBranch);\n          PsiBlockStatement newBranch = (PsiBlockStatement)thenBranch.replace(emptyBlockStatement);\n          reformatNewCodeBlockBraces(ifStatement.getCondition(), newBranch);\n          anchorAfter = newBranch.getCodeBlock().getLBrace();\n        }\n        else {\n          anchorAfter = ((PsiBlockStatement)thenBranch).getCodeBlock().getLBrace();\n        }\n      }\n    }\n    if (statement instanceof PsiWhileStatement) {\n      PsiWhileStatement whileStatement = (PsiWhileStatement)statement;\n      LOG.assertTrue(whileStatement.getLParenth() != null);\n      LOG.assertTrue(whileStatement.getCondition() != null);\n      if (whileStatement.getRParenth() == null) {\n        PsiWhileStatement statementPattern = (PsiWhileStatement)factory.createStatementFromText(\"while (){}\", instanceOfExpression);\n        whileStatement.addAfter(statementPattern.getRParenth(), whileStatement.getCondition());\n      }\n      if (negated) {\n        anchorAfter = whileStatement;\n      }\n      else {\n        PsiStatement body = whileStatement.getBody();\n        if (body == null) {\n          whileStatement.add(emptyBlockStatement);\n        }\n        else if (!(body instanceof PsiBlockStatement)) {\n          emptyBlockStatement.getCodeBlock().add(body);\n          whileStatement.getBody().replace(emptyBlockStatement);\n        }\n        anchorAfter = ((PsiBlockStatement)whileStatement.getBody()).getCodeBlock().getLBrace();\n      }\n    }\n    if (anchorAfter == null) {\n      return null;\n    }\n    return anchorAfter.getParent().addAfter(toInsert, anchorAfter);\n  }","commit_id":"f4d9788a79498743c7d143f6ec8a03fd8a8cf7a6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void dequalifyImpl(@NotNull CompositeElement reference) {\n    final ASTNode qualifier = reference.findChildByRole(ChildRole.QUALIFIER);\n    if (qualifier != null) {\n      reference.deleteChildInternal(qualifier);\n    }\n  }","id":37488,"modified_method":"private static void dequalifyImpl(@NotNull CompositeElement reference) {\n    final ASTNode qualifier = reference.findChildByRole(ChildRole.QUALIFIER);\n    if (qualifier != null) {\n      ASTNode firstChildNode = qualifier.getFirstChildNode();\n      boolean markToReformatBefore = firstChildNode instanceof TreeElement && CodeEditUtil.isMarkedToReformatBefore((TreeElement)firstChildNode);\n      reference.deleteChildInternal(qualifier);\n      if (markToReformatBefore) {\n        firstChildNode = reference.getFirstChildNode();\n        if (firstChildNode != null) {\n          CodeEditUtil.markToReformatBefore(firstChildNode, true);\n        }\n      }\n    }\n  }","commit_id":"f4d9788a79498743c7d143f6ec8a03fd8a8cf7a6","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static SNode _quotation_createNode_1o7xz7_a0o0a0a4a0(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, \"jetbrains.mps.lang.classLike.structure.ClassLikeMethod\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_5, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"execute\");\n    quotedNode_5.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), quotedNode_5, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5155329496662709030\")));\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x10af9581ff1L, \"jetbrains.mps.baseLanguage.structure.PublicVisibility\"), null, null, false);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x112670d273fL, 0x112670d886aL, \"visibility\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_16, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"models\");\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_19.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_25);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_19);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, \"jetbrains.mps.baseLanguage.structure.CastExpression\"), null, null, false);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_32);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4bL, \"type\"), quotedNode_26);\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_33);\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_34.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_34, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule.getModels():java.lang.Iterable\")));\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_34);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4cL, \"expression\"), quotedNode_27);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_20);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_16);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_17, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"nodes\");\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_28, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), (SNode) parameter_1);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_28);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_21);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_29);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_41 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_41.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_42);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_43, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), (SNode) parameter_2);\n    quotedNode_41.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_43);\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_41);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_39);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_37);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_38, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_40);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_38);\n    quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_35);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_30);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_22);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_17);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_23);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_31 = (SNode) parameter_3;\n    if (quotedNode_31 != null) {\n      quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), HUtil.copyIfNecessary(quotedNode_31));\n    }\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_24);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_18);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b215L, \"jetbrains.mps.baseLanguage.structure.Statement\"), null, null, false);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_13);\n    {\n      List<SNode> nodes = (List<SNode>) parameter_4;\n      for (SNode child : nodes) {\n        quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), HUtil.copyIfNecessary(child));\n      }\n    }\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1ffL, \"body\"), quotedNode_7);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"m\");\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\"), null, null, false);\n    quotedNode_15.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), quotedNode_15, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule\")));\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_15);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\"), quotedNode_8);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, \"jetbrains.mps.lang.classLike.structure.DependentTypeInstance\"), null, null, false);\n    quotedNode_9.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), quotedNode_9, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5387853834548062862\")));\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1fdL, \"returnType\"), quotedNode_9);\n    quotedNode_9.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x7e420dcd0899aa0eL, \"point\"), quotedNode_5);\n    quotedNode_23.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_17);\n    quotedNode_29.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_16);\n    quotedNode_33.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_8);\n    quotedNode_42.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_38);\n    return quotedNode_5;\n  }","id":37489,"modified_method":"private static SNode _quotation_createNode_1o7xz7_a0j0a0a0a0n0a(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    SNode quotedNode_44 = null;\n    SNode quotedNode_45 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"attributes\");\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    quotedNode_14.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), quotedNode_14, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049745\")));\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_14);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_18.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_18, facade.createModelReference(\"r:cf512d15-78eb-402a-a0bd-f5eea680b5a8(jetbrains.mps.lang.structure.pluginSolution.plugin)\"), facade.createNodeId(\"3025751040651069573\")));\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_18);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_42);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    quotedNode_43.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), quotedNode_43, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049745\")));\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_43);\n    quotedNode_33.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_38);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_33);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_28);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_29, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_29.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_34);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_29);\n    quotedNode_19.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_23);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_19);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117e3fd45c4L, \"jetbrains.mps.baseLanguage.collections.structure.WhereOperation\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11d47dc0e3bL, \"jetbrains.mps.baseLanguage.structure.NPEEqualsExpression\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_44 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_44);\n    quotedNode_45 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_45.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_45, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"1341860900489573894\")));\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_45);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11cL, \"leftExpression\"), quotedNode_39);\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, \"jetbrains.mps.lang.smodel.structure.LinkIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_40, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957616L, \"conceptDeclaration\"), (SNode) parameter_1);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_40, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957617L, \"linkDeclaration\"), (SNode) parameter_2);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11bL, \"rightExpression\"), quotedNode_40);\n    quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_35);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_30);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_24);\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_25, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_31 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_25.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_31);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_25);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_20);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_11);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_36 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_36);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_37.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_37, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"7714691473529772139\")));\n    quotedNode_41 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, \"jetbrains.mps.lang.smodel.structure.LinkIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_41, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957616L, \"conceptDeclaration\"), (SNode) parameter_3);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_41, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957617L, \"linkDeclaration\"), (SNode) parameter_4);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_41);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_37);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_32);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_26);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_21);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_22, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_27);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_22);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_17);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_13);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_9);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_12.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_8);\n    quotedNode_36.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_22);\n    quotedNode_42.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_29);\n    quotedNode_44.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_25);\n    return quotedNode_5;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_1o7xz7_a0a0a21a0a0e0a(Object parameter_1, Object parameter_2) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_3 = null;\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    quotedNode_3 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_3, MetaAdapterFactory.getProperty(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0xc5cbfc0eeac457bL, \"forceMultiLine\"), \"true\");\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_4, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_6);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_4);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_12, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_1);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_12);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_16, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x11dfede6ec0L, \"jetbrains.mps.lang.smodel.structure.Node_DetachOperation\"), null, null, false);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_14);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_10);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_5);\n    quotedNode_11.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    quotedNode_15.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    return quotedNode_3;\n  }","id":37490,"modified_method":"private static SNode _quotation_createNode_1o7xz7_a0k0a0a0a0n0a(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, \"jetbrains.mps.lang.classLike.structure.ClassLikeMethod\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_5, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"execute\");\n    quotedNode_5.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), quotedNode_5, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5155329496662709030\")));\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x10af9581ff1L, \"jetbrains.mps.baseLanguage.structure.PublicVisibility\"), null, null, false);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x112670d273fL, 0x112670d886aL, \"visibility\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_16, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"models\");\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_19.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_25);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_19);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, \"jetbrains.mps.baseLanguage.structure.CastExpression\"), null, null, false);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_32);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4bL, \"type\"), quotedNode_26);\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_33);\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_34.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_34, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule.getModels():java.lang.Iterable\")));\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_34);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4cL, \"expression\"), quotedNode_27);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_20);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_16);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_17, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"nodes\");\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_28, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), (SNode) parameter_1);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_28);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_21);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_29);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_41 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_41.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_42);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_43, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), (SNode) parameter_2);\n    quotedNode_41.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_43);\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_41);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_39);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_37);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_38, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_40);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_38);\n    quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_35);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_30);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_22);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_17);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_23);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_31 = (SNode) parameter_3;\n    if (quotedNode_31 != null) {\n      quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), HUtil.copyIfNecessary(quotedNode_31));\n    }\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_24);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_18);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b215L, \"jetbrains.mps.baseLanguage.structure.Statement\"), null, null, false);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_13);\n    {\n      List<SNode> nodes = (List<SNode>) parameter_4;\n      for (SNode child : nodes) {\n        quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), HUtil.copyIfNecessary(child));\n      }\n    }\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1ffL, \"body\"), quotedNode_7);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"m\");\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\"), null, null, false);\n    quotedNode_15.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), quotedNode_15, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule\")));\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_15);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\"), quotedNode_8);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, \"jetbrains.mps.lang.classLike.structure.DependentTypeInstance\"), null, null, false);\n    quotedNode_9.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), quotedNode_9, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5387853834548062862\")));\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1fdL, \"returnType\"), quotedNode_9);\n    quotedNode_9.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x7e420dcd0899aa0eL, \"point\"), quotedNode_5);\n    quotedNode_23.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_17);\n    quotedNode_29.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_16);\n    quotedNode_33.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_8);\n    quotedNode_42.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_38);\n    return quotedNode_5;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected boolean collectActionData(AnActionEvent event, final Map<String, Object> _params) {\n    if (!(super.collectActionData(event, _params))) {\n      return false;\n    }\n    {\n      SNode node = event.getData(MPSCommonDataKeys.NODE);\n      if (node != null) {\n        if (!(SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, \"jetbrains.mps.lang.structure.structure.LinkDeclaration\")))) {\n          node = null;\n        }\n      }\n      MapSequence.fromMap(_params).put(\"target\", node);\n    }\n    if (MapSequence.fromMap(_params).get(\"target\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"project\", event.getData(MPSCommonDataKeys.MPS_PROJECT));\n    if (MapSequence.fromMap(_params).get(\"project\") == null) {\n      return false;\n    }\n    return true;\n  }","id":37491,"modified_method":"protected boolean collectActionData(AnActionEvent event, final Map<String, Object> _params) {\n    if (!(super.collectActionData(event, _params))) {\n      return false;\n    }\n    {\n      SNode node = event.getData(MPSCommonDataKeys.NODE);\n      if (node != null) {\n        if (!(SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, \"jetbrains.mps.lang.structure.structure.LinkDeclaration\")))) {\n          node = null;\n        }\n      }\n      MapSequence.fromMap(_params).put(\"target\", node);\n    }\n    if (MapSequence.fromMap(_params).get(\"target\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"mpsProject\", event.getData(MPSCommonDataKeys.MPS_PROJECT));\n    if (MapSequence.fromMap(_params).get(\"mpsProject\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"project\", event.getData(CommonDataKeys.PROJECT));\n    if (MapSequence.fromMap(_params).get(\"project\") == null) {\n      return false;\n    }\n    return true;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_1o7xz7_a0n0a0a4a0(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    SNode quotedNode_44 = null;\n    SNode quotedNode_45 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"attributes\");\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    quotedNode_14.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), quotedNode_14, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049745\")));\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_14);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_18.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_18, facade.createModelReference(\"r:cf512d15-78eb-402a-a0bd-f5eea680b5a8(jetbrains.mps.lang.structure.pluginSolution.plugin)\"), facade.createNodeId(\"3025751040651069573\")));\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_18);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_42);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    quotedNode_43.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), quotedNode_43, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049745\")));\n    quotedNode_38.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_43);\n    quotedNode_33.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_38);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_33);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_28);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_29, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_29.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_34);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_29);\n    quotedNode_19.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_23);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_19);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117e3fd45c4L, \"jetbrains.mps.baseLanguage.collections.structure.WhereOperation\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11d47dc0e3bL, \"jetbrains.mps.baseLanguage.structure.NPEEqualsExpression\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_44 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_44);\n    quotedNode_45 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_45.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_45, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"1341860900489573894\")));\n    quotedNode_39.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_45);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11cL, \"leftExpression\"), quotedNode_39);\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, \"jetbrains.mps.lang.smodel.structure.LinkIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_40, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957616L, \"conceptDeclaration\"), (SNode) parameter_1);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_40, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957617L, \"linkDeclaration\"), (SNode) parameter_2);\n    quotedNode_35.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11bL, \"rightExpression\"), quotedNode_40);\n    quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_35);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_30);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_24);\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_25, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_31 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_25.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_31);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_25);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_20);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_11);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_36 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_36);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_37.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_37, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"7714691473529772139\")));\n    quotedNode_41 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, \"jetbrains.mps.lang.smodel.structure.LinkIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_41, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957616L, \"conceptDeclaration\"), (SNode) parameter_3);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_41, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1957615L, 0x24b2bf7ce1957617L, \"linkDeclaration\"), (SNode) parameter_4);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_41);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_37);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_32);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_26);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_21);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_22, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_27);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_22);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_17);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_13);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_9);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_12.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_8);\n    quotedNode_36.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_22);\n    quotedNode_42.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_29);\n    quotedNode_44.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_25);\n    return quotedNode_5;\n  }","id":37492,"modified_method":"private static SNode _quotation_createNode_1o7xz7_a0a0i0a0a0a0n0a(Object parameter_1, Object parameter_2, Object parameter_3) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_5, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_7);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_5);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_16);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_17, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_1);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_17);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_18);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_19, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_19);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_13);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_10);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_8);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940cd6167L, \"jetbrains.mps.baseLanguage.structure.NullLiteral\"), null, null, false);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_20);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_21, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_3);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_21);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_15);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_11);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_9);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_6);\n    quotedNode_16.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    quotedNode_18.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    quotedNode_20.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    return quotedNode_4;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_1o7xz7_a0a0m0a0a4a0(Object parameter_1, Object parameter_2, Object parameter_3) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_5, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_7);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_5);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_16);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_17, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_1);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_17);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_12);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_18);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_19, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_19);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_13);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_10);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_8);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940cd6167L, \"jetbrains.mps.baseLanguage.structure.NullLiteral\"), null, null, false);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_20);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_21, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_3);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_21);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_15);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_11);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_9);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_6);\n    quotedNode_16.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    quotedNode_18.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    quotedNode_20.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_5);\n    return quotedNode_4;\n  }","id":37493,"modified_method":"private static SNode _quotation_createNode_1o7xz7_a0a0a8a0a0a0a31a0(Object parameter_1, Object parameter_2) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_3 = null;\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    quotedNode_3 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_3, MetaAdapterFactory.getProperty(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0xc5cbfc0eeac457bL, \"forceMultiLine\"), \"true\");\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_4, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_6);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_4);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_12, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_1);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_12);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, \"jetbrains.mps.lang.smodel.structure.SLinkAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_16, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96ea2caL, 0x108f974549cL, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x11dfede6ec0L, \"jetbrains.mps.lang.smodel.structure.Node_DetachOperation\"), null, null, false);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_14);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_10);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_5);\n    quotedNode_11.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    quotedNode_15.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    return quotedNode_3;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SNode targetConcept = MoveUpDialog.getConcept(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getProject(), ((SNode) MapSequence.fromMap(_params).get(\"target\")), \"link\");\n      ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository().getModelAccess();\n      if (targetConcept == null) {\n        return;\n      }\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          final SNode currentConcept = SNodeOperations.getNodeAncestor(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, \"jetbrains.mps.lang.structure.structure.AbstractConceptDeclaration\"), false, false);\n          if (currentConcept == null) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"target\")), ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository()))) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(targetConcept, ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository()))) {\n            return;\n          }\n          Language currentLanguage = Language.getLanguageFor(SNodeOperations.getModel(currentConcept));\n          SNode newLink = SNodeOperations.copyNode(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6bL, \"linkDeclaration\"))).addElement(newLink);\n          AttributeOperations.setAttribute(((SNode) MapSequence.fromMap(_params).get(\"target\")), new IAttributeDescriptor.NodeAttribute(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\")), createDeprecatedNodeAnnotation_1o7xz7_a0h0a0a4a0(\"The link was moved to superconcept \\\"\" + BehaviorReflection.invokeVirtual(String.class, targetConcept, \"virtual_getFqName_1213877404258\", new Object[]{}) + \"\\\"\"));\n          String roleName = SPropertyOperations.getString(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\"));\n          SPropertyOperations.set(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\"), roleName + \"_old\");\n\n          SNode refactorInstances;\n          if (SPropertyOperations.hasValue(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf980556927L, \"metaClass\"), \"reference\", \"reference\")) {\n            refactorInstances = _quotation_createNode_1o7xz7_a0a0m0a0a4a0(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")), ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          } else if (LinkDeclaration_Behavior.call_isSingular_1213877254557(((SNode) MapSequence.fromMap(_params).get(\"target\")))) {\n            refactorInstances = _quotation_createNode_1o7xz7_a0a0a21a0a0e0a(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          } else {\n            refactorInstances = _quotation_createNode_1o7xz7_a0a0a21a0a0e0a_0(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          }\n          SNode migrateAttributes = _quotation_createNode_1o7xz7_a0n0a0a4a0(currentConcept, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, newLink);\n          SNode executeMethod = _quotation_createNode_1o7xz7_a0o0a0a4a0(currentConcept, currentConcept, refactorInstances, (SPropertyOperations.hasValue(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf980556927L, \"metaClass\"), \"reference\", \"reference\") ? SLinkOperations.getChildren(migrateAttributes, MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\")) : ListSequence.fromList(new ArrayList<SNode>(0))));\n          MigrationScriptBuilder.createMigrationScript(currentLanguage).setName(\"Move_link_\" + roleName).setExecuteMethod(executeMethod);\n        }\n      });\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MoveLinkUp\", t);\n      }\n    }\n  }","id":37494,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SNode targetConcept = MoveUpDialog.getConcept(((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getProject(), ((SNode) MapSequence.fromMap(_params).get(\"target\")), \"link\");\n      ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository().getModelAccess();\n      if (targetConcept == null) {\n        return;\n      }\n      final Wrappers._T<SNode> currentConcept = new Wrappers._T<SNode>();\n      final Wrappers._T<Language> currentLanguage = new Wrappers._T<Language>();\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          currentConcept.value = SNodeOperations.getNodeAncestor(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, \"jetbrains.mps.lang.structure.structure.AbstractConceptDeclaration\"), false, false);\n          if (currentConcept.value == null) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"target\")), ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository()))) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(targetConcept, ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository()))) {\n            return;\n          }\n          currentLanguage.value = Language.getLanguageFor(SNodeOperations.getModel(currentConcept.value));\n        }\n      });\n\n\n\n      int result = Messages.showYesNoCancelDialog(((Project) MapSequence.fromMap(_params).get(\"project\")), \"Do you want to run the refactoring locally?\", \"Execute refactoring\", \"Run locally\", \"Write migration\", \"Cancel\", null);\n\n      if (result == Messages.CANCEL) {\n        return;\n      }\n      if (result == Messages.YES) {\n        modelAccess.executeCommandInEDT(new Runnable() {\n          public void run() {\n            Set<SReference> usages = FindUsagesManager.getInstance().findUsages(GlobalScope.getInstance(), Collections.singleton(((SNode) MapSequence.fromMap(_params).get(\"target\"))), new EmptyProgressMonitor());\n            Set<SNode> instances = FindUsagesManager.getInstance().findInstances(GlobalScope.getInstance(), Collections.singleton(SNodeOperations.asSConcept(currentConcept.value)), false, new EmptyProgressMonitor());\n            if (SPropertyOperations.hasValue(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf980556927L, \"metaClass\"), \"aggregation\", \"reference\")) {\n              SContainmentLink oldLink = MetaAdapterByDeclaration.getContainmentLink(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6bL, \"linkDeclaration\"))).addElement(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              SContainmentLink newLink = MetaAdapterByDeclaration.getContainmentLink(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              for (SNode node : SetSequence.fromSet(instances)) {\n                List<SNode> children = ListSequence.fromListWithValues(new ArrayList<SNode>(), node.getChildren(oldLink));\n                for (SNode child : ListSequence.fromList(children)) {\n                  node.removeChild(child);\n                  node.addChild(newLink, child);\n                }\n              }\n            } else {\n              SReferenceLink oldLink = MetaAdapterByDeclaration.getReferenceLink(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6bL, \"linkDeclaration\"))).addElement(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              SReferenceLink newLink = MetaAdapterByDeclaration.getReferenceLink(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n              for (SNode node : SetSequence.fromSet(instances)) {\n                SNode referenceTarget = node.getReferenceTarget(oldLink);\n                node.setReferenceTarget(newLink, referenceTarget);\n                node.setReferenceTarget(oldLink, null);\n              }\n\n            }\n            for (SReference usage : SetSequence.fromSet(usages)) {\n              usage.getSourceNode().setReferenceTarget(usage.getLink(), ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            }\n          }\n        });\n      } else {\n        modelAccess.executeCommandInEDT(new _Adapters._return_P0_E0_to_Runnable_adapter(new _FunctionTypes._return_P0_E0<MigrationScriptBuilder>() {\n          public MigrationScriptBuilder invoke() {\n\n            SNode newLink = SNodeOperations.copyNode(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6bL, \"linkDeclaration\"))).addElement(newLink);\n            AttributeOperations.setAttribute(((SNode) MapSequence.fromMap(_params).get(\"target\")), new IAttributeDescriptor.NodeAttribute(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\")), createDeprecatedNodeAnnotation_1o7xz7_a0d0a0a0a0n0a(\"The link was moved to superconcept \\\"\" + BehaviorReflection.invokeVirtual(String.class, targetConcept, \"virtual_getFqName_1213877404258\", new Object[]{}) + \"\\\"\"));\n            String roleName = SPropertyOperations.getString(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\"));\n            SPropertyOperations.set(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf98052f333L, \"role\"), roleName + \"_old\");\n\n            SNode refactorInstances;\n            if (SPropertyOperations.hasValue(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf980556927L, \"metaClass\"), \"reference\", \"reference\")) {\n              refactorInstances = _quotation_createNode_1o7xz7_a0a0i0a0a0a0n0a(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")), ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            } else if (LinkDeclaration_Behavior.call_isSingular_1213877254557(((SNode) MapSequence.fromMap(_params).get(\"target\")))) {\n              refactorInstances = _quotation_createNode_1o7xz7_a0a0a8a0a0a0a31a0(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            } else {\n              refactorInstances = _quotation_createNode_1o7xz7_a0a0a8a0a0a0a31a0_0(newLink, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            }\n            SNode migrateAttributes = _quotation_createNode_1o7xz7_a0j0a0a0a0n0a(currentConcept.value, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, newLink);\n            SNode executeMethod = _quotation_createNode_1o7xz7_a0k0a0a0a0n0a(currentConcept.value, currentConcept.value, refactorInstances, (SPropertyOperations.hasValue(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086aL, 0xf980556927L, \"metaClass\"), \"reference\", \"reference\") ? SLinkOperations.getChildren(migrateAttributes, MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\")) : ListSequence.fromList(new ArrayList<SNode>(0))));\n            return MigrationScriptBuilder.createMigrationScript(currentLanguage.value).setName(\"Move_link_\" + roleName).setExecuteMethod(executeMethod);\n          }\n        }));\n      }\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MoveLinkUp\", t);\n      }\n    }\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_1o7xz7_a0a0a21a0a0e0a_0(Object parameter_1, Object parameter_2) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_3 = null;\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    quotedNode_3 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_3, MetaAdapterFactory.getProperty(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0xc5cbfc0eeac457bL, \"forceMultiLine\"), \"true\");\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_4, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_6);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_4);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, \"jetbrains.mps.lang.smodel.structure.SLinkListAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_12, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, 0x108f974c962L, \"link\"), (SNode) parameter_1);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_12);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10e3d20dbefL, \"jetbrains.mps.baseLanguage.collections.structure.AddAllElementsOperation\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, \"jetbrains.mps.lang.smodel.structure.SLinkListAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_15, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, 0x108f974c962L, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_15);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x7818f71827244b5L, 0x7818f71827244b6L, \"argument\"), quotedNode_13);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_10);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_5);\n    quotedNode_11.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    quotedNode_14.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    return quotedNode_3;\n  }","id":37495,"modified_method":"private static SNode _quotation_createNode_1o7xz7_a0a0a8a0a0a0a31a0_0(Object parameter_1, Object parameter_2) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_3 = null;\n    SNode quotedNode_4 = null;\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    quotedNode_3 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_3, MetaAdapterFactory.getProperty(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0xc5cbfc0eeac457bL, \"forceMultiLine\"), \"true\");\n    quotedNode_4 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_4, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_4.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_6);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_4);\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, \"jetbrains.mps.lang.smodel.structure.SLinkListAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_12, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, 0x108f974c962L, \"link\"), (SNode) parameter_1);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_12);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10e3d20dbefL, \"jetbrains.mps.baseLanguage.collections.structure.AddAllElementsOperation\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, \"jetbrains.mps.lang.smodel.structure.SLinkListAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_15, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f970c119L, 0x108f974c962L, \"link\"), (SNode) parameter_2);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_15);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x7818f71827244b5L, 0x7818f71827244b6L, \"argument\"), quotedNode_13);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_10);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_7);\n    quotedNode_3.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_5);\n    quotedNode_11.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    quotedNode_14.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_4);\n    return quotedNode_3;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode createDeprecatedNodeAnnotation_1o7xz7_a0h0a0a4a0(Object p0) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode n1 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\"), null, null, false);\n    n1.setProperty(MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, 0x11d3ec760e8L, \"comment\"), String.valueOf(p0));\n    return n1;\n  }","id":37496,"modified_method":"private static SNode createDeprecatedNodeAnnotation_1o7xz7_a0d0a0a0a0n0a(Object p0) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode n1 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\"), null, null, false);\n    n1.setProperty(MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, 0x11d3ec760e8L, \"comment\"), String.valueOf(p0));\n    return n1;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SNode targetConcept = MoveUpDialog.getConcept(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getProject(), ((SNode) MapSequence.fromMap(_params).get(\"target\")), \"property\");\n      ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository().getModelAccess();\n      if (targetConcept == null) {\n        return;\n      }\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          final SNode currentConcept = SNodeOperations.getNodeAncestor(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, \"jetbrains.mps.lang.structure.structure.AbstractConceptDeclaration\"), false, false);\n          if (currentConcept == null) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"target\")), ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository()))) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(targetConcept, ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository()))) {\n            return;\n          }\n          Language sourceLanguage = Language.getLanguageFor(SNodeOperations.getModel(currentConcept));\n          SNode newProperty = SNodeOperations.copyNode(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6cL, \"propertyDeclaration\"))).addElement(newProperty);\n          AttributeOperations.setAttribute(((SNode) MapSequence.fromMap(_params).get(\"target\")), new IAttributeDescriptor.NodeAttribute(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\")), createDeprecatedNodeAnnotation_vnzymo_a0h0a0a4a0(\"The property was moved to superconcept \\\"\" + BehaviorReflection.invokeVirtual(String.class, targetConcept, \"virtual_getFqName_1213877404258\", new Object[]{}) + \"\\\"\"));\n          String propName = SPropertyOperations.getString(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"));\n          SPropertyOperations.set(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), propName + \"_old\");\n\n          SNode refactorInstances;\n          refactorInstances = _quotation_createNode_vnzymo_a0m0a0a4a0(newProperty, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n          SNode executeMethod = _quotation_createNode_vnzymo_a0n0a0a4a0(currentConcept, currentConcept, refactorInstances, targetConcept, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, newProperty);\n          MigrationScriptBuilder.createMigrationScript(sourceLanguage).setName(\"Move_property_\" + propName).setExecuteMethod(executeMethod);\n        }\n      });\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MovePropertyUp\", t);\n      }\n    }\n  }","id":37497,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SNode targetConcept = MoveUpDialog.getConcept(((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getProject(), ((SNode) MapSequence.fromMap(_params).get(\"target\")), \"property\");\n      ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository().getModelAccess();\n      if (targetConcept == null) {\n        return;\n      }\n      final Wrappers._T<SNode> currentConcept = new Wrappers._T<SNode>();\n      final Wrappers._T<Language> currentLanguage = new Wrappers._T<Language>();\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          currentConcept.value = SNodeOperations.getNodeAncestor(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, \"jetbrains.mps.lang.structure.structure.AbstractConceptDeclaration\"), false, false);\n          if (currentConcept.value == null) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"target\")), ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository()))) {\n            return;\n          }\n          if (!(SNodeUtil.isAccessible(targetConcept, ((MPSProject) MapSequence.fromMap(_params).get(\"mpsProject\")).getRepository()))) {\n            return;\n          }\n          currentLanguage.value = Language.getLanguageFor(SNodeOperations.getModel(currentConcept.value));\n        }\n      });\n\n\n\n      int result = Messages.showYesNoCancelDialog(((Project) MapSequence.fromMap(_params).get(\"project\")), \"Do you want to run the refactoring locally?\", \"Execute refactoring\", \"Run locally\", \"Write migration\", \"Cancel\", null);\n\n      if (result == Messages.CANCEL) {\n        return;\n      }\n      if (result == Messages.YES) {\n        modelAccess.executeCommandInEDT(new Runnable() {\n          public void run() {\n            Set<SReference> usages = FindUsagesManager.getInstance().findUsages(GlobalScope.getInstance(), Collections.singleton(((SNode) MapSequence.fromMap(_params).get(\"target\"))), new EmptyProgressMonitor());\n            Set<SNode> instances = FindUsagesManager.getInstance().findInstances(GlobalScope.getInstance(), Collections.singleton(SNodeOperations.asSConcept(currentConcept.value)), false, new EmptyProgressMonitor());\n\n            SProperty oldProp = MetaAdapterByDeclaration.getProperty(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6cL, \"propertyDeclaration\"))).addElement(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            SProperty newProp = MetaAdapterByDeclaration.getProperty(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            for (SNode node : SetSequence.fromSet(instances)) {\n              String value = node.getProperty(oldProp);\n              node.setProperty(newProp, value);\n              node.setProperty(oldProp, null);\n            }\n            for (SReference usage : SetSequence.fromSet(usages)) {\n              usage.getSourceNode().setReferenceTarget(usage.getLink(), ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            }\n          }\n        });\n      } else {\n        modelAccess.executeCommandInEDT(new _Adapters._return_P0_E0_to_Runnable_adapter(new _FunctionTypes._return_P0_E0<MigrationScriptBuilder>() {\n          public MigrationScriptBuilder invoke() {\n            SNode newProperty = SNodeOperations.copyNode(((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            ListSequence.fromList(SLinkOperations.getChildren(targetConcept, MetaAdapterFactory.getContainmentLink(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x1103553c5ffL, 0xf979c3ba6cL, \"propertyDeclaration\"))).addElement(newProperty);\n            AttributeOperations.setAttribute(((SNode) MapSequence.fromMap(_params).get(\"target\")), new IAttributeDescriptor.NodeAttribute(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\")), createDeprecatedNodeAnnotation_vnzymo_a0c0a0a0a0n0a(\"The property was moved to superconcept \\\"\" + BehaviorReflection.invokeVirtual(String.class, targetConcept, \"virtual_getFqName_1213877404258\", new Object[]{}) + \"\\\"\"));\n            String propName = SPropertyOperations.getString(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"));\n            SPropertyOperations.set(((SNode) MapSequence.fromMap(_params).get(\"target\")), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), propName + \"_old\");\n\n            SNode refactorInstances;\n            refactorInstances = _quotation_createNode_vnzymo_a0h0a0a0a0n0a(newProperty, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, ((SNode) MapSequence.fromMap(_params).get(\"target\")));\n            SNode executeMethod = _quotation_createNode_vnzymo_a0i0a0a0a0n0a(currentConcept.value, currentConcept.value, refactorInstances, targetConcept, ((SNode) MapSequence.fromMap(_params).get(\"target\")), targetConcept, newProperty);\n            return MigrationScriptBuilder.createMigrationScript(currentLanguage.value).setName(\"Move_property_\" + propName).setExecuteMethod(executeMethod);\n          }\n        }));\n      }\n\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MovePropertyUp\", t);\n      }\n    }\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode createDeprecatedNodeAnnotation_vnzymo_a0h0a0a4a0(Object p0) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode n1 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\"), null, null, false);\n    n1.setProperty(MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, 0x11d3ec760e8L, \"comment\"), String.valueOf(p0));\n    return n1;\n  }","id":37498,"modified_method":"private static SNode createDeprecatedNodeAnnotation_vnzymo_a0c0a0a0a0n0a(Object p0) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode n1 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\"), null, null, false);\n    n1.setProperty(MetaAdapterFactory.getProperty(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, 0x11d3ec760e8L, \"comment\"), String.valueOf(p0));\n    return n1;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_vnzymo_a0m0a0a4a0(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_6, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_17);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, \"jetbrains.mps.lang.smodel.structure.SPropertyAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_18, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, 0x108f9727bcdL, \"property\"), (SNode) parameter_1);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_18);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_19);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, \"jetbrains.mps.lang.smodel.structure.SPropertyAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_20, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, 0x108f9727bcdL, \"property\"), (SNode) parameter_2);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_20);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_14);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_11);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10aaf6d7435L, \"jetbrains.mps.lang.smodel.structure.SemanticDowncastExpression\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10aaf6d7435L, 0x10aaf6f6e81L, \"leftExpression\"), quotedNode_21);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_16.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_16, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.model(MPS.OpenAPI/org.jetbrains.mps.openapi.model@java_stub)\"), facade.createNodeId(\"~SNode.setProperty(org.jetbrains.mps.openapi.language.SProperty,java.lang.String):void\")));\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_22, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_3);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_22, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_4);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_22);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940cd6167L, \"jetbrains.mps.baseLanguage.structure.NullLiteral\"), null, null, false);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_23);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_12);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_10);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_7);\n    quotedNode_17.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    quotedNode_19.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    quotedNode_21.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    return quotedNode_5;\n  }","id":37499,"modified_method":"private static SNode _quotation_createNode_vnzymo_a0i0a0a0a0n0a(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4, Object parameter_5, Object parameter_6, Object parameter_7) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    SNode quotedNode_44 = null;\n    SNode quotedNode_45 = null;\n    SNode quotedNode_46 = null;\n    SNode quotedNode_47 = null;\n    SNode quotedNode_48 = null;\n    SNode quotedNode_49 = null;\n    SNode quotedNode_50 = null;\n    SNode quotedNode_51 = null;\n    SNode quotedNode_52 = null;\n    SNode quotedNode_53 = null;\n    SNode quotedNode_54 = null;\n    SNode quotedNode_55 = null;\n    SNode quotedNode_56 = null;\n    SNode quotedNode_57 = null;\n    SNode quotedNode_58 = null;\n    SNode quotedNode_59 = null;\n    SNode quotedNode_60 = null;\n    SNode quotedNode_61 = null;\n    SNode quotedNode_62 = null;\n    SNode quotedNode_63 = null;\n    SNode quotedNode_64 = null;\n    SNode quotedNode_65 = null;\n    SNode quotedNode_66 = null;\n    SNode quotedNode_67 = null;\n    SNode quotedNode_68 = null;\n    SNode quotedNode_69 = null;\n    SNode quotedNode_70 = null;\n    SNode quotedNode_71 = null;\n    SNode quotedNode_72 = null;\n    SNode quotedNode_73 = null;\n    SNode quotedNode_74 = null;\n    SNode quotedNode_75 = null;\n    SNode quotedNode_76 = null;\n    SNode quotedNode_77 = null;\n    SNode quotedNode_78 = null;\n    SNode quotedNode_79 = null;\n    SNode quotedNode_80 = null;\n    SNode quotedNode_81 = null;\n    SNode quotedNode_82 = null;\n    SNode quotedNode_83 = null;\n    SNode quotedNode_84 = null;\n    SNode quotedNode_85 = null;\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, \"jetbrains.mps.lang.classLike.structure.ClassLikeMethod\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"execute\");\n    quotedNode_8.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), quotedNode_8, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5155329496662709030\")));\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x10af9581ff1L, \"jetbrains.mps.baseLanguage.structure.PublicVisibility\"), null, null, false);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x112670d273fL, 0x112670d886aL, \"visibility\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_20, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"models\");\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_25.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_35);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_25);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, \"jetbrains.mps.baseLanguage.structure.CastExpression\"), null, null, false);\n    quotedNode_36 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_46 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_36.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_46);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4bL, \"type\"), quotedNode_36);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_47 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_47);\n    quotedNode_48 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_48.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_48, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule.getModels():java.lang.Iterable\")));\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_48);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4cL, \"expression\"), quotedNode_37);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_26);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_20);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_21, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"nodes\");\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_38, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), (SNode) parameter_1);\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_38);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_27);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_39);\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_49 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_56 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_63 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_70 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_76 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_70.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_76);\n    quotedNode_77 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_77, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), (SNode) parameter_2);\n    quotedNode_70.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_77);\n    quotedNode_63.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_70);\n    quotedNode_56.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_63);\n    quotedNode_49.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_56);\n    quotedNode_57 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_57, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_64 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_57.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_64);\n    quotedNode_49.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_57);\n    quotedNode_40.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_49);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_40);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_28);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_21);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_29);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_41 = (SNode) parameter_3;\n    if (quotedNode_41 != null) {\n      quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), HUtil.copyIfNecessary(quotedNode_41));\n    }\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_30);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_22);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b215L, \"jetbrains.mps.baseLanguage.structure.Statement\"), null, null, false);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_16);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_23, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"attributes\");\n    quotedNode_31 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    quotedNode_42.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), quotedNode_42, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049750\")));\n    quotedNode_31.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_42);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_31);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_51 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_43.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_51);\n    quotedNode_52 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_58 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_65 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_71 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_78 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_82 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_78.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_82);\n    quotedNode_83 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    quotedNode_83.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), quotedNode_83, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049750\")));\n    quotedNode_78.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_83);\n    quotedNode_71.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_78);\n    quotedNode_65.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_71);\n    quotedNode_58.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_65);\n    quotedNode_66 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_66, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_72 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_66.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_72);\n    quotedNode_58.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_66);\n    quotedNode_52.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_58);\n    quotedNode_43.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_52);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_43);\n    quotedNode_44 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117e3fd45c4L, \"jetbrains.mps.baseLanguage.collections.structure.WhereOperation\"), null, null, false);\n    quotedNode_53 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_59 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_67 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_73 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11d47dc0e3bL, \"jetbrains.mps.baseLanguage.structure.NPEEqualsExpression\"), null, null, false);\n    quotedNode_79 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_84 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_79.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_84);\n    quotedNode_85 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_85.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_85, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"1341860900488756504\")));\n    quotedNode_79.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_85);\n    quotedNode_73.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11cL, \"leftExpression\"), quotedNode_79);\n    quotedNode_80 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_80, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_4);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_80, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_5);\n    quotedNode_73.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11bL, \"rightExpression\"), quotedNode_80);\n    quotedNode_67.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_73);\n    quotedNode_59.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_67);\n    quotedNode_53.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_59);\n    quotedNode_60 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_60, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_68 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_60.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_68);\n    quotedNode_53.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_60);\n    quotedNode_44.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_53);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_44);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_32);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_23);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_17);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_33);\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_45 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_54 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_61 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_69 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_74 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_69.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_74);\n    quotedNode_75 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_75.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_75, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"7714691473529670203\")));\n    quotedNode_81 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_81, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_6);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_81, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_7);\n    quotedNode_75.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_81);\n    quotedNode_69.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_75);\n    quotedNode_61.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_69);\n    quotedNode_54.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_61);\n    quotedNode_45.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_54);\n    quotedNode_55 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_55, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_62 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_55.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_62);\n    quotedNode_45.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_55);\n    quotedNode_34.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_45);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_34);\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_24);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_18);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1ffL, \"body\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_11, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"m\");\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\"), null, null, false);\n    quotedNode_19.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), quotedNode_19, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule\")));\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_19);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, \"jetbrains.mps.lang.classLike.structure.DependentTypeInstance\"), null, null, false);\n    quotedNode_12.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), quotedNode_12, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5387853834548062862\")));\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1fdL, \"returnType\"), quotedNode_12);\n    quotedNode_12.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x7e420dcd0899aa0eL, \"point\"), quotedNode_8);\n    quotedNode_29.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_21);\n    quotedNode_33.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_23);\n    quotedNode_39.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_20);\n    quotedNode_47.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_11);\n    quotedNode_51.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_20);\n    quotedNode_74.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_55);\n    quotedNode_76.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_57);\n    quotedNode_82.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_66);\n    quotedNode_84.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_60);\n    return quotedNode_8;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"protected boolean collectActionData(AnActionEvent event, final Map<String, Object> _params) {\n    if (!(super.collectActionData(event, _params))) {\n      return false;\n    }\n    {\n      SNode node = event.getData(MPSCommonDataKeys.NODE);\n      if (node != null) {\n        if (!(SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086bL, \"jetbrains.mps.lang.structure.structure.PropertyDeclaration\")))) {\n          node = null;\n        }\n      }\n      MapSequence.fromMap(_params).put(\"target\", node);\n    }\n    if (MapSequence.fromMap(_params).get(\"target\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"project\", event.getData(MPSCommonDataKeys.MPS_PROJECT));\n    if (MapSequence.fromMap(_params).get(\"project\") == null) {\n      return false;\n    }\n    return true;\n  }","id":37500,"modified_method":"protected boolean collectActionData(AnActionEvent event, final Map<String, Object> _params) {\n    if (!(super.collectActionData(event, _params))) {\n      return false;\n    }\n    {\n      SNode node = event.getData(MPSCommonDataKeys.NODE);\n      if (node != null) {\n        if (!(SNodeOperations.isInstanceOf(node, MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0xf979bd086bL, \"jetbrains.mps.lang.structure.structure.PropertyDeclaration\")))) {\n          node = null;\n        }\n      }\n      MapSequence.fromMap(_params).put(\"target\", node);\n    }\n    if (MapSequence.fromMap(_params).get(\"target\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"mpsProject\", event.getData(MPSCommonDataKeys.MPS_PROJECT));\n    if (MapSequence.fromMap(_params).get(\"mpsProject\") == null) {\n      return false;\n    }\n    MapSequence.fromMap(_params).put(\"project\", event.getData(CommonDataKeys.PROJECT));\n    if (MapSequence.fromMap(_params).get(\"project\") == null) {\n      return false;\n    }\n    return true;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static SNode _quotation_createNode_vnzymo_a0n0a0a4a0(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4, Object parameter_5, Object parameter_6, Object parameter_7) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    SNode quotedNode_24 = null;\n    SNode quotedNode_25 = null;\n    SNode quotedNode_26 = null;\n    SNode quotedNode_27 = null;\n    SNode quotedNode_28 = null;\n    SNode quotedNode_29 = null;\n    SNode quotedNode_30 = null;\n    SNode quotedNode_31 = null;\n    SNode quotedNode_32 = null;\n    SNode quotedNode_33 = null;\n    SNode quotedNode_34 = null;\n    SNode quotedNode_35 = null;\n    SNode quotedNode_36 = null;\n    SNode quotedNode_37 = null;\n    SNode quotedNode_38 = null;\n    SNode quotedNode_39 = null;\n    SNode quotedNode_40 = null;\n    SNode quotedNode_41 = null;\n    SNode quotedNode_42 = null;\n    SNode quotedNode_43 = null;\n    SNode quotedNode_44 = null;\n    SNode quotedNode_45 = null;\n    SNode quotedNode_46 = null;\n    SNode quotedNode_47 = null;\n    SNode quotedNode_48 = null;\n    SNode quotedNode_49 = null;\n    SNode quotedNode_50 = null;\n    SNode quotedNode_51 = null;\n    SNode quotedNode_52 = null;\n    SNode quotedNode_53 = null;\n    SNode quotedNode_54 = null;\n    SNode quotedNode_55 = null;\n    SNode quotedNode_56 = null;\n    SNode quotedNode_57 = null;\n    SNode quotedNode_58 = null;\n    SNode quotedNode_59 = null;\n    SNode quotedNode_60 = null;\n    SNode quotedNode_61 = null;\n    SNode quotedNode_62 = null;\n    SNode quotedNode_63 = null;\n    SNode quotedNode_64 = null;\n    SNode quotedNode_65 = null;\n    SNode quotedNode_66 = null;\n    SNode quotedNode_67 = null;\n    SNode quotedNode_68 = null;\n    SNode quotedNode_69 = null;\n    SNode quotedNode_70 = null;\n    SNode quotedNode_71 = null;\n    SNode quotedNode_72 = null;\n    SNode quotedNode_73 = null;\n    SNode quotedNode_74 = null;\n    SNode quotedNode_75 = null;\n    SNode quotedNode_76 = null;\n    SNode quotedNode_77 = null;\n    SNode quotedNode_78 = null;\n    SNode quotedNode_79 = null;\n    SNode quotedNode_80 = null;\n    SNode quotedNode_81 = null;\n    SNode quotedNode_82 = null;\n    SNode quotedNode_83 = null;\n    SNode quotedNode_84 = null;\n    SNode quotedNode_85 = null;\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, \"jetbrains.mps.lang.classLike.structure.ClassLikeMethod\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_8, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"execute\");\n    quotedNode_8.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d154L, 0x443e89bb321537L, \"decl\"), quotedNode_8, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5155329496662709030\")));\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x10af9581ff1L, \"jetbrains.mps.baseLanguage.structure.PublicVisibility\"), null, null, false);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x112670d273fL, 0x112670d886aL, \"visibility\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_20, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"models\");\n    quotedNode_25 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_35 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_25.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_35);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_25);\n    quotedNode_26 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, \"jetbrains.mps.baseLanguage.structure.CastExpression\"), null, null, false);\n    quotedNode_36 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_46 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10a2d94c0cdL, \"jetbrains.mps.lang.smodel.structure.SModelType\"), null, null, false);\n    quotedNode_36.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_46);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4bL, \"type\"), quotedNode_36);\n    quotedNode_37 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_47 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_47);\n    quotedNode_48 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_48.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_48, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule.getModels():java.lang.Iterable\")));\n    quotedNode_37.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_48);\n    quotedNode_26.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940dabe4aL, 0xf940dabe4cL, \"expression\"), quotedNode_37);\n    quotedNode_20.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_26);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_20);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_21, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"nodes\");\n    quotedNode_27 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_38 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_38, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), (SNode) parameter_1);\n    quotedNode_27.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_38);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_27);\n    quotedNode_28 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_39 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_39);\n    quotedNode_40 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_49 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_56 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_63 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_70 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_76 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_70.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_76);\n    quotedNode_77 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_77, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), (SNode) parameter_2);\n    quotedNode_70.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_77);\n    quotedNode_63.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_70);\n    quotedNode_56.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_63);\n    quotedNode_49.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_56);\n    quotedNode_57 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_57, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_64 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_57.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_64);\n    quotedNode_49.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_57);\n    quotedNode_40.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_49);\n    quotedNode_28.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_40);\n    quotedNode_21.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_28);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_21);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_14);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_29 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_29);\n    quotedNode_30 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_41 = (SNode) parameter_3;\n    if (quotedNode_41 != null) {\n      quotedNode_30.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), HUtil.copyIfNecessary(quotedNode_41));\n    }\n    quotedNode_22.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_30);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_22);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b215L, \"jetbrains.mps.baseLanguage.structure.Statement\"), null, null, false);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_16);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclarationStatement\"), null, null, false);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7efL, \"jetbrains.mps.baseLanguage.structure.LocalVariableDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_23, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"attributes\");\n    quotedNode_31 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, \"jetbrains.mps.baseLanguage.collections.structure.SequenceType\"), null, null, false);\n    quotedNode_42 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, \"jetbrains.mps.lang.smodel.structure.SNodeType\"), null, null, false);\n    quotedNode_42.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f968b3caL, 0x1090e46ca51L, \"concept\"), quotedNode_42, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049750\")));\n    quotedNode_31.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x10c260e9444L, 0x10c260ee40eL, \"elementType\"), quotedNode_42);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_31);\n    quotedNode_32 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_43 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_51 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_43.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_51);\n    quotedNode_52 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117d06362dcL, \"jetbrains.mps.baseLanguage.collections.structure.TranslateOperation\"), null, null, false);\n    quotedNode_58 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_65 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_71 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_78 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_82 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_78.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_82);\n    quotedNode_83 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, \"jetbrains.mps.lang.smodel.structure.Model_NodesOperation\"), null, null, false);\n    quotedNode_83.setReference(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), SReference.create(MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x110b8590897L, 0x110b8590898L, \"concept\"), quotedNode_83, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590288(jetbrains.mps.lang.core.structure)\"), facade.createNodeId(\"3364660638048049750\")));\n    quotedNode_78.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_83);\n    quotedNode_71.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_78);\n    quotedNode_65.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_71);\n    quotedNode_58.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_65);\n    quotedNode_66 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_66, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"model\");\n    quotedNode_72 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_66.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_72);\n    quotedNode_58.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_66);\n    quotedNode_52.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_58);\n    quotedNode_43.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_52);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_43);\n    quotedNode_44 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x117e3fd45c4L, \"jetbrains.mps.baseLanguage.collections.structure.WhereOperation\"), null, null, false);\n    quotedNode_53 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_59 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_67 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_73 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11d47dc0e3bL, \"jetbrains.mps.baseLanguage.structure.NPEEqualsExpression\"), null, null, false);\n    quotedNode_79 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_84 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_79.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_84);\n    quotedNode_85 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_85.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_85, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"1341860900488756504\")));\n    quotedNode_79.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_85);\n    quotedNode_73.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11cL, \"leftExpression\"), quotedNode_79);\n    quotedNode_80 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_80, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_4);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_80, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_5);\n    quotedNode_73.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xfbdeb6fecfL, 0xfbdeb7a11bL, \"rightExpression\"), quotedNode_80);\n    quotedNode_67.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_73);\n    quotedNode_59.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_67);\n    quotedNode_53.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_59);\n    quotedNode_60 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_60, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_68 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_60.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_68);\n    quotedNode_53.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_60);\n    quotedNode_44.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_53);\n    quotedNode_32.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_44);\n    quotedNode_23.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c37a7f6eL, 0xf8c37f506eL, \"initializer\"), quotedNode_32);\n    quotedNode_17.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc67c7f0L, 0xf8cc67c7f1L, \"localVariableDeclaration\"), quotedNode_23);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_17);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_24 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_33 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_33);\n    quotedNode_34 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188e700c31L, \"jetbrains.mps.baseLanguage.collections.structure.VisitAllOperation\"), null, null, false);\n    quotedNode_45 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_54 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_61 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_69 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_74 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_69.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_74);\n    quotedNode_75 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x1129a43046bL, \"jetbrains.mps.lang.smodel.structure.Node_ConceptMethodCall\"), null, null, false);\n    quotedNode_75.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_75, facade.createModelReference(\"r:00000000-0000-4000-0000-011c89590282(jetbrains.mps.lang.core.behavior)\"), facade.createNodeId(\"7714691473529670203\")));\n    quotedNode_81 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_81, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_6);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_81, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_7);\n    quotedNode_75.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_81);\n    quotedNode_69.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_75);\n    quotedNode_61.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_69);\n    quotedNode_54.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_61);\n    quotedNode_45.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_54);\n    quotedNode_55 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_55, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"it\");\n    quotedNode_62 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_55.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_62);\n    quotedNode_45.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_55);\n    quotedNode_34.addChild(MetaAdapterFactory.getContainmentLink(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x1188372895aL, 0x11883748452L, \"closure\"), quotedNode_45);\n    quotedNode_24.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_34);\n    quotedNode_18.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_24);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_18);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1ffL, \"body\"), quotedNode_10);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e94L, \"jetbrains.mps.baseLanguage.structure.ParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_11, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"m\");\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, \"jetbrains.mps.baseLanguage.structure.ClassifierType\"), null, null, false);\n    quotedNode_19.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101de48bf9eL, 0x101de490babL, \"classifier\"), quotedNode_19, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.module(MPS.OpenAPI/org.jetbrains.mps.openapi.module@java_stub)\"), facade.createNodeId(\"~SModule\")));\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_19);\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1feL, \"parameter\"), quotedNode_11);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, \"jetbrains.mps.lang.classLike.structure.DependentTypeInstance\"), null, null, false);\n    quotedNode_12.setReference(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), SReference.create(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x340eb2bd2e03d16cL, \"decl\"), quotedNode_12, facade.createModelReference(\"90746344-04fd-4286-97d5-b46ae6a81709/r:52a3d974-bd4f-4651-ba6e-a2de5e336d95(jetbrains.mps.lang.migration/jetbrains.mps.lang.migration.methods)\"), facade.createNodeId(\"5387853834548062862\")));\n    quotedNode_8.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b1fcL, 0xf8cc56b1fdL, \"returnType\"), quotedNode_12);\n    quotedNode_12.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xc7d5b9dda05f4be2L, 0xbc73f2e16994cc67L, 0x340eb2bd2e03d16bL, 0x7e420dcd0899aa0eL, \"point\"), quotedNode_8);\n    quotedNode_29.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_21);\n    quotedNode_33.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_23);\n    quotedNode_39.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_20);\n    quotedNode_47.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_11);\n    quotedNode_51.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_20);\n    quotedNode_74.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_55);\n    quotedNode_76.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_57);\n    quotedNode_82.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_66);\n    quotedNode_84.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_60);\n    return quotedNode_8;\n  }","id":37501,"modified_method":"private static SNode _quotation_createNode_vnzymo_a0h0a0a0a0n0a(Object parameter_1, Object parameter_2, Object parameter_3, Object parameter_4) {\n    PersistenceFacade facade = PersistenceFacade.getInstance();\n    SNode quotedNode_5 = null;\n    SNode quotedNode_6 = null;\n    SNode quotedNode_7 = null;\n    SNode quotedNode_8 = null;\n    SNode quotedNode_9 = null;\n    SNode quotedNode_10 = null;\n    SNode quotedNode_11 = null;\n    SNode quotedNode_12 = null;\n    SNode quotedNode_13 = null;\n    SNode quotedNode_14 = null;\n    SNode quotedNode_15 = null;\n    SNode quotedNode_16 = null;\n    SNode quotedNode_17 = null;\n    SNode quotedNode_18 = null;\n    SNode quotedNode_19 = null;\n    SNode quotedNode_20 = null;\n    SNode quotedNode_21 = null;\n    SNode quotedNode_22 = null;\n    SNode quotedNode_23 = null;\n    quotedNode_5 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, \"jetbrains.mps.baseLanguage.closures.structure.ClosureLiteral\"), null, null, false);\n    quotedNode_6 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x8388864671ce4f1cL, 0x9c53c54016f6ad4fL, 0x118374464e4L, \"jetbrains.mps.baseLanguage.collections.structure.SmartClosureParameterDeclaration\"), null, null, false);\n    SNodeAccessUtil.setProperty(quotedNode_6, MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"), \"node\");\n    quotedNode_8 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x431d52a5d09a4ea9L, \"jetbrains.mps.baseLanguage.structure.UndefinedType\"), null, null, false);\n    quotedNode_6.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x450368d90ce15bc3L, 0x4ed4d318133c80ceL, \"type\"), quotedNode_8);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf02c34L, \"parameter\"), quotedNode_6);\n    quotedNode_7 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, \"jetbrains.mps.baseLanguage.structure.StatementList\"), null, null, false);\n    quotedNode_9 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_11 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e96L, \"jetbrains.mps.baseLanguage.structure.AssignmentExpression\"), null, null, false);\n    quotedNode_13 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_17 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_17);\n    quotedNode_18 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, \"jetbrains.mps.lang.smodel.structure.SPropertyAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_18, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, 0x108f9727bcdL, \"property\"), (SNode) parameter_1);\n    quotedNode_13.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_18);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e97L, \"lValue\"), quotedNode_13);\n    quotedNode_14 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_19 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_19);\n    quotedNode_20 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, \"jetbrains.mps.lang.smodel.structure.SPropertyAccess\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_20, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x108f96cca6fL, 0x108f9727bcdL, \"property\"), (SNode) parameter_2);\n    quotedNode_14.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_20);\n    quotedNode_11.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11b0d00332cL, 0xf8c77f1e99L, \"rValue\"), quotedNode_14);\n    quotedNode_9.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_11);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_9);\n    quotedNode_10 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, \"jetbrains.mps.baseLanguage.structure.ExpressionStatement\"), null, null, false);\n    quotedNode_12 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, \"jetbrains.mps.baseLanguage.structure.DotExpression\"), null, null, false);\n    quotedNode_15 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10aaf6d7435L, \"jetbrains.mps.lang.smodel.structure.SemanticDowncastExpression\"), null, null, false);\n    quotedNode_21 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, \"jetbrains.mps.baseLanguage.structure.VariableReference\"), null, null, false);\n    quotedNode_15.addChild(MetaAdapterFactory.getContainmentLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x10aaf6d7435L, 0x10aaf6f6e81L, \"leftExpression\"), quotedNode_21);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46a4416L, \"operand\"), quotedNode_15);\n    quotedNode_16 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x118154a6332L, \"jetbrains.mps.baseLanguage.structure.InstanceMethodCallOperation\"), null, null, false);\n    quotedNode_16.setReference(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), jetbrains.mps.smodel.SReference.create(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301adL, \"baseMethodDeclaration\"), quotedNode_16, facade.createModelReference(\"8865b7a8-5271-43d3-884c-6fd1d9cfdd34/f:java_stub#8865b7a8-5271-43d3-884c-6fd1d9cfdd34#org.jetbrains.mps.openapi.model(MPS.OpenAPI/org.jetbrains.mps.openapi.model@java_stub)\"), facade.createNodeId(\"~SNode.setProperty(org.jetbrains.mps.openapi.language.SProperty,java.lang.String):void\")));\n    quotedNode_22 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, \"jetbrains.mps.lang.smodel.structure.PropertyIdRefExpression\"), null, null, false);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_22, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa1L, \"conceptDeclaration\"), (SNode) parameter_3);\n    SNodeAccessUtil.setReferenceTarget(quotedNode_22, MetaAdapterFactory.getReferenceLink(0x7866978ea0f04cc7L, 0x81bc4d213d9375e1L, 0x24b2bf7ce1a42fa0L, 0x24b2bf7ce1a42fa2L, \"propertyDeclaration\"), (SNode) parameter_4);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_22);\n    quotedNode_23 = SModelUtil_new.instantiateConceptDeclaration(MetaAdapterFactory.getConcept(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf940cd6167L, \"jetbrains.mps.baseLanguage.structure.NullLiteral\"), null, null, false);\n    quotedNode_16.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x11857355952L, 0xf8c78301aeL, \"actualArgument\"), quotedNode_23);\n    quotedNode_12.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x116b46a08c4L, 0x116b46b36c4L, \"operation\"), quotedNode_16);\n    quotedNode_10.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b213L, 0xf8cc56b214L, \"expression\"), quotedNode_12);\n    quotedNode_7.addChild(MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8cc56b200L, 0xf8cc6bf961L, \"statement\"), quotedNode_10);\n    quotedNode_5.addChild(MetaAdapterFactory.getContainmentLink(0xfd3920347849419dL, 0x907112563d152375L, 0x1174bed3125L, 0x1174bf0522fL, \"body\"), quotedNode_7);\n    quotedNode_17.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    quotedNode_19.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    quotedNode_21.setReferenceTarget(MetaAdapterFactory.getReferenceLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0xf8c77f1e98L, 0xf8cc6bf960L, \"variableDeclaration\"), quotedNode_6);\n    return quotedNode_5;\n  }","commit_id":"0c90630f6c95fc66b2c0c3fc7ed9d51e64910777","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SModelReference targetModelReference;\n      List<SModelReference> myModels;\n      myModels = ListSequence.fromList(((List<SModel>) (SModelRepository.getInstance().getModelDescriptors()))).select(new ISelector<SModel, SModelReference>() {\n        public SModelReference select(SModel it) {\n          return it.getReference();\n        }\n      }).where(new IWhereFilter<SModelReference>() {\n        public boolean accept(SModelReference it) {\n          return Language.getModelAspect(SModelRepository.getInstance().getModelDescriptor(it)) == LanguageAspect.STRUCTURE;\n        }\n      }).toListSequence();\n      targetModelReference = SModelReferenceDialog.getSelectedModel(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getProject(), myModels);\n      if (targetModelReference == null) {\n        return;\n      }\n\n\n\n      final SRepository repository = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository();\n      ModelAccess modelAccess = repository.getModelAccess();\n\n      final Wrappers._T<SModel> targetModel = new Wrappers._T<SModel>();\n      repository.getModelAccess().runReadInEDT(new Runnable() {\n        public void run() {\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"concept\")), repository))) {\n            return;\n          }\n          targetModel.value = targetModelReference.resolve(repository);\n          if (targetModel.value == null) {\n            return;\n          }\n        }\n      });\n\n\n\n\n\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          SNode newConcept = SNodeOperations.copyNode(((SNode) MapSequence.fromMap(_params).get(\"concept\")));\n          SModelOperations.addRootNode(targetModel.value, newConcept);\n\n          AttributeOperations.setAttribute(((SNode) MapSequence.fromMap(_params).get(\"concept\")), new IAttributeDescriptor.NodeAttribute(MetaAdapterFactory.getConcept(0xc72da2b97cce4447L, 0x8389f407dc1158b7L, 0x11d0a70ae54L, \"jetbrains.mps.lang.structure.structure.DeprecatedNodeAnnotation\")), createDeprecatedNodeAnnotation_mqohi3_a0d0a0a91a0(\"The concept was moved to language \\\"\" + targetModel.value.getModule().getModuleName() + \"\\\"\"));\n\n\n          MigrationScriptBuilder builder = MigrationScriptBuilder.createMigrationScript(Language.getLanguageFor(SNodeOperations.getModel(((SNode) MapSequence.fromMap(_params).get(\"concept\")))));\n          SNode moveOwnMembersMethod = MoveConcept_Action.this.moveOwnMembers(((SNode) MapSequence.fromMap(_params).get(\"concept\")), newConcept, _params);\n          builder.setName(\"Move_concept_\" + SPropertyOperations.getString(((SNode) MapSequence.fromMap(_params).get(\"concept\")), MetaAdapterFactory.getProperty(0xceab519525ea4f22L, 0x9b92103b95ca8c0cL, 0x110396eaaa4L, 0x110396ec041L, \"name\"))).appendExecuteStatements(MoveConcept_Action.this.replaceExactInstances(((SNode) MapSequence.fromMap(_params).get(\"concept\")), newConcept, moveOwnMembersMethod, _params));\n          if (moveOwnMembersMethod != null) {\n            ListSequence.fromList(SLinkOperations.getChildren(builder.getScript(), MetaAdapterFactory.getContainmentLink(0xf3061a5392264cc5L, 0xa443f952ceaf5816L, 0x101d9d3ca30L, 0x4a9a46de59132803L, \"member\"))).addElement(moveOwnMembersMethod);\n          }\n          builder.addMissingImports();\n        }\n      });\n\n\n\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MoveConcept\", t);\n      }\n    }\n  }","id":37502,"modified_method":"public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    try {\n      final SModelReference targetModelReference;\n      List<SModelReference> myModels;\n      myModels = ListSequence.fromList(((List<SModel>) (SModelRepository.getInstance().getModelDescriptors()))).select(new ISelector<SModel, SModelReference>() {\n        public SModelReference select(SModel it) {\n          return it.getReference();\n        }\n      }).where(new IWhereFilter<SModelReference>() {\n        public boolean accept(SModelReference it) {\n          return Language.getModelAspect(SModelRepository.getInstance().getModelDescriptor(it)) == LanguageAspect.STRUCTURE;\n        }\n      }).toListSequence();\n      targetModelReference = SModelReferenceDialog.getSelectedModel(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getProject(), myModels);\n      if (targetModelReference == null) {\n        return;\n      }\n\n\n\n      final SRepository repository = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository();\n      ModelAccess modelAccess = repository.getModelAccess();\n\n      final Wrappers._T<SModel> targetModel = new Wrappers._T<SModel>();\n      repository.getModelAccess().runReadInEDT(new Runnable() {\n        public void run() {\n          if (!(SNodeUtil.isAccessible(((SNode) MapSequence.fromMap(_params).get(\"concept\")), repository))) {\n            return;\n          }\n          targetModel.value = targetModelReference.resolve(repository);\n          if (targetModel.value == null) {\n            return;\n          }\n        }\n      });\n\n      modelAccess.executeCommandInEDT(new Runnable() {\n        public void run() {\n          MoveConceptUtil.moveConcept(((SNode) MapSequence.fromMap(_params).get(\"concept\")), targetModel.value);\n        }\n      });\n    } catch (Throwable t) {\n      if (LOG.isEnabledFor(Level.ERROR)) {\n        LOG.error(\"User's action execute method failed. Action:\" + \"MoveConcept\", t);\n      }\n    }\n  }","commit_id":"219ecf741d617fcb12efa6837d05f0f76f38f115","url":"https://github.com/JetBrains/MPS"},{"original_method":"@NotNull\n  public String createVirtualEnv(@NotNull String destinationDir, boolean useGlobalSite) throws PyExternalProcessException {\n    final List<String> args = new ArrayList<String>();\n    final boolean usePyVenv = PythonSdkType.getLanguageLevelForSdk(mySdk).isAtLeast(LanguageLevel.PYTHON33);\n    if (usePyVenv) {\n      args.add(\"pyvenv\");\n      if (useGlobalSite) {\n        args.add(\"--system-site-packages\");\n      }\n      args.add(destinationDir);\n      getHelperResult(PACKAGING_TOOL, args, false, null);\n    }\n    else {\n      if (useGlobalSite) {\n        args.add(\"--system-site-packages\");\n      }\n      args.add(destinationDir);\n      getHelperResult(VIRTUALENV, args, false, null);\n    }\n\n    final String binary = PythonSdkType.getPythonExecutable(destinationDir);\n    final String binaryFallback = destinationDir + File.separator + \"bin\" + File.separator + \"python\";\n    final String path = (binary != null) ? binary : binaryFallback;\n\n    if (usePyVenv) {\n      // Still no 'packaging' and 'pysetup3' for Python 3.3rc1, see PEP 405\n      final VirtualFile binaryFile = LocalFileSystem.getInstance().refreshAndFindFileByPath(path);\n      if (binaryFile != null) {\n        final ProjectJdkImpl tmpSdk = new ProjectJdkImpl(\"\", PythonSdkType.getInstance());\n        tmpSdk.setHomePath(path);\n        final PyPackageManager manager = PyPackageManager.getInstance(tmpSdk);\n        manager.installManagement();\n      }\n    }\n    return path;\n  }","id":37503,"modified_method":"@NotNull\n  public String createVirtualEnv(@NotNull String destinationDir, boolean useGlobalSite) throws PyExternalProcessException {\n    final List<String> args = new ArrayList<String>();\n    final LanguageLevel languageLevel = PythonSdkType.getLanguageLevelForSdk(mySdk);\n    final boolean usePyVenv = languageLevel.isAtLeast(LanguageLevel.PYTHON33);\n    if (usePyVenv) {\n      args.add(\"pyvenv\");\n      if (useGlobalSite) {\n        args.add(\"--system-site-packages\");\n      }\n      args.add(destinationDir);\n      getHelperResult(PACKAGING_TOOL, args, false, null);\n    }\n    else {\n      if (useGlobalSite) {\n        args.add(\"--system-site-packages\");\n      }\n      args.add(destinationDir);\n      final boolean pre26 = languageLevel.isOlderThan(LanguageLevel.PYTHON26);\n      final String name = \"virtualenv-\" + (pre26 ? VIRTUALENV_PRE_26_VERSION : VIRTUALENV_VERSION);\n      final String dirName = extractHelper(name + \".tar.gz\");\n      try {\n        final String fileName = dirName + name + File.separatorChar + \"virtualenv.py\";\n        getPythonProcessResult(fileName, Collections.singletonList(destinationDir), false, dirName + name);\n      }\n      finally {\n        FileUtil.delete(new File(dirName));\n      }\n    }\n\n    final String binary = PythonSdkType.getPythonExecutable(destinationDir);\n    final String binaryFallback = destinationDir + File.separator + \"bin\" + File.separator + \"python\";\n    final String path = (binary != null) ? binary : binaryFallback;\n\n    if (usePyVenv) {\n      // Still no 'packaging' and 'pysetup3' for Python 3.3rc1, see PEP 405\n      final VirtualFile binaryFile = LocalFileSystem.getInstance().refreshAndFindFileByPath(path);\n      if (binaryFile != null) {\n        final ProjectJdkImpl tmpSdk = new ProjectJdkImpl(\"\", PythonSdkType.getInstance());\n        tmpSdk.setHomePath(path);\n        final PyPackageManager manager = PyPackageManager.getInstance(tmpSdk);\n        manager.installManagement();\n      }\n    }\n    return path;\n  }","commit_id":"51a1a11cd5efd6d4e6e634bb30d5dd5c0ed4e11d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  protected ProcessOutput getPythonProcessOutput(@NotNull String helperPath, @NotNull List<String> args, boolean askForSudo,\n                                                 @Nullable String workingDir) throws PyExternalProcessException {\n    final String homePath = mySdk.getHomePath();\n    if (homePath == null) {\n      throw new PyExternalProcessException(ERROR_INVALID_SDK, helperPath, args, \"Cannot find interpreter for SDK\");\n    }\n    if (workingDir == null) {\n      workingDir = new File(homePath).getParent();\n    }\n    final List<String> cmdline = new ArrayList<String>();\n    cmdline.add(homePath);\n    cmdline.add(helperPath);\n    cmdline.addAll(args);\n    LOG.info(\"Running packaging tool: \" + StringUtil.join(cmdline, \" \"));\n\n    final boolean canCreate = FileUtil.ensureCanCreateFile(new File(homePath));\n    final boolean useSudo = !canCreate && !SystemInfo.isWindows && askForSudo;\n\n    try {\n      final Process process;\n      final Map<String, String> environment = PySdkUtil.mergeEnvVariables(System.getenv(), ImmutableMap.of(\"PYTHONUNBUFFERED\", \"1\"));\n      if (useSudo) {\n        process = ExecUtil.sudo(cmdline, \"Please enter your password to make changes in system packages: \", workingDir, environment);\n      }\n      else {\n        process = ExecUtil.exec(cmdline, workingDir, environment);\n      }\n      final CapturingProcessHandler handler = new CapturingProcessHandler(process);\n      // Make the progress indicator an explicit parameter?\n      final ProgressIndicator indicator = ProgressManager.getInstance().getProgressIndicator();\n      final ProcessOutput result;\n      if (indicator != null) {\n        handler.addProcessListener(new ProcessAdapter() {\n          @Override\n          public void onTextAvailable(ProcessEvent event, Key outputType) {\n            if (outputType == ProcessOutputTypes.STDOUT || outputType == ProcessOutputTypes.STDERR) {\n              for (String line : StringUtil.splitByLines(event.getText())) {\n                final String trimmed = line.trim();\n                if (isMeaningfulOutput(trimmed)) {\n                  indicator.setText2(trimmed);\n                }\n              }\n            }\n          }\n\n          private boolean isMeaningfulOutput(@NotNull String trimmed) {\n            return trimmed.length() > 3;\n          }\n        });\n        result = handler.runProcessWithProgressIndicator(indicator);\n      }\n      else {\n        result = handler.runProcess(TIMEOUT);\n      }\n      if (result.isCancelled()) {\n        throw new PyProcessCancelledException(helperPath, args);\n      }\n      String message = result.getStderr();\n      if (result.getExitCode() != 0) {\n        final String stdout = result.getStdout();\n        if (StringUtil.isEmptyOrSpaces(message)) {\n          message = stdout;\n        }\n        if (StringUtil.isEmptyOrSpaces(message)) {\n          message = \"Failed to perform action. Permission denied.\";\n        }\n        throw new PyExternalProcessException(result.getExitCode(), helperPath, args, message);\n      }\n      if (SystemInfo.isMac && !StringUtil.isEmptyOrSpaces(message)) {\n        throw new PyExternalProcessException(result.getExitCode(), helperPath, args, message);\n      }\n      return result;\n    }\n    catch (PyProcessCancelledException e) {\n      throw e;\n    }\n    catch (ExecutionException e) {\n      throw new PyExternalProcessException(ERROR_EXECUTION, helperPath, args, e.getMessage());\n    }\n    catch (IOException e) {\n      throw new PyExternalProcessException(ERROR_ACCESS_DENIED, helperPath, args, e.getMessage());\n    }\n  }","id":37504,"modified_method":"@NotNull\n  protected ProcessOutput getPythonProcessOutput(@NotNull String helperPath, @NotNull List<String> args, boolean askForSudo,\n                                                 @Nullable String workingDir) throws PyExternalProcessException {\n    final String homePath = mySdk.getHomePath();\n    if (homePath == null) {\n      throw new PyExternalProcessException(ERROR_INVALID_SDK, helperPath, args, \"Cannot find interpreter for SDK\");\n    }\n    if (workingDir == null) {\n      workingDir = new File(homePath).getParent();\n    }\n    final List<String> cmdline = new ArrayList<String>();\n    cmdline.add(homePath);\n    cmdline.add(helperPath);\n    cmdline.addAll(args);\n    LOG.info(\"Running packaging tool: \" + StringUtil.join(cmdline, \" \"));\n\n    final boolean canCreate = FileUtil.ensureCanCreateFile(new File(homePath));\n    final boolean useSudo = !canCreate && !SystemInfo.isWindows && askForSudo;\n\n    try {\n      final Process process;\n      final Map<String, String> environment = PySdkUtil.mergeEnvVariables(System.getenv(), ImmutableMap.of(\"PYTHONUNBUFFERED\", \"1\"));\n      if (useSudo) {\n        process = ExecUtil.sudo(cmdline, \"Please enter your password to make changes in system packages: \", workingDir, environment);\n      }\n      else {\n        process = ExecUtil.exec(cmdline, workingDir, environment);\n      }\n      final CapturingProcessHandler handler = new CapturingProcessHandler(process);\n      final ProgressIndicator indicator = ProgressManager.getInstance().getProgressIndicator();\n      final ProcessOutput result;\n      if (indicator != null) {\n        handler.addProcessListener(new ProcessAdapter() {\n          @Override\n          public void onTextAvailable(ProcessEvent event, Key outputType) {\n            if (outputType == ProcessOutputTypes.STDOUT || outputType == ProcessOutputTypes.STDERR) {\n              for (String line : StringUtil.splitByLines(event.getText())) {\n                final String trimmed = line.trim();\n                if (isMeaningfulOutput(trimmed)) {\n                  indicator.setText2(trimmed);\n                }\n              }\n            }\n          }\n\n          private boolean isMeaningfulOutput(@NotNull String trimmed) {\n            return trimmed.length() > 3;\n          }\n        });\n        result = handler.runProcessWithProgressIndicator(indicator);\n      }\n      else {\n        result = handler.runProcess(TIMEOUT);\n      }\n      if (result.isCancelled()) {\n        throw new PyProcessCancelledException(helperPath, args);\n      }\n      String message = result.getStderr();\n      if (result.getExitCode() != 0) {\n        final String stdout = result.getStdout();\n        if (StringUtil.isEmptyOrSpaces(message)) {\n          message = stdout;\n        }\n        if (StringUtil.isEmptyOrSpaces(message)) {\n          message = \"Failed to perform action. Permission denied.\";\n        }\n        throw new PyExternalProcessException(result.getExitCode(), helperPath, args, message);\n      }\n      return result;\n    }\n    catch (PyProcessCancelledException e) {\n      throw e;\n    }\n    catch (ExecutionException e) {\n      throw new PyExternalProcessException(ERROR_EXECUTION, helperPath, args, e.getMessage());\n    }\n    catch (IOException e) {\n      throw new PyExternalProcessException(ERROR_ACCESS_DENIED, helperPath, args, e.getMessage());\n    }\n  }","commit_id":"51a1a11cd5efd6d4e6e634bb30d5dd5c0ed4e11d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void invoke(@NotNull Project project, Editor editor, PsiFile file) throws IncorrectOperationException {\n    PsiElement element = PsiTreeUtil.getParentOfType(file.findElementAt(editor.getCaretModel().getOffset()), PyBinaryExpression.class, false);\n    while (element.getParent() instanceof PyBinaryExpression) {\n      element = element.getParent();\n    }\n    final LanguageLevel languageLevel = LanguageLevel.forElement(element);\n\n    NotNullFunction<String,String> escaper = StringUtil.escaper(false, \"\\\"\\'\\\\\");\n    StringBuilder stringLiteral = new StringBuilder();\n    List<String> parameters = new ArrayList<String>();\n    Pair<String, String> quotes = new Pair<String, String>(\"\\\"\", \"\\\"\");\n    boolean quotesDetected = false;\n    int paramCount = 0;\n    for (PyExpression expression : getSimpleExpressions((PyBinaryExpression) element)) {\n      if (expression instanceof PyStringLiteralExpression) {\n        if (!quotesDetected) {\n          quotes = PythonStringUtil.getQuotes(expression.getText());\n          quotesDetected = true;\n        }\n        stringLiteral.append(escaper.fun(((PyStringLiteralExpression)expression).getStringValue()));\n      } else {\n        addParamToString(stringLiteral, paramCount, languageLevel);\n        parameters.add(expression.getText());\n        ++paramCount;\n      }\n    }\n    if (quotes == null)\n      quotes = new Pair<String, String>(\"\\\"\", \"\\\"\");\n    stringLiteral.insert(0, quotes.getFirst());\n    stringLiteral.append(quotes.getSecond());\n\n    PyElementGenerator elementGenerator = PyElementGenerator.getInstance(project);\n\n    if (!parameters.isEmpty()) {\n      if (LanguageLevel.forElement(element).isAtLeast(LanguageLevel.PYTHON27)) {\n        stringLiteral.append(\".format(\").append(StringUtil.join(parameters, \",\")).append(\")\");\n\n      }\n      else {\n        final String paramString = parameters.size() > 1? \"(\" + StringUtil.join(parameters, \",\") +\")\"\n                                                       : StringUtil.join(parameters, \",\");\n        stringLiteral.append(\" % \").append(paramString);\n      }\n      final PyExpression expression = elementGenerator.createFromText(LanguageLevel.getDefault(),\n                                                                PyExpressionStatement.class, stringLiteral.toString()).getExpression();\n      element.replace(expression);\n    }\n    else {\n      PyStringLiteralExpression stringLiteralExpression =\n        elementGenerator.createStringLiteralAlreadyEscaped(stringLiteral.toString());\n      element.replace(stringLiteralExpression);\n    }\n  }","id":37505,"modified_method":"public void invoke(@NotNull Project project, Editor editor, PsiFile file) throws IncorrectOperationException {\n    PsiElement element = PsiTreeUtil.getParentOfType(file.findElementAt(editor.getCaretModel().getOffset()), PyBinaryExpression.class, false);\n    while (element.getParent() instanceof PyBinaryExpression) {\n      element = element.getParent();\n    }\n    final LanguageLevel languageLevel = LanguageLevel.forElement(element);\n    final boolean useFormatMethod = languageLevel.isAtLeast(LanguageLevel.PYTHON27);\n\n    NotNullFunction<String,String> escaper = StringUtil.escaper(false, \"\\\"\\'\\\\\");\n    StringBuilder stringLiteral = new StringBuilder();\n    List<String> parameters = new ArrayList<String>();\n    Pair<String, String> quotes = new Pair<String, String>(\"\\\"\", \"\\\"\");\n    boolean quotesDetected = false;\n    int paramCount = 0;\n    for (PyExpression expression : getSimpleExpressions((PyBinaryExpression) element)) {\n      if (expression instanceof PyStringLiteralExpression) {\n        if (!quotesDetected) {\n          quotes = PythonStringUtil.getQuotes(expression.getText());\n          quotesDetected = true;\n        }\n        String value = ((PyStringLiteralExpression)expression).getStringValue();\n        if (!useFormatMethod) {\n          value = value.replace(\"%\", \"%%\");\n        }\n        stringLiteral.append(escaper.fun(value));\n      } else {\n        addParamToString(stringLiteral, paramCount, languageLevel);\n        parameters.add(expression.getText());\n        ++paramCount;\n      }\n    }\n    if (quotes == null)\n      quotes = new Pair<String, String>(\"\\\"\", \"\\\"\");\n    stringLiteral.insert(0, quotes.getFirst());\n    stringLiteral.append(quotes.getSecond());\n\n    PyElementGenerator elementGenerator = PyElementGenerator.getInstance(project);\n\n    if (!parameters.isEmpty()) {\n      if (useFormatMethod) {\n        stringLiteral.append(\".format(\").append(StringUtil.join(parameters, \",\")).append(\")\");\n\n      }\n      else {\n        final String paramString = parameters.size() > 1? \"(\" + StringUtil.join(parameters, \",\") +\")\"\n                                                       : StringUtil.join(parameters, \",\");\n        stringLiteral.append(\" % \").append(paramString);\n      }\n      final PyExpression expression = elementGenerator.createFromText(LanguageLevel.getDefault(),\n                                                                PyExpressionStatement.class, stringLiteral.toString()).getExpression();\n      element.replace(expression);\n    }\n    else {\n      PyStringLiteralExpression stringLiteralExpression =\n        elementGenerator.createStringLiteralAlreadyEscaped(stringLiteral.toString());\n      element.replace(stringLiteralExpression);\n    }\n  }","commit_id":"62b23ed17b9f774790b793fd6f703319ceb7c2b4","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override public void visitClass(PsiClass aClass) {\n      // Don't go into classes (anonymous, locals).\n      if (!aClass.hasModifierProperty(PsiModifier.ABSTRACT)) {\n        final Module module = ModuleUtilCore.findModuleForPsiElement(aClass);\n        final LanguageLevel effectiveLanguageLevel = module != null ? getEffectiveLanguageLevel(module) : null;\n        if (effectiveLanguageLevel != null &&\n            !effectiveLanguageLevel.isAtLeast(LanguageLevel.JDK_1_8) &&\n            JavaVersionService.getInstance().getJavaSdkVersion(aClass).isAtLeast(JavaSdkVersion.JDK_1_8)) {\n          final List<PsiMethod> methods = new ArrayList<PsiMethod>();\n          for (HierarchicalMethodSignature methodSignature : aClass.getVisibleSignatures()) {\n            final PsiMethod method = methodSignature.getMethod();\n            if (ourDefaultMethods.contains(getSignature(method))) {\n              methods.add(method);\n            }\n          }\n\n          if (!methods.isEmpty()) {\n            PsiElement element2Highlight = aClass.getNameIdentifier();\n            if (element2Highlight == null) {\n              element2Highlight = aClass;\n            }\n            myHolder.registerProblem(element2Highlight,\n                                     methods.size() == 1 ? InspectionsBundle.message(\"inspection.1.8.problem.single.descriptor\", methods.get(0).getName(), getJdkName(effectiveLanguageLevel)) \n                                                         : InspectionsBundle.message(\"inspection.1.8.problem.descriptor\", methods.size(), getJdkName(effectiveLanguageLevel)),\n                                     QuickFixFactory.getInstance().createImplementMethodsFix(aClass));\n          }\n        }\n      }\n    }","id":37506,"modified_method":"@Override public void visitClass(PsiClass aClass) {\n      // Don't go into classes (anonymous, locals).\n      if (!aClass.hasModifierProperty(PsiModifier.ABSTRACT)) {\n        final Module module = ModuleUtilCore.findModuleForPsiElement(aClass);\n        final LanguageLevel effectiveLanguageLevel = module != null ? getEffectiveLanguageLevel(module) : null;\n        if (effectiveLanguageLevel != null && !effectiveLanguageLevel.isAtLeast(LanguageLevel.JDK_1_8)) {\n          final JavaSdkVersion version = JavaVersionService.getInstance().getJavaSdkVersion(aClass);\n          if (version != null && version.isAtLeast(JavaSdkVersion.JDK_1_8)) {\n            final List<PsiMethod> methods = new ArrayList<PsiMethod>();\n            for (HierarchicalMethodSignature methodSignature : aClass.getVisibleSignatures()) {\n              final PsiMethod method = methodSignature.getMethod();\n              if (ourDefaultMethods.contains(getSignature(method))) {\n                methods.add(method);\n              }\n            }\n  \n            if (!methods.isEmpty()) {\n              PsiElement element2Highlight = aClass.getNameIdentifier();\n              if (element2Highlight == null) {\n                element2Highlight = aClass;\n              }\n              myHolder.registerProblem(element2Highlight,\n                                       methods.size() == 1 ? InspectionsBundle.message(\"inspection.1.8.problem.single.descriptor\", methods.get(0).getName(), getJdkName(effectiveLanguageLevel)) \n                                                           : InspectionsBundle.message(\"inspection.1.8.problem.descriptor\", methods.size(), getJdkName(effectiveLanguageLevel)),\n                                       QuickFixFactory.getInstance().createImplementMethodsFix(aClass));\n            }\n          }\n        }\n      }\n    }","commit_id":"99d0a6edd45b2f992753e8f9e9a62b76e8bdad9d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    protected Properties getStartUpProperties()\n    {\n        Properties props = new Properties();\n        //Inject endpoint names into the config\n        props.put(INBOUND_ENDPOINT_KEY, getJmsConfig().getInboundEndpoint());\n        props.put(OUTBOUND_ENDPOINT_KEY, getJmsConfig().getOutboundEndpoint());\n        props.put(MIDDLE_ENDPOINT_KEY, getJmsConfig().getMiddleEndpoint());\n        props.put(\"protocol\", getJmsConfig().getProtocol());\n\n        Map p = getJmsConfig().getProperties();\n        if (p != null)\n        {\n            props.putAll(p);\n        }\n        return props;\n    }","id":37507,"modified_method":"@Override\n    protected Properties getStartUpProperties()\n    {\n        Properties props = new Properties();\n        //Inject endpoint names into the config\n        props.put(INBOUND_ENDPOINT_KEY, getJmsConfig().getInboundEndpoint());\n        props.put(OUTBOUND_ENDPOINT_KEY, getJmsConfig().getOutboundEndpoint());\n        props.put(MIDDLE_ENDPOINT_KEY, getJmsConfig().getMiddleEndpoint());\n        props.put(MIDDLE2_ENDPOINT_KEY, getJmsConfig().getMiddleEndpoint() + \"2\");\n\n        props.put(BROADCAST_TOPIC_ENDPOINT_KEY, getJmsConfig().getTopicBroadcastEndpoint());\n        props.put(\"protocol\", getJmsConfig().getProtocol());\n\n        Map p = getJmsConfig().getProperties();\n        if (p != null)\n        {\n            props.putAll(p);\n        }\n        return props;\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"protected ConnectionFactory getConnectionFactory(boolean topic, boolean xa) throws Exception\n    {\n        checkConfig();\n        return getJmsConfig().getConnectionFactory(topic, xa);\n    }","id":37508,"modified_method":"protected Connection getConnection(boolean topic, boolean xa) throws Exception\n    {\n        checkConfig();\n        return getJmsConfig().getConnection(topic, xa);\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public Message receive(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            ConnectionFactory factory = getConnectionFactory(false, false);\n            connection = factory.createConnection();\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Destination destination = createOutputDestination(session, scenario);\n                MessageConsumer consumer = null;\n                try\n                {\n                    consumer = session.createConsumer(destination);\n                    return scenario.receive(session, consumer);\n                }\n                finally\n                {\n                    if (consumer != null)\n                    {\n                        consumer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","id":37509,"modified_method":"public Message receive(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            connection = getConnection(false, false);\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Destination destination = createOutputDestination(session, scenario);\n                MessageConsumer consumer = null;\n                try\n                {\n                    consumer = session.createConsumer(destination);\n                    return scenario.receive(session, consumer);\n                }\n                finally\n                {\n                    if (consumer != null)\n                    {\n                        consumer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public void send(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            connection = getConnectionFactory(false, false).createConnection();\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Destination destination = createInputDestination(session, scenario);\n                MessageProducer producer = null;\n                try\n                {\n                    producer = session.createProducer(destination);\n                    if (scenario.isPersistent())\n                    {\n                        producer.setDeliveryMode(DeliveryMode.PERSISTENT);\n                    }\n                    scenario.send(session, producer);\n                }\n                finally\n                {\n                    if (producer != null)\n                    {\n                        producer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","id":37510,"modified_method":"public void send(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            connection = getConnection(false, false);\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Destination destination = createInputDestination(session, scenario);\n                MessageProducer producer = null;\n                try\n                {\n                    producer = session.createProducer(destination);\n                    if (scenario.isPersistent())\n                    {\n                        producer.setDeliveryMode(DeliveryMode.PERSISTENT);\n                    }\n                    scenario.send(session, producer);\n                }\n                finally\n                {\n                    if (producer != null)\n                    {\n                        producer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public ConnectionFactory getConnectionFactory(boolean topic, boolean xa)\n    {\n        if (xa)\n        {\n            return new ActiveMQXAConnectionFactory(DEFAULT_BROKER_URL);\n\n        }\n        else\n        {\n            return new ActiveMQConnectionFactory(DEFAULT_BROKER_URL);\n        }\n    }","id":37511,"modified_method":"public Connection getConnection(boolean topic, boolean xa) throws Exception\n    {\n        if (xa)\n        {\n            return new ActiveMQXAConnectionFactory(DEFAULT_BROKER_URL).createConnection();\n\n        }\n        else\n        {\n            return new ActiveMQConnectionFactory(DEFAULT_BROKER_URL).createConnection();\n        }\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public void testQueueFromJndi() throws Exception\n    {\n        MuleClient client = new MuleClient();\n\n        client.dispatch(\"jms://in2?connector=jmsConnector2\", DEFAULT_INPUT_MESSAGE, null);\n        \n        MuleMessage result = client.request(\"vm://out\", RECEIVE_TIMEOUT);\n        assertNotNull(result);\n        assertEquals(DEFAULT_INPUT_MESSAGE, result.getPayloadAsString());\n    }","id":37512,"modified_method":"public void testQueueFromJndi() throws Exception\n    {\n        MuleClient client = new MuleClient();\n\n        client.dispatch(\"jms://jndi-queue-in?connector=jmsConnector2\", DEFAULT_INPUT_MESSAGE, null);\n        \n        MuleMessage result = client.request(\"vm://out\", RECEIVE_TIMEOUT);\n        assertNotNull(result);\n        assertEquals(DEFAULT_INPUT_MESSAGE, result.getPayloadAsString());\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public void testTopicFromJndi() throws Exception\n    {\n        MuleClient client = new MuleClient();\n        \n        client.dispatch(\"jms://topic:some/long/path/in3?connector=jmsConnector2\", DEFAULT_INPUT_MESSAGE, null);\n        \n        MuleMessage result = client.request(\"vm://out\", RECEIVE_TIMEOUT);\n        assertNotNull(result);\n        assertEquals(DEFAULT_INPUT_MESSAGE, result.getPayloadAsString());\n    }","id":37513,"modified_method":"public void testTopicFromJndi() throws Exception\n    {\n        MuleClient client = new MuleClient();\n        \n        client.dispatch(\"jms://topic:jndi-topic-in?connector=jmsConnector2\", DEFAULT_INPUT_MESSAGE, null);\n        \n        MuleMessage result = client.request(\"vm://out\", RECEIVE_TIMEOUT);\n        assertNotNull(result);\n        assertEquals(DEFAULT_INPUT_MESSAGE, result.getPayloadAsString());\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public Message receive(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            ConnectionFactory factory = getConnectionFactory(true, false);\n            connection = factory.createConnection();\n            connection.setClientID(getClientId());\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Topic destination = session.createTopic(scenario.getOutputDestinationName());\n                MessageConsumer consumer = null;\n                try\n                {\n                    consumer = session.createDurableSubscriber(destination, getClientId());\n                    return scenario.receive(session, consumer);\n                }\n                finally\n                {\n                    if (consumer != null)\n                    {\n                        consumer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","id":37514,"modified_method":"public Message receive(Scenario scenario) throws Exception\n    {\n        Connection connection = null;\n        try\n        {\n            connection = getConnection(true, false);\n            connection.setClientID(getClientId());\n            connection.start();\n            Session session = null;\n            try\n            {\n                session = connection.createSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Topic destination = session.createTopic(scenario.getOutputDestinationName());\n                MessageConsumer consumer = null;\n                try\n                {\n                    consumer = session.createDurableSubscriber(destination, getClientId());\n                    return scenario.receive(session, consumer);\n                }\n                finally\n                {\n                    if (consumer != null)\n                    {\n                        consumer.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"public void send(Scenario scenario) throws Exception\n    {\n        TopicConnection connection = null;\n        try\n        {\n            TopicConnectionFactory factory = (TopicConnectionFactory)getConnectionFactory(true, false);\n            connection = factory.createTopicConnection();\n            connection.start();\n            TopicSession session = null;\n            try\n            {\n                session = connection.createTopicSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Topic destination = session.createTopic(scenario.getInputDestinationName());\n                TopicPublisher publisher = null;\n                try\n                {\n                    publisher = session.createPublisher(destination);\n                    publisher.setDeliveryMode(DeliveryMode.PERSISTENT);\n                    scenario.send(session, publisher);\n                }\n                finally\n                {\n                    if (publisher != null)\n                    {\n                        publisher.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","id":37515,"modified_method":"public void send(Scenario scenario) throws Exception\n    {\n        TopicConnection connection = null;\n        try\n        {\n            connection = (TopicConnection)getConnection(true, false);\n            connection.start();\n            TopicSession session = null;\n            try\n            {\n                session = connection.createTopicSession(scenario.isTransacted(), scenario.getAcknowledge());\n                Topic destination = session.createTopic(scenario.getInputDestinationName());\n                TopicPublisher publisher = null;\n                try\n                {\n                    publisher = session.createPublisher(destination);\n                    publisher.setDeliveryMode(DeliveryMode.PERSISTENT);\n                    scenario.send(session, publisher);\n                }\n                finally\n                {\n                    if (publisher != null)\n                    {\n                        publisher.close();\n                    }\n                }\n            }\n            finally\n            {\n                if (session != null)\n                {\n                    session.close();\n                }\n            }\n        }\n        finally\n        {\n            if (connection != null)\n            {\n                connection.close();\n            }\n        }\n    }","commit_id":"54a9655f3f24346aa28da5d6d89af567b6927496","url":"https://github.com/mulesoft/mule"},{"original_method":"/**\n     * Perform the work to process the fileExchange\n     *\n     * @param exchange fileExchange\n     * @throws Exception is thrown if some error\n     */\n    protected void processExchange(Exchange exchange) throws Exception {\n        if (log.isTraceEnabled()) {\n            log.trace(\"Processing \" + exchange);\n        }\n\n        try {\n            String target = createFileName(exchange);\n\n            preWriteCheck();\n\n            // should we write to a temporary name and then afterwards rename to real target\n            boolean writeAsTempAndRename = ObjectHelper.isNotEmpty(endpoint.getTempPrefix());\n            String tempTarget = null;\n            if (writeAsTempAndRename) {\n                // compute temporary name with the temp prefix\n                tempTarget = createTempFileName(target);\n\n                // cater for file exists option on the real target as\n                // the file operations code will work on the temp file\n\n                // if an existing file already exists what should we do?\n                if (operations.existsFile(target)) {\n                    if (endpoint.getFileExist() == GenericFileExist.Ignore) {\n                        // ignore but indicate that the file was written\n                        if (log.isTraceEnabled()) {\n                            log.trace(\"An existing file already exists: \" + target + \". Ignore and do not override it.\");\n                        }\n                        return;\n                    } else if (endpoint.getFileExist() == GenericFileExist.Fail) {\n                        throw new GenericFileOperationFailedException(\"File already exist: \" + target + \". Cannot write new file.\");\n                    } else if (endpoint.getFileExist() == GenericFileExist.Override) {\n                        // we override the target so we do this by deleting it so the temp file can be renamed later\n                        // with success as the existing target file have been deleted\n                        if (log.isTraceEnabled()) {\n                            log.trace(\"Deleting existing file: \" + tempTarget);\n                        }\n                        operations.deleteFile(target);\n                    }\n                }\n\n                // delete any pre existing temp file\n                if (operations.existsFile(tempTarget)) {\n                    if (log.isTraceEnabled()) {\n                        log.trace(\"Deleting existing temp file: \" + tempTarget);\n                    }\n                    operations.deleteFile(tempTarget);\n                }\n            }\n\n            // write/upload the file\n            writeFile(exchange, tempTarget != null ? tempTarget : target);\n\n            // if we did write to a temporary name then rename it to the real\n            // name after we have written the file\n            if (tempTarget != null) {\n                if (log.isTraceEnabled()) {\n                    log.trace(\"Renaming file: [\" + tempTarget + \"] to: [\" + target + \"]\");\n                }\n                boolean renamed = operations.renameFile(tempTarget, target);\n                if (!renamed) {\n                    throw new GenericFileOperationFailedException(\"Cannot rename file from: \" + tempTarget + \" to: \" + target);\n                }\n            }\n\n            // lets store the name we really used in the header, so end-users\n            // can retrieve it\n            exchange.getIn().setHeader(Exchange.FILE_NAME_PRODUCED, target);\n        } catch (Exception e) {\n            handleFailedWrite(exchange, e);\n        }\n    }","id":37516,"modified_method":"/**\n     * Perform the work to process the fileExchange\n     *\n     * @param exchange fileExchange\n     * @throws Exception is thrown if some error\n     */\n    protected void processExchange(Exchange exchange) throws Exception {\n        if (log.isTraceEnabled()) {\n            log.trace(\"Processing \" + exchange);\n        }\n\n        try {\n            String target = createFileName(exchange);\n\n            preWriteCheck();\n\n            // should we write to a temporary name and then afterwards rename to real target\n            boolean writeAsTempAndRename = ObjectHelper.isNotEmpty(endpoint.getTempPrefix());\n            String tempTarget = null;\n            if (writeAsTempAndRename) {\n                // compute temporary name with the temp prefix\n                tempTarget = createTempFileName(target);\n\n                // cater for file exists option on the real target as\n                // the file operations code will work on the temp file\n\n                // if an existing file already exists what should we do?\n                if (operations.existsFile(target)) {\n                    if (endpoint.getFileExist() == GenericFileExist.Ignore) {\n                        // ignore but indicate that the file was written\n                        if (log.isTraceEnabled()) {\n                            log.trace(\"An existing file already exists: \" + target + \". Ignore and do not override it.\");\n                        }\n                        return;\n                    } else if (endpoint.getFileExist() == GenericFileExist.Fail) {\n                        throw new GenericFileOperationFailedException(\"File already exist: \" + target + \". Cannot write new file.\");\n                    } else if (endpoint.getFileExist() == GenericFileExist.Override) {\n                        // we override the target so we do this by deleting it so the temp file can be renamed later\n                        // with success as the existing target file have been deleted\n                        if (log.isTraceEnabled()) {\n                            log.trace(\"Deleting existing file: \" + tempTarget);\n                        }\n                        if (!operations.deleteFile(target)) {\n                            throw new GenericFileOperationFailedException(\"Cannot delete file: \" + target);\n                        }\n\n                    }\n                }\n\n                // delete any pre existing temp file\n                if (operations.existsFile(tempTarget)) {\n                    if (log.isTraceEnabled()) {\n                        log.trace(\"Deleting existing temp file: \" + tempTarget);\n                    }\n                    if (!operations.deleteFile(tempTarget)) {\n                        throw new GenericFileOperationFailedException(\"Cannot delete file: \" + tempTarget);\n                    }\n                }\n            }\n\n            // write/upload the file\n            writeFile(exchange, tempTarget != null ? tempTarget : target);\n\n            // if we did write to a temporary name then rename it to the real\n            // name after we have written the file\n            if (tempTarget != null) {\n                if (log.isTraceEnabled()) {\n                    log.trace(\"Renaming file: [\" + tempTarget + \"] to: [\" + target + \"]\");\n                }\n                boolean renamed = operations.renameFile(tempTarget, target);\n                if (!renamed) {\n                    throw new GenericFileOperationFailedException(\"Cannot rename file from: \" + tempTarget + \" to: \" + target);\n                }\n            }\n\n            // lets store the name we really used in the header, so end-users\n            // can retrieve it\n            exchange.getIn().setHeader(Exchange.FILE_NAME_PRODUCED, target);\n        } catch (Exception e) {\n            handleFailedWrite(exchange, e);\n        }\n    }","commit_id":"0412c02cb8c0a3c628d581da662ecc558ec3a61a","url":"https://github.com/apache/camel"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chgrp template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chgrp template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n   \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n        \n        String newgroup=(String)parameters.get(C_PARA_NEWGROUP);\n        String filename=(String)parameters.get(C_PARA_FILE);         \n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags== null) {\n            flags=\"false\";\n        }\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        //check if the lock parameter was included in the request\n        // if not, the lock page is shown for the first time\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\t\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n       \n     \n        \n        // a new owner was given in the request so try to change it\n        if (newgroup != null) {\n\n            // check if the current user has the right to change the group of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n                (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                cms.chgrp(file.getAbsolutePath(),newgroup);\n                //check if the file type name is page\n\t\t\t    //if so delete the file body and content\n\t\t\t    // else delete only file\n\t\t\t    if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n\t\t\t\t\t    cms.chgrp(hbodyPath,newgroup);\n\t\t\t\t    }\n                }      \n                \n                // if the resource is a folder, check if there is a corresponding \n                // directory in the content body folder\n                if (file.isFolder()) {\n                    String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                    try {\n                        cms.readFolder(bodyFolder);\n                        cms.lockResource(bodyFolder);\n                        cms.chgrp(bodyFolder,newgroup);\n                        cms.unlockResource(bodyFolder);\n                    } catch (CmsException ex) {\n                        // no folder is there, so do nothing\n                    }\n                }\n                \n                // the resource was a folder and the rekursive flag was set  \n                // do a recursive chown on all files and subfolders\n                if (flags.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        cms.lockResource(folder.getAbsolutePath());\n                        cms.chgrp(folder.getAbsolutePath(),newgroup);\n                        cms.unlockResource(folder.getAbsolutePath());\n                        // check if there is a corresponding \n                        // directory in the content body folder\n                        String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                        try {\n                            cms.readFolder(bodyFolder);\n                            cms.lockResource(bodyFolder);\n                            cms.chgrp(bodyFolder,newgroup);\n                            cms.unlockResource(bodyFolder);\n                        } catch (CmsException ex) {\n                             // no folder is there, so do nothing\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        cms.lockResource(newfile.getAbsolutePath());\n                        cms.chgrp(newfile.getAbsolutePath(),newgroup);\n                        cms.unlockResource(newfile.getAbsolutePath());\n                        if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t            String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n\t\t\t\t            int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t            String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n\t\t\t\t            if (hbodyPath.equals(bodyPath)){\n                                cms.lockResource(hbodyPath);\n\t\t\t\t\t            cms.chgrp(hbodyPath,newgroup);\n                                cms.unlockResource(hbodyPath);\n\t\t\t\t            }\n                        }   \n                        \n                    }    \n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        }\n\n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","id":37517,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chgrp template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chgrp template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n   \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n        \n        String newgroup=(String)parameters.get(C_PARA_NEWGROUP);\n        String filename=(String)parameters.get(C_PARA_FILE);         \n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags== null) {\n            flags=\"false\";\n        }\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        //check if the lock parameter was included in the request\n        // if not, the lock page is shown for the first time\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\t\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n       \n     \n        \n        // a new owner was given in the request so try to change it\n        if (newgroup != null) {\n\n            // check if the current user has the right to change the group of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n                (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                cms.chgrp(file.getAbsolutePath(),newgroup);\n                //check if the file type name is page\n\t\t\t    //if so delete the file body and content\n\t\t\t    // else delete only file\n\t\t\t    if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n\t\t\t\t\t    cms.chgrp(hbodyPath,newgroup);\n\t\t\t\t    }\n                }      \n                \n                // if the resource is a folder, check if there is a corresponding \n                // directory in the content body folder\n                if (file.isFolder()) {\n                    String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                    try {\n                        cms.readFolder(bodyFolder);\n                        cms.lockResource(bodyFolder);\n                        cms.chgrp(bodyFolder,newgroup);\n                        cms.unlockResource(bodyFolder);\n                    } catch (CmsException ex) {\n                        // no folder is there, so do nothing\n                    }\n                }\n                \n                // the resource was a folder and the rekursive flag was set  \n                // do a recursive chown on all files and subfolders\n                if (flags.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        if (folder.getState() != C_STATE_DELETED) {\n                            cms.lockResource(folder.getAbsolutePath());\n                            cms.chgrp(folder.getAbsolutePath(),newgroup);\n                            cms.unlockResource(folder.getAbsolutePath());\n                            // check if there is a corresponding \n                            // directory in the content body folder\n                            String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                            try {\n                                cms.readFolder(bodyFolder);\n                                cms.lockResource(bodyFolder);\n                                cms.chgrp(bodyFolder,newgroup);\n                                cms.unlockResource(bodyFolder);\n                            } catch (CmsException ex) {\n                                 // no folder is there, so do nothing\n                            }\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        if (newfile.getState() != C_STATE_DELETED) {\n                            cms.lockResource(newfile.getAbsolutePath());\n                            cms.chgrp(newfile.getAbsolutePath(),newgroup);\n                            cms.unlockResource(newfile.getAbsolutePath());\n                            if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t                String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n    \t\t\t\t            int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t    \t\t\t            String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n\t\t    \t\t            if (hbodyPath.equals(bodyPath)){\n                                    cms.lockResource(hbodyPath);\n\t\t\t\t    \t            cms.chgrp(hbodyPath,newgroup);\n                                    cms.unlockResource(hbodyPath);\n\t\t\t\t                }\n                            }   \n                        }\n                        \n                    }    \n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        }\n\n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chmod template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chmod template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n        \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n        String newaccess=(String)parameters.get(C_PARA_NEWACCESS);\n \n        // get the filename\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }        \n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\n        // get all access flags from the request\n        String ur=(String)parameters.get(\"ur\");\n        String uw=(String)parameters.get(\"uw\");\n        String uv=(String)parameters.get(\"uv\");\n        String gr=(String)parameters.get(\"gr\");\n        String gw=(String)parameters.get(\"gw\");\n        String gv=(String)parameters.get(\"gv\");\n        String pr=(String)parameters.get(\"pr\");\n        String pw=(String)parameters.get(\"pw\");\n        String pv=(String)parameters.get(\"pv\");\n        String ir=(String)parameters.get(\"ir\");\n      \n        String allflag=(String)parameters.get(C_PARA_FLAGS);\n        if (allflag== null) {\n            allflag=\"false\";\n        }\n        \n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        // check if the newaccess parameter is available. This parameter is set when\n        // the access flags are modified.\n        if (newaccess != null) {\n\n            // check if the current user has the right to change the group of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n               (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                // calculate the new access flags\n                int flag=0;\n                if (ur!= null) {\n                    if (ur.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_READ;\n                    }\n                }\n                if (uw != null) {\n                    if (uw.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_WRITE;\n                    }\n                }           \n                if (uv != null) {\n                    if (uv.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_VISIBLE;\n                    }\n                }     \n                if (gr != null) {\n                    if (gr.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_READ;\n                    }\n                }\n                if (gw != null) {\n                    if (gw.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_WRITE;\n                    }\n                }           \n                if (gv  != null) {\n                    if (gv.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_VISIBLE;\n                    }\n                }   \n                if (pr != null) {\n                    if (pr.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_READ;\n                    }\n                }\n                if (pw != null) {\n                    if (pw.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_WRITE;\n                    }\n                }           \n                if (pv  != null) {\n                    if (pv.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_VISIBLE;\n                    }\n                }  \n                if (ir != null) {\n                    if (ir.equals(\"true\")){                        \n                        flag+=C_ACCESS_INTERNAL_READ;\n                    }\n                }  \n                \n                // modify the access flags\n                cms.chmod(file.getAbsolutePath(),flag);\n                \n                //check if the file type name is page\n\t\t\t    //if so delete the file body and content\n\t\t\t    // else delete only file\n\t\t\t    if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n                        // set the internal read flag if nescessary\n                        if ((flag & C_ACCESS_INTERNAL_READ) ==0 ) {\n                            flag+=C_ACCESS_INTERNAL_READ;\n                        }\n                        cms.chmod(hbodyPath,flag);\n\t\t\t\t    }\n                }     \n                \n                // if the resource is a folder, check if there is a corresponding \n                // directory in the content body folder\n                if (file.isFolder()) {\n                    String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                    try {\n                        cms.readFolder(bodyFolder);\n                        cms.lockResource(bodyFolder);\n                        cms.chmod(bodyFolder,flag);\n                        cms.unlockResource(bodyFolder);\n                    } catch (CmsException ex) {\n                        // no folder is there, so do nothing\n                    }\n                }\n                \n                // the resource was a folder and the rekursive flag was set                   \n                // do a recursive chown on all files and subfolders\n                if (allflag.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        cms.lockResource(folder.getAbsolutePath());\n                        cms.chmod(folder.getAbsolutePath(),flag);\n                        cms.unlockResource(folder.getAbsolutePath());\n                        // check if there is a corresponding \n                        // directory in the content body folder\n                        String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                        try {\n                            cms.readFolder(bodyFolder);\n                            cms.lockResource(bodyFolder);\n                            cms.chmod(bodyFolder,flag);\n                            cms.unlockResource(bodyFolder);\n                        } catch (CmsException ex) {\n                             // no folder is there, so do nothing\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        cms.lockResource(newfile.getAbsolutePath());\n                        cms.chmod(newfile.getAbsolutePath(),flag);\n                        cms.unlockResource(newfile.getAbsolutePath());\n                        if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t            String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n\t\t\t\t            int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t            String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n\t\t\t\t            if (hbodyPath.equals(bodyPath)){\n                                cms.lockResource(hbodyPath);\n\t\t\t\t\t            cms.chmod(hbodyPath,flag);\n                                cms.unlockResource(hbodyPath);\n\t\t\t\t            }\n                        }   \n                        \n                    }    \n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist \n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        } \n\n\t    // set all required datablocks\n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        // now set the actual access flags i the dialog\n        int flags = file.getAccessFlags();\n        if ((flags & C_ACCESS_OWNER_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUR\",\" \");    \n        }\n        if ((flags & C_ACCESS_OWNER_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUW\",\" \");    \n        }\n        if ((flags & C_ACCESS_OWNER_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUV\",\" \");    \n        }     \n        if ((flags & C_ACCESS_GROUP_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGR\",\" \");    \n        }\n        if ((flags & C_ACCESS_GROUP_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGW\",\" \");    \n        }\n        if ((flags & C_ACCESS_GROUP_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGV\",\" \");    \n        }  \n        if ((flags & C_ACCESS_PUBLIC_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPR\",\" \");    \n        }\n        if ((flags & C_ACCESS_PUBLIC_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPW\",\" \");    \n        }\n        if ((flags & C_ACCESS_PUBLIC_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPV\",\" \");    \n        }  \n        if ((flags & C_ACCESS_INTERNAL_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKIF\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKIF\",\" \");    \n        }  \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","id":37518,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chmod template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chmod template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n        \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n        String newaccess=(String)parameters.get(C_PARA_NEWACCESS);\n \n        // get the filename\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }        \n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\n        // get all access flags from the request\n        String ur=(String)parameters.get(\"ur\");\n        String uw=(String)parameters.get(\"uw\");\n        String uv=(String)parameters.get(\"uv\");\n        String gr=(String)parameters.get(\"gr\");\n        String gw=(String)parameters.get(\"gw\");\n        String gv=(String)parameters.get(\"gv\");\n        String pr=(String)parameters.get(\"pr\");\n        String pw=(String)parameters.get(\"pw\");\n        String pv=(String)parameters.get(\"pv\");\n        String ir=(String)parameters.get(\"ir\");\n      \n        String allflag=(String)parameters.get(C_PARA_FLAGS);\n        if (allflag== null) {\n            allflag=\"false\";\n        }\n        \n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        // check if the newaccess parameter is available. This parameter is set when\n        // the access flags are modified.\n        if (newaccess != null) {\n\n            // check if the current user has the right to change the group of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n               (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                // calculate the new access flags\n                int flag=0;\n                if (ur!= null) {\n                    if (ur.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_READ;\n                    }\n                }\n                if (uw != null) {\n                    if (uw.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_WRITE;\n                    }\n                }           \n                if (uv != null) {\n                    if (uv.equals(\"true\")){\n                        flag+=C_ACCESS_OWNER_VISIBLE;\n                    }\n                }     \n                if (gr != null) {\n                    if (gr.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_READ;\n                    }\n                }\n                if (gw != null) {\n                    if (gw.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_WRITE;\n                    }\n                }           \n                if (gv  != null) {\n                    if (gv.equals(\"true\")){\n                        flag+=C_ACCESS_GROUP_VISIBLE;\n                    }\n                }   \n                if (pr != null) {\n                    if (pr.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_READ;\n                    }\n                }\n                if (pw != null) {\n                    if (pw.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_WRITE;\n                    }\n                }           \n                if (pv  != null) {\n                    if (pv.equals(\"true\")){\n                        flag+=C_ACCESS_PUBLIC_VISIBLE;\n                    }\n                }  \n                if (ir != null) {\n                    if (ir.equals(\"true\")){                        \n                        flag+=C_ACCESS_INTERNAL_READ;\n                    }\n                }  \n                \n                // modify the access flags\n                cms.chmod(file.getAbsolutePath(),flag);\n                \n                //check if the file type name is page\n\t\t\t    //if so delete the file body and content\n\t\t\t    // else delete only file\n\t\t\t    if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n                        // set the internal read flag if nescessary\n                        if ((flag & C_ACCESS_INTERNAL_READ) ==0 ) {\n                            flag+=C_ACCESS_INTERNAL_READ;\n                        }\n                        cms.chmod(hbodyPath,flag);\n\t\t\t\t    }\n                }     \n                \n                // if the resource is a folder, check if there is a corresponding \n                // directory in the content body folder\n                if (file.isFolder()) {\n                    String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                    try {\n                        cms.readFolder(bodyFolder);\n                        cms.lockResource(bodyFolder);\n                        cms.chmod(bodyFolder,flag);\n                        cms.unlockResource(bodyFolder);\n                    } catch (CmsException ex) {\n                        // no folder is there, so do nothing\n                    }\n                }\n                \n                // the resource was a folder and the rekursive flag was set                   \n                // do a recursive chown on all files and subfolders\n                if (allflag.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        if (folder.getState() != C_STATE_DELETED) {\n                            cms.lockResource(folder.getAbsolutePath());\n                            cms.chmod(folder.getAbsolutePath(),flag);\n                            cms.unlockResource(folder.getAbsolutePath());\n                            // check if there is a corresponding \n                            // directory in the content body folder\n                            String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                            try {\n                                cms.readFolder(bodyFolder);\n                                cms.lockResource(bodyFolder);\n                                cms.chmod(bodyFolder,flag);\n                                cms.unlockResource(bodyFolder);\n                            } catch (CmsException ex) {\n                                // no folder is there, so do nothing\n                            }\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        if (newfile.getState() != C_STATE_DELETED) {\n                            cms.lockResource(newfile.getAbsolutePath());\n                            cms.chmod(newfile.getAbsolutePath(),flag);\n                            cms.unlockResource(newfile.getAbsolutePath());\n                            if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t                String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n\t\t\t\t                int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t                String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n    \t\t\t\t            if (hbodyPath.equals(bodyPath)){\n                                    cms.lockResource(hbodyPath);\n\t\t    \t\t\t            cms.chmod(hbodyPath,flag);\n                                    cms.unlockResource(hbodyPath);\n\t\t\t\t                }\n                            }   \n                            \n                        }    \n                    }\n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist \n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        } \n\n\t    // set all required datablocks\n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        // now set the actual access flags i the dialog\n        int flags = file.getAccessFlags();\n        if ((flags & C_ACCESS_OWNER_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUR\",\" \");    \n        }\n        if ((flags & C_ACCESS_OWNER_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUW\",\" \");    \n        }\n        if ((flags & C_ACCESS_OWNER_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKUV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKUV\",\" \");    \n        }     \n        if ((flags & C_ACCESS_GROUP_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGR\",\" \");    \n        }\n        if ((flags & C_ACCESS_GROUP_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGW\",\" \");    \n        }\n        if ((flags & C_ACCESS_GROUP_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKGV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKGV\",\" \");    \n        }  \n        if ((flags & C_ACCESS_PUBLIC_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPR\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPR\",\" \");    \n        }\n        if ((flags & C_ACCESS_PUBLIC_WRITE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPW\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPW\",\" \");    \n        }\n        if ((flags & C_ACCESS_PUBLIC_VISIBLE) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKPV\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKPV\",\" \");    \n        }  \n        if ((flags & C_ACCESS_INTERNAL_READ) >0 ) {\n            xmlTemplateDocument.setData(\"CHECKIF\",\"CHECKED\");    \n        } else {\n            xmlTemplateDocument.setData(\"CHECKIF\",\" \");    \n        }  \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chown template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chown template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n        \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n\n        \n        // the template to be displayed\n        String template=null;\n\t\tCmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);        \n\t\t\n        String newowner=(String)parameters.get(C_PARA_NEWOWNER);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags== null) {\n            flags=\"false\";\n        }\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        //check if the lock parameter was included in the request\n        // if not, the lock page is shown for the first time\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\t\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        \n        // a new owner was given in the request so try to change it\n        if (newowner != null) {\n            \n            // check if the current user has the right to change the owner of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n                (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                 cms.chown(file.getAbsolutePath(),newowner);\n                 //check if the file type name is page\n\t\t\t     //if so delete the file body and content\n\t\t\t     // else delete only file\n\t\t\t     if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n\t\t\t\t\t    cms.chown(hbodyPath,newowner);\n\t\t\t\t    }\n                 } \n                \n                 // if the resource is a folder, check if there is a corresponding \n                 // directory in the content body folder\n                 if (file.isFolder()) {\n                     String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                     try {\n                         cms.readFolder(bodyFolder);\n                         cms.lockResource(bodyFolder);\n                         cms.chown(bodyFolder,newowner);\n                         cms.unlockResource(bodyFolder);\n                     } catch (CmsException ex) {\n                         // no folder is there, so do nothing\n                     }\n                 }\n                \n                // the resource was a folder and the rekursive flag was set                   \n                // do a recursive chown on all files and subfolders\n                if (flags.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        cms.lockResource(folder.getAbsolutePath());\n                        cms.chown(folder.getAbsolutePath(),newowner);\n                        cms.unlockResource(folder.getAbsolutePath());\n                        // check if there is a corresponding \n                        // directory in the content body folder\n                        String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                        try {\n                            cms.readFolder(bodyFolder);\n                            cms.lockResource(bodyFolder);\n                            cms.chown(bodyFolder,newowner);\n                            cms.unlockResource(bodyFolder);\n                        } catch (CmsException ex) {\n                             // no folder is there, so do nothing\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        cms.lockResource(newfile.getAbsolutePath());\n                        cms.chown(newfile.getAbsolutePath(),newowner);\n                        cms.unlockResource(newfile.getAbsolutePath());\n                        if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t            String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n\t\t\t\t            int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t            String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n\t\t\t\t            if (hbodyPath.equals(bodyPath)){\n                                cms.lockResource(hbodyPath);\n\t\t\t\t\t            cms.chown(hbodyPath,newowner);\n                                cms.unlockResource(hbodyPath);\n\t\t\t\t            }\n                        }   \n                        \n                    }    \n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        }\n\n\t    // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","id":37519,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the chown template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The chown template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n        \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n        }\n\n        \n        // the template to be displayed\n        String template=null;\n\t\tCmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);        \n\t\t\n        String newowner=(String)parameters.get(C_PARA_NEWOWNER);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags== null) {\n            flags=\"false\";\n        }\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        //check if the lock parameter was included in the request\n        // if not, the lock page is shown for the first time\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\t\t\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        \n        // a new owner was given in the request so try to change it\n        if (newowner != null) {\n            \n            // check if the current user has the right to change the owner of the\n            // resource. Only the owner of a file and the admin are allowed to do this.\n            if ((cms.getRequestContext().currentUser().equals(cms.readOwner(file))) ||\n                (cms.userInGroup(cms.getRequestContext().currentUser().getName(), C_GROUP_ADMIN))){\n                 cms.chown(file.getAbsolutePath(),newowner);\n                 //check if the file type name is page\n\t\t\t     //if so delete the file body and content\n\t\t\t     // else delete only file\n\t\t\t     if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, (CmsFile)file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n\t\t\t\t\t    cms.chown(hbodyPath,newowner);\n\t\t\t\t    }\n                 } \n                \n                 // if the resource is a folder, check if there is a corresponding \n                 // directory in the content body folder\n                 if (file.isFolder()) {\n                     String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+file.getAbsolutePath();\n                     try {\n                         cms.readFolder(bodyFolder);\n                         cms.lockResource(bodyFolder);\n                         cms.chown(bodyFolder,newowner);\n                         cms.unlockResource(bodyFolder);\n                     } catch (CmsException ex) {\n                         // no folder is there, so do nothing\n                     }\n                 }\n                \n                // the resource was a folder and the rekursive flag was set                   \n                // do a recursive chown on all files and subfolders\n                if (flags.equals(\"true\")) {\n                   // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                   cms.unlockResource(file.getAbsolutePath());\n                   // now modify all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        if (folder.getState() != C_STATE_DELETED) {\n                            cms.lockResource(folder.getAbsolutePath());\n                            cms.chown(folder.getAbsolutePath(),newowner);\n                            cms.unlockResource(folder.getAbsolutePath());\n                            // check if there is a corresponding \n                            // directory in the content body folder\n                            String bodyFolder=C_CONTENTBODYPATH.substring(0,C_CONTENTBODYPATH.lastIndexOf(\"/\"))+folder.getAbsolutePath();\n                            try {\n                                cms.readFolder(bodyFolder);\n                                cms.lockResource(bodyFolder);\n                                cms.chown(bodyFolder,newowner);\n                                cms.unlockResource(bodyFolder);\n                            } catch (CmsException ex) {\n                                // no folder is there, so do nothing\n                            }\n                        }\n                    }\n                \n                    // now modify all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        if (newfile.getState() != C_STATE_DELETED) {\n                            cms.lockResource(newfile.getAbsolutePath());\n                            cms.chown(newfile.getAbsolutePath(),newowner);\n                            cms.unlockResource(newfile.getAbsolutePath());\n                            if( (cms.getResourceType(newfile.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t                String bodyPath=getBodyPath(cms, (CmsFile)newfile);\n\t\t\t\t                int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t                String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(newfile.getAbsolutePath());\n    \t\t\t\t            if (hbodyPath.equals(bodyPath)){\n                                    cms.lockResource(hbodyPath);\n\t\t    \t\t\t            cms.chown(hbodyPath,newowner);\n                                    cms.unlockResource(hbodyPath);\n\t\t\t\t                }\n                            }   \n                        }\n                        \n                    }    \n                   cms.lockResource(file.getAbsolutePath());\n                }\n              \n                \n                \n                session.removeValue(C_PARA_FILE);\n                // return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n\t\t\t    } catch (Exception e) {\n\t\t\t        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n\t\t\t    }\n            } else {\n                // the current user is not allowed to change the file owner\n\t\t\t\txmlTemplateDocument.setData(\"details\", \"the current user is not allowed to change the file owner\");\n                template=\"error\";\n                session.removeValue(C_PARA_FILE);\n            }\n        }\n\n\t    // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the copy template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The copy template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n              \n        // the template to be displayed\n        String template=null;\n      \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NEWFILE);\n            session.removeValue(C_PARA_NEWFOLDER);\n            session.removeValue(C_PARA_FLAGS);\n            session.removeValue(C_PARA_NAME);\n        }\n        \n        // get the file to be copied\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        // read all request parameters     \n        String newFile=(String)parameters.get(C_PARA_NEWFILE);\n        if (newFile != null) {\n            session.putValue(C_PARA_NEWFILE,newFile);        \n        }\n        newFile=(String)session.getValue(C_PARA_NEWFILE);\n        \n        String newFolder=(String)parameters.get(C_PARA_NEWFOLDER);\n        if (newFolder != null) {\n            session.putValue(C_PARA_NEWFOLDER,newFolder);        \n        }\n        newFolder=(String)session.getValue(C_PARA_NEWFOLDER);\n\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags != null) {\n            session.putValue(C_PARA_FLAGS,flags);        \n        }\n        flags=(String)session.getValue(C_PARA_FLAGS);\n        \n        String action = (String)parameters.get(\"action\");      \n\n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n        \n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        // modify the folderaname if nescessary (the root folder is always given\n        // as a nice name)\n        if (newFolder!= null) {\n            CmsXmlLanguageFile lang=new CmsXmlLanguageFile(cms);\n            if (newFolder.equals(lang.getLanguageValue(\"title.rootfolder\"))) {\n                newFolder=\"/\";\n            }\n        }\n  \n        //check if the newfile parameter was included in the request\n        // if not, the copy page is shown for the first time\n        if (newFile == null) {\n            session.putValue(C_PARA_NAME,file.getName());\n        } else {       \n\n            if (action== null) {\n                template=\"wait\";\n                \n            } else {\n            \n            // now check if the resource is a file or a folder            \n            if (file.isFile()) {\n                // this is a file, so copy it    \n                try {\n                    copyFile(cms,(CmsFile)file,newFolder,newFile,flags,false);\n                } catch (CmsException ex) {\n                    // something went wrong, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    throw ex;\n                }\n                // everything is done, so remove all session parameters\n                session.removeValue(C_PARA_FILE);\n                session.removeValue(C_PARA_NAME);\n\t\t\t    session.removeValue(C_PARA_NEWFILE);\n                session.removeValue(C_PARA_NEWFOLDER);\n                session.removeValue(C_PARA_FLAGS);\n                 // TODO: Error handling\n                \n                // now return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n                } catch (Exception e) {\n                    throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                } \n                         \n            } else {\n                // the selected resource is a folder, so copy it and all its subresources\n                // get all subfolders and files\n                Vector allFolders=new Vector();\n                Vector allFiles=new Vector();\n                getAllResources(cms,filename,allFiles,allFolders);\n              \n                try {\n                    //copy the selected folder\n                    cms.copyFolder(filename, newFolder+newFile+\"/\");                \n                    checkFlags(cms, newFolder+newFile+\"/\",flags);                                           \n                \n                    // now copy all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        cms.copyFolder(folder.getAbsolutePath(), newFolder+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length()));\n                 \n                        checkFlags(cms,newFolder+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length()),flags);                    \n                     }\n                \n                    // now copy all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        copyFile(cms,newfile,newFolder+newFile+\"/\",newfile.getAbsolutePath().substring(file.getAbsolutePath().length()),flags,true);\n                    }    \n                \t// everything is done, so remove all session parameters\t\t\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n            \n                    template=\"update\";\n                    \n                }catch (CmsException ex) {\n                    // something went wrong, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    throw ex;\n                }\n\n                }\n            }\n           \n        }\n         \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n                   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);   \n    }","id":37520,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the copy template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The copy template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n              \n        // the template to be displayed\n        String template=null;\n      \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n\n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NEWFILE);\n            session.removeValue(C_PARA_NEWFOLDER);\n            session.removeValue(C_PARA_FLAGS);\n            session.removeValue(C_PARA_NAME);\n        }\n        \n        // get the file to be copied\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        // read all request parameters     \n        String newFile=(String)parameters.get(C_PARA_NEWFILE);\n        if (newFile != null) {\n            session.putValue(C_PARA_NEWFILE,newFile);        \n        }\n        newFile=(String)session.getValue(C_PARA_NEWFILE);\n        \n        String newFolder=(String)parameters.get(C_PARA_NEWFOLDER);\n        if (newFolder != null) {\n            session.putValue(C_PARA_NEWFOLDER,newFolder);        \n        }\n        newFolder=(String)session.getValue(C_PARA_NEWFOLDER);\n\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags != null) {\n            session.putValue(C_PARA_FLAGS,flags);        \n        }\n        flags=(String)session.getValue(C_PARA_FLAGS);\n        \n        String action = (String)parameters.get(\"action\");      \n\n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n        \n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n        // modify the folderaname if nescessary (the root folder is always given\n        // as a nice name)\n        if (newFolder!= null) {\n            CmsXmlLanguageFile lang=new CmsXmlLanguageFile(cms);\n            if (newFolder.equals(lang.getLanguageValue(\"title.rootfolder\"))) {\n                newFolder=\"/\";\n            }\n        }\n  \n        //check if the newfile parameter was included in the request\n        // if not, the copy page is shown for the first time\n        if (newFile == null) {\n            session.putValue(C_PARA_NAME,file.getName());\n        } else {       \n\n            if (action== null) {\n                template=\"wait\";\n                \n            } else {\n            \n            // now check if the resource is a file or a folder            \n            if (file.isFile()) {\n                // this is a file, so copy it    \n                try {\n                    copyFile(cms,(CmsFile)file,newFolder,newFile,flags,false);\n                } catch (CmsException ex) {\n                    // something went wrong, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    throw ex;\n                }\n                // everything is done, so remove all session parameters\n                session.removeValue(C_PARA_FILE);\n                session.removeValue(C_PARA_NAME);\n\t\t\t    session.removeValue(C_PARA_NEWFILE);\n                session.removeValue(C_PARA_NEWFOLDER);\n                session.removeValue(C_PARA_FLAGS);\n                 // TODO: Error handling\n                \n                // now return to filelist\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n                } catch (Exception e) {\n                    throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                } \n                         \n            } else {\n                // the selected resource is a folder, so copy it and all its subresources\n                // get all subfolders and files\n                Vector allFolders=new Vector();\n                Vector allFiles=new Vector();\n                getAllResources(cms,filename,allFiles,allFolders);\n              \n                try {\n                    //copy the selected folder\n                    cms.copyFolder(filename, newFolder+newFile+\"/\");                \n                    checkFlags(cms, newFolder+newFile+\"/\",flags);                                           \n                \n                    // now copy all subfolders\n                    for (int i=0;i<allFolders.size();i++) {\n                        CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                        if (folder.getState() != C_STATE_DELETED) {\n                            cms.copyFolder(folder.getAbsolutePath(), newFolder+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length()));\n                 \n                            checkFlags(cms,newFolder+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length()),flags);                    \n                        }\n                    }\n                \n                    // now copy all files in the subfolders\n                    for (int i=0;i<allFiles.size();i++) {\n                        CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                        if (newfile.getState() != C_STATE_DELETED) {\n                            copyFile(cms,newfile,newFolder+newFile+\"/\",newfile.getAbsolutePath().substring(file.getAbsolutePath().length()),flags,true);\n                        }\n                    }    \n                \t// everything is done, so remove all session parameters\t\t\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n            \n                    template=\"update\";\n                    \n                }catch (CmsException ex) {\n                    // something went wrong, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n                    session.removeValue(C_PARA_NAME);\n\t\t\t        session.removeValue(C_PARA_NEWFILE);\n                    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    throw ex;\n                }\n\n                }\n            }\n           \n        }\n         \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n        if (title==null) {\n            title=\"\";\n        }\n        A_CmsUser owner=cms.readOwner(file);\n        xmlTemplateDocument.setData(\"TITLE\",title);\n        xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n        xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n        xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\txmlTemplateDocument.setData(\"FILENAME\",file.getName());\n                   \n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);   \n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the delete template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The delete template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n                      \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_DELETE);\n            session.removeValue(C_PARA_FILE);   \n        }\n        \n        \n        String delete=(String)parameters.get(C_PARA_DELETE);          \n        if (delete != null) {\n            session.putValue(C_PARA_DELETE,delete);        \n        }\n        delete=(String)session.getValue(C_PARA_DELETE); \n        \n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        String action = (String)parameters.get(\"action\");\n        \n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\n        if (file.isFile()) {\n            template=\"file\";\n        } else {\n            template=\"folder\";\n        }\n\n        //check if the name parameter was included in the request\n        // if not, the delete page is shown for the first time\n    \n\n        if (delete != null) {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n            \n            // check if the resource is a file or a folder\n            if (file.isFile()) {            \n                // its a file, so delete it\n                deleteFile(cms,file,false);\n                \n                session.removeValue(C_PARA_DELETE);  \n                session.removeValue(C_PARA_FILE);\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n                } catch (Exception e) {\n                    throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                } \n                \n            } else {               \n                // its a folder, so try to delete the folder and its subfolders\n                // get all subfolders and files\n                Vector allFolders=new Vector();\n                Vector allFiles=new Vector();\n         \n                getAllResources(cms,filename,allFiles,allFolders);\n               \n                // unlock the folder, otherwise the subflders and files could not be\n                // deleted.\n                cms.unlockResource(filename);\n             \n                // now delete all files in the subfolders\n                for (int i=0;i<allFiles.size();i++) {\n                    CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                    cms.lockResource(newfile.getAbsolutePath());\n                    deleteFile(cms,newfile,true);\n                }    \n        \n                // now delete all subfolders\n                for (int i=0;i<allFolders.size();i++) {\n                    CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                    cms.lockResource(folder.getAbsolutePath());\n                    cms.deleteFolder(folder.getAbsolutePath());\n                }\n         \n                // finally delete the selected folder\n                cms.lockResource(filename);\n                cms.deleteFolder(filename);\n                \n                session.removeValue(C_PARA_DELETE);  \n                session.removeValue(C_PARA_FILE);\n                template=\"update\";\n            \n            }\n            }\n            \n          \n            \n            // TODO: Error handling\n           \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n               title=\"\";\n            }\n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template); \n    }","id":37521,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the delete template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The delete template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n                      \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_DELETE);\n            session.removeValue(C_PARA_FILE);   \n        }\n        \n        \n        String delete=(String)parameters.get(C_PARA_DELETE);          \n        if (delete != null) {\n            session.putValue(C_PARA_DELETE,delete);        \n        }\n        delete=(String)session.getValue(C_PARA_DELETE); \n        \n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        String action = (String)parameters.get(\"action\");\n        \n\t\tA_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n\n        if (file.isFile()) {\n            template=\"file\";\n        } else {\n            template=\"folder\";\n        }\n\n        //check if the name parameter was included in the request\n        // if not, the delete page is shown for the first time\n    \n\n        if (delete != null) {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n            \n            // check if the resource is a file or a folder\n            if (file.isFile()) {            \n                // its a file, so delete it\n                deleteFile(cms,file,false);\n                \n                session.removeValue(C_PARA_DELETE);  \n                session.removeValue(C_PARA_FILE);\n                try {\n                    if(lasturl == null || \"\".equals(lasturl)) {\n                        cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                    } else {\n                        ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                    }                            \n                } catch (Exception e) {\n                    throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                } \n                \n            } else {               \n                // its a folder, so try to delete the folder and its subfolders\n                // get all subfolders and files\n                Vector allFolders=new Vector();\n                Vector allFiles=new Vector();\n         \n                getAllResources(cms,filename,allFiles,allFolders);\n               \n                // unlock the folder, otherwise the subflders and files could not be\n                // deleted.\n                cms.unlockResource(filename);\n             \n                // now delete all files in the subfolders\n                for (int i=0;i<allFiles.size();i++) {\n                    CmsFile newfile=(CmsFile)allFiles.elementAt(i);  \n                    if (newfile.getState() != C_STATE_DELETED) {\n                        cms.lockResource(newfile.getAbsolutePath());\n                        deleteFile(cms,newfile,true);\n                    }\n                }    \n        \n                // now delete all subfolders\n                for (int i=0;i<allFolders.size();i++) {\n                    CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                    if (folder.getState() != C_STATE_DELETED) {\n                        cms.lockResource(folder.getAbsolutePath());\n                        cms.deleteFolder(folder.getAbsolutePath());\n                    }\n                }\n         \n                // finally delete the selected folder\n                cms.lockResource(filename);\n                cms.deleteFolder(filename);\n                \n                session.removeValue(C_PARA_DELETE);  \n                session.removeValue(C_PARA_FILE);\n                template=\"update\";\n            \n            }\n            }\n            \n          \n            \n            // TODO: Error handling\n           \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n               title=\"\";\n            }\n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template); \n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the move template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The move template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n      \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n       \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NEWFOLDER);\n            session.removeValue(C_PARA_FLAGS);\n        }\n        \n        // get the file to be copied\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        // read all request parameters\n        String newFolder=(String)parameters.get(C_PARA_NEWFOLDER);\n        if (newFolder != null) {\n            session.putValue(C_PARA_NEWFOLDER,newFolder);        \n        }\n        newFolder=(String)session.getValue(C_PARA_NEWFOLDER);\n\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags != null) {\n            session.putValue(C_PARA_FLAGS,flags);        \n        }\n        flags=(String)session.getValue(C_PARA_FLAGS);\n        \n        String action = (String)parameters.get(\"action\");\n        \n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n        \n        // modify the folderaname if nescessary (the root folder is always given\n        // as a nice name)\n        if (newFolder!= null) {\n            CmsXmlLanguageFile lang=new CmsXmlLanguageFile(cms);\n            if (newFolder.equals(lang.getLanguageValue(\"title.rootfolder\"))) {\n                newFolder=\"/\";\n            }\n        }\n\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n\t\t //check if the newFolder parameter was included in the request\n         //if not, the move page is shown for the first time\n         if (newFolder != null) {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n                 if (file.isFile()) {\n                    // this is a file, so move it               \n                    try {\n                        moveFile(cms,(CmsFile)file,newFolder,flags,false);\n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NEWFOLDER);\n                        session.removeValue(C_PARA_FLAGS);\n                        throw ex;\n                    }\n                   \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    \n                    // TODO: Error handling\n                    \n                    // return to the calling page\n                    try {\n                        if(lasturl == null || \"\".equals(lasturl)) {\n                            cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                        } else {\n                            ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                        }                            \n                    } catch (Exception e) {\n                        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                    } \n                } else {\n                     // this is a folder\n                    // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n          \n                    try {     \n                    \n                        // first creatre the new folder\n                        cms.unlockResource(file.getAbsolutePath());\n                        cms.copyFolder(filename,newFolder+file.getName()+\"/\");\n                                    \n                        // then copy all folders\n                        for (int i=0;i<allFolders.size();i++) {                            \n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                            String newname=newFolder+file.getName()+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                             \n                            System.err.println(\"Copy File \"+folder.getAbsolutePath()+ \"- > \"+newname);\n                            cms.copyFolder(folder.getAbsolutePath(), newname);\n                        }\n                     \n                        // now move the files\n                        for (int i=0;i<allFiles.size();i++) {\n                            CmsFile newfile=(CmsFile)allFiles.elementAt(i);\n                            String newname=newFolder+file.getName()+\"/\"+newfile.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                       \n                            cms.lockResource(newfile.getAbsolutePath());\n                           // cms.moveFile(newfile.getAbsolutePath(),newname);\n                            System.err.println(\"Copy File \"+newfile.getAbsolutePath()+ \"- > \"+newFolder+file.getName()+\"/\");\n                           \n                            moveFile(cms,newfile,newFolder+file.getName()+\"/\",\"true\",true);\n                            cms.unlockResource(newname);\n                        }\n                        \n                       // finally remove the original folders\n                        for (int i=0;i<allFolders.size();i++) {\n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                            cms.lockResource(folder.getAbsolutePath());\n                            System.err.println(\"Delete Folder \"+folder.getAbsolutePath());\n                           \n                            cms.deleteFolder(folder.getAbsolutePath());\n                        }\n                        \n                        // as the last step, delete the original folder\n                         cms.lockResource(filename);\n                         cms.deleteFolder(filename);        \n                         cms.lockResource(newFolder+file.getName()+\"/\");\n                       \n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NEWFOLDER);\n                        session.removeValue(C_PARA_FLAGS);\n                        throw ex;\n                    }\n                      \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    template=\"update\";\n                }\n            }\n\t\t\t\n            \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n                title=\"\";\n            }            \n            \n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","id":37522,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the move template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The move template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n      \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);\n       \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NEWFOLDER);\n            session.removeValue(C_PARA_FLAGS);\n        }\n        \n        // get the file to be copied\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        // read all request parameters\n        String newFolder=(String)parameters.get(C_PARA_NEWFOLDER);\n        if (newFolder != null) {\n            session.putValue(C_PARA_NEWFOLDER,newFolder);        \n        }\n        newFolder=(String)session.getValue(C_PARA_NEWFOLDER);\n\n        String flags=(String)parameters.get(C_PARA_FLAGS);\n        if (flags != null) {\n            session.putValue(C_PARA_FLAGS,flags);        \n        }\n        flags=(String)session.getValue(C_PARA_FLAGS);\n        \n        String action = (String)parameters.get(\"action\");\n        \n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n        \n        // modify the folderaname if nescessary (the root folder is always given\n        // as a nice name)\n        if (newFolder!= null) {\n            CmsXmlLanguageFile lang=new CmsXmlLanguageFile(cms);\n            if (newFolder.equals(lang.getLanguageValue(\"title.rootfolder\"))) {\n                newFolder=\"/\";\n            }\n        }\n\n        // select the template to be displayed\n        if (file.isFile()) {\n            template=\"file\";            \n        } else {\n            template=\"folder\";\n        }\n        \n\t\t //check if the newFolder parameter was included in the request\n         //if not, the move page is shown for the first time\n         if (newFolder != null) {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n                 if (file.isFile()) {\n                    // this is a file, so move it               \n                    try {\n                        moveFile(cms,(CmsFile)file,newFolder,flags,false);\n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NEWFOLDER);\n                        session.removeValue(C_PARA_FLAGS);\n                        throw ex;\n                    }\n                   \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    \n                    // TODO: Error handling\n                    \n                    // return to the calling page\n                    try {\n                        if(lasturl == null || \"\".equals(lasturl)) {\n                            cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                        } else {\n                            ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                        }                            \n                    } catch (Exception e) {\n                        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                    } \n                } else {\n                     // this is a folder\n                    // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n          \n                    try {     \n                    \n                        // first creatre the new folder\n                        cms.unlockResource(file.getAbsolutePath());\n                        cms.copyFolder(filename,newFolder+file.getName()+\"/\");\n                                    \n                        // then copy all folders\n                        for (int i=0;i<allFolders.size();i++) {                            \n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                            if (folder.getState() != C_STATE_DELETED) {\n                                String newname=newFolder+file.getName()+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                             \n                                cms.copyFolder(folder.getAbsolutePath(), newname);\n                            }\n                        }\n                     \n                        // now move the files\n                        for (int i=0;i<allFiles.size();i++) {\n                            CmsFile newfile=(CmsFile)allFiles.elementAt(i);\n                            if (newfile.getState() != C_STATE_DELETED) {\n                                String newname=newFolder+file.getName()+\"/\"+newfile.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                       \n                                cms.lockResource(newfile.getAbsolutePath());\n                                // cms.moveFile(newfile.getAbsolutePath(),newname);\n                                moveFile(cms,newfile,newFolder+file.getName()+\"/\",\"true\",true);\n                                cms.unlockResource(newname);\n                            }\n                        }\n                        \n                       // finally remove the original folders\n                        for (int i=0;i<allFolders.size();i++) {\n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                            if (folder.getState() != C_STATE_DELETED) {\n                                cms.lockResource(folder.getAbsolutePath());\n                                cms.deleteFolder(folder.getAbsolutePath());\n                            }\n                        }\n                        \n                        // as the last step, delete the original folder\n                         cms.lockResource(filename);\n                         cms.deleteFolder(filename);        \n                         cms.lockResource(newFolder+file.getName()+\"/\");\n                       \n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NEWFOLDER);\n                        session.removeValue(C_PARA_FLAGS);\n                        throw ex;\n                    }\n                      \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NEWFOLDER);\n                    session.removeValue(C_PARA_FLAGS);\n                    template=\"update\";\n                }\n            }\n\t\t\t\n            \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n                title=\"\";\n            }            \n            \n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the rename template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The lock template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);    \n        \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NAME); \n        }\n        \n        // TODO: check, if this is neede: String lock=(String)parameters.get(C_PARA_LOCK);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        String newFile=(String)parameters.get(C_PARA_NAME);\n        if (newFile != null) {\n            session.putValue(C_PARA_NAME,newFile);        \n        }\n        newFile=(String)session.getValue(C_PARA_NAME);\n        \n        String action = (String)parameters.get(\"action\");\n\n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n      \n        if (file.isFile()) {\n            template=\"file\";\n        } else {\n            template=\"folder\";\n        }       \n      \n        //check if the name parameter was included in the request\n        // if not, the lock page is shown for the first time    \n        if (newFile == null) {\n            session.putValue(C_PARA_NAME,file.getName());\n        } else {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n            \n                // now check if the resource is a file or a folder            \n                if (file.isFile()) {\n                    // this is a file, so rename it         \n                    try {\n                        renameFile(cms,file,newFile);\n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NAME);\n                        throw ex;\n                    }\n                    \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NAME);\n                \n                    try {\n                        if(lasturl == null || \"\".equals(lasturl)) {\n                            cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                        } else {\n                            ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                        }                            \n                    } catch (Exception e) {\n                        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                    }   \n                    \n                } else {\n                    // this is a folder\n                    // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                    String parent=file.getParent();\n                    try {     \n                    \n                        // first creatre the new folder\n                        cms.unlockResource(file.getAbsolutePath());\n                        cms.copyFolder(filename,parent+newFile+\"/\");\n                                    \n                        // then copy all folders\n                        for (int i=0;i<allFolders.size();i++) {                            \n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                            String newname=parent+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length());                                               \n                            cms.copyFolder(folder.getAbsolutePath(), newname);\n                        }\n                     \n                        // now move the files\n                        for (int i=0;i<allFiles.size();i++) {\n                            CmsFile newfile=(CmsFile)allFiles.elementAt(i);\n                            String newname=parent+newFile+\"/\"+newfile.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                       \n                            cms.lockResource(newfile.getAbsolutePath());\n                           // cms.moveFile(newfile.getAbsolutePath(),newname);\n                            moveFile(cms,newfile,newname,\"true\",true);          \n                            cms.unlockResource(newname);\n                        }\n                        \n                        // finally remove the original folders\n                        for (int i=0;i<allFolders.size();i++) {\n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                            cms.lockResource(folder.getAbsolutePath());\n                            cms.deleteFolder(folder.getAbsolutePath());\n                        }\n                        \n                        // as the last step, delete the original folder\n                         cms.lockResource(filename);\n                         cms.deleteFolder(filename);        \n                         cms.lockResource(parent+newFile+\"/\");\n                        \n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NAME);\n                        throw ex;\n                    }\n                     // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NAME);\n                    template=\"update\";\n                }\n            }\n        }\n        \n  \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n                title=\"\";\n            }            \n            \n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    \n    }","id":37523,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the rename template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The lock template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n        // the template to be displayed\n        String template=null;\n        \n        // get the lasturl parameter\n        String lasturl = getLastUrl(cms, parameters);    \n        \n        // clear session values on first load\n        String initial=(String)parameters.get(C_PARA_INITIAL);\n        if (initial!= null) {\n            // remove all session values\n            session.removeValue(C_PARA_FILE);\n            session.removeValue(C_PARA_NAME); \n        }\n        \n        // TODO: check, if this is neede: String lock=(String)parameters.get(C_PARA_LOCK);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n        \n        String newFile=(String)parameters.get(C_PARA_NAME);\n        if (newFile != null) {\n            session.putValue(C_PARA_NAME,newFile);        \n        }\n        newFile=(String)session.getValue(C_PARA_NAME);\n        \n        String action = (String)parameters.get(\"action\");\n\n        A_CmsResource file=(A_CmsResource)cms.readFileHeader(filename);\n      \n        if (file.isFile()) {\n            template=\"file\";\n        } else {\n            template=\"folder\";\n        }       \n      \n        //check if the name parameter was included in the request\n        // if not, the lock page is shown for the first time    \n        if (newFile == null) {\n            session.putValue(C_PARA_NAME,file.getName());\n        } else {\n            if (action== null) {\n                template=\"wait\";                \n            } else {\n            \n                // now check if the resource is a file or a folder            \n                if (file.isFile()) {\n                    // this is a file, so rename it         \n                    try {\n                        renameFile(cms,file,newFile);\n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NAME);\n                        throw ex;\n                    }\n                    \n                    // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NAME);\n                \n                    try {\n                        if(lasturl == null || \"\".equals(lasturl)) {\n                            cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n                        } else {\n                            ((HttpServletResponse)(cms.getRequestContext().getResponse().getOriginalResponse())).sendRedirect(lasturl);                       \n                        }                            \n                    } catch (Exception e) {\n                        throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n                    }   \n                    \n                } else {\n                    // this is a folder\n                    // get all subfolders and files\n                    Vector allFolders=new Vector();\n                    Vector allFiles=new Vector();\n                    getAllResources(cms,filename,allFiles,allFolders);\n                    \n                    String parent=file.getParent();\n                    try {     \n                    \n                        // first creatre the new folder\n                        cms.unlockResource(file.getAbsolutePath());\n                        cms.copyFolder(filename,parent+newFile+\"/\");\n                                    \n                        // then copy all folders\n                        for (int i=0;i<allFolders.size();i++) {                            \n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(i);  \n                            if (folder.getState() != C_STATE_DELETED) {\n                                String newname=parent+newFile+\"/\"+folder.getAbsolutePath().substring(file.getAbsolutePath().length());                                               \n                                cms.copyFolder(folder.getAbsolutePath(), newname);\n                            }\n                        }\n                     \n                        // now move the files\n                        for (int i=0;i<allFiles.size();i++) {\n                            CmsFile newfile=(CmsFile)allFiles.elementAt(i);\n                            if (newfile.getState() != C_STATE_DELETED) {\n                                String newname=parent+newFile+\"/\"+newfile.getAbsolutePath().substring(file.getAbsolutePath().length());                                                                       \n                                cms.lockResource(newfile.getAbsolutePath());\n                                // cms.moveFile(newfile.getAbsolutePath(),newname);\n                                moveFile(cms,newfile,newname,\"true\",true);          \n                                cms.unlockResource(newname);\n                            }\n                        }\n                        \n                        // finally remove the original folders\n                        for (int i=0;i<allFolders.size();i++) {\n                            CmsFolder folder=(CmsFolder)allFolders.elementAt(allFolders.size()-i-1);  \n                            if (folder.getState() != C_STATE_DELETED) {\n                                cms.lockResource(folder.getAbsolutePath());\n                                cms.deleteFolder(folder.getAbsolutePath());\n                            }\n                        }\n                        \n                        // as the last step, delete the original folder\n                         cms.lockResource(filename);\n                         cms.deleteFolder(filename);        \n                         cms.lockResource(parent+newFile+\"/\");\n                        \n                    } catch (CmsException ex) {\n                        // something went wrong, so remove all session parameters\n                        session.removeValue(C_PARA_FILE);\n\t    \t\t        session.removeValue(C_PARA_NAME);\n                        throw ex;\n                    }\n                     // everything is done, so remove all session parameters\n                    session.removeValue(C_PARA_FILE);\n\t    \t\t    session.removeValue(C_PARA_NAME);\n                    template=\"update\";\n                }\n            }\n        }\n        \n  \n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);          \n        // set the required datablocks\n        if (action == null) {\n            String title=cms.readProperty(file.getAbsolutePath(),C_PROPERTY_TITLE);\n            if (title==null) {\n                title=\"\";\n            }            \n            \n            A_CmsUser owner=cms.readOwner(file);\n            xmlTemplateDocument.setData(\"TITLE\",title);\n            xmlTemplateDocument.setData(\"STATE\",getState(cms,file,new CmsXmlLanguageFile(cms)));\n            xmlTemplateDocument.setData(\"OWNER\",owner.getFirstname()+\" \"+owner.getLastname()+\"(\"+owner.getName()+\")\");\n            xmlTemplateDocument.setData(\"GROUP\",cms.readGroup(file).getName());\n\t\t    xmlTemplateDocument.setData(\"FILENAME\",file.getName());\n        }\n        \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template);\n    \n    }","commit_id":"ee5fdb19bcb842ea696a28a76d4adb3d74deeea9","url":"https://github.com/alkacon/opencms-core"},{"original_method":"@Override\n\tpublic boolean handlePortalException(String exception) throws Exception {\n\t\tif (exception.isEmpty()) {\n\t\t\treturn false;\n\t\t}\n\n\t\tint pos = exception.indexOf(\"$\");\n\n\t\tif (pos > 0) {\n\t\t\texception = exception.substring(0, pos);\n\t\t}\n\n\t\tboolean retryInProgress = ConnectionRetryUtil.retryInProgress(\n\t\t\tgetSyncAccountId());\n\n\t\tif (!retryInProgress && _logger.isDebugEnabled()) {\n\t\t\t_logger.debug(\"Handling exception {}\", exception);\n\t\t}\n\n\t\tif (exception.equals(\n\t\t\t\t\"com.liferay.portal.kernel.lock.DuplicateLockException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_DUPLICATE_LOCK);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.kernel.upload.UploadException\") ||\n\t\t\t\t exception.contains(\"SizeLimitExceededException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_EXCEEDED_SIZE_LIMIT);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.security.auth.PrincipalException\")) {\n\n\t\t\tSyncFileService.setStatuses(\n\t\t\t\tgetLocalSyncFile(), SyncFile.STATE_ERROR,\n\t\t\t\tSyncFile.UI_EVENT_INVALID_PERMISSIONS);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t\"FileExtensionException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_INVALID_FILE_EXTENSION);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.FileNameException\") ||\n\t\t\t\t exception.equals(\n\t\t\t\t\t \"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t \"FolderNameException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_INVALID_FILE_NAME);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t\"NoSuchFileEntryException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tPath filePath = Paths.get(syncFile.getFilePathName());\n\n\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\tSyncFileService.deleteSyncFile(syncFile, false);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncClientMinBuildException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_MIN_BUILD_REQUIREMENT_FAILED);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncServicesUnavailableException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_SYNC_SERVICES_NOT_ACTIVE);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncSiteUnavailableException\")) {\n\n\t\t\thandleSiteDeactivatedException();\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.kernel.jsonwebservice.\" +\n\t\t\t\t\t\t\"NoSuchJSONWebServiceException\")) {\n\n\t\t\tretryServerConnection(SyncAccount.UI_EVENT_SYNC_WEB_MISSING);\n\t\t}\n\t\telse if (exception.equals(\"Authenticated access required\") ||\n\t\t\t\t exception.equals(\"java.lang.SecurityException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_AUTHENTICATION_EXCEPTION);\n\t\t}\n\t\telse {\n\t\t\tif (retryInProgress && _logger.isDebugEnabled()) {\n\t\t\t\t_logger.debug(\"Handling exception {}\", exception);\n\t\t\t}\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_NONE);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\n\t\treturn true;\n\t}","id":37524,"modified_method":"@Override\n\tpublic boolean handlePortalException(String exception) throws Exception {\n\t\tif (exception.isEmpty()) {\n\t\t\treturn false;\n\t\t}\n\n\t\tint pos = exception.indexOf(\"$\");\n\n\t\tif (pos > 0) {\n\t\t\texception = exception.substring(0, pos);\n\t\t}\n\n\t\tboolean retryInProgress = ConnectionRetryUtil.retryInProgress(\n\t\t\tgetSyncAccountId());\n\n\t\tif (!retryInProgress && _logger.isDebugEnabled()) {\n\t\t\t_logger.debug(\"Handling exception {}\", exception);\n\t\t}\n\n\t\tif (exception.equals(\n\t\t\t\t\"com.liferay.portal.kernel.lock.DuplicateLockException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_DUPLICATE_LOCK);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.kernel.upload.UploadException\") ||\n\t\t\t\t exception.contains(\"SizeLimitExceededException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_EXCEEDED_SIZE_LIMIT);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.security.auth.PrincipalException\")) {\n\n\t\t\tSyncFileService.setStatuses(\n\t\t\t\tgetLocalSyncFile(), SyncFile.STATE_ERROR,\n\t\t\t\tSyncFile.UI_EVENT_INVALID_PERMISSIONS);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t\"FileExtensionException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_INVALID_FILE_EXTENSION);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.FileNameException\") ||\n\t\t\t\t exception.equals(\n\t\t\t\t\t \"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t \"FolderNameException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_INVALID_FILE_NAME);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portlet.documentlibrary.\" +\n\t\t\t\t\t\t\"NoSuchFileEntryException\")) {\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tPath filePath = Paths.get(syncFile.getFilePathName());\n\n\t\t\tif (Files.exists(filePath)) {\n\t\t\t\tWatcher watcher = WatcherRegistry.getWatcher(\n\t\t\t\t\tgetSyncAccountId());\n\n\t\t\t\tList<String> deletedFilePathNames =\n\t\t\t\t\twatcher.getDeletedFilePathNames();\n\n\t\t\t\tdeletedFilePathNames.add(syncFile.getFilePathName());\n\n\t\t\t\tFileUtil.deleteFile(filePath);\n\t\t\t}\n\n\t\t\tSyncFileService.deleteSyncFile(syncFile, false);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncClientMinBuildException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_MIN_BUILD_REQUIREMENT_FAILED);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncServicesUnavailableException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_SYNC_SERVICES_NOT_ACTIVE);\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.sync.SyncSiteUnavailableException\")) {\n\n\t\t\thandleSiteDeactivatedException();\n\t\t}\n\t\telse if (exception.equals(\n\t\t\t\t\t\"com.liferay.portal.kernel.jsonwebservice.\" +\n\t\t\t\t\t\t\"NoSuchJSONWebServiceException\")) {\n\n\t\t\tretryServerConnection(SyncAccount.UI_EVENT_SYNC_WEB_MISSING);\n\t\t}\n\t\telse if (exception.equals(\"Authenticated access required\") ||\n\t\t\t\t exception.equals(\"java.lang.SecurityException\")) {\n\n\t\t\tretryServerConnection(\n\t\t\t\tSyncAccount.UI_EVENT_AUTHENTICATION_EXCEPTION);\n\t\t}\n\t\telse {\n\t\t\tif (retryInProgress && _logger.isDebugEnabled()) {\n\t\t\t\t_logger.debug(\"Handling exception {}\", exception);\n\t\t\t}\n\n\t\t\tSyncFile syncFile = getLocalSyncFile();\n\n\t\t\tsyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\tsyncFile.setUiEvent(SyncFile.UI_EVENT_NONE);\n\n\t\t\tSyncFileService.update(syncFile);\n\t\t}\n\n\t\treturn true;\n\t}","commit_id":"26f297b083a4f6df1d9269805ec9ded7de764580","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void deleteFile(SyncFile sourceSyncFile, boolean trashed)\n\t\tthrows Exception {\n\n\t\tif (sourceSyncFile.getUiEvent() == SyncFile.UI_EVENT_DELETED_LOCAL) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (trashed) {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_TRASHED_REMOTE);\n\t\t}\n\t\telse {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_DELETED_REMOTE);\n\t\t}\n\n\t\tSyncFileService.deleteSyncFile(sourceSyncFile);\n\n\t\tPath sourceFilePath = Paths.get(sourceSyncFile.getFilePathName());\n\n\t\tif (Files.notExists(sourceFilePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (sourceSyncFile.isFile()) {\n\t\t\tFileUtil.deleteFile(sourceFilePath);\n\n\t\t\treturn;\n\t\t}\n\n\t\tfinal Watcher watcher = WatcherRegistry.getWatcher(getSyncAccountId());\n\n\t\tFiles.walkFileTree(\n\t\t\tsourceFilePath,\n\t\t\tnew SimpleFileVisitor<Path>() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(\n\t\t\t\t\t\tPath filePath, IOException ioe)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\twatcher.unregisterFilePath(filePath);\n\n\t\t\t\t\treturn super.preVisitDirectory(\n\t\t\t\t\t\tfilePath, basicFileAttributes);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t});\n\t}","id":37525,"modified_method":"protected void deleteFile(SyncFile sourceSyncFile, boolean trashed)\n\t\tthrows Exception {\n\n\t\tif (sourceSyncFile.getUiEvent() == SyncFile.UI_EVENT_DELETED_LOCAL) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (trashed) {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_TRASHED_REMOTE);\n\t\t}\n\t\telse {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_DELETED_REMOTE);\n\t\t}\n\n\t\tSyncFileService.deleteSyncFile(sourceSyncFile);\n\n\t\tPath sourceFilePath = Paths.get(sourceSyncFile.getFilePathName());\n\n\t\tif (Files.notExists(sourceFilePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tfinal Watcher watcher = WatcherRegistry.getWatcher(getSyncAccountId());\n\n\t\tfinal List<String> deletedFilePathNames =\n\t\t\twatcher.getDeletedFilePathNames();\n\n\t\tif (sourceSyncFile.isFile()) {\n\t\t\tdeletedFilePathNames.add(sourceSyncFile.getFilePathName());\n\n\t\t\tFileUtil.deleteFile(sourceFilePath);\n\n\t\t\treturn;\n\t\t}\n\n\t\tFiles.walkFileTree(\n\t\t\tsourceFilePath,\n\t\t\tnew SimpleFileVisitor<Path>() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(\n\t\t\t\t\t\tPath filePath, IOException ioe)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tif (ioe != null) {\n\t\t\t\t\t\treturn super.postVisitDirectory(filePath, ioe);\n\t\t\t\t\t}\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\twatcher.unregisterFilePath(filePath);\n\n\t\t\t\t\treturn super.preVisitDirectory(\n\t\t\t\t\t\tfilePath, basicFileAttributes);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t});\n\t}","commit_id":"26f297b083a4f6df1d9269805ec9ded7de764580","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected static void deleteSyncFiles(SyncSite syncSite)\n\t\tthrows IOException {\n\n\t\tList<SyncFile> syncFiles = SyncFileService.findSyncFilesByRepositoryId(\n\t\t\tsyncSite.getGroupId(), syncSite.getSyncAccountId());\n\n\t\tfor (SyncFile syncFile : syncFiles) {\n\t\t\tif (!syncFile.isSystem()) {\n\t\t\t\tSyncFileService.deleteSyncFile(syncFile, false);\n\t\t\t}\n\t\t}\n\n\t\tPath filePath = Paths.get(syncSite.getFilePathName());\n\n\t\tif (!Files.exists(filePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tFileUtils.deleteDirectory(filePath.toFile());\n\t}","id":37526,"modified_method":"protected static void deleteSyncFiles(SyncSite syncSite)\n\t\tthrows IOException {\n\n\t\tList<SyncFile> syncFiles = SyncFileService.findSyncFilesByRepositoryId(\n\t\t\tsyncSite.getGroupId(), syncSite.getSyncAccountId());\n\n\t\tfor (SyncFile syncFile : syncFiles) {\n\t\t\tif (!syncFile.isSystem()) {\n\t\t\t\tSyncFileService.deleteSyncFile(syncFile, false);\n\t\t\t}\n\t\t}\n\n\t\tPath filePath = Paths.get(syncSite.getFilePathName());\n\n\t\tif (!Files.exists(filePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tfinal Watcher watcher = WatcherRegistry.getWatcher(\n\t\t\tsyncSite.getSyncAccountId());\n\n\t\tfinal List<String> deletedFilePathNames =\n\t\t\twatcher.getDeletedFilePathNames();\n\n\t\tFiles.walkFileTree(\n\t\t\tfilePath,\n\t\t\tnew SimpleFileVisitor<Path>() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(\n\t\t\t\t\t\tPath filePath, IOException ioe)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tif (ioe != null) {\n\t\t\t\t\t\treturn super.postVisitDirectory(filePath, ioe);\n\t\t\t\t\t}\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t});\n\t}","commit_id":"26f297b083a4f6df1d9269805ec9ded7de764580","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void processWatchEvent(String eventType, Path filePath)\n\t\tthrows IOException {\n\n\t\t_watcherEventsLogger.trace(\"{}: {}\", eventType, filePath);\n\n\t\tif (!OSDetector.isLinux() &&\n\t\t\tfilePath.startsWith(_baseFilePath.resolve(\".data\"))) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tif (eventType.equals(SyncWatchEvent.EVENT_TYPE_CREATE)) {\n\t\t\tif (isIgnoredFilePath(filePath)) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\taddCreatedFilePathName(filePath.toString());\n\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString())) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(eventType, filePath);\n\n\t\t\tif (!OSDetector.isApple() && Files.isDirectory(filePath)) {\n\t\t\t\twalkFileTree(filePath);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_DELETE)) {\n\t\t\tif (Files.exists(filePath)) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tremoveCreatedFilePathName(filePath.toString());\n\n\t\t\tprocessMissingFilePath(filePath);\n\n\t\t\tif (Files.notExists(filePath.getParent())) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(SyncWatchEvent.EVENT_TYPE_DELETE, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MODIFY)) {\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString()) ||\n\t\t\t\t(removeCreatedFilePathName(filePath.toString()) &&\n\t\t\t\t !FileUtil.isValidChecksum(filePath)) ||\n\t\t\t\tFiles.notExists(filePath) || Files.isDirectory(filePath)) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(SyncWatchEvent.EVENT_TYPE_MODIFY, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME_FROM)) {\n\t\t\tremoveCreatedFilePathName(filePath.toString());\n\n\t\t\tprocessMissingFilePath(filePath);\n\n\t\t\tfireWatchEventListener(\n\t\t\t\tSyncWatchEvent.EVENT_TYPE_RENAME_FROM, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME_TO)) {\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString()) ||\n\t\t\t\tisIgnoredFilePath(filePath)) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(\n\t\t\t\tSyncWatchEvent.EVENT_TYPE_RENAME_TO, filePath);\n\t\t}\n\t}","id":37527,"modified_method":"protected void processWatchEvent(String eventType, Path filePath)\n\t\tthrows IOException {\n\n\t\t_watcherEventsLogger.trace(\"{}: {}\", eventType, filePath);\n\n\t\tif (!OSDetector.isLinux() &&\n\t\t\tfilePath.startsWith(_baseFilePath.resolve(\".data\"))) {\n\n\t\t\treturn;\n\t\t}\n\n\t\tif (eventType.equals(SyncWatchEvent.EVENT_TYPE_CREATE)) {\n\t\t\tif (isIgnoredFilePath(filePath)) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\taddCreatedFilePathName(filePath.toString());\n\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString())) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(eventType, filePath);\n\n\t\t\tif (!OSDetector.isApple() && Files.isDirectory(filePath)) {\n\t\t\t\twalkFileTree(filePath);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_DELETE)) {\n\t\t\tif (Files.exists(filePath)) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tremoveCreatedFilePathName(filePath.toString());\n\n\t\t\tif (_deletedFilePathNames.remove(filePath.toString())) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tprocessMissingFilePath(filePath);\n\n\t\t\tif (Files.notExists(filePath.getParent())) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(SyncWatchEvent.EVENT_TYPE_DELETE, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MODIFY)) {\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString()) ||\n\t\t\t\t(removeCreatedFilePathName(filePath.toString()) &&\n\t\t\t\t !FileUtil.isValidChecksum(filePath)) ||\n\t\t\t\tFiles.notExists(filePath) || Files.isDirectory(filePath)) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(SyncWatchEvent.EVENT_TYPE_MODIFY, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME_FROM)) {\n\t\t\tremoveCreatedFilePathName(filePath.toString());\n\n\t\t\tprocessMissingFilePath(filePath);\n\n\t\t\tfireWatchEventListener(\n\t\t\t\tSyncWatchEvent.EVENT_TYPE_RENAME_FROM, filePath);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME_TO)) {\n\t\t\tif (_downloadedFilePathNames.remove(filePath.toString()) ||\n\t\t\t\tisIgnoredFilePath(filePath)) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfireWatchEventListener(\n\t\t\t\tSyncWatchEvent.EVENT_TYPE_RENAME_TO, filePath);\n\t\t}\n\t}","commit_id":"26f297b083a4f6df1d9269805ec9ded7de764580","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void executeAsynchronousPost(\n\t\t\tfinal String urlPath, final Map<String, Object> parameters,\n\t\t\tfinal Handler<Void> handler)\n\t\tthrows Exception {\n\n\t\tRunnable runnable = new Runnable() {\n\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttry {\n\t\t\t\t\texecutePost(urlPath, parameters, handler);\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t\thandler.handleException(e);\n\t\t\t\t}\n\t\t\t}\n\n\t\t};\n\n\t\t_executorService.execute(runnable);\n\t}","id":37528,"modified_method":"public void executeAsynchronousPost(\n\t\t\tfinal String urlPath, final Map<String, Object> parameters,\n\t\t\tfinal Handler<Void> handler)\n\t\tthrows Exception {\n\n\t\tRunnable runnable = new Runnable() {\n\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttry {\n\t\t\t\t\texecutePost(urlPath, parameters, handler);\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\thandler.handleException(e);\n\t\t\t\t}\n\t\t\t}\n\n\t\t};\n\n\t\t_executorService.execute(runnable);\n\t}","commit_id":"52141c538e32334db6db94e2b5dcbbd5fa7e1cc5","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void processSyncWatchEvent(SyncWatchEvent syncWatchEvent)\n\t\tthrows Exception {\n\n\t\tSyncAccount syncAccount = SyncAccountService.fetchSyncAccount(\n\t\t\t_syncAccountId);\n\n\t\tif (syncAccount.getState() != SyncAccount.STATE_CONNECTED) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (_processedSyncWatchEventIds.contains(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId())) {\n\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\n\t\t\treturn;\n\t\t}\n\n\t\tif (_logger.isDebugEnabled()) {\n\t\t\t_logger.debug(\n\t\t\t\t\"Event type {} file path {} file type {} timestamp {}\",\n\t\t\t\tsyncWatchEvent.getEventType(), syncWatchEvent.getFilePathName(),\n\t\t\t\tsyncWatchEvent.getFileType(), syncWatchEvent.getTimestamp());\n\t\t}\n\n\t\tString fileType = syncWatchEvent.getFileType();\n\n\t\tString eventType = syncWatchEvent.getEventType();\n\n\t\tif (eventType.equals(SyncWatchEvent.EVENT_TYPE_CREATE)) {\n\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\taddFile(syncWatchEvent);\n\t\t\t}\n\t\t\telse {\n\t\t\t\taddFolder(syncWatchEvent);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_DELETE)) {\n\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\tdeleteFile(syncWatchEvent);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tdeleteFolder(syncWatchEvent);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MODIFY)) {\n\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\tmodifyFile(syncWatchEvent);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MOVE)) {\n\t\t\tmoveFile(syncWatchEvent);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME)) {\n\t\t\trenameFile(syncWatchEvent);\n\t\t}\n\n\t\tsyncAccount = SyncAccountService.fetchSyncAccount(_syncAccountId);\n\n\t\tif (syncAccount.getState() == SyncAccount.STATE_CONNECTED) {\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\t\t}\n\t}","id":37529,"modified_method":"protected void processSyncWatchEvent(SyncWatchEvent syncWatchEvent)\n\t\tthrows Exception {\n\n\t\tSyncAccount syncAccount = SyncAccountService.fetchSyncAccount(\n\t\t\t_syncAccountId);\n\n\t\tif (syncAccount.getState() != SyncAccount.STATE_CONNECTED) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (_processedSyncWatchEventIds.contains(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId())) {\n\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\n\t\t\treturn;\n\t\t}\n\n\t\tif (_logger.isDebugEnabled()) {\n\t\t\t_logger.debug(\n\t\t\t\t\"Event type {} file path {} file type {} timestamp {}\",\n\t\t\t\tsyncWatchEvent.getEventType(), syncWatchEvent.getFilePathName(),\n\t\t\t\tsyncWatchEvent.getFileType(), syncWatchEvent.getTimestamp());\n\t\t}\n\n\t\tString fileType = syncWatchEvent.getFileType();\n\n\t\tString eventType = syncWatchEvent.getEventType();\n\n\t\tif (eventType.equals(SyncWatchEvent.EVENT_TYPE_CREATE)) {\n\t\t\tif (fileType.equals(SyncFile.TYPE_FILE)) {\n\t\t\t\taddFile(syncWatchEvent);\n\t\t\t}\n\t\t\telse {\n\t\t\t\taddFolder(syncWatchEvent);\n\t\t\t}\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_DELETE)) {\n\t\t\tdeleteFile(syncWatchEvent);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MODIFY)) {\n\t\t\tmodifyFile(syncWatchEvent);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_MOVE)) {\n\t\t\tmoveFile(syncWatchEvent);\n\t\t}\n\t\telse if (eventType.equals(SyncWatchEvent.EVENT_TYPE_RENAME)) {\n\t\t\trenameFile(syncWatchEvent);\n\t\t}\n\n\t\tsyncAccount = SyncAccountService.fetchSyncAccount(_syncAccountId);\n\n\t\tif (syncAccount.getState() == SyncAccount.STATE_CONNECTED) {\n\t\t\tSyncWatchEventService.deleteSyncWatchEvent(\n\t\t\t\tsyncWatchEvent.getSyncWatchEventId());\n\t\t}\n\t}","commit_id":"52141c538e32334db6db94e2b5dcbbd5fa7e1cc5","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void deleteFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(filePath.toString());\n\n\t\tif ((syncFile == null) ||\n\t\t\tFiles.exists(Paths.get(syncFile.getFilePathName()))) {\n\n\t\t\treturn;\n\t\t}\n\t\telse if ((syncFile.getState() == SyncFile.STATE_ERROR) ||\n\t\t\t\t (syncFile.getState() == SyncFile.STATE_UNSYNCED)) {\n\n\t\t\tSyncFileService.deleteSyncFile(syncFile);\n\n\t\t\treturn;\n\t\t}\n\t\telse if (isPendingTypePK(syncFile)) {\n\t\t\tqueueSyncWatchEvent(syncFile.getFilePathName(), syncWatchEvent);\n\n\t\t\treturn;\n\t\t}\n\n\t\tFileEventUtil.deleteFile(_syncAccountId, syncFile);\n\t}","id":37530,"modified_method":"protected void deleteFile(SyncWatchEvent syncWatchEvent) throws Exception {\n\t\tPath filePath = Paths.get(syncWatchEvent.getFilePathName());\n\n\t\tSyncFile syncFile = SyncFileService.fetchSyncFile(filePath.toString());\n\n\t\tif ((syncFile == null) ||\n\t\t\tFiles.exists(Paths.get(syncFile.getFilePathName()))) {\n\n\t\t\treturn;\n\t\t}\n\t\telse if ((syncFile.getState() == SyncFile.STATE_ERROR) ||\n\t\t\t\t (syncFile.getState() == SyncFile.STATE_UNSYNCED)) {\n\n\t\t\tSyncFileService.deleteSyncFile(syncFile);\n\n\t\t\treturn;\n\t\t}\n\t\telse if (isPendingTypePK(syncFile)) {\n\t\t\tqueueSyncWatchEvent(syncFile.getFilePathName(), syncWatchEvent);\n\n\t\t\treturn;\n\t\t}\n\n\t\tString type = syncFile.getType();\n\n\t\tif (type.equals(SyncFile.TYPE_FILE)) {\n\t\t\tFileEventUtil.deleteFile(_syncAccountId, syncFile);\n\t\t}\n\t\telse {\n\t\t\tFileEventUtil.deleteFolder(_syncAccountId, syncFile);\n\t\t}\n\t}","commit_id":"52141c538e32334db6db94e2b5dcbbd5fa7e1cc5","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void deleteFile(SyncFile sourceSyncFile, boolean trashed)\n\t\tthrows Exception {\n\n\t\tif (sourceSyncFile.getUiEvent() == SyncFile.UI_EVENT_DELETED_LOCAL) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (trashed) {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_TRASHED_REMOTE);\n\t\t}\n\t\telse {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_DELETED_REMOTE);\n\t\t}\n\n\t\tSyncFileService.deleteSyncFile(sourceSyncFile);\n\n\t\tPath sourceFilePath = Paths.get(sourceSyncFile.getFilePathName());\n\n\t\tif (Files.notExists(sourceFilePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tfinal Watcher watcher = WatcherManager.getWatcher(getSyncAccountId());\n\n\t\tfinal List<String> deletedFilePathNames =\n\t\t\twatcher.getDeletedFilePathNames();\n\n\t\tif (sourceSyncFile.isFile()) {\n\t\t\tdeletedFilePathNames.add(sourceSyncFile.getFilePathName());\n\n\t\t\tFileUtil.deleteFile(sourceFilePath);\n\n\t\t\treturn;\n\t\t}\n\n\t\tFiles.walkFileTree(\n\t\t\tsourceFilePath,\n\t\t\tnew SimpleFileVisitor<Path>() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(\n\t\t\t\t\t\tPath filePath, IOException ioe)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tif (ioe != null) {\n\t\t\t\t\t\treturn super.postVisitDirectory(filePath, ioe);\n\t\t\t\t\t}\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\twatcher.unregisterFilePath(filePath);\n\n\t\t\t\t\treturn super.preVisitDirectory(\n\t\t\t\t\t\tfilePath, basicFileAttributes);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t});\n\t}","id":37531,"modified_method":"protected void deleteFile(SyncFile sourceSyncFile, SyncFile targetSyncFile)\n\t\tthrows Exception {\n\n\t\tif (sourceSyncFile.getUiEvent() == SyncFile.UI_EVENT_DELETED_LOCAL) {\n\t\t\treturn;\n\t\t}\n\n\t\tsourceSyncFile.setModifiedTime(targetSyncFile.getModifiedTime());\n\n\t\tif (targetSyncFile.getEvent() == SyncFile.EVENT_TRASH) {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_TRASHED_REMOTE);\n\t\t}\n\t\telse {\n\t\t\tsourceSyncFile.setUiEvent(SyncFile.UI_EVENT_DELETED_REMOTE);\n\t\t}\n\n\t\tSyncFileService.deleteSyncFile(sourceSyncFile);\n\n\t\tPath sourceFilePath = Paths.get(sourceSyncFile.getFilePathName());\n\n\t\tif (Files.notExists(sourceFilePath)) {\n\t\t\treturn;\n\t\t}\n\n\t\tfinal Watcher watcher = WatcherManager.getWatcher(getSyncAccountId());\n\n\t\tfinal List<String> deletedFilePathNames =\n\t\t\twatcher.getDeletedFilePathNames();\n\n\t\tif (sourceSyncFile.isFile()) {\n\t\t\tdeletedFilePathNames.add(sourceSyncFile.getFilePathName());\n\n\t\t\tFileUtil.deleteFile(sourceFilePath);\n\n\t\t\treturn;\n\t\t}\n\n\t\tFiles.walkFileTree(\n\t\t\tsourceFilePath,\n\t\t\tnew SimpleFileVisitor<Path>() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(\n\t\t\t\t\t\tPath filePath, IOException ioe)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tif (ioe != null) {\n\t\t\t\t\t\treturn super.postVisitDirectory(filePath, ioe);\n\t\t\t\t\t}\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\twatcher.unregisterFilePath(filePath);\n\n\t\t\t\t\treturn super.preVisitDirectory(\n\t\t\t\t\t\tfilePath, basicFileAttributes);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(\n\t\t\t\t\t\tPath filePath, BasicFileAttributes basicFileAttributes)\n\t\t\t\t\tthrows IOException {\n\n\t\t\t\t\tdeletedFilePathNames.add(filePath.toString());\n\n\t\t\t\t\tFileUtil.deleteFile(filePath);\n\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\n\t\t\t});\n\t}","commit_id":"1621ccda0f156a3290b9a02c939a750c8ee34f3d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected void processSyncFile(SyncFile targetSyncFile) {\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\ttargetSyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\ttargetSyncFile.getParentFolderId());\n\n\t\tif (parentSyncFile == null) {\n\t\t\tqueueSyncFile(targetSyncFile.getParentFolderId(), targetSyncFile);\n\n\t\t\treturn;\n\t\t}\n\n\t\tString filePathName = \"\";\n\n\t\ttry {\n\t\t\tfilePathName = FileUtil.getFilePathName(\n\t\t\t\tparentSyncFile.getFilePathName(),\n\t\t\t\tFileUtil.getSanitizedFileName(\n\t\t\t\t\ttargetSyncFile.getName(), targetSyncFile.getExtension()));\n\n\t\t\tSyncFile sourceSyncFile = SyncFileService.fetchSyncFile(\n\t\t\t\ttargetSyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\t\ttargetSyncFile.getTypePK());\n\n\t\t\tif (isIgnoredFilePath(sourceSyncFile, filePathName) ||\n\t\t\t\t((sourceSyncFile != null) &&\n\t\t\t\t (sourceSyncFile.getModifiedTime() ==\n\t\t\t\t\t targetSyncFile.getModifiedTime()))) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (sourceSyncFile != null) {\n\t\t\t\tsourceSyncFile.setState(SyncFile.STATE_IN_PROGRESS);\n\t\t\t}\n\n\t\t\ttargetSyncFile.setFilePathName(filePathName);\n\t\t\ttargetSyncFile.setState(SyncFile.STATE_IN_PROGRESS);\n\n\t\t\tString event = targetSyncFile.getEvent();\n\n\t\t\tif (event.equals(SyncFile.EVENT_ADD) ||\n\t\t\t\tevent.equals(SyncFile.EVENT_GET)) {\n\n\t\t\t\tif (sourceSyncFile != null) {\n\t\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(sourceSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taddFile(targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_DELETE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tdeleteFile(sourceSyncFile, false);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_MOVE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\taddFile(targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tmoveFile(sourceSyncFile, targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_RESTORE)) {\n\t\t\t\tif (sourceSyncFile != null) {\n\t\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(sourceSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\ttargetSyncFile.setLocalExtraSetting(\"restoreEvent\", true);\n\n\t\t\t\tSyncFileService.update(targetSyncFile);\n\n\t\t\t\taddFile(targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_TRASH)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tdeleteFile(sourceSyncFile, true);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_UPDATE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\taddFile(targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\t\t\t}\n\n\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\t\t}\n\t\tcatch (FileSystemException fse) {\n\t\t\tString message = fse.getMessage();\n\n\t\t\tif (message.contains(\"File name too long\")) {\n\t\t\t\ttargetSyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\t\ttargetSyncFile.setUiEvent(SyncFile.UI_EVENT_FILE_NAME_TOO_LONG);\n\n\t\t\t\tSyncFileService.update(targetSyncFile);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_logger.error(e.getMessage(), e);\n\t\t}\n\t}","id":37532,"modified_method":"protected void processSyncFile(SyncFile targetSyncFile) {\n\t\tSyncFile parentSyncFile = SyncFileService.fetchSyncFile(\n\t\t\ttargetSyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\ttargetSyncFile.getParentFolderId());\n\n\t\tif (parentSyncFile == null) {\n\t\t\tqueueSyncFile(targetSyncFile.getParentFolderId(), targetSyncFile);\n\n\t\t\treturn;\n\t\t}\n\n\t\tString filePathName = \"\";\n\n\t\ttry {\n\t\t\tfilePathName = FileUtil.getFilePathName(\n\t\t\t\tparentSyncFile.getFilePathName(),\n\t\t\t\tFileUtil.getSanitizedFileName(\n\t\t\t\t\ttargetSyncFile.getName(), targetSyncFile.getExtension()));\n\n\t\t\tSyncFile sourceSyncFile = SyncFileService.fetchSyncFile(\n\t\t\t\ttargetSyncFile.getRepositoryId(), getSyncAccountId(),\n\t\t\t\ttargetSyncFile.getTypePK());\n\n\t\t\tif (isIgnoredFilePath(sourceSyncFile, filePathName) ||\n\t\t\t\t((sourceSyncFile != null) &&\n\t\t\t\t (sourceSyncFile.getModifiedTime() ==\n\t\t\t\t\t targetSyncFile.getModifiedTime()))) {\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (sourceSyncFile != null) {\n\t\t\t\tsourceSyncFile.setState(SyncFile.STATE_IN_PROGRESS);\n\t\t\t}\n\n\t\t\ttargetSyncFile.setFilePathName(filePathName);\n\t\t\ttargetSyncFile.setState(SyncFile.STATE_IN_PROGRESS);\n\n\t\t\tString event = targetSyncFile.getEvent();\n\n\t\t\tif (event.equals(SyncFile.EVENT_ADD) ||\n\t\t\t\tevent.equals(SyncFile.EVENT_GET)) {\n\n\t\t\t\tif (sourceSyncFile != null) {\n\t\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(sourceSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taddFile(targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_DELETE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tdeleteFile(sourceSyncFile, targetSyncFile);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_MOVE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\taddFile(targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tmoveFile(sourceSyncFile, targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_RESTORE)) {\n\t\t\t\tif (sourceSyncFile != null) {\n\t\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(sourceSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\ttargetSyncFile.setLocalExtraSetting(\"restoreEvent\", true);\n\n\t\t\t\tSyncFileService.update(targetSyncFile);\n\n\t\t\t\taddFile(targetSyncFile, filePathName);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_TRASH)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tdeleteFile(sourceSyncFile, targetSyncFile);\n\t\t\t}\n\t\t\telse if (event.equals(SyncFile.EVENT_UPDATE)) {\n\t\t\t\tif (sourceSyncFile == null) {\n\t\t\t\t\taddFile(targetSyncFile, filePathName);\n\n\t\t\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tupdateFile(sourceSyncFile, targetSyncFile, filePathName);\n\t\t\t}\n\n\t\t\tprocessDependentSyncFiles(targetSyncFile);\n\t\t}\n\t\tcatch (FileSystemException fse) {\n\t\t\tString message = fse.getMessage();\n\n\t\t\tif (message.contains(\"File name too long\")) {\n\t\t\t\ttargetSyncFile.setState(SyncFile.STATE_ERROR);\n\t\t\t\ttargetSyncFile.setUiEvent(SyncFile.UI_EVENT_FILE_NAME_TOO_LONG);\n\n\t\t\t\tSyncFileService.update(targetSyncFile);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_logger.error(e.getMessage(), e);\n\t\t}\n\t}","commit_id":"1621ccda0f156a3290b9a02c939a750c8ee34f3d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void smartCheck(@NotNull final Project project,\n                         @NotNull final VirtualFile answerFile,\n                         @NotNull final TaskFile answerTaskFile,\n                         @NotNull final TaskFile usersTaskFile,\n                         @NotNull final StudyTestRunner testRunner,\n                         @NotNull final VirtualFile virtualFile,\n                         @NotNull final Document usersDocument) {\n\n    try {\n      final VirtualFile windowCopy =\n        answerFile.copy(this, answerFile.getParent(), answerFile.getNameWithoutExtension() + myIndex + WINDOW_POSTFIX);\n      final FileDocumentManager documentManager = FileDocumentManager.getInstance();\n      final Document windowDocument = documentManager.getDocument(windowCopy);\n      if (windowDocument != null) {\n        final File resourceFile = StudyUtils.copyResourceFile(virtualFile.getName(), windowCopy.getName(), project, usersTaskFile.getTask());\n        final TaskFile windowTaskFile = new TaskFile();\n        TaskFile.copy(answerTaskFile, windowTaskFile);\n        StudyDocumentListener listener = new StudyDocumentListener(windowTaskFile);\n        windowDocument.addDocumentListener(listener);\n        int start = getRealStartOffset(windowDocument);\n        int end = start + getLength();\n        final AnswerPlaceholder userAnswerPlaceholder = usersTaskFile.getAnswerPlaceholders().get(getIndex());\n        int userStart = userAnswerPlaceholder.getRealStartOffset(usersDocument);\n        int userEnd = userStart + userAnswerPlaceholder.getLength();\n        String text = usersDocument.getText(new TextRange(userStart, userEnd));\n        windowDocument.replaceString(start, end, text);\n        ApplicationManager.getApplication().runWriteAction(new Runnable() {\n          @Override\n          public void run() {\n            documentManager.saveDocument(windowDocument);\n          }\n        });\n        VirtualFile fileWindows = StudyUtils.flushWindows(windowTaskFile, windowCopy);\n        Process smartTestProcess = testRunner.createCheckProcess(project, windowCopy.getPath());\n        final CapturingProcessHandler handler = new CapturingProcessHandler(smartTestProcess);\n        final ProcessOutput output = handler.runProcess();\n        boolean res = testRunner.getTestsOutput(output).equals(StudyTestRunner.TEST_OK);\n        userAnswerPlaceholder.setStatus(res ? StudyStatus.Solved : StudyStatus.Failed, StudyStatus.Unchecked);\n        StudyUtils.deleteFile(windowCopy);\n        StudyUtils.deleteFile(fileWindows);\n        if (!resourceFile.delete()) {\n          LOG.error(\"failed to delete\", resourceFile.getPath());\n        }\n      }\n    }\n    catch (ExecutionException e) {\n      LOG.error(e);\n    }\n    catch (IOException e) {\n      LOG.error(e);\n    }\n  }","id":37533,"modified_method":"public void smartCheck(@NotNull final Project project,\n                         @NotNull final VirtualFile answerFile,\n                         @NotNull final TaskFile answerTaskFile,\n                         @NotNull final TaskFile usersTaskFile,\n                         @NotNull final StudyTestRunner testRunner,\n                         @NotNull final VirtualFile virtualFile,\n                         @NotNull final Document usersDocument) {\n\n    try {\n      final VirtualFile windowCopy =\n        answerFile.copy(this, answerFile.getParent(), answerFile.getNameWithoutExtension() + myIndex + WINDOW_POSTFIX);\n      final FileDocumentManager documentManager = FileDocumentManager.getInstance();\n      final Document windowDocument = documentManager.getDocument(windowCopy);\n      if (windowDocument != null) {\n        final File resourceFile = StudyUtils.copyResourceFile(virtualFile.getName(), windowCopy.getName(), project, usersTaskFile.getTask());\n        final TaskFile windowTaskFile = new TaskFile();\n        TaskFile.copy(answerTaskFile, windowTaskFile);\n        StudyDocumentListener listener = new StudyDocumentListener(windowTaskFile);\n        windowDocument.addDocumentListener(listener);\n        int start = getRealStartOffset(windowDocument);\n        int end = start + getLength();\n        final AnswerPlaceholder userAnswerPlaceholder = usersTaskFile.getAnswerPlaceholders().get(getIndex());\n        int userStart = userAnswerPlaceholder.getRealStartOffset(usersDocument);\n        int userEnd = userStart + userAnswerPlaceholder.getLength();\n        String text = usersDocument.getText(new TextRange(userStart, userEnd));\n        windowDocument.replaceString(start, end, text);\n        ApplicationManager.getApplication().runWriteAction(new Runnable() {\n          @Override\n          public void run() {\n            documentManager.saveDocument(windowDocument);\n          }\n        });\n        VirtualFile fileWindows = StudyUtils.flushWindows(windowTaskFile, windowCopy);\n        Process smartTestProcess = testRunner.createCheckProcess(project, windowCopy.getPath());\n        final CapturingProcessHandler handler = new CapturingProcessHandler(smartTestProcess);\n        final ProcessOutput output = handler.runProcess();\n        boolean res = testRunner.getTestsOutput(output).equals(StudyTestRunner.TEST_OK);\n        userAnswerPlaceholder.setStatus(res ? StudyStatus.Solved : StudyStatus.Failed, StudyStatus.Unchecked);\n        StudyUtils.deleteFile(windowCopy);\n        if (fileWindows != null) {\n          StudyUtils.deleteFile(fileWindows);\n        }\n        if (!resourceFile.delete()) {\n          LOG.error(\"failed to delete\", resourceFile.getPath());\n        }\n      }\n    }\n    catch (ExecutionException e) {\n      LOG.error(e);\n    }\n    catch (IOException e) {\n      LOG.error(e);\n    }\n  }","commit_id":"49cb7159c382b39df505e59ba3d78177108f051d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n   * Draw task window with color according to its status\n   */\n  public void draw(@NotNull final Editor editor, boolean drawSelection, boolean moveCaret) {\n    Document document = editor.getDocument();\n    if (!isValid(document)) {\n      return;\n    }\n    TextAttributes defaultTestAttributes =\n      EditorColorsManager.getInstance().getGlobalScheme().getAttributes(EditorColors.LIVE_TEMPLATE_ATTRIBUTES);\n    JBColor color = getColor();\n    int startOffset = document.getLineStartOffset(line) + start;\n    RangeHighlighter\n      rh = editor.getMarkupModel().addRangeHighlighter(startOffset, startOffset + length, HighlighterLayer.LAST + 1,\n                                                       new TextAttributes(defaultTestAttributes.getForegroundColor(),\n                                                                          defaultTestAttributes.getBackgroundColor(), color,\n                                                                          defaultTestAttributes.getEffectType(),\n                                                                          defaultTestAttributes.getFontType()),\n                                                       HighlighterTargetArea.EXACT_RANGE);\n    if (drawSelection) {\n      editor.getSelectionModel().setSelection(startOffset, startOffset + length);\n    }\n    if (moveCaret) {\n      editor.getCaretModel().moveToOffset(startOffset);\n    }\n    rh.setGreedyToLeft(true);\n    rh.setGreedyToRight(true);\n  }","id":37534,"modified_method":"/**\n   * Draw task window with color according to its status\n   */\n  public void draw(@NotNull final Editor editor, boolean drawSelection, boolean moveCaret) {\n    Document document = editor.getDocument();\n    if (!isValid(document)) {\n      return;\n    }\n    TextAttributes defaultTestAttributes =\n      EditorColorsManager.getInstance().getGlobalScheme().getAttributes(EditorColors.LIVE_TEMPLATE_ATTRIBUTES);\n    JBColor color = getColor();\n    int startOffset = document.getLineStartOffset(line) + start;\n    RangeHighlighter highlighter = editor.getMarkupModel().addRangeHighlighter(startOffset, startOffset + length, HighlighterLayer.LAST + 1,\n                                                       new TextAttributes(defaultTestAttributes.getForegroundColor(),\n                                                                          defaultTestAttributes.getBackgroundColor(), color,\n                                                                          defaultTestAttributes.getEffectType(),\n                                                                          defaultTestAttributes.getFontType()),\n                                                       HighlighterTargetArea.EXACT_RANGE);\n    if (drawSelection) {\n      editor.getSelectionModel().setSelection(startOffset, startOffset + length);\n    }\n    if (moveCaret) {\n      editor.getCaretModel().moveToOffset(startOffset);\n    }\n    highlighter.setGreedyToLeft(true);\n    highlighter.setGreedyToRight(true);\n  }","commit_id":"49cb7159c382b39df505e59ba3d78177108f051d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n    protected void textChanged(DocumentEvent e) {\n      myBuffer.delete(0, myBuffer.length());\n      try {\n        myBuffer.append(e.getDocument().getText(0, e.getDocument().getLength()));\n      }\n      catch (BadLocationException e1) {\n        e1.printStackTrace();\n      }\n    }","id":37535,"modified_method":"@Override\n    protected void textChanged(DocumentEvent e) {\n      myBuffer.delete(0, myBuffer.length());\n      try {\n        myBuffer.append(e.getDocument().getText(0, e.getDocument().getLength()));\n      }\n      catch (BadLocationException exception) {\n        LOG.warn(exception);\n      }\n    }","commit_id":"49cb7159c382b39df505e59ba3d78177108f051d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  @Override\n  public Collection<AbstractTreeNode> modify(@NotNull AbstractTreeNode parent,\n                                             @NotNull Collection<AbstractTreeNode> children,\n                                             ViewSettings settings) {\n    if (!needModify(parent)) {\n      return children;\n    }\n    Collection<AbstractTreeNode> nodes = new ArrayList<AbstractTreeNode>();\n    for (AbstractTreeNode node : children) {\n      Project project = node.getProject();\n      if (project != null) {\n        if (node.getValue() instanceof PsiDirectory) {\n          PsiDirectory nodeValue = (PsiDirectory)node.getValue();\n          if (!nodeValue.getName().contains(Task.USER_TESTS)) {\n            StudyDirectoryNode newNode = new StudyDirectoryNode(project, nodeValue, settings);\n            nodes.add(newNode);\n          }\n        }\n        else {\n          if (parent instanceof StudyDirectoryNode) {\n            if (node instanceof PsiFileNode) {\n              PsiFileNode psiFileNode = (PsiFileNode)node;\n              VirtualFile virtualFile = psiFileNode.getVirtualFile();\n              if (virtualFile == null) {\n                return nodes;\n              }\n              TaskFile taskFile = StudyTaskManager.getInstance(project).getTaskFile(virtualFile);\n              if (taskFile != null) {\n                nodes.add(node);\n              }\n              String parentName = parent.getName();\n              if (parentName != null) {\n                if (parentName.equals(Course.SANDBOX_DIR)) {\n                  nodes.add(node);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    return nodes;\n  }","id":37536,"modified_method":"@NotNull\n  @Override\n  public Collection<AbstractTreeNode> modify(@NotNull AbstractTreeNode parent,\n                                             @NotNull Collection<AbstractTreeNode> children,\n                                             ViewSettings settings) {\n    if (!isCourseBasedProject(parent)) {\n      return children;\n    }\n    Collection<AbstractTreeNode> nodes = new ArrayList<AbstractTreeNode>();\n    for (AbstractTreeNode node : children) {\n      final Project project = node.getProject();\n      if (project != null) {\n        if (node.getValue() instanceof PsiDirectory) {\n          final PsiDirectory nodeValue = (PsiDirectory)node.getValue();\n          if (!nodeValue.getName().contains(Task.USER_TESTS)) {\n            StudyDirectoryNode newNode = new StudyDirectoryNode(project, nodeValue, settings);\n            nodes.add(newNode);\n          }\n        }\n        else {\n          if (parent instanceof StudyDirectoryNode && node instanceof PsiFileNode) {\n            final PsiFileNode psiFileNode = (PsiFileNode)node;\n            final VirtualFile virtualFile = psiFileNode.getVirtualFile();\n            if (virtualFile == null) {\n              return nodes;\n            }\n            final TaskFile taskFile = StudyTaskManager.getInstance(project).getTaskFile(virtualFile);\n            if (taskFile != null) {\n              nodes.add(node);\n            }\n            final String parentName = parent.getName();\n            if (parentName != null) {\n              if (parentName.equals(Course.SANDBOX_DIR)) {\n                nodes.add(node);\n              }\n            }\n          }\n        }\n      }\n    }\n    return nodes;\n  }","commit_id":"49cb7159c382b39df505e59ba3d78177108f051d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static boolean needModify(AbstractTreeNode parent) {\n    Project project = parent.getProject();\n    if (project != null) {\n      StudyTaskManager studyTaskManager = StudyTaskManager.getInstance(project);\n      if (studyTaskManager.getCourse() == null) {\n        return false;\n      }\n    }\n    return true;\n  }","id":37537,"modified_method":"private static boolean isCourseBasedProject(@NotNull final AbstractTreeNode parent) {\n    final Project project = parent.getProject();\n    if (project != null) {\n      final StudyTaskManager studyTaskManager = StudyTaskManager.getInstance(project);\n      if (studyTaskManager.getCourse() == null) {\n        return false;\n      }\n    }\n    return true;\n  }","commit_id":"49cb7159c382b39df505e59ba3d78177108f051d","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  protected JComponent createCenterPanel() {\n    final JPanel panel = new JPanel(new GridBagLayout());\n    final GridBagConstraints gbc = new GridBagConstraints();\n\n    gbc.insets = new Insets(4, 8, 4, 8);\n    gbc.weighty = 1;\n    gbc.weightx = 1;\n    gbc.gridx = 0;\n    gbc.gridy = 0;\n    gbc.gridwidth = 2;\n    gbc.fill = GridBagConstraints.BOTH;\n    gbc.anchor = GridBagConstraints.WEST;\n    panel.add(new JLabel(myMessage), gbc);\n\n    myCheckBoxes = new JCheckBox[myOptions.length];\n    for (int i = 0; i < myOptions.length; i++) {\n      gbc.gridy++;\n      gbc.gridx = 0;\n      gbc.weightx = 0.0;\n      gbc.gridwidth = 1;\n      gbc.insets = new Insets(4, 8, 0, 8);\n\n      DeleteOption option = myOptions[i];\n      myCheckBoxes[i] = new JCheckBox(option.caption, option.selected);\n      myCheckBoxes[i].setEnabled(option.enabled);\n      panel.add(myCheckBoxes[i], gbc);\n    }\n\n    return panel;\n  }","id":37538,"modified_method":"@Override\n  protected JComponent createCenterPanel() {\n    final JPanel panel = new JBPanel(new GridBagLayout());\n    final GridBagConstraints gbc = new GridBagConstraints();\n\n    gbc.insets = new Insets(4, 8, 4, 8);\n    gbc.weighty = 1;\n    gbc.weightx = 1;\n    gbc.gridx = 0;\n    gbc.gridy = 0;\n    gbc.gridwidth = 2;\n    gbc.fill = GridBagConstraints.BOTH;\n    gbc.anchor = GridBagConstraints.WEST;\n    panel.add(new JBLabel(myMessage), gbc);\n\n    myCheckBoxes = new JCheckBox[myOptions.length];\n    for (int i = 0; i < myOptions.length; i++) {\n      gbc.gridy++;\n      gbc.gridx = 0;\n      gbc.weightx = 0.0;\n      gbc.gridwidth = 1;\n      gbc.insets = new Insets(4, 8, 0, 8);\n\n      DeleteOption option = myOptions[i];\n      myCheckBoxes[i] = new JBCheckBox(option.caption, option.selected);\n      myCheckBoxes[i].setEnabled(option.enabled);\n      panel.add(myCheckBoxes[i], gbc);\n    }\n\n    return panel;\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"private static void delete(MPSProject project, SModule module, boolean deleteFiles) {\n    //HACK: generator module is not project module, so need to check it separately\n    if (!project.isProjectModule(module instanceof Generator ? ((Generator) module).getSourceLanguage() : module) && !deleteFiles) {\n      throw new IllegalArgumentException(\"Non-project modules can only be deleted with files deletion enabled\");\n    }\n\n    //see MPS-18743\n    project.getRepository().saveAll();\n\n    if (deleteFiles) {\n      for (SModel model : module.getModels()) {\n        DeleteModelHelper.delete(module, model, true);\n      }\n\n      if (module.getFacet(JavaModuleFacet.class) != null) {\n        IFile classesGen = module.getFacet(JavaModuleFacet.class).getClassesGen();\n        if (classesGen != null) {\n          deleteFile(classesGen.toPath().toString());\n        }\n      }\n      if (module.getFacet(TestsFacet.class) != null) {\n        final IFile testsOutputPath = module.getFacet(TestsFacet.class).getTestsOutputPath();\n        if (testsOutputPath != null) {\n          deleteFile(testsOutputPath.toPath().toString());\n        }\n      }\n\n      if (module instanceof AbstractModule) {\n        AbstractModule curModule = (AbstractModule) module;\n        String outputPath = curModule.getOutputPath().toPath().toString();\n        deleteFile(outputPath);\n        deleteFile(FileGenerationUtil.getCachesPath(outputPath));\n\n        if (curModule.getDescriptorFile() != null) {\n          curModule.getDescriptorFile().delete();\n        }\n\n        if (curModule.getModuleSourceDir() != null && curModule.getModuleSourceDir().getChildren().isEmpty()) {\n          deleteFile(curModule.getModuleSourceDir().toPath().toString());\n        }\n\n        if (curModule.getDescriptorFile() != null) {\n          IFile moduleFolder = curModule.getDescriptorFile().getParent();\n          if (moduleFolder !=null && deleteDirIfEmpty(moduleFolder)) {\n            moduleFolder.delete();\n          }\n        }\n      }\n    }\n\n    //remove from project\n    if (project.isProjectModule(module)) {\n      final SRepository repository = project.getRepository();\n      if (repository instanceof SRepositoryExt) {\n        ((SRepositoryExt) repository).unregisterModule(module, project);\n      }\n      project.removeModule(module);\n      project.save();\n\n      ((StandaloneMPSProject) project).update();\n    }\n\n    if (deleteFiles) {\n      new ModuleRepositoryFacade(project.getRepository()).removeModuleForced(module);\n    }\n  }","id":37539,"modified_method":"private static void delete(MPSProject project, SModule module, boolean deleteFiles) {\n    //HACK: generator module is not project module, so need to check it separately\n    if (!project.isProjectModule(module instanceof Generator ? ((Generator) module).getSourceLanguage() : module) && !deleteFiles) {\n      throw new IllegalArgumentException(\"Non-project modules can only be deleted with files deletion enabled\");\n    }\n\n    //see MPS-18743\n    project.getRepository().saveAll();\n\n    if (deleteFiles) {\n      for (SModel model : module.getModels()) {\n        DeleteModelHelper.delete(module, model, true);\n      }\n\n      if (module.getFacet(JavaModuleFacet.class) != null) {\n        IFile classesGen = module.getFacet(JavaModuleFacet.class).getClassesGen();\n        if (classesGen != null) {\n          deleteFile(classesGen.toPath().toString());\n        }\n      }\n      if (module.getFacet(TestsFacet.class) != null) {\n        final IFile testsOutputPath = module.getFacet(TestsFacet.class).getTestsOutputPath();\n        if (testsOutputPath != null) {\n          deleteFile(testsOutputPath.toPath().toString());\n        }\n      }\n\n      if (module instanceof AbstractModule) {\n        AbstractModule curModule = (AbstractModule) module;\n        final IFile output = curModule.getOutputPath();\n        if (output != null) {\n          String outputPath = output.toPath().toString();\n          deleteFile(outputPath);\n          deleteFile(FileGenerationUtil.getCachesPath(outputPath));\n        }\n\n        if (curModule.getDescriptorFile() != null) {\n          curModule.getDescriptorFile().delete();\n        }\n\n        if (curModule.getModuleSourceDir() != null && curModule.getModuleSourceDir().getChildren().isEmpty()) {\n          deleteFile(curModule.getModuleSourceDir().toPath().toString());\n        }\n\n        if (curModule.getDescriptorFile() != null) {\n          IFile moduleFolder = curModule.getDescriptorFile().getParent();\n          if (moduleFolder != null && deleteDirIfEmpty(moduleFolder)) {\n            moduleFolder.delete();\n          }\n        }\n      }\n    }\n\n    //remove from project\n    if (project.isProjectModule(module)) {\n      final SRepository repository = project.getRepository();\n      if (repository instanceof SRepositoryExt) {\n        ((SRepositoryExt) repository).unregisterModule(module, project);\n      }\n      project.removeModule(module);\n      project.save();\n\n      ((StandaloneMPSProject) project).update();\n    }\n\n    if (deleteFiles) {\n      new ModuleRepositoryFacade(project.getRepository()).removeModuleForced(module);\n    }\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    String message = \"Are you sure you want to delete selected modules? This operation is not undoable.\";\n    final DeleteDialog.DeleteOption filesOption = new DeleteDialog.DeleteOption(\"Delete Files\", false, true);\n    DeleteDialog dialog = new DeleteDialog(((MPSProject) MapSequence.fromMap(_params).get(\"project\")), \"Delete Modules\", message, filesOption);\n    dialog.show();\n    if (!(dialog.isOK())) {\n      return;\n    }\n\n    ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository().getModelAccess();\n    if (!(filesOption.selected) && Sequence.fromIterable(((Iterable<SModule>) ((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")))).any(new IWhereFilter<SModule>() {\n      public boolean accept(SModule it) {\n        return !(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).isProjectModule(it));\n      }\n    })) {\n      JOptionPane.showMessageDialog(((Frame) MapSequence.fromMap(_params).get(\"frame\")), \"Non-project modules can only be deleted with files deletion enabled\", \"Can't delete module\", JOptionPane.WARNING_MESSAGE);\n      return;\n    }\n\n    modelAccess.executeCommandInEDT(new Runnable() {\n      public void run() {\n        for (SModule module : ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")))) {\n          DeleteModuleHelper.deleteModule(((MPSProject) MapSequence.fromMap(_params).get(\"project\")), module, false, filesOption.selected);\n        }\n      }\n    });\n  }","id":37540,"modified_method":"@Override\n  public void doExecute(@NotNull final AnActionEvent event, final Map<String, Object> _params) {\n    String message = \"<html>Are you sure you want to delete selected modules?<br>This operation is not undoable.<\/html>\";\n    final DeleteDialog.DeleteOption filesOption = new DeleteDialog.DeleteOption(UIUtil.replaceMnemonicAmpersand(\"Delete &Files\"), false, true);\n    DeleteDialog dialog = new DeleteDialog(((MPSProject) MapSequence.fromMap(_params).get(\"project\")), \"Delete Modules\", message, filesOption);\n    dialog.show();\n    if (!(dialog.isOK())) {\n      return;\n    }\n\n    ModelAccess modelAccess = ((MPSProject) MapSequence.fromMap(_params).get(\"project\")).getRepository().getModelAccess();\n    if (!(filesOption.selected) && Sequence.fromIterable(((Iterable<SModule>) ((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")))).any(new IWhereFilter<SModule>() {\n      public boolean accept(SModule it) {\n        return !(((MPSProject) MapSequence.fromMap(_params).get(\"project\")).isProjectModule(it));\n      }\n    })) {\n      JOptionPane.showMessageDialog(((Frame) MapSequence.fromMap(_params).get(\"frame\")), \"Non-project modules can only be deleted with files deletion enabled\", \"Can't delete module\", JOptionPane.WARNING_MESSAGE);\n      return;\n    }\n\n    modelAccess.executeCommandInEDT(new Runnable() {\n      public void run() {\n        for (SModule module : ListSequence.fromList(((List<SModule>) MapSequence.fromMap(_params).get(\"modules\")))) {\n          DeleteModuleHelper.deleteModule(((MPSProject) MapSequence.fromMap(_params).get(\"project\")), module, false, filesOption.selected);\n        }\n      }\n    });\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void createMainComponent() {\n    myContentPane = new JPanel(new GridLayout(4, 1));\n    myContentPane.setPreferredSize(new Dimension(400, 100));\n\n    myContentPane.add(new JLabel(\"Name\"));\n    myContentPane.add(myNameField = new JTextField());\n    myNameField.setName(\"Name\");\n\n    myContentPane.add(new JLabel(\"Folder\"));\n    myContentPane.add(myPathField = new PathField());\n    myPathField.setName(\"Path\");\n\n    myPathField.setPath(myProject.getProjectFile().getAbsolutePath() + File.separator + \"devkits\" + File.separator);\n    myNameField.setText(\"NewDevkit\");\n  }","id":37541,"modified_method":"private void createMainComponent() {\n    myContentPane = new JPanel(new VerticalLayout(5));\n\n    myContentPane.add(new JLabel(\"Name\"));\n    myContentPane.add(myDevkitName = new JTextField(\"NewDevkit\"));\n    myDevkitName.getDocument().addDocumentListener(new DocumentAdapter() {\n      protected void textChanged(DocumentEvent p0) {\n        if (!(myDevkitLocationChangedByUser)) {\n          setDevkitLocation(generateDevkitPath());\n        }\n        check();\n      }\n    });\n\n    myDevkitLocation = new JTextField(generateDevkitPath());\n    myDevkitLocation.getDocument().addDocumentListener(new DocumentAdapter() {\n      protected void textChanged(DocumentEvent p0) {\n        if (myDevkitLocationDocListenerEnabled) {\n          myDevkitLocationChangedByUser = true;\n          check();\n        }\n      }\n    });\n\n    final FileChooserDescriptor descriptor = FileChooserDescriptorFactory.createSingleFolderDescriptor();\n    InsertPathAction.addTo(myDevkitLocation, descriptor);\n    BrowseFilesListener listener = new BrowseFilesListener(myDevkitLocation, \"Choose Devkit Location Folder\", \"\", descriptor);\n    FieldPanel fieldPanel = new FieldPanel(myDevkitLocation, \"Devkit location:\", null, listener, EmptyRunnable.getInstance());\n    FileChooserFactory.getInstance().installFileCompletion(fieldPanel.getTextField(), descriptor, false, myProject.getProject());\n    myContentPane.add(fieldPanel);\n\n    check();\n\n    // Testing stuff \n    myDevkitName.setName(\"Name\");\n    myDevkitLocation.setName(\"Path\");\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"public NewDevKitDialog(Project project) {\n    super(project);\n    setTitle(\"New DevKit\");\n    setOKButtonText(\"&OK\");\n    setCancelButtonText(\"Ca&ncel\");\n\n    myProject = ProjectHelper.fromIdeaProject(project);\n    createMainComponent();\n\n    init();\n  }","id":37542,"modified_method":"public NewDevKitDialog(Project project) {\n    super(project);\n    setTitle(\"New Devkit\");\n    setOKButtonText(\"&OK\");\n    setCancelButtonText(\"Ca&ncel\");\n\n    myProject = ProjectHelper.fromIdeaProject(project);\n    createMainComponent();\n\n    init();\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n  protected void doOKAction() {\n    final String path = myPathField.getPath();\n    String message = NewModuleUtil.check(MPSExtentions.DOT_DEVKIT, myNameField.getText(), path);\n    if (message != null) {\n      setErrorText(message);\n      return;\n    }\n    dispose();\n    NewModuleUtil.runModuleCreation(myProject, new _FunctionTypes._void_P0_E0() {\n      public void invoke() {\n        myResult = NewModuleUtil.createDevKit(myNameField.getText(), path, myProject);\n      }\n    });\n  }","id":37543,"modified_method":"@Override\n  protected void doOKAction() {\n    final String devkitName = getDevkitName();\n    final String devkitLocation = getDevkitLocation();\n    super.doOKAction();\n\n    NewModuleUtil.runModuleCreation(myProject, new _FunctionTypes._void_P0_E0() {\n      public void invoke() {\n        myResult = NewModuleUtil.createDevKit(devkitName, devkitLocation, myProject);\n      }\n    });\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"private JComponent createProjectModulesList() {\n    final JBList list = new JBList(new ProjectPropertiesComponent.PathsListModel());\n\n    list.setCellRenderer(new PathRenderer());\n    list.setSelectionMode(ListSelectionModel.SINGLE_SELECTION);\n\n    ToolbarDecorator decorator = ToolbarDecorator.createDecorator(list);\n    decorator.setAddAction(new AnActionButtonRunnable() {\n      @Override\n      public void run(AnActionButton button) {\n        ModulePath path = new ModulePathChooser().compute();\n        if (path != null) {\n          for (ModulePath p : ((ProjectPropertiesComponent.PathsListModel) list.getModel()).getPaths()) {\n            if (p.getPath().equals(path.getPath())) {\n              list.setSelectedValue(p, true);\n              return;\n            }\n          }\n          ((ProjectPropertiesComponent.PathsListModel) list.getModel()).addPath(path);\n        }\n      }\n    }).setRemoveAction(new AnActionButtonRunnable() {\n      @Override\n      public void run(AnActionButton button) {\n        ((ProjectPropertiesComponent.PathsListModel) list.getModel()).removePath(list.getSelectedValue());\n      }\n    }).disableUpAction().disableDownAction();\n    decorator.setPreferredSize(new Dimension(500, 150));\n\n    JPanel panel = decorator.createPanel();\n    panel.setBorder(IdeBorderFactory.createTitledBorder(\"Modules\", false));\n    return panel;\n  }","id":37544,"modified_method":"private JComponent createProjectModulesList() {\n    final JBList list = new JBList(new ProjectPropertiesComponent.PathsListModel());\n\n    list.setCellRenderer(new PathRenderer());\n    list.setSelectionMode(ListSelectionModel.SINGLE_SELECTION);\n\n    ToolbarDecorator decorator = ToolbarDecorator.createDecorator(list);\n    decorator.setAddAction(new AnActionButtonRunnable() {\n      @Override\n      public void run(AnActionButton button) {\n        final TreeFileChooser chooser = new TreeFileChooser();\n        chooser.setExtensionFileFilter(MPSExtentions.DOT_LANGUAGE, MPSExtentions.DOT_SOLUTION, MPSExtentions.DOT_LIBRARY, MPSExtentions.DOT_DEVKIT);\n        chooser.setInitialFile(VirtualFileUtils.toIFile(myProject.getProject().getBaseDir()));\n\n        final IFile file = chooser.showDialog();\n        if (file == null) {\n          return;\n        }\n\n        ModulePath path = new ModulePath(file.toPath().toString());\n        for (ModulePath p : ((ProjectPropertiesComponent.PathsListModel) list.getModel()).getPaths()) {\n          if (p.getPath().equals(path.getPath())) {\n            list.setSelectedValue(p, true);\n            return;\n          }\n        }\n        ((ProjectPropertiesComponent.PathsListModel) list.getModel()).addPath(path);\n      }\n    }).setRemoveAction(new AnActionButtonRunnable() {\n      @Override\n      public void run(AnActionButton button) {\n        ((ProjectPropertiesComponent.PathsListModel) list.getModel()).removePath(list.getSelectedValue());\n      }\n    }).disableUpAction().disableDownAction();\n    decorator.setPreferredSize(new Dimension(500, 150));\n\n    JPanel panel = decorator.createPanel();\n    panel.setBorder(IdeBorderFactory.createTitledBorder(\"Modules\", false));\n    return panel;\n  }","commit_id":"08c46d100e3c4c664443e31627e726b538917efe","url":"https://github.com/JetBrains/MPS"},{"original_method":"private void generateManifestUi(List<LanguageConfig> configs, XpandExecutionContext ctx) {\n\t\tif (isUi() && !isMergedProjects()) {\n\t\t\tString manifestPath = \"META-INF/MANIFEST.MF_gen\";\n\t\t\tdeleteFile(ctx, manifestPath, PLUGIN_UI);\n\t\t\ttry {\n\t\t\t\tctx.getOutput().openFile(manifestPath, PLUGIN_UI);\n\t\t\t\tXpandFacade facade = XpandFacade.create(ctx);\n\t\t\t\tSet<String> exported = new LinkedHashSet<String>();\n\t\t\t\tSet<String> requiredBundles = new LinkedHashSet<String>();\n\t\t\t\tfor (LanguageConfig config : languageConfigs) {\n\t\t\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesUi(config.getGrammar())));\n\t\t\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesUi(config.getGrammar())));\n\t\t\t\t}\n\t\t\t\tgenerateManifest(facade, getProjectNameUi(), getProjectNameUi(), getBundleVersion(), exported,\n\t\t\t\t\t\trequiredBundles, getActivator());\n\t\t\t} finally {\n\t\t\t\tctx.getOutput().closeFile();\n\t\t\t}\n\t\t}\n\t}","id":37545,"modified_method":"private void generateManifestUi(List<LanguageConfig> configs, XpandExecutionContext ctx) {\n\t\tif (isUi() && !isMergedProjects()) {\n\t\t\tString manifestPath = \"META-INF/MANIFEST.MF\";\n\t\t\tSet<String> exported = new LinkedHashSet<String>();\n\t\t\tSet<String> requiredBundles = new LinkedHashSet<String>();\n\t\t\tfor (LanguageConfig config : languageConfigs) {\n\t\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesUi(config.getGrammar())));\n\t\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesUi(config.getGrammar())));\n\t\t\t}\n\t\t\t\n\t\t\tif (isMergeManifest()) {\n\t\t\t\tString path = ctx.getOutput().getOutlet(PLUGIN_UI).getPath() + \"/\" + manifestPath;\n\t\t\t\tmergeManifest(path, exported, requiredBundles);\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tmanifestPath = manifestPath + \"_gen\";\n\t\t\t\t\tdeleteFile(ctx, manifestPath, PLUGIN_UI);\n\t\t\t\t\tctx.getOutput().openFile(manifestPath, PLUGIN_UI);\n\t\t\t\t\tXpandFacade facade = XpandFacade.create(ctx);\n\t\t\t\t\tgenerateManifest(facade, getProjectNameUi(), getProjectNameUi(), getBundleVersion(), exported,\n\t\t\t\t\t\t\trequiredBundles, getActivator());\n\t\t\t\t} finally {\n\t\t\t\t\tctx.getOutput().closeFile();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}","commit_id":"9d5d1ed6c47824d0b6f1e9ce0e1264d6701b924f","url":"https://github.com/eclipse/xtext"},{"original_method":"private void generateManifestRt(List<LanguageConfig> configs, XpandExecutionContext ctx) {\n\t\tString manifestPath = \"META-INF/MANIFEST.MF_gen\";\n\t\tdeleteFile(ctx, manifestPath, PLUGIN_RT);\n\t\ttry {\n\t\t\tctx.getOutput().openFile(manifestPath, PLUGIN_RT);\n\t\t\tXpandFacade facade = XpandFacade.create(ctx);\n\t\t\tSet<String> exported = new LinkedHashSet<String>();\n\t\t\tSet<String> requiredBundles = new LinkedHashSet<String>();\n\t\t\tString activator = null;\n\t\t\tif (isMergedProjects())\n\t\t\t\tactivator = getActivator();\n\t\t\tfor (LanguageConfig config : configs) {\n\t\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesRt(config.getGrammar())));\n\t\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesRt(config.getGrammar())));\n\t\t\t\tif (isMergedProjects()) {\n\t\t\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesUi(config.getGrammar())));\n\t\t\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesUi(config.getGrammar())));\n\t\t\t\t}\n\t\t\t}\n\t\t\tgenerateManifest(facade, getProjectNameRt(), getProjectNameRt(), getBundleVersion(), exported,\n\t\t\t\t\trequiredBundles, activator);\n\t\t} finally {\n\t\t\tctx.getOutput().closeFile();\n\t\t}\n\t}","id":37546,"modified_method":"private void generateManifestRt(List<LanguageConfig> configs, XpandExecutionContext ctx) {\n\t\tString manifestPath = \"META-INF/MANIFEST.MF\";\n\n\t\tSet<String> exported = new LinkedHashSet<String>();\n\t\tSet<String> requiredBundles = new LinkedHashSet<String>();\n\t\tString activator = null;\n\t\tif (isMergedProjects())\n\t\t\tactivator = getActivator();\n\t\tfor (LanguageConfig config : configs) {\n\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesRt(config.getGrammar())));\n\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesRt(config.getGrammar())));\n\t\t\tif (isMergedProjects()) {\n\t\t\t\texported.addAll(Arrays.asList(config.getExportedPackagesUi(config.getGrammar())));\n\t\t\t\trequiredBundles.addAll(Arrays.asList(config.getRequiredBundlesUi(config.getGrammar())));\n\t\t\t}\n\t\t}\n\t\tif (isMergeManifest()) {\n\t\t\tString path = ctx.getOutput().getOutlet(PLUGIN_RT).getPath() + \"/\" + manifestPath;\n\t\t\tmergeManifest(path, exported, requiredBundles);\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tmanifestPath = manifestPath + \"_gen\";\n\t\t\t\tdeleteFile(ctx, manifestPath, PLUGIN_RT);\n\t\t\t\tctx.getOutput().openFile(manifestPath, PLUGIN_RT);\n\t\t\t\tXpandFacade facade = XpandFacade.create(ctx);\n\t\t\t\tgenerateManifest(facade, getProjectNameRt(), getProjectNameRt(), getBundleVersion(), exported,\n\t\t\t\t\t\trequiredBundles, activator);\n\t\t\t} finally {\n\t\t\t\tctx.getOutput().closeFile();\n\t\t\t}\n\t\t}\n\t}","commit_id":"9d5d1ed6c47824d0b6f1e9ce0e1264d6701b924f","url":"https://github.com/eclipse/xtext"},{"original_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the delete template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The delete template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n       // the template to be displayed\n        String template=null;\n        \n        String delete=(String)parameters.get(C_PARA_DELETE);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tCmsFile file=(CmsFile)cms.readFileHeader(filename);\n\n        //check if the name parameter was included in the request\n        // if not, the delete page is shown for the first time\n    \n        if (delete != null) {\n\t\t\t//check if the file type name is page\n\t\t\t//if so delete the file body and content\n\t\t\t// else delete only file\n\t\t\tif( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\tString bodyPath=getBodyPath(cms, file);\n\t\t\t\tint help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\tString hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\tif (hbodyPath.equals(bodyPath)){\n\t\t\t\t\tcms.deleteFile(hbodyPath);\n\t\t\t\t}\n\t\t\t}\n            cms.deleteFile(filename);\n            session.removeValue(C_PARA_FILE);\n            \n            // TODO: Error handling\n            try {\n                cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n            } catch (Exception e) {\n                  throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n            } \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n\t\txmlTemplateDocument.setXmlData(\"FILENAME\",file.getName());\n           \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template); \n    }","id":37547,"modified_method":"/**\n     * Overwrites the getContent method of the CmsWorkplaceDefault.<br>\n     * Gets the content of the delete template and processed the data input.\n     * @param cms The CmsObject.\n     * @param templateFile The delete template file\n     * @param elementName not used\n     * @param parameters Parameters of the request and the template.\n     * @param templateSelector Selector of the template tag to be displayed.\n     * @return Bytearre containgine the processed data of the template.\n     * @exception Throws CmsException if something goes wrong.\n     */\n    public byte[] getContent(A_CmsObject cms, String templateFile, String elementName, \n                             Hashtable parameters, String templateSelector)\n        throws CmsException {\n        HttpSession session= ((HttpServletRequest)cms.getRequestContext().getRequest().getOriginalRequest()).getSession(true);   \n        \n       // the template to be displayed\n        String template=null;\n        \n        String delete=(String)parameters.get(C_PARA_DELETE);\n        String filename=(String)parameters.get(C_PARA_FILE);\n        if (filename != null) {\n            session.putValue(C_PARA_FILE,filename);        \n        }\n        filename=(String)session.getValue(C_PARA_FILE);\n\t\tCmsFile file=(CmsFile)cms.readFileHeader(filename);\n\n        if (file.isFile()) {\n            template=\"file\";\n        } else {\n            template=\"folder\";\n        }\n\n        //check if the name parameter was included in the request\n        // if not, the delete page is shown for the first time\n    \n        if (delete != null) {\n            \n            // check if the resource is a file or a folder\n            if (file.isFile()) {            \n\t\t\t    //check if the file type name is page\n\t\t\t    //if so delete the file body and content\n\t\t\t    // else delete only file\n\t\t\t    if( (cms.getResourceType(file.getType()).getResourceName()).equals(C_TYPE_PAGE_NAME) ){\n\t\t\t\t    String bodyPath=getBodyPath(cms, file);\n\t\t\t\t    int help = C_CONTENTBODYPATH.lastIndexOf(\"/\");\n\t\t\t\t    String hbodyPath=(C_CONTENTBODYPATH.substring(0,help))+(file.getAbsolutePath());\n\t\t\t\t    if (hbodyPath.equals(bodyPath)){\n\t\t\t\t\t    cms.deleteFile(hbodyPath);\n\t\t\t\t    }\n\t\t\t    }\n                cms.deleteFile(filename);\n            } else {               \n                cms.deleteFolder(filename);\n            }\n            \n            session.removeValue(C_PARA_FILE);\n            \n            // TODO: Error handling\n            try {\n                cms.getRequestContext().getResponse().sendCmsRedirect( getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST);\n            } catch (Exception e) {\n                  throw new CmsException(\"Redirect fails :\"+ getConfigFile(cms).getWorkplaceActionPath()+C_WP_EXPLORER_FILELIST,CmsException.C_UNKNOWN_EXCEPTION,e);\n            } \n        }\n\n        CmsXmlWpTemplateFile xmlTemplateDocument = new CmsXmlWpTemplateFile(cms,templateFile);\n\t\txmlTemplateDocument.setXmlData(\"FILENAME\",file.getName());\n           \n        // process the selected template \n        return startProcessing(cms,xmlTemplateDocument,\"\",parameters,template); \n    }","commit_id":"5256a426dee5a8e4ec2d60efb15da3f3a583c243","url":"https://github.com/alkacon/opencms-core"},{"original_method":"public static String getStringForKey(DashletSpec dashletSpec, String key) {\n        String value = dashletSpec.getParameters().get(key);\n        return (value == null ? \"\" : value);\n    }","id":37548,"modified_method":"/**\n     * Returns the string value for a given key. Null values will be returned as empty\n     * strings.\n     * @param map the map to use\n     * @param key the key\n     * @return the string value\n     */\n    public static String getStringForKey(Map<String, String> map, String key) {\n        String value = map.get(key);\n        return (value == null ? \"\" : value);\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public static boolean getBooleanForKey(DashletSpec dashletSpec, String key) {\n        String value = dashletSpec.getParameters().get(key);\n        return (\"true\".equals(value) || \"yes\".equals(value) || \"1\".equals(value));\n    }","id":37549,"modified_method":"/**\n     * Returns a boolean value for a given key from the map where \"1\", \"true\" and \"yes\"\n     * are interpeted as boolean true, otherwise false.\n     *\n     * @param map the map to be used\n     * @param key the key\n     * @return the boolean value\n     */\n    public static boolean getBooleanForKey(Map<String, String> map, String key) {\n        String value = map.get(key);\n        return (\"true\".equals(value) || \"yes\".equals(value) || \"1\".equals(value));\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"public static int getIntForKey(DashletSpec dashletSpec, String key) {\n        String value = dashletSpec.getParameters().get(key);\n        try {\n            return Integer.parseInt(value);\n        } catch (NumberFormatException e) {\n            return 0;\n        }\n    }","id":37550,"modified_method":"/**\n     * Returns the int value for a given key. Unparsable values are returned as zero.\n     *\n     * @param map the map to be used\n     * @param key the key\n     * @return the int value, 0 if not parsable\n     */\n    public static int getIntForKey(Map<String, String> map, String key) {\n        String value = map.get(key);\n        try {\n            return Integer.parseInt(value);\n        } catch (NumberFormatException e) {\n            return 0;\n        }\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private void addToComponent(VerticalLayout verticalLayout, Component component) {\n        HorizontalLayout horizontalLayout = new HorizontalLayout();\n        horizontalLayout.setWidth(100, Unit.PERCENTAGE);\n        Label label = new Label(component.getCaption());\n        label.setWidth(200, Unit.PIXELS);\n        component.setSizeFull();\n        component.setCaption(null);\n        horizontalLayout.addComponent(label);\n        horizontalLayout.addComponent(component);\n        horizontalLayout.setExpandRatio(component, 1.0f);\n        verticalLayout.addComponent(horizontalLayout);\n    }","id":37551,"modified_method":"/**\n     * Adds a component to a given vertical layout and applies some sizing and formatting options.\n     * @param verticalLayout the vertical layout\n     * @param component the component to be added\n     */\n    private void addToComponent(VerticalLayout verticalLayout, Component component) {\n        HorizontalLayout horizontalLayout = new HorizontalLayout();\n        horizontalLayout.setWidth(100, Unit.PERCENTAGE);\n        Label label = new Label(component.getCaption());\n        label.setWidth(200, Unit.PIXELS);\n        component.setSizeFull();\n        component.setCaption(null);\n        horizontalLayout.addComponent(label);\n        horizontalLayout.addComponent(component);\n        horizontalLayout.setExpandRatio(component, 1.0f);\n        verticalLayout.addComponent(horizontalLayout);\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"private DashletSpec getDashletSpec() {\n        return m_dashletSpec;\n    }","id":37552,"modified_method":"/**\n     * Returns the associated dashlet specification.\n     * @return the dashlet specification\n     */\n    private DashletSpec getDashletSpec() {\n        return m_dashletSpec;\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Constructor for instantiating new objects of this class.\n     *\n     * @param dashletSpec the {@link DashletSpec} to be edited\n     */\n    public BSMConfigurationWindow(DashletSpec dashletSpec) {\n        /**\n         * Setting the members\n         */\n        m_dashletSpec = dashletSpec;\n\n        /**\n         * Setting up the base layouts\n         */\n\n        setHeight(80, Unit.PERCENTAGE);\n        setWidth(60, Unit.PERCENTAGE);\n\n        /**\n         * Retrieve the config...\n         */\n\n        boolean filterByName = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterByName\");\n        String nameValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"nameValue\");\n\n        boolean filterByAttribute = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterByAttribute\");\n        String attributeKey = BSMConfigHelper.getStringForKey(getDashletSpec(), \"attributeKey\");\n        String attributeValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"attributeValue\");\n\n        boolean filterBySeverity = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterBySeverity\");\n\n        String severityValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"severityValue\");\n\n        if (severityValue == null || \"\".equals(severityValue)) {\n            severityValue = OnmsSeverity.WARNING.getLabel();\n        }\n\n        int resultsLimit = BSMConfigHelper.getIntForKey(getDashletSpec(), \"resultsLimit\");\n\n        /**\n         * Adding the \"Filter By Name\" panel\n         */\n\n        m_filterByNameCheckBox = new CheckBox();\n        m_filterByNameCheckBox.setCaption(\"Enable\");\n        m_filterByNameCheckBox.setDescription(\"Filter by Business Service name\");\n\n        VerticalLayout nameLayout = new VerticalLayout();\n        nameLayout.setSpacing(true);\n        nameLayout.setMargin(true);\n        nameLayout.setSizeFull();\n\n        m_nameTextField = new TextField(\"Name (REGEXP)\");\n        m_nameTextField.setEnabled(false);\n\n        addToComponent(nameLayout, m_filterByNameCheckBox);\n        addToComponent(nameLayout, m_nameTextField);\n\n        Panel namePanel = new Panel();\n        namePanel.setCaption(\"Filter by Name\");\n        namePanel.setContent(nameLayout);\n\n        m_filterByNameCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_nameTextField.setEnabled(m_filterByNameCheckBox.getValue());\n            }\n        });\n\n        m_nameTextField.setValue(nameValue);\n        m_filterByNameCheckBox.setValue(filterByName);\n\n        /**\n         * Adding the \"Filter By Attribute\" panel\n         */\n\n        m_filterByAttributeCheckBox = new CheckBox();\n        m_filterByAttributeCheckBox.setCaption(\"Enable\");\n        m_filterByAttributeCheckBox.setDescription(\"Filter by Business Service attribute\");\n\n        VerticalLayout attributeLayout = new VerticalLayout();\n        attributeLayout.setSpacing(true);\n        attributeLayout.setMargin(true);\n        attributeLayout.setSizeFull();\n\n        m_attributeKeyTextField = new TextField(\"Key\");\n        m_attributeKeyTextField.setEnabled(false);\n        m_attributeValueTextField = new TextField(\"Value (REGEXP)\");\n        m_attributeValueTextField.setEnabled(false);\n        addToComponent(attributeLayout, m_filterByAttributeCheckBox);\n        addToComponent(attributeLayout, m_attributeKeyTextField);\n        addToComponent(attributeLayout, m_attributeValueTextField);\n\n        Panel attributePanel = new Panel();\n        attributePanel.setCaption(\"Filter by Attribute\");\n        attributePanel.setContent(attributeLayout);\n\n        m_filterByAttributeCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_attributeKeyTextField.setEnabled(m_filterByAttributeCheckBox.getValue());\n                m_attributeValueTextField.setEnabled(m_filterByAttributeCheckBox.getValue());\n            }\n        });\n\n        m_attributeKeyTextField.setValue(attributeKey);\n        m_attributeValueTextField.setValue(attributeValue);\n        m_filterByAttributeCheckBox.setValue(filterByAttribute);\n\n        /**\n         * Adding the \"Filter By Severity\" panel\n         */\n\n        m_filterBySeverityCheckBox = new CheckBox();\n        m_filterBySeverityCheckBox.setCaption(\"Enable\");\n        m_filterBySeverityCheckBox.setDescription(\"Filter by Business Service severity\");\n\n        VerticalLayout severityLayout = new VerticalLayout();\n        severityLayout.setSpacing(true);\n        severityLayout.setMargin(true);\n        severityLayout.setSizeFull();\n\n        m_severitySelect = new NativeSelect(\"Severity\");\n        m_severitySelect.setEnabled(false);\n        m_severitySelect.setNullSelectionAllowed(false);\n        m_severitySelect.setMultiSelect(false);\n\n        for (String name : OnmsSeverity.names()) {\n            m_severitySelect.addItem(name);\n        }\n        addToComponent(severityLayout, m_filterBySeverityCheckBox);\n        addToComponent(severityLayout, m_severitySelect);\n\n        Panel severityPanel = new Panel();\n        severityPanel.setCaption(\"Filter by Severity\");\n        severityPanel.setContent(severityLayout);\n\n        m_filterBySeverityCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_severitySelect.setEnabled(m_filterBySeverityCheckBox.getValue());\n            }\n        });\n\n        m_severitySelect.setValue(severityValue);\n        m_filterBySeverityCheckBox.setValue(filterBySeverity);\n\n        /**\n         * Adding the \"Limit\" panel\n         */\n\n        VerticalLayout limitLayout = new VerticalLayout();\n        limitLayout.setSpacing(true);\n        limitLayout.setMargin(true);\n        limitLayout.setSizeFull();\n\n        m_limitTextField = new TextField(\"Limit\");\n        addToComponent(limitLayout, m_limitTextField);\n\n        Panel limitPanel = new Panel();\n        limitPanel.setSizeFull();\n        limitPanel.setCaption(\"Limit Results\");\n        limitPanel.setContent(limitLayout);\n\n        m_limitTextField.setValue(String.valueOf(resultsLimit));\n        m_limitTextField.addValidator(new AbstractStringValidator(\"Number greater zero expected\") {\n            @Override\n            protected boolean isValidValue(String value) {\n                try {\n                    int i = Integer.parseInt(value);\n                    return i > 0;\n                } catch (NumberFormatException e) {\n                    return false;\n                }\n            }\n        });\n\n        /**\n         * Create the main layout...\n         */\n\n        VerticalLayout verticalLayout = new VerticalLayout();\n\n        verticalLayout.setWidth(100, Unit.PERCENTAGE);\n        verticalLayout.setSpacing(true);\n        verticalLayout.setMargin(true);\n\n        verticalLayout.addComponent(namePanel);\n        verticalLayout.addComponent(attributePanel);\n\n        HorizontalLayout bottomLayout = new HorizontalLayout(severityPanel, limitPanel);\n        bottomLayout.setSpacing(true);\n        bottomLayout.setWidth(100, Unit.PERCENTAGE);\n        verticalLayout.addComponent(bottomLayout);\n\n        /**\n         * Using an additional {@link HorizontalLayout} for layouting the buttons\n         */\n        HorizontalLayout buttonLayout = new HorizontalLayout();\n\n        buttonLayout.setMargin(true);\n        buttonLayout.setSpacing(true);\n        buttonLayout.setWidth(\"100%\");\n        /**\n         * Adding the cancel button...\n         */\n        Button cancel = new Button(\"Cancel\");\n        cancel.setDescription(\"Cancel editing\");\n        cancel.addClickListener(new Button.ClickListener() {\n            @Override\n            public void buttonClick(Button.ClickEvent event) {\n                close();\n            }\n        });\n\n        cancel.setClickShortcut(ShortcutAction.KeyCode.ESCAPE, null);\n        buttonLayout.addComponent(cancel);\n        buttonLayout.setExpandRatio(cancel, 1.0f);\n        buttonLayout.setComponentAlignment(cancel, Alignment.TOP_RIGHT);\n\n        /**\n         * ...and the OK button\n         */\n        Button ok = new Button(\"Save\");\n        ok.setDescription(\"Save properties and close\");\n        ok.addClickListener(new Button.ClickListener() {\n            @Override\n            public void buttonClick(Button.ClickEvent event) {\n                if (!m_limitTextField.isValid()) {\n                    return;\n                }\n\n                m_dashletSpec.getParameters().put(\"filterByName\", (m_filterByNameCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterByNameCheckBox.getValue()) {\n                    m_dashletSpec.getParameters().put(\"nameValue\", m_nameTextField.getValue());\n                } else {\n                    m_dashletSpec.getParameters().put(\"nameValue\", \"\");\n                }\n\n                m_dashletSpec.getParameters().put(\"filterByAttribute\", (m_filterByAttributeCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterByAttributeCheckBox.getValue()) {\n                    m_dashletSpec.getParameters().put(\"attributeKey\", m_attributeKeyTextField.getValue());\n                    m_dashletSpec.getParameters().put(\"attributeValue\", m_attributeValueTextField.getValue());\n                } else {\n                    m_dashletSpec.getParameters().put(\"attributeKey\", \"\");\n                    m_dashletSpec.getParameters().put(\"attributeValue\", \"\");\n                }\n\n                m_dashletSpec.getParameters().put(\"filterBySeverity\", (m_filterBySeverityCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterBySeverityCheckBox.getValue() && m_severitySelect.getValue() != null) {\n                    m_dashletSpec.getParameters().put(\"severityValue\", m_severitySelect.getValue().toString());\n                } else {\n                    m_dashletSpec.getParameters().put(\"severityValue\", OnmsSeverity.WARNING.getLabel());\n                }\n\n                m_dashletSpec.getParameters().put(\"resultsLimit\", m_limitTextField.getValue().toString());\n\n                WallboardProvider.getInstance().save();\n                ((WallboardConfigUI) getUI()).notifyMessage(\"Data saved\", \"Properties\");\n\n                close();\n            }\n        });\n\n        ok.setClickShortcut(ShortcutAction.KeyCode.ENTER, null);\n        buttonLayout.addComponent(ok);\n\n        /**\n         * Adding the layout and setting the content\n         */\n        verticalLayout.addComponent(buttonLayout);\n\n        setContent(verticalLayout);\n    }","id":37553,"modified_method":"/**\n     * Constructor for instantiating new objects of this class.\n     *\n     * @param dashletSpec the {@link DashletSpec} to be edited\n     */\n    public BSMConfigurationWindow(DashletSpec dashletSpec) {\n        /**\n         * Setting the members\n         */\n        m_dashletSpec = dashletSpec;\n\n        /**\n         * Setting up the base layouts\n         */\n\n        setHeight(80, Unit.PERCENTAGE);\n        setWidth(60, Unit.PERCENTAGE);\n\n        /**\n         * Retrieve the config...\n         */\n\n        boolean filterByName = BSMConfigHelper.getBooleanForKey(getDashletSpec().getParameters(), \"filterByName\");\n        String nameValue = BSMConfigHelper.getStringForKey(getDashletSpec().getParameters(), \"nameValue\");\n\n        boolean filterByAttribute = BSMConfigHelper.getBooleanForKey(getDashletSpec().getParameters(), \"filterByAttribute\");\n        String attributeKey = BSMConfigHelper.getStringForKey(getDashletSpec().getParameters(), \"attributeKey\");\n        String attributeValue = BSMConfigHelper.getStringForKey(getDashletSpec().getParameters(), \"attributeValue\");\n\n        boolean filterBySeverity = BSMConfigHelper.getBooleanForKey(getDashletSpec().getParameters(), \"filterBySeverity\");\n\n        String severityValue = BSMConfigHelper.getStringForKey(getDashletSpec().getParameters(), \"severityValue\");\n\n        if (severityValue == null || \"\".equals(severityValue)) {\n            severityValue = OnmsSeverity.WARNING.getLabel();\n        }\n\n        int resultsLimit = BSMConfigHelper.getIntForKey(getDashletSpec().getParameters(), \"resultsLimit\");\n\n        /**\n         * Adding the \"Filter By Name\" panel\n         */\n\n        m_filterByNameCheckBox = new CheckBox();\n        m_filterByNameCheckBox.setCaption(\"Enable\");\n        m_filterByNameCheckBox.setDescription(\"Filter by Business Service name\");\n\n        VerticalLayout nameLayout = new VerticalLayout();\n        nameLayout.setSpacing(true);\n        nameLayout.setMargin(true);\n        nameLayout.setSizeFull();\n\n        m_nameTextField = new TextField(\"Name (REGEXP)\");\n        m_nameTextField.setEnabled(false);\n\n        addToComponent(nameLayout, m_filterByNameCheckBox);\n        addToComponent(nameLayout, m_nameTextField);\n\n        Panel namePanel = new Panel();\n        namePanel.setCaption(\"Filter by Name\");\n        namePanel.setContent(nameLayout);\n\n        m_filterByNameCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_nameTextField.setEnabled(m_filterByNameCheckBox.getValue());\n            }\n        });\n\n        m_nameTextField.setValue(nameValue);\n        m_filterByNameCheckBox.setValue(filterByName);\n\n        /**\n         * Adding the \"Filter By Attribute\" panel\n         */\n\n        m_filterByAttributeCheckBox = new CheckBox();\n        m_filterByAttributeCheckBox.setCaption(\"Enable\");\n        m_filterByAttributeCheckBox.setDescription(\"Filter by Business Service attribute\");\n\n        VerticalLayout attributeLayout = new VerticalLayout();\n        attributeLayout.setSpacing(true);\n        attributeLayout.setMargin(true);\n        attributeLayout.setSizeFull();\n\n        m_attributeKeyTextField = new TextField(\"Key\");\n        m_attributeKeyTextField.setEnabled(false);\n        m_attributeValueTextField = new TextField(\"Value (REGEXP)\");\n        m_attributeValueTextField.setEnabled(false);\n        addToComponent(attributeLayout, m_filterByAttributeCheckBox);\n        addToComponent(attributeLayout, m_attributeKeyTextField);\n        addToComponent(attributeLayout, m_attributeValueTextField);\n\n        Panel attributePanel = new Panel();\n        attributePanel.setCaption(\"Filter by Attribute\");\n        attributePanel.setContent(attributeLayout);\n\n        m_filterByAttributeCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_attributeKeyTextField.setEnabled(m_filterByAttributeCheckBox.getValue());\n                m_attributeValueTextField.setEnabled(m_filterByAttributeCheckBox.getValue());\n            }\n        });\n\n        m_attributeKeyTextField.setValue(attributeKey);\n        m_attributeValueTextField.setValue(attributeValue);\n        m_filterByAttributeCheckBox.setValue(filterByAttribute);\n\n        /**\n         * Adding the \"Filter By Severity\" panel\n         */\n\n        m_filterBySeverityCheckBox = new CheckBox();\n        m_filterBySeverityCheckBox.setCaption(\"Enable\");\n        m_filterBySeverityCheckBox.setDescription(\"Filter by Business Service severity\");\n\n        VerticalLayout severityLayout = new VerticalLayout();\n        severityLayout.setSpacing(true);\n        severityLayout.setMargin(true);\n        severityLayout.setSizeFull();\n\n        m_severitySelect = new NativeSelect(\"Severity\");\n        m_severitySelect.setEnabled(false);\n        m_severitySelect.setNullSelectionAllowed(false);\n        m_severitySelect.setMultiSelect(false);\n\n        for (String name : OnmsSeverity.names()) {\n            m_severitySelect.addItem(name);\n        }\n        addToComponent(severityLayout, m_filterBySeverityCheckBox);\n        addToComponent(severityLayout, m_severitySelect);\n\n        Panel severityPanel = new Panel();\n        severityPanel.setCaption(\"Filter by Severity\");\n        severityPanel.setContent(severityLayout);\n\n        m_filterBySeverityCheckBox.addValueChangeListener(new Property.ValueChangeListener() {\n            @Override\n            public void valueChange(Property.ValueChangeEvent event) {\n                m_severitySelect.setEnabled(m_filterBySeverityCheckBox.getValue());\n            }\n        });\n\n        m_severitySelect.setValue(severityValue);\n        m_filterBySeverityCheckBox.setValue(filterBySeverity);\n\n        /**\n         * Adding the \"Limit\" panel\n         */\n\n        VerticalLayout limitLayout = new VerticalLayout();\n        limitLayout.setSpacing(true);\n        limitLayout.setMargin(true);\n        limitLayout.setSizeFull();\n\n        m_limitTextField = new TextField(\"Limit\");\n        addToComponent(limitLayout, m_limitTextField);\n\n        Panel limitPanel = new Panel();\n        limitPanel.setSizeFull();\n        limitPanel.setCaption(\"Limit Results\");\n        limitPanel.setContent(limitLayout);\n\n        m_limitTextField.setValue(String.valueOf(resultsLimit));\n        m_limitTextField.addValidator(new AbstractStringValidator(\"Number greater zero expected\") {\n            @Override\n            protected boolean isValidValue(String value) {\n                try {\n                    int i = Integer.parseInt(value);\n                    return i > 0;\n                } catch (NumberFormatException e) {\n                    return false;\n                }\n            }\n        });\n\n        /**\n         * Create the main layout...\n         */\n\n        VerticalLayout verticalLayout = new VerticalLayout();\n\n        verticalLayout.setWidth(100, Unit.PERCENTAGE);\n        verticalLayout.setSpacing(true);\n        verticalLayout.setMargin(true);\n\n        verticalLayout.addComponent(namePanel);\n        verticalLayout.addComponent(attributePanel);\n\n        HorizontalLayout bottomLayout = new HorizontalLayout(severityPanel, limitPanel);\n        bottomLayout.setSpacing(true);\n        bottomLayout.setWidth(100, Unit.PERCENTAGE);\n        verticalLayout.addComponent(bottomLayout);\n\n        /**\n         * Using an additional {@link HorizontalLayout} for layouting the buttons\n         */\n        HorizontalLayout buttonLayout = new HorizontalLayout();\n\n        buttonLayout.setMargin(true);\n        buttonLayout.setSpacing(true);\n        buttonLayout.setWidth(\"100%\");\n        /**\n         * Adding the cancel button...\n         */\n        Button cancel = new Button(\"Cancel\");\n        cancel.setDescription(\"Cancel editing\");\n        cancel.addClickListener(new Button.ClickListener() {\n            @Override\n            public void buttonClick(Button.ClickEvent event) {\n                close();\n            }\n        });\n\n        cancel.setClickShortcut(ShortcutAction.KeyCode.ESCAPE, null);\n        buttonLayout.addComponent(cancel);\n        buttonLayout.setExpandRatio(cancel, 1.0f);\n        buttonLayout.setComponentAlignment(cancel, Alignment.TOP_RIGHT);\n\n        /**\n         * ...and the OK button\n         */\n        Button ok = new Button(\"Save\");\n        ok.setDescription(\"Save properties and close\");\n        ok.addClickListener(new Button.ClickListener() {\n            @Override\n            public void buttonClick(Button.ClickEvent event) {\n                if (!m_limitTextField.isValid()) {\n                    return;\n                }\n\n                m_dashletSpec.getParameters().put(\"filterByName\", (m_filterByNameCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterByNameCheckBox.getValue()) {\n                    m_dashletSpec.getParameters().put(\"nameValue\", m_nameTextField.getValue());\n                } else {\n                    m_dashletSpec.getParameters().put(\"nameValue\", \"\");\n                }\n\n                m_dashletSpec.getParameters().put(\"filterByAttribute\", (m_filterByAttributeCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterByAttributeCheckBox.getValue()) {\n                    m_dashletSpec.getParameters().put(\"attributeKey\", m_attributeKeyTextField.getValue());\n                    m_dashletSpec.getParameters().put(\"attributeValue\", m_attributeValueTextField.getValue());\n                } else {\n                    m_dashletSpec.getParameters().put(\"attributeKey\", \"\");\n                    m_dashletSpec.getParameters().put(\"attributeValue\", \"\");\n                }\n\n                m_dashletSpec.getParameters().put(\"filterBySeverity\", (m_filterBySeverityCheckBox.getValue() ? \"true\" : \"false\"));\n\n                if (m_filterBySeverityCheckBox.getValue() && m_severitySelect.getValue() != null) {\n                    m_dashletSpec.getParameters().put(\"severityValue\", m_severitySelect.getValue().toString());\n                } else {\n                    m_dashletSpec.getParameters().put(\"severityValue\", OnmsSeverity.WARNING.getLabel());\n                }\n\n                m_dashletSpec.getParameters().put(\"resultsLimit\", m_limitTextField.getValue().toString());\n\n                WallboardProvider.getInstance().save();\n                ((WallboardConfigUI) getUI()).notifyMessage(\"Data saved\", \"Properties\");\n\n                close();\n            }\n        });\n\n        ok.setClickShortcut(ShortcutAction.KeyCode.ENTER, null);\n        buttonLayout.addComponent(ok);\n\n        /**\n         * Adding the layout and setting the content\n         */\n        verticalLayout.addComponent(buttonLayout);\n\n        setContent(verticalLayout);\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"/**\n     * Constructor for instantiating new objects.\n     *\n     * @param dashletSpec            the {@link DashletSpec} to be used\n     * @param businessServiceManager the {@link BusinessServiceManager} to be used\n     */\n    public BSMDashlet(String name, DashletSpec dashletSpec, BusinessServiceManager businessServiceManager) {\n        super(name, dashletSpec);\n        /**\n         * Setting the member fields\n         */\n        m_businessServiceManager = businessServiceManager;\n\n        /**\n         * Retrieve the config...\n         */\n\n        m_filterByName = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterByName\");\n        m_nameValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"nameValue\");\n        m_filterByAttribute = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterByAttribute\");\n        m_attributeKey = BSMConfigHelper.getStringForKey(getDashletSpec(), \"attributeKey\");\n        m_attributeValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"attributeValue\");\n        m_filterBySeverity = BSMConfigHelper.getBooleanForKey(getDashletSpec(), \"filterBySeverity\");\n        m_severityValue = BSMConfigHelper.getStringForKey(getDashletSpec(), \"severityValue\");\n        m_resultsLimit = BSMConfigHelper.getIntForKey(getDashletSpec(), \"resultsLimit\");\n    }","id":37554,"modified_method":"/**\n     * Constructor for instantiating new objects.\n     *\n     * @param dashletSpec            the {@link DashletSpec} to be used\n     * @param businessServiceManager the {@link BusinessServiceManager} to be used\n     */\n    public BSMDashlet(String name, DashletSpec dashletSpec, BusinessServiceManager businessServiceManager) {\n        super(name, dashletSpec);\n        /**\n         * Setting the member fields\n         */\n        m_businessServiceManager = businessServiceManager;\n\n        /**\n         * Retrieve the config...\n         */\n\n        m_businessServiceSearchCriteria = BSMConfigHelper.fromMap(getDashletSpec().getParameters());\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    public DashletComponent getWallboardComponent() {\n        if (m_wallboardComponent == null) {\n            m_wallboardComponent = new AbstractDashletComponent() {\n                private VerticalLayout m_verticalLayout = new VerticalLayout();\n\n                {\n                    m_verticalLayout.setCaption(getName());\n                    m_verticalLayout.setWidth(\"100%\");\n                    refresh();\n                }\n\n                @Override\n                public void refresh() {\n                    m_verticalLayout.removeAllComponents();\n\n                    final List<BusinessServiceDTO> serviceDTOs = getDTOs();\n                    if (serviceDTOs.isEmpty()) {\n                        m_verticalLayout.addComponent(new Label(\"There are no Business Services with matching criterias found.\"));\n                    } else {\n                        for (BusinessServiceDTO eachService : serviceDTOs) {\n                            m_verticalLayout.addComponent(createRow(eachService));\n                        }\n                    }\n                    boosted = false;\n                }\n\n                @Override\n                public Component getComponent() {\n                    return m_verticalLayout;\n                }\n            };\n        }\n        return m_wallboardComponent;\n    }","id":37555,"modified_method":"@Override\n    public DashletComponent getWallboardComponent() {\n        if (m_wallboardComponent == null) {\n            m_wallboardComponent = new AbstractDashletComponent() {\n                private VerticalLayout m_verticalLayout = new VerticalLayout();\n\n                {\n                    m_verticalLayout.setCaption(getName());\n                    m_verticalLayout.setWidth(\"100%\");\n                    refresh();\n                }\n\n                @Override\n                public void refresh() {\n                    m_verticalLayout.removeAllComponents();\n\n                    final List<BusinessServiceDTO> serviceDTOs = m_businessServiceManager.search(m_businessServiceSearchCriteria);\n                    if (serviceDTOs.isEmpty()) {\n                        m_verticalLayout.addComponent(new Label(\"There are no Business Services with matching criterias found.\"));\n                    } else {\n                        for (BusinessServiceDTO eachService : serviceDTOs) {\n                            m_verticalLayout.addComponent(createRow(eachService));\n                        }\n                    }\n                    boosted = false;\n                }\n\n                @Override\n                public Component getComponent() {\n                    return m_verticalLayout;\n                }\n            };\n        }\n        return m_wallboardComponent;\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n    public DashletComponent getDashboardComponent() {\n        if (m_dashboardComponent == null) {\n            m_dashboardComponent = new AbstractDashletComponent() {\n                private VerticalLayout m_verticalLayout = new VerticalLayout();\n\n                {\n                    m_verticalLayout.setCaption(getName());\n                    m_verticalLayout.setWidth(\"100%\");\n                    refresh();\n                }\n\n                @Override\n                public void refresh() {\n                    m_verticalLayout.removeAllComponents();\n\n                    final List<BusinessServiceDTO> serviceDTOs = getDTOs();\n                    if (serviceDTOs.isEmpty()) {\n                        m_verticalLayout.addComponent(new Label(\"There are no Business Services with matching criterias found.\"));\n                    } else {\n                        for (BusinessServiceDTO eachService : serviceDTOs) {\n                            m_verticalLayout.addComponent(createRow(eachService));\n                        }\n                    }\n                    boosted = false;\n                }\n\n                @Override\n                public Component getComponent() {\n                    return m_verticalLayout;\n                }\n            };\n        }\n        return m_dashboardComponent;\n    }","id":37556,"modified_method":"@Override\n    public DashletComponent getDashboardComponent() {\n        if (m_dashboardComponent == null) {\n            m_dashboardComponent = new AbstractDashletComponent() {\n                private VerticalLayout m_verticalLayout = new VerticalLayout();\n\n                {\n                    m_verticalLayout.setCaption(getName());\n                    m_verticalLayout.setWidth(\"100%\");\n                    refresh();\n                }\n\n                @Override\n                public void refresh() {\n                    m_verticalLayout.removeAllComponents();\n\n                    final List<BusinessServiceDTO> serviceDTOs = m_businessServiceManager.search(m_businessServiceSearchCriteria);\n                    if (serviceDTOs.isEmpty()) {\n                        m_verticalLayout.addComponent(new Label(\"There are no Business Services with matching criterias found.\"));\n                    } else {\n                        for (BusinessServiceDTO eachService : serviceDTOs) {\n                            m_verticalLayout.addComponent(createRow(eachService));\n                        }\n                    }\n                    boosted = false;\n                }\n\n                @Override\n                public Component getComponent() {\n                    return m_verticalLayout;\n                }\n            };\n        }\n        return m_dashboardComponent;\n    }","commit_id":"1d7e0587c3b7e3881c055b871fc7b51edb5745b7","url":"https://github.com/OpenNMS/opennms"},{"original_method":"@Override\n  public void messageReceived(ChannelHandlerContext ctx,\n                              MessageEvent event) throws Exception {\n\n    final Channel inboundChannel = event.getChannel();\n    if (event.getMessage() instanceof HttpChunk) {\n      // This case below should never happen this would mean we get Chunks before HTTPMessage.\n      raiseExceptionIfNull(chunkEventSender, HttpResponseStatus.INTERNAL_SERVER_ERROR,\n                           \"Chunk received and event sender is null\");\n      chunkEventSender.sendMessage(((HttpChunk) event.getMessage()));\n    } else if (event.getMessage() instanceof HttpRequest) {\n      // Discover and forward event.\n      HttpRequest request = (HttpRequest) event.getMessage();\n      HeaderDecoder.HeaderInfo headInfo = new HeaderDecoder.HeaderInfo(request.getUri(),\n                                                                       request.getHeader(HttpHeaders.Names.HOST),\n                                                                       request.getMethod().getName());\n      // Suspend incoming traffic until connected to the outbound service.\n      inboundChannel.setReadable(false);\n      WrappedDiscoverable discoverable = getDiscoverable(request,\n                                                         (InetSocketAddress) inboundChannel.getLocalAddress());\n\n      // if there is a event sender is already present use it.\n      if (discoveryLookup.containsKey(discoverable)) {\n        inboundChannel.setReadable(true);\n        EventSender eventSender =  discoveryLookup.get(discoverable);\n        eventSender.sendMessage(request);\n        //Save the channelFuture for subsequent chunks\n        if (request.isChunked()) {\n          chunkEventSender = eventSender;\n        }\n      } else {\n        InetSocketAddress address = discoverable.getSocketAddress();\n\n        ChannelFuture outFuture = clientBootstrap.connect(address);\n        Channel outboundChannel = outFuture.getChannel();\n        outboundChannel.getPipeline().addAfter(\"request-encoder\",\n                                               \"outbound-handler\", new OutboundHandler(inboundChannel));\n\n        EventSender eventSender = new EventSender(outFuture);\n        eventSender.sendMessage(request);\n        inboundChannel.setReadable(true);\n        //Save the channelFuture for subsequent chunks\n        if (request.isChunked()) {\n          chunkEventSender = eventSender;\n        }\n        discoveryLookup.put(discoverable, eventSender);\n      }\n\n    } else {\n      super.messageReceived(ctx, event);\n    }\n  }","id":37557,"modified_method":"@Override\n  public void messageReceived(ChannelHandlerContext ctx,\n                              MessageEvent event) throws Exception {\n\n    final Channel inboundChannel = event.getChannel();\n    if (event.getMessage() instanceof HttpChunk) {\n      // This case below should never happen this would mean we get Chunks before HTTPMessage.\n      raiseExceptionIfNull(chunkEventSender, HttpResponseStatus.INTERNAL_SERVER_ERROR,\n                           \"Chunk received and event sender is null\");\n      chunkEventSender.sendMessage(((HttpChunk) event.getMessage()));\n    } else if (event.getMessage() instanceof HttpRequest) {\n      // Discover and forward event.\n      HttpRequest request = (HttpRequest) event.getMessage();\n\n      // Suspend incoming traffic until connected to the outbound service.\n      inboundChannel.setReadable(false);\n      WrappedDiscoverable discoverable = getDiscoverable(request,\n                                                         (InetSocketAddress) inboundChannel.getLocalAddress());\n\n      // If no event sender, make new connection, otherwise reuse existing one.\n      EventSender eventSender =  discoveryLookup.get(discoverable);\n      if (eventSender == null) {\n        InetSocketAddress address = discoverable.getSocketAddress();\n\n        ChannelFuture outFuture = clientBootstrap.connect(address);\n        Channel outboundChannel = outFuture.getChannel();\n        outboundChannel.getPipeline().addAfter(\"request-encoder\",\n                                               \"outbound-handler\", new OutboundHandler(inboundChannel));\n\n        eventSender = new EventSender(outFuture);\n        discoveryLookup.put(discoverable, eventSender);\n      }\n\n      // Send the message.\n      eventSender.sendMessage(request);\n      inboundChannel.setReadable(true);\n      //Save the channelFuture for subsequent chunks\n      if (request.isChunked()) {\n        chunkEventSender = eventSender;\n      }\n\n    } else {\n      super.messageReceived(ctx, event);\n    }\n  }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"public String getHostHeaader() {\n      return hostHeaader;\n    }","id":37558,"modified_method":"public String getHost() {\n      return host;\n    }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"private String genLookupName(String service, String host, String firstPathPart) throws UnsupportedEncodingException {\n    String normalizedHost = Networks.normalizeWebappDiscoveryName(host + firstPathPart);\n    return service.replace(\"$HOST\", normalizedHost);\n  }","id":37559,"modified_method":"private CacheKey(String service, String host, String path) {\n      this.service = service;\n      this.host = host;\n      int ind = path.indexOf('/', 1);\n      this.firstPathPart = ind == -1 ? path : path.substring(0, ind);\n      this.hashCode = Objects.hashCode(service, host, firstPathPart);\n    }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"private EndpointStrategy discoverService(CacheKey key)\n    throws UnsupportedEncodingException, ExecutionException {\n    // First try with path routing\n    String lookupService = genLookupName(key.getService(), key.getHostHeaader(), key.getFirstPathPart());\n    EndpointStrategy endpointStrategy = discover(lookupService);\n\n    if (endpointStrategy.pick() == null) {\n      // Try without path routing\n      lookupService = genLookupName(key.getService(), key.getHostHeaader());\n      endpointStrategy = discover(lookupService);\n    }\n\n    return endpointStrategy;\n  }","id":37560,"modified_method":"private EndpointStrategy discoverService(CacheKey key)\n    throws UnsupportedEncodingException, ExecutionException {\n    // First try with path routing\n    String lookupService = genLookupName(key.getService(), key.getHost(), key.getFirstPathPart());\n    EndpointStrategy endpointStrategy = discover(lookupService);\n\n    if (endpointStrategy.pick() == null) {\n      // Try without path routing\n      lookupService = genLookupName(key.getService(), key.getHost());\n      endpointStrategy = discover(lookupService);\n    }\n\n    return endpointStrategy;\n  }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"/**\n   * Returns the discoverable mapped to the given port.\n   *\n   * @param port port to lookup.\n   * @param httpRequest supplies the header information for the lookup.\n   * @return instance of EndpointStrategy if available null otherwise.\n   */\n  public EndpointStrategy getDiscoverable(int port, HttpRequest httpRequest) {\n    final String service = serviceMapRef.get().get(port);\n    if (service == null) {\n      LOG.debug(\"No service found for port {}\", port);\n      return null;\n    }\n\n    String path = httpRequest.getUri();\n    String host = httpRequest.getHeader(HttpHeaders.Names.HOST);\n    String httpMethod = httpRequest.getMethod().getName();\n\n    final HeaderDecoder.HeaderInfo headerInfo = new HeaderDecoder.HeaderInfo(path, host, httpMethod);\n\n    if (headerInfo == null) {\n      LOG.debug(\"Cannot find host header for service {} on port {}\", service, port);\n      return null;\n    }\n\n    try {\n      String destService = routerPathLookup.getRoutingPath(headerInfo.getPath(), httpRequest);\n      CacheKey cacheKey;\n      if (destService != null) {\n        cacheKey = new CacheKey(destService, headerInfo);\n        LOG.trace(\"Request was routed from {} to: {}\", headerInfo.getPath(), destService);\n      } else {\n        cacheKey = new CacheKey(service, headerInfo);\n        LOG.trace(\"Request was routed from {} to: {}\", headerInfo.getPath(), service);\n      }\n      EndpointStrategy strategy = discoverableCache.get(cacheKey);\n      return strategy;\n    } catch (ExecutionException e) {\n      return null;\n    }\n  }","id":37561,"modified_method":"/**\n   * Returns the discoverable mapped to the given port.\n   *\n   * @param port port to lookup.\n   * @param httpRequest supplies the header information for the lookup.\n   * @return instance of EndpointStrategy if available null otherwise.\n   */\n  public EndpointStrategy getDiscoverable(int port, HttpRequest httpRequest) {\n    final String service = serviceMapRef.get().get(port);\n    if (service == null) {\n      LOG.debug(\"No service found for port {}\", port);\n      return null;\n    }\n\n    // Normalize the path once and strip off any query string. Just keep the URI path.\n    String path = URI.create(httpRequest.getUri()).normalize().getPath();\n    String host = httpRequest.getHeader(HttpHeaders.Names.HOST);\n\n    if (host == null) {\n      LOG.debug(\"Cannot find host header for service {} on port {}\", service, port);\n      return null;\n    }\n\n    try {\n      String destService = routerPathLookup.getRoutingPath(path, httpRequest);\n      CacheKey cacheKey = new CacheKey(destService == null ? service : destService, host, path);\n      LOG.trace(\"Request was routed from {} to: {}\", path, cacheKey.getService());\n\n      return discoverableCache.get(cacheKey);\n    } catch (ExecutionException e) {\n      return null;\n    }\n  }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"@Override\n    public String toString() {\n      return Objects.toStringHelper(this)\n        .add(\"service\", service)\n        .add(\"hostHeaader\", hostHeaader)\n        .add(\"firstPathPart\", firstPathPart)\n        .toString();\n    }","id":37562,"modified_method":"@Override\n    public String toString() {\n      return Objects.toStringHelper(this)\n        .add(\"service\", service)\n        .add(\"host\", host)\n        .add(\"firstPathPart\", firstPathPart)\n        .toString();\n    }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"@Override\n    public int hashCode() {\n      int result = service != null ? service.hashCode() : 0;\n      result = 31 * result + (hostHeaader != null ? hostHeaader.hashCode() : 0);\n      result = 31 * result + (firstPathPart != null ? firstPathPart.hashCode() : 0);\n      return result;\n    }","id":37563,"modified_method":"@Override\n    public int hashCode() {\n      return hashCode;\n    }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"@SuppressWarnings(\"RedundantIfStatement\")\n    @Override\n    public boolean equals(Object o) {\n      if (this == o) {\n        return true;\n      }\n      if (o == null || getClass() != o.getClass()) {\n        return false;\n      }\n\n      CacheKey cacheKey = (CacheKey) o;\n\n      if (firstPathPart != null ? !firstPathPart.equals(cacheKey.firstPathPart) : cacheKey.firstPathPart != null) {\n        return false;\n      }\n      if (hostHeaader != null ? !hostHeaader.equals(cacheKey.hostHeaader) : cacheKey.hostHeaader != null) {\n        return false;\n      }\n      if (service != null ? !service.equals(cacheKey.service) : cacheKey.service != null) {\n        return false;\n      }\n\n      return true;\n    }","id":37564,"modified_method":"@Override\n    public boolean equals(Object o) {\n      if (this == o) {\n        return true;\n      }\n      if (o == null || getClass() != o.getClass()) {\n        return false;\n      }\n\n      CacheKey other = (CacheKey) o;\n      return Objects.equal(service, other.service)\n        && Objects.equal(host, other.host)\n        && Objects.equal(firstPathPart, other.firstPathPart);\n    }","commit_id":"429bdf0989703c3eae6976660406460021b401ad","url":"https://github.com/caskdata/cdap"},{"original_method":"public byte[] loadNextEntry(JarInputStream jarInputStream, DeploymentAction packingAction) throws IOException {\n        final ByteArrayOutputStream byteArrayOutput = new ByteArrayOutputStream();\n        OutputStream outputStreamReference = byteArrayOutput;\n\n        if (packingAction == DeploymentAction.UNPACK_ENTRY) {\n            outputStreamReference = new OutputStreamSplitter(byteArrayOutput, unpackEntry());\n        }\n\n        final byte[] buffer = new byte[BUFFER_READ_LENGTH_IN_BYTES];\n        int read;\n\n        while ((read = jarInputStream.read(buffer)) != -1) {\n            outputStreamReference.write(buffer, 0, read);\n        }\n\n        outputStreamReference.close();\n\n        // add to internal resource hashtable\n        return byteArrayOutput.toByteArray();\n    }","id":37565,"modified_method":"public byte[] loadNextEntry(JarInputStream jarInputStream, DeploymentAction packingAction) throws IOException {\n        final ByteArrayOutputStream byteArrayOutput = new ByteArrayOutputStream();\n        OutputStream outputStreamReference = byteArrayOutput;\n\n        if (packingAction == DeploymentAction.UNPACK_ENTRY) {\n            outputStreamReference = new OutputStreamSplitter(byteArrayOutput, unpackEntry());\n        }\n\n        RawInputStreamReader.instance().copyTo(jarInputStream, outputStreamReference);\n\n        // add to internal resource hashtable\n        return byteArrayOutput.toByteArray();\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public FileOutputStream unpackEntry() throws FileNotFoundException {\n        final String prefix = archiveEntryDescriptor.getPrefix();\n        final File targetDir = new DirectoryHelper(unpackRootDirectory, prefix).createTargetDirectory();\n        final File target = new File(targetDir, archiveEntryDescriptor.getSimpleName() + \".\" + archiveEntryDescriptor.getExtension());\n\n        return new FileOutputStream(target);\n    }","id":37566,"modified_method":"public FileOutputStream unpackEntry() throws FileNotFoundException {\n        final String prefix = archiveEntryDescriptor.getPrefix();\n        final File targetDir = new File(unpackRootDirectory, StringUtilities.isBlank(prefix) ? \"\" : prefix);\n        final DirectoryHelper directoryHelper = new DirectoryHelper(targetDir);\n        \n        if (!directoryHelper.exists()) {\n            if (!directoryHelper.createTargetDirectory()) {\n                LOG.error(\"Unable to create target directory for unpacking artifact - Target directory: \" + targetDir);\n            }\n        }\n        \n        final File target = new File(targetDir, archiveEntryDescriptor.getSimpleName() + \".\" + archiveEntryDescriptor.getExtension());\n        \n        return new FileOutputStream(target);\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ArtifactDirectoryWatcher(EventService eventManagerReference) {\n        this.eventManagerReference = eventManagerReference;\n        this.checkIntervalInMilliseconds = DEFAULT_DIRECTORY_CHECK_INTERVAL;\n\n        artifactSizes = new HashMap<String, Long>();\n    }","id":37567,"modified_method":"public ArtifactDirectoryWatcher(EventService eventManagerReference) {\n        this.eventManagerReference = eventManagerReference;\n        this.checkIntervalInMilliseconds = DEFAULT_DIRECTORY_CHECK_INTERVAL;\n\n        artifactModificationTimes = new HashMap<String, Long>();\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"private void checkArtifacts(final File artifactDirectoryReference) {\n        final Set<String> previousArtifacts = new HashSet<String>(artifactSizes.keySet());\n\n        if (artifactDirectoryReference == null) {\n            throw new DeploymentDirectoryNotFoundException(\"The Power API configured deployment directory is null.  Please check the Power API configuration file.\");\n        }\n\n        for (String artifactPath : artifactDirectoryReference.list(EarFilenameFilter.getInstance())) {\n            final File artifactFile = new File(artifactDirectoryReference, artifactPath);\n            final Long previousArtifactSize = artifactSizes.get(artifactPath), currentArtifactSize = artifactFile.length();\n\n            if (previousArtifactSize != null) {\n                previousArtifacts.remove(artifactPath);\n\n                if (previousArtifactSize != artifactFile.length()) {\n                    artifactSizes.put(artifactPath, currentArtifactSize);\n                    eventManagerReference.newEvent(ApplicationArtifactEvent.UPDATED, artifactFile.getAbsolutePath());\n                }\n            } else {\n                eventManagerReference.newEvent(ApplicationArtifactEvent.NEW, artifactFile.getAbsolutePath());\n            }\n            \n            artifactSizes.put(artifactPath, currentArtifactSize);\n        }\n\n        for (String artifactPath : previousArtifacts) {\n            final File artifactFile = new File(artifactDirectoryReference, artifactPath);\n            \n            artifactSizes.remove(artifactPath);\n            eventManagerReference.newEvent(ApplicationArtifactEvent.DELETED, artifactFile.getAbsolutePath());\n        }\n    }","id":37568,"modified_method":"private void checkArtifacts(final File artifactDirectoryReference) {\n        final Set<String> removedArtifacts = new HashSet<String>(artifactModificationTimes.keySet());\n\n        if (artifactDirectoryReference == null) {\n            throw new DeploymentDirectoryNotFoundException(\"The Power API configured deployment directory is null.  Please check the Power API configuration file.\");\n        }\n\n        for (String artifactPath : artifactDirectoryReference.list(EarFilenameFilter.getInstance())) {\n            final File artifactFile = new File(artifactDirectoryReference, artifactPath);\n            final long lastModifiedTime = artifactFile.lastModified();\n            \n            if (artifactModificationTimes.containsKey(artifactPath)) {\n                final long lastRecordedModifiedTime = artifactModificationTimes.get(artifactPath);\n                \n                removedArtifacts.remove(artifactPath);\n\n                if (lastRecordedModifiedTime != lastModifiedTime) {\n                    artifactModificationTimes.put(artifactPath, lastModifiedTime);\n                    eventManagerReference.newEvent(ApplicationArtifactEvent.UPDATED, artifactFile.getAbsolutePath());\n                }\n            } else {\n                eventManagerReference.newEvent(ApplicationArtifactEvent.NEW, artifactFile.getAbsolutePath());\n            }\n            \n            artifactModificationTimes.put(artifactPath, lastModifiedTime);\n        }\n\n        for (String artifactPath : removedArtifacts) {\n            final File artifactFile = new File(artifactDirectoryReference, artifactPath);\n            \n            artifactModificationTimes.remove(artifactPath);\n            eventManagerReference.newEvent(ApplicationArtifactEvent.DELETED, artifactFile.getAbsolutePath());\n        }\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ArtifactManager(ContainerConfigurationListener containerCfgListener) {\n        this.containerCfgListener = containerCfgListener;\n    }","id":37569,"modified_method":"public ArtifactManager(ContainerConfigurationListener containerCfgListener) {\n        this.containerCfgListener = containerCfgListener;\n        \n        artifactApplicationNames = new HashMap<String, String>();\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public void onEvent(Event<ApplicationArtifactEvent, String> e) {\n        if (StringUtilities.isBlank(e.payload())) {\n            throw new IllegalArgumentException(\"Artifact file must not be null for DeploymentArtifactEvent events\");\n        }\n\n        final File archiveThatChanged = new File(e.payload());\n\n        switch (e.type()) {\n            case NEW:\n                LOG.info(\"New artifact: \" + e.payload());\n                loadArtifact(archiveThatChanged, e.eventManager());\n                break;\n\n            case UPDATED:\n                LOG.info(\"Artifact updated: \" + e.payload());\n                break;\n\n            case DELETED:\n                LOG.info(\"Artifact deleted: \" + e.payload());\n                break;\n        }\n    }","id":37570,"modified_method":"@Override\n    public void onEvent(Event<ApplicationArtifactEvent, String> e) {\n        final String artifactPath = e.payload();\n        \n        if (StringUtilities.isBlank(artifactPath)) {\n            throw new IllegalArgumentException(\"Artifact file must not be null for DeploymentArtifactEvent events\");\n        }\n        \n        switch (e.type()) {\n            case NEW:\n                LOG.info(\"New artifact: \" + artifactPath);\n                loadArtifact(artifactPath, e.eventManager());\n                break;\n\n            case UPDATED:\n                LOG.info(\"Artifact updated: \" + artifactPath);\n                loadArtifact(artifactPath, e.eventManager());\n                break;\n\n            case DELETED:\n                LOG.info(\"Artifact deleted: \" + artifactPath);\n                \n                // Tell the artifact manager that the artifact has been removed\n                e.eventManager().newEvent(ApplicationDeploymentEvent.APPLICATION_DELETED, removeApplicationNameForArtifact(artifactPath));\n                break;\n        }\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"private void loadArtifact(File archive, EventService eventManager) {\n        try {\n            final EarArchiveEntryListener listener = containerCfgListener.newEarArchiveEntryListener();\n            final EarClassLoaderContext classLoaderContext = containerCfgListener.getUnpacker().read(listener, archive);\n\n            // Notify of the new application\n            eventManager.newEvent(ApplicationDeploymentEvent.APPLICATION_LOADED, classLoaderContext);\n        } catch (IOException ioe) {\n            LOG.error(\"Failure in loading artifact, \\\"\" + archive.getAbsolutePath() + \"\\\" - Reason: \" + ioe.getMessage(), ioe);\n        }\n    }","id":37571,"modified_method":"private void loadArtifact(String archivePath, EventService eventManager) {\n        final File archive = new File(archivePath);\n        \n        try {\n            final EarArchiveEntryListener listener = containerCfgListener.newEarArchiveEntryListener();\n            final EarClassLoaderContext classLoaderContext = containerCfgListener.getUnpacker().read(listener, archive);\n\n            // Associates this artifact with the application name for unlinking later\n            setApplicationNameForArtifact(archive.getAbsolutePath(), classLoaderContext.getEarDescriptor().getApplicationName());\n            \n            // Notify of the new application\n            eventManager.newEvent(ApplicationDeploymentEvent.APPLICATION_LOADED, classLoaderContext);\n        } catch (IOException ioe) {\n            LOG.error(\"Failure in loading artifact, \\\"\" + archive.getAbsolutePath() + \"\\\" - Reason: \" + ioe.getMessage(), ioe);\n        }\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public ApplicationClassLoader getService() {\n        return classLoaderContext;\n    }","id":37572,"modified_method":"@Override\n    public ApplicationClassLoaderManager getService() {\n        return classLoaderContext;\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public ClassLoaderServiceContext() {\n        classLoaderContext = new ApplicationClassLoaderImpl();\n    }","id":37573,"modified_method":"public ClassLoaderServiceContext() {\n        classLoaderContext = new ApplicationClassLoaderManagerImpl();\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public void contextInitialized(ServletContextEvent sce) {\n        ServletContextHelper.getPowerApiContext(sce.getServletContext()).eventService().listen(\n                new EventListener<ApplicationDeploymentEvent, EarClassLoaderContext>() {\n\n                    @Override\n                    public void onEvent(Event<ApplicationDeploymentEvent, EarClassLoaderContext> e) {\n                        final EarClassLoaderContext ctx = e.payload();\n\n                        classLoaderContext.putContext(ctx.getEarDescriptor().getApplicationName(), ctx);\n                        e.eventManager().newEvent(ApplicationDeploymentEvent.APPLICATION_COLLECTION_MODIFIED, ctx.getEarDescriptor().getApplicationName());\n                    }\n                }, ApplicationDeploymentEvent.APPLICATION_LOADED);\n    }","id":37574,"modified_method":"@Override\n    public void contextInitialized(ServletContextEvent sce) {\n        final EventService eventSerivce = ServletContextHelper.getPowerApiContext(sce.getServletContext()).eventService();\n\n        eventSerivce.listen(\n                new EventListener<ApplicationDeploymentEvent, EarClassLoaderContext>() {\n\n                    @Override\n                    public void onEvent(Event<ApplicationDeploymentEvent, EarClassLoaderContext> e) {\n                        final EarClassLoaderContext ctx = e.payload();\n\n                        classLoaderContext.putApplication(ctx.getEarDescriptor().getApplicationName(), ctx);\n                        e.eventManager().newEvent(ApplicationDeploymentEvent.APPLICATION_COLLECTION_MODIFIED, ctx.getEarDescriptor().getApplicationName());\n                    }\n                }, ApplicationDeploymentEvent.APPLICATION_LOADED);\n\n        eventSerivce.listen(\n                new EventListener<ApplicationDeploymentEvent, String>() {\n\n                    @Override\n                    public void onEvent(Event<ApplicationDeploymentEvent, String> e) {\n                        classLoaderContext.removeApplication(e.payload());\n                        e.eventManager().newEvent(ApplicationDeploymentEvent.APPLICATION_COLLECTION_MODIFIED, e.payload());\n                    }\n                }, ApplicationDeploymentEvent.APPLICATION_DELETED);\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public DirectoryHelper(File rootDirectory, String directoryName) {\n        this.rootDirectory = rootDirectory;\n        this.directoryName = formatPrefix(directoryName);\n    }","id":37575,"modified_method":"public DirectoryHelper(File directoryFile) {\n        this.directoryFile = directoryFile;\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public File createTargetDirectory() {\n        final File targetDir = new File(rootDirectory, directoryName);\n                        \n        if (!targetDir.mkdirs()) {\n            LOG.warn(\"Failed to create directory [\" + getRootDirectory() + \", \" + getDirectoryName() + \"]\");\n        }\n\n        targetDir.setReadable(false, false);        \n        targetDir.setReadable(true, true);\n\n        targetDir.setExecutable(false, false);\n        targetDir.setExecutable(true, true);\n\n        return targetDir;\n    }","id":37576,"modified_method":"public boolean createTargetDirectory() {\n        if (directoryFile.mkdirs()) {\n            directoryFile.setReadable(false, false);\n            directoryFile.setReadable(true, true);\n\n            directoryFile.setExecutable(false, false);\n            directoryFile.setExecutable(true, true);\n\n            return true;\n        }\n\n        return false;\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"private static File createDeploymentDestination(String target) {\n        final File deploymentDestination = new File(TMP_DIR, target);\n\n        if (!deploymentDestination.mkdirs()) {\n            fail(\"failed to make directory: {\" + TMP_DIR + \",  \" + target + \"}\");\n        }\n\n        return deploymentDestination;\n    }","id":37577,"modified_method":"private static File createDeploymentDestination(String target) {\n        final File deploymentDestination = new File(TMP_DIR, target);\n\n        if (!deploymentDestination.exists() && !deploymentDestination.mkdirs()) {\n            fail(\"failed to make directory: {\" + TMP_DIR + \",  \" + target + \"}\");\n        }\n\n        return deploymentDestination;\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public FilterContext initializeFilter(FilterClassFactory filterClassFactory) {\n        FilterContext newFilterContext;\n        final Thread currentThread = Thread.currentThread();\n        final ClassLoader previousClassLoader = currentThread.getContextClassLoader();\n        final ClassLoader nextClassLoader = filterClassFactory.getClassLoader();\n\n        try {\n            currentThread.setContextClassLoader(nextClassLoader);\n            final javax.servlet.Filter newFilterInstance = filterClassFactory.newInstance();\n\n            newFilterInstance.init(filterConfig);\n\n            newFilterContext = new FilterContext(newFilterInstance, filterClassFactory.getClassLoader());\n\n            LOG.info(\"Filter: \" + newFilterInstance + \" successfully created\");\n        } catch (Throwable e) {\n            LOG.error(\"Failed to initialize filter \" + filterClassFactory + \".\");\n            throw(new FilterInitializationException(e.getMessage(), e));\n        } finally {\n            currentThread.setContextClassLoader(previousClassLoader);\n        }\n\n        return newFilterContext;\n    }","id":37578,"modified_method":"public FilterContext initializeFilter(FilterClassFactory filterClassFactory) {\n        final Thread currentThread = Thread.currentThread();\n        final ClassLoader previousClassLoader = currentThread.getContextClassLoader();\n        final ClassLoader nextClassLoader = filterClassFactory.getClassLoader();\n\n        try {\n            currentThread.setContextClassLoader(nextClassLoader);\n            final javax.servlet.Filter newFilterInstance = filterClassFactory.newInstance();\n\n            newFilterInstance.init(filterConfig);\n\n            LOG.info(\"Filter: \" + newFilterInstance + \" successfully created\");\n            \n            return new FilterContext(newFilterInstance, filterClassFactory.getClassLoader());\n        } catch (Throwable e) {\n            LOG.error(\"Failed to initialize filter \" + filterClassFactory + \".\");\n            throw new FilterInitializationException(e.getMessage(), e);\n        } finally {\n            currentThread.setContextClassLoader(previousClassLoader);\n        }\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public static FilterClassFactory getFilterClassFactory(String filterName, Collection<EarClassLoaderContext> loadedApplications) {\n        FilterClassFactory filterClassFactory = null;\n\n        for (EarClassLoaderContext classLoaderCtx : loadedApplications) {\n            final String filterClassName = classLoaderCtx.getEarDescriptor().getRegisteredFilters().get(filterName);\n\n            if (filterClassName != null) {\n                filterClassFactory = new FilterClassFactory(filterClassName, classLoaderCtx.getClassLoader());\n\n                break;\n            }\n        }\n\n        return filterClassFactory;\n    }","id":37579,"modified_method":"public static FilterClassFactory getFilterClassFactory(String filterName, Collection<EarClassLoaderContext> loadedApplications) {\n        for (EarClassLoaderContext classLoaderCtx : loadedApplications) {\n            final String filterClassName = classLoaderCtx.getEarDescriptor().getRegisteredFilters().get(filterName);\n\n            if (filterClassName != null) {\n                return new FilterClassFactory(filterClassName, classLoaderCtx.getClassLoader());\n            }\n        }\n\n        throw new IllegalStateException(\"Unable to look up filter \" + filterName + \" - this is protected by a validation guard in a higher level of the architecture and should be logged as a defect\");\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Test\n        public void shouldReturnNullIfGivenAnEmptyList() throws ClassNotFoundException {\n            assertNull(FilterContextManagerImpl.getFilterClassFactory(\"\", new LinkedList<EarClassLoaderContext>()));\n        }","id":37580,"modified_method":"@Test (expected=IllegalStateException.class)\n        public void shouldThrowExceptionIfGivenAnEmptyList() throws ClassNotFoundException {\n            assertNull(FilterContextManagerImpl.getFilterClassFactory(\"\", new LinkedList<EarClassLoaderContext>()));\n        }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public ApplicationClassLoader classLoader() throws ServiceUnavailableException {\n        return lookup(ClassLoaderServiceContext.SERVICE_NAME, namingContext);\n    }","id":37581,"modified_method":"@Override\n    public ApplicationClassLoaderManager classLoader() throws ServiceUnavailableException {\n        return lookup(ClassLoaderServiceContext.SERVICE_NAME, namingContext);\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public List<FilterContext> build(ApplicationClassLoader classLoaderContextManager, PowerProxy powerProxy) {\n        final List<FilterContext> filterContexts = new LinkedList<FilterContext>();\n\n        for (com.rackspace.papi.model.Filter papiFilter : new LocalhostFilterList(powerProxy).getFilters()) {\n            //TODO: Validate Filter configuration contents - i.e. null name\n            \n            final FilterContext context = getFilterContext(classLoaderContextManager, papiFilter);\n\n            if (context != null) {\n                filterContexts.add(context);\n            }\n        }\n\n        return new LinkedList<FilterContext>(filterContexts);\n    }","id":37582,"modified_method":"public List<FilterContext> build(ApplicationClassLoaderManager classLoaderContextManager, PowerProxy powerProxy) {\n        final List<FilterContext> filterContexts = new LinkedList<FilterContext>();\n\n        for (com.rackspace.papi.model.Filter papiFilter : new LocalhostFilterList(powerProxy).getFilters()) {\n            if (StringUtilities.isBlank(papiFilter.getName())) {\n                LOG.error(\"Filter declaration has a null or empty name value - please check your system model configuration\");\n                continue;\n            }\n            \n            if (classLoaderContextManager.hasFilter(papiFilter.getName())) {\n                final FilterContext context = getFilterContext(classLoaderContextManager, papiFilter);\n\n                if (context != null) {\n                    filterContexts.add(context);\n                }\n            } else {\n                LOG.error(\"Unable to satisfy requested filter chain - none of the loaded artifacts supply a filter named \" + papiFilter.getName());\n            }\n        }\n\n        return new LinkedList<FilterContext>(filterContexts);\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public FilterContext getFilterContext(ApplicationClassLoader classLoaderContextManager, Filter papiFilter) {\n        FilterContext context = null;\n\n        try {\n            context = filterContextManager.loadFilterContext(papiFilter.getName(),\n                    classLoaderContextManager.getLoadedApplications());\n        } catch (Exception e) {\n            LOG.info(\"Problem loading the filter class. Just process the next filter.\", e);\n        }\n\n        return context;\n    }","id":37583,"modified_method":"public FilterContext getFilterContext(ApplicationClassLoaderManager classLoaderContextManager, Filter papiFilter) {\n        FilterContext context = null;\n\n        try {\n            context = filterContextManager.loadFilterContext(papiFilter.getName(),\n                    classLoaderContextManager.getLoadedApplications());\n        } catch (Exception e) {\n            LOG.info(\"Problem loading the filter class. Just process the next filter.\", e);\n        }\n\n        return context;\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Test\n        public void shouldBuild() throws ClassNotFoundException {\n            ApplicationClassLoader mockedEarClassLoaderContextManager = mock(ApplicationClassLoader.class);\n\n            EarClassLoaderContext mockedEarClassLoaderContext = mock(EarClassLoaderContext.class);\n            EarDescriptor mockedEarDescriptor = mock(EarDescriptor.class);\n            Map<String, String> mockedFiltersMap = mock(Map.class);\n            EarClassLoader mockedEarClassLoader = mock(EarClassLoader.class);\n\n            when(mockedEarClassLoaderContext.getEarDescriptor()).thenReturn(mockedEarDescriptor);\n            when(mockedEarDescriptor.getRegisteredFilters()).thenReturn(mockedFiltersMap);\n            when(mockedEarClassLoaderContext.getClassLoader()).thenReturn(mockedEarClassLoader);\n            when(mockedFiltersMap.get(any(String.class))).thenReturn(\"FilterClassName\");\n            when(mockedEarClassLoader.loadClass(any(String.class))).thenReturn((Class) FakeFilterClass.class);\n\n            Collection<EarClassLoaderContext> loadedApplications = new LinkedList<EarClassLoaderContext>();\n            loadedApplications.add(mockedEarClassLoaderContext);\n\n            when(mockedEarClassLoaderContextManager.getLoadedApplications()).thenReturn(loadedApplications);\n\n            Filter mockedFilter = mock(Filter.class);\n            when(mockedFilter.getName()).thenReturn(\"filterName\");\n\n            PowerFilterChainBuilder powerFilterChainBuilder = new PowerFilterChainBuilder(mockedFilterConfig);\n\n            PowerProxy mockedPowerProxy = mock(PowerProxy.class);\n            List<Host> hosts = createTestHosts();\n            when(mockedPowerProxy.getHost()).thenReturn(hosts);\n\n            List<FilterContext> powerFilterChain = powerFilterChainBuilder.build(mockedEarClassLoaderContextManager, mockedPowerProxy);\n\n            assertNotNull(powerFilterChain);\n        }","id":37584,"modified_method":"@Test\n        public void shouldBuild() throws ClassNotFoundException {\n            ApplicationClassLoaderManager mockedEarClassLoaderContextManager = mock(ApplicationClassLoaderManager.class);\n\n            EarClassLoaderContext mockedEarClassLoaderContext = mock(EarClassLoaderContext.class);\n            EarDescriptor mockedEarDescriptor = mock(EarDescriptor.class);\n            Map<String, String> mockedFiltersMap = mock(Map.class);\n            EarClassLoader mockedEarClassLoader = mock(EarClassLoader.class);\n\n            when(mockedEarClassLoaderContext.getEarDescriptor()).thenReturn(mockedEarDescriptor);\n            when(mockedEarDescriptor.getRegisteredFilters()).thenReturn(mockedFiltersMap);\n            when(mockedEarClassLoaderContext.getClassLoader()).thenReturn(mockedEarClassLoader);\n            when(mockedFiltersMap.get(any(String.class))).thenReturn(\"FilterClassName\");\n            when(mockedEarClassLoader.loadClass(any(String.class))).thenReturn((Class) FakeFilterClass.class);\n\n            Collection<EarClassLoaderContext> loadedApplications = new LinkedList<EarClassLoaderContext>();\n            loadedApplications.add(mockedEarClassLoaderContext);\n\n            when(mockedEarClassLoaderContextManager.getLoadedApplications()).thenReturn(loadedApplications);\n\n            Filter mockedFilter = mock(Filter.class);\n            when(mockedFilter.getName()).thenReturn(\"filterName\");\n\n            PowerFilterChainBuilder powerFilterChainBuilder = new PowerFilterChainBuilder(mockedFilterConfig);\n\n            PowerProxy mockedPowerProxy = mock(PowerProxy.class);\n            List<Host> hosts = createTestHosts();\n            when(mockedPowerProxy.getHost()).thenReturn(hosts);\n\n            List<FilterContext> powerFilterChain = powerFilterChainBuilder.build(mockedEarClassLoaderContextManager, mockedPowerProxy);\n\n            assertNotNull(powerFilterChain);\n        }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Test\n        public void shouldReturnEmptyList() throws ClassNotFoundException {\n            ApplicationClassLoader mockedEarClassLoaderContextManager = mock(ApplicationClassLoader.class);\n\n            EarClassLoaderContext mockedEarClassLoaderContext = mock(EarClassLoaderContext.class);\n            EarDescriptor mockedEarDescriptor = mock(EarDescriptor.class);\n            Map<String, String> mockedFiltersMap = mock(Map.class);\n            EarClassLoader mockedEarClassLoader = mock(EarClassLoader.class);\n\n            when(mockedEarClassLoaderContext.getEarDescriptor()).thenReturn(mockedEarDescriptor);\n            when(mockedEarDescriptor.getRegisteredFilters()).thenReturn(mockedFiltersMap);\n            when(mockedEarClassLoaderContext.getClassLoader()).thenReturn(mockedEarClassLoader);\n            when(mockedFiltersMap.get(any(String.class))).thenReturn(\"FilterClassName\");\n            when(mockedEarClassLoader.loadClass(any(String.class))).thenReturn(null);\n\n            Collection<EarClassLoaderContext> loadedApplications = new LinkedList<EarClassLoaderContext>();\n            loadedApplications.add(mockedEarClassLoaderContext);\n\n            when(mockedEarClassLoaderContextManager.getLoadedApplications()).thenReturn(loadedApplications);\n\n            Filter mockedFilter = mock(Filter.class);\n            when(mockedFilter.getName()).thenReturn(\"filterName\");\n\n            PowerFilterChainBuilder powerFilterChainBuilder = new PowerFilterChainBuilder(mockedFilterConfig);\n\n            PowerProxy mockedPowerProxy = mock(PowerProxy.class);\n            List<Host> hosts = createTestHosts();\n            when(mockedPowerProxy.getHost()).thenReturn(hosts);\n\n            List<FilterContext> powerFilterChain = powerFilterChainBuilder.build(mockedEarClassLoaderContextManager, mockedPowerProxy);\n\n            assertEquals(0, powerFilterChain.size());\n        }","id":37585,"modified_method":"@Test\n        public void shouldReturnEmptyList() throws ClassNotFoundException {\n            ApplicationClassLoaderManager mockedEarClassLoaderContextManager = mock(ApplicationClassLoaderManager.class);\n\n            EarClassLoaderContext mockedEarClassLoaderContext = mock(EarClassLoaderContext.class);\n            EarDescriptor mockedEarDescriptor = mock(EarDescriptor.class);\n            Map<String, String> mockedFiltersMap = mock(Map.class);\n            EarClassLoader mockedEarClassLoader = mock(EarClassLoader.class);\n\n            when(mockedEarClassLoaderContext.getEarDescriptor()).thenReturn(mockedEarDescriptor);\n            when(mockedEarDescriptor.getRegisteredFilters()).thenReturn(mockedFiltersMap);\n            when(mockedEarClassLoaderContext.getClassLoader()).thenReturn(mockedEarClassLoader);\n            when(mockedFiltersMap.get(any(String.class))).thenReturn(\"FilterClassName\");\n            when(mockedEarClassLoader.loadClass(any(String.class))).thenReturn(null);\n\n            Collection<EarClassLoaderContext> loadedApplications = new LinkedList<EarClassLoaderContext>();\n            loadedApplications.add(mockedEarClassLoaderContext);\n\n            when(mockedEarClassLoaderContextManager.getLoadedApplications()).thenReturn(loadedApplications);\n\n            Filter mockedFilter = mock(Filter.class);\n            when(mockedFilter.getName()).thenReturn(\"filterName\");\n\n            PowerFilterChainBuilder powerFilterChainBuilder = new PowerFilterChainBuilder(mockedFilterConfig);\n\n            PowerProxy mockedPowerProxy = mock(PowerProxy.class);\n            List<Host> hosts = createTestHosts();\n            when(mockedPowerProxy.getHost()).thenReturn(hosts);\n\n            List<FilterContext> powerFilterChain = powerFilterChainBuilder.build(mockedEarClassLoaderContextManager, mockedPowerProxy);\n\n            assertEquals(0, powerFilterChain.size());\n        }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"public byte[] readFully(InputStream is) throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final byte[] internalBuffer = new byte[DEFAULT_INTERNAL_BUFFER_SIZE];\n        \n        int read;\n        \n        while((read = is.read(internalBuffer)) != -1) {\n            baos.write(internalBuffer, 0, read);\n        }\n        \n        is.close();\n        \n        return baos.toByteArray();\n    }","id":37586,"modified_method":"public byte[] readFully(InputStream is) throws IOException {\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        final byte[] internalBuffer = new byte[DEFAULT_INTERNAL_BUFFER_SIZE];\n\n        int read;\n\n        while ((read = is.read(internalBuffer)) != -1) {\n            baos.write(internalBuffer, 0, read);\n        }\n\n        return baos.toByteArray();\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"@Override\n    public Object perform(Unmarshaller resource) throws ResourceContextException {\n        try {\n            return resource.unmarshal(cfgResource.newInputStream());\n        } catch(Exception ex) {\n            throw new ResourceContextException(\"Failed to unmarshall input stream. Reason: \" + ex.getMessage(), ex);\n        }\n    }","id":37587,"modified_method":"@Override\n    public Object perform(Unmarshaller resource) throws ResourceContextException {\n        try {\n            return resource.unmarshal(cfgResource.newInputStream());\n        } catch (JAXBException jaxbe) {\n            throw new ResourceContextException(\"Failed to unmarshall resource \" + cfgResource.name() + \" - Error code: \" + jaxbe.getErrorCode(), jaxbe.getLinkedException());\n        } catch (Exception ex) {\n            throw new ResourceContextException(\"Failed to unmarshall resource \" + cfgResource.name() + \" - Reason: \" + ex.getMessage(), ex);\n        }\n    }","commit_id":"2260ab453b76468f02d1c9e374beb0b9537b37a3","url":"https://github.com/rackerlabs/repose"},{"original_method":"private void maybeSlowShrink(boolean dontCheckForHoles, boolean inStartUp) throws DatabaseException, IOException {\n\t\tList wantedKeep = new ArrayList(); // keep; content is wanted, and is in the right place\n\t\tList unwantedIgnore = new ArrayList(); // ignore; content is not wanted, and is not in the right place\n\t\tList wantedMove = new ArrayList(); // content is wanted, but is in the wrong part of the store\n\t\tList unwantedMove = new ArrayList(); // content is not wanted, but is in the part of the store we will keep\n\t\tList alreadyDropped = new ArrayList(); // any blocks past the end which have already been truncated, but which there are still database blocks pointing to\n\t\t\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\n\t\tlong newSize = maxBlocksInStore;\n\t\tif(blocksInStore < maxBlocksInStore) return;\n\t\t\n\t\tSystem.err.println(\"Shrinking from \"+blocksInStore+\" to \"+maxBlocksInStore+\" (from db \"+keysDB.count()+\" from file \"+countCHKBlocksFromFile()+ ')');\n\t\t\n\t\tif(!dontCheckForHoles)\n\t\t\tcheckForHoles(maxBlocksInStore, true);\n\t\t\n\t\tWrapperManager.signalStarting((int) (Math.min(Integer.MAX_VALUE, 5 * 60 * 1000 + blocksInStore * 100L))); // 10 per second\n\t\t\n\t\tlong realSize = countCHKBlocksFromFile();\n\t\t\n\t\tlong highestBlock = 0;\n\t\t\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(null,null);\n\t\t\t\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\t\tOperationStatus opStat;\n\t\t\topStat = c.getLast(keyDBE, blockDBE, LockMode.RMW);\n\t\t\t\n\t\t\tif(opStat == OperationStatus.NOTFOUND) {\n\t\t\t\tSystem.err.println(\"Database is empty (shrinking).\");\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t//Logger.minor(this, \"Found first key\");\n\t\t\tint x = 0;\n\t\t\twhile(true) {\n\t\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\tlong block = storeBlock.offset;\n\t\t\t\tif(block > highestBlock) highestBlock = block;\n\t\t\t\tif(storeBlock.offset > Integer.MAX_VALUE) {\n\t\t\t\t\t// 2^31 * blockSize; ~ 70TB for CHKs, 2TB for the others\n\t\t\t\t\tSystem.err.println(\"Store too big, doing quick shrink\"); // memory usage would be insane\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tmaybeQuickShrink(true);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tInteger blockNum = (int) storeBlock.offset;\n\t\t\t\t//Long seqNum = new Long(storeBlock.recentlyUsed);\n\t\t\t\t//System.out.println(\"#\"+x+\" seq \"+seqNum+\": block \"+blockNum);\n\t\t\t\tif(blockNum.longValue() >= realSize) {\n\t\t\t\t\t// Truncated already?\n\t\t\t\t\tLogger.minor(this, \"Truncated already? \"+blockNum.longValue());\n\t\t\t\t\talreadyDropped.add(blockNum);\n\t\t\t\t\t\n\t\t\t\t} else {\n\t\t\t\t\tif(x < newSize) {\n\t\t\t\t\t\t// Wanted\n\t\t\t\t\t\tif(block < newSize) {\n\t\t\t\t\t\t\t//System.out.println(\"Keep where it is: block \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\twantedKeep.add(blockNum);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t//System.out.println(\"Move to where it should go: \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\twantedMove.add(blockNum);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Unwanted\n\t\t\t\t\t\tif(block < newSize) {\n\t\t\t\t\t\t\t//System.out.println(\"Overwrite: \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\tunwantedMove.add(blockNum);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t//System.out.println(\"Ignore, will be wiped: block \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\tunwantedIgnore.add(blockNum);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tx++;\n\t\t\t\t\tif(x % 1024 == 0) {\n\t\t\t\t\t\tSystem.out.println(\"Reading store prior to shrink: \"+(x*100L/realSize)+ \"% ( \"+x+ '/' +realSize+ ')');\n\t\t\t\t\t}\n\t\t\t\t\tif(x == Integer.MAX_VALUE) {\n\t\t\t\t\t\tSystem.err.println(\"Key number \"+x+\" - ignoring store after \"+(x*(dataBlockSize+headerBlockSize)+\" bytes\"));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\topStat = c.getPrev(keyDBE, blockDBE, LockMode.RMW);\n\t\t\t\tif(opStat == OperationStatus.NOTFOUND) {\n\t\t\t\t\tSystem.out.println(\"Read store: \"+x+\" keys.\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t} finally {\n\t\t\tif(c != null)\n\t\t\t\tc.close();\n\t\t}\n\t\t\n\t\tInteger[] wantedKeepNums = (Integer[]) wantedKeep.toArray(new Integer[wantedKeep.size()]);\n\t\tInteger[] unwantedIgnoreNums = (Integer[]) unwantedIgnore.toArray(new Integer[unwantedIgnore.size()]);\n\t\tInteger[] wantedMoveNums = (Integer[]) wantedMove.toArray(new Integer[wantedMove.size()]);\n\t\tInteger[] unwantedMoveNums = (Integer[]) unwantedMove.toArray(new Integer[unwantedMove.size()]);\n\t\tlong[] freeEarlySlots = freeBlocks.toArray();\n\t\tArrays.sort(wantedKeepNums);\n\t\tArrays.sort(unwantedIgnoreNums);\n\t\tArrays.sort(wantedMoveNums);\n\t\tArrays.sort(unwantedMoveNums);\n\t\t\n\t\tfor(int i=0;i<newSize;i++) {\n\t\t\tInteger ii = new Integer(i);\n\t\t\tif(Arrays.binarySearch(wantedKeepNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(unwantedIgnoreNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(wantedMoveNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(unwantedMoveNums, ii) >= 0) continue;\n\t\t\tunwantedMove.add(ii);\n\t\t}\n\t\tunwantedMoveNums = (Integer[]) unwantedMove.toArray(new Integer[unwantedMove.size()]);\n\t\t\n\t\tSystem.err.println(\"Keys to keep where they are:     \"+wantedKeepNums.length);\n\t\tSystem.err.println(\"Keys which will be wiped anyway: \"+unwantedIgnoreNums.length);\n\t\tSystem.err.println(\"Keys to move:                    \"+wantedMoveNums.length);\n\t\tSystem.err.println(\"Keys to be moved over:           \"+unwantedMoveNums.length);\n\t\tSystem.err.println(\"Free slots to be moved over:     \"+freeEarlySlots.length);\n\t\t\n\t\t// Now move all the wantedMove blocks onto the corresponding unwantedMove's.\n\t\t\n\t\tWrapperManager.signalStarting((int)Math.min(Integer.MAX_VALUE, (5*60*1000 + wantedMoveNums.length*1000L + alreadyDropped.size() * 100L))); // 1 per second\n\t\t\n\t\tByteBuffer buf = ByteBuffer.allocate(headerBlockSize + dataBlockSize);\n\t\tlong lruValue;\n\t\tbyte[] keyBuf = new byte[keyLength];\n\t\tt = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tif(alreadyDropped.size() > 0) {\n\t\t\t\tSystem.err.println(\"Deleting \"+alreadyDropped.size()+\" blocks beyond the length of the file\");\n\t\t\t\tfor(int i=0;i<alreadyDropped.size();i++) {\n\t\t\t\t\tint unwantedBlock = ((Integer) alreadyDropped.get(i)).intValue();\n\t\t\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\t\t\tLongBinding.longToEntry(unwantedBlock, unwantedBlockEntry);\n\t\t\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\t\t\tif(i % 1024 == 0) {\n\t\t\t\t\t\tt.commit();\n\t\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(alreadyDropped.size() % 1024 != 0) {\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor(int i=0;i<wantedMoveNums.length;i++) {\n\t\t\t\tInteger wantedBlock = wantedMoveNums[i];\n\t\t\t\t\n\t\t\t\tInteger unwantedBlock;\n\t\t\t\t\n\t\t\t\t// Can we move over an empty slot?\n\t\t\t\tif(i < freeEarlySlots.length) {\n\t\t\t\t\t// Don't need to delete old block\n\t\t\t\t\tunwantedBlock = new Integer((int) freeEarlySlots[i]); // will fit in an int\n\t\t\t\t} else if(unwantedMoveNums.length + freeEarlySlots.length > i) {\n\t\t\t\t\tunwantedBlock = unwantedMoveNums[i-freeEarlySlots.length];\n\t\t\t\t\t// Delete unwantedBlock from the store\n\t\t\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\t\t\tLongBinding.longToEntry(unwantedBlock.longValue(), unwantedBlockEntry);\n\t\t\t\t\t// Delete the old block from the database.\n\t\t\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\t\t} else {\n\t\t\t\t\tSystem.err.println(\"Keys to move but no keys to move over! Moved \"+i);\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// Move old data to new location\n\t\t\t\t\n\t\t\t\tDatabaseEntry wantedBlockEntry = new DatabaseEntry();\n\t\t\t\tLongBinding.longToEntry(wantedBlock.longValue(), wantedBlockEntry);\n\t\t\t\tlong entry = wantedBlock.longValue();\n\t\t\t\tboolean readLRU = false;\n\t\t\t\tboolean readKey = false;\n\t\t\t\ttry {\n\t\t\t\t\tbuf.rewind();\n\t\t\t\t\tdo {\n\t\t\t\t\t\tint byteRead = storeFC.read(buf, entry * (headerBlockSize + dataBlockSize) + buf.position());\n\t\t\t\t\t\tif (byteRead == -1)\n\t\t\t\t\t\t\tthrow new EOFException();\n\t\t\t\t\t} while (buf.hasRemaining());\n\t\t\t\t\tbuf.flip();\n\t\t\t\t\tlruValue = 0;\n\t\t\t\t\tif(lruRAF.length() > ((entry + 1) * 8)) {\n\t\t\t\t\t\treadLRU = true;\n\t\t\t\t\t\tlruValue = fcReadLRU(entry);\n\t\t\t\t\t}\n\t\t\t\t\tif(keysRAF != null && keysRAF.length() > ((entry + 1) * keyLength)) {\n\t\t\t\t\t\treadKey = true;\n\t\t\t\t\t\tfcReadKey(entry, keyBuf);\n\t\t\t\t\t}\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tSystem.err.println(\"Was reading \"+wantedBlock+\" to write to \"+unwantedBlock);\n\t\t\t\t\tSystem.err.println(e);\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t\tentry = unwantedBlock.longValue();\n\t\t\t\tdo {\n\t\t\t\t\tint byteWritten = storeFC.write(buf, entry * (headerBlockSize + dataBlockSize) + buf.position());\n\t\t\t\t\tif (byteWritten == -1)\n\t\t\t\t\t\tthrow new EOFException();\n\t\t\t\t} while (buf.hasRemaining());\n\t\t\t\tif(readLRU) {\n\t\t\t\t\tfcWriteLRU(entry, lruValue);\n\t\t\t\t}\n\t\t\t\tif(readKey) {\n\t\t\t\t\tfcWriteKey(entry, keyBuf);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// Update the database w.r.t. the old block.\n\t\t\t\t\n\t\t\t\tDatabaseEntry routingKeyDBE = new DatabaseEntry();\n\t\t\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\t\t\tblockNumDB.get(t, wantedBlockEntry, routingKeyDBE, blockDBE, LockMode.RMW);\n\t\t\t\tStoreBlock block = (StoreBlock) storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\tblock.offset = unwantedBlock.longValue();\n\t\t\t\tstoreBlockTupleBinding.objectToEntry(block, blockDBE);\n\t\t\t\tkeysDB.put(t, routingKeyDBE, blockDBE);\n\t\t\t\t\n\t\t\t\t// Think about committing the transaction.\n\t\t\t\t\n\t\t\t\tif((i+1) % 2048 == 0) {\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t\tSystem.out.println(\"Moving blocks: \"+(i*100/wantedMove.size())+ \"% ( \"+i+ '/' +wantedMove.size()+ ')');\n\t\t\t\t}\n\t\t\t\t//System.err.println(\"Moved \"+wantedBlock+\" to \"+unwantedBlock);\n\t\t\t}\n\t\t\tSystem.out.println(\"Moved all \"+wantedMove.size()+\" blocks\");\n\t\t\tif(t != null) {\n\t\t\t\tt.commit();\n\t\t\t\tt = null;\n\t\t\t}\n\t\t} finally {\n\t\t\tif(t != null)\n\t\t\t\tt.abort();\n\t\t\tt = null;\n\t\t}\n\t\tSystem.out.println(\"Completing shrink\"); // FIXME remove\n\t\t\n\t\tint totalUnwantedBlocks = unwantedMoveNums.length+freeEarlySlots.length;\n\t\tWrapperManager.signalStarting((int) Math.min(Integer.MAX_VALUE, 5*60*1000 + (totalUnwantedBlocks-wantedMoveNums.length) * 100L));\n\t\t// If there are any slots left over, they must be free.\n\t\t\n\t\t// FIXME put these into the database as we do in reconstruct().\n\t\t// Not doing that now as its not immediately obvious how to deal with it...\n\t\t\n\t\tfreeBlocks.clear();\n\t\tt = environment.beginTransaction(null,null);\n\t\tfor(int i=wantedMoveNums.length;i<totalUnwantedBlocks;i++) {\n\t\t\tlong blockNo;\n\t\t\tString reason;\n\t\t\tif(i < freeEarlySlots.length) {\n\t\t\t\tblockNo = freeEarlySlots[i];\n\t\t\t\treason = \"early slot \"+i;\n\t\t\t} else {\n\t\t\t\tblockNo = unwantedMoveNums[i-freeEarlySlots.length].longValue();\n\t\t\t\treason = \"unwanted \"+(i-freeEarlySlots.length);\n\t\t\t}\n\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\tLongBinding.longToEntry(blockNo, unwantedBlockEntry);\n\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\tif(i % 1024 == 0) {\n\t\t\t\tSystem.out.println(\"Trimmed surplus keys in database: \"+(i-wantedMoveNums.length)+\"/\"+(totalUnwantedBlocks-wantedMoveNums.length));\n\t\t\t\tt.commit();\n\t\t\t\tif(i == totalUnwantedBlocks-1)\n\t\t\t\t\tt = null;\n\t\t\t\telse\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t}\n\t\t\taddFreeBlock(blockNo, true, reason);\n\t\t}\n\t\tif(t != null) t.commit();\n\t\tt = null;\n\t\t\n\t\tSystem.out.println(\"Finishing shrink\"); // FIXME remove\n\t\t\n\t\tstoreRAF.setLength(newSize * (dataBlockSize + headerBlockSize));\n\t\tlruRAF.setLength(newSize * 8);\n\t\tif(keysRAF != null)\n\t\t\tkeysRAF.setLength(newSize * keyLength);\n\t\t\n\t\tsynchronized(this) {\n\t\t\tblocksInStore = newSize;\n\t\t}\n\t\tSystem.err.println(\"Shrunk store, now have \"+blocksInStore+\" of \"+maxBlocksInStore);\n\t}","id":37588,"modified_method":"private void maybeSlowShrink(boolean dontCheckForHoles, boolean inStartUp) throws DatabaseException, IOException {\n\t\tList<Integer> wantedKeep = new ArrayList<Integer>(); // keep; content is wanted, and is in the right place\n\t\tList<Integer> unwantedIgnore = new ArrayList<Integer>(); // ignore; content is not wanted, and is not in the right place\n\t\tList<Integer> wantedMove = new ArrayList<Integer>(); // content is wanted, but is in the wrong part of the store\n\t\tList<Integer> unwantedMove = new ArrayList<Integer>(); // content is not wanted, but is in the part of the store we will keep\n\t\tList<Integer> alreadyDropped = new ArrayList<Integer>(); // any blocks past the end which have already been truncated, but which there are still database blocks pointing to\n\t\t\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\n\t\tlong newSize = maxBlocksInStore;\n\t\tif(blocksInStore < maxBlocksInStore) return;\n\t\t\n\t\tSystem.err.println(\"Shrinking from \"+blocksInStore+\" to \"+maxBlocksInStore+\" (from db \"+keysDB.count()+\" from file \"+countCHKBlocksFromFile()+ ')');\n\t\t\n\t\tif(!dontCheckForHoles)\n\t\t\tcheckForHoles(maxBlocksInStore, true);\n\t\t\n\t\tWrapperManager.signalStarting((int) (Math.min(Integer.MAX_VALUE, 5 * 60 * 1000 + blocksInStore * 100L))); // 10 per second\n\t\t\n\t\tlong realSize = countCHKBlocksFromFile();\n\t\t\n\t\tlong highestBlock = 0;\n\t\t\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(null,null);\n\t\t\t\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\t\tOperationStatus opStat;\n\t\t\topStat = c.getLast(keyDBE, blockDBE, LockMode.RMW);\n\t\t\t\n\t\t\tif(opStat == OperationStatus.NOTFOUND) {\n\t\t\t\tSystem.err.println(\"Database is empty (shrinking).\");\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t//Logger.minor(this, \"Found first key\");\n\t\t\tint x = 0;\n\t\t\twhile(true) {\n\t\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\tlong block = storeBlock.offset;\n\t\t\t\tif(block > highestBlock) highestBlock = block;\n\t\t\t\tif(storeBlock.offset > Integer.MAX_VALUE) {\n\t\t\t\t\t// 2^31 * blockSize; ~ 70TB for CHKs, 2TB for the others\n\t\t\t\t\tSystem.err.println(\"Store too big, doing quick shrink\"); // memory usage would be insane\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tmaybeQuickShrink(true);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tInteger blockNum = (int) storeBlock.offset;\n\t\t\t\t//Long seqNum = new Long(storeBlock.recentlyUsed);\n\t\t\t\t//System.out.println(\"#\"+x+\" seq \"+seqNum+\": block \"+blockNum);\n\t\t\t\tif(blockNum.longValue() >= realSize) {\n\t\t\t\t\t// Truncated already?\n\t\t\t\t\tLogger.minor(this, \"Truncated already? \"+blockNum.longValue());\n\t\t\t\t\talreadyDropped.add(blockNum);\n\t\t\t\t\t\n\t\t\t\t} else {\n\t\t\t\t\tif(x < newSize) {\n\t\t\t\t\t\t// Wanted\n\t\t\t\t\t\tif(block < newSize) {\n\t\t\t\t\t\t\t//System.out.println(\"Keep where it is: block \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\twantedKeep.add(blockNum);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t//System.out.println(\"Move to where it should go: \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\twantedMove.add(blockNum);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Unwanted\n\t\t\t\t\t\tif(block < newSize) {\n\t\t\t\t\t\t\t//System.out.println(\"Overwrite: \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\tunwantedMove.add(blockNum);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t//System.out.println(\"Ignore, will be wiped: block \"+blockNum+\" seq # \"+x+\" / \"+newSize);\n\t\t\t\t\t\t\tunwantedIgnore.add(blockNum);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tx++;\n\t\t\t\t\tif(x % 1024 == 0) {\n\t\t\t\t\t\tSystem.out.println(\"Reading store prior to shrink: \"+(x*100L/realSize)+ \"% ( \"+x+ '/' +realSize+ ')');\n\t\t\t\t\t}\n\t\t\t\t\tif(x == Integer.MAX_VALUE) {\n\t\t\t\t\t\tSystem.err.println(\"Key number \"+x+\" - ignoring store after \"+(x*(dataBlockSize+headerBlockSize)+\" bytes\"));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\topStat = c.getPrev(keyDBE, blockDBE, LockMode.RMW);\n\t\t\t\tif(opStat == OperationStatus.NOTFOUND) {\n\t\t\t\t\tSystem.out.println(\"Read store: \"+x+\" keys.\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t} finally {\n\t\t\tif(c != null)\n\t\t\t\tc.close();\n\t\t}\n\t\t\n\t\tInteger[] wantedKeepNums = wantedKeep.toArray(new Integer[wantedKeep.size()]);\n\t\tInteger[] unwantedIgnoreNums = unwantedIgnore.toArray(new Integer[unwantedIgnore.size()]);\n\t\tInteger[] wantedMoveNums = wantedMove.toArray(new Integer[wantedMove.size()]);\n\t\tInteger[] unwantedMoveNums = unwantedMove.toArray(new Integer[unwantedMove.size()]);\n\t\tlong[] freeEarlySlots = freeBlocks.toArray();\n\t\tArrays.sort(wantedKeepNums);\n\t\tArrays.sort(unwantedIgnoreNums);\n\t\tArrays.sort(wantedMoveNums);\n\t\tArrays.sort(unwantedMoveNums);\n\t\t\n\t\tfor(int i=0;i<newSize;i++) {\n\t\t\tInteger ii = new Integer(i);\n\t\t\tif(Arrays.binarySearch(wantedKeepNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(unwantedIgnoreNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(wantedMoveNums, ii) >= 0) continue;\n\t\t\tif(Arrays.binarySearch(unwantedMoveNums, ii) >= 0) continue;\n\t\t\tunwantedMove.add(ii);\n\t\t}\n\t\tunwantedMoveNums = unwantedMove.toArray(new Integer[unwantedMove.size()]);\n\t\t\n\t\tSystem.err.println(\"Keys to keep where they are:     \"+wantedKeepNums.length);\n\t\tSystem.err.println(\"Keys which will be wiped anyway: \"+unwantedIgnoreNums.length);\n\t\tSystem.err.println(\"Keys to move:                    \"+wantedMoveNums.length);\n\t\tSystem.err.println(\"Keys to be moved over:           \"+unwantedMoveNums.length);\n\t\tSystem.err.println(\"Free slots to be moved over:     \"+freeEarlySlots.length);\n\t\t\n\t\t// Now move all the wantedMove blocks onto the corresponding unwantedMove's.\n\t\t\n\t\tWrapperManager.signalStarting((int)Math.min(Integer.MAX_VALUE, (5*60*1000 + wantedMoveNums.length*1000L + alreadyDropped.size() * 100L))); // 1 per second\n\t\t\n\t\tByteBuffer buf = ByteBuffer.allocate(headerBlockSize + dataBlockSize);\n\t\tlong lruValue;\n\t\tbyte[] keyBuf = new byte[keyLength];\n\t\tt = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tif(alreadyDropped.size() > 0) {\n\t\t\t\tSystem.err.println(\"Deleting \"+alreadyDropped.size()+\" blocks beyond the length of the file\");\n\t\t\t\tfor(int i=0;i<alreadyDropped.size();i++) {\n\t\t\t\t\tint unwantedBlock = (alreadyDropped.get(i)).intValue();\n\t\t\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\t\t\tLongBinding.longToEntry(unwantedBlock, unwantedBlockEntry);\n\t\t\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\t\t\tif(i % 1024 == 0) {\n\t\t\t\t\t\tt.commit();\n\t\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(alreadyDropped.size() % 1024 != 0) {\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor(int i=0;i<wantedMoveNums.length;i++) {\n\t\t\t\tInteger wantedBlock = wantedMoveNums[i];\n\t\t\t\t\n\t\t\t\tInteger unwantedBlock;\n\t\t\t\t\n\t\t\t\t// Can we move over an empty slot?\n\t\t\t\tif(i < freeEarlySlots.length) {\n\t\t\t\t\t// Don't need to delete old block\n\t\t\t\t\tunwantedBlock = new Integer((int) freeEarlySlots[i]); // will fit in an int\n\t\t\t\t} else if(unwantedMoveNums.length + freeEarlySlots.length > i) {\n\t\t\t\t\tunwantedBlock = unwantedMoveNums[i-freeEarlySlots.length];\n\t\t\t\t\t// Delete unwantedBlock from the store\n\t\t\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\t\t\tLongBinding.longToEntry(unwantedBlock.longValue(), unwantedBlockEntry);\n\t\t\t\t\t// Delete the old block from the database.\n\t\t\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\t\t} else {\n\t\t\t\t\tSystem.err.println(\"Keys to move but no keys to move over! Moved \"+i);\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// Move old data to new location\n\t\t\t\t\n\t\t\t\tDatabaseEntry wantedBlockEntry = new DatabaseEntry();\n\t\t\t\tLongBinding.longToEntry(wantedBlock.longValue(), wantedBlockEntry);\n\t\t\t\tlong entry = wantedBlock.longValue();\n\t\t\t\tboolean readLRU = false;\n\t\t\t\tboolean readKey = false;\n\t\t\t\ttry {\n\t\t\t\t\tbuf.rewind();\n\t\t\t\t\tdo {\n\t\t\t\t\t\tint byteRead = storeFC.read(buf, entry * (headerBlockSize + dataBlockSize) + buf.position());\n\t\t\t\t\t\tif (byteRead == -1)\n\t\t\t\t\t\t\tthrow new EOFException();\n\t\t\t\t\t} while (buf.hasRemaining());\n\t\t\t\t\tbuf.flip();\n\t\t\t\t\tlruValue = 0;\n\t\t\t\t\tif(lruRAF.length() > ((entry + 1) * 8)) {\n\t\t\t\t\t\treadLRU = true;\n\t\t\t\t\t\tlruValue = fcReadLRU(entry);\n\t\t\t\t\t}\n\t\t\t\t\tif(keysRAF != null && keysRAF.length() > ((entry + 1) * keyLength)) {\n\t\t\t\t\t\treadKey = true;\n\t\t\t\t\t\tfcReadKey(entry, keyBuf);\n\t\t\t\t\t}\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tSystem.err.println(\"Was reading \"+wantedBlock+\" to write to \"+unwantedBlock);\n\t\t\t\t\tSystem.err.println(e);\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t\tentry = unwantedBlock.longValue();\n\t\t\t\tdo {\n\t\t\t\t\tint byteWritten = storeFC.write(buf, entry * (headerBlockSize + dataBlockSize) + buf.position());\n\t\t\t\t\tif (byteWritten == -1)\n\t\t\t\t\t\tthrow new EOFException();\n\t\t\t\t} while (buf.hasRemaining());\n\t\t\t\tif(readLRU) {\n\t\t\t\t\tfcWriteLRU(entry, lruValue);\n\t\t\t\t}\n\t\t\t\tif(readKey) {\n\t\t\t\t\tfcWriteKey(entry, keyBuf);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// Update the database w.r.t. the old block.\n\t\t\t\t\n\t\t\t\tDatabaseEntry routingKeyDBE = new DatabaseEntry();\n\t\t\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\t\t\tblockNumDB.get(t, wantedBlockEntry, routingKeyDBE, blockDBE, LockMode.RMW);\n\t\t\t\tStoreBlock block = storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\tblock.offset = unwantedBlock.longValue();\n\t\t\t\tstoreBlockTupleBinding.objectToEntry(block, blockDBE);\n\t\t\t\tkeysDB.put(t, routingKeyDBE, blockDBE);\n\t\t\t\t\n\t\t\t\t// Think about committing the transaction.\n\t\t\t\t\n\t\t\t\tif((i+1) % 2048 == 0) {\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t\t\tSystem.out.println(\"Moving blocks: \"+(i*100/wantedMove.size())+ \"% ( \"+i+ '/' +wantedMove.size()+ ')');\n\t\t\t\t}\n\t\t\t\t//System.err.println(\"Moved \"+wantedBlock+\" to \"+unwantedBlock);\n\t\t\t}\n\t\t\tSystem.out.println(\"Moved all \"+wantedMove.size()+\" blocks\");\n\t\t\tif(t != null) {\n\t\t\t\tt.commit();\n\t\t\t\tt = null;\n\t\t\t}\n\t\t} finally {\n\t\t\tif(t != null)\n\t\t\t\tt.abort();\n\t\t\tt = null;\n\t\t}\n\t\tSystem.out.println(\"Completing shrink\"); // FIXME remove\n\t\t\n\t\tint totalUnwantedBlocks = unwantedMoveNums.length+freeEarlySlots.length;\n\t\tWrapperManager.signalStarting((int) Math.min(Integer.MAX_VALUE, 5*60*1000 + (totalUnwantedBlocks-wantedMoveNums.length) * 100L));\n\t\t// If there are any slots left over, they must be free.\n\t\t\n\t\t// FIXME put these into the database as we do in reconstruct().\n\t\t// Not doing that now as its not immediately obvious how to deal with it...\n\t\t\n\t\tfreeBlocks.clear();\n\t\tt = environment.beginTransaction(null,null);\n\t\tfor(int i=wantedMoveNums.length;i<totalUnwantedBlocks;i++) {\n\t\t\tlong blockNo;\n\t\t\tString reason;\n\t\t\tif(i < freeEarlySlots.length) {\n\t\t\t\tblockNo = freeEarlySlots[i];\n\t\t\t\treason = \"early slot \"+i;\n\t\t\t} else {\n\t\t\t\tblockNo = unwantedMoveNums[i-freeEarlySlots.length].longValue();\n\t\t\t\treason = \"unwanted \"+(i-freeEarlySlots.length);\n\t\t\t}\n\t\t\tDatabaseEntry unwantedBlockEntry = new DatabaseEntry();\n\t\t\tLongBinding.longToEntry(blockNo, unwantedBlockEntry);\n\t\t\tblockNumDB.delete(t, unwantedBlockEntry);\n\t\t\tif(i % 1024 == 0) {\n\t\t\t\tSystem.out.println(\"Trimmed surplus keys in database: \"+(i-wantedMoveNums.length)+\"/\"+(totalUnwantedBlocks-wantedMoveNums.length));\n\t\t\t\tt.commit();\n\t\t\t\tif(i == totalUnwantedBlocks-1)\n\t\t\t\t\tt = null;\n\t\t\t\telse\n\t\t\t\t\tt = environment.beginTransaction(null,null);\n\t\t\t}\n\t\t\taddFreeBlock(blockNo, true, reason);\n\t\t}\n\t\tif(t != null) t.commit();\n\t\tt = null;\n\t\t\n\t\tSystem.out.println(\"Finishing shrink\"); // FIXME remove\n\t\t\n\t\tstoreRAF.setLength(newSize * (dataBlockSize + headerBlockSize));\n\t\tlruRAF.setLength(newSize * 8);\n\t\tif(keysRAF != null)\n\t\t\tkeysRAF.setLength(newSize * keyLength);\n\t\t\n\t\tsynchronized(this) {\n\t\t\tblocksInStore = newSize;\n\t\t}\n\t\tSystem.err.println(\"Shrunk store, now have \"+blocksInStore+\" of \"+maxBlocksInStore);\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"private long getMinRecentlyUsed(Transaction t) {\n\t\tlong minRecentlyUsed = 0;\n\t\t\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(t,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getFirst(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\tminRecentlyUsed = storeBlock.getRecentlyUsed();\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} catch(DatabaseException ex) {\n\t\t\tex.printStackTrace();\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn minRecentlyUsed;\n\t}","id":37589,"modified_method":"private long getMinRecentlyUsed(Transaction t) {\n\t\tlong minRecentlyUsed = 0;\n\t\t\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(t,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getFirst(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\tminRecentlyUsed = storeBlock.getRecentlyUsed();\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} catch(DatabaseException ex) {\n\t\t\tex.printStackTrace();\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn minRecentlyUsed;\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"/**\n\t * Overwrite a block with a new block which has the same key.\n\t */\n\tprivate boolean overwriteKeyUnchanged(byte[] routingkey, byte[] fullKey, byte[] data, byte[] header) throws IOException {\n\t\tsynchronized(this) {\n\t\t\tif(closed)\n\t\t\t\treturn false;\n\t\t}\n\t\t\n\t\tDatabaseEntry routingkeyDBE = new DatabaseEntry(routingkey);\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tc = keysDB.openCursor(t,null);\n\n\t\t\t// Lock the record.\n\t\t\tif(c.getSearchKey(routingkeyDBE,blockDBE,LockMode.RMW)\n\t\t\t\t\t!=OperationStatus.SUCCESS) {\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.abort();\n\t\t\t\tt = null;\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\t\t\t\n\t\t\tfcWriteStore(storeBlock.offset, header, data);\n\t\t\tif (keysRAF != null) {\n\t\t\t\tfcWriteKey(storeBlock.offset, fullKey);\n\t\t\t}\n\t\t\t\n\t\t\t// Unlock record.\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t\tt.commit();\n\t\t\tt = null;\n\t\t\t\n\t\t} catch(Throwable ex) {  // FIXME: ugly\n\t\t\tcheckSecondaryDatabaseError(ex);\n\t\t\tLogger.error(this, \"Caught \"+ex, ex);\n\t\t\tex.printStackTrace();\n\t\t\tthrow new IOException(ex.getMessage());\n\t\t} finally {\n\t\t\tif(c!=null) {\n\t\t\t\ttry{c.close();}catch(DatabaseException ex2){}\n\t\t\t\n\t\t\t}\n\t\t\tif(t!=null) {\n\t\t\t\ttry{t.abort();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\t\n\t\treturn true;\n\t}","id":37590,"modified_method":"/**\n\t * Overwrite a block with a new block which has the same key.\n\t */\n\tprivate boolean overwriteKeyUnchanged(byte[] routingkey, byte[] fullKey, byte[] data, byte[] header) throws IOException {\n\t\tsynchronized(this) {\n\t\t\tif(closed)\n\t\t\t\treturn false;\n\t\t}\n\t\t\n\t\tDatabaseEntry routingkeyDBE = new DatabaseEntry(routingkey);\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tc = keysDB.openCursor(t,null);\n\n\t\t\t// Lock the record.\n\t\t\tif(c.getSearchKey(routingkeyDBE,blockDBE,LockMode.RMW)\n\t\t\t\t\t!=OperationStatus.SUCCESS) {\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.abort();\n\t\t\t\tt = null;\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\t\t\t\n\t\t\tfcWriteStore(storeBlock.offset, header, data);\n\t\t\tif (keysRAF != null) {\n\t\t\t\tfcWriteKey(storeBlock.offset, fullKey);\n\t\t\t}\n\t\t\t\n\t\t\t// Unlock record.\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t\tt.commit();\n\t\t\tt = null;\n\t\t\t\n\t\t} catch(Throwable ex) {  // FIXME: ugly\n\t\t\tcheckSecondaryDatabaseError(ex);\n\t\t\tLogger.error(this, \"Caught \"+ex, ex);\n\t\t\tex.printStackTrace();\n\t\t\tthrow new IOException(ex.getMessage());\n\t\t} finally {\n\t\t\tif(c!=null) {\n\t\t\t\ttry{c.close();}catch(DatabaseException ex2){}\n\t\t\t\n\t\t\t}\n\t\t\tif(t!=null) {\n\t\t\t\ttry{t.abort();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\t\n\t\treturn true;\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"public boolean createSecondaryKey(SecondaryDatabase secDb,\n\t\t\t\tDatabaseEntry keyEntry,\n\t\t\t\tDatabaseEntry dataEntry,\n\t\t\t\tDatabaseEntry resultEntry) {\n\n\t\t\tStoreBlock storeblock = (StoreBlock) theBinding.entryToObject(dataEntry);\n\t\t\tLongBinding.longToEntry(storeblock.getRecentlyUsed(), resultEntry);\n\t\t\treturn true;\n\t\t}","id":37591,"modified_method":"public boolean createSecondaryKey(SecondaryDatabase secDb,\n\t\t\t\tDatabaseEntry keyEntry,\n\t\t\t\tDatabaseEntry dataEntry,\n\t\t\t\tDatabaseEntry resultEntry) {\n\n\t\t\tStoreBlock storeblock = theBinding.entryToObject(dataEntry);\n\t\t\tLongBinding.longToEntry(storeblock.getRecentlyUsed(), resultEntry);\n\t\t\treturn true;\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"private void overwriteLRUBlock(byte[] header, byte[] data, Transaction t, DatabaseEntry routingkeyDBE, byte[] fullKey) throws DatabaseException, IOException {\n\t\t// Overwrite an other block\n\t\tCursor c = accessTimeDB.openCursor(t,null);\n\t\tStoreBlock oldStoreBlock;\n\t\ttry {\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tc.getFirst(keyDBE,dataDBE,LockMode.RMW);\n\t\t\toldStoreBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\tc.delete();\n\t\t} finally {\n\t\t\tc.close();\n\t\t}\n\t\t// Deleted, so we can now reuse it.\n\t\t// Because we acquired a write lock, nobody else has taken it.\n\t\t// FIXME if this fails we can leak the block??\n\t\tStoreBlock storeBlock = new StoreBlock(this, oldStoreBlock.getOffset());\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\n\t\tfcWriteStore(storeBlock.getOffset(), header, data);\n\t\tfcWriteLRU( storeBlock.getOffset(),storeBlock.recentlyUsed);\n\t\tif (keysRAF != null)\n\t\t\tfcWriteKey(storeBlock.getOffset(), fullKey);\n\t\tsynchronized (this) {\n\t\t\twrites++;\n\t\t}\n\t}","id":37592,"modified_method":"private void overwriteLRUBlock(byte[] header, byte[] data, Transaction t, DatabaseEntry routingkeyDBE, byte[] fullKey) throws DatabaseException, IOException {\n\t\t// Overwrite an other block\n\t\tCursor c = accessTimeDB.openCursor(t,null);\n\t\tStoreBlock oldStoreBlock;\n\t\ttry {\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tc.getFirst(keyDBE,dataDBE,LockMode.RMW);\n\t\t\toldStoreBlock = storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\tc.delete();\n\t\t} finally {\n\t\t\tc.close();\n\t\t}\n\t\t// Deleted, so we can now reuse it.\n\t\t// Because we acquired a write lock, nobody else has taken it.\n\t\t// FIXME if this fails we can leak the block??\n\t\tStoreBlock storeBlock = new StoreBlock(this, oldStoreBlock.getOffset());\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\n\t\tfcWriteStore(storeBlock.getOffset(), header, data);\n\t\tfcWriteLRU( storeBlock.getOffset(),storeBlock.recentlyUsed);\n\t\tif (keysRAF != null)\n\t\t\tfcWriteKey(storeBlock.getOffset(), fullKey);\n\t\tsynchronized (this) {\n\t\t\twrites++;\n\t\t}\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"public boolean createSecondaryKey(SecondaryDatabase secDb,\n\t\t\t\tDatabaseEntry keyEntry,\n\t\t\t\tDatabaseEntry dataEntry,\n\t\t\t\tDatabaseEntry resultEntry) {\n\n\t\t\tStoreBlock storeblock = (StoreBlock) theBinding.entryToObject(dataEntry);\n\t\t\tLongBinding.longToEntry(storeblock.offset, resultEntry);\n\t\t\treturn true;\n\t\t}","id":37593,"modified_method":"public boolean createSecondaryKey(SecondaryDatabase secDb,\n\t\t\t\tDatabaseEntry keyEntry,\n\t\t\t\tDatabaseEntry dataEntry,\n\t\t\t\tDatabaseEntry resultEntry) {\n\n\t\t\tStoreBlock storeblock = theBinding.entryToObject(dataEntry);\n\t\t\tLongBinding.longToEntry(storeblock.offset, resultEntry);\n\t\t\treturn true;\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"/**\n\t * {@inheritDoc}\n\t */\n\tpublic StorableBlock fetch(byte[] routingkey, byte[] fullKey, boolean dontPromote) throws IOException {\n\t\tDatabaseEntry routingkeyDBE = new DatabaseEntry(routingkey);\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tint running;\n\t\tsynchronized(this) {\n\t\t\tif(closed)\n\t\t\t\treturn null;\n\t\t\trunning = runningFetches++;\n\t\t}\n\t\t\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tc = keysDB.openCursor(t,null);\n\t\t\t\n\t\t\t/**\n\t\t\t* We will have to write, unless both dontPromote and the key is valid.\n\t\t\t* The lock only applies to this record, so it's not a big problem for our use.\n\t\t\t* What *IS* a big problem is that if we take a LockMode.DEFAULT, and two threads\n\t\t\t* access the same key, they will both take the read lock, and then both try to\n\t\t\t* take the write lock. Neither can relinquish the read in order for the other to\n\t\t\t* take the write, so we're screwed.\n\t\t\t*/\n\t\t\tif(logMINOR) Logger.minor(this, \"Fetching \"+HexUtil.bytesToHex(routingkey)+\" dontPromote=\"+dontPromote+\" for \"+callback+\" running fetches: \"+running);\n\t\t\tif(c.getSearchKey(routingkeyDBE,blockDBE,LockMode.RMW)\n\t\t\t\t\t!=OperationStatus.SUCCESS) {\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.abort();\n\t\t\t\tt = null;\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tmisses++;\n\t\t\t\t}\n\t\t\t\tif(logMINOR) Logger.minor(this, \"Not found\");\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\t\t\t\n\t\t\tStorableBlock block = null;\n\t\t\t\n\t\t\tif(logMINOR) Logger.minor(this, \"Reading block \"+storeBlock.offset+\"...\");\n\t\t\ttry {\n\t\t\t\tbyte[] header = new byte[headerBlockSize];\n\t\t\t\tbyte[] data = new byte[dataBlockSize];\n\t\t\t\ttry {\n\t\t\t\t\tfcReadStore(storeBlock.offset, header, data);\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tLogger.error(this, \"No block\");\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Data off end of store file\");\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tblock = callback.construct(data, header, routingkey, fullKey);\n\t\t\t\t\n\t\t\t\t// Write the key.\n\t\t\t\tbyte[] newFullKey = block.getFullKey();\n\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\tfcWriteKey(storeBlock.offset, newFullKey);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(!Arrays.equals(block.getRoutingKey(), routingkey)) {\n\t\t\t\t\t\n\t\t\t\t\tsynchronized(this) {\n\t\t\t\t\t\tmisses++;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\t\n\t\t\t\t\t// Insert the block into the index.\n\t\t\t\t\t// Set the LRU to minimum - 1.\n\t\t\t\t\t\n\t\t\t\t\tlong lru = getMinRecentlyUsed(t) - 1;\n\t\t\t\t\t\n\t\t\t\t\tLogger.normal(this, \"Does not verify (not the expected key), setting accessTime to \"+lru+\" for : \"+HexUtil.bytesToHex(routingkey));\n\t\t\t\t\t\n\t\t\t\t\tstoreBlock = new StoreBlock(storeBlock.offset, lru);\n\t\t\t\t\t\n\t\t\t\t\troutingkeyDBE = new DatabaseEntry(block.getRoutingKey());\n\t\t\t\t\t\n\t\t\t\t\tblockDBE = new DatabaseEntry();\n\t\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\t\t\t\tif(fullKey == null)\n\t\t\t\t\t\t\tfullKey = block.getFullKey();\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\t\t\t\tfcWriteKey(storeBlock.offset, fullKey);\n\t\t\t\t\t\t\t\tif(logDEBUG)\n\t\t\t\t\t\t\t\t\tLogger.debug(this, \"Written full key length \"+fullKey.length+\" to block \"+storeBlock.offset+\" at \"+(storeBlock.offset * keyLength)+\" for \"+callback);\n\t\t\t\t\t\t\t} else if(logDEBUG) {\n\t\t\t\t\t\t\t\tLogger.debug(this, \"Not writing full key length \"+fullKey.length+\" for block \"+storeBlock.offset+\" for \"+callback);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\t\tLogger.error(this, \"Caught database exception \"+e+\" while replacing element\");\n\t\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Bogus key\");\n\t\t\t\t\t\tc.close();\n\t\t\t\t\t\tc = null;\n\t\t\t\t\t\tt.commit();\n\t\t\t\t\t\tt = null;\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t\tLogger.normal(this, \"Successfully replaced entry at block number \"+storeBlock.offset+\" lru \"+lru);\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(!dontPromote) {\n\t\t\t\t\tstoreBlock.updateRecentlyUsed();\n\t\t\t\t\tDatabaseEntry updateDBE = new DatabaseEntry();\n\t\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, updateDBE);\n\t\t\t\t\tc.putCurrent(updateDBE);\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\tfcWriteLRU(storeBlock.offset, storeBlock.recentlyUsed);\n\t\t\t\t} else {\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.abort();\n\t\t\t\t\tt = null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(logMINOR) {\n\t\t\t\t\tLogger.minor(this, \"Headers: \" + header.length+\" bytes, hash \" + Fields.hashCode(header));\n\t\t\t\t\tLogger.minor(this, \"Data: \" + data.length + \" bytes, hash \" + Fields.hashCode(data) + \" fetching \" + HexUtil.bytesToHex(routingkey));\n\t\t\t\t}\n\t\t\t\t\n\t\t\t} catch(KeyVerifyException ex) {\n\t\t\t\tLogger.normal(this, \"Does not verify (\"+ex+\"), setting accessTime to 0 for : \"+HexUtil.bytesToHex(routingkey), ex);\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tmisses++;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\t// Clear the key in the keys file.\n\t\t\t\t\tbyte[] buf = new byte[keyLength];\n\t\t\t\t\tfor(int i=0;i<buf.length;i++) buf[i] = 0; // FIXME unnecessary?\n\t\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\t\tfcWriteKey(storeBlock.offset, buf);\n\t\t\t\t\t}\n\t\t\t\t\n\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\n\t\t\t\t// Insert the block into the index with a random key, so that it's part of the LRU.\n\t\t\t\t// Set the LRU to minimum - 1.\n\t\t\t\t\n\t\t\t\tlong lru = getMinRecentlyUsed(t) - 1;\n\t\t\t\t\n\t\t\t\tbyte[] randomKey = new byte[keyLength];\n\t\t\t\trandom.nextBytes(randomKey);\n\t\t\t\t\n\t\t\t\tstoreBlock = new StoreBlock(storeBlock.offset, lru);\n\t\t\t\t\n\t\t\t\troutingkeyDBE = new DatabaseEntry(randomKey);\n\t\t\t\t\n\t\t\t\tblockDBE = new DatabaseEntry();\n\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\t\t\ttry {\n\t\t\t\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught database exception \"+e+\" while adding corrupt element to LRU\");\n\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Bogus key\");\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.commit();\n\t\t\t\tt = null;\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tsynchronized(this) {\n\t\t\t\thits++;\n\t\t\t}\n\t\t\treturn block;\n\t\t} catch (ClosedChannelException cce) {\n\t\t\t// The channel is already close\n\t\t\tLogger.debug(this, \"channel closed\" , cce);\n\t\t\treturn null;\n\t\t} catch(Throwable ex) {  // FIXME: ugly\n\t\t\tif(ex instanceof IOException) {\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tif(closed) return null;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(c!=null) {\n\t\t\t\ttry{c.close();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\tif(t!=null) {\n\t\t\t\ttry{t.abort();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\tcheckSecondaryDatabaseError(ex);\n\t\t\tLogger.error(this, \"Caught \"+ex, ex);\n\t\t\tex.printStackTrace();\n\t\t\tthrow new IOException(ex.getMessage());\n\t\t} finally {\n\t\t\tint x;\n\t\t\tsynchronized(this) {\n\t\t\t\tx = runningFetches--;\n\t\t\t}\n\t\t\tif(logMINOR) Logger.minor(this, \"Running fetches now \"+x);\n\t\t}\n\t}","id":37594,"modified_method":"/**\n\t * {@inheritDoc}\n\t */\n\tpublic StorableBlock fetch(byte[] routingkey, byte[] fullKey, boolean dontPromote) throws IOException {\n\t\tDatabaseEntry routingkeyDBE = new DatabaseEntry(routingkey);\n\t\tDatabaseEntry blockDBE = new DatabaseEntry();\n\t\tint running;\n\t\tsynchronized(this) {\n\t\t\tif(closed)\n\t\t\t\treturn null;\n\t\t\trunning = runningFetches++;\n\t\t}\n\t\t\n\t\tCursor c = null;\n\t\tTransaction t = null;\n\t\ttry {\n\t\t\tt = environment.beginTransaction(null,null);\n\t\t\tc = keysDB.openCursor(t,null);\n\t\t\t\n\t\t\t/**\n\t\t\t* We will have to write, unless both dontPromote and the key is valid.\n\t\t\t* The lock only applies to this record, so it's not a big problem for our use.\n\t\t\t* What *IS* a big problem is that if we take a LockMode.DEFAULT, and two threads\n\t\t\t* access the same key, they will both take the read lock, and then both try to\n\t\t\t* take the write lock. Neither can relinquish the read in order for the other to\n\t\t\t* take the write, so we're screwed.\n\t\t\t*/\n\t\t\tif(logMINOR) Logger.minor(this, \"Fetching \"+HexUtil.bytesToHex(routingkey)+\" dontPromote=\"+dontPromote+\" for \"+callback+\" running fetches: \"+running);\n\t\t\tif(c.getSearchKey(routingkeyDBE,blockDBE,LockMode.RMW)\n\t\t\t\t\t!=OperationStatus.SUCCESS) {\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.abort();\n\t\t\t\tt = null;\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tmisses++;\n\t\t\t\t}\n\t\t\t\tif(logMINOR) Logger.minor(this, \"Not found\");\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(blockDBE);\n\t\t\t\t\t\t\n\t\t\tStorableBlock block = null;\n\t\t\t\n\t\t\tif(logMINOR) Logger.minor(this, \"Reading block \"+storeBlock.offset+\"...\");\n\t\t\ttry {\n\t\t\t\tbyte[] header = new byte[headerBlockSize];\n\t\t\t\tbyte[] data = new byte[dataBlockSize];\n\t\t\t\ttry {\n\t\t\t\t\tfcReadStore(storeBlock.offset, header, data);\n\t\t\t\t} catch (EOFException e) {\n\t\t\t\t\tLogger.error(this, \"No block\");\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Data off end of store file\");\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tblock = callback.construct(data, header, routingkey, fullKey);\n\t\t\t\t\n\t\t\t\t// Write the key.\n\t\t\t\tbyte[] newFullKey = block.getFullKey();\n\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\tfcWriteKey(storeBlock.offset, newFullKey);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(!Arrays.equals(block.getRoutingKey(), routingkey)) {\n\t\t\t\t\t\n\t\t\t\t\tsynchronized(this) {\n\t\t\t\t\t\tmisses++;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\t\n\t\t\t\t\t// Insert the block into the index.\n\t\t\t\t\t// Set the LRU to minimum - 1.\n\t\t\t\t\t\n\t\t\t\t\tlong lru = getMinRecentlyUsed(t) - 1;\n\t\t\t\t\t\n\t\t\t\t\tLogger.normal(this, \"Does not verify (not the expected key), setting accessTime to \"+lru+\" for : \"+HexUtil.bytesToHex(routingkey));\n\t\t\t\t\t\n\t\t\t\t\tstoreBlock = new StoreBlock(storeBlock.offset, lru);\n\t\t\t\t\t\n\t\t\t\t\troutingkeyDBE = new DatabaseEntry(block.getRoutingKey());\n\t\t\t\t\t\n\t\t\t\t\tblockDBE = new DatabaseEntry();\n\t\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\t\t\t\tif(fullKey == null)\n\t\t\t\t\t\t\tfullKey = block.getFullKey();\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\t\t\t\tfcWriteKey(storeBlock.offset, fullKey);\n\t\t\t\t\t\t\t\tif(logDEBUG)\n\t\t\t\t\t\t\t\t\tLogger.debug(this, \"Written full key length \"+fullKey.length+\" to block \"+storeBlock.offset+\" at \"+(storeBlock.offset * keyLength)+\" for \"+callback);\n\t\t\t\t\t\t\t} else if(logDEBUG) {\n\t\t\t\t\t\t\t\tLogger.debug(this, \"Not writing full key length \"+fullKey.length+\" for block \"+storeBlock.offset+\" for \"+callback);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\t\tLogger.error(this, \"Caught database exception \"+e+\" while replacing element\");\n\t\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Bogus key\");\n\t\t\t\t\t\tc.close();\n\t\t\t\t\t\tc = null;\n\t\t\t\t\t\tt.commit();\n\t\t\t\t\t\tt = null;\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t\tLogger.normal(this, \"Successfully replaced entry at block number \"+storeBlock.offset+\" lru \"+lru);\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(!dontPromote) {\n\t\t\t\t\tstoreBlock.updateRecentlyUsed();\n\t\t\t\t\tDatabaseEntry updateDBE = new DatabaseEntry();\n\t\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, updateDBE);\n\t\t\t\t\tc.putCurrent(updateDBE);\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\tfcWriteLRU(storeBlock.offset, storeBlock.recentlyUsed);\n\t\t\t\t} else {\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.abort();\n\t\t\t\t\tt = null;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif(logMINOR) {\n\t\t\t\t\tLogger.minor(this, \"Headers: \" + header.length+\" bytes, hash \" + Fields.hashCode(header));\n\t\t\t\t\tLogger.minor(this, \"Data: \" + data.length + \" bytes, hash \" + Fields.hashCode(data) + \" fetching \" + HexUtil.bytesToHex(routingkey));\n\t\t\t\t}\n\t\t\t\t\n\t\t\t} catch(KeyVerifyException ex) {\n\t\t\t\tLogger.normal(this, \"Does not verify (\"+ex+\"), setting accessTime to 0 for : \"+HexUtil.bytesToHex(routingkey), ex);\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tmisses++;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\t// Clear the key in the keys file.\n\t\t\t\t\tbyte[] buf = new byte[keyLength];\n\t\t\t\t\tfor(int i=0;i<buf.length;i++) buf[i] = 0; // FIXME unnecessary?\n\t\t\t\t\tif(keysRAF != null) {\n\t\t\t\t\t\tfcWriteKey(storeBlock.offset, buf);\n\t\t\t\t\t}\n\t\t\t\t\n\t\t\t\tkeysDB.delete(t, routingkeyDBE);\n\t\t\t\t\n\t\t\t\t// Insert the block into the index with a random key, so that it's part of the LRU.\n\t\t\t\t// Set the LRU to minimum - 1.\n\t\t\t\t\n\t\t\t\tlong lru = getMinRecentlyUsed(t) - 1;\n\t\t\t\t\n\t\t\t\tbyte[] randomKey = new byte[keyLength];\n\t\t\t\trandom.nextBytes(randomKey);\n\t\t\t\t\n\t\t\t\tstoreBlock = new StoreBlock(storeBlock.offset, lru);\n\t\t\t\t\n\t\t\t\troutingkeyDBE = new DatabaseEntry(randomKey);\n\t\t\t\t\n\t\t\t\tblockDBE = new DatabaseEntry();\n\t\t\t\tstoreBlockTupleBinding.objectToEntry(storeBlock, blockDBE);\n\t\t\t\ttry {\n\t\t\t\t\tkeysDB.put(t,routingkeyDBE,blockDBE);\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught database exception \"+e+\" while adding corrupt element to LRU\");\n\t\t\t\t\taddFreeBlock(storeBlock.offset, true, \"Bogus key\");\n\t\t\t\t\tc.close();\n\t\t\t\t\tc = null;\n\t\t\t\t\tt.commit();\n\t\t\t\t\tt = null;\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\n\t\t\t\tc.close();\n\t\t\t\tc = null;\n\t\t\t\tt.commit();\n\t\t\t\tt = null;\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tsynchronized(this) {\n\t\t\t\thits++;\n\t\t\t}\n\t\t\treturn block;\n\t\t} catch (ClosedChannelException cce) {\n\t\t\t// The channel is already close\n\t\t\tLogger.debug(this, \"channel closed\" , cce);\n\t\t\treturn null;\n\t\t} catch(Throwable ex) {  // FIXME: ugly\n\t\t\tif(ex instanceof IOException) {\n\t\t\t\tsynchronized(this) {\n\t\t\t\t\tif(closed) return null;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(c!=null) {\n\t\t\t\ttry{c.close();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\tif(t!=null) {\n\t\t\t\ttry{t.abort();}catch(DatabaseException ex2){}\n\t\t\t}\n\t\t\tcheckSecondaryDatabaseError(ex);\n\t\t\tLogger.error(this, \"Caught \"+ex, ex);\n\t\t\tex.printStackTrace();\n\t\t\tthrow new IOException(ex.getMessage());\n\t\t} finally {\n\t\t\tint x;\n\t\t\tsynchronized(this) {\n\t\t\t\tx = runningFetches--;\n\t\t\t}\n\t\t\tif(logMINOR) Logger.minor(this, \"Running fetches now \"+x);\n\t\t}\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"@Override\n        public Object entryToObject(TupleInput ti) {\n\t\t\tlong offset = ti.readLong();\n\t\t\tlong lastAccessed = ti.readLong();\n\t\t\t\n\t\t\tStoreBlock storeBlock = new StoreBlock(offset,lastAccessed);\n\t\t\treturn storeBlock;\n\t\t}","id":37595,"modified_method":"@Override\n        public StoreBlock entryToObject(TupleInput ti) {\n\t\t\tlong offset = ti.readLong();\n\t\t\tlong lastAccessed = ti.readLong();\n\t\t\t\n\t\t\tStoreBlock storeBlock = new StoreBlock(offset,lastAccessed);\n\t\t\treturn storeBlock;\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"public BlockNumberKeyCreator(TupleBinding theBinding1) {\n\t\t\ttheBinding = theBinding1;\n\t\t}","id":37596,"modified_method":"public BlockNumberKeyCreator(TupleBinding<StoreBlock> theBinding1) {\n\t\t\ttheBinding = theBinding1;\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"@Override\n        public void objectToEntry(Object object, TupleOutput to)  {\n\t\t\tStoreBlock myData = (StoreBlock)object;\n\n\t\t\tto.writeLong(myData.getOffset());\n\t\t\tto.writeLong(myData.getRecentlyUsed());\n\t\t}","id":37597,"modified_method":"@Override\n        public void objectToEntry(StoreBlock myData, TupleOutput to) {\n\t\t\tto.writeLong(myData.getOffset());\n\t\t\tto.writeLong(myData.getRecentlyUsed());\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"private long highestBlockNumberInDatabase() throws DatabaseException {\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = blockNumDB.openCursor(null,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getLast(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\treturn storeBlock.offset + 1;\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}","id":37598,"modified_method":"private long highestBlockNumberInDatabase() throws DatabaseException {\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = blockNumDB.openCursor(null,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getLast(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\treturn storeBlock.offset + 1;\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"private long getMaxRecentlyUsed() {\n\t\tlong maxRecentlyUsed = 0;\n\t\t\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(null,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getLast(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = (StoreBlock) storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\tmaxRecentlyUsed = storeBlock.getRecentlyUsed();\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} catch(DatabaseException ex) {\n\t\t\tex.printStackTrace();\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn maxRecentlyUsed;\n\t}","id":37599,"modified_method":"private long getMaxRecentlyUsed() {\n\t\tlong maxRecentlyUsed = 0;\n\t\t\n\t\tCursor c = null;\n\t\ttry {\n\t\t\tc = accessTimeDB.openCursor(null,null);\n\t\t\tDatabaseEntry keyDBE = new DatabaseEntry();\n\t\t\tDatabaseEntry dataDBE = new DatabaseEntry();\n\t\t\tif(c.getLast(keyDBE,dataDBE,null)==OperationStatus.SUCCESS) {\n\t\t\t\tStoreBlock storeBlock = storeBlockTupleBinding.entryToObject(dataDBE);\n\t\t\t\tmaxRecentlyUsed = storeBlock.getRecentlyUsed();\n\t\t\t}\n\t\t\tc.close();\n\t\t\tc = null;\n\t\t} catch(DatabaseException ex) {\n\t\t\tex.printStackTrace();\n\t\t} finally {\n\t\t\tif(c != null) {\n\t\t\t\ttry {\n\t\t\t\t\tc.close();\n\t\t\t\t} catch (DatabaseException e) {\n\t\t\t\t\tLogger.error(this, \"Caught \"+e, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn maxRecentlyUsed;\n\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"public AccessTimeKeyCreator(TupleBinding theBinding1) {\n\t\t\ttheBinding = theBinding1;\n\t\t}","id":37600,"modified_method":"public AccessTimeKeyCreator(TupleBinding<StoreBlock> theBinding1) {\n\t\t\ttheBinding = theBinding1;\n\t\t}","commit_id":"a7e43d54f9b0a87b3cba0d824433a7b9b7144511","url":"https://github.com/freenet/fred"},{"original_method":"@Override\n        public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope,\n                                      @NotNull Importer importer) {\n            ImportsResolver.ImportResolver importResolver = new ImportsResolver.ImportResolver(trace, true);\n            importResolver.processImportReference(JetPsiFactory.createImportDirective(project, \"js.*\"), rootScope, importer);\n        }","id":37601,"modified_method":"@Override\n        public void addDefaultImports(@NotNull WritableScope rootScope,\n                                      @NotNull Collection<JetImportDirective> directives) {\n            directives.add(JetPsiFactory.createImportDirective(project, \"js.*\"));\n        }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n     * Check that function or property with the given qualified name can be resolved in given scope and called on given receiver\n     *\n     * @param callableFQN\n     * @param project\n     * @param scope\n     * @return\n     */\n    public static List<CallableDescriptor> canFindSuitableCall(\n            @NotNull String callableFQN,\n            @NotNull Project project,\n            @NotNull JetExpression receiverExpression,\n            @NotNull JetType receiverType,\n            @NotNull JetScope scope) {\n\n        WritableScopeWithImports writableScopeWithImports = new WritableScopeImpl(\n                scope, scope.getContainingDeclaration(), RedeclarationHandler.DO_NOTHING);\n\n        JetImportDirective importDirective = JetPsiFactory.createImportDirective(project, callableFQN);\n\n        ImportsResolver.ImportResolver importResolver = new ImportsResolver.ImportResolver(new BindingTraceContext(), false);\n        Collection<? extends DeclarationDescriptor> declarationDescriptors = importResolver.processImportReference(\n                importDirective, scope,\n                new Importer.StandardImporter(writableScopeWithImports, false));\n\n        List<CallableDescriptor> callableExtensionDescriptors = new ArrayList<CallableDescriptor>();\n        ReceiverDescriptor receiverDescriptor = new ExpressionReceiver(receiverExpression, receiverType);\n\n        for (DeclarationDescriptor declarationDescriptor : declarationDescriptors) {\n            if (declarationDescriptor instanceof CallableDescriptor) {\n                CallableDescriptor callableDescriptor = (CallableDescriptor) declarationDescriptor;\n\n                if (checkIsExtensionCallable(receiverDescriptor, callableDescriptor)) {\n                    callableExtensionDescriptors.add(callableDescriptor);\n                }\n            }\n        }\n\n        return callableExtensionDescriptors;\n    }","id":37602,"modified_method":"/**\n     * Check that function or property with the given qualified name can be resolved in given scope and called on given receiver\n     *\n     * @param callableFQN\n     * @param project\n     * @param scope\n     * @return\n     */\n    public static List<CallableDescriptor> canFindSuitableCall(\n            @NotNull String callableFQN,\n            @NotNull Project project,\n            @NotNull JetExpression receiverExpression,\n            @NotNull JetType receiverType,\n            @NotNull JetScope scope) {\n\n        JetImportDirective importDirective = JetPsiFactory.createImportDirective(project, callableFQN);\n\n        Collection<? extends DeclarationDescriptor> declarationDescriptors = ImportsResolver.analyseImportReference(importDirective, scope, new BindingTraceContext());\n\n        List<CallableDescriptor> callableExtensionDescriptors = new ArrayList<CallableDescriptor>();\n        ReceiverDescriptor receiverDescriptor = new ExpressionReceiver(receiverExpression, receiverType);\n\n        for (DeclarationDescriptor declarationDescriptor : declarationDescriptors) {\n            if (declarationDescriptor instanceof CallableDescriptor) {\n                CallableDescriptor callableDescriptor = (CallableDescriptor) declarationDescriptor;\n\n                if (checkIsExtensionCallable(receiverDescriptor, callableDescriptor)) {\n                    callableExtensionDescriptors.add(callableDescriptor);\n                }\n            }\n        }\n\n        return callableExtensionDescriptors;\n    }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void processImports(boolean firstPhase) {\n        ImportResolver importResolver = new ImportResolver(context.getTrace(), firstPhase);\n        for (JetFile file : context.getNamespaceDescriptors().keySet()) {\n            WritableScope namespaceScope = context.getNamespaceScopes().get(file);\n            Importer.DelayedImporter delayedImporter = new Importer.DelayedImporter(namespaceScope, firstPhase);\n            if (!firstPhase) {\n                namespaceScope.clearImports();\n            }\n            context.getConfiguration().addDefaultImports(context.getTrace(), namespaceScope, delayedImporter);\n            Map<JetImportDirective, DeclarationDescriptor> resolvedDirectives = Maps.newHashMap();\n\n            List<JetImportDirective> importDirectives = file.getImportDirectives();\n            for (JetImportDirective importDirective : importDirectives) {\n                Collection<? extends DeclarationDescriptor> descriptors = importResolver.processImportReference(importDirective, namespaceScope, delayedImporter);\n                if (descriptors.size() == 1) {\n                    resolvedDirectives.put(importDirective, descriptors.iterator().next());\n                }\n            }\n            delayedImporter.processImports();\n\n            if (firstPhase) continue;\n            for (JetImportDirective importDirective : importDirectives) {\n                reportUselessImport(importDirective, namespaceScope, resolvedDirectives);\n            }\n        }\n    }","id":37603,"modified_method":"private void processImports(boolean firstPhase) {\n        SingleImportResolver importResolver = new SingleImportResolver(context.getTrace(), firstPhase);\n        SingleImportResolver defaultImportResolver = new SingleImportResolver(TemporaryBindingTrace.create(context.getTrace()), firstPhase);//not to trace errors of default imports\n        for (JetFile file : context.getNamespaceDescriptors().keySet()) {\n            WritableScope namespaceScope = context.getNamespaceScopes().get(file);\n            Importer.DelayedImporter delayedImporter = new Importer.DelayedImporter(namespaceScope, firstPhase);\n            if (!firstPhase) {\n                namespaceScope.clearImports();\n            }\n            Map<JetImportDirective, DeclarationDescriptor> resolvedDirectives = Maps.newHashMap();\n            Collection<JetImportDirective> defaultImportDirectives = Lists.newArrayList();\n            context.getConfiguration().addDefaultImports(namespaceScope, defaultImportDirectives);\n            for (JetImportDirective defaultImportDirective : defaultImportDirectives) {\n                defaultImportResolver.processImportReference(defaultImportDirective, namespaceScope, delayedImporter);\n            }\n\n            List<JetImportDirective> importDirectives = file.getImportDirectives();\n            for (JetImportDirective importDirective : importDirectives) {\n                Collection<? extends DeclarationDescriptor> descriptors = importResolver.processImportReference(importDirective, namespaceScope, delayedImporter);\n                if (descriptors.size() == 1) {\n                    resolvedDirectives.put(importDirective, descriptors.iterator().next());\n                }\n            }\n            delayedImporter.processImports();\n\n            if (firstPhase) continue;\n            for (JetImportDirective importDirective : importDirectives) {\n                reportUselessImport(importDirective, namespaceScope, resolvedDirectives);\n            }\n        }\n    }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope, @NotNull Importer importer) {\n        rootScope.importScope(new JavaPackageScope(\"\", createNamespaceDescriptor(JavaDescriptorResolver.JAVA_ROOT, \"\"), javaSemanticServices));\n        for (String importFQN : DEFAULT_JAVA_IMPORTS) {\n            NamespaceDescriptor namespaceDescriptor = javaSemanticServices.getDescriptorResolver().resolveNamespace(importFQN);\n            if (namespaceDescriptor != null) {\n                importer.addScopeImport(namespaceDescriptor.getMemberScope());\n            }\n        }\n        delegateConfiguration.addDefaultImports(trace, rootScope, importer);\n    }","id":37604,"modified_method":"@Override\n    public void addDefaultImports(@NotNull WritableScope rootScope, @NotNull Collection<JetImportDirective> directives) {\n        rootScope.importScope(new JavaPackageScope(\"\", createNamespaceDescriptor(JavaDescriptorResolver.JAVA_ROOT, \"\"), javaSemanticServices));\n        for (String importFQN : DEFAULT_JAVA_IMPORTS) {\n            directives.add(JetPsiFactory.createImportDirective(project, importFQN));\n        }\n        delegateConfiguration.addDefaultImports(rootScope, directives);\n    }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private JavaBridgeConfiguration(Project project, BindingTrace trace, Configuration delegateConfiguration) {\n        this.javaSemanticServices = new JavaSemanticServices(project, JetSemanticServices.createSemanticServices(project), trace);\n        this.delegateConfiguration = delegateConfiguration;\n    }","id":37605,"modified_method":"private JavaBridgeConfiguration(Project project, BindingTrace trace, Configuration delegateConfiguration) {\n        this.project = project;\n        this.javaSemanticServices = new JavaSemanticServices(project, JetSemanticServices.createSemanticServices(project), trace);\n        this.delegateConfiguration = delegateConfiguration;\n    }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope, @NotNull Importer importer) {\n        ImportsResolver.ImportResolver importResolver = new ImportsResolver.ImportResolver(trace, true);\n        for (String defaultJetImport : DEFAULT_JET_IMPORTS) {\n            importResolver.processImportReference(JetPsiFactory.createImportDirective(project, defaultJetImport), rootScope, importer);\n        }\n    }","id":37606,"modified_method":"@Override\n    public void addDefaultImports(@NotNull WritableScope rootScope, @NotNull Collection<JetImportDirective> directives) {\n        for (String defaultJetImport : DEFAULT_JET_IMPORTS) {\n            directives.add(JetPsiFactory.createImportDirective(project, defaultJetImport));\n        }\n    }","commit_id":"d5da6e8c235d9579b4d869ace05733bf6d0152e0","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void processImports(boolean firstPhase) {\n        ImportResolver importResolver = new ImportResolver(context.getTrace(), firstPhase);\n        for (JetFile file : context.getNamespaceDescriptors().keySet()) {\n            WritableScope namespaceScope = context.getNamespaceScopes().get(file);\n            if (!firstPhase) {\n                namespaceScope.clearImports();\n            }\n            context.getConfiguration().addDefaultImports(context.getTrace(), namespaceScope);\n            Map<JetImportDirective, DeclarationDescriptor> resolvedDirectives = Maps.newHashMap();\n\n            List<JetImportDirective> importDirectives = file.getImportDirectives();\n            for (JetImportDirective importDirective : importDirectives) {\n                Collection<? extends DeclarationDescriptor> descriptors = importResolver.processImportReference(importDirective, namespaceScope);\n                if (descriptors != null && descriptors.size() == 1) {\n                    resolvedDirectives.put(importDirective, descriptors.iterator().next());\n                }\n            }\n\n            if (firstPhase) continue;\n            for (JetImportDirective importDirective : importDirectives) {\n                reportUselessImport(importDirective, namespaceScope, resolvedDirectives);\n            }\n        }\n    }","id":37607,"modified_method":"private void processImports(boolean firstPhase) {\n        ImportResolver importResolver = new ImportResolver(context.getTrace(), firstPhase);\n        for (JetFile file : context.getNamespaceDescriptors().keySet()) {\n            WritableScope namespaceScope = context.getNamespaceScopes().get(file);\n            Importer.DelayedImporter delayedImporter = new Importer.DelayedImporter(namespaceScope, firstPhase);\n            if (!firstPhase) {\n                namespaceScope.clearImports();\n            }\n            context.getConfiguration().addDefaultImports(context.getTrace(), namespaceScope, delayedImporter);\n            Map<JetImportDirective, DeclarationDescriptor> resolvedDirectives = Maps.newHashMap();\n\n            List<JetImportDirective> importDirectives = file.getImportDirectives();\n            for (JetImportDirective importDirective : importDirectives) {\n                Collection<? extends DeclarationDescriptor> descriptors = importResolver.processImportReference(importDirective, namespaceScope, delayedImporter);\n                if (descriptors != null && descriptors.size() == 1) {\n                    resolvedDirectives.put(importDirective, descriptors.iterator().next());\n                }\n            }\n            delayedImporter.processImports();\n\n            if (firstPhase) continue;\n            for (JetImportDirective importDirective : importDirectives) {\n                reportUselessImport(importDirective, namespaceScope, resolvedDirectives);\n            }\n        }\n    }","commit_id":"7fae503a387d431bdeb3a7b30dd104d454ffc63a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Nullable\n        public Collection<? extends DeclarationDescriptor> processImportReference(@NotNull JetImportDirective importDirective, @NotNull WritableScope namespaceScope) {\n            if (importDirective.isAbsoluteInRootNamespace()) {\n                trace.report(UNSUPPORTED.on(importDirective, \"TypeHierarchyResolver\")); // TODO\n                return null;\n            }\n            JetExpression importedReference = importDirective.getImportedReference();\n            if (importedReference == null) return null;\n            Collection<? extends DeclarationDescriptor> descriptors;\n            if (importedReference instanceof JetQualifiedExpression) {\n                descriptors = lookupDescriptorsForQualifiedExpression((JetQualifiedExpression) importedReference, namespaceScope);\n            }\n            else {\n                assert importedReference instanceof JetSimpleNameExpression;\n                descriptors = lookupDescriptorsForSimpleNameReference((JetSimpleNameExpression) importedReference, namespaceScope, true);\n            }\n\n            JetSimpleNameExpression referenceExpression = getLastReference(importedReference);\n            if (importDirective.isAllUnder()) {\n                if (referenceExpression == null || !canImportMembersFrom(descriptors, referenceExpression)) return null;\n                for (DeclarationDescriptor descriptor : descriptors) {\n                    importAllUnderDeclaration(descriptor, namespaceScope);\n                }\n                return null;\n            }\n\n            String aliasName = getAliasName(importDirective);\n            if (aliasName == null) return null;\n\n            for (DeclarationDescriptor descriptor : descriptors) {\n                importDeclarationAlias(namespaceScope, aliasName, descriptor);\n            }\n            return descriptors;\n        }","id":37608,"modified_method":"@Nullable\n        public Collection<? extends DeclarationDescriptor> processImportReference(@NotNull JetImportDirective importDirective, @NotNull JetScope scope, @NotNull Importer importer) {\n            if (importDirective.isAbsoluteInRootNamespace()) {\n                trace.report(UNSUPPORTED.on(importDirective, \"TypeHierarchyResolver\")); // TODO\n                return null;\n            }\n            JetExpression importedReference = importDirective.getImportedReference();\n            if (importedReference == null) return null;\n            Collection<? extends DeclarationDescriptor> descriptors;\n            if (importedReference instanceof JetQualifiedExpression) {\n                descriptors = lookupDescriptorsForQualifiedExpression((JetQualifiedExpression) importedReference, scope);\n            }\n            else {\n                assert importedReference instanceof JetSimpleNameExpression;\n                descriptors = lookupDescriptorsForSimpleNameReference((JetSimpleNameExpression) importedReference, scope, true);\n            }\n\n            JetSimpleNameExpression referenceExpression = getLastReference(importedReference);\n            if (importDirective.isAllUnder()) {\n                if (referenceExpression == null || !canImportMembersFrom(descriptors, referenceExpression)) return null;\n                for (DeclarationDescriptor descriptor : descriptors) {\n                    importer.addAllUnderImport(descriptor);\n                }\n                return null;\n            }\n\n            String aliasName = getAliasName(importDirective);\n            if (aliasName == null) return null;\n\n            for (DeclarationDescriptor descriptor : descriptors) {\n                importer.addAliasImport(descriptor, aliasName);\n            }\n            return descriptors;\n        }","commit_id":"7fae503a387d431bdeb3a7b30dd104d454ffc63a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n        private Collection<? extends DeclarationDescriptor> lookupObjectMembers(@NotNull ClassDescriptor classDescriptor, @NotNull JetSimpleNameExpression memberReference) {\n            if (firstPhase) {\n                ClassDescriptor objectDescriptor = getObjectIfObjectOrClassObjectDescriptor(classDescriptor);\n                if (objectDescriptor == null) return Collections.emptyList();\n                return getInnerClassesAndObjectsByName(objectDescriptor, memberReference);\n            }\n            //on second phase class descriptor is only a descriptor for class object\n            JetType classObjectType = classDescriptor.getClassObjectType();\n            if (classObjectType == null) return Collections.emptyList();\n            return lookupDescriptorsForSimpleNameReference(memberReference, classObjectType.getMemberScope(), false);\n        }","id":37609,"modified_method":"@NotNull\n        private Collection<? extends DeclarationDescriptor> lookupObjectMembers(@NotNull ClassDescriptor classDescriptor, @NotNull JetSimpleNameExpression memberReference) {\n            if (firstPhase) {\n                ClassDescriptor objectDescriptor = DescriptorUtils.getObjectIfObjectOrClassObjectDescriptor(classDescriptor);\n                if (objectDescriptor == null) return Collections.emptyList();\n                return getInnerClassesAndObjectsByName(objectDescriptor, memberReference);\n            }\n            //on second phase class descriptor is only a descriptor for class object\n            JetType classObjectType = classDescriptor.getClassObjectType();\n            if (classObjectType == null) return Collections.emptyList();\n            return lookupDescriptorsForSimpleNameReference(memberReference, classObjectType.getMemberScope(), false);\n        }","commit_id":"7fae503a387d431bdeb3a7b30dd104d454ffc63a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope) {\n        rootScope.importScope(new JavaPackageScope(\"\", null, javaSemanticServices));\n        rootScope.importScope(new JavaPackageScope(\"java.lang\", null, javaSemanticServices));\n        delegateConfiguration.addDefaultImports(trace, rootScope);\n    }","id":37610,"modified_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope, @NotNull Importer importer) {\n        rootScope.importScope(new JavaPackageScope(\"\", null, javaSemanticServices));\n        importer.addScopeImport(new JavaPackageScope(\"java.lang\", null, javaSemanticServices));\n        delegateConfiguration.addDefaultImports(trace, rootScope, importer);\n    }","commit_id":"7fae503a387d431bdeb3a7b30dd104d454ffc63a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope) {\n        JetImportDirective importDirective = JetPsiFactory.createImportDirective(project, \"std.*\");\n        new ImportsResolver.ImportResolver(trace, true).processImportReference(importDirective, rootScope);\n    }","id":37611,"modified_method":"@Override\n    public void addDefaultImports(@NotNull BindingTrace trace, @NotNull WritableScope rootScope, @NotNull Importer importer) {\n        ImportsResolver.ImportResolver importResolver = new ImportsResolver.ImportResolver(trace, true);\n        importResolver.processImportReference(JetPsiFactory.createImportDirective(project, \"std.*\"), rootScope, importer);\n    }","commit_id":"7fae503a387d431bdeb3a7b30dd104d454ffc63a","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n  public Collection<PsiElement> getDefaultContexts(PsiElement element) {\n    Project project = element.getProject();\n    PsiFile file = element.getContainingFile();\n    if (file == null) {\n      LOG.assertTrue(false, \"Invalid element: \" + element);\n    }\n\n    if (!file.isPhysical()) file = file.getOriginalFile();\n    if (file == null) return Collections.emptyList();\n    final WebModuleProperties properties = (WebModuleProperties)WebUtil.getWebModuleProperties(file);\n\n    PsiElement result = null;\n    if (myPathString.startsWith(SEPARATOR_STRING)) {\n      if (properties != null) {\n        result = JspManager.getInstance(project).findWebDirectoryElementByPath(\"/\", properties);\n      }\n      else {\n        final VirtualFile virtualFile = file.getVirtualFile();\n        if (virtualFile != null) {\n          final VirtualFile contentRootForFile = ProjectRootManager.getInstance(project).getFileIndex()\n            .getContentRootForFile(virtualFile);\n          if (contentRootForFile != null) {\n            result = PsiManager.getInstance(project).findDirectory(contentRootForFile);\n          }\n        }\n      }\n    }\n    else {\n      final PsiDirectory dir = file.getContainingDirectory();\n      if (dir != null) {\n        if (properties != null) {\n          result = JspManager.getInstance(project).findWebDirectoryByFile(dir.getVirtualFile(), properties);\n          if (result == null) result = dir;\n        }\n        else {\n          result = dir;\n        }\n      }\n    }\n\n    return result == null ?\n           Collections.<PsiElement>emptyList() :\n           Collections.singleton(result);\n  }","id":37612,"modified_method":"@NotNull\n  public Collection<PsiElement> getDefaultContexts(PsiElement element) {\n    Project project = element.getProject();\n    PsiFile file = element.getContainingFile();\n    if (file == null) {\n      LOG.assertTrue(false, \"Invalid element: \" + element);\n    }\n\n    if (!file.isPhysical()) file = file.getOriginalFile();\n    if (file == null) return Collections.emptyList();\n    if (myOptions != null) {\n      final Function<PsiFile,PsiElement> value = DEFAULT_PATH_EVALUATOR_OPTION.getValue(myOptions);\n\n      if (value != null) {\n        final PsiElement result = value.fun(file);\n        return result == null ?\n           Collections.<PsiElement>emptyList() :\n           Collections.singleton(result);\n      }\n    }\n\n    final WebModuleProperties properties = WebUtil.getWebModuleProperties(file);\n\n    PsiElement result = null;\n    if (myPathString.startsWith(SEPARATOR_STRING)) {\n      result = getAbsoluteTopLevelDirLocation(properties, project, file);\n    }\n    else {\n      final PsiDirectory dir = file.getContainingDirectory();\n      if (dir != null) {\n        if (properties != null) {\n          result = JspManager.getInstance(project).findWebDirectoryByFile(dir.getVirtualFile(), properties);\n          if (result == null) result = dir;\n        }\n        else {\n          result = dir;\n        }\n      }\n    }\n\n    return result == null ?\n           Collections.<PsiElement>emptyList() :\n           Collections.singleton(result);\n  }","commit_id":"097aa0ec4b8f48949145051e07f2d9d565d014e8","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public FileReferenceSet(String str,\n                          PsiElement element,\n                          int startInElement,\n                          ReferenceType type,\n                          PsiReferenceProvider provider,\n                          final boolean isCaseSensitive,\n                          boolean allowEmptyFileReferenceAtEnd){\n    myType = type;\n    myElement = element;\n    myStartInElement = startInElement;\n    myProvider = provider;\n    myCaseSensitive = isCaseSensitive;\n    myPathString = str.trim();\n    myAllowEmptyFileReferenceAtEnd = allowEmptyFileReferenceAtEnd;\n\n    reparse(str);\n  }","id":37613,"modified_method":"public FileReferenceSet(String str,\n                          PsiElement element,\n                          int startInElement,\n                          ReferenceType type,\n                          PsiReferenceProvider provider,\n                          final boolean isCaseSensitive,\n                          boolean allowEmptyFileReferenceAtEnd){\n    myType = type;\n    myElement = element;\n    myStartInElement = startInElement;\n    myProvider = provider;\n    myCaseSensitive = isCaseSensitive;\n    myPathString = str.trim();\n    myAllowEmptyFileReferenceAtEnd = allowEmptyFileReferenceAtEnd;\n    myOptions = (provider instanceof CustomizableReferenceProvider) ? ((CustomizableReferenceProvider)provider).getOptions() : null;\n\n    reparse(str);\n  }","commit_id":"097aa0ec4b8f48949145051e07f2d9d565d014e8","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private ReferenceProvidersRegistry() {\n    // Temp scopes declarations\n    myTempScopes.add(PsiIdentifier.class);\n\n    // Manipulators mapping\n    registerManipulator(XmlAttributeValue.class, new XmlAttributeValueManipulator());\n    registerManipulator(PsiPlainTextFile.class, new PlainFileManipulator());\n    registerManipulator(XmlToken.class, new XmlTokenManipulator());\n    registerManipulator(PsiLiteralExpression.class, new StringLiteralManipulator());\n    registerManipulator(XmlTag.class, new XmlTagValueManipulator());\n    // Binding declarations\n\n    myReferenceTypeToProviderMap.put(CLASS_REFERENCE_PROVIDER, new JavaClassReferenceProvider());\n    myReferenceTypeToProviderMap.put(PATH_REFERENCES_PROVIDER, new JspxIncludePathReferenceProvider());\n    myReferenceTypeToProviderMap.put(DYNAMIC_PATH_REFERENCES_PROVIDER, new JspxDynamicPathReferenceProvider());\n    myReferenceTypeToProviderMap.put(PROPERTIES_FILE_KEY_PROVIDER, new PropertiesReferenceProvider());\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"class\", \"type\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new TextFilter(\"useBean\"),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ), 2\n        )\n      ), getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    RegisterInPsi.referenceProviders(this);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"extends\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ), getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    final CustomizableReferenceProvider classReferenceProvider = (CustomizableReferenceProvider)getProviderByType(CLASS_REFERENCE_PROVIDER);\n    final CustomizingReferenceProvider qualifiedClassReferenceProvider = new CustomizingReferenceProvider(classReferenceProvider);\n    qualifiedClassReferenceProvider.addCustomization(JavaClassReferenceProvider.RESOLVE_QUALIFIED_CLASS_NAME, true);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"type\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.attribute\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"attribute\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      qualifiedClassReferenceProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"variable-class\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.variable\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"variable\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      qualifiedClassReferenceProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] { \"import\" },\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      new JspImportListReferenceProvider()\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"errorPage\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              ),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ))\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"file\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"include\")\n              ),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.include\")\n              ))\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    final CustomizableReferenceProvider dynamicPathReferenceProvider = (CustomizableReferenceProvider)getProviderByType(DYNAMIC_PATH_REFERENCES_PROVIDER);\n    final CustomizingReferenceProvider dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd = new CustomizingReferenceProvider(dynamicPathReferenceProvider);\n    dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd.addCustomization(\n      JspxDynamicPathReferenceProvider.ALLOW_REFERENCING_DIR_WITH_END_SLASH,\n      true\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"value\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"url\")\n            )\n          ), 2\n        )\n      ), dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"url\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new OrFilter(\n                new TextFilter(\"import\"),\n                new TextFilter(\"redirect\")\n              )\n            )\n          ), 2\n        )\n      ), dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"key\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new NamespaceFilter(XmlUtil.JSTL_FORMAT_URIS),\n              new NamespaceFilter(XmlUtil.STRUTS_BEAN_URI)\n            ),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"message\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"altKey\",\"titleKey\",\"pageKey\",\"srcKey\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.STRUTS_HTML_URI),\n            new ClassFilter(XmlTag.class)\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"code\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.SPRING_URI),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"message\", \"theme\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"page\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new OrFilter(\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.JSP_URI),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"include\",\"forward\")\n              )\n            ),\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.STRUTS_HTML_URI),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"rewrite\")\n              )\n            )\n          ), 2\n        )\n      ), getProviderByType(DYNAMIC_PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlTagReferenceProvider(\n      new String[]{\"welcome-file\",\"location\",\"taglib-location\"},\n      new NamespaceFilter(XmlUtil.WEB_XML_URIS),\n      true,\n      getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"tagdir\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"taglib\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] { \"uri\" },\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"taglib\")\n            )\n          ), 2\n        )\n      ),\n      new JspUriReferenceProvider()\n    );\n\n    final JavaClassListReferenceProvider classListProvider = new JavaClassListReferenceProvider();\n    registerXmlAttributeValueReferenceProvider(null,\n    new AndFilter(\n      new NotFilter(\n        new ParentElementFilter(\n          new NamespaceFilter(XmlUtil.ANT_URI), 2)),\n      new NotFilter(\n      new ScopeFilter(new ParentElementFilter(\n        new AndFilter(\n          new OrFilter(\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"directive.page\")),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"page\"))),\n          new NamespaceFilter(XmlUtil.JSP_URI)), 2)))), classListProvider);\n\n    registerReferenceProvider(new TokenTypeFilter(XmlTokenType.XML_DATA_CHARACTERS), XmlToken.class,\n                              classListProvider);\n\n    registerXmlTagReferenceProvider(\n      new String[] {\n        \"function-class\", \"tag-class\", \"tei-class\", \"variable-class\", \"type\", \"path\",\n        \"function-signature\", \"name\", \"name-given\"\n      },\n      new NamespaceFilter(MetaRegistry.TAGLIB_URIS),\n      true,\n      new TaglibReferenceProvider( getProviderByType(CLASS_REFERENCE_PROVIDER) )\n    );\n\n    final NamespaceFilter jsfNsFilter = new NamespaceFilter(XmlUtil.JSF_URIS);\n    registerXmlTagReferenceProvider(\n      new String[] {\n        \"render-kit-class\",\"renderer-class\",\"managed-bean-class\",\"attribute-class\",\"component-class\",\n        \"converter-for-class\", \"converter-class\", \"key-class\", \"value-class\",\n        \"referenced-bean-class\", \"validator-class\", \"application-factory\", \"faces-context-factory\",\n        \"render-kit-factory\", \"lifecycle-factory\", \"view-handler\", \"variable-resolver\", \"phase-listener\",\n        \"property-resolver\", \"state-manager\", \"action-listener\", \"navigation-handler\"\n      },\n      jsfNsFilter,\n      true,\n      getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    final JSFReferencesProvider jsfProvider = new JSFReferencesProvider();\n\n    registerXmlTagReferenceProvider(\n      new String[] { \"property-name\", \"property-class\" },\n      jsfNsFilter,\n      true,\n      jsfProvider\n    );\n\n    final DtdReferencesProvider dtdReferencesProvider = new DtdReferencesProvider();\n    //registerReferenceProvider(null, XmlEntityDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlEntityRef.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlDoctype.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlElementDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlAttlistDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlElementContentSpec.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlToken.class,dtdReferencesProvider);\n\n    URIReferenceProvider uriProvider = new URIReferenceProvider();\n\n    registerTypeWithProvider(URI_PROVIDER,uriProvider);\n    registerXmlAttributeValueReferenceProvider(\n      null,\n      dtdReferencesProvider.getSystemReferenceFilter(),\n      uriProvider\n    );\n\n    //registerReferenceProvider(PsiPlainTextFile.class, new JavaClassListReferenceProvider());\n\n    HtmlReferenceProvider provider = new HtmlReferenceProvider();\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\n        \"src\", \"href\", \"action\", \"background\", \"width\", \"height\", \"type\", \"bgcolor\", \"color\", \"vlink\", \"link\", \"alink\", \"text\", \"name\"\n      },\n      provider.getFilter(),\n      false,\n      provider\n    );\n\n    final PsiReferenceProvider filePathReferenceProvider = new FilePathReferenceProvider();\n    registerReferenceProvider(\n      new ElementFilter() {\n        public boolean isAcceptable(Object element, PsiElement context) {\n          if (context instanceof PsiLiteralExpression) {\n            PsiLiteralExpression literalExpression = (PsiLiteralExpression) context;\n            final Map<String, Object> annotationParams = new HashMap<String, Object>();\n            annotationParams.put(AnnotationUtil.PROPERTY_KEY_RESOURCE_BUNDLE_PARAMETER, null);\n            if (I18nUtil.mustBePropertyKey(literalExpression, annotationParams)) {\n              return false;\n            }\n          }\n          return true;\n        }\n\n        public boolean isClassAcceptable(Class hintClass) {\n          return true;\n        }\n      }, PsiLiteralExpression.class, filePathReferenceProvider);\n\n    final SchemaReferencesProvider schemaReferencesProvider = new SchemaReferencesProvider();\n    registerTypeWithProvider(SCHEMA_PROVIDER, schemaReferencesProvider);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"ref\",\"type\",\"base\",\"name\",\"substitutionGroup\",\"memberTypes\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new NamespaceFilter(MetaRegistry.SCHEMA_URIS), 2\n        )\n      ),\n      schemaReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"xsi:type\"},\n      null,\n      schemaReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"xsi:noNamespaceSchemaLocation\"},\n      null,\n      uriProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"schemaLocation\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(MetaRegistry.SCHEMA_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"import\",\"include\")\n            )\n          ), 2\n        )\n      ),\n      uriProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      null,\n      uriProvider.getNamespaceAttributeFilter(),\n      uriProvider\n    );\n\n    final JspReferencesProvider jspReferencesProvider = new JspReferencesProvider();\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"fragment\",\"name\",\"property\",\"id\",\"name-given\",\"dynamic-attributes\",\"name-from-attribute\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new NamespaceFilter(\n              new String[] {\n                XmlUtil.JSP_URI,\n                XmlUtil.STRUTS_BEAN_URI,\n                XmlUtil.STRUTS_LOGIC_URI\n              }\n            )\n          ), 2\n        )\n      ),\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"var\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS)\n          ), 2\n        )\n      ),\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"scope\"},\n      null,\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"name\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new AndFilter(\n              new TextFilter(\"property\"),\n              new NamespaceFilter(XmlUtil.SPRING_CORE_URIS)\n            )\n          ), 2\n        )\n      ),\n      new SpringReferencesProvider()\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"name\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.HIBERNATE_URIS),\n              new TextFilter(new String[] { \"property\",\"list\",\"map\",\"set\", \"array\", \"bag\", \"idbag\", \"primitive-array\", \"many-to-one\", \"one-to-one\"} )\n            )\n          ), 2\n        )\n      ),\n      new HibernateReferencesProvider()\n    );\n  }","id":37614,"modified_method":"private ReferenceProvidersRegistry() {\n    // Temp scopes declarations\n    myTempScopes.add(PsiIdentifier.class);\n\n    // Manipulators mapping\n    registerManipulator(XmlAttributeValue.class, new XmlAttributeValueManipulator());\n    registerManipulator(PsiPlainTextFile.class, new PlainFileManipulator());\n    registerManipulator(XmlToken.class, new XmlTokenManipulator());\n    registerManipulator(PsiLiteralExpression.class, new StringLiteralManipulator());\n    registerManipulator(XmlTag.class, new XmlTagValueManipulator());\n    // Binding declarations\n\n    myReferenceTypeToProviderMap.put(CLASS_REFERENCE_PROVIDER, new JavaClassReferenceProvider());\n    myReferenceTypeToProviderMap.put(PATH_REFERENCES_PROVIDER, new JspxIncludePathReferenceProvider());\n    myReferenceTypeToProviderMap.put(DYNAMIC_PATH_REFERENCES_PROVIDER, new JspxDynamicPathReferenceProvider());\n    myReferenceTypeToProviderMap.put(PROPERTIES_FILE_KEY_PROVIDER, new PropertiesReferenceProvider());\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"class\", \"type\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new TextFilter(\"useBean\"),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ), 2\n        )\n      ), getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    RegisterInPsi.referenceProviders(this);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"extends\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ), getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    final CustomizableReferenceProvider classReferenceProvider = (CustomizableReferenceProvider)getProviderByType(CLASS_REFERENCE_PROVIDER);\n    final CustomizingReferenceProvider qualifiedClassReferenceProvider = new CustomizingReferenceProvider(classReferenceProvider);\n    qualifiedClassReferenceProvider.addCustomization(JavaClassReferenceProvider.RESOLVE_QUALIFIED_CLASS_NAME, true);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"type\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.attribute\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"attribute\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      qualifiedClassReferenceProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"variable-class\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.variable\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"variable\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      qualifiedClassReferenceProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] { \"import\" },\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ),\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              )\n            ),\n            new NamespaceFilter(XmlUtil.JSP_URI)\n          ),\n          2\n        )\n      ),\n      new JspImportListReferenceProvider()\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"errorPage\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"page\")\n              ),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.page\")\n              ))\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"file\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new OrFilter(\n              new AndFilter(\n                new ClassFilter(JspDirective.class),\n                new TextFilter(\"include\")\n              ),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"directive.include\")\n              ))\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    final CustomizableReferenceProvider dynamicPathReferenceProvider = (CustomizableReferenceProvider)getProviderByType(DYNAMIC_PATH_REFERENCES_PROVIDER);\n    final CustomizingReferenceProvider dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd = new CustomizingReferenceProvider(dynamicPathReferenceProvider);\n    dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd.addCustomization(\n      JspxDynamicPathReferenceProvider.ALLOW_REFERENCING_DIR_WITH_END_SLASH,\n      true\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"value\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"url\")\n            )\n          ), 2\n        )\n      ), dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"url\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new OrFilter(\n                new TextFilter(\"import\"),\n                new TextFilter(\"redirect\")\n              )\n            )\n          ), 2\n        )\n      ), dynamicPathReferenceProviderNoEmptyFileReferencesAtEnd\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"key\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new OrFilter(\n              new NamespaceFilter(XmlUtil.JSTL_FORMAT_URIS),\n              new NamespaceFilter(XmlUtil.STRUTS_BEAN_URI)\n            ),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"message\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"altKey\",\"titleKey\",\"pageKey\",\"srcKey\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.STRUTS_HTML_URI),\n            new ClassFilter(XmlTag.class)\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"code\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.SPRING_URI),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"message\", \"theme\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PROPERTIES_FILE_KEY_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"page\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new OrFilter(\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.JSP_URI),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"include\",\"forward\")\n              )\n            ),\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.STRUTS_HTML_URI),\n              new AndFilter(\n                new ClassFilter(XmlTag.class),\n                new TextFilter(\"rewrite\")\n              )\n            )\n          ), 2\n        )\n      ), getProviderByType(DYNAMIC_PATH_REFERENCES_PROVIDER)\n    );\n\n    final PsiReferenceProvider pathReferenceProvider = getProviderByType(PATH_REFERENCES_PROVIDER);\n    final CustomizingReferenceProvider webXmlPathReferenceProvider = new CustomizingReferenceProvider(\n      (CustomizableReferenceProvider)pathReferenceProvider\n    );\n\n    webXmlPathReferenceProvider.addCustomization(\n      FileReferenceSet.DEFAULT_PATH_EVALUATOR_OPTION,\n      new Function<PsiFile, PsiElement>() {\n        public PsiElement fun(final PsiFile file) {\n          return FileReferenceSet.getAbsoluteTopLevelDirLocation(\n            WebUtil.getWebModuleProperties(file),\n            file.getProject(),\n            file\n          );\n        }\n      }\n    );\n\n    registerXmlTagReferenceProvider(\n      new String[]{\"welcome-file\",\"location\",\"taglib-location\"},\n      new NamespaceFilter(XmlUtil.WEB_XML_URIS),\n      true,\n      webXmlPathReferenceProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[]{\"tagdir\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"taglib\")\n            )\n          ), 2\n        )\n      ), getProviderByType(PATH_REFERENCES_PROVIDER)\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] { \"uri\" },\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(XmlUtil.JSP_URI),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"taglib\")\n            )\n          ), 2\n        )\n      ),\n      new JspUriReferenceProvider()\n    );\n\n    final JavaClassListReferenceProvider classListProvider = new JavaClassListReferenceProvider();\n    registerXmlAttributeValueReferenceProvider(null,\n    new AndFilter(\n      new NotFilter(\n        new ParentElementFilter(\n          new NamespaceFilter(XmlUtil.ANT_URI), 2)),\n      new NotFilter(\n      new ScopeFilter(new ParentElementFilter(\n        new AndFilter(\n          new OrFilter(\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"directive.page\")),\n            new AndFilter(\n              new ClassFilter(JspDirective.class),\n              new TextFilter(\"page\"))),\n          new NamespaceFilter(XmlUtil.JSP_URI)), 2)))), classListProvider);\n\n    registerReferenceProvider(new TokenTypeFilter(XmlTokenType.XML_DATA_CHARACTERS), XmlToken.class,\n                              classListProvider);\n\n    registerXmlTagReferenceProvider(\n      new String[] {\n        \"function-class\", \"tag-class\", \"tei-class\", \"variable-class\", \"type\", \"path\",\n        \"function-signature\", \"name\", \"name-given\"\n      },\n      new NamespaceFilter(MetaRegistry.TAGLIB_URIS),\n      true,\n      new TaglibReferenceProvider( getProviderByType(CLASS_REFERENCE_PROVIDER) )\n    );\n\n    final NamespaceFilter jsfNsFilter = new NamespaceFilter(XmlUtil.JSF_URIS);\n    registerXmlTagReferenceProvider(\n      new String[] {\n        \"render-kit-class\",\"renderer-class\",\"managed-bean-class\",\"attribute-class\",\"component-class\",\n        \"converter-for-class\", \"converter-class\", \"key-class\", \"value-class\",\n        \"referenced-bean-class\", \"validator-class\", \"application-factory\", \"faces-context-factory\",\n        \"render-kit-factory\", \"lifecycle-factory\", \"view-handler\", \"variable-resolver\", \"phase-listener\",\n        \"property-resolver\", \"state-manager\", \"action-listener\", \"navigation-handler\"\n      },\n      jsfNsFilter,\n      true,\n      getProviderByType(CLASS_REFERENCE_PROVIDER)\n    );\n\n    final JSFReferencesProvider jsfProvider = new JSFReferencesProvider();\n\n    registerXmlTagReferenceProvider(\n      new String[] { \"property-name\", \"property-class\" },\n      jsfNsFilter,\n      true,\n      jsfProvider\n    );\n\n    final DtdReferencesProvider dtdReferencesProvider = new DtdReferencesProvider();\n    //registerReferenceProvider(null, XmlEntityDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlEntityRef.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlDoctype.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlElementDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlAttlistDecl.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlElementContentSpec.class,dtdReferencesProvider);\n    registerReferenceProvider(null, XmlToken.class,dtdReferencesProvider);\n\n    URIReferenceProvider uriProvider = new URIReferenceProvider();\n\n    registerTypeWithProvider(URI_PROVIDER,uriProvider);\n    registerXmlAttributeValueReferenceProvider(\n      null,\n      dtdReferencesProvider.getSystemReferenceFilter(),\n      uriProvider\n    );\n\n    //registerReferenceProvider(PsiPlainTextFile.class, new JavaClassListReferenceProvider());\n\n    HtmlReferenceProvider provider = new HtmlReferenceProvider();\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\n        \"src\", \"href\", \"action\", \"background\", \"width\", \"height\", \"type\", \"bgcolor\", \"color\", \"vlink\", \"link\", \"alink\", \"text\", \"name\"\n      },\n      provider.getFilter(),\n      false,\n      provider\n    );\n\n    final PsiReferenceProvider filePathReferenceProvider = new FilePathReferenceProvider();\n    registerReferenceProvider(\n      new ElementFilter() {\n        public boolean isAcceptable(Object element, PsiElement context) {\n          if (context instanceof PsiLiteralExpression) {\n            PsiLiteralExpression literalExpression = (PsiLiteralExpression) context;\n            final Map<String, Object> annotationParams = new HashMap<String, Object>();\n            annotationParams.put(AnnotationUtil.PROPERTY_KEY_RESOURCE_BUNDLE_PARAMETER, null);\n            if (I18nUtil.mustBePropertyKey(literalExpression, annotationParams)) {\n              return false;\n            }\n          }\n          return true;\n        }\n\n        public boolean isClassAcceptable(Class hintClass) {\n          return true;\n        }\n      }, PsiLiteralExpression.class, filePathReferenceProvider);\n\n    final SchemaReferencesProvider schemaReferencesProvider = new SchemaReferencesProvider();\n    registerTypeWithProvider(SCHEMA_PROVIDER, schemaReferencesProvider);\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"ref\",\"type\",\"base\",\"name\",\"substitutionGroup\",\"memberTypes\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new NamespaceFilter(MetaRegistry.SCHEMA_URIS), 2\n        )\n      ),\n      schemaReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"xsi:type\"},\n      null,\n      schemaReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"xsi:noNamespaceSchemaLocation\"},\n      null,\n      uriProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"schemaLocation\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new NamespaceFilter(MetaRegistry.SCHEMA_URIS),\n            new AndFilter(\n              new ClassFilter(XmlTag.class),\n              new TextFilter(\"import\",\"include\")\n            )\n          ), 2\n        )\n      ),\n      uriProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      null,\n      uriProvider.getNamespaceAttributeFilter(),\n      uriProvider\n    );\n\n    final JspReferencesProvider jspReferencesProvider = new JspReferencesProvider();\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"fragment\",\"name\",\"property\",\"id\",\"name-given\",\"dynamic-attributes\",\"name-from-attribute\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new NamespaceFilter(\n              new String[] {\n                XmlUtil.JSP_URI,\n                XmlUtil.STRUTS_BEAN_URI,\n                XmlUtil.STRUTS_LOGIC_URI\n              }\n            )\n          ), 2\n        )\n      ),\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"var\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new NamespaceFilter(XmlUtil.JSTL_CORE_URIS)\n          ), 2\n        )\n      ),\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"scope\"},\n      null,\n      jspReferencesProvider\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"name\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new AndFilter(\n              new TextFilter(\"property\"),\n              new NamespaceFilter(XmlUtil.SPRING_CORE_URIS)\n            )\n          ), 2\n        )\n      ),\n      new SpringReferencesProvider()\n    );\n\n    registerXmlAttributeValueReferenceProvider(\n      new String[] {\"name\"},\n      new ScopeFilter(\n        new ParentElementFilter(\n          new AndFilter(\n            new ClassFilter(XmlTag.class),\n            new AndFilter(\n              new NamespaceFilter(XmlUtil.HIBERNATE_URIS),\n              new TextFilter(new String[] { \"property\",\"list\",\"map\",\"set\", \"array\", \"bag\", \"idbag\", \"primitive-array\", \"many-to-one\", \"one-to-one\"} )\n            )\n          ), 2\n        )\n      ),\n      new HibernateReferencesProvider()\n    );\n  }","commit_id":"097aa0ec4b8f48949145051e07f2d9d565d014e8","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static String getFileFqn(final PsiFile file) {\n    final VirtualFile virtualFile = file.getVirtualFile();\n    if (virtualFile == null) {\n      return file.getName();\n    }\n    final Project project = file.getManager().getProject();\n    final WebModuleProperties webModuleProperties = (WebModuleProperties)WebUtil.getWebModuleProperties(file);\n    if (webModuleProperties != null) {\n      final WebRoot webRoot = WebUtil.findParentWebRoot(virtualFile, webModuleProperties.getWebRoots(true));\n      if (webRoot != null && webRoot.getFile() != null) {\n        return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(webRoot.getFile()), VfsUtil.virtualToIoFile(virtualFile));\n      }\n    }\n\n    final VirtualFile sourceRoot = ProjectRootManager.getInstance(project).getFileIndex().getSourceRootForFile(virtualFile);\n    if (sourceRoot != null) {\n      return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(sourceRoot), VfsUtil.virtualToIoFile(virtualFile));\n    }\n    final VirtualFile contentRoot = ProjectRootManager.getInstance(project).getFileIndex().getContentRootForFile(virtualFile);\n    if (contentRoot != null) {\n      return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(contentRoot), VfsUtil.virtualToIoFile(virtualFile));\n    }\n    return virtualFile.getPath();\n  }","id":37615,"modified_method":"private static String getFileFqn(final PsiFile file) {\n    final VirtualFile virtualFile = file.getVirtualFile();\n    if (virtualFile == null) {\n      return file.getName();\n    }\n    final Project project = file.getManager().getProject();\n    final WebModuleProperties webModuleProperties = WebUtil.getWebModuleProperties(file);\n    if (webModuleProperties != null) {\n      final WebRoot webRoot = WebUtil.findParentWebRoot(virtualFile, webModuleProperties.getWebRoots(true));\n      if (webRoot != null && webRoot.getFile() != null) {\n        return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(webRoot.getFile()), VfsUtil.virtualToIoFile(virtualFile));\n      }\n    }\n\n    final VirtualFile sourceRoot = ProjectRootManager.getInstance(project).getFileIndex().getSourceRootForFile(virtualFile);\n    if (sourceRoot != null) {\n      return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(sourceRoot), VfsUtil.virtualToIoFile(virtualFile));\n    }\n    final VirtualFile contentRoot = ProjectRootManager.getInstance(project).getFileIndex().getContentRootForFile(virtualFile);\n    if (contentRoot != null) {\n      return \"/\"+FileUtil.getRelativePath(VfsUtil.virtualToIoFile(contentRoot), VfsUtil.virtualToIoFile(virtualFile));\n    }\n    return virtualFile.getPath();\n  }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean isPasteEnabled(DataContext dataContext) {\n      final Project project = (Project)dataContext.getData(DataConstants.PROJECT);\n      final Editor editor = (Editor)dataContext.getData(DataConstants.EDITOR);\n      if (project == null || editor == null) return false;\n      return getCopiedFqn() != null;\n    }","id":37616,"modified_method":"public boolean isPasteEnabled(DataContext dataContext) {\n      final Project project = (Project)dataContext.getData(DataConstants.PROJECT);\n      final Editor editor = (Editor)dataContext.getData(DataConstants.EDITOR);\n      return project != null && editor != null && getCopiedFqn() != null;\n    }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static String getCopiedFqn() {\n    final Transferable contents = CopyPasteManagerEx.getInstance().getContents();\n    if (contents == null) return null;\n    try {\n      return (String)contents.getTransferData(OUR_DATA_FLAVOR);\n    }\n    catch (UnsupportedFlavorException e) {\n    }\n    catch (IOException e) {\n    }\n    return null;\n  }","id":37617,"modified_method":"private static String getCopiedFqn() {\n    final Transferable contents = CopyPasteManager.getInstance().getContents();\n    if (contents == null) return null;\n    try {\n      return (String)contents.getTransferData(OUR_DATA_FLAVOR);\n    }\n    catch (UnsupportedFlavorException e) {\n    }\n    catch (IOException e) {\n    }\n    return null;\n  }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static PsiNamedElement fqnToElement(final Project project, final String fqn) {\n    PsiClass aClass = PsiManager.getInstance(project).findClass(fqn, GlobalSearchScope.allScope(project));\n    PsiNamedElement element;\n    if (aClass != null) {\n      return aClass;\n    }\n    final int endIndex = fqn.indexOf(\"#\");\n    if (endIndex == -1) return null;\n    String className = fqn.substring(0, endIndex);\n    if (className == null) return null;\n    aClass = PsiManager.getInstance(project).findClass(className, GlobalSearchScope.allScope(project));\n    if (aClass == null) return null;\n    String memberName = fqn.substring(endIndex + 1);\n    element = aClass.findFieldByName(memberName, false);\n    if (element != null) {\n      return element;\n    }\n    element = aClass.findMethodsByName(memberName, false)[0];\n    return element;\n  }","id":37618,"modified_method":"private static PsiNamedElement fqnToElement(final Project project, final String fqn) {\n    PsiClass aClass = PsiManager.getInstance(project).findClass(fqn, GlobalSearchScope.allScope(project));\n    if (aClass != null) {\n      return aClass;\n    }\n    final int endIndex = fqn.indexOf('#');\n    if (endIndex == -1) return null;\n    String className = fqn.substring(0, endIndex);\n    if (className == null) return null;\n    aClass = PsiManager.getInstance(project).findClass(className, GlobalSearchScope.allScope(project));\n    if (aClass == null) return null;\n    String memberName = fqn.substring(endIndex + 1);\n    PsiNamedElement element = aClass.findFieldByName(memberName, false);\n    if (element != null) {\n      return element;\n    }\n    element = aClass.findMethodsByName(memberName, false)[0];\n    return element;\n  }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static void doCopy(final PsiElement element, final Project project) {\n    String fqn = elementToFqn(element);\n\n    CopyPasteManagerEx.getInstance().setContents(new MyTransferable(fqn));\n\n    final StatusBarEx statusBar = (StatusBarEx)WindowManager.getInstance().getStatusBar(project);\n    statusBar.setInfo(IdeBundle.message(\"message.reference.to.fqn.has.been.copied\", fqn));\n  }","id":37619,"modified_method":"public static void doCopy(final PsiElement element, final Project project) {\n    String fqn = elementToFqn(element);\n\n    CopyPasteManager.getInstance().setContents(new MyTransferable(fqn));\n\n    final StatusBarEx statusBar = (StatusBarEx)WindowManager.getInstance().getStatusBar(project);\n    statusBar.setInfo(IdeBundle.message(\"message.reference.to.fqn.has.been.copied\", fqn));\n  }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void performPaste(DataContext dataContext) {\n      final Project project = (Project)dataContext.getData(DataConstants.PROJECT);\n      final Editor editor = (Editor)dataContext.getData(DataConstants.EDITOR);\n      if (project == null || editor == null) return;\n\n      final String fqn = getCopiedFqn();\n      PsiNamedElement element = CopyReferenceAction.fqnToElement(project, fqn);\n      insert(fqn, element, editor);\n\n    }","id":37620,"modified_method":"public void performPaste(DataContext dataContext) {\n      final Project project = (Project)dataContext.getData(DataConstants.PROJECT);\n      final Editor editor = (Editor)dataContext.getData(DataConstants.EDITOR);\n      if (project == null || editor == null) return;\n\n      final String fqn = getCopiedFqn();\n      PsiNamedElement element = fqnToElement(project, fqn);\n      insert(fqn, element, editor);\n\n    }","commit_id":"0a7024b96d137f73a159155c374e45625067cd71","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public PsiElement bindToElement(PsiElement element) throws IncorrectOperationException{\n    if (!(element instanceof PsiFileSystemItem)) throw new IncorrectOperationException(\"Cannot bind to element\");\n\n    final PsiFile file = getElement().getContainingFile();\n    final WebModuleProperties properties = (WebModuleProperties)WebUtil.getWebModuleProperties(file);\n    final String newName;\n    if (properties != null) {\n      newName = JspUtil.getDeploymentPath((PsiFileSystemItem)element);\n    } else {\n      final VirtualFile dst = element.getContainingFile().getVirtualFile();\n      if (dst == null) throw new IncorrectOperationException(\"Cannot bind to non-physical element:\" + element);\n      final VirtualFile currentFile = file.getVirtualFile();\n      LOG.assertTrue(currentFile != null);\n      newName = VfsUtil.getPath(currentFile, dst, '/');\n      if (newName == null) {\n        throw new IncorrectOperationException(\"Cannot find path between files; src = \" +\n                                              currentFile.getPresentableUrl() + \"; dst = \" + dst.getPresentableUrl());\n      }\n    }\n    final TextRange range = new TextRange(myFileReferenceSet.getStartInElement(), getRangeInElement().getEndOffset());\n    final ElementManipulator<PsiElement> manipulator = getManipulator(getElement());\n    if (manipulator == null) {\n      throw new IncorrectOperationException(\"Manipulator not defined for: \" + getElement());\n    }\n    return manipulator.handleContentChange(getElement(), range, newName);\n  }","id":37621,"modified_method":"public PsiElement bindToElement(PsiElement element) throws IncorrectOperationException{\n    if (!(element instanceof PsiFileSystemItem)) throw new IncorrectOperationException(\"Cannot bind to element\");\n\n    final PsiFile file = getElement().getContainingFile();\n    final String newName;\n    if (WebUtil.getWebModuleProperties(file) != null) {\n      newName = JspUtil.getDeploymentPath((PsiFileSystemItem)element);\n    } else {\n      final VirtualFile dst = element.getContainingFile().getVirtualFile();\n      if (dst == null) throw new IncorrectOperationException(\"Cannot bind to non-physical element:\" + element);\n      final VirtualFile currentFile = file.getVirtualFile();\n      LOG.assertTrue(currentFile != null);\n      newName = VfsUtil.getPath(currentFile, dst, '/');\n      if (newName == null) {\n        throw new IncorrectOperationException(\"Cannot find path between files; src = \" +\n                                              currentFile.getPresentableUrl() + \"; dst = \" + dst.getPresentableUrl());\n      }\n    }\n    final TextRange range = new TextRange(myFileReferenceSet.getStartInElement(), getRangeInElement().getEndOffset());\n    final ElementManipulator<PsiElement> manipulator = getManipulator(getElement());\n    if (manipulator == null) {\n      throw new IncorrectOperationException(\"Manipulator not defined for: \" + getElement());\n    }\n    return manipulator.handleContentChange(getElement(), range, newName);\n  }","commit_id":"dedeba38eaa20a4525ce5241570724d91b0c5251","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public ModuleType findByID(String moduleTypeID) {\n    if (JAVA_MODULE_ID_OLD.equals(moduleTypeID)) {\n      return ModuleType.JAVA; // for compatibility with the previous ID that Java modules had\n    }\n    for (int i = 0; i < myModuleTypes.size(); i++) {\n      ModuleType type = myModuleTypes.get(i);\n      if (type.getId().equals(moduleTypeID)) {\n        return type;\n      }\n    }\n\n    return new UnknownModuleType(moduleTypeID);\n  }","id":37622,"modified_method":"public ModuleType findByID(String moduleTypeID) {\n    if (JAVA_MODULE_ID_OLD.equals(moduleTypeID)) {\n      return ModuleType.JAVA; // for compatibility with the previous ID that Java modules had\n    }\n    for (ModuleType type : myModuleTypes) {\n      if (type.getId().equals(moduleTypeID)) {\n        return type;\n      }\n    }\n\n    return new UnknownModuleType(moduleTypeID);\n  }","commit_id":"dedeba38eaa20a4525ce5241570724d91b0c5251","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void registerDefaultTypes() {\n    ModuleType.JAVA = new JavaModuleType();\n    ModuleType.WEB = new WebModuleType();\n    ModuleType.J2EE_APPLICATION = new J2EEApplicationModuleType();\n\n    registerModuleType(ModuleType.JAVA);\n    registerModuleType(ModuleType.WEB);\n    registerModuleType(ModuleType.J2EE_APPLICATION);\n  }","id":37623,"modified_method":"private void registerDefaultTypes() {\n    ModuleType.JAVA = new JavaModuleType();\n    ModuleType.J2EE_APPLICATION = new J2EEApplicationModuleType();\n\n    registerModuleType(ModuleType.JAVA);\n    registerModuleType(ModuleType.J2EE_APPLICATION);\n  }","commit_id":"dedeba38eaa20a4525ce5241570724d91b0c5251","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void registerModuleType(ModuleType type) {\n    for (int i = 0; i < myModuleTypes.size(); i++) {\n      ModuleType oldType = myModuleTypes.get(i);\n      if (oldType.getId().equals(type.getId())) {\n        LOG.error(\"Trying to register a module type that claunches with existing one. Old=\" + oldType + \", new = \" + type);\n        return;\n      }\n    }\n    myModuleTypes.add(type);\n  }","id":37624,"modified_method":"public void registerModuleType(ModuleType type) {\n    for (ModuleType oldType : myModuleTypes) {\n      if (oldType.getId().equals(type.getId())) {\n        LOG.error(\"Trying to register a module type that claunches with existing one. Old=\" + oldType + \", new = \" + type);\n        return;\n      }\n    }\n    myModuleTypes.add(type);\n  }","commit_id":"dedeba38eaa20a4525ce5241570724d91b0c5251","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void updateStep() {\n    if (!myNamePathComponent.isPathChangedByUser()) {\n      final String contentEntryPath = myDescriptor.getContentEntryPath();\n      if (contentEntryPath != null) {\n        @NonNls String path = null;\n        if (myDescriptor instanceof WebModuleBuilder) {\n          final String explodedPath = ((WebModuleBuilder)myDescriptor).explodedDirPath;\n          if (explodedPath != null) {\n            path = explodedPath + \"/WEB-INF/classes\";\n          }\n        }\n        if (path == null) {\n          path = StringUtil.endsWithChar(contentEntryPath, '/') ? contentEntryPath + \"classes\" : contentEntryPath + \"/classes\";\n        }\n        myNamePathComponent.setPath(path.replace('/', File.separatorChar));\n        myNamePathComponent.getPathComponent().selectAll();\n      }\n    }\n  }","id":37625,"modified_method":"public void updateStep() {\n    if (!myNamePathComponent.isPathChangedByUser()) {\n      final String contentEntryPath = myDescriptor.getContentEntryPath();\n      if (contentEntryPath != null) {\n        @NonNls String path = myDescriptor.getPathForOutputPathStep();\n        if (path == null) {\n          path = StringUtil.endsWithChar(contentEntryPath, '/') ? contentEntryPath + \"classes\" : contentEntryPath + \"/classes\";\n        }\n        myNamePathComponent.setPath(path.replace('/', File.separatorChar));\n        myNamePathComponent.getPathComponent().selectAll();\n      }\n    }\n  }","commit_id":"dedeba38eaa20a4525ce5241570724d91b0c5251","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean tryToSaveChanges(boolean validateObjects) {\n        if (log.isDebugEnabled()) log.debug(\"tryToSaveChanges() validateObjects: \"+validateObjects+\"  shouldSaveChanges: \"+shouldSaveChanges());\n        boolean saved = false;\n        try {\n            if (!isListEmpty() && validateObjects && shouldValidateBeforeSave()) {\n                if (log.isDebugEnabled()) log.debug(\"tryToSaveChanges calling validateForSave\");\n                editingContext().insertedObjects().makeObjectsPerformSelector(ValidateForInsertSelector, null);\n                editingContext().updatedObjects().makeObjectsPerformSelector(ValidateForSaveSelector, null);\n            }\n            if (!isListEmpty() && shouldSaveChanges() && editingContext().hasChanges())\n                ERXEOControlUtilities.saveChanges(editingContext());\n            saved = true;\n        } catch (NSValidation.ValidationException ex) {\n            errorMessage = ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSave\", ex);\n            validationFailedWithException(ex, ex.object(), \"saveChangesExceptionKey\");\n        } catch(EOGeneralAdaptorException ex) {\n            if(shouldRecoverFromOptimisticLockingFailure() && ERXEOAccessUtilities.recoverFromAdaptorException(object().editingContext(), ex)) {\n                errorMessage = ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSavePleaseReapply\", d2wContext());\n            } else {\n                throw ex;\n            }\n        }\n\n        return saved;\n    }","id":37626,"modified_method":"public boolean tryToSaveChanges(boolean validateObjects) {\n        if (log.isDebugEnabled()) log.debug(\"tryToSaveChanges() validateObjects: \"+validateObjects+\"  shouldSaveChanges: \"+shouldSaveChanges());\n        boolean saved = false;\n        try {\n            if (!isListEmpty() && validateObjects && shouldValidateBeforeSave()) {\n                if (log.isDebugEnabled()) log.debug(\"tryToSaveChanges calling validateForSave\");\n                editingContext().insertedObjects().makeObjectsPerformSelector(ValidateForInsertSelector, null);\n                editingContext().updatedObjects().makeObjectsPerformSelector(ValidateForSaveSelector, null);\n            }\n            if (!isListEmpty() && shouldSaveChanges() && editingContext().hasChanges())\n                editingContext().saveChanges();\n            saved = true;\n        } catch (NSValidation.ValidationException ex) {\n            setErrorMessage(ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSave\", ex));\n            validationFailedWithException(ex, ex.object(), \"saveChangesExceptionKey\");\n        } catch(EOGeneralAdaptorException ex) {\n            if(shouldRecoverFromOptimisticLockingFailure()) {\n                EOEnterpriseObject eo = ERXEOAccessUtilities.refetchFailedObject(editingContext(), ex);\n                setErrorMessage(ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSavePleaseReapply\", d2wContext()));\n                validationFailedWithException(ex, eo, \"CouldNotSavePleaseReapply\");\n            } else {\n                throw ex;\n            }\n        }\n\n        return saved;\n    }","commit_id":"012cd5a2b722ca4f690547ffe87cbf8a546e4cdb","url":"https://github.com/wocommunity/wonder"},{"original_method":"public boolean tryToSaveChanges(boolean validateObject) { // throws Throwable {\n        validationLog.debug(\"tryToSaveChanges calling validateForSave\");\n        boolean saved = false;\n        EOEditingContext ec = object().editingContext();\n        try {\n            if (object()!=null && validateObject && shouldValidateBeforeSave()) {\n                if (ec.insertedObjects().containsObject(object()))\n                    object().validateForInsert();\n                else\n                    object().validateForUpdate();\n            }\n            if (object()!=null && shouldSaveChanges() && ec.hasChanges()) {\n                ec.saveChanges();\n            }\n            saved = true;\n        } catch (NSValidation.ValidationException ex) {\n            errorMessage = ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSave\", ex);\n            validationFailedWithException(ex, ex.object(), \"saveChangesExceptionKey\");\n        } catch(EOGeneralAdaptorException ex) {\n            if(ERXEOAccessUtilities.isOptimisticLockingFailure(ex) && shouldRecoverFromOptimisticLockingFailure()) {\n                EOEnterpriseObject eo = ERXEOAccessUtilities.refetchFailedObject(ec, ex);\n                errorMessage = ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSavePleaseReapply\", d2wContext());\n                validationFailedWithException(ex, eo, \"CouldNotSavePleaseReapply\");\n            } else {\n                throw ex;\n            }\n        }\n\n        return saved;\n    }","id":37627,"modified_method":"public boolean tryToSaveChanges(boolean validateObject) { // throws Throwable {\n        validationLog.debug(\"tryToSaveChanges calling validateForSave\");\n        boolean saved = false;\n        EOEditingContext ec = object().editingContext();\n        try {\n            if (object()!=null && validateObject && shouldValidateBeforeSave()) {\n                if (ec.insertedObjects().containsObject(object()))\n                    object().validateForInsert();\n                else\n                    object().validateForUpdate();\n            }\n            if (object()!=null && shouldSaveChanges() && ec.hasChanges()) {\n                ec.saveChanges();\n            }\n            saved = true;\n        } catch (NSValidation.ValidationException ex) {\n            setErrorMessage(ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSave\", ex));\n            validationFailedWithException(ex, ex.object(), \"saveChangesExceptionKey\");\n        } catch(EOGeneralAdaptorException ex) {\n            if(ERXEOAccessUtilities.isOptimisticLockingFailure(ex) && shouldRecoverFromOptimisticLockingFailure()) {\n                EOEnterpriseObject eo = ERXEOAccessUtilities.refetchFailedObject(ec, ex);\n                setErrorMessage(ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"CouldNotSavePleaseReapply\", d2wContext()));\n                validationFailedWithException(ex, eo, \"CouldNotSavePleaseReapply\");\n            } else {\n                throw ex;\n            }\n        }\n\n        return saved;\n    }","commit_id":"47bab89e303b4696b4a325a45a195eee25d123fb","url":"https://github.com/wocommunity/wonder"},{"original_method":"public WOComponent submitAction() throws Throwable {\n        WOComponent returnComponent = null;\n        // catch the case where the user hits cancel and then the back button\n        if (object()!=null && object().editingContext()==null) {\n            errorMessage = ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"ERD2WInspect.alreadyAborted\", d2wContext());\n            clearValidationFailed();\n        } else {\n            if (errorMessages.count()==0) {\n                try {\n                    _objectWasSaved=true;\n                    returnComponent = tryToSaveChanges(true) ? nextPage() : null;\n                } finally {\n                    _objectWasSaved=false;\n                }\n            } else {\n                // if we don't do this, we end up with the error message in two places\n                // in errorMessages and errorMessage (super class)\n                errorMessage=null;\n            }\n        }\n        return returnComponent;\n    }","id":37628,"modified_method":"public WOComponent submitAction() throws Throwable {\n        WOComponent returnComponent = null;\n        // catch the case where the user hits cancel and then the back button\n        if (object()!=null && object().editingContext()==null) {\n            setErrorMessage(ERXLocalizer.currentLocalizer().localizedTemplateStringForKeyWithObject(\"ERD2WInspect.alreadyAborted\", d2wContext()));\n            clearValidationFailed();\n        } else {\n            if (errorMessages.count()==0) {\n                try {\n                    _objectWasSaved=true;\n                    returnComponent = tryToSaveChanges(true) ? nextPage() : null;\n                } finally {\n                    _objectWasSaved=false;\n                }\n            } else {\n                // if we don't do this, we end up with the error message in two places\n                // in errorMessages and errorMessage (super class)\n                setErrorMessage(null);\n            }\n        }\n        return returnComponent;\n    }","commit_id":"47bab89e303b4696b4a325a45a195eee25d123fb","url":"https://github.com/wocommunity/wonder"},{"original_method":"/**\n     * Testing passivation over nodes - switching a node on and off. Testing prepassivate annotated bean function.\n     */\n    private void runPassivation(boolean isPassivation) throws Exception {\n        // Loading context from file to get ejb:// remote context\n        setupEJBClientContextSelector(); // setting context from .properties file\n        final StatefulBeanRemote statefulBeanRemote = context.lookupStateful(StatefulBean.class, StatefulBeanRemote.class);\n        log.debug(\"Passivated (\" + (isPassivation ? \"TRUE\" : \"FALSE\") + \") by on start: \" + statefulBeanRemote.getPassivatedBy());\n\n        // Calling on server one\n        int clientNumber = 40;\n        String calledNodeFirst = statefulBeanRemote.setNumber(clientNumber);\n        statefulBeanRemote.setPassivationNode(calledNodeFirst);\n        statefulBeanRemote.incrementNumber(); // 41\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 41\n        // nodeName of nested bean should be the same as the node of parent\n        Assert.assertEquals(\"Nested bean has to be called on the same node as parent one\", calledNodeFirst, statefulBeanRemote.getRemoteNestedBeanNodeName());\n        log.info(\"Called node name first: \" + calledNodeFirst);\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n\n        // A small hack - deleting node (by name) from cluster which this client knows\n        // It means that the next request (ejb call) will be passed to the server #2\n        EJBClientContext.requireCurrent().getClusterContext(CLUSTER_NAME).removeClusterNode(calledNodeFirst);\n        \n        if (isPassivation) {\n            // this was redefined in @PrePassivate method on first server - checking whether second server knows about it\n            Assert.assertEquals(\"Supposing to get passivation node which was set\", calledNodeFirst, statefulBeanRemote.getPassivatedBy());\n            // Nested beans have to be passivated as well\n            Assert.assertTrue(\"Passivation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of deep nested bean was not propagated\", statefulBeanRemote.getDeepNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of deep nested bean was not propagated\",statefulBeanRemote.getDeepNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanActivatedCalled() > 0);\n            statefulBeanRemote.resetNestedBean();\n        } else {\n            Assert.assertNull(\"We suppose that the passivation is not provided.\", statefulBeanRemote.getPassivatedBy());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0,  statefulBeanRemote.getNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getDeepNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getDeepNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getRemoteNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getRemoteNestedBeanActivatedCalled());            \n        }\n        \n        String calledNodeSecond = statefulBeanRemote.incrementNumber(); // 42\n        Assert.assertEquals(\"Nested bean has to be calledn on the same node as parent one\", calledNodeSecond, statefulBeanRemote.getNestedBeanNodeName());\n        statefulBeanRemote.setPassivationNode(calledNodeSecond);\n        log.info(\"Called node name second: \" + calledNodeSecond);\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n\n        // Resetting cluster context to know both cluster nodes\n        setupEJBClientContextSelector();\n        // Waiting for getting cluster context - it could take some time for client to get info from cluster nodes\n        waitForClusterContext();\n\n        // Stopping node #2\n        deployer.undeploy(node2deployment.get(calledNodeSecond));\n        controller.stop(node2container.get(calledNodeSecond));\n\n        // We killed second node and we check the value on first node\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 42\n        // Calling on first server\n        String calledNode = statefulBeanRemote.incrementNumber(); // 43\n        // Checking called node and set number\n        Assert.assertEquals(\"It can't be node \" + calledNodeSecond + \" because is switched off\", calledNodeFirst, calledNode);\n        if (isPassivation) {\n            Assert.assertEquals(\"Supposing to get passivation node which was set\", calledNodeSecond, statefulBeanRemote.getPassivatedBy());\n            Assert.assertTrue(\"Passivation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of deep nested bean was not propagated\", statefulBeanRemote.getDeepNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of deep nested bean was not propagated\",statefulBeanRemote.getDeepNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanActivatedCalled() > 0);\n            statefulBeanRemote.resetNestedBean();\n        } else {\n            Assert.assertNull(\"We suppose that the passivation is not provided.\", statefulBeanRemote.getPassivatedBy());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getDeepNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getDeepNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getRemoteNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getRemoteNestedBeanActivatedCalled());\n        }\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 43\n    }","id":37629,"modified_method":"/**\n     * Testing passivation over nodes - switching a node on and off. Testing prepassivate annotated bean function.\n     */\n    private void runPassivation(boolean isPassivation) throws Exception {\n        // Loading context from file to get ejb:// remote context\n        setupEJBClientContextSelector(); // setting context from .properties file\n        final StatefulBeanRemote statefulBeanRemote = context.lookupStateful(StatefulBean.class, StatefulBeanRemote.class);\n        log.debug(\"Passivated (\" + (isPassivation ? \"TRUE\" : \"FALSE\") + \") by on start: \" + statefulBeanRemote.getPassivatedBy());\n\n        // Calling on server one\n        int clientNumber = 40;\n        String calledNodeFirst = statefulBeanRemote.setNumber(clientNumber);\n        statefulBeanRemote.setPassivationNode(calledNodeFirst);\n        statefulBeanRemote.incrementNumber(); // 41\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 41\n        // nodeName of nested bean should be the same as the node of parent\n        Assert.assertEquals(\"Nested bean has to be called on the same node as parent one\", calledNodeFirst, statefulBeanRemote.getRemoteNestedBeanNodeName());\n        log.info(\"Called node name first: \" + calledNodeFirst);\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n\n        // A small hack - deleting node (by name) from cluster which this client knows\n        // It means that the next request (ejb call) will be passed to the server #2\n        EJBClientContext.requireCurrent().getClusterContext(CLUSTER_NAME).removeClusterNode(calledNodeFirst);\n        \n        if (isPassivation) {\n            // this was redefined in @PrePassivate method on first server - checking whether second server knows about it\n            Assert.assertEquals(\"Supposing to get passivation node which was set\", calledNodeFirst, statefulBeanRemote.getPassivatedBy());\n            // Nested beans have to be passivated as well\n            Assert.assertTrue(\"Passivation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of deep nested bean was not propagated\", statefulBeanRemote.getDeepNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of deep nested bean was not propagated\",statefulBeanRemote.getDeepNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanActivatedCalled() > 0);\n            statefulBeanRemote.resetNestedBean();\n        } else {\n            Assert.assertEquals(\"We suppose that the passivation is not provided\", \"unknown\", statefulBeanRemote.getPassivatedBy());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0,  statefulBeanRemote.getNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getDeepNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getDeepNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getRemoteNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\", 0, statefulBeanRemote.getRemoteNestedBeanActivatedCalled());            \n        }\n        \n        String calledNodeSecond = statefulBeanRemote.incrementNumber(); // 42\n        Assert.assertEquals(\"Nested bean has to be calledn on the same node as parent one\", calledNodeSecond, statefulBeanRemote.getNestedBeanNodeName());\n        statefulBeanRemote.setPassivationNode(calledNodeSecond);\n        log.info(\"Called node name second: \" + calledNodeSecond);\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n\n        // Resetting cluster context to know both cluster nodes\n        setupEJBClientContextSelector();\n        // Waiting for getting cluster context - it could take some time for client to get info from cluster nodes\n        waitForClusterContext();\n\n        // Stopping node #2\n        deployer.undeploy(node2deployment.get(calledNodeSecond));\n        controller.stop(node2container.get(calledNodeSecond));\n\n        // We killed second node and we check the value on first node\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 42\n        // Calling on first server\n        String calledNode = statefulBeanRemote.incrementNumber(); // 43\n        // Checking called node and set number\n        Assert.assertEquals(\"It can't be node \" + calledNodeSecond + \" because is switched off\", calledNodeFirst, calledNode);\n        if (isPassivation) {\n            Assert.assertEquals(\"Supposing to get passivation node which was set\", calledNodeSecond, statefulBeanRemote.getPassivatedBy());\n            Assert.assertTrue(\"Passivation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of nested bean was not propagated\", statefulBeanRemote.getNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of deep nested bean was not propagated\", statefulBeanRemote.getDeepNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of deep nested bean was not propagated\",statefulBeanRemote.getDeepNestedBeanActivatedCalled() > 0);\n            Assert.assertTrue(\"Passivation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanPassivatedCalled() > 0);\n            Assert.assertTrue(\"Activation of remote bean was not propagated\", statefulBeanRemote.getRemoteNestedBeanActivatedCalled() > 0);\n            statefulBeanRemote.resetNestedBean();\n        } else {\n            Assert.assertEquals(\"We suppose that the passivation is not provided.\", \"unknown\", statefulBeanRemote.getPassivatedBy());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getDeepNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getDeepNestedBeanActivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getRemoteNestedBeanPassivatedCalled());\n            Assert.assertEquals(\"No passivation should be done\",0, statefulBeanRemote.getRemoteNestedBeanActivatedCalled());\n        }\n        Thread.sleep(WAIT_FOR_PASSIVATION_MS); // waiting for passivation\n        Assert.assertEquals(++clientNumber, statefulBeanRemote.getNumber()); // 43\n    }","commit_id":"7b81f963fb4b297723077ed6acef608198d4bb38","url":"https://github.com/wildfly/wildfly"},{"original_method":"@PreDestroy\n    protected void preDestroy() throws JMSException {\n\n        this.log.info(\"MDB about to be gone, releasing resources\");\n        this.session.close();\n        this.connection.close();\n        this.lifeCycleCounter.incrementPreDestroyCount();\n    }","id":37630,"modified_method":"@PreDestroy\n    protected void preDestroy() throws JMSException {\n\n        log.info(\"@PreDestroy on \" + this);\n        try {\n            lifeCycleTracker.trackPreDestroyOn(this.getClass().getName());\n        } finally {\n            // closing the connection will close the session too (see javadoc of javax.jms.Connection#close())\n            safeClose(this.connection);\n        }\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@PostConstruct\n    protected void postConstruct() throws JMSException, NamingException {\n        this.log.info(\"MDB created, initializing\");\n        this.connection = this.factory.createConnection();\n        this.session = this.connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\n        this.lifeCycleCounter = (LifecycleCounter) new InitialContext()\n                .lookup(\"java:global/pool-ejb-callbacks-singleton/LifecycleCounterBean!org.jboss.as.test.integration.ejb.pool.lifecycle.LifecycleCounter\");\n        this.lifeCycleCounter.incrementPostCreateCount();\n    }","id":37631,"modified_method":"@PostConstruct\n    protected void postConstruct() throws JMSException, NamingException {\n        lifeCycleTracker.trackPostConstructOn(this.getClass().getName());\n        log.info(this + \" MDB @PostConstructed\");\n\n        this.connection = this.factory.createConnection();\n        this.session = this.connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    public void onMessage(Message message) {\n        try {\n            System.out.println(\"Message \" + message);\n            final Destination destination = message.getJMSReplyTo();\n            // ignore messages that need no reply\n            if (destination == null)\n                return;\n            final MessageProducer replyProducer = session.createProducer(destination);\n            final Message replyMsg = session.createTextMessage(\"replying \" + ((TextMessage) message).getText());\n            replyMsg.setJMSCorrelationID(message.getJMSMessageID());\n            replyProducer.send(replyMsg);\n            replyProducer.close();\n        } catch (JMSException e) {\n            throw new RuntimeException(e);\n        }\n    }","id":37632,"modified_method":"@Override\n    public void onMessage(Message message) {\n        try {\n            log.info(this + \" received message \" + message);\n            final Destination destination = message.getJMSReplyTo();\n            // ignore messages that need no reply\n            if (destination == null) {\n                log.info(this + \" noticed that no reply-to destination has been set. Just returning\");\n                return;\n            }\n            final MessageProducer replyProducer = session.createProducer(destination);\n            final Message replyMsg = session.createTextMessage(Constants.REPLY_MESSAGE_PREFIX + ((TextMessage) message).getText());\n            replyMsg.setJMSCorrelationID(message.getJMSMessageID());\n            replyProducer.send(replyMsg);\n            replyProducer.close();\n        } catch (JMSException e) {\n            throw new RuntimeException(e);\n        }\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Deployment(name = SLSB_DEPLOYMENT_NAME, managed = false, testable = false)\n    public static JavaArchive getSLSBTestArchive() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, SLSB_DEPLOYMENT_NAME);\n        archive.addClass(LifecycleCounterSLSB.class);\n        archive.setManifest(new Asset() {\n            @Override\n            public InputStream openStream() {\n                ManifestBuilder builder = ManifestBuilder.newInstance();\n                StringBuffer dependencies = new StringBuffer();\n                dependencies.append(DEPLOYED_SINGLETON_MODULE);\n                dependencies.append(\" , org.hornetq.ra\");\n                builder.addManifestHeader(\"Dependencies\", dependencies.toString());\n                return builder.openStream();\n            }\n        });\n        log.info(archive.toString(true));\n        return archive;\n    }","id":37633,"modified_method":"@Deployment(name = SLSB_DEPLOYMENT_NAME, managed = false, testable = false)\n    public static JavaArchive getSLSBTestArchive() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, SLSB_DEPLOYMENT_NAME);\n        archive.addClass(PointLessMathBean.class);\n        archive.addClass(LifecycleTracker.class);\n        archive.setManifest(new Asset() {\n            @Override\n            public InputStream openStream() {\n                ManifestBuilder builder = ManifestBuilder.newInstance();\n                StringBuffer dependencies = new StringBuffer();\n                dependencies.append(DEPLOYED_SINGLETON_MODULE);\n                dependencies.append(\" , org.hornetq.ra\");\n                builder.addManifestHeader(\"Dependencies\", dependencies.toString());\n                return builder.openStream();\n            }\n        });\n        log.info(archive.toString(true));\n        return archive;\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@SuppressWarnings(\"static-access\")\n    @Test\n    public void testSLSB() throws Exception {\n        try {\n            log.info(\"-->About to deploy SLSB archive\");\n            deployer.deploy(SLSB_DEPLOYMENT_NAME);\n            log.info(\"-->deployed\");\n            // do checks\n            assertEquals(\"Wrong postCreate calls count\", 0, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count\", 0, cycleCounter.getPreDestroyCount());\n            triggerSLSB();\n            assertEquals(\"Wrong postCreate calls count, after EJB has been triggered\", 1, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count, after EJB has been triggered\", 0, cycleCounter.getPreDestroyCount());\n            log.info(\"-->About to undeploy SLSB archive\");\n            deployer.undeploy(SLSB_DEPLOYMENT_NAME);\n            assertEquals(\"Wrong postCreate calls count, after EJB has been undeployed\", 1, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count, after EJB has been undeployed\", 1, cycleCounter.getPreDestroyCount());\n        } finally {\n            cycleCounter.reset();\n        }\n    }","id":37634,"modified_method":"@SuppressWarnings(\"static-access\")\n    @Test\n    public void testSLSB() throws Exception {\n        boolean requiresUndeploy = false;\n        try {\n            // deploy the SLSB\n            log.info(\"About to deploy SLSB archive \" + SLSB_DEPLOYMENT_NAME);\n            deployer.deploy(SLSB_DEPLOYMENT_NAME);\n            requiresUndeploy = true;\n            log.info(\"deployed \" + SLSB_DEPLOYMENT_NAME);\n\n            // invoke on bean\n            final PointlesMathInterface mathBean = (PointlesMathInterface) new InitialContext().lookup(SLSB_JNDI_NAME);\n            mathBean.pointlesMathOperation(4, 5, 6);\n\n            assertTrue(\"@PostConstruct wasn't invoked on SLSB\", lifecycleTracker.wasPostConstructInvokedOn(this.getClass().getPackage().getName() + \".PointLessMathBean\"));\n\n            log.info(\"About to undeploy SLSB archive \" + SLSB_DEPLOYMENT_NAME);\n            deployer.undeploy(SLSB_DEPLOYMENT_NAME);\n            requiresUndeploy = false;\n\n            assertTrue(\"@PreDestroy wasn't invoked on SLSB\", lifecycleTracker.wasPreDestroyInvokedOn(this.getClass().getPackage().getName() + \".PointLessMathBean\"));\n\n        } finally {\n            if (requiresUndeploy) {\n                try {\n                    deployer.undeploy(SLSB_DEPLOYMENT_NAME);\n                } catch (Throwable t) {\n                    // log and return since we don't want to corrupt any original exceptions that might have caused the test to fail\n                    log.info(\"Ignoring the undeployment failure of \" + SLSB_DEPLOYMENT_NAME, t);\n                }\n            }\n        }\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@SuppressWarnings(\"static-access\")\n    @Test\n    public void testMDB() throws Exception {\n        try {\n            log.info(\"-->About to deploy MDB archive\");\n            deployer.deploy(MDB_DEPLOYMENT_NAME);\n            log.info(\"-->deployed\");\n\n            // // do checks\n            assertEquals(\"Wrong postCreate calls count\", 0, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count\", 0, cycleCounter.getPreDestroyCount());\n            log.info(\"-->Performing JMS call to spawn bean\");\n            triggerMDB();\n            assertEquals(\"Wrong postCreate calls count, after EJB has been triggered\", 1, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count, after EJB has been triggered\", 0, cycleCounter.getPreDestroyCount());\n            // undeploy\n            log.info(\"-->About to undeploy MDB archive\");\n            deployer.undeploy(MDB_DEPLOYMENT_NAME);\n            assertEquals(\"Wrong postCreate calls count, after EJB has been undeployed\", 1, cycleCounter.getPostCreateCount());\n            assertEquals(\"Wrong preDestroy calls count, after EJB has been undeployed\", 1, cycleCounter.getPreDestroyCount());\n        } finally {\n            cycleCounter.reset();\n        }\n    }","id":37635,"modified_method":"@SuppressWarnings(\"static-access\")\n    @Test\n    public void testMDB() throws Exception {\n        boolean requiresUndeploy = false;\n        try {\n            // do the deployment of the MDB\n            log.info(\"About to deploy MDB archive \" + MDB_DEPLOYMENT_NAME);\n            deployer.deploy(MDB_DEPLOYMENT_NAME);\n            // we keep track of this to make sure we undeploy before leaving this method\n            requiresUndeploy = true;\n            log.info(\"deployed \" + MDB_DEPLOYMENT_NAME);\n\n            // now send a messag to the queue on which the MDB is listening\n            log.info(\"Sending a message to the queue on which the MDB \" + \" is listening\");\n            triggerRequestResponseCycleOnQueue();\n\n            assertTrue(\"@PostConstruct wasn't invoked on MDB\", lifecycleTracker.wasPostConstructInvokedOn(this.getClass().getPackage().getName() + \".LifecycleCounterMDB\"));\n\n            // undeploy\n            log.info(\"About to undeploy MDB archive \" + MDB_DEPLOYMENT_NAME);\n            deployer.undeploy(MDB_DEPLOYMENT_NAME);\n            // we have undeployed successfully, there's no need anymore to trigger an undeployment before returning from this method\n            requiresUndeploy = false;\n\n            assertTrue(\"@PreDestroy wasn't invoked on MDB\", lifecycleTracker.wasPreDestroyInvokedOn(this.getClass().getPackage().getName() + \".LifecycleCounterMDB\"));\n        } finally {\n            if (requiresUndeploy) {\n                try {\n                    deployer.undeploy(MDB_DEPLOYMENT_NAME);\n                } catch (Throwable t) {\n                    // log and return since we don't want to corrupt any original exceptions that might have caused the test to fail\n                    log.info(\"Ignoring the undeployment failure of \" + MDB_DEPLOYMENT_NAME, t);\n                }\n            }\n        }\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Deployment(name = MDB_DEPLOYMENT_NAME, managed = false, testable = false)\n    public static JavaArchive getMDBTestArchive() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, MDB_DEPLOYMENT_NAME);\n        archive.addClass(LifecycleCounterMDB.class);\n        archive.setManifest(new Asset() {\n            @Override\n            public InputStream openStream() {\n                ManifestBuilder builder = ManifestBuilder.newInstance();\n                StringBuffer dependencies = new StringBuffer();\n                dependencies.append(DEPLOYED_SINGLETON_MODULE);\n                dependencies.append(\" , org.hornetq.ra\");\n                builder.addManifestHeader(\"Dependencies\", dependencies.toString());\n                return builder.openStream();\n            }\n        });\n\n        log.info(archive.toString(true));\n        return archive;\n    }","id":37636,"modified_method":"@Deployment(name = MDB_DEPLOYMENT_NAME, managed = false, testable = false)\n    public static JavaArchive getMDBTestArchive() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, MDB_DEPLOYMENT_NAME);\n        archive.addClass(LifecycleCounterMDB.class);\n        archive.addClass(LifecycleTracker.class);\n        archive.addClass(Constants.class);\n        archive.setManifest(new Asset() {\n            @Override\n            public InputStream openStream() {\n                ManifestBuilder builder = ManifestBuilder.newInstance();\n                StringBuffer dependencies = new StringBuffer();\n                dependencies.append(DEPLOYED_SINGLETON_MODULE);\n                dependencies.append(\" , org.hornetq.ra\");\n                builder.addManifestHeader(\"Dependencies\", dependencies.toString());\n                return builder.openStream();\n            }\n        });\n\n        log.info(archive.toString(true));\n        return archive;\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Deployment\n    public static JavaArchive createDeployment() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, SINGLETON_JAR);\n        // this includes test case class, since package name is the same.\n        archive.addClass(LifecycleCounter.class);\n        archive.addClass(LifecycleCounterBean.class);\n        archive.addClass(PointlesMathInterface.class);\n        archive.addClass(CreateQueueSetupTask.class);\n        log.info(archive.toString(true));\n        return archive;\n    }","id":37637,"modified_method":"@Deployment\n    public static JavaArchive createDeployment() {\n        final JavaArchive archive = ShrinkWrap.create(JavaArchive.class, SINGLETON_JAR);\n        // this includes test case class, since package name is the same.\n        archive.addClass(LifecycleTracker.class);\n        archive.addClass(LifecycleTrackerBean.class);\n        archive.addClass(TimeoutUtil.class);\n        archive.addClass(PointlesMathInterface.class);\n        archive.addClass(Constants.class);\n        log.info(archive.toString(true));\n        return archive;\n    }","commit_id":"1a5dedecfcd82550c65de6c4f5a6fa65ad6e4381","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void renderBodies (World world) {\r\n\t\trenderer.begin(ShapeType.Line);\r\n\r\n\t\tif (drawBodies || drawAABBs) {\r\n\t\t\tworld.getBodies(bodies);\r\n\t\t\tfor (Iterator<Body> iter = bodies.iterator(); iter.hasNext();) {\r\n\t\t\t\tBody body = iter.next();\r\n\t\t\t\tif (body.isActive() || drawInactiveBodies) renderBody(body);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif (drawJoints) {\r\n\t\t\tworld.getJoints(joints);\r\n\t\t\tfor (Iterator<Joint> iter = joints.iterator(); iter.hasNext();) {\r\n\t\t\t\tJoint joint = iter.next();\r\n\t\t\t\tdrawJoint(joint);\r\n\t\t\t}\r\n\t\t}\r\n\t\trenderer.end();\r\n\t\tif (drawContacts) {\r\n\t\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(3);\r\n\t\t\trenderer.begin(ShapeType.Point);\r\n\t\t\tint len = world.getContactList().size;\r\n\t\t\tfor (int i = 0; i < len; i++)\r\n\t\t\t\tdrawContact(world.getContactList().get(i));\r\n\t\t\trenderer.end();\r\n\t\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(1);\r\n\t\t}\r\n\t}","id":37638,"modified_method":"private void renderBodies (World world) {\r\n\t\trenderer.begin(ShapeType.Line);\r\n\r\n\t\tif (drawBodies || drawAABBs) {\r\n\t\t\tworld.getBodies(bodies);\r\n\t\t\tfor (Iterator<Body> iter = bodies.iterator(); iter.hasNext();) {\r\n\t\t\t\tBody body = iter.next();\r\n\t\t\t\tif (body.isActive() || drawInactiveBodies) renderBody(body);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif (drawJoints) {\r\n\t\t\tworld.getJoints(joints);\r\n\t\t\tfor (Iterator<Joint> iter = joints.iterator(); iter.hasNext();) {\r\n\t\t\t\tJoint joint = iter.next();\r\n\t\t\t\tdrawJoint(joint);\r\n\t\t\t}\r\n\t\t}\r\n\t\trenderer.end();\r\n\t\tif (drawContacts) {\r\n\t\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(3);\r\n\t\t\trenderer.begin(ShapeType.Point);\r\n\t\t\tfor (Contact contact : world.getContactList())\r\n\t\t\t\tdrawContact(contact);\r\n\t\t\trenderer.end();\r\n\t\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(1);\r\n\t\t}\r\n\t}","commit_id":"522daca787e03762e6e05601a104197cacac18cc","url":"https://github.com/libgdx/libgdx"},{"original_method":"private void renderBodies (World world) {\r\n\t\trenderer.begin(ShapeType.Line);\r\n\r\n\t\tif (drawBodies || drawAABBs) {\r\n\t\t\tworld.getBodies(bodies);\r\n\t\t\tfor (Iterator<Body> iter = bodies.iterator(); iter.hasNext();) {\r\n\t\t\t\tBody body = iter.next();\r\n\t\t\t\tif (body.isActive() || drawInactiveBodies) renderBody(body);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif (drawJoints) {\r\n\t\t\tworld.getJoints(joints);\r\n\t\t\tfor (Iterator<Joint> iter = joints.iterator(); iter.hasNext();) {\r\n\t\t\t\tJoint joint = iter.next();\r\n\t\t\t\tdrawJoint(joint);\r\n\t\t\t}\r\n\t\t}\r\n\t\trenderer.end();\r\n\r\n\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(3);\r\n\t\trenderer.begin(ShapeType.Point);\r\n\t\tint len = world.getContactList().size;\r\n\t\tfor (int i = 0; i < len; i++)\r\n\t\t\tdrawContact(world.getContactList().get(i));\r\n\t\trenderer.end();\r\n\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(1);\r\n\t}","id":37639,"modified_method":"private void renderBodies (World world) {\r\n\t\trenderer.begin(ShapeType.Line);\r\n\r\n\t\tif (drawBodies || drawAABBs) {\r\n\t\t\tworld.getBodies(bodies);\r\n\t\t\tfor (Iterator<Body> iter = bodies.iterator(); iter.hasNext();) {\r\n\t\t\t\tBody body = iter.next();\r\n\t\t\t\tif (body.isActive() || drawInactiveBodies) renderBody(body);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tif (drawJoints) {\r\n\t\t\tworld.getJoints(joints);\r\n\t\t\tfor (Iterator<Joint> iter = joints.iterator(); iter.hasNext();) {\r\n\t\t\t\tJoint joint = iter.next();\r\n\t\t\t\tdrawJoint(joint);\r\n\t\t\t}\r\n\t\t}\r\n\t\trenderer.end();\r\n\r\n\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(3);\r\n\t\trenderer.begin(ShapeType.Point);\r\n\t\tfor (Contact contact : world.getContactList())\r\n\t\t\tdrawContact(contact);\r\n\t\trenderer.end();\r\n\t\tif (Gdx.gl10 != null) Gdx.gl10.glPointSize(1);\r\n\t}","commit_id":"0535ee6fb91e5fc8bbcd212be3b9b7c6cc62b869","url":"https://github.com/libgdx/libgdx"},{"original_method":"public void actionPerformed(ActionEvent evt)\n        {\n            JButton button = (JButton) evt.getSource();\n\n            if (button.equals(signinButton))\n            {\n                Iterator regIterator = registrationForms.iterator();\n\n                if (regIterator.hasNext())\n                    setCursor(Cursor.getPredefinedCursor(Cursor.WAIT_CURSOR));\n\n                while(regIterator.hasNext())\n                {\n                    AccountRegistrationPanel regForm\n                        = (AccountRegistrationPanel) regIterator.next();\n\n                    if (regForm.isFilled())\n                    {\n                        regForm.signin();\n                    }\n                }\n\n                InitialAccountRegistrationFrame.this.dispose();\n            }\n            else\n                InitialAccountRegistrationFrame.this.dispose();\n        }","id":37640,"modified_method":"public void actionPerformed(ActionEvent evt)\n        {\n            JButton button = (JButton) evt.getSource();\n\n            if (button.equals(signinButton))\n            {\n                Iterator regIterator = registrationForms.iterator();\n\n                if (regIterator.hasNext())\n                    setCursor(Cursor.getPredefinedCursor(Cursor.WAIT_CURSOR));\n\n                while(regIterator.hasNext())\n                {\n                    AccountRegistrationPanel regForm\n                        = (AccountRegistrationPanel) regIterator.next();\n\n                    if (regForm.isFilled())\n                    {\n                        regForm.signin();\n                    }\n                }\n            }\n\n            InitialAccountRegistrationFrame initialAccountRegistrationFrame =\n                InitialAccountRegistrationFrame.this;\n            initialAccountRegistrationFrame.setVisible(false);\n            initialAccountRegistrationFrame.dispose();\n        }","commit_id":"c48ee0d7c69ab56c0852a7a7c9e9fceeabddf1ea","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates an instance of <tt>NoAccountFoundPage<\/tt>.\n     */\n    public InitialAccountRegistrationFrame()\n    {\n        this.setTitle(Resources.getString(\"signin\"));\n\n        this.mainPanel.setBorder(\n            BorderFactory.createEmptyBorder(20, 20, 20, 20));\n\n        this.getContentPane().add(mainPanel);\n\n        this.mainPanel.add(messageAreaPanel, BorderLayout.NORTH);\n        this.mainPanel.add(mainAccountsPanel, BorderLayout.CENTER);\n        this.mainPanel.add(buttonPanel, BorderLayout.SOUTH);\n\n        this.messageAreaPanel.add(messageArea);\n        this.messageArea.setPreferredSize(new Dimension(350, 20));\n        this.messageArea.setFont(messageArea.getFont().deriveFont(Font.BOLD));\n\n        this.mainAccountsPanel.add(accountsPanel, BorderLayout.CENTER);\n\n        this.mainAccountsPanel.setOpaque(false);\n        this.accountsPanel.setOpaque(false);\n        this.buttonPanel.setOpaque(false);\n        this.messageArea.setOpaque(false);\n        this.messageAreaPanel.setOpaque(false);\n\n        SigninActionListener actionListener = new SigninActionListener();\n\n        this.signinButton.addActionListener(actionListener);\n        this.cancelButton.addActionListener(actionListener);\n\n        this.buttonPanel.add(cancelButton);\n        this.buttonPanel.add(signinButton);\n\n        this.messageArea.setLineWrap(true);\n        this.messageArea.setWrapStyleWord(true);\n        this.messageArea.setEditable(false);\n        this.messageArea.setOpaque(false);\n\n        this.getRootPane().setDefaultButton(signinButton);\n\n        this.initAccountWizards();\n        \n        // Create the default group\n        String groupName = Resources.getApplicationProperty(\"defaultGroupName\");\n        \n        if(groupName != null && groupName.length() > 0)\n        {\n            Iterator iter = SimpleAccountRegistrationActivator.getContactList().\n                getRoot().getSubgroups();\n            while (iter.hasNext()) \n            {\n                MetaContactGroup gr = (MetaContactGroup)iter.next();\n                if(gr.getGroupName().equals(groupName))\n                    return;\n            }\n\n            SimpleAccountRegistrationActivator.getContactList().\n                createMetaContactGroup(\n                    SimpleAccountRegistrationActivator.getContactList().getRoot(), \n                    groupName);\n\n            SimpleAccountRegistrationActivator.getConfigurationService().\n                setProperty(\n                \"net.java.sip.communicator.impl.gui.addcontact.lastContactParent\",\n                groupName\n            );\n        }\n    }","id":37641,"modified_method":"/**\n     * Creates an instance of <tt>NoAccountFoundPage<\/tt>.\n     */\n    public InitialAccountRegistrationFrame()\n    {\n        setDefaultCloseOperation(DISPOSE_ON_CLOSE);\n\n        MainPanel mainPanel = new MainPanel(new BorderLayout(5, 5));\n        JPanel messageAreaPanel = new JPanel(new FlowLayout(FlowLayout.CENTER));\n        JTextArea messageArea =\n            new JTextArea(Resources.getString(\"initialAccountRegistration\"));\n        JPanel buttonPanel = new JPanel(new FlowLayout(FlowLayout.RIGHT));\n        JButton cancelButton = new JButton(Resources.getString(\"cancel\"));\n\n        this.setTitle(Resources.getString(\"signin\"));\n\n        mainPanel.setBorder(BorderFactory.createEmptyBorder(20, 20, 20, 20));\n\n        this.getContentPane().add(mainPanel);\n\n        mainPanel.add(messageAreaPanel, BorderLayout.NORTH);\n        mainPanel.add(mainAccountsPanel, BorderLayout.CENTER);\n        mainPanel.add(buttonPanel, BorderLayout.SOUTH);\n\n        messageAreaPanel.add(messageArea);\n        messageArea.setPreferredSize(new Dimension(350, 20));\n        messageArea.setFont(messageArea.getFont().deriveFont(Font.BOLD));\n\n        mainAccountsPanel.add(accountsPanel, BorderLayout.CENTER);\n\n        mainAccountsPanel.setOpaque(false);\n        accountsPanel.setOpaque(false);\n        buttonPanel.setOpaque(false);\n        messageArea.setOpaque(false);\n        messageAreaPanel.setOpaque(false);\n\n        SigninActionListener actionListener = new SigninActionListener();\n\n        signinButton.addActionListener(actionListener);\n        cancelButton.addActionListener(actionListener);\n\n        buttonPanel.add(cancelButton);\n        buttonPanel.add(signinButton);\n\n        messageArea.setLineWrap(true);\n        messageArea.setWrapStyleWord(true);\n        messageArea.setEditable(false);\n        messageArea.setOpaque(false);\n\n        this.getRootPane().setDefaultButton(signinButton);\n\n        this.initAccountWizards();\n        \n        // Create the default group\n        String groupName = Resources.getApplicationProperty(\"defaultGroupName\");\n        \n        if(groupName != null && groupName.length() > 0)\n        {\n            MetaContactListService contactList =\n                SimpleAccountRegistrationActivator.getContactList();\n            Iterator iter = contactList.getRoot().getSubgroups();\n            while (iter.hasNext())\n            {\n                MetaContactGroup gr = (MetaContactGroup) iter.next();\n                if (groupName.equals(gr.getGroupName()))\n                    return;\n            }\n\n            contactList\n                .createMetaContactGroup(contactList.getRoot(), groupName);\n\n            SimpleAccountRegistrationActivator.getConfigurationService().\n                setProperty(\n                \"net.java.sip.communicator.impl.gui.addcontact.lastContactParent\",\n                groupName\n            );\n        }\n    }","commit_id":"c48ee0d7c69ab56c0852a7a7c9e9fceeabddf1ea","url":"https://github.com/jitsi/jitsi"},{"original_method":"public void start(BundleContext bc) throws Exception\n    {\n        bundleContext = bc;\n\n        if (!hasRegisteredAccounts())\n        {\n            // If no preferred wizard is specified we launch the default wizard.\n            InitialAccountRegistrationFrame accountRegFrame\n                = new InitialAccountRegistrationFrame();\n\n            accountRegFrame.pack();\n            accountRegFrame.setLocation(\n                Toolkit.getDefaultToolkit().getScreenSize().width/2\n                - accountRegFrame.getWidth()/2,\n            Toolkit.getDefaultToolkit().getScreenSize().height/2\n                - accountRegFrame.getHeight()/2\n            );\n\n            accountRegFrame.setVisible(true);\n        }\n        \n        logger.info(\"SIMPLE ACCOUNT REGISTRATION ...[STARTED]\");\n    }","id":37642,"modified_method":"public void start(BundleContext bc) throws Exception\n    {\n        bundleContext = bc;\n\n        if (!hasRegisteredAccounts())\n        {\n            // If no preferred wizard is specified we launch the default wizard.\n            InitialAccountRegistrationFrame accountRegFrame\n                = new InitialAccountRegistrationFrame();\n\n            accountRegFrame.pack();\n\n            Dimension screenSize = Toolkit.getDefaultToolkit().getScreenSize();\n            accountRegFrame.setLocation(screenSize.width / 2\n                - accountRegFrame.getWidth() / 2, screenSize.height / 2\n                - accountRegFrame.getHeight() / 2);\n\n            accountRegFrame.setVisible(true);\n        }\n        \n        logger.info(\"SIMPLE ACCOUNT REGISTRATION ...[STARTED]\");\n    }","commit_id":"c48ee0d7c69ab56c0852a7a7c9e9fceeabddf1ea","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Returns the <tt>MetaContactListService<\/tt> obtained from the bundle\n     * context.\n     * @return the <tt>MetaContactListService<\/tt> obtained from the bundle\n     * context\n     */\n    public static MetaContactListService getContactList() \n    {\n        if (contactListService == null) {\n            ServiceReference serviceReference = bundleContext\n                .getServiceReference(MetaContactListService.class.getName());\n\n            contactListService = (MetaContactListService) bundleContext\n                .getService(serviceReference);\n        }\n\n        return contactListService;\n    }","id":37643,"modified_method":"/**\n     * Returns the <tt>MetaContactListService<\/tt> obtained from the bundle\n     * context.\n     * <p>\n     * <b>Note<\/b>: Because this plug-in is meant to be initially displayed (if\n     * necessary) and not get used afterwards, the method doesn't cache the\n     * return value. Make sure you call it as little as possible if execution\n     * speed is under consideration.\n     * <\/p>\n     * \n     * @return the <tt>MetaContactListService<\/tt> obtained from the bundle\n     *         context\n     */\n    public static MetaContactListService getContactList()\n    {\n        ServiceReference serviceReference =\n            bundleContext.getServiceReference(MetaContactListService.class\n                .getName());\n\n        return (MetaContactListService) bundleContext\n            .getService(serviceReference);\n    }","commit_id":"c48ee0d7c69ab56c0852a7a7c9e9fceeabddf1ea","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**creates the elements for the hierarchy map including duplicated nodes\n       and links between them according to the shortest path*/\n    public void createMap()\n    {\n        //create the duplicates of the nodes and map them to the original nodes\n        //using the node hashtable\n        for (Iterator i = originalNodes.iterator(); i.hasNext();)\n        {\n            LWNode node = (LWNode)i.next();\n            LWNode copy = (LWNode)node.duplicate();\n            addNode(copy);\n            \n            //maps the orginal node to the duplicated one using the nodes' toString method\n            nodeHash.put(node, copy);\n        }\n        \n        //verify a path between nodes and create a link between the nodes\n        for (Iterator i = originalNodes.iterator(); i.hasNext();)\n        {\n            LWNode child = (LWNode)i.next();\n            LWNode parent = (LWNode)parentHash.get(child);\n            \n            //if the node has a parent\n            if (parent != null)\n            {\n              //creates the link using the mapped duplicates of the original nodes\n              LWNode childCopy = (LWNode)nodeHash.get(child);\n              LWNode parentCopy = (LWNode)nodeHash.get(parent);\n              \n              LWLink link = new LWLink(parentCopy, childCopy);\n              addLink(link);\n            }\n        }\n    }","id":37644,"modified_method":"/**creates the elements for the hierarchy map including duplicated nodes\n       and links between them according to the shortest path*/\n    public void createMap()\n    {\n        //verify a path between nodes and create a link between the nodes\n        for (Iterator i = originalNodes.iterator(); i.hasNext();)\n        {\n            LWNode child = (LWNode)i.next();\n            LWNode parent = (LWNode)parentHash.get(child);\n            \n            //if the node has a parent\n            if (parent != null)\n            {\n              //creates the link using the mapped duplicates of the original nodes\n              LWNode childCopy = (LWNode)nodeHash.get(child);\n              LWNode parentCopy = (LWNode)nodeHash.get(parent);\n              \n              LWLink link = new LWLink(parentCopy, childCopy);\n              addLink(link);\n            }\n        }\n    }","commit_id":"8561350b7a14cad1e160d1720511f3f92c332cb6","url":"https://github.com/VUE/VUE"},{"original_method":"/**biggest question is whether this should inherit LWMap or return LWMap as a product of a method*/\n    public void createHierarchy()\n    {    \n        computeShortestPath();\n        createMap();\n        layout(rootNode);\n    }","id":37645,"modified_method":"/**biggest question is whether this should inherit LWMap or return LWMap as a product of a method*/\n    public void createHierarchy()\n    {    \n        computeShortestPath();\n        createMap();\n        \n        originalNodes.clear();\n        layout(rootNode);\n    }","commit_id":"8561350b7a14cad1e160d1720511f3f92c332cb6","url":"https://github.com/VUE/VUE"},{"original_method":"/**Dijkstra's theorem is used here to compute the shortest path between nodes*/\n    public void computeShortestPath()\n    {\n        //a vector used for the Dijkstra's theorem\n        Vector nodesVector = new Vector();\n        \n        //initial set up for the computation for the shortest path\n        nodesVector.add(rootNode);\n        originalNodes.add(rootNode);\n        \n        //stores default values to the distance and parent hashtables\n        distanceHash.put(rootNode, new Integer(0));\n        parentHash.put(rootNode, null);\n        \n        //Dijkstra's theorem (shortest path)\n        while(!nodesVector.isEmpty())\n        {   \n            //removes the first element in the vector as it is a queue\n            LWNode currentNode = (LWNode)nodesVector.remove(0);\n            \n            //retrieves the current shortest distance to get to the given node from the root node\n            int totalDistance = ((Integer)distanceHash.get(currentNode)).intValue();\n\n            //iterates through nodes that are connected to the given node\n            for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n            {   \n                LWLink connectedLink = (LWLink)i.next();\n                LWNode nextNode = null;\n                \n                //calculates the distance to adjacent nodes from the root node passing through the given node\n                //could lose the precision..\n                int length = (int)connectedLink.getLine().getP1().distance(connectedLink.getLine().getP2());\n                totalDistance += length;\n             \n                //gets the component associated with the given link\n                if ((nextNode = (LWNode)connectedLink.getComponent1()) == currentNode)\n                    nextNode = (LWNode)connectedLink.getComponent2();\n                \n                //if it is the first time traversing through this node or if the calculated distance is shorter\n                //than the shortest distance associated with the adjacent node\n                if (!distanceHash.containsKey(nextNode) || \n                   totalDistance < ((Integer)distanceHash.get(nextNode)).intValue())\n                {  \n                    //updates the distance and parent hashtables and adds to the vector\n                    nodesVector.add(nextNode);\n                    distanceHash.put(nextNode, new Integer(totalDistance));\n                    parentHash.put(nextNode, currentNode);                    \n                }\n                \n                //keep track of nodes that are connected \n                if(!originalNodes.contains(nextNode))\n                  originalNodes.add(nextNode);\n            }\n        }\n          \n        //debugging\n        /*\n        for (Enumeration e = parentHash.keys(); e.hasMoreElements();)\n        {\n          Object a = e.nextElement();\n          System.out.println(\"key \" + a);\n          System.out.println(\"value \" + parentHash.get(a) + \"\\n\\n\");\n        }\n         **/\n    }","id":37646,"modified_method":"/**Dijkstra's theorem is used here to compute the shortest path between nodes*/\n    public void computeShortestPath()\n    {\n        //a vector used for the Dijkstra's theorem\n        Vector nodesVector = new Vector();\n        \n        //initial set up for the computation for the shortest path\n        nodesVector.add(rootNode);\n        \n        originalNodes.add(rootNode);\n        LWNode copy = (LWNode)rootNode.duplicate();\n        addNode(copy);\n            \n        //maps the orginal node to the duplicated one using the nodes' toString method\n        nodeHash.put(rootNode, copy);\n        \n        //stores default values to the distance and parent hashtables\n        distanceHash.put(rootNode, new Integer(0));\n        parentHash.put(rootNode, null);\n        \n        //Dijkstra's theorem (shortest path)\n        while(!nodesVector.isEmpty())\n        {   \n            //removes the first element in the vector as it is a queue\n            LWNode currentNode = (LWNode)nodesVector.remove(0);\n            \n            //retrieves the current shortest distance to get to the given node from the root node\n            int totalDistance = ((Integer)distanceHash.get(currentNode)).intValue();\n\n            //iterates through nodes that are connected to the given node\n            for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n            {   \n                LWLink connectedLink = (LWLink)i.next();\n                LWNode nextNode = null;\n                \n                //calculates the distance to adjacent nodes from the root node passing through the given node\n                //could lose the precision..\n                int length = (int)connectedLink.getLine().getP1().distance(connectedLink.getLine().getP2());\n                totalDistance += length;\n             \n                //gets the component associated with the given link\n                if ((nextNode = (LWNode)connectedLink.getComponent1()) == currentNode)\n                    nextNode = (LWNode)connectedLink.getComponent2();\n                \n                //if it is the first time traversing through this node or if the calculated distance is shorter\n                //than the shortest distance associated with the adjacent node\n                if (!distanceHash.containsKey(nextNode) || \n                   totalDistance < ((Integer)distanceHash.get(nextNode)).intValue())\n                {  \n                    //updates the distance and parent hashtables and adds to the vector\n                    nodesVector.add(nextNode);\n                    distanceHash.put(nextNode, new Integer(totalDistance));\n                    parentHash.put(nextNode, currentNode);                    \n                }\n                \n                //keep track of nodes that are connected \n                if(!originalNodes.contains(nextNode))\n                {\n                  originalNodes.add(nextNode);\n                    \n                  //create the duplicates of the nodes and map them to the original nodes\n                  //using the node hashtable\n                  copy = (LWNode)nextNode.duplicate();\n                  addNode(copy);\n            \n                  //maps the orginal node to the duplicated one using the nodes' toString method\n                  nodeHash.put(nextNode, copy);\n                }\n            }\n        }\n          \n        //debugging\n        for (Iterator ii = parentHash.keySet().iterator(); ii.hasNext();)\n        {\n          LWNode a = (LWNode)ii.next();\n          System.out.println(\"key \" + a.toString());\n          \n          if(parentHash.get(a) != null)\n            System.out.println(\"value \" + ((LWNode)parentHash.get(a)).toString() + \"\\n\\n\");\n          \n          else\n            System.out.println(\"value null\" + \"\\n\\n\");\n        }\n    }","commit_id":"8561350b7a14cad1e160d1720511f3f92c332cb6","url":"https://github.com/VUE/VUE"},{"original_method":"/**organizes the nodes in a hierarchical manner*/\n    public void layout(LWNode currentNode)\n    {   \n        LWNode copyNode = (LWNode)nodeHash.get(currentNode);\n        LWNode parentNode = (LWNode)parentHash.get(currentNode);\n            \n        if(parent != null)\n          {\n            //set the location\n            Point2D point = parent.getLocation();\n            double x = point.getX();\n            double y = point.getY();\n            \n            copyNode.setLocation(0, 0);\n          }\n            \n        //if it is the rootnode\n        else\n          {\n            copyNode.setLocation(0, 0);\n          }\n            \n        for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n        {\n            //links to nodes\n            LWLink link = (LWLink)i.next();\n            LWNode nextNode = null;\n            \n            if ((nextNode = (LWNode)link.getComponent1()) == currentNode)\n              nextNode = (LWNode)link.getComponent2();\n            \n            layout(nextNode);\n        }\n    }","id":37647,"modified_method":"/**organizes the nodes in a hierarchical manner*/\n    public void layout(LWNode currentNode)\n    {   \n        System.out.println(\"calling layout() on \" + currentNode.toString());\n        originalNodes.add(currentNode);\n        \n        LWNode copyNode = (LWNode)nodeHash.get(currentNode);\n        LWNode parentNode = (LWNode)parentHash.get(currentNode);\n            \n        if(parentNode != null)\n          {\n            //set the location\n            Point2D point = parentNode.getLocation();\n            float x = (float)point.getX();\n            float y = (float)point.getY();\n            \n            x += 10;\n            y += 30;\n            \n            copyNode.setLocation(x, y);\n          }\n            \n        //if it is the rootnode\n        else\n          {\n            copyNode.setLocation(200f, 0f);\n          }\n            \n        for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n        {\n            //links to nodes\n            LWLink link = (LWLink)i.next();\n            LWNode nextNode = null;\n            \n            if ((nextNode = (LWNode)link.getComponent1()) == currentNode)\n              nextNode = (LWNode)link.getComponent2();\n            \n            if(!originalNodes.contains(nextNode))\n              layout(nextNode);\n        }\n    }","commit_id":"8561350b7a14cad1e160d1720511f3f92c332cb6","url":"https://github.com/VUE/VUE"},{"original_method":"void act(LWSelection selection) {\n    \tact(selection, true);\n    }","id":37648,"modified_method":"void act(LWSelection selection) {\n    \tact(selection, false);\n    }","commit_id":"300559d96a6212ebc610a26a4881635b3511e1b2","url":"https://github.com/VUE/VUE"},{"original_method":"public void act(List<? extends LWComponent> bag) {\n        act(bag, true);\n    }","id":37649,"modified_method":"public void act(List<? extends LWComponent> bag) {\n        act(bag, false);\n    }","commit_id":"300559d96a6212ebc610a26a4881635b3511e1b2","url":"https://github.com/VUE/VUE"},{"original_method":"public void act(LWSelection selection, boolean autoFit) {\n        if (DEBUG.Enabled) Log.debug(this + \"; autoFit=\" + autoFit);\n        try {\n            layout.layout(selection);\n            if (autoFit)\n            \tActions.ZoomFit.act();\n        } catch(Throwable t) {\n            Log.debug(\"LayoutAction.act: \"+t.getMessage());\n             tufts.Util.printStackTrace(t);\n        }\n    }","id":37650,"modified_method":"public void act(LWSelection selection, boolean autoFit) {\n        if (DEBUG.Enabled) Log.debug(this + \"; autoFit=\" + autoFit);\n        try {\n            layout.layout(selection);\n            if (DEBUG.Enabled)Log.debug(\"autoFit: \"+autoFit+\" s.size \"+selection.size()+\" map.size:\"+VUE.getActiveMap().getAllDescendents(LWContainer.ChildKind.PROPER).size());\n            if (autoFit || (selection.size() == VUE.getActiveMap().getAllDescendents(LWContainer.ChildKind.PROPER).size())) {\n            \tActions.ZoomFit.act();\n            }\n        } catch(Throwable t) {\n            Log.debug(\"LayoutAction.act: \"+t.getMessage());\n             tufts.Util.printStackTrace(t);\n        }\n    }","commit_id":"300559d96a6212ebc610a26a4881635b3511e1b2","url":"https://github.com/VUE/VUE"},{"original_method":"/**biggest question is whether this should inherit LWMap or return LWMap as a product of a method*/\n    public void createHierarchy()\n    {    \n        computeShortestPath();\n        createMap();\n        \n        originalNodes.clear();\n        layout(rootNode);\n    }","id":37651,"modified_method":"/**biggest question is whether this should inherit LWMap or return LWMap as a product of a method*/\n    public void createHierarchy()\n    {    \n        computeShortestPath();\n        createMap();\n        \n        originalNodes.clear();\n        layout(rootNode, 0, 0);\n    }","commit_id":"970cbfe699d7cac658ec7b2ef6c5e184dc1f15f5","url":"https://github.com/VUE/VUE"},{"original_method":"/**organizes the nodes in a hierarchical manner*/\n    public void layout(LWNode currentNode)\n    {   \n        System.out.println(\"calling layout() on \" + currentNode.toString());\n        originalNodes.add(currentNode);\n        \n        LWNode copyNode = (LWNode)nodeHash.get(currentNode);\n        LWNode parentNode = (LWNode)parentHash.get(currentNode);\n            \n        if(parentNode != null)\n          {\n            //set the location\n            Point2D point = parentNode.getLocation();\n            float x = (float)point.getX();\n            float y = (float)point.getY();\n            \n            x += 10;\n            y += 30;\n            \n            copyNode.setLocation(x, y);\n          }\n            \n        //if it is the rootnode\n        else\n          {\n            copyNode.setLocation(200f, 0f);\n          }\n            \n        for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n        {\n            //links to nodes\n            LWLink link = (LWLink)i.next();\n            LWNode nextNode = null;\n            \n            if ((nextNode = (LWNode)link.getComponent1()) == currentNode)\n              nextNode = (LWNode)link.getComponent2();\n            \n            if(!originalNodes.contains(nextNode))\n              layout(nextNode);\n        }\n    }","id":37652,"modified_method":"/**organizes the nodes in a hierarchical manner*/\n    public void layout(LWNode currentNode, int number, int total)\n    {   \n        System.out.println(\"calling layout() on \" + currentNode.toString());\n        originalNodes.add(currentNode);\n        \n        LWNode copyNode = (LWNode)nodeHash.get(currentNode);\n        LWNode parentNode = (LWNode)parentHash.get(currentNode);\n            \n        if(parentNode != null)\n          {\n            //set the location\n            Point2D point = parentNode.getLocation();\n            float x = (float)point.getX();\n            float y = (float)point.getY();\n            \n            //location for the node\n            int xIncrement = 50 / total;\n            int xOffSet = number * xIncrement;\n            \n            x = x - 10;\n            \n            y += 60;\n            \n            copyNode.setLocation(x, y);\n          }\n            \n        //if it is the rootnode\n        else\n          {\n            copyNode.setLocation(200f, 0f);\n          }\n            \n        int nextNumber = 0;\n        int nextTotal = currentNode.getLinks().size() - 1; //taking out the parent node\n        \n        for (Iterator i = currentNode.getLinks().iterator(); i.hasNext();)\n        {\n            //links to nodes\n            LWLink link = (LWLink)i.next();\n            LWNode nextNode = null;\n            \n            if ((nextNode = (LWNode)link.getComponent1()) == currentNode)\n              nextNode = (LWNode)link.getComponent2();\n            \n            if(!originalNodes.contains(nextNode))\n            {\n              layout(nextNode, nextNumber, nextTotal);\n              nextNumber++;\n            }\n        }\n    }","commit_id":"970cbfe699d7cac658ec7b2ef6c5e184dc1f15f5","url":"https://github.com/VUE/VUE"},{"original_method":"public void stop() {\n      super.stop();\n      LOG.debug(\"STOPPED\", new Throwable());\n      synchronized(myStoppedNotify) {\n        myStoppedNotify.notifyAll();\n      }\n    }","id":37653,"modified_method":"public void stop() {\n      super.stop();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"STOPPED\", new Throwable());\n      }\n      synchronized(myStoppedNotify) {\n        myStoppedNotify.notifyAll();\n      }\n    }","commit_id":"034f32c3c1891334051f61678e27be4272fde111","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static void layout(@NotNull final TextEditorHighlightingPass pass,\n                             @NotNull final List<TextEditorHighlightingPass> result,\n                             @NotNull final TIntObjectHashMap<TextEditorHighlightingPass> id2Pass) {\n    if (result.contains(pass)) return;\n    for (int id : pass.getCompletionPredecessorIds()) {\n      TextEditorHighlightingPass pred = id2Pass.get(id);\n      layout(pred, result, id2Pass);\n    }\n    for (int id : pass.getStartingPredecessorIds()) {\n      TextEditorHighlightingPass pred = id2Pass.get(id);\n      layout(pred, result, id2Pass);\n    }\n    result.add(pass);\n  }","id":37654,"modified_method":"private static void layout(@NotNull final TextEditorHighlightingPass pass,\n                             @NotNull final List<TextEditorHighlightingPass> result,\n                             @NotNull final TIntObjectHashMap<TextEditorHighlightingPass> id2Pass) {\n    if (result.contains(pass)) return;\n    for (int id : pass.getCompletionPredecessorIds()) {\n      TextEditorHighlightingPass pred = id2Pass.get(id);\n      if (pred != null) {\n        layout(pred, result, id2Pass);\n      }\n    }\n    for (int id : pass.getStartingPredecessorIds()) {\n      TextEditorHighlightingPass pred = id2Pass.get(id);\n      if (pred != null) {\n        layout(pred, result, id2Pass);\n      }\n    }\n    result.add(pass);\n  }","commit_id":"034f32c3c1891334051f61678e27be4272fde111","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static List<TextEditorHighlightingPass> topoSort(final TIntObjectHashMap<TextEditorHighlightingPass> id2Pass) {\n    final Set<TextEditorHighlightingPass> topPasses = new THashSet<TextEditorHighlightingPass>(id2Pass.size());\n    id2Pass.forEachValue(new TObjectProcedure<TextEditorHighlightingPass>() {\n      public boolean execute(TextEditorHighlightingPass object) {\n        topPasses.add(object);\n        return true;\n      }\n    });\n    id2Pass.forEachValue(new TObjectProcedure<TextEditorHighlightingPass>() {\n      public boolean execute(TextEditorHighlightingPass pass) {\n        for (int id : pass.getCompletionPredecessorIds()) {\n          assert id2Pass.get(id) != null : id;\n          topPasses.remove(id2Pass.get(id));\n        }\n        for (int id : pass.getStartingPredecessorIds()) {\n          assert id2Pass.get(id) != null : id;\n          topPasses.remove(id2Pass.get(id));\n        }\n        return true;\n      }\n    });\n    List<TextEditorHighlightingPass> result = new ArrayList<TextEditorHighlightingPass>();\n    for (TextEditorHighlightingPass topPass : topPasses) {\n      layout(topPass, result, id2Pass);\n    }\n    return result;\n  }","id":37655,"modified_method":"private static List<TextEditorHighlightingPass> topoSort(final TIntObjectHashMap<TextEditorHighlightingPass> id2Pass) {\n    final Set<TextEditorHighlightingPass> topPasses = new THashSet<TextEditorHighlightingPass>(id2Pass.size());\n    id2Pass.forEachValue(new TObjectProcedure<TextEditorHighlightingPass>() {\n      public boolean execute(TextEditorHighlightingPass object) {\n        topPasses.add(object);\n        return true;\n      }\n    });\n    id2Pass.forEachValue(new TObjectProcedure<TextEditorHighlightingPass>() {\n      public boolean execute(TextEditorHighlightingPass pass) {\n        for (int id : pass.getCompletionPredecessorIds()) {\n          TextEditorHighlightingPass pred = id2Pass.get(id);\n          if (pred != null) {  //can be null if filtered out by passesToIgnore\n            topPasses.remove(pred);\n          }\n        }\n        for (int id : pass.getStartingPredecessorIds()) {\n          TextEditorHighlightingPass pred = id2Pass.get(id);\n          if (pred != null) {  //can be null if filtered out by passesToIgnore\n            topPasses.remove(pred);\n          }\n        }\n        return true;\n      }\n    });\n    List<TextEditorHighlightingPass> result = new ArrayList<TextEditorHighlightingPass>();\n    for (TextEditorHighlightingPass topPass : topPasses) {\n      layout(topPass, result, id2Pass);\n    }\n    return result;\n  }","commit_id":"034f32c3c1891334051f61678e27be4272fde111","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public boolean deQueue() {\r\n        try {\r\n            // work off fresh entries from the proxy or from the crawler\r\n            if (onlineCaution()) {\r\n                log.logFine(\"deQueue: online caution, omitting resource stack processing\");\r\n                return false;\r\n            }\r\n\r\n            if ((sbQueue.size() == 0) && ((getThread(CRAWLJOB_LOCAL_CRAWL).getJobCount() == 0))) setPerformance((int) Math.max(120, 60000 / getConfigLong(INDEX_DIST_BUSYSLEEP, 6000))); // if there is no activity, set low performance\r\n            \r\n            // flush some entries from the RAM cache\r\n            if (sbQueue.size() == 0) wordIndex.flushCacheSome(); // permanent flushing only if we are not busy\r\n            wordIndex.loadedURL.flushCacheSome();\r\n\r\n            boolean doneSomething = false;\r\n\r\n            // possibly delete entries from last chunk\r\n            if ((this.dhtTransferChunk != null) &&\r\n                    (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_COMPLETE)) {\r\n                String deletedURLs = this.dhtTransferChunk.deleteTransferIndexes();\r\n                this.log.logFine(\"Deleted from \" + this.dhtTransferChunk.containers().length + \" transferred RWIs locally, removed \" + deletedURLs + \" URL references\");\r\n                this.dhtTransferChunk = null;\r\n            }\r\n\r\n            // generate a dht chunk\r\n            if (\r\n                    (dhtShallTransfer() == null) &&\r\n                    (\r\n                            (this.dhtTransferChunk == null) ||\r\n                            (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_UNDEFINED) ||\r\n                            // (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_COMPLETE) ||\r\n                            (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_FAILED)\r\n                    )\r\n            ) {\r\n                // generate new chunk\r\n                int minChunkSize = (int) getConfigLong(INDEX_DIST_CHUNK_SIZE_MIN, 30);\r\n                dhtTransferChunk = new plasmaDHTChunk(this.log, wordIndex, minChunkSize, dhtTransferIndexCount, 5000);\r\n                doneSomething = true;\r\n            }\r\n\r\n            // check for interruption\r\n            checkInterruption();\r\n\r\n            // getting the next entry from the indexing queue\r\n            synchronized (sbQueue) {\r\n\r\n                if (sbQueue.size() == 0) {\r\n                    //log.logFine(\"deQueue: nothing to do, queue is emtpy\");\r\n                    return doneSomething; // nothing to do\r\n                }\r\n\r\n                /*\r\n                if (wordIndex.wordCacheRAMSize() + 1000 > (int) getConfigLong(\"wordCacheMaxLow\", 8000)) {\r\n                    log.logFine(\"deQueue: word index ram cache too full (\" + ((int) getConfigLong(\"wordCacheMaxLow\", 8000) - wordIndex.wordCacheRAMSize()) + \" slots left); dismissed to omit ram flush lock\");\r\n                    return false;\r\n                }\r\n                */\r\n\r\n                int stackCrawlQueueSize;\r\n                if ((stackCrawlQueueSize = sbStackCrawlThread.size()) >= stackCrawlSlots) {\r\n                    log.logFine(\"deQueue: too many processes in stack crawl thread queue, dismissed to protect emergency case (\" + \"stackCrawlQueue=\" + stackCrawlQueueSize + \")\");\r\n                    return doneSomething;\r\n                }\r\n\r\n                plasmaSwitchboardQueue.Entry nextentry;\r\n\r\n                // if we were interrupted we should return now\r\n                if (Thread.currentThread().isInterrupted()) {\r\n                    log.logFine(\"deQueue: thread was interrupted\");\r\n                    return false;\r\n                }\r\n\r\n                // do one processing step\r\n                log.logFine(\"DEQUEUE: sbQueueSize=\" + sbQueue.size() +\r\n                        \", coreStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_CORE) +\r\n                        \", limitStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_LIMIT) +\r\n                        \", overhangStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_OVERHANG) +\r\n                        \", remoteStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_REMOTE));\r\n                try {\r\n                    nextentry = sbQueue.pop();\r\n                    if (nextentry == null) {\r\n                        log.logFine(\"deQueue: null entry on queue stack\");\r\n                        return false;\r\n                    }\r\n                } catch (IOException e) {\r\n                    log.logSevere(\"IOError in plasmaSwitchboard.deQueue: \" + e.getMessage(), e);\r\n                    return doneSomething;\r\n                }\r\n\r\n                synchronized (this.indexingTasksInProcess) {\r\n                    this.indexingTasksInProcess.put(nextentry.urlHash(), nextentry);\r\n                }\r\n\r\n                // parse and index the resource\r\n                processResourceStack(nextentry);\r\n            }\r\n\r\n            // ready & finished\r\n            return true;\r\n        } catch (InterruptedException e) {\r\n            log.logInfo(\"DEQUEUE: Shutdown detected.\");\r\n            return false;\r\n        }\r\n    }","id":37656,"modified_method":"public boolean deQueue() {\r\n        try {\r\n            // work off fresh entries from the proxy or from the crawler\r\n            if (onlineCaution()) {\r\n                log.logFine(\"deQueue: online caution, omitting resource stack processing\");\r\n                return false;\r\n            }\r\n\r\n            if ((sbQueue.size() == 0) && ((getThread(CRAWLJOB_LOCAL_CRAWL).getJobCount() == 0))) {\r\n            \tlong sleep = getConfigLong(INDEX_DIST_BUSYSLEEP, 6000);\r\n            \tsetPerformance((int) Math.max(120, 60000 / (sleep==0?1:sleep))); // if there is no activity, set low performance\r\n            }\r\n            \r\n            // flush some entries from the RAM cache\r\n            if (sbQueue.size() == 0) wordIndex.flushCacheSome(); // permanent flushing only if we are not busy\r\n            wordIndex.loadedURL.flushCacheSome();\r\n\r\n            boolean doneSomething = false;\r\n\r\n            // possibly delete entries from last chunk\r\n            if ((this.dhtTransferChunk != null) &&\r\n                    (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_COMPLETE)) {\r\n                String deletedURLs = this.dhtTransferChunk.deleteTransferIndexes();\r\n                this.log.logFine(\"Deleted from \" + this.dhtTransferChunk.containers().length + \" transferred RWIs locally, removed \" + deletedURLs + \" URL references\");\r\n                this.dhtTransferChunk = null;\r\n            }\r\n\r\n            // generate a dht chunk\r\n            if (\r\n                    (dhtShallTransfer() == null) &&\r\n                    (\r\n                            (this.dhtTransferChunk == null) ||\r\n                            (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_UNDEFINED) ||\r\n                            // (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_COMPLETE) ||\r\n                            (this.dhtTransferChunk.getStatus() == plasmaDHTChunk.chunkStatus_FAILED)\r\n                    )\r\n            ) {\r\n                // generate new chunk\r\n                int minChunkSize = (int) getConfigLong(INDEX_DIST_CHUNK_SIZE_MIN, 30);\r\n                dhtTransferChunk = new plasmaDHTChunk(this.log, wordIndex, minChunkSize, dhtTransferIndexCount, 5000);\r\n                doneSomething = true;\r\n            }\r\n\r\n            // check for interruption\r\n            checkInterruption();\r\n\r\n            // getting the next entry from the indexing queue\r\n            synchronized (sbQueue) {\r\n\r\n                if (sbQueue.size() == 0) {\r\n                    //log.logFine(\"deQueue: nothing to do, queue is emtpy\");\r\n                    return doneSomething; // nothing to do\r\n                }\r\n\r\n                /*\r\n                if (wordIndex.wordCacheRAMSize() + 1000 > (int) getConfigLong(\"wordCacheMaxLow\", 8000)) {\r\n                    log.logFine(\"deQueue: word index ram cache too full (\" + ((int) getConfigLong(\"wordCacheMaxLow\", 8000) - wordIndex.wordCacheRAMSize()) + \" slots left); dismissed to omit ram flush lock\");\r\n                    return false;\r\n                }\r\n                */\r\n\r\n                int stackCrawlQueueSize;\r\n                if ((stackCrawlQueueSize = sbStackCrawlThread.size()) >= stackCrawlSlots) {\r\n                    log.logFine(\"deQueue: too many processes in stack crawl thread queue, dismissed to protect emergency case (\" + \"stackCrawlQueue=\" + stackCrawlQueueSize + \")\");\r\n                    return doneSomething;\r\n                }\r\n\r\n                plasmaSwitchboardQueue.Entry nextentry;\r\n\r\n                // if we were interrupted we should return now\r\n                if (Thread.currentThread().isInterrupted()) {\r\n                    log.logFine(\"deQueue: thread was interrupted\");\r\n                    return false;\r\n                }\r\n\r\n                // do one processing step\r\n                log.logFine(\"DEQUEUE: sbQueueSize=\" + sbQueue.size() +\r\n                        \", coreStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_CORE) +\r\n                        \", limitStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_LIMIT) +\r\n                        \", overhangStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_OVERHANG) +\r\n                        \", remoteStackSize=\" + noticeURL.stackSize(plasmaCrawlNURL.STACK_TYPE_REMOTE));\r\n                try {\r\n                    nextentry = sbQueue.pop();\r\n                    if (nextentry == null) {\r\n                        log.logFine(\"deQueue: null entry on queue stack\");\r\n                        return false;\r\n                    }\r\n                } catch (IOException e) {\r\n                    log.logSevere(\"IOError in plasmaSwitchboard.deQueue: \" + e.getMessage(), e);\r\n                    return doneSomething;\r\n                }\r\n\r\n                synchronized (this.indexingTasksInProcess) {\r\n                    this.indexingTasksInProcess.put(nextentry.urlHash(), nextentry);\r\n                }\r\n\r\n                // parse and index the resource\r\n                processResourceStack(nextentry);\r\n            }\r\n\r\n            // ready & finished\r\n            return true;\r\n        } catch (InterruptedException e) {\r\n            log.logInfo(\"DEQUEUE: Shutdown detected.\");\r\n            return false;\r\n        }\r\n    }","commit_id":"4990909178b15243e2a8f994c9411d6f50391725","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"/**\n     * Checks if crawl queue has elements and new crawl will not exceed thread-limit\n     * @param stackType \n     * @param type\n     * @return\n     */\n    private boolean crawlIsPossible(int stackType, final String type) {\n        if (noticeURL.stackSize(stackType) == 0) {\n            //log.logDebug(\"GlobalCrawl: queue is empty\");\n            return false;\n        }\n        \n        if (sb.webIndex.queuePreStack.size() >= (int) sb.getConfigLong(plasmaSwitchboardConstants.INDEXER_SLOTS, 30)) {\n            if (this.log.isFine()) log.logFine(type + \"Crawl: too many processes in indexing queue, dismissed (\" + \"sbQueueSize=\" + sb.webIndex.queuePreStack.size() + \")\");\n            return false;\n        }\n        if (this.size() >= sb.getConfigLong(plasmaSwitchboardConstants.CRAWLER_THREADS_ACTIVE_MAX, 10)) {\n            // try a cleanup\n            this.cleanup();\n        }\n        // check again\n        if (this.size() >= sb.getConfigLong(plasmaSwitchboardConstants.CRAWLER_THREADS_ACTIVE_MAX, 10)) {\n            if (this.log.isFine()) log.logFine(type + \"Crawl: too many processes in loader queue, dismissed (\" + \"cacheLoader=\" + this.size() + \")\");\n            return false;\n        }\n        \n        if (sb.onlineCaution()) {\n            if (this.log.isFine()) log.logFine(type + \"Crawl: online caution, omitting processing\");\n            return false;\n        }\n        return true;\n    }","id":37657,"modified_method":"/**\r\n     * Checks if crawl queue has elements and new crawl will not exceed thread-limit\r\n     * @param stackType\r\n     * @param type\r\n     * @return\r\n     */\r\n    private boolean crawlIsPossible(int stackType, final String type) {\r\n        int value;\r\n        if (noticeURL.stackSize(stackType) == 0) {\r\n            //log.logDebug(\"GlobalCrawl: queue is empty\");\r\n            return false;\r\n        }\r\n\r\n        value = (int) sb.getConfigLong(plasmaSwitchboardConstants.INDEXER_SLOTS, 30);\r\n        if (sb.webIndex.queuePreStack.size() >= value) {\r\n            if (this.log.isFine()) {\r\n                log.logFine(type + \"Crawl: too many processes in indexing queue, dismissed (\" + \"sbQueueSize=\" + sb.webIndex.queuePreStack.size() + \")\");\r\n            }\r\n            return false;\r\n        }\r\n        value = (int) sb.getConfigLong(plasmaSwitchboardConstants.CRAWLER_THREADS_ACTIVE_MAX, 10);\r\n        if (this.size() >= value) {\r\n            // try a cleanup\r\n            this.cleanup();\r\n        }\r\n        // check again\r\n        if (this.size() >= value) {\r\n            if (this.log.isFine()) {\r\n                log.logFine(type + \"Crawl: too many processes in loader queue, dismissed (\" + \"cacheLoader=\" + this.size() + \")\");\r\n            }\r\n            return false;\r\n        }\r\n\r\n        if (sb.onlineCaution()) {\r\n            if (this.log.isFine()) {\r\n                log.logFine(type + \"Crawl: online caution, omitting processing\");\r\n            }\r\n            return false;\r\n        }\r\n        return true;\r\n    }","commit_id":"fd0976c0a7c44d42f2e1bbb76520e43d2d12b011","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public String stackCrawl(final CrawlEntry entry) {\r\n        // stacks a crawl item. The position can also be remote\r\n        // returns null if successful, a reason string if not successful\r\n        //this.log.logFinest(\"stackCrawl: nexturlString='\" + nexturlString + \"'\");\r\n        \r\n        final long startTime = System.currentTimeMillis();\r\n        String reason = null; // failure reason\r\n\r\n        // check if the protocol is supported\r\n        final String urlProtocol = entry.url().getProtocol();\r\n        if (!nextQueue.isSupportedProtocol(urlProtocol)) {\r\n            reason = \"unsupported protocol\";\r\n            this.log.logSevere(\"Unsupported protocol in URL '\" + entry.url().toString() + \"'. \" + \r\n                               \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;            \r\n        }\r\n\r\n        // check if ip is local ip address\r\n        final String urlRejectReason = urlInAcceptedDomain(entry.url());\r\n        if (urlRejectReason != null) {\r\n            reason = \"denied_(\" + urlRejectReason + \")\";\r\n            if (this.log.isFine()) this.log.logFine(reason + \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;                \r\n        }\r\n        \r\n        // check blacklist\r\n        if (plasmaSwitchboard.urlBlacklist.isListed(Blacklist.BLACKLIST_CRAWLER, entry.url())) {\r\n            reason = \"url in blacklist\";\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is in blacklist. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n        \r\n        final CrawlProfile.entry profile = wordIndex.profilesActiveCrawls.getEntry(entry.profileHandle());\r\n        if (profile == null) {\r\n            final String errorMsg = \"LOST STACKER PROFILE HANDLE '\" + entry.profileHandle() + \"' for URL \" + entry.url();\r\n            log.logWarning(errorMsg);\r\n            return errorMsg;\r\n        }\r\n        \r\n        // filter with must-match\r\n        if ((entry.depth() > 0) && !profile.mustMatchPattern().matcher(entry.url().toString()).matches()) {\r\n            reason = \"url does not match must-match filter\";\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' does not match must-match crawling filter '\" + profile.mustMatchPattern().toString() + \"'. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n\r\n        // filter with must-not-match\r\n        if ((entry.depth() > 0) && profile.mustNotMatchPattern().matcher(entry.url().toString()).matches()) {\r\n            reason = \"url matches must-not-match filter\";\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' does matches do-not-match crawling filter '\" + profile.mustNotMatchPattern().toString() + \"'. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n\r\n        // deny cgi\r\n        if (entry.url().isCGI())  {\r\n            reason = \"cgi url not allowed\";\r\n\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is CGI URL. \" + \r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n        \r\n        // deny post properties\r\n        if (entry.url().isPOST() && !(profile.crawlingQ()))  {\r\n            reason = \"post url not allowed\";\r\n\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is post URL. \" + \r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n        \r\n        final yacyURL referrerURL = (entry.referrerhash() == null) ? null : nextQueue.getURL(entry.referrerhash());\r\n        \r\n        // add domain to profile domain list\r\n        if ((profile.domFilterDepth() != Integer.MAX_VALUE) || (profile.domMaxPages() != Integer.MAX_VALUE)) {\r\n            profile.domInc(entry.url().getHost(), (referrerURL == null) ? null : referrerURL.getHost().toLowerCase(), entry.depth());\r\n        }\r\n\r\n        // deny urls that do not match with the profile domain list\r\n        if (!(profile.grantedDomAppearance(entry.url().getHost()))) {\r\n            reason = \"url does not match domain filter\";\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is not listed in granted domains. \" + \r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n\r\n        // deny urls that exceed allowed number of occurrences\r\n        if (!(profile.grantedDomCount(entry.url().getHost()))) {\r\n            reason = \"domain counter exceeded\";\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' appeared too often, a maximum of \" + profile.domMaxPages() + \" is allowed. \"+ \r\n                             \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n            return reason;\r\n        }\r\n\r\n        // check if the url is double registered\r\n        final String dbocc = nextQueue.urlExists(entry.url().hash());\r\n        if (dbocc != null || wordIndex.metadata().exists(entry.url().hash())) {\r\n            final MetadataRowContainer oldEntry = wordIndex.metadata().load(entry.url().hash(), null, 0);\r\n            final boolean recrawl = (oldEntry != null) && (profile.recrawlIfOlder() > oldEntry.loaddate().getTime());\r\n            // do double-check\r\n            if ((dbocc != null) && (!recrawl)) {\r\n                reason = \"double \" + dbocc;\r\n                if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is double registered in '\" + dbocc + \"'. \" + \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n                return reason;\r\n            }\r\n            if ((oldEntry != null) && (!recrawl)) {\r\n                reason = \"double LURL\";\r\n                if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is double registered in 'LURL'. \" + \"Stack processing time: \" + (System.currentTimeMillis()-startTime) + \"ms\");\r\n                return reason;\r\n            }\r\n    \r\n            // show potential re-crawl\r\n            if (recrawl && oldEntry != null) {\r\n                if (this.log.isFine()) this.log.logFine(\"RE-CRAWL of URL '\" + entry.url().toString() + \"': this url was crawled \" +\r\n                        ((System.currentTimeMillis() - oldEntry.loaddate().getTime()) / 60000 / 60 / 24) + \" days ago.\");\r\n            }\r\n        }\r\n        \r\n        // store information\r\n        final boolean local = entry.initiator().equals(wordIndex.peers().mySeed().hash);\r\n        final boolean proxy = (entry.initiator() == null || entry.initiator().equals(\"------------\")) && profile.handle().equals(wordIndex.defaultProxyProfile.handle());\r\n        final boolean remote = profile.handle().equals(wordIndex.defaultRemoteProfile.handle());\r\n        final boolean global = \r\n            (profile.remoteIndexing()) /* granted */ &&\r\n            (entry.depth() == profile.depth()) /* leaf node */ && \r\n            //(initiatorHash.equals(yacyCore.seedDB.mySeed.hash)) /* not proxy */ &&\r\n            (\r\n                    (wordIndex.peers().mySeed().isSenior()) ||\r\n                    (wordIndex.peers().mySeed().isPrincipal())\r\n            ) /* qualified */;\r\n        \r\n        if (!local && !global && !remote && !proxy) {\r\n            this.log.logSevere(\"URL '\" + entry.url().toString() + \"' cannot be crawled. initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n        } else {\r\n            if (global) {\r\n                // it may be possible that global == true and local == true, so do not check an error case against it\r\n                if (proxy) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: global = true, proxy = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: global = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_LIMIT, entry);\r\n            } else if (local) {\r\n                if (proxy) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: local = true, proxy = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: local = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_CORE, entry);\r\n            } else if (proxy) {\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: proxy = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_CORE, entry);\r\n            } else if (remote) {\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_REMOTE, entry);\r\n            }\r\n        }\r\n        \r\n        return null;\r\n    }","id":37658,"modified_method":"public String stackCrawl(final CrawlEntry entry) {\r\n        // stacks a crawl item. The position can also be remote\r\n        // returns null if successful, a reason string if not successful\r\n        //this.log.logFinest(\"stackCrawl: nexturlString='\" + nexturlString + \"'\");\r\n\r\n        final long startTime = System.currentTimeMillis();\r\n\r\n        // check if the protocol is supported\r\n        final String urlProtocol = entry.url().getProtocol();\r\n        if (!nextQueue.isSupportedProtocol(urlProtocol)) {\r\n            this.log.logSevere(\"Unsupported protocol in URL '\" + entry.url().toString() + \"'. \" +\r\n                               \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"unsupported protocol\";\r\n        }\r\n\r\n        // check if ip is local ip address\r\n        final String urlRejectReason = urlInAcceptedDomain(entry.url());\r\n        if (urlRejectReason != null) {\r\n            if (this.log.isFine()) this.log.logFine(\"denied_(\" + urlRejectReason + \") Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"denied_(\" + urlRejectReason + \")\";\r\n        }\r\n\r\n        // check blacklist\r\n        if (plasmaSwitchboard.urlBlacklist.isListed(Blacklist.BLACKLIST_CRAWLER, entry.url())) {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is in blacklist. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"url in blacklist\";\r\n        }\r\n\r\n        final CrawlProfile.entry profile = wordIndex.profilesActiveCrawls.getEntry(entry.profileHandle());\r\n        if (profile == null) {\r\n            final String errorMsg = \"LOST STACKER PROFILE HANDLE '\" + entry.profileHandle() + \"' for URL \" + entry.url();\r\n            log.logWarning(errorMsg);\r\n            return errorMsg;\r\n        }\r\n\r\n        // filter with must-match\r\n        if ((entry.depth() > 0) && !profile.mustMatchPattern().matcher(entry.url().toString()).matches()) {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' does not match must-match crawling filter '\" + profile.mustMatchPattern().toString() + \"'. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"url does not match must-match filter\";\r\n        }\r\n\r\n        // filter with must-not-match\r\n        if ((entry.depth() > 0) && profile.mustNotMatchPattern().matcher(entry.url().toString()).matches()) {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' does matches do-not-match crawling filter '\" + profile.mustNotMatchPattern().toString() + \"'. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"url matches must-not-match filter\";\r\n        }\r\n\r\n        // deny cgi\r\n        if (entry.url().isCGI())  {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is CGI URL. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"cgi url not allowed\";\r\n        }\r\n\r\n        // deny post properties\r\n        if (entry.url().isPOST() && !(profile.crawlingQ()))  {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is post URL. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"post url not allowed\";\r\n        }\r\n\r\n        final yacyURL referrerURL = (entry.referrerhash() == null) ? null : nextQueue.getURL(entry.referrerhash());\r\n\r\n        // add domain to profile domain list\r\n        if ((profile.domFilterDepth() != Integer.MAX_VALUE) || (profile.domMaxPages() != Integer.MAX_VALUE)) {\r\n            profile.domInc(entry.url().getHost(), (referrerURL == null) ? null : referrerURL.getHost().toLowerCase(), entry.depth());\r\n        }\r\n\r\n        // deny urls that do not match with the profile domain list\r\n        if (!(profile.grantedDomAppearance(entry.url().getHost()))) {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is not listed in granted domains. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"url does not match domain filter\";\r\n        }\r\n\r\n        // deny urls that exceed allowed number of occurrences\r\n        if (!(profile.grantedDomCount(entry.url().getHost()))) {\r\n            if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' appeared too often, a maximum of \" + profile.domMaxPages() + \" is allowed. \" +\r\n                             \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n            return \"domain counter exceeded\";\r\n        }\r\n\r\n        // check if the url is double registered\r\n        final String dbocc = nextQueue.urlExists(entry.url().hash());\r\n        if (dbocc != null || wordIndex.metadata().exists(entry.url().hash())) {\r\n            final MetadataRowContainer oldEntry = wordIndex.metadata().load(entry.url().hash(), null, 0);\r\n            final boolean recrawl = (oldEntry != null) && (profile.recrawlIfOlder() > oldEntry.loaddate().getTime());\r\n            // do double-check\r\n            if ((dbocc != null) && (!recrawl)) {\r\n                if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is double registered in '\" + dbocc + \"'. \" + \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n                return \"double \" + dbocc;\r\n            }\r\n            if ((oldEntry != null) && (!recrawl)) {\r\n                if (this.log.isFine()) this.log.logFine(\"URL '\" + entry.url().toString() + \"' is double registered in 'LURL'. \" + \"Stack processing time: \" + (System.currentTimeMillis() - startTime) + \"ms\");\r\n                return \"double LURL\";\r\n            }\r\n\r\n            // show potential re-crawl\r\n            if (recrawl && oldEntry != null) {\r\n                if (this.log.isFine()) this.log.logFine(\"RE-CRAWL of URL '\" + entry.url().toString() + \"': this url was crawled \" +\r\n                        ((System.currentTimeMillis() - oldEntry.loaddate().getTime()) / 60000 / 60 / 24) + \" days ago.\");\r\n            }\r\n        }\r\n\r\n        // store information\r\n        final boolean local = entry.initiator().equals(wordIndex.peers().mySeed().hash);\r\n        final boolean proxy = (entry.initiator() == null || entry.initiator().equals(\"------------\")) && profile.handle().equals(wordIndex.defaultProxyProfile.handle());\r\n        final boolean remote = profile.handle().equals(wordIndex.defaultRemoteProfile.handle());\r\n        final boolean global =\r\n            (profile.remoteIndexing()) /* granted */ &&\r\n            (entry.depth() == profile.depth()) /* leaf node */ &&\r\n            //(initiatorHash.equals(yacyCore.seedDB.mySeed.hash)) /* not proxy */ &&\r\n            (\r\n                    (wordIndex.peers().mySeed().isSenior()) ||\r\n                    (wordIndex.peers().mySeed().isPrincipal())\r\n            ) /* qualified */;\r\n\r\n        if (!local && !global && !remote && !proxy) {\r\n            this.log.logSevere(\"URL '\" + entry.url().toString() + \"' cannot be crawled. initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n        } else {\r\n            if (global) {\r\n                // it may be possible that global == true and local == true, so do not check an error case against it\r\n                if (proxy) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: global = true, proxy = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: global = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_LIMIT, entry);\r\n            } else if (local) {\r\n                if (proxy) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: local = true, proxy = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: local = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_CORE, entry);\r\n            } else if (proxy) {\r\n                if (remote) this.log.logWarning(\"URL '\" + entry.url().toString() + \"' has conflicting initiator properties: proxy = true, remote = true, initiator = \" + entry.initiator() + \", profile.handle = \" + profile.handle());\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_CORE, entry);\r\n            } else if (remote) {\r\n                nextQueue.noticeURL.push(NoticedURL.STACK_TYPE_REMOTE, entry);\r\n            }\r\n        }\r\n\r\n        return null;\r\n    }","commit_id":"fd0976c0a7c44d42f2e1bbb76520e43d2d12b011","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"/**\r\n     * get the next entry in this crawl queue in such a way that the domain access time delta is maximized\r\n     * and always above the given minimum delay time. An additional delay time is computed using the robots.txt\r\n     * crawl-delay time which is always respected. In case the minimum time cannot ensured, this method pauses\r\n     * the necessary time until the url is released and returned as CrawlEntry object. In case that a profile\r\n     * for the computed Entry does not exist, null is returned\r\n     * @param delay\r\n     * @param profile\r\n     * @return a url in a CrawlEntry object\r\n     * @throws IOException\r\n     */\r\n    public synchronized CrawlEntry pop(boolean delay, CrawlProfile profile) throws IOException {\r\n        // returns a crawl entry from the stack and ensures minimum delta times\r\n        // we have 3 sources to choose from: the ramStack, the domainStacks and the fileStack\r\n        \r\n        String result = null; // the result\r\n        \r\n        // 1st: check ramStack\r\n        if (urlRAMStack.size() > 0) {\r\n            //result = urlRAMStack.remove(0);\r\n            Iterator<String> i = urlRAMStack.iterator();\r\n            String urlhash;\r\n            long waitingtime, min = Long.MAX_VALUE;\r\n            String besthash = null;\r\n            while (i.hasNext()) {\r\n                urlhash = i.next();\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(urlhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // zero waiting is a good one\r\n                    result = urlhash;\r\n                    i.remove();\r\n                    min = Long.MAX_VALUE; // that causes that the if at the end of this loop is not used\r\n                    besthash = null;\r\n                    break;\r\n                }\r\n                if (waitingtime < min) {\r\n                    min = waitingtime;\r\n                    besthash = urlhash;\r\n                }\r\n            }\r\n            if (min <= 500 && besthash != null) {\r\n                // find that entry that was best end remove it\r\n                i = urlRAMStack.iterator();\r\n                while (i.hasNext()) {\r\n                    urlhash = i.next();\r\n                    if (urlhash.equals(besthash)) {\r\n                        // zero waiting is a good one\r\n                        result = urlhash;\r\n                        i.remove();\r\n                        break;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        \r\n        // the next options use the domain stack. If this is not filled enough, they dont work at all\r\n        // so just fill them up with some stuff\r\n        if (result == null) shiftFileToDomStacks(1000);\r\n        \r\n        // 2nd-b: check domainStacks for best match between stack size and retrieval time\r\n        String maxhash = null;\r\n        if ((result == null) && (domainStacks.size() > 0)) synchronized (domainStacks) {\r\n            // we order all domains by the number of entries per domain\r\n            // then we iterate through these domains in descending entry order\r\n            // and take that one, that has a zero waiting time\r\n            final Iterator<Map.Entry<String, LinkedList<String>>> i = domainStacks.entrySet().iterator();\r\n            Map.Entry<String, LinkedList<String>> entry;\r\n            String domhash;\r\n            LinkedList<String> domlist;\r\n            final TreeMap<Integer, String> hitlist = new TreeMap<Integer, String>();\r\n            int count = 0;\r\n            // first collect information about sizes of the domain lists\r\n            while (i.hasNext()) {\r\n                entry = i.next();\r\n                domhash = entry.getKey();\r\n                domlist = entry.getValue();\r\n                hitlist.put(Integer.valueOf(domlist.size() * 100 + count++), domhash);\r\n            }\r\n            \r\n            // now iterate in descending order and fetch that one,\r\n            // that is acceptable by the minimumDelta constraint\r\n            long waitingtime;\r\n            while (hitlist.size() > 0) {\r\n                domhash = hitlist.remove(hitlist.lastKey());\r\n                if (maxhash == null) maxhash = domhash; // remember first entry\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(domhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime < 100) {\r\n                    domlist = domainStacks.get(domhash);\r\n                    result = domlist.removeFirst();\r\n                    if (domlist.size() == 0) domainStacks.remove(domhash);\r\n                    break;\r\n                }\r\n            }\r\n            \r\n        }\r\n        \r\n        // 2nd-a: check domainStacks for latest arrivals\r\n        if ((result == null) && (domainStacks.size() > 0)) synchronized (domainStacks) {\r\n            // we select specific domains that have not been used for a long time\r\n            // Latest arrivals that have not yet been crawled fit also in that scheme\r\n            final Iterator<Map.Entry<String, LinkedList<String>>> i = domainStacks.entrySet().iterator();\r\n            Map.Entry<String, LinkedList<String>> entry;\r\n            String domhash;\r\n            long waitingtime, min = Long.MAX_VALUE;\r\n            String besthash = null;\r\n            LinkedList<String> domlist;\r\n            while (i.hasNext()) {\r\n                entry = i.next();\r\n                domhash = entry.getKey();\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(domhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // zero waiting is a good one\r\n                    domlist = entry.getValue();\r\n                    result = domlist.removeFirst();\r\n                    if (domlist.size() == 0) i.remove();\r\n                    min = Long.MAX_VALUE; // that causes that the if at the end of this loop is not used\r\n                    besthash = null;\r\n                    break;\r\n                }\r\n                if (waitingtime < min) {\r\n                    min = waitingtime;\r\n                    besthash = domhash;\r\n                }\r\n            }\r\n            if (min <= 500 && besthash != null) {\r\n                domlist = domainStacks.get(besthash);\r\n                result = domlist.removeFirst();\r\n                if (domlist.size() == 0) domainStacks.remove(besthash);\r\n            }\r\n        }\r\n        \r\n        // 2nd-c: if we did yet not choose any entry, we simply take that one with the most entries\r\n        if ((result == null) && (maxhash != null)) {\r\n            LinkedList<String> domlist = domainStacks.get(maxhash);\r\n            if (domlist != null) {\r\n                result = domlist.removeFirst();\r\n                if (domlist.size() == 0) domainStacks.remove(maxhash);\r\n            }\r\n        }\r\n        \r\n        // 3rd: take entry from file\r\n        if ((result == null) && (urlFileStack.size() > 0)) {\r\n            final Row.Entry nextentry = (top) ? urlFileStack.top() : urlFileStack.bot();\r\n            if (nextentry == null) {\r\n                // emergency case: this means that something with the stack organization is wrong\r\n                // the file appears to be broken. We kill the file.\r\n                urlFileStack.clear();\r\n                Log.logSevere(\"BALANCER\", \"get() failed to fetch entry from file stack. reset stack file.\");\r\n            } else {\r\n                final String nexthash = new String(nextentry.getColBytes(0));\r\n\r\n                // check if the time after retrieval of last hash from same\r\n                // domain is not shorter than the minimumDelta\r\n                long waitingtime = CrawlEntry.waitingRemainingGuessed(nexthash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // the entry is fine\r\n                    result = new String((top) ? urlFileStack.pop().getColBytes(0) : urlFileStack.pot().getColBytes(0));\r\n                } else {\r\n                    // try other entry\r\n                    result = new String((top) ? urlFileStack.pot().getColBytes(0) : urlFileStack.pop().getColBytes(0));\r\n                }\r\n            }\r\n            top = !top; // alternate top/bottom\r\n        }\r\n        \r\n        // check case where we did not found anything\r\n        if (result == null) {\r\n            Log.logSevere(\"BALANCER\", \"get() was not able to find a valid urlhash - total size = \" + size() + \", fileStack.size() = \" + urlFileStack.size() + \", ramStack.size() = \" + urlRAMStack.size() + \", domainStacks.size() = \" + domainStacks.size());\r\n            return null;\r\n        }\r\n        \r\n        // finally: check minimumDelta and if necessary force a sleep\r\n        final int s = urlFileIndex.size();\r\n        Row.Entry rowEntry = urlFileIndex.remove(result.getBytes());\r\n        if (rowEntry == null) {\r\n            throw new IOException(\"get() found a valid urlhash, but failed to fetch the corresponding url entry - total size = \" + size() + \", fileStack.size() = \" + urlFileStack.size() + \", ramStack.size() = \" + urlRAMStack.size() + \", domainStacks.size() = \" + domainStacks.size());\r\n        }\r\n        assert urlFileIndex.size() + 1 == s : \"urlFileIndex.size() = \" + urlFileIndex.size() + \", s = \" + s + \", result = \" + result;\r\n        final CrawlEntry crawlEntry = new CrawlEntry(rowEntry);\r\n        // at this point we must check if the crawlEntry has relevancy because the crawl profile still exists\r\n        // if not: return null. A calling method must handle the null value and try again\r\n        if (profile != null && !profile.hasEntry(crawlEntry.profileHandle())) return null;\r\n        long sleeptime = crawlEntry.waitingRemaining(minimumLocalDelta, minimumGlobalDelta); // this uses the robots.txt database and may cause a loading of robots.txt from the server\r\n        \r\n        if (delay && sleeptime > 0) {\r\n            // force a busy waiting here\r\n            // in best case, this should never happen if the balancer works propertly\r\n            // this is only to protection against the worst case, where the crawler could\r\n            // behave in a DoS-manner\r\n            Log.logInfo(\"BALANCER\", \"forcing crawl-delay of \" + sleeptime + \" milliseconds for \" + crawlEntry.url().getHost() + ((sleeptime > Math.max(minimumLocalDelta, minimumGlobalDelta)) ? \" (caused by robots.txt)\" : \"\"));\r\n            if (System.currentTimeMillis() - this.lastPrepare > 10000) {\r\n                prepare(100);\r\n                this.lastPrepare = System.currentTimeMillis();\r\n            }\r\n            try {synchronized(this) { this.wait(sleeptime); }} catch (final InterruptedException e) {}\r\n        }\r\n        \r\n        // update statistical data\r\n        crawlEntry.updateAccess();\r\n        \r\n        return crawlEntry;\r\n    }","id":37659,"modified_method":"/**\r\n     * get the next entry in this crawl queue in such a way that the domain access time delta is maximized\r\n     * and always above the given minimum delay time. An additional delay time is computed using the robots.txt\r\n     * crawl-delay time which is always respected. In case the minimum time cannot ensured, this method pauses\r\n     * the necessary time until the url is released and returned as CrawlEntry object. In case that a profile\r\n     * for the computed Entry does not exist, null is returned\r\n     * @param delay\r\n     * @param profile\r\n     * @return a url in a CrawlEntry object\r\n     * @throws IOException\r\n     */\r\n    public synchronized CrawlEntry pop(boolean delay, CrawlProfile profile) throws IOException {\r\n        // returns a crawl entry from the stack and ensures minimum delta times\r\n        // we have 3 sources to choose from: the ramStack, the domainStacks and the fileStack\r\n        \r\n        String result = null; // the result\r\n        \r\n        // 1st: check ramStack\r\n        if (urlRAMStack.size() > 0) {\r\n            //result = urlRAMStack.remove(0);\r\n            Iterator<String> i = urlRAMStack.iterator();\r\n            String urlhash;\r\n            long waitingtime, min = Long.MAX_VALUE;\r\n            String besthash = null;\r\n            while (i.hasNext()) {\r\n                urlhash = i.next();\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(urlhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // zero waiting is a good one\r\n                    result = urlhash;\r\n                    i.remove();\r\n                    min = Long.MAX_VALUE; // that causes that the if at the end of this loop is not used\r\n                    besthash = null;\r\n                    break;\r\n                }\r\n                if (waitingtime < min) {\r\n                    min = waitingtime;\r\n                    besthash = urlhash;\r\n                }\r\n            }\r\n            if (min <= 500 && besthash != null) {\r\n                // find that entry that was best end remove it\r\n                i = urlRAMStack.iterator();\r\n                while (i.hasNext()) {\r\n                    urlhash = i.next();\r\n                    if (urlhash.equals(besthash)) {\r\n                        // zero waiting is a good one\r\n                        result = urlhash;\r\n                        i.remove();\r\n                        break;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        \r\n        // the next options use the domain stack. If this is not filled enough, they dont work at all\r\n        // so just fill them up with some stuff\r\n        if (result == null) shiftFileToDomStacks(1000);\r\n        \r\n        // 2nd-b: check domainStacks for best match between stack size and retrieval time\r\n        String maxhash = null;\r\n        if ((result == null) && (domainStacks.size() > 0)) synchronized (domainStacks) {\r\n            // we order all domains by the number of entries per domain\r\n            // then we iterate through these domains in descending entry order\r\n            // and take that one, that has a zero waiting time\r\n            final Iterator<Map.Entry<String, LinkedList<String>>> i = domainStacks.entrySet().iterator();\r\n            Map.Entry<String, LinkedList<String>> entry;\r\n            String domhash;\r\n            LinkedList<String> domlist;\r\n            final TreeMap<Integer, String> hitlist = new TreeMap<Integer, String>();\r\n            int count = 0;\r\n            // first collect information about sizes of the domain lists\r\n            while (i.hasNext()) {\r\n                entry = i.next();\r\n                domhash = entry.getKey();\r\n                domlist = entry.getValue();\r\n                hitlist.put(Integer.valueOf(domlist.size() * 100 + count++), domhash);\r\n            }\r\n            \r\n            // now iterate in descending order and fetch that one,\r\n            // that is acceptable by the minimumDelta constraint\r\n            long waitingtime;\r\n            while (hitlist.size() > 0) {\r\n                domhash = hitlist.remove(hitlist.lastKey());\r\n                if (maxhash == null) maxhash = domhash; // remember first entry\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(domhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime < 100) {\r\n                    domlist = domainStacks.get(domhash);\r\n                    result = domlist.removeFirst();\r\n                    if (domlist.size() == 0) domainStacks.remove(domhash);\r\n                    break;\r\n                }\r\n            }\r\n            \r\n        }\r\n        \r\n        // 2nd-a: check domainStacks for latest arrivals\r\n        if ((result == null) && (domainStacks.size() > 0)) synchronized (domainStacks) {\r\n            // we select specific domains that have not been used for a long time\r\n            // Latest arrivals that have not yet been crawled fit also in that scheme\r\n            final Iterator<Map.Entry<String, LinkedList<String>>> i = domainStacks.entrySet().iterator();\r\n            Map.Entry<String, LinkedList<String>> entry;\r\n            String domhash;\r\n            long waitingtime, min = Long.MAX_VALUE;\r\n            String besthash = null;\r\n            LinkedList<String> domlist;\r\n            while (i.hasNext()) {\r\n                entry = i.next();\r\n                domhash = entry.getKey();\r\n                waitingtime = CrawlEntry.waitingRemainingGuessed(domhash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // zero waiting is a good one\r\n                    domlist = entry.getValue();\r\n                    result = domlist.removeFirst();\r\n                    if (domlist.size() == 0) i.remove();\r\n                    min = Long.MAX_VALUE; // that causes that the if at the end of this loop is not used\r\n                    besthash = null;\r\n                    break;\r\n                }\r\n                if (waitingtime < min) {\r\n                    min = waitingtime;\r\n                    besthash = domhash;\r\n                }\r\n            }\r\n            if (min <= 500 && besthash != null) {\r\n                domlist = domainStacks.get(besthash);\r\n                result = domlist.removeFirst();\r\n                if (domlist.size() == 0) domainStacks.remove(besthash);\r\n            }\r\n        }\r\n        \r\n        // 2nd-c: if we did yet not choose any entry, we simply take that one with the most entries\r\n        if ((result == null) && (maxhash != null)) {\r\n            LinkedList<String> domlist = domainStacks.get(maxhash);\r\n            if (domlist != null) {\r\n                result = domlist.removeFirst();\r\n                if (domlist.size() == 0) domainStacks.remove(maxhash);\r\n            }\r\n        }\r\n        \r\n        // 3rd: take entry from file\r\n        if ((result == null) && (urlFileStack.size() > 0)) {\r\n            final Row.Entry nextentry = (top) ? urlFileStack.top() : urlFileStack.bot();\r\n            if (nextentry == null) {\r\n                // emergency case: this means that something with the stack organization is wrong\r\n                // the file appears to be broken. We kill the file.\r\n                urlFileStack.clear();\r\n                Log.logSevere(\"BALANCER\", \"get() failed to fetch entry from file stack. reset stack file.\");\r\n            } else {\r\n                final String nexthash = new String(nextentry.getColBytes(0));\r\n\r\n                // check if the time after retrieval of last hash from same\r\n                // domain is not shorter than the minimumDelta\r\n                long waitingtime = CrawlEntry.waitingRemainingGuessed(nexthash, minimumLocalDelta, minimumGlobalDelta);\r\n                if (waitingtime == 0) {\r\n                    // the entry is fine\r\n                    result = new String((top) ? urlFileStack.pop().getColBytes(0) : urlFileStack.pot().getColBytes(0));\r\n                } else {\r\n                    // try other entry\r\n                    result = new String((top) ? urlFileStack.pot().getColBytes(0) : urlFileStack.pop().getColBytes(0));\r\n                }\r\n            }\r\n            top = !top; // alternate top/bottom\r\n        }\r\n        \r\n        // check case where we did not found anything\r\n        if (result == null) {\r\n            Log.logSevere(\"BALANCER\", \"get() was not able to find a valid urlhash - total size = \" + size() + \", fileStack.size() = \" + urlFileStack.size() + \", ramStack.size() = \" + urlRAMStack.size() + \", domainStacks.size() = \" + domainStacks.size());\r\n            return null;\r\n        }\r\n        \r\n        // finally: check minimumDelta and if necessary force a sleep\r\n        final int s = urlFileIndex.size();\r\n        Row.Entry rowEntry = urlFileIndex.remove(result.getBytes());\r\n        if (rowEntry == null) {\r\n            throw new IOException(\"get() found a valid urlhash, but failed to fetch the corresponding url entry - total size = \" + size() + \", fileStack.size() = \" + urlFileStack.size() + \", ramStack.size() = \" + urlRAMStack.size() + \", domainStacks.size() = \" + domainStacks.size());\r\n        }\r\n        assert urlFileIndex.size() + 1 == s : \"urlFileIndex.size() = \" + urlFileIndex.size() + \", s = \" + s + \", result = \" + result;\r\n        final CrawlEntry crawlEntry = new CrawlEntry(rowEntry);\r\n        // at this point we must check if the crawlEntry has relevancy because the crawl profile still exists\r\n        // if not: return null. A calling method must handle the null value and try again\r\n        if (profile != null && !profile.hasEntry(crawlEntry.profileHandle())) return null;\r\n        long sleeptime = crawlEntry.waitingRemaining(minimumLocalDelta, minimumGlobalDelta); // this uses the robots.txt database and may cause a loading of robots.txt from the server\r\n        \r\n        if (delay && sleeptime > 0) {\r\n            // force a busy waiting here\r\n            // in best case, this should never happen if the balancer works propertly\r\n            // this is only to protection against the worst case, where the crawler could\r\n            // behave in a DoS-manner\r\n            Log.logInfo(\"BALANCER\", \"forcing crawl-delay of \" + sleeptime + \" milliseconds for \" + crawlEntry.url().getHost() + ((sleeptime > Math.max(minimumLocalDelta, minimumGlobalDelta)) ? \" (caused by robots.txt)\" : \"\"));\r\n            if (System.currentTimeMillis() - this.lastPrepare > 10000) {\r\n                long t = System.currentTimeMillis();\r\n                prepare(400);\r\n                this.lastPrepare = System.currentTimeMillis();\r\n                sleeptime -= this.lastPrepare - t;\r\n            }\r\n            if (sleeptime > 0) try {synchronized(this) { this.wait(sleeptime); }} catch (final InterruptedException e) {}\r\n        }\r\n        \r\n        // update statistical data\r\n        crawlEntry.updateAccess();\r\n        \r\n        return crawlEntry;\r\n    }","commit_id":"61f9dbf0cc67fedd6d16654bc0e1f40262a64623","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"public static serverObjects respond(final httpRequestHeader header, final serverObjects post, final serverSwitch<?> env) {\r\n        // return variable that accumulates replacements\r\n        final plasmaSwitchboard sb = (plasmaSwitchboard) env;\r\n        final serverObjects prop = new serverObjects();\r\n        if (post == null || !post.containsKey(\"html\"))\r\n            prop.setLocalized(false);\r\n        prop.put(\"rejected\", \"0\");\r\n        sb.updateMySeed();\r\n        final int  cacheSize = sb.webIndex.index().getBufferSize();\r\n        final long cacheMaxSize = sb.getConfigLong(plasmaSwitchboardConstants.WORDCACHE_MAX_COUNT, 10000);\r\n        prop.putNum(\"ppm\", sb.currentPPM());\r\n        prop.putNum(\"qpm\", sb.webIndex.peers().mySeed().getQPM());\r\n        prop.putNum(\"wordCacheSize\", sb.webIndex.index().getBufferSize());\r\n        prop.putNum(\"wordCacheSize\", cacheSize);\r\n        prop.putNum(\"wordCacheMaxSize\", cacheMaxSize);\r\n        prop.put(\"wordCacheCount\", cacheSize);\r\n        prop.put(\"wordCacheMaxCount\", cacheMaxSize);\r\n\r\n\t\t//\r\n\t\t// memory usage and system attributes\r\n        prop.putNum(\"freeMemory\", MemoryControl.free());\r\n        prop.putNum(\"totalMemory\", MemoryControl.total());\r\n        prop.putNum(\"maxMemory\", MemoryControl.max());\r\n        prop.putNum(\"processors\", serverProcessor.availableCPU);\r\n\r\n\t\t// proxy traffic\r\n\t\tprop.put(\"trafficIn\", httpdByteCountInputStream.getGlobalCount());\r\n\t\tprop.put(\"trafficProxy\", httpdByteCountOutputStream.getAccountCount(\"PROXY\"));\r\n\t\tprop.put(\"trafficCrawler\", httpdByteCountInputStream.getAccountCount(\"CRAWLER\"));\r\n\r\n        // return rewrite properties\r\n        return prop;\r\n    }","id":37660,"modified_method":"public static serverObjects respond(final httpRequestHeader header, final serverObjects post, final serverSwitch<?> env) {\r\n        // return variable that accumulates replacements\r\n        final plasmaSwitchboard sb = (plasmaSwitchboard) env;\r\n        final serverObjects prop = new serverObjects();\r\n        if (post == null || !post.containsKey(\"html\"))\r\n            prop.setLocalized(false);\r\n        prop.put(\"rejected\", \"0\");\r\n        sb.updateMySeed();\r\n        final int cacheMaxSize = (int) sb.getConfigLong(plasmaSwitchboardConstants.WORDCACHE_MAX_COUNT, 10000);\r\n        prop.putNum(\"ppm\", sb.currentPPM());\r\n        prop.putNum(\"qpm\", sb.webIndex.peers().mySeed().getQPM());\r\n        prop.put(\"wordCacheSize\", Integer.toString(sb.webIndex.index().getBufferSize()));\r\n        prop.put(\"wordCacheMaxSize\", Integer.toString(cacheMaxSize));\r\n\t\t//\r\n\t\t// memory usage and system attributes\r\n        prop.putNum(\"freeMemory\", MemoryControl.free());\r\n        prop.putNum(\"totalMemory\", MemoryControl.total());\r\n        prop.putNum(\"maxMemory\", MemoryControl.max());\r\n        prop.putNum(\"processors\", serverProcessor.availableCPU);\r\n\r\n\t\t// proxy traffic\r\n\t\tprop.put(\"trafficIn\", httpdByteCountInputStream.getGlobalCount());\r\n\t\tprop.put(\"trafficProxy\", httpdByteCountOutputStream.getAccountCount(\"PROXY\"));\r\n\t\tprop.put(\"trafficCrawler\", httpdByteCountInputStream.getAccountCount(\"CRAWLER\"));\r\n\r\n        // return rewrite properties\r\n        return prop;\r\n    }","commit_id":"61f9dbf0cc67fedd6d16654bc0e1f40262a64623","url":"https://github.com/yacy/yacy_search_server"},{"original_method":"private static String getNormalizedPath(MavenProject mavenProject) {\n    return FileUtil.toSystemIndependentName(mavenProject.getFile().getAbsolutePath());\n  }","id":37661,"modified_method":"private static String getNormalizedPath(MavenProject mavenProject) {\n    return new Path(mavenProject.getFile().getPath()).getPath();\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void useModuleOutput(String production, String test) {\n    modifiableRootModel.inheritCompilerOutputPath(false);\n    modifiableRootModel.setCompilerOutputPath(toUrl(production));\n    modifiableRootModel.setCompilerOutputPathForTests(toUrl(test));\n  }","id":37662,"modified_method":"public void useModuleOutput(String production, String test) {\n    modifiableRootModel.inheritCompilerOutputPath(false);\n    modifiableRootModel.setCompilerOutputPath(toUrl(production).getUrl());\n    modifiableRootModel.setCompilerOutputPathForTests(toUrl(test).getUrl());\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private String toUrl(String path) {\n    path = PathUtil.getCanonicalPath(path);\n    path = FileUtil.toSystemIndependentName(path);\n    return VfsUtil.pathToUrl(path);\n  }","id":37663,"modified_method":"private Url toUrl(String path) {\n    return new Path(path).toUrl();\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void addSourceDir(String path, boolean testSource) {\n    String url = toUrl(path);\n    findOrCreateContentRoot(url).addSourceFolder(url, testSource);\n  }","id":37664,"modified_method":"public void addSourceDir(String path, boolean testSource) {\n    Url url = toUrl(path);\n    findOrCreateContentRoot(url).addSourceFolder(url.getUrl(), testSource);\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"ContentEntry findOrCreateContentRoot(String url) {\n    try {\n      for (ContentEntry e : modifiableRootModel.getContentEntries()) {\n        if (FileUtil.isAncestor(new File(e.getUrl()), new File(url), false)) return e;\n      }\n      return modifiableRootModel.addContentEntry(url);\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }","id":37665,"modified_method":"ContentEntry findOrCreateContentRoot(Url url) {\n    try {\n      for (ContentEntry e : modifiableRootModel.getContentEntries()) {\n        if (FileUtil.isAncestor(new File(e.getUrl()), new File(url.getUrl()), false)) return e;\n      }\n      return modifiableRootModel.addContentEntry(url.getUrl());\n    }\n    catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void excludeRoot(String path) {\n    String url = toUrl(path);\n    findOrCreateContentRoot(url).addExcludeFolder(url);\n  }","id":37666,"modified_method":"public void excludeRoot(String path) {\n    Url url = toUrl(path);\n    findOrCreateContentRoot(url).addExcludeFolder(url.getUrl());\n  }","commit_id":"c76ae6022182f813b2d8aa05032acdb214684b7b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void buildFilePaths(final Collection<FilePath> filePaths, final ChangesBrowserNode baseNode) {\n    final ChangesGroupingPolicy policy = createGroupingPolicy();\n    for (FilePath file : filePaths) {\n      assert file != null;\n      // whether a folder does not matter\n      final StaticFilePath pathKey = new StaticFilePath(false, file.getIOFile().getAbsolutePath(), file.getVirtualFile());\n      ChangesBrowserNode oldNode = myFoldersCache.get(pathKey.getKey());\n      if (oldNode == null) {\n        final ChangesBrowserNode node = ChangesBrowserNode.create(myProject, file);\n        final ChangesBrowserNode parentNode = getParentNodeFor(pathKey, policy, baseNode);\n        model.insertNodeInto(node, parentNode, 0);\n        // we could also ask whether a file or directory, though for deleted files not a good idea\n        myFoldersCache.put(pathKey.getKey(), node);\n      }\n    }\n  }","id":37667,"modified_method":"private void buildFilePaths(final Collection<FilePath> filePaths, final ChangesBrowserNode baseNode) {\n    final ChangesGroupingPolicy policy = createGroupingPolicy();\n    for (FilePath file : filePaths) {\n      assert file != null;\n      // whether a folder does not matter\n      final StaticFilePath pathKey = new StaticFilePath(false, new File(file.getIOFile().getPath().replace('\\\\', '/')).getAbsolutePath(), file.getVirtualFile());\n      ChangesBrowserNode oldNode = myFoldersCache.get(pathKey.getKey());\n      if (oldNode == null) {\n        final ChangesBrowserNode node = ChangesBrowserNode.create(myProject, file);\n        final ChangesBrowserNode parentNode = getParentNodeFor(pathKey, policy, baseNode);\n        model.insertNodeInto(node, parentNode, 0);\n        // we could also ask whether a file or directory, though for deleted files not a good idea\n        myFoldersCache.put(pathKey.getKey(), node);\n      }\n    }\n  }","commit_id":"b3265887952e1d7ebaf68a749ae75f1a395e444b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private static StaticFilePath staticFrom(final FilePath fp) {\n    return new StaticFilePath(fp.isDirectory(), fp.getIOFile().getAbsolutePath(), fp.getVirtualFile());\n  }","id":37668,"modified_method":"private static StaticFilePath staticFrom(final FilePath fp) {\n    return new StaticFilePath(fp.isDirectory(), new File(fp.getIOFile().getPath().replace('\\\\', '/')).getAbsolutePath(), fp.getVirtualFile());\n  }","commit_id":"b3265887952e1d7ebaf68a749ae75f1a395e444b","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Override\n  public void applyPresentation(@Nullable Icon icon, @NotNull XValuePresentation valuePresentation, boolean hasChildren) {\n    // extra check for obsolete nodes - tree root was changed\n    // too dangerous to put this into isObsolete - it is called from anywhere, not only EDT\n    if (isObsolete() || !TreeUtil.isAncestor(getTree().getRoot(), this)) return;\n\n    setIcon(icon);\n    myValuePresentation = valuePresentation;\n    myRawValue = XValuePresentationUtil.computeValueText(valuePresentation);\n    if (Registry.is(\"ide.debugger.inline\")) {\n      updateInlineDebuggerData();\n    }\n    updateText();\n    setLeaf(!hasChildren);\n    fireNodeChanged();\n    myTree.nodeLoaded(this, myName);\n  }","id":37669,"modified_method":"@Override\n  public void applyPresentation(@Nullable Icon icon, @NotNull XValuePresentation valuePresentation, boolean hasChildren) {\n    // extra check for obsolete nodes - tree root was changed\n    // too dangerous to put this into isObsolete - it is called from anywhere, not only EDT\n    if (isObsolete()) return;\n    XDebuggerTreeNode root = getTree().getRoot();\n    if (root != null && !TreeUtil.isAncestor(root, this)) return;\n\n    setIcon(icon);\n    myValuePresentation = valuePresentation;\n    myRawValue = XValuePresentationUtil.computeValueText(valuePresentation);\n    if (Registry.is(\"ide.debugger.inline\")) {\n      updateInlineDebuggerData();\n    }\n    updateText();\n    setLeaf(!hasChildren);\n    fireNodeChanged();\n    myTree.nodeLoaded(this, myName);\n  }","commit_id":"099396258021904af46cebcbc51025d148604c50","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"/**\n     * Calculates a translated document's hash.\n     *\n     * @param projectSlug\n     *            Project identifier\n     * @param iterationSlug\n     *            Iteration identifier\n     * @param docId\n     *            Document identifier\n     * @param locale\n     *            Translated document's locale.\n     * @return A Hash string (checksum) for a translated document.\n     */\n    public String\n            getTranslatedDocumentStateHash(final String projectSlug,\n                    final String iterationSlug, final String docId,\n                    final HLocale locale) {\n        // NB: This method uses a native SQL query tested on mysql and h2\n        // databases.\n        Session session = getSession();\n        StringBuilder nativeSql = new StringBuilder();\n        nativeSql.append(\"select MD5(group_concat(hashState)) from \");\n        nativeSql.append(\"( \");\n        nativeSql.append(\"   select \");\n        nativeSql.append(\"   concat( \");\n        nativeSql.append(\"   d.id, '|',  \");\n        nativeSql.append(\"   d.versionNum, '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(poth.versionNum separator '|'), ''), '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(tft.id separator '|'), ''), '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(tft.versionNum separator '|'), ''),  '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(tf.id separator '|'), ''),  '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(tf.revision separator '|'), ''),  '|',  \");\n        nativeSql\n                .append(\"   ifnull(group_concat(c.comment separator '|'), '')) as hashState  \");\n        nativeSql.append(\"   from  \");\n        nativeSql.append(\"   HDocument d \");\n        nativeSql\n                .append(\"   inner join HTextFlow tf on tf.document_id = d.id \");\n        nativeSql\n                .append(\"   inner join HProjectIteration i on d.project_iteration_id = i.id \");\n        nativeSql.append(\"   inner join HProject p on i.project_id = p.id \");\n        nativeSql\n                .append(\"   left outer join HTextFlowTarget tft on tft.tf_id = tf.id and tft.locale = :localeId \");\n        nativeSql\n                .append(\"   left outer join HSimpleComment c on c.id = tft.comment_id  \");\n        nativeSql\n                .append(\"   left outer join HPoTargetHeader poth on poth.document_id = d.id and poth.targetLanguage = :localeId \");\n        nativeSql.append(\"   where  \");\n        nativeSql.append(\"   d.docId = :docId \");\n        nativeSql.append(\"   and p.slug = :projectSlug \");\n        nativeSql.append(\"   and i.slug = :iterationSlug \");\n        nativeSql.append(\"   group by d.id, d.versionNum \");\n        nativeSql.append(\")  as T\");\n\n        Query query =\n                session.createSQLQuery(nativeSql.toString())\n                        .setParameter(\"localeId\", locale.getId())\n                        .setParameter(\"docId\", docId)\n                        .setParameter(\"projectSlug\", projectSlug)\n                        .setParameter(\"iterationSlug\", iterationSlug);\n        // Transform the results from byte[] into Strings when necessary\n        query.setResultTransformer(new ResultTransformer() {\n            @Override\n            public Object transformTuple(Object[] tuple, String[] aliases) {\n                if (tuple[0] instanceof byte[]) {\n                    return new String((byte[]) tuple[0]);\n                }\n                return tuple[0];\n            }\n\n            @Override\n            public List transformList(List collection) {\n                return collection; // no transformation needed\n            }\n        });\n        String stateHash = (String) query.uniqueResult();\n        return stateHash;\n    }","id":37670,"modified_method":"/**\n     * Calculates a translated document's hash.\n     *\n     * @param projectSlug\n     *            Project identifier\n     * @param iterationSlug\n     *            Iteration identifier\n     * @param docId\n     *            Document identifier\n     * @param locale\n     *            Translated document's locale.\n     * @return A Hash string (checksum) for a translated document.\n     */\n    public String\n            getTranslatedDocumentStateHash(final String projectSlug,\n                    final String iterationSlug, final String docId,\n                    final HLocale locale) {\n        HDocument doc =\n                getByProjectIterationAndDocId(projectSlug,\n                        iterationSlug, docId);\n        if (doc == null) {\n            return \"\";\n        }\n        // NB: This method uses a native SQL query tested on mysql and h2\n        // databases.\n        String sql =\n                \"select greatest(\\n\" +\n                \"  d.lastChanged,\\n\" +\n                \"  max(ifnull(tft.lastChanged, {d '1753-01-01'})),\\n\" +\n                \"  max(ifnull(c.lastChanged, {d '1753-01-01'})),\\n\" +\n                \"  max(ifnull(poth.lastChanged, {d '1753-01-01'}))\\n\" +\n                \")\\n\" +\n                \"from HDocument d\\n\" +\n                \"  left outer join HTextFlow tf\\n\" +\n                \"    on d.id = tf.document_id\\n\" +\n                \"  left outer join HTextFlowTarget tft\\n\" +\n                \"    on tft.tf_id = tf.id and tft.locale = :locale\\n\" +\n                \"  left outer join HSimpleComment c\\n\" +\n                \"    on c.id = tft.comment_id\\n\" +\n                \"  left outer join HPoTargetHeader poth\\n\" +\n                \"    on poth.document_id = d.id\\n\" +\n                \"    and poth.targetLanguage = :locale\\n\" +\n                \"where d.id = :doc\\n\" +\n                \"group by d.lastChanged\";\n\n        Query query =\n                getSession().createSQLQuery(sql)\n                        .setParameter(\"locale\", locale)\n                        .setParameter(\"doc\", doc);\n        Timestamp timestamp = (Timestamp) query.uniqueResult();\n        return timestamp.toString();\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n    public void tftCommentChangesHash() throws Exception {\n        String docHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, as);\n\n        // Translate something in the document\n        HDocument doc =\n                documentDAO.getByProjectIterationAndDocId(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID);\n        HTextFlow tf = doc.getTextFlows().get(0);\n        HTextFlowTarget tft = tf.getTargets().get(new Long(1)); // 'as' target\n        tft.setComment(new HSimpleComment(\"This is a new comment\"));\n\n        // force a flush on the DB\n        getSession().flush();\n\n        // Hash must change\n        String changedDocHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, bn);\n\n        assertThat(\n                \"Translated document hash must change when translation is changed\",\n                changedDocHash, not(equalTo(docHash)));\n    }","id":37671,"modified_method":"@Test\n    public void tftNewCommentChangesHash() throws Exception {\n        testHashChange(new Function<HDocument, Void>() {\n            @Override\n            @Nullable\n            public Void apply(@Nullable HDocument doc) {\n                HTextFlow tf = doc.getTextFlows().get(0);\n                HTextFlowTarget tft = tf.getTargets().get(as.getId());\n                tft.setComment(new HSimpleComment(\"This is a new comment\"));\n                return null;\n            }\n        }, true);\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n    public void translationChangesHash() throws Exception {\n        String docHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, as);\n        String bnDocHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, bn);\n\n        // Translate something in the document\n        HDocument doc =\n                documentDAO.getByProjectIterationAndDocId(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID);\n        HTextFlow tf = doc.getTextFlows().get(0);\n        HTextFlowTarget tft = tf.getTargets().get(new Long(1)); // 'as' target\n        tft.setContent0(\"new Translation for as\");\n\n        // force a flush on the DB\n        getSession().flush();\n\n        // Hash must change\n        String changedDocHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, bn);\n\n        assertThat(\n                \"Translated document hash must change when translation is changed\",\n                changedDocHash, not(equalTo(docHash)));\n\n        // Make sure other language's state hash did not change\n        String changedBnDocHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, bn);\n\n        assertThat(\n                \"Translated document hash must not change when translation for other language is changed\",\n                changedBnDocHash, equalTo(bnDocHash));\n    }","id":37672,"modified_method":"@Test\n    public void translationChangesHash() throws Exception {\n        testHashChange(new Function<HDocument, Void>() {\n            @Override\n            @Nullable\n            public Void apply(@Nullable HDocument doc) {\n                HTextFlow tf = doc.getTextFlows().get(0);\n                HTextFlowTarget tft = tf.getTargets().get(as.getId());\n                tft.setContent0(\"new Translation for as\");\n                return null;\n            }\n        }, true);\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n    public void simpleDocumentUpdateChangesHash() throws Exception {\n        String docHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, as);\n\n        // Change the document's name\n        HDocument doc =\n                documentDAO.getByProjectIterationAndDocId(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID);\n        doc.setName(\"newdocname.txt\");\n\n        documentDAO.makePersistent(doc);\n        documentDAO.flush();\n\n        // Hash must change\n        String changedDocHash =\n                documentDAO.getTranslatedDocumentStateHash(PROJECT_SLUG,\n                        ITERATION_SLUG, DOC_ID, as);\n\n        assertThat(\n                \"Translated document hash must change when document is changed\",\n                changedDocHash, not(equalTo(docHash)));\n    }","id":37673,"modified_method":"@Test\n    public void simpleDocumentUpdateChangesHash() throws Exception {\n        testHashChange(new Function<HDocument, Void>() {\n            @Override\n            @Nullable\n            public Void apply(@Nullable HDocument doc) {\n                doc.setName(\"newdocname.txt\");\n                return null;\n            }\n        }, true);\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@BeforeMethod(firstTimeOnly = true)\n    public void setup() {\n        documentDAO = new DocumentDAO(getSession());\n        localeDAO = new LocaleDAO(getSession());\n        as = localeDAO.findByLocaleId(new LocaleId(\"as\"));\n        bn = localeDAO.findByLocaleId(new LocaleId(\"bn\"));\n    }","id":37674,"modified_method":"@BeforeMethod(firstTimeOnly = true)\n    public void setup() {\n        documentDAO = new DocumentDAO(getSession());\n        localeDAO = new LocaleDAO(getSession());\n        as = localeDAO.findByLocaleId(new LocaleId(\"as\"));\n        de = localeDAO.findByLocaleId(new LocaleId(\"de\"));\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Override\n    @Restrict(\"#{s:hasPermission(translatedDocResourceService.securedIteration.project, 'modify-translation')}\")\n    public\n            Response deleteTranslations(String idNoSlash, LocaleId locale) {\n        String id = URIHelper.convertFromDocumentURIId(idNoSlash);\n        HProjectIteration hProjectIteration =\n                restSlugValidator.retrieveAndCheckIteration(projectSlug,\n                        iterationSlug, true);\n        HLocale hLocale =\n                restSlugValidator.validateTargetLocale(locale, projectSlug,\n                        iterationSlug);\n\n        EntityTag etag =\n                eTagUtils.generateETagForTranslatedDocument(hProjectIteration,\n                        id, hLocale);\n\n        ResponseBuilder response = request.evaluatePreconditions(etag);\n        if (response != null) {\n            return response.build();\n        }\n\n        HDocument document =\n                documentDAO.getByDocIdAndIteration(hProjectIteration, id);\n        if (document.isObsolete()) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n        List<HTextFlowTarget> targets =\n                textFlowTargetDAO.findAllTranslations(document, locale);\n\n        for (HTextFlowTarget target : targets) {\n            target.clear();\n        }\n\n        // we also need to delete the extensions here\n        document.getPoTargetHeaders().remove(hLocale);\n        textFlowTargetDAO.flush();\n\n        return Response.ok().build();\n\n    }","id":37675,"modified_method":"@Override\n    @Restrict(\"#{s:hasPermission(translatedDocResourceService.securedIteration.project, 'modify-translation')}\")\n    public\n            Response deleteTranslations(String idNoSlash, LocaleId locale) {\n        String id = URIHelper.convertFromDocumentURIId(idNoSlash);\n        HProjectIteration hProjectIteration =\n                restSlugValidator.retrieveAndCheckIteration(projectSlug,\n                        iterationSlug, true);\n        HLocale hLocale =\n                restSlugValidator.validateTargetLocale(locale, projectSlug,\n                        iterationSlug);\n\n        EntityTag etag =\n                eTagUtils.generateETagForTranslatedDocument(hProjectIteration,\n                        id, hLocale);\n\n        ResponseBuilder response = request.evaluatePreconditions(etag);\n        if (response != null) {\n            return response.build();\n        }\n\n        HDocument document =\n                documentDAO.getByDocIdAndIteration(hProjectIteration, id);\n        if (document == null || document.isObsolete()) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n        List<HTextFlowTarget> targets =\n                textFlowTargetDAO.findAllTranslations(document, locale);\n\n        for (HTextFlowTarget target : targets) {\n            target.clear();\n        }\n\n        // we also need to delete the extensions here\n        document.getPoTargetHeaders().remove(hLocale);\n        textFlowTargetDAO.flush();\n\n        return Response.ok().build();\n\n    }","commit_id":"f978e9eaf90ebdeeb1cdaaa9c02d5fd0a025745d","url":"https://github.com/zanata/zanata-server"},{"original_method":"public static void transfer(ProjectIteration from, HProjectIteration to) {\n\t\tto.setName(from.getName());\n\t\tto.setDescription(from.getDescription());\n\t}","id":37676,"modified_method":"public static boolean transfer(ProjectIteration from, HProjectIteration to) {\n\t\tboolean changed = false;\n\t\tif( !ResourceUtils.equals(to.getName(), from.getName()) ) {\n\t\t\tto.setName(from.getName());\n\t\t\tchanged = true;\n\t\t}\n\t\tif( !ResourceUtils.equals(to.getDescription(), from.getDescription()) ) {\n\t\t\tto.setDescription(from.getDescription());\n\t\t\tchanged = true;\n\t\t}\n\t\treturn changed;\n\t\t\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"@PUT\n\t@Consumes( { \n\t\tMediaTypes.APPLICATION_FLIES_PROJECT_ITERATION_XML,\n\t\tMediaTypes.APPLICATION_FLIES_PROJECT_ITERATION_JSON,\n\t\tMediaType.APPLICATION_XML,\n\t\tMediaType.APPLICATION_JSON})\n\t@Restrict(\"#{identity.loggedIn}\")\n\tpublic Response put(InputStream messageBody) {\n\t\t\n\t\tResponseBuilder response;\n\t\tEntityTag etag;\n\t\t\n\t\tHProjectIteration hProjectIteration = projectIterationDAO\n\t\t\t.getBySlug(projectSlug, iterationSlug);\n\t\t\n\t\tif(hProjectIteration == null) { // must be a create operation\n\t\t\tresponse = request.evaluatePreconditions();\n\t\t\tif(response != null) {\n\t\t\t\treturn response.build();\n\t\t\t}\n\t\t\tHProject hProject = projectDAO.getBySlug(projectSlug);\n\t\t\tif(hProject == null) {\n\t\t\t\treturn Response.status(Status.NOT_FOUND)\n\t\t\t\t\t.entity(\"Project '\"+ projectSlug +\"' not found.\")\n\t\t\t\t\t.build();\n\t\t\t}\n\t\t\thProjectIteration = new HProjectIteration();\n\t\t\thProjectIteration.setSlug(iterationSlug);\n\t\t\thProjectIteration.setProject((HIterationProject) hProject);\n\t\t\tresponse = Response.created( uri.getAbsolutePath() );\n\t\t\t\n\t\t}\n\t\telse{ // must be an update operation\n\t\t\tetag = eTagUtils.generateETagForIteration(projectSlug, iterationSlug);\n\t\t\tresponse = request.evaluatePreconditions(etag);\n\t\t\tif(response != null) {\n\t\t\t\treturn response.build();\n\t\t\t}\n\t\t\tresponse = Response.ok();\n\t\t}\n\n\t\tProjectIteration projectIteration = RestUtils.unmarshall(ProjectIteration.class, messageBody, requestContentType, headers.getRequestHeaders());\n\t\ttransfer(projectIteration, hProjectIteration);\n\t\t\n\t\tprojectIterationDAO.makePersistent(hProjectIteration);\n\t\tprojectIterationDAO.flush();\n\n\t\tetag = eTagUtils.generateETagForIteration(projectSlug, iterationSlug);\n\t\treturn response.tag(etag).build();\n\t\t\n\t}","id":37677,"modified_method":"@PUT\n\t@Consumes( { \n\t\tMediaTypes.APPLICATION_FLIES_PROJECT_ITERATION_XML,\n\t\tMediaTypes.APPLICATION_FLIES_PROJECT_ITERATION_JSON,\n\t\tMediaType.APPLICATION_XML,\n\t\tMediaType.APPLICATION_JSON})\n\t@Restrict(\"#{identity.loggedIn}\")\n\tpublic Response put(InputStream messageBody) {\n\t\t\n\t\tResponseBuilder response;\n\t\tEntityTag etag = null;\n\t\tboolean changed = false;\n\t\t\n\t\tHProject hProject = projectDAO.getBySlug(projectSlug);\n\t\t\n\t\tif(hProject == null) {\n\t\t\treturn Response.status(Status.NOT_FOUND)\n\t\t\t\t.entity(\"Project '\"+ projectSlug +\"' not found.\")\n\t\t\t\t.build();\n\t\t}\n\n\t\tHProjectIteration hProjectIteration = projectIterationDAO\n\t\t\t.getBySlug(projectSlug, iterationSlug);\n\t\t\n\t\tif(hProjectIteration == null) { // must be a create operation\n\t\t\tresponse = request.evaluatePreconditions();\n\t\t\tif(response != null) {\n\t\t\t\treturn response.build();\n\t\t\t}\n\t\t\thProjectIteration = new HProjectIteration();\n\t\t\thProjectIteration.setSlug(iterationSlug);\n\t\t\thProjectIteration.setProject((HIterationProject) hProject);\n\t\t\tresponse = Response.created( uri.getAbsolutePath() );\n\t\t\tchanged = true;\n\t\t\t\n\t\t}\n\t\telse{ // must be an update operation\n\t\t\tetag = eTagUtils.generateETagForIteration(projectSlug, iterationSlug);\n\t\t\tresponse = request.evaluatePreconditions(etag);\n\t\t\tif(response != null) {\n\t\t\t\treturn response.build();\n\t\t\t}\n\t\t\tresponse = Response.ok();\n\t\t}\n\n\t\tProjectIteration projectIteration = RestUtils.unmarshall(ProjectIteration.class, messageBody, requestContentType, headers.getRequestHeaders());\n\t\tchanged |= transfer(projectIteration, hProjectIteration);\n\t\t\n\t\tif(changed) {\n\t\t\tprojectIterationDAO.makePersistent(hProjectIteration);\n\t\t\tprojectIterationDAO.flush();\n\t\t\tetag = eTagUtils.generateETagForIteration(projectSlug, iterationSlug);\n\t\t}\n\t\treturn response.tag(etag).build();\n\t\t\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"private static <T> boolean equals(T a, T b) {\n\t\tif(a == null && b == null ) {\n\t\t\treturn true;\n\t\t}\n\t\tif(a == null || b == null) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn a.equals(b);\n\t}","id":37678,"modified_method":"public static <T> boolean equals(T a, T b) {\n\t\tif(a == null && b == null ) {\n\t\t\treturn true;\n\t\t}\n\t\tif(a == null || b == null) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\treturn a.equals(b);\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n\tpublic void retrieveTranslations() {\n\t\tcreateResourceWithContent();\n\t\t\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\n\t\tClientResponse<TargetResource> response = client.getTargets(\"my.txt\", LanguageQualifier.ALL, StringSet.valueOf(\"\"));\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\tTargetResource entity = response.getEntity();\n\t\t\n\t\tassertThat(entity.getTextFlows().size(), is(1));\n\t}","id":37679,"modified_method":"@Test\n\tpublic void retrieveTranslations() {\n\t\tcreateResourceWithContentUsingPut();\n\t\t\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\n\t\tClientResponse<TargetResource> response = client.getTargets(\"my.txt\", LanguageQualifier.ALL, StringSet.valueOf(\"\"));\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\tTargetResource entity = response.getEntity();\n\t\t\n\t\tassertThat(entity.getTextFlows().size(), is(1));\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n\tpublic void createResourceWithContent() {\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\t\t\n\t\tSourceResource sr = createSourceResource(\"my.txt\");\n\t\t\n\t\tSourceTextFlow stf = new SourceTextFlow(\"tf1\", LocaleId.EN, \"tf1\");\n\t\tsr.getTextFlows().add(stf);\n\t\t\n\t\tClientResponse<String> postResponse = client.post(sr, null);\n\t\tassertThat(postResponse.getResponseStatus(), is(Status.CREATED));\n\t\tpostResponse = client.post(sr, null);\n\t\t\n\t\tClientResponse<SourceResource> resourceGetResponse = client.getResource(\"my.txt\", null);\n\t\tassertThat(resourceGetResponse.getResponseStatus(), is(Status.OK));\n\t\tSourceResource gotSr = resourceGetResponse.getEntity();\n\t\tassertThat(gotSr.getTextFlows().size(), is(1));\n\t\tassertThat(gotSr.getTextFlows().get(0).getContent(), is(\"tf1\"));\n\t\t\n\t}","id":37680,"modified_method":"@Test\n\tpublic void createResourceWithContentUsingPut() {\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\t\t\n\t\tSourceResource sr = createSourceResource(\"my.txt\");\n\t\t\n\t\tSourceTextFlow stf = new SourceTextFlow(\"tf1\", LocaleId.EN, \"tf1\");\n\t\tsr.getTextFlows().add(stf);\n\t\t\n\t\tClientResponse<String> response = client.putResource(\"my.txt\", sr);\n\t\tassertThat(response.getResponseStatus(), is(Status.CREATED));\n\t\tassertThat( response.getLocation().getHref(), endsWith(\"/r/my.txt\"));\n\t\t\n\t\tClientResponse<SourceResource> resourceGetResponse = client.getResource(\"my.txt\", null);\n\t\tassertThat(resourceGetResponse.getResponseStatus(), is(Status.OK));\n\t\tSourceResource gotSr = resourceGetResponse.getEntity();\n\t\tassertThat(gotSr.getTextFlows().size(), is(1));\n\t\tassertThat(gotSr.getTextFlows().get(0).getContent(), is(\"tf1\"));\n\t\t\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Test\n\tpublic void publishTranslations() {\n\t\tcreateResourceWithContent();\n\t\t\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\n\t\tTranslationResource entity = new TranslationResource();\n\t\tTextFlowTargetWithId target = new TextFlowTargetWithId(\"tf1\");\n\t\ttarget.setContent(\"hello world\");\n\t\ttarget.setState(ContentState.Approved);\n\t\ttarget.setTranslator( new Person(\"root@localhost\", \"Admin user\"));\n\t\tentity.getTextFlowTargets().add(target);\n\t\t\n\t\tClientResponse<String> response = client.putTranslations(\"my.txt\", LocaleId.DE, entity);\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\t\n\t\tClientResponse<TranslationResource> getResponse = client.getTranslations(\"my.txt\", LocaleId.DE);\n\t\tassertThat(getResponse.getResponseStatus(), is(Status.OK));\n\t\tTranslationResource entity2 = getResponse.getEntity();\n\t\tassertThat(entity2.getTextFlowTargets().size(), is(entity.getTextFlowTargets().size()));\n\n\t\tentity.getTextFlowTargets().clear();\n\t\tresponse = client.putTranslations(\"my.txt\", LocaleId.DE, entity);\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\t\n\t\tgetResponse = client.getTranslations(\"my.txt\", LocaleId.DE);\n\t\tassertThat(getResponse.getResponseStatus(), is(Status.NOT_FOUND));\n\t\t\n\t}","id":37681,"modified_method":"@Test\n\tpublic void publishTranslations() {\n\t\tcreateResourceWithContentUsingPut();\n\t\t\n\t\tITranslationResources client = \n\t\t\tgetClientRequestFactory()\n\t\t\t.createProxy(ITranslationResources.class, createBaseURI(RESOURCE_PATH));\n\n\t\tTranslationResource entity = new TranslationResource();\n\t\tTextFlowTargetWithId target = new TextFlowTargetWithId(\"tf1\");\n\t\ttarget.setContent(\"hello world\");\n\t\ttarget.setState(ContentState.Approved);\n\t\ttarget.setTranslator( new Person(\"root@localhost\", \"Admin user\"));\n\t\tentity.getTextFlowTargets().add(target);\n\t\t\n\t\tClientResponse<String> response = client.putTranslations(\"my.txt\", LocaleId.DE, entity);\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\t\n\t\tClientResponse<TranslationResource> getResponse = client.getTranslations(\"my.txt\", LocaleId.DE);\n\t\tassertThat(getResponse.getResponseStatus(), is(Status.OK));\n\t\tTranslationResource entity2 = getResponse.getEntity();\n\t\tassertThat(entity2.getTextFlowTargets().size(), is(entity.getTextFlowTargets().size()));\n\n\t\tentity.getTextFlowTargets().clear();\n\t\tresponse = client.putTranslations(\"my.txt\", LocaleId.DE, entity);\n\t\t\n\t\tassertThat(response.getResponseStatus(), is(Status.OK));\n\t\t\n\t\tgetResponse = client.getTranslations(\"my.txt\", LocaleId.DE);\n\t\tassertThat(getResponse.getResponseStatus(), is(Status.NOT_FOUND));\n\t\t\n\t}","commit_id":"3bed403fccc0402322f38f98a9bc274e8ad498a2","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Observer(JpaIdentityStore.EVENT_USER_AUTHENTICATED)\n    public void loginSuccessful(HAccount account) {\n        log.info(\"Account {} authenticated\", account.getUsername());\n        injectAuthenticatedPersonIntoWorkingMemory(account);\n    }","id":37682,"modified_method":"@Observer(JpaIdentityStore.EVENT_USER_AUTHENTICATED)\n    public void loginSuccessful(HAccount account) {\n        log.debug(\"Account {} authenticated\", account.getUsername());\n        injectAuthenticatedPersonIntoWorkingMemory(account);\n    }","commit_id":"06c3c79bbbeb653d115c745e66cc91e62c32b57d","url":"https://github.com/zanata/zanata-server"},{"original_method":"@Override\n    public Response getTranslations(String idNoSlash, LocaleId locale,\n            Set<String> extensions, boolean skeletons, String eTag) {\n        log.debug(\"start to get translation\");\n        String id = URIHelper.convertFromDocumentURIId(idNoSlash);\n        HProjectIteration hProjectIteration =\n                restSlugValidator.retrieveAndCheckIteration(projectSlug,\n                        iterationSlug, false);\n        HLocale hLocale =\n                restSlugValidator.validateTargetLocale(locale, projectSlug,\n                        iterationSlug);\n\n        ResourceUtils.validateExtensions(extensions);\n\n        // Check Etag header\n        EntityTag generatedEtag =\n                eTagUtils.generateETagForTranslatedDocument(hProjectIteration,\n                        id, hLocale);\n        List<String> requestedEtagHeaders =\n                headers.getRequestHeader(HttpHeaders.IF_NONE_MATCH);\n        if (requestedEtagHeaders != null && !requestedEtagHeaders.isEmpty()) {\n            if (requestedEtagHeaders.get(0).equals(generatedEtag.getValue())) {\n                return Response.notModified(generatedEtag).build();\n            }\n        }\n\n        ResponseBuilder response = request.evaluatePreconditions(generatedEtag);\n        if (response != null) {\n            return response.build();\n        }\n\n        HDocument document =\n                documentDAO.getByDocIdAndIteration(hProjectIteration, id);\n        if (document.isObsolete()) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n\n        TranslationsResource translationResource = new TranslationsResource();\n        // TODO avoid queries for better cacheability\n        List<HTextFlowTarget> hTargets =\n                textFlowTargetDAO.findTranslations(document, hLocale);\n        boolean foundData =\n                resourceUtils.transferToTranslationsResource(\n                        translationResource, document, hLocale, extensions,\n                        hTargets, Optional.<String> absent());\n\n        if (!foundData && !skeletons) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n\n        // TODO lastChanged\n        return Response.ok().entity(translationResource).tag(generatedEtag)\n                .build();\n    }","id":37683,"modified_method":"@Override\n    public Response getTranslations(String idNoSlash, LocaleId locale,\n            Set<String> extensions, boolean skeletons, String eTag) {\n        log.debug(\"start to get translation\");\n        String id = URIHelper.convertFromDocumentURIId(idNoSlash);\n        HProjectIteration hProjectIteration =\n                restSlugValidator.retrieveAndCheckIteration(projectSlug,\n                        iterationSlug, false);\n        HLocale hLocale =\n                restSlugValidator.validateTargetLocale(locale, projectSlug,\n                        iterationSlug);\n\n        ResourceUtils.validateExtensions(extensions);\n\n        // Check Etag header\n        EntityTag generatedEtag =\n                eTagUtils.generateETagForTranslatedDocument(hProjectIteration,\n                        id, hLocale);\n        List<String> requestedEtagHeaders =\n                headers.getRequestHeader(HttpHeaders.IF_NONE_MATCH);\n        if (requestedEtagHeaders != null && !requestedEtagHeaders.isEmpty()) {\n            if (requestedEtagHeaders.get(0).equals(generatedEtag.getValue())) {\n                return Response.notModified(generatedEtag).build();\n            }\n        }\n\n        ResponseBuilder response = request.evaluatePreconditions(generatedEtag);\n        if (response != null) {\n            return response.build();\n        }\n\n        HDocument document =\n                documentDAO.getByDocIdAndIteration(hProjectIteration, id);\n        if (document == null || document.isObsolete()) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n\n        TranslationsResource translationResource = new TranslationsResource();\n        // TODO avoid queries for better cacheability\n        List<HTextFlowTarget> hTargets =\n                textFlowTargetDAO.findTranslations(document, hLocale);\n        boolean foundData =\n                resourceUtils.transferToTranslationsResource(\n                        translationResource, document, hLocale, extensions,\n                        hTargets, Optional.<String> absent());\n\n        if (!foundData && !skeletons) {\n            return Response.status(Status.NOT_FOUND).build();\n        }\n\n        // TODO lastChanged\n        return Response.ok().entity(translationResource).tag(generatedEtag)\n                .build();\n    }","commit_id":"06c3c79bbbeb653d115c745e66cc91e62c32b57d","url":"https://github.com/zanata/zanata-server"},{"original_method":"public String buildAndExpand(Object... uriVariables) {\n\t\t\treturn MvcUriComponentsBuilder.fromMethod(this.method, this.argumentValues)\n\t\t\t\t\t.build(false).expand(uriVariables).encode().toString();\n\t\t}","id":37684,"modified_method":"public String buildAndExpand(Object... uriVariables) {\n\t\t\treturn MvcUriComponentsBuilder.fromMethod(this.baseUrl, this.method, this.argumentValues)\n\t\t\t\t\t.build(false).expand(uriVariables).encode().toString();\n\t\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Create a {@link UriComponentsBuilder} from the mapping of a controller class\n\t * and current request information including Servlet mapping. If the controller\n\t * contains multiple mappings, only the first one is used.\n\t * @param controllerType the controller to build a URI for\n\t * @return a UriComponentsBuilder instance (never {@code null})\n\t */\n\tpublic static UriComponentsBuilder fromController(Class<?> controllerType) {\n\t\treturn fromController(null, controllerType);\n\t}","id":37685,"modified_method":"/**\n\t * Default constructor. Protected to prevent direct instantiation.\n\t *\n\t * @see #fromController(Class)\n\t * @see #fromMethodName(Class, String, Object...)\n\t * @see #fromMethodCall(Object)\n\t * @see #fromMappingName(String)\n\t * @see #fromMethod(java.lang.reflect.Method, Object...)\n\t */\n\tprotected MvcUriComponentsBuilder(UriComponentsBuilder baseUrl) {\n\t\tAssert.notNull(baseUrl, \"'baseUrl' is required\");\n\t\tthis.baseUrl = baseUrl;\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public String build() {\n\t\t\treturn MvcUriComponentsBuilder.fromMethod(this.method, this.argumentValues)\n\t\t\t\t\t.build(false).encode().toUriString();\n\t\t}","id":37686,"modified_method":"public String build() {\n\t\t\treturn MvcUriComponentsBuilder.fromMethod(this.baseUrl, this.method, this.argumentValues)\n\t\t\t\t\t.build(false).encode().toUriString();\n\t\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Create a URL from the name of a Spring MVC controller method's request mapping.\n\t *\n\t * <p>The configured\n\t * {@link org.springframework.web.servlet.handler.HandlerMethodMappingNamingStrategy\n\t * HandlerMethodMappingNamingStrategy} determines the names of controller\n\t * method request mappings at startup. By default all mappings are assigned\n\t * a name based on the capital letters of the class name, followed by \"#\" as\n\t * separator, and then the method name. For example \"PC#getPerson\"\n\t * for a class named PersonController with method getPerson. In case the\n\t * naming convention does not produce unique results, an explicit name may\n\t * be assigned through the name attribute of the {@code @RequestMapping}\n\t * annotation.\n\t *\n\t * <p>This is aimed primarily for use in view rendering technologies and EL\n\t * expressions. The Spring URL tag library registers this method as a function\n\t * called \"mvcUrl\".\n\t *\n\t * <p>For example, given this controller:\n\t * <pre class=\"code\">\n\t * &#064;RequestMapping(\"/people\")\n\t * class PersonController {\n\t *\n\t *   &#064;RequestMapping(\"/{id}\")\n\t *   public HttpEntity<Void> getPerson(&#064;PathVariable String id) { ... }\n\t *\n\t * }\n\t * <\/pre>\n\t *\n\t * A JSP can prepare a URL to the controller method as follows:\n\t *\n\t * <pre class=\"code\">\n\t * <%@ taglib uri=\"http://www.springframework.org/tags\" prefix=\"s\" %>\n\t *\n\t * &lt;a href=\"${s:mvcUrl('PC#getPerson').arg(0,\"123\").build()}\"&gt;Get Person&lt;/a&gt;\n\t * <\/pre>\n\t *\n\t * <p>Note that it's not necessary to specify all arguments. Only the ones\n\t * required to prepare the URL, mainly {@code @RequestParam} and {@code @PathVariable}).\n\t *\n\t * @param mappingName the mapping name\n\t * @return a builder to to prepare the URI String\n\t * @throws IllegalArgumentException if the mapping name is not found or\n\t * if there is no unique match\n\t * @since 4.1\n\t */\n\tpublic static MethodArgumentBuilder fromMappingName(String mappingName) {\n\t\tRequestMappingInfoHandlerMapping handlerMapping = getRequestMappingInfoHandlerMapping();\n\t\tList<HandlerMethod> handlerMethods = handlerMapping.getHandlerMethodsForMappingName(mappingName);\n\t\tif (handlerMethods == null) {\n\t\t\tthrow new IllegalArgumentException(\"Mapping mappingName not found: \" + mappingName);\n\t\t}\n\t\tif (handlerMethods.size() != 1) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"No unique match for mapping mappingName \" + mappingName + \": \" + handlerMethods);\n\t\t}\n\t\treturn new MethodArgumentBuilder(handlerMethods.get(0).getMethod());\n\t}","id":37687,"modified_method":"/**\n\t * Create a URL from the name of a Spring MVC controller method's request mapping.\n\t *\n\t * <p>The configured\n\t * {@link org.springframework.web.servlet.handler.HandlerMethodMappingNamingStrategy\n\t * HandlerMethodMappingNamingStrategy} determines the names of controller\n\t * method request mappings at startup. By default all mappings are assigned\n\t * a name based on the capital letters of the class name, followed by \"#\" as\n\t * separator, and then the method name. For example \"PC#getPerson\"\n\t * for a class named PersonController with method getPerson. In case the\n\t * naming convention does not produce unique results, an explicit name may\n\t * be assigned through the name attribute of the {@code @RequestMapping}\n\t * annotation.\n\t *\n\t * <p>This is aimed primarily for use in view rendering technologies and EL\n\t * expressions. The Spring URL tag library registers this method as a function\n\t * called \"mvcUrl\".\n\t *\n\t * <p>For example, given this controller:\n\t * <pre class=\"code\">\n\t * &#064;RequestMapping(\"/people\")\n\t * class PersonController {\n\t *\n\t *   &#064;RequestMapping(\"/{id}\")\n\t *   public HttpEntity<Void> getPerson(&#064;PathVariable String id) { ... }\n\t *\n\t * }\n\t * <\/pre>\n\t *\n\t * A JSP can prepare a URL to the controller method as follows:\n\t *\n\t * <pre class=\"code\">\n\t * <%@ taglib uri=\"http://www.springframework.org/tags\" prefix=\"s\" %>\n\t *\n\t * &lt;a href=\"${s:mvcUrl('PC#getPerson').arg(0,\"123\").build()}\"&gt;Get Person&lt;/a&gt;\n\t * <\/pre>\n\t *\n\t * <p>Note that it's not necessary to specify all arguments. Only the ones\n\t * required to prepare the URL, mainly {@code @RequestParam} and {@code @PathVariable}).\n\t *\n\t * @param mappingName the mapping name\n\t * @return a builder to to prepare the URI String\n\t * @throws IllegalArgumentException if the mapping name is not found or\n\t * if there is no unique match\n\t * @since 4.1\n\t */\n\tpublic static MethodArgumentBuilder fromMappingName(String mappingName) {\n\t\treturn fromMappingName(null, mappingName);\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public MethodArgumentBuilder(Method method) {\n\t\t\tAssert.notNull(method, \"'method' is required\");\n\t\t\tthis.method = method;\n\t\t\tthis.argumentValues = new Object[method.getParameterTypes().length];\n\t\t\tfor (int i = 0; i < this.argumentValues.length; i++) {\n\t\t\t\tthis.argumentValues[i] = null;\n\t\t\t}\n\t\t}","id":37688,"modified_method":"public MethodArgumentBuilder(Method method) {\n\t\t\tthis(null, method);\n\t\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n\t * Create a deep copy of the given MvcUriComponentsBuilder.\n\t * @param other the other builder to copy from\n\t */\n\tprotected MvcUriComponentsBuilder(MvcUriComponentsBuilder other) {\n\t\tsuper(other);\n\t}","id":37689,"modified_method":"/**\n\t * Create a deep copy of the given MvcUriComponentsBuilder.\n\t * @param other the other builder to copy from\n\t */\n\tprotected MvcUriComponentsBuilder(MvcUriComponentsBuilder other) {\n\t\tsuper(other);\n\t\tthis.baseUrl = other.baseUrl;\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Test\n\tpublic void testFromMethodCallWithCustomBaseUrl() {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tUriComponents uriComponents = fromMethodCall(builder, on(ControllerWithMethods.class).myMethod(null)).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/something/else\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","id":37690,"modified_method":"@Test\n\tpublic void testFromMethodCallWithCustomBaseUrlViaStaticCall() {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tUriComponents uriComponents = fromMethodCall(builder, on(ControllerWithMethods.class).myMethod(null)).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/something/else\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Test\n\tpublic void testFromMethodNameWithCustomBaseUrl() throws Exception {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tUriComponents uriComponents = fromMethodName(builder, ControllerWithMethods.class,\n\t\t\t\t\"methodWithPathVariable\", new Object[] {\"1\"}).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/something/1/foo\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","id":37691,"modified_method":"@Test\n\tpublic void testFromMethodNameWithCustomBaseUrlViaInstance() throws Exception {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tMvcUriComponentsBuilder mvcBuilder = MvcUriComponentsBuilder.relativeTo(builder);\n\t\tUriComponents uriComponents = mvcBuilder.withMethodName(ControllerWithMethods.class,\n\t\t\t\t\"methodWithPathVariable\", new Object[] {\"1\"}).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/something/1/foo\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Test\n\tpublic void testFromControllerWithCustomBaseUrl() {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tUriComponents uriComponents = fromController(builder, PersonControllerImpl.class).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/people\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","id":37692,"modified_method":"@Test\n\tpublic void testFromControllerWithCustomBaseUrlViaStaticCall() {\n\t\tUriComponentsBuilder builder = UriComponentsBuilder.fromUriString(\"http://example.org:9090/base\");\n\t\tUriComponents uriComponents = fromController(builder, PersonControllerImpl.class).build();\n\n\t\tassertEquals(\"http://example.org:9090/base/people\", uriComponents.toString());\n\t\tassertEquals(\"http://example.org:9090/base\", builder.toUriString());\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Override\n\tpublic boolean supportsParameter(MethodParameter parameter) {\n\t\treturn UriComponentsBuilder.class.isAssignableFrom(parameter.getParameterType());\n\t}","id":37693,"modified_method":"@Override\n\tpublic boolean supportsParameter(MethodParameter parameter) {\n\t\tClass<?> type = parameter.getParameterType();\n\t\treturn (UriComponentsBuilder.class.equals(type) || ServletUriComponentsBuilder.class.equals(type));\n\t}","commit_id":"1cd0f433e0a5dd9b659143664ea432d24b4386eb","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"/**\n     * reduceInit is called once before any calls to the map function.  We use it here to setup the output\n     * bam file, if it was specified on the command line\n     *\n     * @return\n     */\n    public ClippingData reduceInit() {\n        SAMFileWriter outputBam = null;\n\n        if ( outputBamFile != null ) {\n            SAMFileHeader header = this.getToolkit().getSAMFileHeader();\n            boolean maintainsSort = clippingRepresentation != ClippingRepresentation.SOFTCLIP_BASES;\n            outputBam = Utils.createSAMFileWriterWithCompression(header, maintainsSort, outputBamFile, 5);\n        }\n\n        return new ClippingData(outputBam, sequencesToClip);\n    }","id":37694,"modified_method":"/**\n     * reduceInit is called once before any calls to the map function.  We use it here to setup the output\n     * bam file, if it was specified on the command line\n     *\n     * @return\n     */\n    public ClippingData reduceInit() {\n        return new ClippingData(sequencesToClip);\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public ClippingData reduce(ReadClipper clipper, ClippingData data) {\n        if ( clipper == null )\n            return data;\n\n        if (data.output != null) {\n            data.output.addAlignment(clipper.clipRead(clippingRepresentation));\n        } else {\n            out.println(clipper.clipRead(clippingRepresentation).format());\n        }\n\n        data.nTotalReads++;\n        data.nTotalBases += clipper.getRead().getReadLength();\n        if (clipper.wasClipped()) {\n            data.nClippedReads++;\n            for (ClippingOp op : clipper.getOps()) {\n                switch (op.type) {\n                    case LOW_Q_SCORES:\n                        data.incNQClippedBases(op.getLength());\n                        break;\n                    case WITHIN_CLIP_RANGE:\n                        data.incNRangeClippedBases(op.getLength());\n                        break;\n                    case MATCHES_CLIP_SEQ:\n                        data.incSeqClippedBases((String) op.extraInfo, op.getLength());\n                        break;\n                }\n            }\n        }\n\n        return data;\n    }","id":37695,"modified_method":"public ClippingData reduce(ReadClipper clipper, ClippingData data) {\n        if ( clipper == null )\n            return data;\n\n        if (outputBam != null) {\n            outputBam.addAlignment(clipper.clipRead(clippingRepresentation));\n        } else {\n            out.println(clipper.clipRead(clippingRepresentation).format());\n        }\n\n        data.nTotalReads++;\n        data.nTotalBases += clipper.getRead().getReadLength();\n        if (clipper.wasClipped()) {\n            data.nClippedReads++;\n            for (ClippingOp op : clipper.getOps()) {\n                switch (op.type) {\n                    case LOW_Q_SCORES:\n                        data.incNQClippedBases(op.getLength());\n                        break;\n                    case WITHIN_CLIP_RANGE:\n                        data.incNRangeClippedBases(op.getLength());\n                        break;\n                    case MATCHES_CLIP_SEQ:\n                        data.incSeqClippedBases((String) op.extraInfo, op.getLength());\n                        break;\n                }\n            }\n        }\n\n        return data;\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public void onTraversalDone(ClippingData data) {\n        if (data.output != null)\n            data.output.close();\n\n        out.printf(data.toString());\n    }","id":37696,"modified_method":"public void onTraversalDone(ClippingData data) {\n        out.printf(data.toString());\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"/**\n     * The initialize function.\n     */\n    public void initialize() {\n        if (qTrimmingThreshold >= 0) {\n            logger.info(String.format(\"Creating Q-score clipper with threshold %d\", qTrimmingThreshold));\n        }\n\n        //\n        // Initialize the sequences to clip\n        //\n        if (clipSequencesArgs != null) {\n            int i = 0;\n            for (String toClip : clipSequencesArgs) {\n                i++;\n                ReferenceSequence rs = new ReferenceSequence(\"CMDLINE-\" + i, -1, StringUtil.stringToBytes(toClip));\n                addSeqToClip(rs.getName(), rs.getBases());\n            }\n        }\n\n        if (clipSequenceFile != null) {\n            ReferenceSequenceFile rsf = ReferenceSequenceFileFactory.getReferenceSequenceFile(new File(clipSequenceFile));\n\n            while (true) {\n                ReferenceSequence rs = rsf.nextSequence();\n                if (rs == null)\n                    break;\n                else {\n                    addSeqToClip(rs.getName(), rs.getBases());\n                }\n            }\n        }\n\n\n        //\n        // Initialize the cycle ranges to clip\n        //\n        if (cyclesToClipArg != null) {\n            cyclesToClip = new ArrayList<Pair<Integer, Integer>>();\n            for (String range : cyclesToClipArg.split(\",\")) {\n                try {\n                    String[] elts = range.split(\"-\");\n                    int start = Integer.parseInt(elts[0]) - 1;\n                    int stop = Integer.parseInt(elts[1]) - 1;\n\n                    if (start < 0) throw new Exception();\n                    if (stop < start) throw new Exception();\n\n                    logger.info(String.format(\"Creating cycle clipper %d-%d\", start, stop));\n                    cyclesToClip.add(new Pair<Integer, Integer>(start, stop));\n                } catch (Exception e) {\n                    throw new RuntimeException(\"Badly formatted cyclesToClip argument: \" + cyclesToClipArg);\n                }\n            }\n        }\n    }","id":37697,"modified_method":"/**\n     * The initialize function.\n     */\n    public void initialize() {\n        if (qTrimmingThreshold >= 0) {\n            logger.info(String.format(\"Creating Q-score clipper with threshold %d\", qTrimmingThreshold));\n        }\n\n        //\n        // Initialize the sequences to clip\n        //\n        if (clipSequencesArgs != null) {\n            int i = 0;\n            for (String toClip : clipSequencesArgs) {\n                i++;\n                ReferenceSequence rs = new ReferenceSequence(\"CMDLINE-\" + i, -1, StringUtil.stringToBytes(toClip));\n                addSeqToClip(rs.getName(), rs.getBases());\n            }\n        }\n\n        if (clipSequenceFile != null) {\n            ReferenceSequenceFile rsf = ReferenceSequenceFileFactory.getReferenceSequenceFile(new File(clipSequenceFile));\n\n            while (true) {\n                ReferenceSequence rs = rsf.nextSequence();\n                if (rs == null)\n                    break;\n                else {\n                    addSeqToClip(rs.getName(), rs.getBases());\n                }\n            }\n        }\n\n\n        //\n        // Initialize the cycle ranges to clip\n        //\n        if (cyclesToClipArg != null) {\n            cyclesToClip = new ArrayList<Pair<Integer, Integer>>();\n            for (String range : cyclesToClipArg.split(\",\")) {\n                try {\n                    String[] elts = range.split(\"-\");\n                    int start = Integer.parseInt(elts[0]) - 1;\n                    int stop = Integer.parseInt(elts[1]) - 1;\n\n                    if (start < 0) throw new Exception();\n                    if (stop < start) throw new Exception();\n\n                    logger.info(String.format(\"Creating cycle clipper %d-%d\", start, stop));\n                    cyclesToClip.add(new Pair<Integer, Integer>(start, stop));\n                } catch (Exception e) {\n                    throw new RuntimeException(\"Badly formatted cyclesToClip argument: \" + cyclesToClipArg);\n                }\n            }\n        }\n\n        outputBam.setPresorted(clippingRepresentation != ClippingRepresentation.SOFTCLIP_BASES);\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public ClippingData(SAMFileWriter output, List<SeqToClip> clipSeqs) {\n            this.output = output;\n            for (SeqToClip clipSeq : clipSeqs) {\n                seqClipCounts.put(clipSeq.seq, 0L);\n            }\n        }","id":37698,"modified_method":"public ClippingData(List<SeqToClip> clipSeqs) {\n            for (SeqToClip clipSeq : clipSeqs) {\n                seqClipCounts.put(clipSeq.seq, 0L);\n            }\n        }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"@Override\n    public boolean supports( Class type ) {\n        return SAMFileWriter.class.isAssignableFrom(type);\n    }","id":37699,"modified_method":"@Override\n    public boolean supports( Class type ) {\n        return SAMFileWriter.class.equals(type) || StingSAMFileWriter.class.equals(type);\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public SAMFileWriterStorage( SAMFileWriterStub stub, File file ) {\n        this.file = file;\n        if( stub.getCompressionLevel() != null )\n            this.writer = new SAMFileWriterFactory().makeBAMWriter( stub.getSAMFileHeader(), true, file, stub.getCompressionLevel() );\n        else\n            this.writer = new SAMFileWriterFactory().makeBAMWriter( stub.getSAMFileHeader(), true, file );\n    }","id":37700,"modified_method":"public SAMFileWriterStorage( SAMFileWriterStub stub, File file ) {\n        this.file = file;\n        if( stub.getCompressionLevel() != null )\n            this.writer = new SAMFileWriterFactory().makeBAMWriter( stub.getFileHeader(), stub.isPresorted(), file, stub.getCompressionLevel() );\n        else\n            this.writer = new SAMFileWriterFactory().makeBAMWriter( stub.getFileHeader(), stub.isPresorted(), file );\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"/**\n     * Retrieves the header to use when creating the new SAM file.\n     * @return header to use when creating the new SAM file.\n     */\n    public SAMFileHeader getSAMFileHeader() {\n        return engine.getSAMFileHeader();    \n    }","id":37701,"modified_method":"/**\n     * Use the given header as the target for this writer.\n     * @param header The header to write.\n     */\n    public void writeHeader(SAMFileHeader header) {\n        this.headerOverride = header;\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public SAMFileHeader getFileHeader() {\n        return getSAMFileHeader();\n    }","id":37702,"modified_method":"/**\n     * Retrieves the header to use when creating the new SAM file.\n     * @return header to use when creating the new SAM file.\n     */\n    public SAMFileHeader getFileHeader() {\n        return headerOverride != null ? headerOverride : engine.getSAMFileHeader();\n    }","commit_id":"58999a8e9dbfca19c5807665f36c73711267ecbd","url":"https://github.com/broadgsa/gatk"},{"original_method":"public <T> void add(Formatter<T> formatter) {\n\t\t// TODO\n\t}","id":37703,"modified_method":"public <T> void add(Formatter<T> formatter) {\n\t\ttypeFormatters.put(getFormattedObjectType(formatter.getClass()), formatter);\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"private Formatter<?> getFormatter(Class<?> type) {\n\t\tAssert.notNull(type, \"The Class of the object to format is required\");\n\t\tFormatter formatter = typeFormatters.get(type);\n\t\tif (formatter != null) {\n\t\t\treturn formatter;\n\t\t} else {\n\t\t\tFormatted formatted = AnnotationUtils.findAnnotation(type, Formatted.class);\n\t\t\tif (formatted != null) {\n\t\t\t\tClass formatterClass = formatted.value();\n\t\t\t\ttry {\n\t\t\t\t\tformatter = (Formatter) formatterClass.newInstance();\n\t\t\t\t} catch (InstantiationException e) {\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Formatter referenced by @Formatted annotation does not have default constructor\", e);\n\t\t\t\t} catch (IllegalAccessException e) {\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Formatter referenced by @Formatted annotation does not have public constructor\", e);\n\t\t\t\t}\n\t\t\t\ttypeFormatters.put(type, formatter);\n\t\t\t\treturn formatter;\n\t\t\t} else {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t}","id":37704,"modified_method":"private Formatter<?> getTypeFormatter(Class<?> type) {\n\t\tAssert.notNull(type, \"The Class of the object to format is required\");\n\t\tFormatter formatter = typeFormatters.get(type);\n\t\tif (formatter != null) {\n\t\t\tClass<?> formattedObjectType = getFormattedObjectType(formatter.getClass());\n\t\t\tif (type.isAssignableFrom(formattedObjectType)) {\n\t\t\t\treturn formatter;\n\t\t\t} else {\n\t\t\t\treturn new ConvertingFormatter(type, formattedObjectType, formatter);\n\t\t\t}\n\t\t} else {\n\t\t\treturn getDefaultFormatter(type);\n\t\t}\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public Formatter<?> getFormatter(TypeDescriptor type) {\n\t\tAssert.notNull(type, \"The TypeDescriptor is required\");\n\t\tAnnotation[] annotations = type.getAnnotations();\n\t\tfor (Annotation a : annotations) {\n\t\t\tAnnotationFormatterFactory factory = annotationFormatters.get(a.annotationType());\n\t\t\tif (factory != null) {\n\t\t\t\treturn factory.getFormatter(a);\n\t\t\t}\n\t\t}\n\t\treturn getFormatter(type.getType());\n\t}","id":37705,"modified_method":"public Formatter<?> getFormatter(TypeDescriptor type) {\n\t\tAssert.notNull(type, \"The TypeDescriptor is required\");\n\t\tFormatter formatter = getAnnotationFormatter(type);\n\t\tif (formatter == null) {\n\t\t\tformatter = getTypeFormatter(type.getType());\n\t\t}\n\t\treturn formatter;\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"public <A extends Annotation, T> void add(AnnotationFormatterFactory<A, T> factory) {\n\t\tannotationFormatters.put(getAnnotationType(factory), factory);\n\t}","id":37706,"modified_method":"public <A extends Annotation, T> void add(AnnotationFormatterFactory<A, T> factory) {\n\t\tannotationFormatters.put(getAnnotationType(factory.getClass()), factory);\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"private Class getAnnotationType(AnnotationFormatterFactory factory) {\n\t\tClass classToIntrospect = factory.getClass();\n\t\twhile (classToIntrospect != null) {\n\t\t\tType[] genericInterfaces = classToIntrospect.getGenericInterfaces();\n\t\t\tfor (Type genericInterface : genericInterfaces) {\n\t\t\t\tif (genericInterface instanceof ParameterizedType) {\n\t\t\t\t\tParameterizedType pInterface = (ParameterizedType) genericInterface;\n\t\t\t\t\tif (AnnotationFormatterFactory.class.isAssignableFrom((Class) pInterface.getRawType())) {\n\t\t\t\t\t\treturn getParameterClass(pInterface.getActualTypeArguments()[0], factory.getClass());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tclassToIntrospect = classToIntrospect.getSuperclass();\n\t\t}\n\t\tthrow new IllegalArgumentException(\n\t\t\t\t\"Unable to extract Annotation type A argument from AnnotationFormatterFactory [\"\n\t\t\t\t\t\t+ factory.getClass().getName() + \"]; does the factory parameterize the <A> generic type?\");\n\t}","id":37707,"modified_method":"private Formatter<?> getAnnotationFormatter(TypeDescriptor type) {\n\t\tAnnotation[] annotations = type.getAnnotations();\n\t\tfor (Annotation a : annotations) {\n\t\t\tAnnotationFormatterFactory factory = annotationFormatters.get(a.annotationType());\n\t\t\tif (factory != null) {\n\t\t\t\treturn factory.getFormatter(a);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Test\n\t@Ignore\n\tpublic void testAddAnnotationFormatterFactory() {\n\t}","id":37708,"modified_method":"@Test\n\tpublic void testAddAnnotationFormatterFactory() throws Exception {\n\t\tregistry.add(new CurrencyAnnotationFormatterFactory());\n\t\tFormatter formatter = registry.getFormatter(new TypeDescriptor(getClass().getField(\"currencyField\")));\n\t\tString formatted = formatter.format(new BigDecimal(\"5.00\"), Locale.US);\n\t\tassertEquals(\"$5.00\", formatted);\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"@Test\n\t@Ignore\n\tpublic void testAddByOtherObjectType() {\n\t\tregistry.add(Integer.class, new IntegerFormatter());\n\t\tFormatter formatter = registry.getFormatter(typeDescriptor(Integer.class));\n\t\tString formatted = formatter.format(new Integer(3), Locale.US);\n\t\tassertEquals(\"3\", formatted);\n\t}","id":37709,"modified_method":"@Test\n\tpublic void testAddByObjectType() {\n\t\tregistry.add(Integer.class, new IntegerFormatter());\n\t\tFormatter formatter = registry.getFormatter(typeDescriptor(Integer.class));\n\t\tString formatted = formatter.format(new Integer(3), Locale.US);\n\t\tassertEquals(\"3\", formatted);\n\t}","commit_id":"20f5f99e9a44bbafabe29a56f12e8fe7cb7c8925","url":"https://github.com/spring-projects/spring-framework"},{"original_method":"private void resolveImpl(GrReferenceExpressionImpl refExpr, GrExpression qualifier, ResolverProcessor processor) {\n      if (qualifier == null) {\n        ResolveUtil.treeWalkUp(refExpr, processor);\n      } else {\n        PsiType qualifierType = qualifier.getType();\n        if (qualifierType instanceof PsiClassType) {\n          PsiClass qualifierClass = ((PsiClassType) qualifierType).resolve();\n          if (qualifierClass != null) {\n            qualifierClass.processDeclarations(processor, PsiSubstitutor.EMPTY, null, refExpr);\n            if (!(qualifierClass instanceof GrTypeDefinition)) {\n              ResolveUtil.processDefaultMethods(qualifierClass, processor);\n            }\n          }\n        }\n      }\n    }","id":37710,"modified_method":"private void resolveImpl(GrReferenceExpressionImpl refExpr, ResolverProcessor processor) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      if (qualifier == null) {\n        ResolveUtil.treeWalkUp(refExpr, processor);\n      } else {\n        processQualifierType(refExpr, processor, qualifier);\n      }\n    }","commit_id":"309f932c57c25c85d4f7b9d8e45f7bd4755a6c36","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public GroovyResolveResult[] resolve(GrReferenceExpressionImpl refExpr, boolean incompleteCode) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      String name = refExpr.getReferenceName();\n      if (name == null) return null;\n      ResolverProcessor processor = getResolveProcessor(refExpr, name, false);\n\n      resolveImpl(refExpr, qualifier, processor);\n\n      GroovyResolveResult[] propertyCandidates = processor.getCandidates();\n      if (propertyCandidates.length > 0) return propertyCandidates;\n      if (refExpr.getKind() == Kind.TYPE_OR_PROPERTY) {\n        ResolverProcessor classProcessor = new ResolverProcessor(refExpr.getReferenceName(), EnumSet.of(ResolveKind.CLASS), refExpr, false);\n        resolveImpl(refExpr, qualifier, classProcessor);\n        return classProcessor.getCandidates();\n      }\n\n      return GroovyResolveResult.EMPTY_ARRAY;\n    }","id":37711,"modified_method":"public GroovyResolveResult[] resolve(GrReferenceExpressionImpl refExpr, boolean incompleteCode) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      String name = refExpr.getReferenceName();\n      if (name == null) return null;\n      ResolverProcessor processor = getResolveProcessor(refExpr, name, false);\n\n      resolveImpl(refExpr, processor);\n\n      GroovyResolveResult[] propertyCandidates = processor.getCandidates();\n      if (propertyCandidates.length > 0) return propertyCandidates;\n      if (refExpr.getKind() == Kind.TYPE_OR_PROPERTY) {\n        ResolverProcessor classProcessor = new ResolverProcessor(refExpr.getReferenceName(), EnumSet.of(ResolveKind.CLASS), refExpr, false);\n        resolveImpl(refExpr, classProcessor);\n        return classProcessor.getCandidates();\n      }\n\n      return GroovyResolveResult.EMPTY_ARRAY;\n    }","commit_id":"309f932c57c25c85d4f7b9d8e45f7bd4755a6c36","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private Object[] getVariantsImpl(ResolverProcessor processor) {\n    GrExpression qualifierExpression = getQualifierExpression();\n    if (qualifierExpression == null) {\n      ResolveUtil.treeWalkUp(this, processor);\n    } else {\n      PsiType qualifierType = qualifierExpression.getType();\n      if (qualifierType instanceof PsiClassType) {\n        PsiClass qualifierClass = ((PsiClassType) qualifierType).resolve();\n        if (qualifierClass != null) {\n          qualifierClass.processDeclarations(processor, PsiSubstitutor.EMPTY, null, this);\n          if (!(qualifierClass instanceof GrTypeDefinition)) {\n            ResolveUtil.processDefaultMethods(qualifierClass, processor);\n          }\n        }\n      }\n    }\n\n    GroovyResolveResult[] candidates = processor.getCandidates();\n    if (candidates.length == 0) return PsiNamedElement.EMPTY_ARRAY;\n    return ResolveUtil.mapToElements(candidates);\n  }","id":37712,"modified_method":"private Object[] getVariantsImpl(ResolverProcessor processor) {\n    GrExpression qualifier = getQualifierExpression();\n    if (qualifier == null) {\n      ResolveUtil.treeWalkUp(this, processor);\n      qualifier = getRuntimeQualifier(this);\n      if (qualifier != null) getVariantsFromQualifier(processor, qualifier);\n    } else {\n      getVariantsFromQualifier(processor, qualifier);\n    }\n\n    GroovyResolveResult[] candidates = processor.getCandidates();\n    if (candidates.length == 0) return PsiNamedElement.EMPTY_ARRAY;\n    return ResolveUtil.mapToElements(candidates);\n  }","commit_id":"309f932c57c25c85d4f7b9d8e45f7bd4755a6c36","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private static PsiElement resolveInRoot(final VirtualFile root, final String referencedName, final PyReferenceExpression importRef) {\n    final PsiManager psi_mgr = PsiManager.getInstance(importRef.getProject());\n    final VirtualFile childFile = root.findChild(referencedName + \".py\");\n    if (childFile != null) {\n      return psi_mgr.findFile(childFile);\n    }\n\n    final VirtualFile childDir = root.findChild(referencedName);\n    if (childDir != null) {\n      return psi_mgr.findDirectory(childDir);\n    }\n\n    // NOTE: a preliminary attempt to resolve to a C lib\n    VirtualFile clib_file = root.findChild(referencedName + \".so\"); // TODO: platform-dependent choice of .so | .pyd\n    if (clib_file != null) {\n      return psi_mgr.findFile(clib_file);\n    }\n    return null;\n  }","id":37713,"modified_method":"/**\n  Tries to find referencedName under a root. Only used for resolution of import statements.\n  @param root where to look for the referenced name.\n  @param referencedName which name to look for.\n  @param importRef import reference which resolution led to this call.\n  @return the element the referencedName resolves to, or null.\n  */\n  @Nullable\n  private static PsiElement resolveInRoot(final VirtualFile root, final String referencedName, final PyReferenceExpression importRef) {\n    final PsiManager psi_mgr = PsiManager.getInstance(importRef.getProject());\n    final VirtualFile childFile = root.findChild(referencedName + PY_SUFFIX);\n    if (childFile != null) {\n      return psi_mgr.findFile(childFile);\n    }\n\n    final VirtualFile childDir = root.findChild(referencedName);\n    if (childDir != null) {\n      return psi_mgr.findDirectory(childDir);\n    }\n\n    // NOTE: a preliminary attempt to resolve to a C lib\n    VirtualFile clib_file = root.findChild(referencedName + \".so\"); // XXX: platform-dependent choice of .so | .pyd\n    if (clib_file != null) {\n      return psi_mgr.findFile(clib_file);\n    }\n    return null;\n  }","commit_id":"3457e35621594322a16b44f5bf3e7fd2eebf01b0","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@Nullable\n  private static PsiElement resolveChild(final PsiElement parent, final String referencedName, final PyReferenceExpression importRef) {\n    if (parent instanceof PyFile) {\n      return PyResolveUtil.treeWalkUp(new PyResolveUtil.ResolveProcessor(referencedName), parent, null, importRef);\n    }\n    else if (parent instanceof PsiDirectory) {\n      final PsiDirectory dir = (PsiDirectory)parent;\n      final PsiFile file = dir.findFile(referencedName + \".py\");\n      if (file != null) return file;\n      final PsiDirectory subdir = dir.findSubdirectory(referencedName);\n      if (subdir != null) return subdir;\n      final PsiFile initPy = dir.findFile(\"__init__.py\");\n      if (initPy != null) {\n        return PyResolveUtil.treeWalkUp(new PyResolveUtil.ResolveProcessor(referencedName), initPy, null, importRef);\n      }\n    }\n    return null;\n  }","id":37714,"modified_method":"/**\n  Tries to find referencedName under the parent element. Used to reesolve any names that look imported.\n  Parent might happen to be a PyFile(__init__.py), then it is treated <i>both<\/i> as a file and as ist base dir.\n  For details of this ugly magic, see {@link com.jetbrains.python.psi.impl.PyReferenceExpressionImpl#resolve()}.\n  @param parent element under which to look for referenced name.\n  @param referencedName which name to look for.\n  @param importRef import reference which resolution led to this call.\n  @return the element the referencedName resolves to, or null.\n  @todo: Honor module's __all__ value.\n  @todo: Honor package's __path__ value (hard).\n  */\n  @Nullable\n  public static PsiElement resolveChild(final PsiElement parent, final String referencedName, final PyReferenceExpression importRef) {\n    PsiDirectory dir = null;\n    PsiElement ret = null;\n    if (parent instanceof PyFile) {\n      PyFile pfparent = (PyFile)parent; \n      if (INIT_PY.equals(pfparent.getName())) {\n        // try both file and dir, for we can't tell.\n        dir = pfparent.getContainingDirectory();\n      }\n      // to be used if dir resolution is not applicable:\n      ret = PyResolveUtil.treeWalkUp(new PyResolveUtil.ResolveProcessor(referencedName), parent, null, importRef);\n    }\n    else if (parent instanceof PsiDirectory) {\n      dir = (PsiDirectory)parent;\n    }\n    if (dir != null) {\n      final PsiFile file = dir.findFile(referencedName + PY_SUFFIX);\n      if (file != null) return file;\n      final PsiDirectory subdir = dir.findSubdirectory(referencedName);\n      if (subdir != null) return subdir;\n      else { // not a subdir, not a file; could be a name in parent/__init__.py\n        final PsiFile initPy = dir.findFile(INIT_PY);\n        if (initPy != null) {\n          return PyResolveUtil.treeWalkUp(new PyResolveUtil.ResolveProcessor(referencedName), initPy, null, importRef);\n        }\n      }\n    }\n    return ret;\n  }","commit_id":"3457e35621594322a16b44f5bf3e7fd2eebf01b0","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"private void resolveImpl(GrReferenceExpressionImpl refExpr, ResolverProcessor processor) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      if (qualifier == null) {\n        ResolveUtil.treeWalkUp(refExpr, processor);\n      } else {\n        processQualifierType(refExpr, processor, qualifier);\n      }\n    }","id":37715,"modified_method":"private void resolveImpl(GrReferenceExpressionImpl refExpr, ResolverProcessor processor) {\n      GrExpression qualifier = refExpr.getQualifierExpression();\n      if (qualifier == null) {\n        ResolveUtil.treeWalkUp(refExpr, processor);\n        if (!processor.hasCandidates()) {\n          qualifier = getRuntimeQualifier(refExpr);\n          if (qualifier != null) {\n            processQualifierType(refExpr, processor, qualifier);\n          }\n        }\n      } else {\n        processQualifierType(refExpr, processor, qualifier);\n      }\n    }","commit_id":"69ca4cda24cd96efcfe3c8528ce80a1951b9204a","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public Object[] getVariants() {\n    ResolverProcessor processor = getResolveProcessor(this, null);\n    ResolveUtil.treeWalkUp(this, processor);\n    GroovyResolveResult[] candidates = processor.getCandidates();\n    if (candidates.length == 0) return PsiNamedElement.EMPTY_ARRAY;\n    return ResolveUtil.mapToElements(candidates);\n  }","id":37716,"modified_method":"public Object[] getVariants() {\n    ResolverProcessor processor = getResolveProcessor(this, null);\n    GrExpression qualifierExpression = getQualifierExpression();\n    if (qualifierExpression == null) {\n      ResolveUtil.treeWalkUp(this, processor);\n    } else {\n      PsiType qualifierType = qualifierExpression.getType();\n      if (qualifierType instanceof PsiClassType) {\n        PsiClass qualifierClass = ((PsiClassType) qualifierType).resolve();\n        if (qualifierClass != null) {\n          qualifierClass.processDeclarations(processor, PsiSubstitutor.EMPTY, null, this);\n        }\n      }\n    }\n\n    GroovyResolveResult[] candidates = processor.getCandidates();\n    if (candidates.length == 0) return PsiNamedElement.EMPTY_ARRAY;\n    return ResolveUtil.mapToElements(candidates);\n  }","commit_id":"62336e7260e981684cb2cca7209ed7181e72a71e","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"@NotNull\n  public PsiType getType() {\n    GrTypeElement typeElement = ((GrVariableDeclarations) getParent()).getTypeElementGroovy();\n    return typeElement == null ?\n        getManager().getElementFactory().createTypeByFQClassName(\"java.lang.Object\", getResolveScope()) :\n        typeElement.getType();\n  }","id":37717,"modified_method":"@NotNull\n  public PsiType getType() {\n    GrTypeElement typeElement = ((GrVariableDeclarations) getParent()).getTypeElementGroovy();\n    if (typeElement != null) return typeElement.getType();\n\n    GrExpression initializer = getInitializerGroovy();\n    if (initializer != null) {\n      if (!(initializer instanceof GrReferenceExpression) || !initializer.getText().equals(getName())) { //prevent infinite recursion\n        PsiType initializerType = initializer.getType();\n        if (initializerType != null) return initializerType;\n      }\n    }\n\n    return getManager().getElementFactory().createTypeByFQClassName(\"java.lang.Object\", getResolveScope());\n  }","commit_id":"62336e7260e981684cb2cca7209ed7181e72a71e","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static SLanguageId getLanguageId(Language l) {\n    SModuleId moduleId = l.getModuleReference().getModuleId();\n    return getLanguageId(moduleId);\n  }","id":37718,"modified_method":"public static SLanguageId getLanguageId(Language l) {\n    return getLanguageId(l.getModuleReference().getModuleId());\n  }","commit_id":"6e776429cd6f7627bd7d294622751cb02bee2f00","url":"https://github.com/JetBrains/MPS"},{"original_method":"public static SConceptId getConceptId(SNode c) {\n    SNodeId nodeId = c.getNodeId();\n    assert nodeId instanceof Regular;\n    return new SConceptId(LangUtil.getLanguageId(((Language) c.getModel().getModule())),\n        ((int) ((jetbrains.mps.smodel.SNodeId.Regular) nodeId).getId()));\n  }","id":37719,"modified_method":"public static SConceptId getConceptId(SNode c) {\n    SNodeId nodeId = c.getNodeId();\n    assert nodeId instanceof jetbrains.mps.smodel.SNodeId.Regular;\n    return new SConceptId(LangUtil.getLanguageId(((Language) c.getModel().getModule())),\n        ((int) ((jetbrains.mps.smodel.SNodeId.Regular) nodeId).getId()));\n  }","commit_id":"6e776429cd6f7627bd7d294622751cb02bee2f00","url":"https://github.com/JetBrains/MPS"},{"original_method":"public void processAction(\n\t\t\tActionMapping mapping, ActionForm form, PortletConfig config,\n\t\t\tActionRequest req, ActionResponse res)\n\t\tthrows Exception {\n\n\t\tif (!OmniadminUtil.isOmniadmin(req.getRemoteUser())) {\n\t\t\tSessionErrors.add(req, PrincipalException.class.getName());\n\n\t\t\tsetForward(req, \"portlet.admin.error\");\n\n\t\t\treturn;\n\t\t}\n\n\t\tString cmd = ParamUtil.getString(req, Constants.CMD);\n\n\t\tif (cmd.equals(\"autoDeploy\")) {\n\t\t\tautoDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"cacheDb\")) {\n\t\t\tcacheDb();\n\t\t}\n\t\telse if (cmd.equals(\"cacheMulti\")) {\n\t\t\tcacheMulti();\n\t\t}\n\t\telse if (cmd.equals(\"cacheSingle\")) {\n\t\t\tcacheSingle();\n\t\t}\n\t\telse if (cmd.equals(\"gc\")) {\n\t\t\tgc();\n\t\t}\n\t\telse if (cmd.equals(\"hotDeploy\")) {\n\t\t\thotDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"precompile\")) {\n\t\t\tprecompile(req, res);\n\t\t}\n\t\telse if (cmd.equals(\"remoteDeploy\")) {\n\t\t\tremoteDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"shutdown\")) {\n\t\t\tshutdown(req);\n\t\t}\n\t\telse if (cmd.equals(\"updateLogLevels\")) {\n\t\t\tupdateLogLevels(req);\n\t\t}\n\n\t\tsendRedirect(req, res);\n\t}","id":37720,"modified_method":"public void processAction(\n\t\t\tActionMapping mapping, ActionForm form, PortletConfig config,\n\t\t\tActionRequest req, ActionResponse res)\n\t\tthrows Exception {\n\n\t\tif (!OmniadminUtil.isOmniadmin(req.getRemoteUser())) {\n\t\t\tSessionErrors.add(req, PrincipalException.class.getName());\n\n\t\t\tsetForward(req, \"portlet.admin.error\");\n\n\t\t\treturn;\n\t\t}\n\n\t\tString cmd = ParamUtil.getString(req, Constants.CMD);\n\n\t\tif (cmd.equals(\"autoDeploy\")) {\n\t\t\tautoDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"cacheDb\")) {\n\t\t\tcacheDb();\n\t\t}\n\t\telse if (cmd.equals(\"cacheMulti\")) {\n\t\t\tcacheMulti();\n\t\t}\n\t\telse if (cmd.equals(\"cacheSingle\")) {\n\t\t\tcacheSingle();\n\t\t}\n\t\telse if (cmd.equals(\"gc\")) {\n\t\t\tgc();\n\t\t}\n\t\telse if (cmd.equals(\"hotDeploy\")) {\n\t\t\thotDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"precompile\")) {\n\t\t\tprecompile(req, res);\n\t\t}\n\t\telse if (cmd.equals(\"refreshRepository\")) {\n\t\t\trefreshRepository(req);\n\t\t}\n\t\telse if (cmd.equals(\"remoteDeploy\")) {\n\t\t\tremoteDeploy(req);\n\t\t}\n\t\telse if (cmd.equals(\"shutdown\")) {\n\t\t\tshutdown(req);\n\t\t}\n\t\telse if (cmd.equals(\"updateLogLevels\")) {\n\t\t\tupdateLogLevels(req);\n\t\t}\n\n\t\tsendRedirect(req, res);\n\t}","commit_id":"84674f5e65c879be2c9f913631271db3234b781d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public int compareTo(Object o) {\n\n\t\tif (!(o instanceof Plugin)) {\n\t\t\treturn -1;\n\t\t}\n\n\t\tPlugin p = (Plugin) o;\n\n\t\treturn p.getName().compareTo(getName());\n\t}","id":37721,"modified_method":"public int compareTo(Object o) {\n\n\t\tif (!(o instanceof Plugin)) {\n\t\t\treturn -1;\n\t\t}\n\n\t\tPlugin p = (Plugin) o;\n\n\t\treturn getName().compareTo(p.getName());\n\t}","commit_id":"84674f5e65c879be2c9f913631271db3234b781d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public boolean equals(Object o) {\n\n\t\tif (!(o instanceof Plugin)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tPlugin p = (Plugin) o;\n\n\t\treturn p.getModuleId().equals(getModuleId());\n\t}","id":37722,"modified_method":"public boolean equals(Object o) {\n\n\t\tif (!(o instanceof Plugin)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tPlugin p = (Plugin) o;\n\n\t\treturn new EqualsBuilder()\n\t\t\t\t.append(getModuleId(), p.getModuleId())\n\t\t\t\t.append(getRepositoryURL(), p.getRepositoryURL())\n\t\t\t\t.isEquals();\n\t}","commit_id":"84674f5e65c879be2c9f913631271db3234b781d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public static PluginRepository getRepository(String repositoryURL) {\n\n\t\tPluginRepository repository =\n\t\t\t\t(PluginRepository)_repositoryCache.get(repositoryURL);\n\n\t\tif (repository != null) {\n\t\t\treturn repository;\n\t\t}\n\n\t\tString pluginsXmlURL = repositoryURL + StringPool.SLASH +\n\t\t\t\t_PLUGINS_XML_FILENAME;\n\n\t\ttry {\n\t\t\tHttpClient client = new HttpClient();\n\n\t\t\tGetMethod getFile = new GetMethod(pluginsXmlURL);\n\n\t\t\tint responseCode = client.executeMethod(getFile);\n\t\t\tif (responseCode != 200) {\n\t\t\t\tthrow new RuntimeException(\"Cannot download file: \" +\n\t\t\t\t\t\tpluginsXmlURL +\" Response\" + \" code: \" + responseCode);\n\t\t\t}\n\n\t\t\tbyte[] bytes = getFile.getResponseBody();\n\n\t\t\tgetFile.releaseConnection();\n\n\t\t\tif ((bytes != null) && (bytes.length > 0)) {\n\n\t\t\t\trepository =\n\t\t\t\t\t\t_parsePluginsXml(new String(bytes), repositoryURL);\n\n\t\t\t\treturn repository;\n\t\t\t}\n\t\t\telse {\n\n\t\t\t\tthrow new RuntimeException(\"Download error\");\n\t\t\t}\n\t\t}\n\t\tcatch (MalformedURLException mue) {\n\n\t\t\tthrow new RuntimeException(\"Invalid URL:\" + pluginsXmlURL);\n\t\t}\n\t\tcatch (IOException ioe) {\n\n\t\t\tthrow new RuntimeException(\"Communication error: \" + ioe);\n\t\t}\n\t\tcatch (DocumentException de) {\n\n\t\t\tthrow new RuntimeException(\"Parse Error: \" + de);\n\t\t}\n\t}","id":37723,"modified_method":"public static PluginRepository getRepository(String repositoryURL) {\n\n\t\tPluginRepository repository =\n\t\t\t\t(PluginRepository)_repositoryCache.get(repositoryURL);\n\n\t\tif (repository != null) {\n\t\t\treturn repository;\n\t\t}\n\n\t\treturn _loadRepository(repositoryURL);\n\t}","commit_id":"84674f5e65c879be2c9f913631271db3234b781d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"private static PluginRepository _parsePluginsXml(\n\t\t\tString xml, String repositoryURL)\n\t\t\tthrows DocumentException, IOException {\n\n\t\t_log.debug(\"Plugins: \" + xml);\n\n\t\tPluginRepository plugins = new PluginRepository();\n\n\t\tif (xml == null) {\n\t\t\treturn plugins;\n\t\t}\n\n\t\tSAXReader reader = SAXReaderFactory.getInstance();\n\n\t\tDocument doc = reader.read(new XMLSafeReader(xml));\n\n\t\tElement root = doc.getRootElement();\n\n\t\tIterator itr1 = root.elements().iterator();\n\n\t\twhile (itr1.hasNext()) {\n\t\t\tElement pluginElm = (Element)itr1.next();\n\n\t\t\tString pluginName = pluginElm.elementText(\"name\");\n\n\t\t\tif (_log.isDebugEnabled()) {\n\t\t\t\t_log.debug(\"Reading plugin definition \" + pluginName);\n\t\t\t}\n\n\t\t\tPlugin plugin = new PluginImpl();\n\n\t\t\tList liferayVersions = _readElementList(\n\t\t\t\t\tpluginElm.element(\"liferay-versions\"), \"liferay-version\");\n\t\t\tif (!_isCurrentVersionSupported(liferayVersions)) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tplugin.setRepositoryURL(repositoryURL);\n\t\t\tplugin.setTags(liferayVersions);\n\n\t\t\tplugin.setName(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"name\"), plugin.getName()));\n\t\t\tplugin.setModuleId(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"module-id\"), plugin.getModuleId()));\n\t\t\tplugin.setType(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"type\"), plugin.getType()));\n\t\t\tplugin.setShortDescription(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"short-description\"),\n\t\t\t\t\tplugin.getShortDescription()));\n\t\t\tplugin.setLongDescription(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"long-description\"),\n\t\t\t\t\tplugin.getLongDescription()));\n\t\t\tplugin.setPageURL(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"page-url\"), plugin.getPageURL()));\n\t\t\tplugin.setAuthor(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"author\"), plugin.getAuthor()));\n\n\t\t\tplugin.setTags(_readElementList(pluginElm.element(\"tags\"), \"tag\"));\n\n\t\t\tplugin.setLicenses(_readElementList(\n\t\t\t\t\tpluginElm.element(\"licenses\"), \"license\"));\n\n\t\t\tplugins.addPlugin(plugin);\n\t\t}\n\n\t\treturn plugins;\n\t}","id":37724,"modified_method":"private static PluginRepository _parsePluginsXml(\n\t\t\tString xml, String repositoryURL)\n\t\t\tthrows DocumentException, IOException {\n\n\t\t_log.debug(\"Plugins: \" + xml);\n\n\t\tPluginRepository plugins = new PluginRepository();\n\n\t\tif (xml == null) {\n\t\t\treturn plugins;\n\t\t}\n\n\t\tSAXReader reader = SAXReaderFactory.getInstance();\n\n\t\tDocument doc = reader.read(new XMLSafeReader(xml));\n\n\t\tElement root = doc.getRootElement();\n\n\t\tIterator itr1 = root.elements().iterator();\n\n\t\twhile (itr1.hasNext()) {\n\t\t\tElement pluginElm = (Element)itr1.next();\n\n\t\t\tString pluginName = pluginElm.elementText(\"name\");\n\n\t\t\tif (_log.isDebugEnabled()) {\n\t\t\t\t_log.debug(\"Reading plugin definition \" + pluginName);\n\t\t\t}\n\n\t\t\tPlugin plugin = new PluginImpl();\n\n\t\t\tList liferayVersions = _readElementList(\n\t\t\t\t\tpluginElm.element(\"liferay-versions\"), \"liferay-version\");\n\t\t\tif (!_isCurrentVersionSupported(liferayVersions)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tplugin.setLiferayVersions(liferayVersions);\n\n\t\t\tplugin.setRepositoryURL(repositoryURL);\n\t\t\tplugin.setTags(liferayVersions);\n\n\t\t\tplugin.setName(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"name\"), plugin.getName()));\n\t\t\tplugin.setModuleId(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"module-id\"), plugin.getModuleId()));\n\t\t\tplugin.setType(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"type\"), plugin.getType()));\n\t\t\tplugin.setShortDescription(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"short-description\"),\n\t\t\t\t\tplugin.getShortDescription()));\n\t\t\tplugin.setLongDescription(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"long-description\"),\n\t\t\t\t\tplugin.getLongDescription()));\n\t\t\tplugin.setPageURL(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"page-url\"), plugin.getPageURL()));\n\t\t\tplugin.setAuthor(GetterUtil.getString(\n\t\t\t\t\tpluginElm.elementText(\"author\"), plugin.getAuthor()));\n\n\t\t\tplugin.setTags(_readElementList(pluginElm.element(\"tags\"), \"tag\"));\n\n\t\t\tplugin.setLicenses(_readElementList(\n\t\t\t\t\tpluginElm.element(\"licenses\"), \"license\"));\n\n\t\t\tplugins.addPlugin(plugin);\n\t\t}\n\n\t\treturn plugins;\n\t}","commit_id":"84674f5e65c879be2c9f913631271db3234b781d","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n  public int compareTo(ModelRoot o) {\n    int pc = myPath.compareTo(o.myPath);\n    if (pc != 0) return pc;\n\n    pc = myManager.getClassName().compareTo(o.myManager.getClassName());\n    if (pc != 0) return pc;\n\n    return myManager.getModuleId().compareTo(o.myManager.getModuleId());\n  }","id":37725,"modified_method":"@Override\n  public int compareTo(ModelRoot o) {\n    if (myPath == null && o.myPath != null) return -1;\n    if (myPath!=null){\n      int pc = myPath.compareTo(o.myPath);\n      if (pc != 0) return pc;\n    }\n\n    if (myManager == null && o.myManager != null) return -1;\n    if (myManager!=null){\n      String c1 = myManager.getClassName();\n      String c2 = o.myManager.getClassName();\n\n      if (c1 == null && c2 != null) return -1;\n      if (c1!=null){\n        int pc = c1.compareTo(c2);\n        if (pc != 0) return pc;\n      }\n\n      String mi1 = myManager.getModuleId();\n      String mi2 = o.myManager.getModuleId();\n      if (mi1!=null){\n        int pc = mi1.compareTo(mi2);\n        if (pc != 0) return pc;\n      }\n    }\n\n    return 0;\n  }","commit_id":"838637d1e2a85d4be7b5ff1eb112c2a49213e105","url":"https://github.com/JetBrains/MPS"},{"original_method":"@Override\n    public ExtendedURL serialize(TemporaryResourceReference resource)\n        throws SerializeResourceReferenceException, UnsupportedResourceReferenceException\n    {\n        DocumentReference owningReference = (DocumentReference) resource.getOwningEntityReference();\n        return new ExtendedURL(Arrays.asList(owningReference.getLastSpaceReference().getName(),\n            owningReference.getName(), resource.getModuleId(), resource.getResourceName()));\n    }","id":37726,"modified_method":"@Override\n    public ExtendedURL serialize(TemporaryResourceReference resource)\n        throws SerializeResourceReferenceException, UnsupportedResourceReferenceException\n    {\n        DocumentReference owningReference = (DocumentReference) resource.getOwningEntityReference();\n        List<String> segments = new LinkedList<>();\n        segments.add(\"temp\");\n        segments.add(owningReference.getLastSpaceReference().getName());\n        segments.add(owningReference.getName());\n        segments.add(resource.getModuleId());\n        segments.add(resource.getResourceName());\n        ExtendedURL result = new ExtendedURL(segments, new HashMap<String, List<String>>());\n        return this.extendedURLNormalizer.normalize(result);\n    }","commit_id":"2c4ae85bf94223280835aeffa98c87b1545d8ac3","url":"https://github.com/xwiki/xwiki-platform"},{"original_method":"@Test (timeout = 300000)\n  public void testAppendToFileBadArgs() throws Exception {\n    final int inputFileLength = 1024 * 1024;\n    File testRoot = new File(TEST_ROOT_DIR, \"testAppendToFileBadArgsDir\");\n    testRoot.mkdirs();\n\n    File file1 = new File(testRoot, \"file1\");\n    createLocalFileWithRandomData(inputFileLength, file1);\n\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n    cluster.waitActive();\n\n    try {\n      FileSystem dfs = cluster.getFileSystem();\n      assertTrue(\"Not a HDFS: \" + dfs.getUri(),\n                 dfs instanceof DistributedFileSystem);\n\n      // Run appendToFile with insufficient arguments.\n      FsShell shell = new FsShell();\n      shell.setConf(conf);\n      String[] argv = new String[] {\n          \"-appendToFile\", file1.toString() };\n      int res = ToolRunner.run(shell, argv);\n      assertThat(res, not(0));\n\n      // Mix stdin with other input files. Must fail.\n      Path remoteFile = new Path(\"/remoteFile\");\n      argv = new String[] {\n          \"-appendToFile\", file1.toString(), \"-\", remoteFile.toString() };\n      res = ToolRunner.run(shell, argv);\n      assertThat(res, not(0));\n    } finally {\n      cluster.shutdown();\n    }\n  }","id":37727,"modified_method":"@Test (timeout = 300000)\n  public void testAppendToFileBadArgs() throws Exception {\n    final int inputFileLength = 1024 * 1024;\n    File testRoot = new File(TEST_ROOT_DIR, \"testAppendToFileBadArgsDir\");\n    testRoot.mkdirs();\n\n    File file1 = new File(testRoot, \"file1\");\n    createLocalFileWithRandomData(inputFileLength, file1);\n\n    // Run appendToFile with insufficient arguments.\n    FsShell shell = new FsShell();\n    shell.setConf(dfs.getConf());\n    String[] argv = new String[] {\n        \"-appendToFile\", file1.toString() };\n    int res = ToolRunner.run(shell, argv);\n    assertThat(res, not(0));\n\n    // Mix stdin with other input files. Must fail.\n    Path remoteFile = new Path(\"/remoteFile\");\n    argv = new String[] {\n        \"-appendToFile\", file1.toString(), \"-\", remoteFile.toString() };\n    res = ToolRunner.run(shell, argv);\n    assertThat(res, not(0));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testFilePermissions() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n\n    //test chmod on local fs\n    FileSystem fs = FileSystem.getLocal(conf);\n    testChmod(conf, fs,\n              (new File(TEST_ROOT_DIR, \"chmodTest\")).getAbsolutePath());\n\n    conf.set(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, \"true\");\n\n    //test chmod on DFS\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    fs = cluster.getFileSystem();\n    testChmod(conf, fs, \"/tmp/chmodTest\");\n\n    // test chown and chgrp on DFS:\n\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n    fs = cluster.getFileSystem();\n\n    /* For dfs, I am the super user and I can change owner of any file to\n     * anything. \"-R\" option is already tested by chmod test above.\n     */\n\n    String file = \"/tmp/chownTest\";\n    Path path = new Path(file);\n    Path parent = new Path(\"/tmp\");\n    Path root = new Path(\"/\");\n    TestDFSShell.writeFile(fs, path);\n\n    runCmd(shell, \"-chgrp\", \"-R\", \"herbivores\", \"/*\", \"unknownFile*\");\n    confirmOwner(null, \"herbivores\", fs, parent, path);\n\n    runCmd(shell, \"-chgrp\", \"mammals\", file);\n    confirmOwner(null, \"mammals\", fs, path);\n\n    runCmd(shell, \"-chown\", \"-R\", \":reptiles\", \"/\");\n    confirmOwner(null, \"reptiles\", fs, root, parent, path);\n\n    runCmd(shell, \"-chown\", \"python:\", \"/nonExistentFile\", file);\n    confirmOwner(\"python\", \"reptiles\", fs, path);\n\n    runCmd(shell, \"-chown\", \"-R\", \"hadoop:toys\", \"unknownFile\", \"/\");\n    confirmOwner(\"hadoop\", \"toys\", fs, root, parent, path);\n\n    // Test different characters in names\n\n    runCmd(shell, \"-chown\", \"hdfs.user\", file);\n    confirmOwner(\"hdfs.user\", null, fs, path);\n\n    runCmd(shell, \"-chown\", \"_Hdfs.User-10:_hadoop.users--\", file);\n    confirmOwner(\"_Hdfs.User-10\", \"_hadoop.users--\", fs, path);\n\n    runCmd(shell, \"-chown\", \"hdfs/hadoop-core@apache.org:asf-projects\", file);\n    confirmOwner(\"hdfs/hadoop-core@apache.org\", \"asf-projects\", fs, path);\n\n    runCmd(shell, \"-chgrp\", \"hadoop-core@apache.org/100\", file);\n    confirmOwner(null, \"hadoop-core@apache.org/100\", fs, path);\n\n    cluster.shutdown();\n  }","id":37728,"modified_method":"@Test (timeout = 30000)\n  public void testFilePermissions() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n\n    //test chmod on local fs\n    FileSystem fs = FileSystem.getLocal(conf);\n    testChmod(conf, fs,\n              (new File(TEST_ROOT_DIR, \"chmodTest\")).getAbsolutePath());\n\n    conf.set(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, \"true\");\n\n    //test chmod on DFS\n    fs = dfs;\n    conf = dfs.getConf();\n    testChmod(conf, fs, \"/tmp/chmodTest\");\n\n    // test chown and chgrp on DFS:\n\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    /* For dfs, I am the super user and I can change owner of any file to\n     * anything. \"-R\" option is already tested by chmod test above.\n     */\n\n    String file = \"/tmp/chownTest\";\n    Path path = new Path(file);\n    Path parent = new Path(\"/tmp\");\n    Path root = new Path(\"/\");\n    TestDFSShell.writeFile(fs, path);\n\n    runCmd(shell, \"-chgrp\", \"-R\", \"herbivores\", \"/*\", \"unknownFile*\");\n    confirmOwner(null, \"herbivores\", fs, parent, path);\n\n    runCmd(shell, \"-chgrp\", \"mammals\", file);\n    confirmOwner(null, \"mammals\", fs, path);\n\n    runCmd(shell, \"-chown\", \"-R\", \":reptiles\", \"/\");\n    confirmOwner(null, \"reptiles\", fs, root, parent, path);\n\n    runCmd(shell, \"-chown\", \"python:\", \"/nonExistentFile\", file);\n    confirmOwner(\"python\", \"reptiles\", fs, path);\n\n    runCmd(shell, \"-chown\", \"-R\", \"hadoop:toys\", \"unknownFile\", \"/\");\n    confirmOwner(\"hadoop\", \"toys\", fs, root, parent, path);\n\n    // Test different characters in names\n\n    runCmd(shell, \"-chown\", \"hdfs.user\", file);\n    confirmOwner(\"hdfs.user\", null, fs, path);\n\n    runCmd(shell, \"-chown\", \"_Hdfs.User-10:_hadoop.users--\", file);\n    confirmOwner(\"_Hdfs.User-10\", \"_hadoop.users--\", fs, path);\n\n    runCmd(shell, \"-chown\", \"hdfs/hadoop-core@apache.org:asf-projects\", file);\n    confirmOwner(\"hdfs/hadoop-core@apache.org\", \"asf-projects\", fs, path);\n\n    runCmd(shell, \"-chgrp\", \"hadoop-core@apache.org/100\", file);\n    confirmOwner(null, \"hadoop-core@apache.org/100\", fs, path);\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 180000)\n  public void testDuSnapshots() throws IOException {\n    final int replication = 2;\n    final Configuration conf = new HdfsConfiguration();\n    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n        .numDataNodes(replication).build();\n    final DistributedFileSystem dfs = cluster.getFileSystem();\n    final PrintStream psBackup = System.out;\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    final PrintStream psOut = new PrintStream(out);\n    final FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      System.setOut(psOut);\n      cluster.waitActive();\n      final Path parent = new Path(\"/test\");\n      final Path dir = new Path(parent, \"dir\");\n      mkdir(dfs, dir);\n      final Path file = new Path(dir, \"file\");\n      writeFile(dfs, file);\n      final Path file2 = new Path(dir, \"file2\");\n      writeFile(dfs, file2);\n      final Long fileLength = dfs.getFileStatus(file).getLen();\n      final Long fileDiskUsed = fileLength * replication;\n      final Long file2Length = dfs.getFileStatus(file2).getLen();\n      final Long file2DiskUsed = file2Length * replication;\n\n      /*\n       * Construct dir as follows:\n       * /test/dir/file   <- this will later be deleted after snapshot taken.\n       * /test/dir/newfile <- this will be created after snapshot taken.\n       * /test/dir/file2\n       * Snapshot enabled on /test\n       */\n\n      // test -du on /test/dir\n      int ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", dir.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      String returnString = out.toString();\n      LOG.info(\"-du return is:\\n\" + returnString);\n      // Check if size matches as expected\n      assertTrue(returnString.contains(fileLength.toString()));\n      assertTrue(returnString.contains(fileDiskUsed.toString()));\n      assertTrue(returnString.contains(file2Length.toString()));\n      assertTrue(returnString.contains(file2DiskUsed.toString()));\n      out.reset();\n\n      // take a snapshot, then remove file and add newFile\n      final String snapshotName = \"ss1\";\n      final Path snapshotPath = new Path(parent, \".snapshot/\" + snapshotName);\n      dfs.allowSnapshot(parent);\n      assertThat(dfs.createSnapshot(parent, snapshotName), is(snapshotPath));\n      rmr(dfs, file);\n      final Path newFile = new Path(dir, \"newfile\");\n      writeFile(dfs, newFile);\n      final Long newFileLength = dfs.getFileStatus(newFile).getLen();\n      final Long newFileDiskUsed = newFileLength * replication;\n\n      // test -du -s on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-s\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -s return is:\\n\" + returnString);\n      Long combinedLength = fileLength + file2Length + newFileLength;\n      Long combinedDiskUsed = fileDiskUsed + file2DiskUsed + newFileDiskUsed;\n      assertTrue(returnString.contains(combinedLength.toString()));\n      assertTrue(returnString.contains(combinedDiskUsed.toString()));\n      out.reset();\n\n      // test -du on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du return is:\\n\" + returnString);\n      assertTrue(returnString.contains(combinedLength.toString()));\n      assertTrue(returnString.contains(combinedDiskUsed.toString()));\n      out.reset();\n\n      // test -du -s -x on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-s\", \"-x\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -s -x return is:\\n\" + returnString);\n      Long exludeSnapshotLength = file2Length + newFileLength;\n      Long excludeSnapshotDiskUsed = file2DiskUsed + newFileDiskUsed;\n      assertTrue(returnString.contains(exludeSnapshotLength.toString()));\n      assertTrue(returnString.contains(excludeSnapshotDiskUsed.toString()));\n      out.reset();\n\n      // test -du -x on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-x\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -x return is:\\n\" + returnString);\n      assertTrue(returnString.contains(exludeSnapshotLength.toString()));\n      assertTrue(returnString.contains(excludeSnapshotDiskUsed.toString()));\n      out.reset();\n    } finally {\n      System.setOut(psBackup);\n      cluster.shutdown();\n    }\n  }","id":37729,"modified_method":"@Test (timeout = 180000)\n  public void testDuSnapshots() throws IOException {\n    final int replication = 2;\n    final PrintStream psBackup = System.out;\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    final PrintStream psOut = new PrintStream(out);\n    final FsShell shell = new FsShell(dfs.getConf());\n\n    try {\n      System.setOut(psOut);\n      final Path parent = new Path(\"/testDuSnapshots\");\n      final Path dir = new Path(parent, \"dir\");\n      mkdir(dfs, dir);\n      final Path file = new Path(dir, \"file\");\n      writeFile(dfs, file);\n      final Path file2 = new Path(dir, \"file2\");\n      writeFile(dfs, file2);\n      final Long fileLength = dfs.getFileStatus(file).getLen();\n      final Long fileDiskUsed = fileLength * replication;\n      final Long file2Length = dfs.getFileStatus(file2).getLen();\n      final Long file2DiskUsed = file2Length * replication;\n\n      /*\n       * Construct dir as follows:\n       * /test/dir/file   <- this will later be deleted after snapshot taken.\n       * /test/dir/newfile <- this will be created after snapshot taken.\n       * /test/dir/file2\n       * Snapshot enabled on /test\n       */\n\n      // test -du on /test/dir\n      int ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", dir.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      String returnString = out.toString();\n      LOG.info(\"-du return is:\\n\" + returnString);\n      // Check if size matches as expected\n      assertTrue(returnString.contains(fileLength.toString()));\n      assertTrue(returnString.contains(fileDiskUsed.toString()));\n      assertTrue(returnString.contains(file2Length.toString()));\n      assertTrue(returnString.contains(file2DiskUsed.toString()));\n      out.reset();\n\n      // take a snapshot, then remove file and add newFile\n      final String snapshotName = \"ss1\";\n      final Path snapshotPath = new Path(parent, \".snapshot/\" + snapshotName);\n      dfs.allowSnapshot(parent);\n      assertThat(dfs.createSnapshot(parent, snapshotName), is(snapshotPath));\n      rmr(dfs, file);\n      final Path newFile = new Path(dir, \"newfile\");\n      writeFile(dfs, newFile);\n      final Long newFileLength = dfs.getFileStatus(newFile).getLen();\n      final Long newFileDiskUsed = newFileLength * replication;\n\n      // test -du -s on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-s\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -s return is:\\n\" + returnString);\n      Long combinedLength = fileLength + file2Length + newFileLength;\n      Long combinedDiskUsed = fileDiskUsed + file2DiskUsed + newFileDiskUsed;\n      assertTrue(returnString.contains(combinedLength.toString()));\n      assertTrue(returnString.contains(combinedDiskUsed.toString()));\n      out.reset();\n\n      // test -du on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du return is:\\n\" + returnString);\n      assertTrue(returnString.contains(combinedLength.toString()));\n      assertTrue(returnString.contains(combinedDiskUsed.toString()));\n      out.reset();\n\n      // test -du -s -x on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-s\", \"-x\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -s -x return is:\\n\" + returnString);\n      Long exludeSnapshotLength = file2Length + newFileLength;\n      Long excludeSnapshotDiskUsed = file2DiskUsed + newFileDiskUsed;\n      assertTrue(returnString.contains(exludeSnapshotLength.toString()));\n      assertTrue(returnString.contains(excludeSnapshotDiskUsed.toString()));\n      out.reset();\n\n      // test -du -x on /test\n      ret = -1;\n      try {\n        ret = shell.run(new String[] {\"-du\", \"-x\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, ret);\n      returnString = out.toString();\n      LOG.info(\"-du -x return is:\\n\" + returnString);\n      assertTrue(returnString.contains(exludeSnapshotLength.toString()));\n      assertTrue(returnString.contains(excludeSnapshotDiskUsed.toString()));\n      out.reset();\n    } finally {\n      System.setOut(psBackup);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   * Test chmod.\n   */\n  void testChmod(Configuration conf, FileSystem fs, String chmodDir)\n                                                    throws IOException {\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      //first make dir\n      Path dir = new Path(chmodDir);\n      fs.delete(dir, true);\n      fs.mkdirs(dir);\n\n      confirmPermissionChange(/* Setting */ \"u+rwx,g=rw,o-rwx\",\n                             /* Should give */ \"rwxrw----\", fs, shell, dir);\n\n      //create an empty file\n      Path file = new Path(chmodDir, \"file\");\n      TestDFSShell.writeFile(fs, file);\n\n      //test octal mode\n      confirmPermissionChange(\"644\", \"rw-r--r--\", fs, shell, file);\n\n      //test recursive\n      runCmd(shell, \"-chmod\", \"-R\", \"a+rwX\", chmodDir);\n      assertEquals(\"rwxrwxrwx\",\n          fs.getFileStatus(dir).getPermission().toString());\n      assertEquals(\"rw-rw-rw-\",\n          fs.getFileStatus(file).getPermission().toString());\n\n      // Skip \"sticky bit\" tests on Windows.\n      //\n      if (!Path.WINDOWS) {\n        // test sticky bit on directories\n        Path dir2 = new Path(dir, \"stickybit\");\n        fs.mkdirs(dir2);\n        LOG.info(\"Testing sticky bit on: \" + dir2);\n        LOG.info(\"Sticky bit directory initial mode: \" +\n            fs.getFileStatus(dir2).getPermission());\n\n        confirmPermissionChange(\"u=rwx,g=rx,o=rx\", \"rwxr-xr-x\", fs, shell, dir2);\n        // sticky bit explicit set\n        confirmPermissionChange(\"+t\", \"rwxr-xr-t\", fs, shell, dir2);\n        // sticky bit explicit reset\n        confirmPermissionChange(\"-t\", \"rwxr-xr-x\", fs, shell, dir2);\n        confirmPermissionChange(\"=t\", \"--------T\", fs, shell, dir2);\n        // reset all permissions\n        confirmPermissionChange(\"0000\", \"---------\", fs, shell, dir2);\n        // turn on rw permissions for all\n        confirmPermissionChange(\"1666\", \"rw-rw-rwT\", fs, shell, dir2);\n        // sticky bit explicit set along with x permission\n        confirmPermissionChange(\"1777\", \"rwxrwxrwt\", fs, shell, dir2);\n        // sticky bit explicit reset\n        confirmPermissionChange(\"0777\", \"rwxrwxrwx\", fs, shell, dir2);\n        // sticky bit explicit set\n        confirmPermissionChange(\"1777\", \"rwxrwxrwt\", fs, shell, dir2);\n        // sticky bit implicit reset\n        confirmPermissionChange(\"777\", \"rwxrwxrwx\", fs, shell, dir2);\n        fs.delete(dir2, true);\n      } else {\n        LOG.info(\"Skipped sticky bit tests on Windows\");\n      }\n\n      fs.delete(dir, true);\n\n    } finally {\n      try {\n        fs.close();\n        shell.close();\n      } catch (IOException ignored) {}\n    }\n  }","id":37730,"modified_method":"/**\n   * Test chmod.\n   */\n  void testChmod(Configuration conf, FileSystem fs, String chmodDir)\n                                                    throws IOException {\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      //first make dir\n      Path dir = new Path(chmodDir);\n      fs.delete(dir, true);\n      fs.mkdirs(dir);\n\n      confirmPermissionChange(/* Setting */ \"u+rwx,g=rw,o-rwx\",\n                             /* Should give */ \"rwxrw----\", fs, shell, dir);\n\n      //create an empty file\n      Path file = new Path(chmodDir, \"file\");\n      TestDFSShell.writeFile(fs, file);\n\n      //test octal mode\n      confirmPermissionChange(\"644\", \"rw-r--r--\", fs, shell, file);\n\n      //test recursive\n      runCmd(shell, \"-chmod\", \"-R\", \"a+rwX\", chmodDir);\n      assertEquals(\"rwxrwxrwx\",\n          fs.getFileStatus(dir).getPermission().toString());\n      assertEquals(\"rw-rw-rw-\",\n          fs.getFileStatus(file).getPermission().toString());\n\n      // Skip \"sticky bit\" tests on Windows.\n      //\n      if (!Path.WINDOWS) {\n        // test sticky bit on directories\n        Path dir2 = new Path(dir, \"stickybit\");\n        fs.mkdirs(dir2);\n        LOG.info(\"Testing sticky bit on: \" + dir2);\n        LOG.info(\"Sticky bit directory initial mode: \" +\n            fs.getFileStatus(dir2).getPermission());\n\n        confirmPermissionChange(\"u=rwx,g=rx,o=rx\", \"rwxr-xr-x\", fs, shell, dir2);\n        // sticky bit explicit set\n        confirmPermissionChange(\"+t\", \"rwxr-xr-t\", fs, shell, dir2);\n        // sticky bit explicit reset\n        confirmPermissionChange(\"-t\", \"rwxr-xr-x\", fs, shell, dir2);\n        confirmPermissionChange(\"=t\", \"--------T\", fs, shell, dir2);\n        // reset all permissions\n        confirmPermissionChange(\"0000\", \"---------\", fs, shell, dir2);\n        // turn on rw permissions for all\n        confirmPermissionChange(\"1666\", \"rw-rw-rwT\", fs, shell, dir2);\n        // sticky bit explicit set along with x permission\n        confirmPermissionChange(\"1777\", \"rwxrwxrwt\", fs, shell, dir2);\n        // sticky bit explicit reset\n        confirmPermissionChange(\"0777\", \"rwxrwxrwx\", fs, shell, dir2);\n        // sticky bit explicit set\n        confirmPermissionChange(\"1777\", \"rwxrwxrwt\", fs, shell, dir2);\n        // sticky bit implicit reset\n        confirmPermissionChange(\"777\", \"rwxrwxrwx\", fs, shell, dir2);\n        fs.delete(dir2, true);\n      } else {\n        LOG.info(\"Skipped sticky bit tests on Windows\");\n      }\n\n      fs.delete(dir, true);\n\n    } finally {\n      try {\n        shell.close();\n      } catch (IOException ignored) {}\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testZeroSizeFile() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    assertTrue(\"Not a HDFS: \"+fs.getUri(),\n               fs instanceof DistributedFileSystem);\n    final DistributedFileSystem dfs = (DistributedFileSystem)fs;\n\n    try {\n      //create a zero size file\n      final File f1 = new File(TEST_ROOT_DIR, \"f1\");\n      assertTrue(!f1.exists());\n      assertTrue(f1.createNewFile());\n      assertTrue(f1.exists());\n      assertTrue(f1.isFile());\n      assertEquals(0L, f1.length());\n\n      //copy to remote\n      final Path root = mkdir(dfs, new Path(\"/test/zeroSizeFile\"));\n      final Path remotef = new Path(root, \"dst\");\n      show(\"copy local \" + f1 + \" to remote \" + remotef);\n      dfs.copyFromLocalFile(false, false, new Path(f1.getPath()), remotef);\n\n      //getBlockSize() should not throw exception\n      show(\"Block size = \" + dfs.getFileStatus(remotef).getBlockSize());\n\n      //copy back\n      final File f2 = new File(TEST_ROOT_DIR, \"f2\");\n      assertTrue(!f2.exists());\n      dfs.copyToLocalFile(remotef, new Path(f2.getPath()));\n      assertTrue(f2.exists());\n      assertTrue(f2.isFile());\n      assertEquals(0L, f2.length());\n\n      f1.delete();\n      f2.delete();\n    } finally {\n      try {dfs.close();} catch (Exception e) {}\n      cluster.shutdown();\n    }\n  }","id":37731,"modified_method":"@Test (timeout = 30000)\n  public void testZeroSizeFile() throws IOException {\n    //create a zero size file\n    final File f1 = new File(TEST_ROOT_DIR, \"f1\");\n    assertTrue(!f1.exists());\n    assertTrue(f1.createNewFile());\n    assertTrue(f1.exists());\n    assertTrue(f1.isFile());\n    assertEquals(0L, f1.length());\n\n    //copy to remote\n    final Path root = mkdir(dfs, new Path(\"/testZeroSizeFile/zeroSizeFile\"));\n    final Path remotef = new Path(root, \"dst\");\n    show(\"copy local \" + f1 + \" to remote \" + remotef);\n    dfs.copyFromLocalFile(false, false, new Path(f1.getPath()), remotef);\n\n    //getBlockSize() should not throw exception\n    show(\"Block size = \" + dfs.getFileStatus(remotef).getBlockSize());\n\n    //copy back\n    final File f2 = new File(TEST_ROOT_DIR, \"f2\");\n    assertTrue(!f2.exists());\n    dfs.copyToLocalFile(remotef, new Path(f2.getPath()));\n    assertTrue(f2.exists());\n    assertTrue(f2.isFile());\n    assertEquals(0L, f2.length());\n\n    f1.delete();\n    f2.delete();\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testChmodReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell();\n      shell.setConf(conf);\n      runCmd(shell, \"-chmod\", \"777\", \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n      cluster.shutdown();\n    }\n  }","id":37732,"modified_method":"@Test (timeout = 30000)\n  public void testChmodReserved() throws IOException {\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell(dfs.getConf());\n      runCmd(shell, \"-chmod\", \"777\", \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   * Test that -tail displays last kilobyte of the file to stdout.\n   */\n  @Test (timeout = 30000)\n  public void testTail() throws Exception {\n    final int blockSize = 1024;\n    final int fileLen = 5 * blockSize;\n    final Configuration conf = new Configuration();\n    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, blockSize);\n\n    try (MiniDFSCluster cluster =\n             new MiniDFSCluster.Builder(conf).numDataNodes(3).build()) {\n      cluster.waitActive();\n      final DistributedFileSystem dfs = cluster.getFileSystem();\n\n      // create a text file with multiple KB bytes (and multiple blocks)\n      final Path testFile = new Path(\"testTail\", \"file1\");\n      final String text = RandomStringUtils.randomAscii(fileLen);\n      try (OutputStream pout = dfs.create(testFile)) {\n        pout.write(text.getBytes());\n      }\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setOut(new PrintStream(out));\n      final String[] argv = new String[]{\"-tail\", testFile.toString()};\n      final int ret = ToolRunner.run(new FsShell(conf), argv);\n\n      assertEquals(Arrays.toString(argv) + \" returned \" + ret, 0, ret);\n      assertEquals(\"-tail returned \" + out.size() + \" bytes data, expected 1KB\",\n          1024, out.size());\n      // tailed out last 1KB of the file content\n      assertArrayEquals(\"Tail output doesn't match input\",\n          text.substring(fileLen - 1024).getBytes(), out.toByteArray());\n      out.reset();\n    }\n  }","id":37733,"modified_method":"/**\n   * Test that -tail displays last kilobyte of the file to stdout.\n   */\n  @Test (timeout = 30000)\n  public void testTail() throws Exception {\n    final int fileLen = 5 * BLOCK_SIZE;\n\n    // create a text file with multiple KB bytes (and multiple blocks)\n    final Path testFile = new Path(\"testTail\", \"file1\");\n    final String text = RandomStringUtils.randomAscii(fileLen);\n    try (OutputStream pout = dfs.create(testFile)) {\n      pout.write(text.getBytes());\n    }\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    System.setOut(new PrintStream(out));\n    final String[] argv = new String[]{\"-tail\", testFile.toString()};\n    final int ret = ToolRunner.run(new FsShell(dfs.getConf()), argv);\n\n    assertEquals(Arrays.toString(argv) + \" returned \" + ret, 0, ret);\n    assertEquals(\"-tail returned \" + out.size() + \" bytes data, expected 1KB\",\n        1024, out.size());\n    // tailed out last 1KB of the file content\n    assertArrayEquals(\"Tail output doesn't match input\",\n        text.substring(fileLen - 1024).getBytes(), out.toByteArray());\n    out.reset();\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   *\n   * Test to make sure that user namespace xattrs can be set only if path has\n   * access and for sticky directorries, only owner/privileged user can write.\n   * Trusted namespace xattrs can be set only with privileged users.\n   *\n   * As user1: Create a directory (/foo) as user1, chown it to user1 (and\n   * user1's group), grant rwx to \"other\".\n   *\n   * As user2: Set an xattr (should pass with path access).\n   *\n   * As user1: Set an xattr (should pass).\n   *\n   * As user2: Read the xattr (should pass). Remove the xattr (should pass with\n   * path access).\n   *\n   * As user1: Read the xattr (should pass). Remove the xattr (should pass).\n   *\n   * As user1: Change permissions only to owner\n   *\n   * As User2: Set an Xattr (Should fail set with no path access) Remove an\n   * Xattr (Should fail with no path access)\n   *\n   * As SuperUser: Set an Xattr with Trusted (Should pass)\n   */\n  @Test (timeout = 30000)\n  public void testSetXAttrPermissionAsDifferentOwner() throws Exception {\n    final String USER1 = \"user1\";\n    final String GROUP1 = \"supergroup\";\n    final UserGroupInformation user1 = UserGroupInformation.\n        createUserForTesting(USER1, new String[] {GROUP1});\n    final UserGroupInformation user2 = UserGroupInformation.\n        createUserForTesting(\"user2\", new String[] {\"mygroup2\"});\n    final UserGroupInformation SUPERUSER = UserGroupInformation.getCurrentUser();\n    MiniDFSCluster cluster = null;\n    PrintStream bak = null;\n    try {\n      final Configuration conf = new HdfsConfiguration();\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n      cluster.waitActive();\n\n      final FileSystem fs = cluster.getFileSystem();\n      fs.setOwner(new Path(\"/\"), USER1, GROUP1);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(conf);\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      //Test 1.  Let user1 be owner for /foo\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-mkdir\", \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      //Test 2. Give access to others\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Give access to \"other\"\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-chmod\", \"707\", \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 3. Should be allowed to write xattr if there is a path access to\n      // user (user2).\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      //Test 4. There should be permission to write xattr for\n      // the owning user with write permissions.\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 5. There should be permission to read non-owning user (user2) if\n      // there is path access to that user and also can remove.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Read\n          int ret = ToolRunner.run(fshell, new String[] { \"-getfattr\", \"-n\",\n              \"user.a1\", \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          // Remove\n          ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-x\",\n              \"user.a1\", \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 6. There should be permission to read/remove for\n      // the owning user with path access.\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          return null;\n        }\n      });\n\n      // Test 7. Change permission to have path access only to owner(user1)\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Give access to \"other\"\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-chmod\", \"700\", \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 8. There should be no permissions to set for\n      // the non-owning user with no path access.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-n\",\n              \"user.a2\", \"/foo\" });\n          assertEquals(\"Returned should be 1\", 1, ret);\n          final String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 9. There should be no permissions to remove for\n      // the non-owning user with no path access.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-x\",\n              \"user.a2\", \"/foo\" });\n          assertEquals(\"Returned should be 1\", 1, ret);\n          final String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 10. Superuser should be allowed to set with trusted namespace\n      SUPERUSER.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-n\",\n              \"trusted.a3\", \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n      if (cluster != null) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37734,"modified_method":"/**\n   *\n   * Test to make sure that user namespace xattrs can be set only if path has\n   * access and for sticky directorries, only owner/privileged user can write.\n   * Trusted namespace xattrs can be set only with privileged users.\n   *\n   * As user1: Create a directory (/foo) as user1, chown it to user1 (and\n   * user1's group), grant rwx to \"other\".\n   *\n   * As user2: Set an xattr (should pass with path access).\n   *\n   * As user1: Set an xattr (should pass).\n   *\n   * As user2: Read the xattr (should pass). Remove the xattr (should pass with\n   * path access).\n   *\n   * As user1: Read the xattr (should pass). Remove the xattr (should pass).\n   *\n   * As user1: Change permissions only to owner\n   *\n   * As User2: Set an Xattr (Should fail set with no path access) Remove an\n   * Xattr (Should fail with no path access)\n   *\n   * As SuperUser: Set an Xattr with Trusted (Should pass)\n   */\n  @Test (timeout = 30000)\n  public void testSetXAttrPermissionAsDifferentOwner() throws Exception {\n    final String root = \"/testSetXAttrPermissionAsDifferentOwner\";\n    final String USER1 = \"user1\";\n    final String GROUP1 = \"supergroup\";\n    final UserGroupInformation user1 = UserGroupInformation.\n        createUserForTesting(USER1, new String[] {GROUP1});\n    final UserGroupInformation user2 = UserGroupInformation.\n        createUserForTesting(\"user2\", new String[] {\"mygroup2\"});\n    final UserGroupInformation SUPERUSER = UserGroupInformation.getCurrentUser();\n    PrintStream bak = null;\n    try {\n      dfs.mkdirs(new Path(root));\n      dfs.setOwner(new Path(root), USER1, GROUP1);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(dfs.getConf());\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      //Test 1.  Let user1 be owner for /foo\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-mkdir\", root + \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      //Test 2. Give access to others\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Give access to \"other\"\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-chmod\", \"707\", root + \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 3. Should be allowed to write xattr if there is a path access to\n      // user (user2).\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", root + \"/foo\"});\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      //Test 4. There should be permission to write xattr for\n      // the owning user with write permissions.\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", root + \"/foo\"});\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 5. There should be permission to read non-owning user (user2) if\n      // there is path access to that user and also can remove.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Read\n          int ret = ToolRunner.run(fshell, new String[] { \"-getfattr\", \"-n\",\n              \"user.a1\", root + \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          // Remove\n          ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-x\",\n              \"user.a1\", root + \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 6. There should be permission to read/remove for\n      // the owning user with path access.\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          return null;\n        }\n      });\n\n      // Test 7. Change permission to have path access only to owner(user1)\n      user1.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Give access to \"other\"\n          final int ret = ToolRunner.run(fshell, new String[]{\n              \"-chmod\", \"700\", root + \"/foo\"});\n          assertEquals(\"Return should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 8. There should be no permissions to set for\n      // the non-owning user with no path access.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-n\",\n              \"user.a2\", root + \"/foo\" });\n          assertEquals(\"Returned should be 1\", 1, ret);\n          final String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 9. There should be no permissions to remove for\n      // the non-owning user with no path access.\n      user2.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-x\",\n              \"user.a2\", root + \"/foo\" });\n          assertEquals(\"Returned should be 1\", 1, ret);\n          final String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      // Test 10. Superuser should be allowed to set with trusted namespace\n      SUPERUSER.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // set\n          int ret = ToolRunner.run(fshell, new String[] { \"-setfattr\", \"-n\",\n              \"trusted.a3\", root + \"/foo\" });\n          assertEquals(\"Returned should be 0\", 0, ret);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testChownReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell();\n      shell.setConf(conf);\n      runCmd(shell, \"-chown\", \"user1\", \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n      cluster.shutdown();\n    }\n  }","id":37735,"modified_method":"@Test (timeout = 30000)\n  public void testChownReserved() throws IOException {\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell(dfs.getConf());\n      runCmd(shell, \"-chown\", \"user1\", \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test(timeout = 30000)\n  public void testTotalSizeOfAllFiles() throws Exception {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = null;\n    try {\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n      FileSystem fs = cluster.getFileSystem();\n      // create file under root\n      FSDataOutputStream File1 = fs.create(new Path(\"/File1\"));\n      File1.write(\"hi\".getBytes());\n      File1.close();\n      // create file under sub-folder\n      FSDataOutputStream File2 = fs.create(new Path(\"/Folder1/File2\"));\n      File2.write(\"hi\".getBytes());\n      File2.close();\n      // getUsed() should return total length of all the files in Filesystem\n      assertEquals(4, fs.getUsed());\n    } finally {\n      if (cluster != null) {\n        cluster.shutdown();\n        cluster = null;\n      }\n    }\n  }","id":37736,"modified_method":"@Test(timeout = 30000)\n  public void testTotalSizeOfAllFiles() throws Exception {\n    final Path root = new Path(\"/testTotalSizeOfAllFiles\");\n    dfs.mkdirs(root);\n    // create file under root\n    FSDataOutputStream File1 = dfs.create(new Path(root, \"File1\"));\n    File1.write(\"hi\".getBytes());\n    File1.close();\n    // create file under sub-folder\n    FSDataOutputStream File2 = dfs.create(new Path(root, \"Folder1/File2\"));\n    File2.write(\"hi\".getBytes());\n    File2.close();\n    // getUsed() should return total length of all the files in Filesystem\n    assertEquals(4, dfs.getUsed(root));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testRecursiveRm() throws IOException {\n\t  Configuration conf = new HdfsConfiguration();\n\t  MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n\t  FileSystem fs = cluster.getFileSystem();\n\t  assertTrue(\"Not a HDFS: \" + fs.getUri(),\n        fs instanceof DistributedFileSystem);\n\t  try {\n      fs.mkdirs(new Path(new Path(\"parent\"), \"child\"));\n      try {\n        fs.delete(new Path(\"parent\"), false);\n        assert(false); // should never reach here.\n      } catch(IOException e) {\n         //should have thrown an exception\n      }\n      try {\n        fs.delete(new Path(\"parent\"), true);\n      } catch(IOException e) {\n        assert(false);\n      }\n    } finally {\n      try { fs.close();}catch(IOException e){};\n      cluster.shutdown();\n    }\n  }","id":37737,"modified_method":"@Test (timeout = 30000)\n  public void testRecursiveRm() throws IOException {\n    final Path parent = new Path(\"/testRecursiveRm\", \"parent\");\n    final Path child = new Path(parent, \"child\");\n    dfs.mkdirs(child);\n    try {\n      dfs.delete(parent, false);\n      fail(\"Should have failed because dir is not empty\");\n    } catch(IOException e) {\n       //should have thrown an exception\n    }\n    dfs.delete(parent, true);\n    assertFalse(dfs.exists(parent));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testText() throws Exception {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = null;\n    try {\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n      final FileSystem dfs = cluster.getFileSystem();\n      textTest(new Path(\"/texttest\").makeQualified(dfs.getUri(),\n            dfs.getWorkingDirectory()), conf);\n\n      conf.set(\"fs.defaultFS\", dfs.getUri().toString());\n      final FileSystem lfs = FileSystem.getLocal(conf);\n      textTest(new Path(TEST_ROOT_DIR, \"texttest\").makeQualified(lfs.getUri(),\n            lfs.getWorkingDirectory()), conf);\n    } finally {\n      if (null != cluster) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37738,"modified_method":"@Test (timeout = 30000)\n  public void testText() throws Exception {\n    final Configuration conf = dfs.getConf();\n    textTest(new Path(\"/texttest\").makeQualified(dfs.getUri(),\n          dfs.getWorkingDirectory()), conf);\n\n    final FileSystem lfs = FileSystem.getLocal(conf);\n    textTest(new Path(TEST_ROOT_DIR, \"texttest\").makeQualified(lfs.getUri(),\n          lfs.getWorkingDirectory()), conf);\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/** check command error outputs and exit statuses. */\n  @Test (timeout = 30000)\n  public void testErrOutPut() throws Exception {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = null;\n    PrintStream bak = null;\n    try {\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n      FileSystem srcFs = cluster.getFileSystem();\n      Path root = new Path(\"/nonexistentfile\");\n      bak = System.err;\n      ByteArrayOutputStream out = new ByteArrayOutputStream();\n      PrintStream tmp = new PrintStream(out);\n      System.setErr(tmp);\n      String[] argv = new String[2];\n      argv[0] = \"-cat\";\n      argv[1] = root.toUri().getPath();\n      int ret = ToolRunner.run(new FsShell(), argv);\n      assertEquals(\" -cat returned 1 \", 1, ret);\n      String returned = out.toString();\n      assertTrue(\"cat does not print exceptions \",\n          (returned.lastIndexOf(\"Exception\") == -1));\n      out.reset();\n      argv[0] = \"-rm\";\n      argv[1] = root.toString();\n      FsShell shell = new FsShell();\n      shell.setConf(conf);\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -rm returned 1 \", 1, ret);\n      returned = out.toString();\n      out.reset();\n      assertTrue(\"rm prints reasonable error \",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      argv[0] = \"-rmr\";\n      argv[1] = root.toString();\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -rmr returned 1\", 1, ret);\n      returned = out.toString();\n      assertTrue(\"rmr prints reasonable error \",\n    \t\t  (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-du\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -du prints reasonable error \",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-dus\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -dus prints reasonable error\",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/nonexistenfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -ls does not return Found 0 items\",\n          (returned.lastIndexOf(\"Found 0\") == -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -lsr should fail \", 1, ret);\n      out.reset();\n      srcFs.mkdirs(new Path(\"/testdir\"));\n      argv[0] = \"-ls\";\n      argv[1] = \"/testdir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -ls does not print out anything \",\n          (returned.lastIndexOf(\"Found 0\") == -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/user/nonxistant/*\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -ls on nonexistent glob returns 1\", 1, ret);\n      out.reset();\n      argv[0] = \"-mkdir\";\n      argv[1] = \"/testdir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -mkdir returned 1 \", 1, ret);\n      assertTrue(\" -mkdir returned File exists\",\n          (returned.lastIndexOf(\"File exists\") != -1));\n      Path testFile = new Path(\"/testfile\");\n      OutputStream outtmp = srcFs.create(testFile);\n      outtmp.write(testFile.toString().getBytes());\n      outtmp.close();\n      out.reset();\n      argv[0] = \"-mkdir\";\n      argv[1] = \"/testfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -mkdir returned 1\", 1, ret);\n      assertTrue(\" -mkdir returned this is a file \",\n          (returned.lastIndexOf(\"not a directory\") != -1));\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"file\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"mv failed to rename\", 1,  ret);\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"/testfiletest\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\"no output from rename\",\n          (returned.lastIndexOf(\"Renamed\") == -1));\n      out.reset();\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"/testfiletmp\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" unix like output\",\n          (returned.lastIndexOf(\"No such file or\") != -1));\n      out.reset();\n      argv = new String[1];\n      argv[0] = \"-du\";\n      srcFs.mkdirs(srcFs.getHomeDirectory());\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" no error \", 0, ret);\n      assertTrue(\"empty path specified\",\n          (returned.lastIndexOf(\"empty string\") == -1));\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-test\";\n      argv[1] = \"-d\";\n      argv[2] = \"/no/such/dir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -test -d wrong result \", 1, ret);\n      assertTrue(returned.isEmpty());\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n      if (cluster != null) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37739,"modified_method":"/** check command error outputs and exit statuses. */\n  @Test (timeout = 30000)\n  public void testErrOutPut() throws Exception {\n    PrintStream bak = null;\n    try {\n      Path root = new Path(\"/nonexistentfile\");\n      bak = System.err;\n      ByteArrayOutputStream out = new ByteArrayOutputStream();\n      PrintStream tmp = new PrintStream(out);\n      System.setErr(tmp);\n      String[] argv = new String[2];\n      argv[0] = \"-cat\";\n      argv[1] = root.toUri().getPath();\n      int ret = ToolRunner.run(new FsShell(), argv);\n      assertEquals(\" -cat returned 1 \", 1, ret);\n      String returned = out.toString();\n      assertTrue(\"cat does not print exceptions \",\n          (returned.lastIndexOf(\"Exception\") == -1));\n      out.reset();\n      argv[0] = \"-rm\";\n      argv[1] = root.toString();\n      FsShell shell = new FsShell(dfs.getConf());\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -rm returned 1 \", 1, ret);\n      returned = out.toString();\n      out.reset();\n      assertTrue(\"rm prints reasonable error \",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      argv[0] = \"-rmr\";\n      argv[1] = root.toString();\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -rmr returned 1\", 1, ret);\n      returned = out.toString();\n      assertTrue(\"rmr prints reasonable error \",\n    \t\t  (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-du\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -du prints reasonable error \",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-dus\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -dus prints reasonable error\",\n          (returned.lastIndexOf(\"No such file or directory\") != -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/nonexistenfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -ls does not return Found 0 items\",\n          (returned.lastIndexOf(\"Found 0\") == -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/nonexistentfile\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -lsr should fail \", 1, ret);\n      out.reset();\n      dfs.mkdirs(new Path(\"/testdir\"));\n      argv[0] = \"-ls\";\n      argv[1] = \"/testdir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" -ls does not print out anything \",\n          (returned.lastIndexOf(\"Found 0\") == -1));\n      out.reset();\n      argv[0] = \"-ls\";\n      argv[1] = \"/user/nonxistant/*\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" -ls on nonexistent glob returns 1\", 1, ret);\n      out.reset();\n      argv[0] = \"-mkdir\";\n      argv[1] = \"/testdir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -mkdir returned 1 \", 1, ret);\n      assertTrue(\" -mkdir returned File exists\",\n          (returned.lastIndexOf(\"File exists\") != -1));\n      Path testFile = new Path(\"/testfile\");\n      OutputStream outtmp = dfs.create(testFile);\n      outtmp.write(testFile.toString().getBytes());\n      outtmp.close();\n      out.reset();\n      argv[0] = \"-mkdir\";\n      argv[1] = \"/testfile\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -mkdir returned 1\", 1, ret);\n      assertTrue(\" -mkdir returned this is a file \",\n          (returned.lastIndexOf(\"not a directory\") != -1));\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"/no-such-dir/file\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"mv failed to rename\", 1,  ret);\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"/testfiletest\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\"no output from rename\",\n          (returned.lastIndexOf(\"Renamed\") == -1));\n      out.reset();\n      argv[0] = \"-mv\";\n      argv[1] = \"/testfile\";\n      argv[2] = \"/testfiletmp\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertTrue(\" unix like output\",\n          (returned.lastIndexOf(\"No such file or\") != -1));\n      out.reset();\n      argv = new String[1];\n      argv[0] = \"-du\";\n      dfs.mkdirs(dfs.getHomeDirectory());\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" no error \", 0, ret);\n      assertTrue(\"empty path specified\",\n          (returned.lastIndexOf(\"empty string\") == -1));\n      out.reset();\n      argv = new String[3];\n      argv[0] = \"-test\";\n      argv[1] = \"-d\";\n      argv[2] = \"/no/such/dir\";\n      ret = ToolRunner.run(shell, argv);\n      returned = out.toString();\n      assertEquals(\" -test -d wrong result \", 1, ret);\n      assertTrue(returned.isEmpty());\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testSymLinkReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    try {\n      fs.createSymlink(new Path(\"/.reserved\"), new Path(\"/rl1\"), false);\n      fail(\"Can't create symlink to /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid target name: /.reserved\"));\n    }\n    cluster.shutdown();\n  }","id":37740,"modified_method":"@Test (timeout = 30000)\n  public void testSymLinkReserved() throws IOException {\n    try {\n      dfs.createSymlink(new Path(\"/.reserved\"), new Path(\"/rl1\"), false);\n      fail(\"Can't create symlink to /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid target name: /.reserved\"));\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testPut() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    assertTrue(\"Not a HDFS: \"+fs.getUri(),\n               fs instanceof DistributedFileSystem);\n    final DistributedFileSystem dfs = (DistributedFileSystem)fs;\n\n    try {\n      // remove left over crc files:\n      new File(TEST_ROOT_DIR, \".f1.crc\").delete();\n      new File(TEST_ROOT_DIR, \".f2.crc\").delete();\n      final File f1 = createLocalFile(new File(TEST_ROOT_DIR, \"f1\"));\n      final File f2 = createLocalFile(new File(TEST_ROOT_DIR, \"f2\"));\n\n      final Path root = mkdir(dfs, new Path(\"/test/put\"));\n      final Path dst = new Path(root, \"dst\");\n\n      show(\"begin\");\n\n      final Thread copy2ndFileThread = new Thread() {\n        @Override\n        public void run() {\n          try {\n            show(\"copy local \" + f2 + \" to remote \" + dst);\n            dfs.copyFromLocalFile(false, false, new Path(f2.getPath()), dst);\n          } catch (IOException ioe) {\n            show(\"good \" + StringUtils.stringifyException(ioe));\n            return;\n          }\n          //should not be here, must got IOException\n          assertTrue(false);\n        }\n      };\n\n      //use SecurityManager to pause the copying of f1 and begin copying f2\n      SecurityManager sm = System.getSecurityManager();\n      System.out.println(\"SecurityManager = \" + sm);\n      System.setSecurityManager(new SecurityManager() {\n        private boolean firstTime = true;\n\n        @Override\n        public void checkPermission(Permission perm) {\n          if (firstTime) {\n            Thread t = Thread.currentThread();\n            if (!t.toString().contains(\"DataNode\")) {\n              String s = \"\" + Arrays.asList(t.getStackTrace());\n              if (s.contains(\"FileUtil.copyContent\")) {\n                //pause at FileUtil.copyContent\n\n                firstTime = false;\n                copy2ndFileThread.start();\n                try {Thread.sleep(5000);} catch (InterruptedException e) {}\n              }\n            }\n          }\n        }\n      });\n      show(\"copy local \" + f1 + \" to remote \" + dst);\n      dfs.copyFromLocalFile(false, false, new Path(f1.getPath()), dst);\n      show(\"done\");\n\n      try {copy2ndFileThread.join();} catch (InterruptedException e) { }\n      System.setSecurityManager(sm);\n\n      // copy multiple files to destination directory\n      final Path destmultiple = mkdir(dfs, new Path(\"/test/putmultiple\"));\n      Path[] srcs = new Path[2];\n      srcs[0] = new Path(f1.getPath());\n      srcs[1] = new Path(f2.getPath());\n      dfs.copyFromLocalFile(false, false, srcs, destmultiple);\n      srcs[0] = new Path(destmultiple,\"f1\");\n      srcs[1] = new Path(destmultiple,\"f2\");\n      assertTrue(dfs.exists(srcs[0]));\n      assertTrue(dfs.exists(srcs[1]));\n\n      // move multiple files to destination directory\n      final Path destmultiple2 = mkdir(dfs, new Path(\"/test/movemultiple\"));\n      srcs[0] = new Path(f1.getPath());\n      srcs[1] = new Path(f2.getPath());\n      dfs.moveFromLocalFile(srcs, destmultiple2);\n      assertFalse(f1.exists());\n      assertFalse(f2.exists());\n      srcs[0] = new Path(destmultiple2, \"f1\");\n      srcs[1] = new Path(destmultiple2, \"f2\");\n      assertTrue(dfs.exists(srcs[0]));\n      assertTrue(dfs.exists(srcs[1]));\n\n      f1.delete();\n      f2.delete();\n    } finally {\n      try {dfs.close();} catch (Exception e) {}\n      cluster.shutdown();\n    }\n  }","id":37741,"modified_method":"@Test (timeout = 30000)\n  public void testPut() throws IOException {\n    // remove left over crc files:\n    new File(TEST_ROOT_DIR, \".f1.crc\").delete();\n    new File(TEST_ROOT_DIR, \".f2.crc\").delete();\n    final File f1 = createLocalFile(new File(TEST_ROOT_DIR, \"f1\"));\n    final File f2 = createLocalFile(new File(TEST_ROOT_DIR, \"f2\"));\n\n    final Path root = mkdir(dfs, new Path(\"/testPut\"));\n    final Path dst = new Path(root, \"dst\");\n\n    show(\"begin\");\n\n    final Thread copy2ndFileThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          show(\"copy local \" + f2 + \" to remote \" + dst);\n          dfs.copyFromLocalFile(false, false, new Path(f2.getPath()), dst);\n        } catch (IOException ioe) {\n          show(\"good \" + StringUtils.stringifyException(ioe));\n          return;\n        }\n        //should not be here, must got IOException\n        assertTrue(false);\n      }\n    };\n\n    //use SecurityManager to pause the copying of f1 and begin copying f2\n    SecurityManager sm = System.getSecurityManager();\n    System.out.println(\"SecurityManager = \" + sm);\n    System.setSecurityManager(new SecurityManager() {\n      private boolean firstTime = true;\n\n      @Override\n      public void checkPermission(Permission perm) {\n        if (firstTime) {\n          Thread t = Thread.currentThread();\n          if (!t.toString().contains(\"DataNode\")) {\n            String s = \"\" + Arrays.asList(t.getStackTrace());\n            if (s.contains(\"FileUtil.copyContent\")) {\n              //pause at FileUtil.copyContent\n\n              firstTime = false;\n              copy2ndFileThread.start();\n              try {Thread.sleep(5000);} catch (InterruptedException e) {}\n            }\n          }\n        }\n      }\n    });\n    show(\"copy local \" + f1 + \" to remote \" + dst);\n    dfs.copyFromLocalFile(false, false, new Path(f1.getPath()), dst);\n    show(\"done\");\n\n    try {copy2ndFileThread.join();} catch (InterruptedException e) { }\n    System.setSecurityManager(sm);\n\n    // copy multiple files to destination directory\n    final Path destmultiple = mkdir(dfs, new Path(root, \"putmultiple\"));\n    Path[] srcs = new Path[2];\n    srcs[0] = new Path(f1.getPath());\n    srcs[1] = new Path(f2.getPath());\n    dfs.copyFromLocalFile(false, false, srcs, destmultiple);\n    srcs[0] = new Path(destmultiple,\"f1\");\n    srcs[1] = new Path(destmultiple,\"f2\");\n    assertTrue(dfs.exists(srcs[0]));\n    assertTrue(dfs.exists(srcs[1]));\n\n    // move multiple files to destination directory\n    final Path destmultiple2 = mkdir(dfs, new Path(root, \"movemultiple\"));\n    srcs[0] = new Path(f1.getPath());\n    srcs[1] = new Path(f2.getPath());\n    dfs.moveFromLocalFile(srcs, destmultiple2);\n    assertFalse(f1.exists());\n    assertFalse(f2.exists());\n    srcs[0] = new Path(destmultiple2, \"f1\");\n    srcs[1] = new Path(destmultiple2, \"f2\");\n    assertTrue(dfs.exists(srcs[0]));\n    assertTrue(dfs.exists(srcs[1]));\n\n    f1.delete();\n    f2.delete();\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 120000)\n  public void testCopyCommandsWithRawXAttrs() throws Exception {\n    final Configuration conf = new Configuration();\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);\n    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).\n      numDataNodes(1).format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithRawXAttrs-\"\n      + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    final Path rawHdfsTestDir = new Path(\"/.reserved/raw\" + testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      final Path src = new Path(hdfsTestDir, \"srcfile\");\n      final String rawSrcBase = \"/.reserved/raw\" + testdir;\n      final Path rawSrc = new Path(rawSrcBase, \"srcfile\");\n      fs.create(src).close();\n\n      final Path srcDir = new Path(hdfsTestDir, \"srcdir\");\n      final Path rawSrcDir = new Path(\"/.reserved/raw\" + testdir, \"srcdir\");\n      fs.mkdirs(srcDir);\n      final Path srcDirFile = new Path(srcDir, \"srcfile\");\n      final Path rawSrcDirFile =\n              new Path(\"/.reserved/raw\" + srcDirFile);\n      fs.create(srcDirFile).close();\n\n      final Path[] paths = { rawSrc, rawSrcDir, rawSrcDirFile };\n      final String[] xattrNames = { USER_A1, RAW_A1 };\n      final byte[][] xattrVals = { USER_A1_VALUE, RAW_A1_VALUE };\n\n      for (int i = 0; i < paths.length; i++) {\n        for (int j = 0; j < xattrNames.length; j++) {\n          fs.setXAttr(paths[i], xattrNames[j], xattrVals[j]);\n        }\n      }\n\n      shell = new FsShell(conf);\n\n      /* Check that a file as the source path works ok. */\n      doTestCopyCommandsWithRawXAttrs(shell, fs, src, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, rawSrc, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, src, rawHdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, rawSrc, rawHdfsTestDir, true);\n\n      /* Use a relative /.reserved/raw path. */\n      final Path savedWd = fs.getWorkingDirectory();\n      try {\n        fs.setWorkingDirectory(new Path(rawSrcBase));\n        final Path relRawSrc = new Path(\"../srcfile\");\n        final Path relRawHdfsTestDir = new Path(\"..\");\n        doTestCopyCommandsWithRawXAttrs(shell, fs, relRawSrc, relRawHdfsTestDir,\n                true);\n      } finally {\n        fs.setWorkingDirectory(savedWd);\n      }\n\n      /* Check that a directory as the source path works ok. */\n      doTestCopyCommandsWithRawXAttrs(shell, fs, srcDir, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, rawSrcDir, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, srcDir, rawHdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, fs, rawSrcDir, rawHdfsTestDir,\n        true);\n\n      /* Use relative in an absolute path. */\n      final String relRawSrcDir = \"./.reserved/../.reserved/raw/../raw\" +\n          testdir + \"/srcdir\";\n      final String relRawDstDir = \"./.reserved/../.reserved/raw/../raw\" +\n          testdir;\n      doTestCopyCommandsWithRawXAttrs(shell, fs, new Path(relRawSrcDir),\n          new Path(relRawDstDir), true);\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n\n      if (null != fs) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37742,"modified_method":"@Test (timeout = 120000)\n  public void testCopyCommandsWithRawXAttrs() throws Exception {\n    FsShell shell = null;\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithRawXAttrs-\"\n      + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    final Path rawHdfsTestDir = new Path(\"/.reserved/raw\" + testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      final Path src = new Path(hdfsTestDir, \"srcfile\");\n      final String rawSrcBase = \"/.reserved/raw\" + testdir;\n      final Path rawSrc = new Path(rawSrcBase, \"srcfile\");\n      dfs.create(src).close();\n\n      final Path srcDir = new Path(hdfsTestDir, \"srcdir\");\n      final Path rawSrcDir = new Path(\"/.reserved/raw\" + testdir, \"srcdir\");\n      dfs.mkdirs(srcDir);\n      final Path srcDirFile = new Path(srcDir, \"srcfile\");\n      final Path rawSrcDirFile =\n              new Path(\"/.reserved/raw\" + srcDirFile);\n      dfs.create(srcDirFile).close();\n\n      final Path[] paths = { rawSrc, rawSrcDir, rawSrcDirFile };\n      final String[] xattrNames = { USER_A1, RAW_A1 };\n      final byte[][] xattrVals = { USER_A1_VALUE, RAW_A1_VALUE };\n\n      for (int i = 0; i < paths.length; i++) {\n        for (int j = 0; j < xattrNames.length; j++) {\n          dfs.setXAttr(paths[i], xattrNames[j], xattrVals[j]);\n        }\n      }\n\n      shell = new FsShell(dfs.getConf());\n\n      /* Check that a file as the source path works ok. */\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, src, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, rawSrc, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, src, rawHdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, rawSrc, rawHdfsTestDir, true);\n\n      /* Use a relative /.reserved/raw path. */\n      final Path savedWd = dfs.getWorkingDirectory();\n      try {\n        dfs.setWorkingDirectory(new Path(rawSrcBase));\n        final Path relRawSrc = new Path(\"../srcfile\");\n        final Path relRawHdfsTestDir = new Path(\"..\");\n        doTestCopyCommandsWithRawXAttrs(shell, dfs, relRawSrc,\n            relRawHdfsTestDir, true);\n      } finally {\n        dfs.setWorkingDirectory(savedWd);\n      }\n\n      /* Check that a directory as the source path works ok. */\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, srcDir, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, rawSrcDir, hdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, srcDir, rawHdfsTestDir, false);\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, rawSrcDir, rawHdfsTestDir,\n        true);\n\n      /* Use relative in an absolute path. */\n      final String relRawSrcDir = \"./.reserved/../.reserved/raw/../raw\" +\n          testdir + \"/srcdir\";\n      final String relRawDstDir = \"./.reserved/../.reserved/raw/../raw\" +\n          testdir;\n      doTestCopyCommandsWithRawXAttrs(shell, dfs, new Path(relRawSrcDir),\n          new Path(relRawDstDir), true);\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n      dfs.delete(hdfsTestDir, true);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test //(timeout = 30000)\n  public void testCopyReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileForPut\");\n    localFile.createNewFile();\n    final String localfilepath =\n        new Path(localFile.getAbsolutePath()).toUri().toString();\n    try {\n      fs.copyFromLocalFile(new Path(localfilepath), new Path(\"/.reserved\"));\n      fail(\"Can't copyFromLocal to /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid path name /.reserved\"));\n    }\n\n    final String testdir = GenericTestUtils.getTempPath(\n        \"TestDFSShell-testCopyReserved\");\n    final Path hdfsTestDir = new Path(testdir);\n    writeFile(fs, new Path(testdir, \"testFileForPut\"));\n    final Path src = new Path(hdfsTestDir, \"srcfile\");\n    fs.create(src).close();\n    assertTrue(fs.exists(src));\n\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell();\n      shell.setConf(conf);\n      runCmd(shell, \"-cp\", src.toString(), \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n      cluster.shutdown();\n    }\n  }","id":37743,"modified_method":"@Test //(timeout = 30000)\n  public void testCopyReserved() throws IOException {\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileForPut\");\n    localFile.createNewFile();\n    final String localfilepath =\n        new Path(localFile.getAbsolutePath()).toUri().toString();\n    try {\n      dfs.copyFromLocalFile(new Path(localfilepath), new Path(\"/.reserved\"));\n      fail(\"Can't copyFromLocal to /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid path name /.reserved\"));\n    }\n\n    final String testdir = GenericTestUtils.getTempPath(\n        \"TestDFSShell-testCopyReserved\");\n    final Path hdfsTestDir = new Path(testdir);\n    writeFile(dfs, new Path(testdir, \"testFileForPut\"));\n    final Path src = new Path(hdfsTestDir, \"srcfile\");\n    dfs.create(src).close();\n    assertTrue(dfs.exists(src));\n\n    // runCmd prints error into System.err, thus verify from there.\n    PrintStream syserr = System.err;\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintStream ps = new PrintStream(baos);\n    System.setErr(ps);\n    try {\n      FsShell shell = new FsShell(dfs.getConf());\n      runCmd(shell, \"-cp\", src.toString(), \"/.reserved\");\n      assertTrue(baos.toString().contains(\"Invalid path name /.reserved\"));\n    } finally {\n      System.setErr(syserr);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   * Test that -tail -f outputs appended data as the file grows.\n   */\n  @Test(timeout = 30000)\n  public void testTailWithFresh() throws Exception {\n    final int blockSize = 1024;\n    final Configuration conf = new Configuration();\n    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, blockSize);\n\n    try (MiniDFSCluster cluster =\n             new MiniDFSCluster.Builder(conf).numDataNodes(3).build()) {\n      cluster.waitActive();\n      final DistributedFileSystem dfs = cluster.getFileSystem();\n      final Path testFile = new Path(\"testTailWithFresh\", \"file1\");\n      dfs.create(testFile);\n\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setOut(new PrintStream(out));\n      final Thread tailer = new Thread() {\n        @Override\n        public void run() {\n          final String[] argv = new String[]{\"-tail\", \"-f\",\n              testFile.toString()};\n          try {\n            ToolRunner.run(new FsShell(conf), argv);\n          } catch (Exception e) {\n            LOG.error(\"Client that tails the test file fails\", e);\n          } finally {\n            out.reset();\n          }\n        }\n      };\n      tailer.start();\n      // wait till the tailer is sleeping\n      GenericTestUtils.waitFor(new Supplier<Boolean>() {\n        @Override\n        public Boolean get() {\n          return tailer.getState() == Thread.State.TIMED_WAITING;\n        }\n      }, 100, 10000);\n\n      final String text = RandomStringUtils.randomAscii(blockSize / 2);\n      try (OutputStream pout = dfs.create(testFile)) {\n        pout.write(text.getBytes());\n      }\n      // The tailer should eventually show the file contents\n      GenericTestUtils.waitFor(new Supplier<Boolean>() {\n        @Override\n        public Boolean get() {\n          return Arrays.equals(text.getBytes(), out.toByteArray());\n        }\n      }, 100, 10000);\n    }\n  }","id":37744,"modified_method":"/**\n   * Test that -tail -f outputs appended data as the file grows.\n   */\n  @Test(timeout = 30000)\n  public void testTailWithFresh() throws Exception {\n    final Path testFile = new Path(\"testTailWithFresh\", \"file1\");\n    dfs.create(testFile);\n\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    System.setOut(new PrintStream(out));\n    final Thread tailer = new Thread() {\n      @Override\n      public void run() {\n        final String[] argv = new String[]{\"-tail\", \"-f\",\n            testFile.toString()};\n        try {\n          ToolRunner.run(new FsShell(dfs.getConf()), argv);\n        } catch (Exception e) {\n          LOG.error(\"Client that tails the test file fails\", e);\n        } finally {\n          out.reset();\n        }\n      }\n    };\n    tailer.start();\n    // wait till the tailer is sleeping\n    GenericTestUtils.waitFor(new Supplier<Boolean>() {\n      @Override\n      public Boolean get() {\n        return tailer.getState() == Thread.State.TIMED_WAITING;\n      }\n    }, 100, 10000);\n\n    final String text = RandomStringUtils.randomAscii(BLOCK_SIZE / 2);\n    try (OutputStream pout = dfs.create(testFile)) {\n      pout.write(text.getBytes());\n    }\n    // The tailer should eventually show the file contents\n    GenericTestUtils.waitFor(new Supplier<Boolean>() {\n      @Override\n      public Boolean get() {\n        return Arrays.equals(text.getBytes(), out.toByteArray());\n      }\n    }, 100, 10000);\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testRemoteException() throws Exception {\n    UserGroupInformation tmpUGI =\n      UserGroupInformation.createUserForTesting(\"tmpname\", new String[] {\"mygroup\"});\n    MiniDFSCluster dfs = null;\n    PrintStream bak = null;\n    try {\n      final Configuration conf = new HdfsConfiguration();\n      dfs = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n      FileSystem fs = dfs.getFileSystem();\n      Path p = new Path(\"/foo\");\n      fs.mkdirs(p);\n      fs.setPermission(p, new FsPermission((short)0700));\n      bak = System.err;\n\n      tmpUGI.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          FsShell fshell = new FsShell(conf);\n          ByteArrayOutputStream out = new ByteArrayOutputStream();\n          PrintStream tmp = new PrintStream(out);\n          System.setErr(tmp);\n          String[] args = new String[2];\n          args[0] = \"-ls\";\n          args[1] = \"/foo\";\n          int ret = ToolRunner.run(fshell, args);\n          assertEquals(\"returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"permission denied printed\",\n                     str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n      if (dfs != null) {\n        dfs.shutdown();\n      }\n    }\n  }","id":37745,"modified_method":"@Test (timeout = 30000)\n  public void testRemoteException() throws Exception {\n    UserGroupInformation tmpUGI =\n      UserGroupInformation.createUserForTesting(\"tmpname\", new String[] {\"mygroup\"});\n    PrintStream bak = null;\n    try {\n      Path p = new Path(\"/foo\");\n      dfs.mkdirs(p);\n      dfs.setPermission(p, new FsPermission((short)0700));\n      bak = System.err;\n\n      tmpUGI.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          FsShell fshell = new FsShell(dfs.getConf());\n          ByteArrayOutputStream out = new ByteArrayOutputStream();\n          PrintStream tmp = new PrintStream(out);\n          System.setErr(tmp);\n          String[] args = new String[2];\n          args[0] = \"-ls\";\n          args[1] = \"/foo\";\n          int ret = ToolRunner.run(fshell, args);\n          assertEquals(\"returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"permission denied printed\",\n                     str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testSetrep() throws Exception {\n\n    Configuration conf = new Configuration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n                                                             .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n\n    final String testdir1 = \"/tmp/TestDFSShell-testSetrep-\" + counter.getAndIncrement();\n    final String testdir2 = testdir1 + \"/nestedDir\";\n    final Path hdfsFile1 = new Path(testdir1, \"testFileForSetrep\");\n    final Path hdfsFile2 = new Path(testdir2, \"testFileForSetrep\");\n    final Short oldRepFactor = new Short((short) 1);\n    final Short newRepFactor = new Short((short) 3);\n    try {\n      String[] argv;\n      cluster.waitActive();\n      fs = cluster.getFileSystem();\n      assertThat(fs.mkdirs(new Path(testdir2)), is(true));\n      shell = new FsShell(conf);\n\n      fs.create(hdfsFile1, true).close();\n      fs.create(hdfsFile2, true).close();\n\n      // Tests for setrep on a file.\n      argv = new String[] { \"-setrep\", newRepFactor.toString(), hdfsFile1.toString() };\n      assertThat(shell.run(argv), is(SUCCESS));\n      assertThat(fs.getFileStatus(hdfsFile1).getReplication(), is(newRepFactor));\n      assertThat(fs.getFileStatus(hdfsFile2).getReplication(), is(oldRepFactor));\n\n      // Tests for setrep\n\n      // Tests for setrep on a directory and make sure it is applied recursively.\n      argv = new String[] { \"-setrep\", newRepFactor.toString(), testdir1 };\n      assertThat(shell.run(argv), is(SUCCESS));\n      assertThat(fs.getFileStatus(hdfsFile1).getReplication(), is(newRepFactor));\n      assertThat(fs.getFileStatus(hdfsFile2).getReplication(), is(newRepFactor));\n\n    } finally {\n      if (shell != null) {\n        shell.close();\n      }\n\n      cluster.shutdown();\n    }\n  }","id":37746,"modified_method":"@Test (timeout = 30000)\n  public void testSetrep() throws Exception {\n    FsShell shell = null;\n    final String testdir1 = \"/tmp/TestDFSShell-testSetrep-\" + counter.getAndIncrement();\n    final String testdir2 = testdir1 + \"/nestedDir\";\n    final Path hdfsFile1 = new Path(testdir1, \"testFileForSetrep\");\n    final Path hdfsFile2 = new Path(testdir2, \"testFileForSetrep\");\n    final Short oldRepFactor = new Short((short) 2);\n    final Short newRepFactor = new Short((short) 3);\n    try {\n      String[] argv;\n      assertThat(dfs.mkdirs(new Path(testdir2)), is(true));\n      shell = new FsShell(dfs.getConf());\n\n      dfs.create(hdfsFile1, true).close();\n      dfs.create(hdfsFile2, true).close();\n\n      // Tests for setrep on a file.\n      argv = new String[] { \"-setrep\", newRepFactor.toString(), hdfsFile1.toString() };\n      assertThat(shell.run(argv), is(SUCCESS));\n      assertThat(dfs.getFileStatus(hdfsFile1).getReplication(), is(newRepFactor));\n      assertThat(dfs.getFileStatus(hdfsFile2).getReplication(), is(oldRepFactor));\n\n      // Tests for setrep\n\n      // Tests for setrep on a directory and make sure it is applied recursively.\n      argv = new String[] { \"-setrep\", newRepFactor.toString(), testdir1 };\n      assertThat(shell.run(argv), is(SUCCESS));\n      assertThat(dfs.getFileStatus(hdfsFile1).getReplication(), is(newRepFactor));\n      assertThat(dfs.getFileStatus(hdfsFile2).getReplication(), is(newRepFactor));\n\n    } finally {\n      if (shell != null) {\n        shell.close();\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testMkdirReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    try {\n      fs.mkdirs(new Path(\"/.reserved\"));\n      fail(\"Can't mkdir /.reserved\");\n    } catch (Exception e) {\n      // Expected, HadoopIllegalArgumentException thrown from remote\n      assertTrue(e.getMessage().contains(\"\\\".reserved\\\" is reserved\"));\n    }\n    cluster.shutdown();\n  }","id":37747,"modified_method":"@Test (timeout = 30000)\n  public void testMkdirReserved() throws IOException {\n    try {\n      dfs.mkdirs(new Path(\"/.reserved\"));\n      fail(\"Can't mkdir /.reserved\");\n    } catch (Exception e) {\n      // Expected, HadoopIllegalArgumentException thrown from remote\n      assertTrue(e.getMessage().contains(\"\\\".reserved\\\" is reserved\"));\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 180000)\n  public void testCountSnapshots() throws IOException {\n    final int replication = 2;\n    final Configuration conf = new HdfsConfiguration();\n    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n        .numDataNodes(replication).build();\n    final DistributedFileSystem dfs = cluster.getFileSystem();\n    final PrintStream psBackup = System.out;\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    final PrintStream psOut = new PrintStream(out);\n    System.setOut(psOut);\n    final FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      cluster.waitActive();\n      final Path parent = new Path(\"/test\");\n      final Path dir = new Path(parent, \"dir\");\n      mkdir(dfs, dir);\n      final Path file = new Path(dir, \"file\");\n      writeFile(dfs, file);\n      final Path file2 = new Path(dir, \"file2\");\n      writeFile(dfs, file2);\n      final long fileLength = dfs.getFileStatus(file).getLen();\n      final long file2Length = dfs.getFileStatus(file2).getLen();\n      final Path dir2 = new Path(parent, \"dir2\");\n      mkdir(dfs, dir2);\n\n      /*\n       * Construct dir as follows:\n       * /test/dir/file   <- this will later be deleted after snapshot taken.\n       * /test/dir/newfile <- this will be created after snapshot taken.\n       * /test/dir/file2\n       * /test/dir2       <- this will later be deleted after snapshot taken.\n       * Snapshot enabled on /test\n       */\n\n      // take a snapshot\n      // then create /test/dir/newfile and remove /test/dir/file, /test/dir2\n      final String snapshotName = \"s1\";\n      final Path snapshotPath = new Path(parent, \".snapshot/\" + snapshotName);\n      dfs.allowSnapshot(parent);\n      assertThat(dfs.createSnapshot(parent, snapshotName), is(snapshotPath));\n      rmr(dfs, file);\n      rmr(dfs, dir2);\n      final Path newFile = new Path(dir, \"new file\");\n      writeFile(dfs, newFile);\n      final Long newFileLength = dfs.getFileStatus(newFile).getLen();\n\n      // test -count on /test. Include header for easier debugging.\n      int val = -1;\n      try {\n        val = shell.run(new String[] {\"-count\", \"-v\", parent.toString() });\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n      String returnString = out.toString();\n      LOG.info(\"-count return is:\\n\" + returnString);\n      Scanner in = new Scanner(returnString);\n      in.nextLine();\n      assertEquals(3, in.nextLong()); //DIR_COUNT\n      assertEquals(3, in.nextLong()); //FILE_COUNT\n      assertEquals(fileLength + file2Length + newFileLength,\n          in.nextLong()); //CONTENT_SIZE\n      out.reset();\n\n      // test -count -x on /test. Include header for easier debugging.\n      val = -1;\n      try {\n        val =\n            shell.run(new String[] {\"-count\", \"-x\", \"-v\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n      returnString = out.toString();\n      LOG.info(\"-count -x return is:\\n\" + returnString);\n      in = new Scanner(returnString);\n      in.nextLine();\n      assertEquals(2, in.nextLong()); //DIR_COUNT\n      assertEquals(2, in.nextLong()); //FILE_COUNT\n      assertEquals(file2Length + newFileLength, in.nextLong()); //CONTENT_SIZE\n      out.reset();\n    } finally {\n      System.setOut(psBackup);\n      cluster.shutdown();\n    }\n  }","id":37748,"modified_method":"@Test (timeout = 180000)\n  public void testCountSnapshots() throws IOException {\n    final PrintStream psBackup = System.out;\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    final PrintStream psOut = new PrintStream(out);\n    System.setOut(psOut);\n    final FsShell shell = new FsShell(dfs.getConf());\n\n    try {\n      final Path parent = new Path(\"/testCountSnapshots\");\n      final Path dir = new Path(parent, \"dir\");\n      mkdir(dfs, dir);\n      final Path file = new Path(dir, \"file\");\n      writeFile(dfs, file);\n      final Path file2 = new Path(dir, \"file2\");\n      writeFile(dfs, file2);\n      final long fileLength = dfs.getFileStatus(file).getLen();\n      final long file2Length = dfs.getFileStatus(file2).getLen();\n      final Path dir2 = new Path(parent, \"dir2\");\n      mkdir(dfs, dir2);\n\n      /*\n       * Construct dir as follows:\n       * /test/dir/file   <- this will later be deleted after snapshot taken.\n       * /test/dir/newfile <- this will be created after snapshot taken.\n       * /test/dir/file2\n       * /test/dir2       <- this will later be deleted after snapshot taken.\n       * Snapshot enabled on /test\n       */\n\n      // take a snapshot\n      // then create /test/dir/newfile and remove /test/dir/file, /test/dir2\n      final String snapshotName = \"s1\";\n      final Path snapshotPath = new Path(parent, \".snapshot/\" + snapshotName);\n      dfs.allowSnapshot(parent);\n      assertThat(dfs.createSnapshot(parent, snapshotName), is(snapshotPath));\n      rmr(dfs, file);\n      rmr(dfs, dir2);\n      final Path newFile = new Path(dir, \"new file\");\n      writeFile(dfs, newFile);\n      final Long newFileLength = dfs.getFileStatus(newFile).getLen();\n\n      // test -count on /test. Include header for easier debugging.\n      int val = -1;\n      try {\n        val = shell.run(new String[] {\"-count\", \"-v\", parent.toString() });\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n      String returnString = out.toString();\n      LOG.info(\"-count return is:\\n\" + returnString);\n      Scanner in = new Scanner(returnString);\n      in.nextLine();\n      assertEquals(3, in.nextLong()); //DIR_COUNT\n      assertEquals(3, in.nextLong()); //FILE_COUNT\n      assertEquals(fileLength + file2Length + newFileLength,\n          in.nextLong()); //CONTENT_SIZE\n      out.reset();\n\n      // test -count -x on /test. Include header for easier debugging.\n      val = -1;\n      try {\n        val =\n            shell.run(new String[] {\"-count\", \"-x\", \"-v\", parent.toString()});\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n      returnString = out.toString();\n      LOG.info(\"-count -x return is:\\n\" + returnString);\n      in = new Scanner(returnString);\n      in.nextLine();\n      assertEquals(2, in.nextLong()); //DIR_COUNT\n      assertEquals(2, in.nextLong()); //FILE_COUNT\n      assertEquals(file2Length + newFileLength, in.nextLong()); //CONTENT_SIZE\n      out.reset();\n    } finally {\n      System.setOut(psBackup);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testSnapshotReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    DistributedFileSystem fs = cluster.getFileSystem();\n    final Path reserved = new Path(\"/.reserved\");\n    try {\n      fs.allowSnapshot(reserved);\n      fail(\"Can't allow snapshot on /.reserved\");\n    } catch (FileNotFoundException e) {\n      assertTrue(e.getMessage().contains(\"Directory does not exist\"));\n    }\n    try {\n      fs.createSnapshot(reserved, \"snap\");\n      fail(\"Can't create snapshot on /.reserved\");\n    } catch (FileNotFoundException e) {\n      assertTrue(e.getMessage().contains(\"Directory/File does not exist\"));\n    }\n    cluster.shutdown();\n  }","id":37749,"modified_method":"@Test (timeout = 30000)\n  public void testSnapshotReserved() throws IOException {\n    final Path reserved = new Path(\"/.reserved\");\n    try {\n      dfs.allowSnapshot(reserved);\n      fail(\"Can't allow snapshot on /.reserved\");\n    } catch (FileNotFoundException e) {\n      assertTrue(e.getMessage().contains(\"Directory does not exist\"));\n    }\n    try {\n      dfs.createSnapshot(reserved, \"snap\");\n      fail(\"Can't create snapshot on /.reserved\");\n    } catch (FileNotFoundException e) {\n      assertTrue(e.getMessage().contains(\"Directory/File does not exist\"));\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 120000)\n  public void testCopyCommandsToDirectoryWithPreserveOption()\n      throws Exception {\n    Configuration conf = new Configuration();\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    final String testdir =\n        \"/tmp/TestDFSShell-testCopyCommandsToDirectoryWithPreserveOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      Path srcDir = new Path(hdfsTestDir, \"srcDir\");\n      fs.mkdirs(srcDir);\n\n      fs.setAcl(srcDir, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(DEFAULT, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n      // set sticky bit\n      fs.setPermission(srcDir,\n          new FsPermission(ALL, READ_EXECUTE, EXECUTE, true));\n\n      // Create a file in srcDir to check if modification time of\n      // srcDir to be preserved after copying the file.\n      // If cp -p command is to preserve modification time and then copy child\n      // (srcFile), modification time will not be preserved.\n      Path srcFile = new Path(srcDir, \"srcFile\");\n      fs.create(srcFile).close();\n\n      FileStatus status = fs.getFileStatus(srcDir);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      fs.setXAttr(srcDir, USER_A1, USER_A1_VALUE);\n      fs.setXAttr(srcDir, TRUSTED_A1, TRUSTED_A1_VALUE);\n\n      shell = new FsShell(conf);\n\n      // -p\n      Path targetDir1 = new Path(hdfsTestDir, \"targetDir1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", srcDir.toUri().toString(),\n          targetDir1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -p is not working\", SUCCESS, ret);\n      FileStatus targetStatus = fs.getFileStatus(targetDir1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      Map<String, byte[]> xattrs = fs.getXAttrs(targetDir1);\n      assertTrue(xattrs.isEmpty());\n      List<AclEntry> acls = fs.getAclStatus(targetDir1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptop\n      Path targetDir2 = new Path(hdfsTestDir, \"targetDir2\");\n      argv = new String[] { \"-cp\", \"-ptop\", srcDir.toUri().toString(),\n          targetDir2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptop is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(targetDir2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(targetDir2);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(targetDir2).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopx\n      Path targetDir3 = new Path(hdfsTestDir, \"targetDir3\");\n      argv = new String[] { \"-cp\", \"-ptopx\", srcDir.toUri().toString(),\n          targetDir3.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopx is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(targetDir3);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(targetDir3);\n      assertEquals(xattrs.size(), 2);\n      assertArrayEquals(USER_A1_VALUE, xattrs.get(USER_A1));\n      assertArrayEquals(TRUSTED_A1_VALUE, xattrs.get(TRUSTED_A1));\n      acls = fs.getAclStatus(targetDir3).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa\n      Path targetDir4 = new Path(hdfsTestDir, \"targetDir4\");\n      argv = new String[] { \"-cp\", \"-ptopa\", srcDir.toUri().toString(),\n          targetDir4.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(targetDir4);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(targetDir4);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(targetDir4).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(fs.getAclStatus(srcDir), fs.getAclStatus(targetDir4));\n\n      // -ptoa (verify -pa option will preserve permissions also)\n      Path targetDir5 = new Path(hdfsTestDir, \"targetDir5\");\n      argv = new String[] { \"-cp\", \"-ptoa\", srcDir.toUri().toString(),\n          targetDir5.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptoa is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(targetDir5);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(targetDir5);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(targetDir5).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(fs.getAclStatus(srcDir), fs.getAclStatus(targetDir5));\n    } finally {\n      if (shell != null) {\n        shell.close();\n      }\n      if (fs != null) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37750,"modified_method":"@Test (timeout = 120000)\n  public void testCopyCommandsToDirectoryWithPreserveOption()\n      throws Exception {\n    FsShell shell = null;\n    final String testdir =\n        \"/tmp/TestDFSShell-testCopyCommandsToDirectoryWithPreserveOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      Path srcDir = new Path(hdfsTestDir, \"srcDir\");\n      dfs.mkdirs(srcDir);\n\n      dfs.setAcl(srcDir, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(DEFAULT, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n      // set sticky bit\n      dfs.setPermission(srcDir,\n          new FsPermission(ALL, READ_EXECUTE, EXECUTE, true));\n\n      // Create a file in srcDir to check if modification time of\n      // srcDir to be preserved after copying the file.\n      // If cp -p command is to preserve modification time and then copy child\n      // (srcFile), modification time will not be preserved.\n      Path srcFile = new Path(srcDir, \"srcFile\");\n      dfs.create(srcFile).close();\n\n      FileStatus status = dfs.getFileStatus(srcDir);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      dfs.setXAttr(srcDir, USER_A1, USER_A1_VALUE);\n      dfs.setXAttr(srcDir, TRUSTED_A1, TRUSTED_A1_VALUE);\n\n      shell = new FsShell(dfs.getConf());\n\n      // -p\n      Path targetDir1 = new Path(hdfsTestDir, \"targetDir1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", srcDir.toUri().toString(),\n          targetDir1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -p is not working\", SUCCESS, ret);\n      FileStatus targetStatus = dfs.getFileStatus(targetDir1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      Map<String, byte[]> xattrs = dfs.getXAttrs(targetDir1);\n      assertTrue(xattrs.isEmpty());\n      List<AclEntry> acls = dfs.getAclStatus(targetDir1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptop\n      Path targetDir2 = new Path(hdfsTestDir, \"targetDir2\");\n      argv = new String[] { \"-cp\", \"-ptop\", srcDir.toUri().toString(),\n          targetDir2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptop is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(targetDir2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(targetDir2);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(targetDir2).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopx\n      Path targetDir3 = new Path(hdfsTestDir, \"targetDir3\");\n      argv = new String[] { \"-cp\", \"-ptopx\", srcDir.toUri().toString(),\n          targetDir3.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopx is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(targetDir3);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(targetDir3);\n      assertEquals(xattrs.size(), 2);\n      assertArrayEquals(USER_A1_VALUE, xattrs.get(USER_A1));\n      assertArrayEquals(TRUSTED_A1_VALUE, xattrs.get(TRUSTED_A1));\n      acls = dfs.getAclStatus(targetDir3).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa\n      Path targetDir4 = new Path(hdfsTestDir, \"targetDir4\");\n      argv = new String[] { \"-cp\", \"-ptopa\", srcDir.toUri().toString(),\n          targetDir4.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(targetDir4);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(targetDir4);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(targetDir4).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(dfs.getAclStatus(srcDir), dfs.getAclStatus(targetDir4));\n\n      // -ptoa (verify -pa option will preserve permissions also)\n      Path targetDir5 = new Path(hdfsTestDir, \"targetDir5\");\n      argv = new String[] { \"-cp\", \"-ptoa\", srcDir.toUri().toString(),\n          targetDir5.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptoa is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(targetDir5);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(targetDir5);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(targetDir5).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(dfs.getAclStatus(srcDir), dfs.getAclStatus(targetDir5));\n    } finally {\n      if (shell != null) {\n        shell.close();\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testSetXAttrCaseSensitivity() throws Exception {\n    MiniDFSCluster cluster = null;\n    PrintStream bak = null;\n    try {\n      final Configuration conf = new HdfsConfiguration();\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n      cluster.waitActive();\n\n      FileSystem fs = cluster.getFileSystem();\n      Path p = new Path(\"/mydir\");\n      fs.mkdirs(p);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(conf);\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setOut(new PrintStream(out));\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"User.Foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"user.FOO\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"USER.foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\", \"user.foo\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"USER.fOo\", \"-v\", \"myval\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\", \"user.foo\", \"user.fOo=\\\"myval\\\"\"},\n        new String[] {\"user.Foo=\", \"user.FOO=\", \"user.foo=\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"useR.foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\"},\n        new String[] {\"foo\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"USER.FOO\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\"},\n        new String[] {\"FOO\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"useR.Foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-n\", \"User.Foo\", \"/mydir\"},\n        new String[] {},\n        new String[] {\"Foo\"});\n\n    } finally {\n      if (bak != null) {\n        System.setOut(bak);\n      }\n      if (cluster != null) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37751,"modified_method":"@Test (timeout = 30000)\n  public void testSetXAttrCaseSensitivity() throws Exception {\n    PrintStream bak = null;\n    try {\n      Path p = new Path(\"/mydir\");\n      dfs.mkdirs(p);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(dfs.getConf());\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setOut(new PrintStream(out));\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"User.Foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"user.FOO\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"USER.foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\", \"user.foo\"},\n        new String[] {});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-n\", \"USER.fOo\", \"-v\", \"myval\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\", \"user.foo\", \"user.fOo=\\\"myval\\\"\"},\n        new String[] {\"user.Foo=\", \"user.FOO=\", \"user.foo=\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"useR.foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\", \"user.FOO\"},\n        new String[] {\"foo\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"USER.FOO\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-d\", \"/mydir\"},\n        new String[] {\"user.Foo\"},\n        new String[] {\"FOO\"});\n\n      doSetXattr(out, fshell,\n        new String[] {\"-setfattr\", \"-x\", \"useR.Foo\", \"/mydir\"},\n        new String[] {\"-getfattr\", \"-n\", \"User.Foo\", \"/mydir\"},\n        new String[] {},\n        new String[] {\"Foo\"});\n\n    } finally {\n      if (bak != null) {\n        System.setOut(bak);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 120000)\n  public void testGetFAttrErrors() throws Exception {\n    final UserGroupInformation user = UserGroupInformation.\n        createUserForTesting(\"user\", new String[] {\"mygroup\"});\n    MiniDFSCluster cluster = null;\n    PrintStream bakErr = null;\n    try {\n      final Configuration conf = new HdfsConfiguration();\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n      cluster.waitActive();\n\n      final FileSystem fs = cluster.getFileSystem();\n      final Path p = new Path(\"/foo\");\n      fs.mkdirs(p);\n      bakErr = System.err;\n\n      final FsShell fshell = new FsShell(conf);\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      // No permission for \"other\".\n      fs.setPermission(p, new FsPermission((short) 0700));\n\n      {\n        final int ret = ToolRunner.run(fshell, new String[] {\n            \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n        assertEquals(\"Returned should be 0\", 0, ret);\n        out.reset();\n      }\n\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n          @Override\n          public Object run() throws Exception {\n            int ret = ToolRunner.run(fshell, new String[] {\n                \"-getfattr\", \"-n\", \"user.a1\", \"/foo\"});\n            String str = out.toString();\n            assertTrue(\"xattr value was incorrectly returned\",\n                str.indexOf(\"1234\") == -1);\n            out.reset();\n            return null;\n          }\n        });\n\n      {\n        final int ret = ToolRunner.run(fshell, new String[]{\n            \"-getfattr\", \"-n\", \"user.nonexistent\", \"/foo\"});\n        String str = out.toString();\n        assertTrue(\"xattr value was incorrectly returned\",\n          str.indexOf(\n              \"getfattr: At least one of the attributes provided was not found\")\n               >= 0);\n        out.reset();\n      }\n    } finally {\n      if (bakErr != null) {\n        System.setErr(bakErr);\n      }\n      if (cluster != null) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37752,"modified_method":"@Test (timeout = 120000)\n  public void testGetFAttrErrors() throws Exception {\n    final UserGroupInformation user = UserGroupInformation.\n        createUserForTesting(\"user\", new String[] {\"mygroup\"});\n    PrintStream bakErr = null;\n    try {\n      final Path p = new Path(\"/testGetFAttrErrors\");\n      dfs.mkdirs(p);\n      bakErr = System.err;\n\n      final FsShell fshell = new FsShell(dfs.getConf());\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      // No permission for \"other\".\n      dfs.setPermission(p, new FsPermission((short) 0700));\n\n      {\n        final int ret = ToolRunner.run(fshell, new String[] {\n            \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", p.toString()});\n        assertEquals(\"Returned should be 0\", 0, ret);\n        out.reset();\n      }\n\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n          @Override\n          public Object run() throws Exception {\n            int ret = ToolRunner.run(fshell, new String[] {\n                \"-getfattr\", \"-n\", \"user.a1\", p.toString()});\n            String str = out.toString();\n            assertTrue(\"xattr value was incorrectly returned\",\n                str.indexOf(\"1234\") == -1);\n            out.reset();\n            return null;\n          }\n        });\n\n      {\n        final int ret = ToolRunner.run(fshell, new String[]{\n            \"-getfattr\", \"-n\", \"user.nonexistent\", p.toString()});\n        String str = out.toString();\n        assertTrue(\"xattr value was incorrectly returned\",\n          str.indexOf(\n              \"getfattr: At least one of the attributes provided was not found\")\n               >= 0);\n        out.reset();\n      }\n    } finally {\n      if (bakErr != null) {\n        System.setErr(bakErr);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 120000)\n  public void testCopyCommandsPreserveAclAndStickyBit() throws Exception {\n    Configuration conf = new Configuration();\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    final String testdir =\n        \"/tmp/TestDFSShell-testCopyCommandsPreserveAclAndStickyBit-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      Path src = new Path(hdfsTestDir, \"srcfile\");\n      fs.create(src).close();\n\n      fs.setAcl(src, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(ACCESS, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n      // set sticky bit\n      fs.setPermission(src,\n          new FsPermission(ALL, READ_EXECUTE, EXECUTE, true));\n\n      FileStatus status = fs.getFileStatus(src);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      shell = new FsShell(conf);\n\n      // -p preserves sticky bit and doesn't preserve ACL\n      Path target1 = new Path(hdfsTestDir, \"targetfile1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", src.toUri().toString(),\n          target1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp is not working\", SUCCESS, ret);\n      FileStatus targetStatus = fs.getFileStatus(target1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      List<AclEntry> acls = fs.getAclStatus(target1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa preserves both sticky bit and ACL\n      Path target2 = new Path(hdfsTestDir, \"targetfile2\");\n      argv = new String[] { \"-cp\", \"-ptopa\", src.toUri().toString(),\n          target2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(target2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      acls = fs.getAclStatus(target2).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(fs.getAclStatus(src), fs.getAclStatus(target2));\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n      if (null != fs) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37753,"modified_method":"@Test (timeout = 120000)\n  public void testCopyCommandsPreserveAclAndStickyBit() throws Exception {\n    FsShell shell = null;\n    final String testdir =\n        \"/tmp/TestDFSShell-testCopyCommandsPreserveAclAndStickyBit-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      Path src = new Path(hdfsTestDir, \"srcfile\");\n      dfs.create(src).close();\n\n      dfs.setAcl(src, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(ACCESS, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n      // set sticky bit\n      dfs.setPermission(src,\n          new FsPermission(ALL, READ_EXECUTE, EXECUTE, true));\n\n      FileStatus status = dfs.getFileStatus(src);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      shell = new FsShell(dfs.getConf());\n\n      // -p preserves sticky bit and doesn't preserve ACL\n      Path target1 = new Path(hdfsTestDir, \"targetfile1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", src.toUri().toString(),\n          target1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp is not working\", SUCCESS, ret);\n      FileStatus targetStatus = dfs.getFileStatus(target1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      List<AclEntry> acls = dfs.getAclStatus(target1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa preserves both sticky bit and ACL\n      Path target2 = new Path(hdfsTestDir, \"targetfile2\");\n      argv = new String[] { \"-cp\", \"-ptopa\", src.toUri().toString(),\n          target2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(target2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      acls = dfs.getAclStatus(target2).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(dfs.getAclStatus(src), dfs.getAclStatus(target2));\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testURIPaths() throws Exception {\n    Configuration srcConf = new HdfsConfiguration();\n    Configuration dstConf = new HdfsConfiguration();\n    MiniDFSCluster srcCluster =  null;\n    MiniDFSCluster dstCluster = null;\n    File bak = new File(PathUtils.getTestDir(getClass()), \"dfs_tmp_uri\");\n    bak.mkdirs();\n    try{\n      srcCluster = new MiniDFSCluster.Builder(srcConf).numDataNodes(2).build();\n      dstConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, bak.getAbsolutePath());\n      dstCluster = new MiniDFSCluster.Builder(dstConf).numDataNodes(2).build();\n      FileSystem srcFs = srcCluster.getFileSystem();\n      FileSystem dstFs = dstCluster.getFileSystem();\n      FsShell shell = new FsShell();\n      shell.setConf(srcConf);\n      //check for ls\n      String[] argv = new String[2];\n      argv[0] = \"-ls\";\n      argv[1] = dstFs.getUri().toString() + \"/\";\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"ls works on remote uri \", 0, ret);\n      //check for rm -r\n      dstFs.mkdirs(new Path(\"/hadoopdir\"));\n      argv = new String[2];\n      argv[0] = \"-rmr\";\n      argv[1] = dstFs.getUri().toString() + \"/hadoopdir\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"-rmr works on remote uri \" + argv[1], 0, ret);\n      //check du\n      argv[0] = \"-du\";\n      argv[1] = dstFs.getUri().toString() + \"/\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"du works on remote uri \", 0, ret);\n      //check put\n      File furi = new File(TEST_ROOT_DIR, \"furi\");\n      createLocalFile(furi);\n      argv = new String[3];\n      argv[0] = \"-put\";\n      argv[1] = furi.toURI().toString();\n      argv[2] = dstFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" put is working \", 0, ret);\n      //check cp\n      argv[0] = \"-cp\";\n      argv[1] = dstFs.getUri().toString() + \"/furi\";\n      argv[2] = srcFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" cp is working \", 0, ret);\n      assertTrue(srcFs.exists(new Path(\"/furi\")));\n      //check cat\n      argv = new String[2];\n      argv[0] = \"-cat\";\n      argv[1] = dstFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" cat is working \", 0, ret);\n      //check chown\n      dstFs.delete(new Path(\"/furi\"), true);\n      dstFs.delete(new Path(\"/hadoopdir\"), true);\n      String file = \"/tmp/chownTest\";\n      Path path = new Path(file);\n      Path parent = new Path(\"/tmp\");\n      Path root = new Path(\"/\");\n      TestDFSShell.writeFile(dstFs, path);\n      runCmd(shell, \"-chgrp\", \"-R\", \"herbivores\", dstFs.getUri().toString() +\"/*\");\n      confirmOwner(null, \"herbivores\", dstFs, parent, path);\n      runCmd(shell, \"-chown\", \"-R\", \":reptiles\", dstFs.getUri().toString() + \"/\");\n      confirmOwner(null, \"reptiles\", dstFs, root, parent, path);\n      //check if default hdfs:/// works\n      argv[0] = \"-cat\";\n      argv[1] = \"hdfs:///furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" default works for cat\", 0, ret);\n      argv[0] = \"-ls\";\n      argv[1] = \"hdfs:///\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"default works for ls \", 0, ret);\n      argv[0] = \"-rmr\";\n      argv[1] = \"hdfs:///furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"default works for rm/rmr\", 0, ret);\n    } finally {\n      if (null != srcCluster) {\n        srcCluster.shutdown();\n      }\n      if (null != dstCluster) {\n        dstCluster.shutdown();\n      }\n    }\n  }","id":37754,"modified_method":"@Test (timeout = 30000)\n  public void testURIPaths() throws Exception {\n    Configuration srcConf = new HdfsConfiguration();\n    Configuration dstConf = new HdfsConfiguration();\n    MiniDFSCluster srcCluster =  null;\n    MiniDFSCluster dstCluster = null;\n    File bak = new File(PathUtils.getTestDir(getClass()), \"testURIPaths\");\n    bak.mkdirs();\n    try{\n      srcCluster = new MiniDFSCluster.Builder(srcConf).numDataNodes(2).build();\n      dstConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, bak.getAbsolutePath());\n      dstCluster = new MiniDFSCluster.Builder(dstConf).numDataNodes(2).build();\n      FileSystem srcFs = srcCluster.getFileSystem();\n      FileSystem dstFs = dstCluster.getFileSystem();\n      FsShell shell = new FsShell();\n      shell.setConf(srcConf);\n      //check for ls\n      String[] argv = new String[2];\n      argv[0] = \"-ls\";\n      argv[1] = dstFs.getUri().toString() + \"/\";\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"ls works on remote uri \", 0, ret);\n      //check for rm -r\n      dstFs.mkdirs(new Path(\"/hadoopdir\"));\n      argv = new String[2];\n      argv[0] = \"-rmr\";\n      argv[1] = dstFs.getUri().toString() + \"/hadoopdir\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"-rmr works on remote uri \" + argv[1], 0, ret);\n      //check du\n      argv[0] = \"-du\";\n      argv[1] = dstFs.getUri().toString() + \"/\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"du works on remote uri \", 0, ret);\n      //check put\n      File furi = new File(TEST_ROOT_DIR, \"furi\");\n      createLocalFile(furi);\n      argv = new String[3];\n      argv[0] = \"-put\";\n      argv[1] = furi.toURI().toString();\n      argv[2] = dstFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" put is working \", 0, ret);\n      //check cp\n      argv[0] = \"-cp\";\n      argv[1] = dstFs.getUri().toString() + \"/furi\";\n      argv[2] = srcFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" cp is working \", 0, ret);\n      assertTrue(srcFs.exists(new Path(\"/furi\")));\n      //check cat\n      argv = new String[2];\n      argv[0] = \"-cat\";\n      argv[1] = dstFs.getUri().toString() + \"/furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" cat is working \", 0, ret);\n      //check chown\n      dstFs.delete(new Path(\"/furi\"), true);\n      dstFs.delete(new Path(\"/hadoopdir\"), true);\n      String file = \"/tmp/chownTest\";\n      Path path = new Path(file);\n      Path parent = new Path(\"/tmp\");\n      Path root = new Path(\"/\");\n      TestDFSShell.writeFile(dstFs, path);\n      runCmd(shell, \"-chgrp\", \"-R\", \"herbivores\", dstFs.getUri().toString() +\"/*\");\n      confirmOwner(null, \"herbivores\", dstFs, parent, path);\n      runCmd(shell, \"-chown\", \"-R\", \":reptiles\", dstFs.getUri().toString() + \"/\");\n      confirmOwner(null, \"reptiles\", dstFs, root, parent, path);\n      //check if default hdfs:/// works\n      argv[0] = \"-cat\";\n      argv[1] = \"hdfs:///furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\" default works for cat\", 0, ret);\n      argv[0] = \"-ls\";\n      argv[1] = \"hdfs:///\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"default works for ls \", 0, ret);\n      argv[0] = \"-rmr\";\n      argv[1] = \"hdfs:///furi\";\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"default works for rm/rmr\", 0, ret);\n    } finally {\n      if (null != srcCluster) {\n        srcCluster.shutdown();\n      }\n      if (null != dstCluster) {\n        dstCluster.shutdown();\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testSetXAttrPermission() throws Exception {\n    UserGroupInformation user = UserGroupInformation.\n        createUserForTesting(\"user\", new String[] {\"mygroup\"});\n    MiniDFSCluster cluster = null;\n    PrintStream bak = null;\n    try {\n      final Configuration conf = new HdfsConfiguration();\n      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n      cluster.waitActive();\n\n      FileSystem fs = cluster.getFileSystem();\n      Path p = new Path(\"/foo\");\n      fs.mkdirs(p);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(conf);\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      // No permission to write xattr\n      fs.setPermission(p, new FsPermission((short) 0700));\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      int ret = ToolRunner.run(fshell, new String[]{\n          \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n      assertEquals(\"Returned should be 0\", 0, ret);\n      out.reset();\n\n      // No permission to read and remove\n      fs.setPermission(p, new FsPermission((short) 0750));\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Read\n          int ret = ToolRunner.run(fshell, new String[]{\n              \"-getfattr\", \"-n\", \"user.a1\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          // Remove\n          ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-x\", \"user.a1\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n      if (cluster != null) {\n        cluster.shutdown();\n      }\n    }\n  }","id":37755,"modified_method":"@Test (timeout = 30000)\n  public void testSetXAttrPermission() throws Exception {\n    UserGroupInformation user = UserGroupInformation.\n        createUserForTesting(\"user\", new String[] {\"mygroup\"});\n    PrintStream bak = null;\n    try {\n      Path p = new Path(\"/foo\");\n      dfs.mkdirs(p);\n      bak = System.err;\n\n      final FsShell fshell = new FsShell(dfs.getConf());\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setErr(new PrintStream(out));\n\n      // No permission to write xattr\n      dfs.setPermission(p, new FsPermission((short) 0700));\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          int ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n\n      int ret = ToolRunner.run(fshell, new String[]{\n          \"-setfattr\", \"-n\", \"user.a1\", \"-v\", \"1234\", \"/foo\"});\n      assertEquals(\"Returned should be 0\", 0, ret);\n      out.reset();\n\n      // No permission to read and remove\n      dfs.setPermission(p, new FsPermission((short) 0750));\n      user.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // Read\n          int ret = ToolRunner.run(fshell, new String[]{\n              \"-getfattr\", \"-n\", \"user.a1\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          String str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          // Remove\n          ret = ToolRunner.run(fshell, new String[]{\n              \"-setfattr\", \"-x\", \"user.a1\", \"/foo\"});\n          assertEquals(\"Returned should be 1\", 1, ret);\n          str = out.toString();\n          assertTrue(\"Permission denied printed\",\n              str.indexOf(\"Permission denied\") != -1);\n          out.reset();\n          return null;\n        }\n      });\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testLsr() throws Exception {\n    final Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    DistributedFileSystem dfs = cluster.getFileSystem();\n\n    try {\n      final String root = createTree(dfs, \"lsr\");\n      dfs.mkdirs(new Path(root, \"zzz\"));\n\n      runLsr(new FsShell(conf), root, 0);\n\n      final Path sub = new Path(root, \"sub\");\n      dfs.setPermission(sub, new FsPermission((short)0));\n\n      final UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\n      final String tmpusername = ugi.getShortUserName() + \"1\";\n      UserGroupInformation tmpUGI = UserGroupInformation.createUserForTesting(\n          tmpusername, new String[] {tmpusername});\n      String results = tmpUGI.doAs(new PrivilegedExceptionAction<String>() {\n        @Override\n        public String run() throws Exception {\n          return runLsr(new FsShell(conf), root, 1);\n        }\n      });\n      assertTrue(results.contains(\"zzz\"));\n    } finally {\n      cluster.shutdown();\n    }\n  }","id":37756,"modified_method":"@Test (timeout = 30000)\n  public void testLsr() throws Exception {\n    final Configuration conf = dfs.getConf();\n    final String root = createTree(dfs, \"lsr\");\n    dfs.mkdirs(new Path(root, \"zzz\"));\n\n    runLsr(new FsShell(conf), root, 0);\n\n    final Path sub = new Path(root, \"sub\");\n    dfs.setPermission(sub, new FsPermission((short)0));\n\n    final UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\n    final String tmpusername = ugi.getShortUserName() + \"1\";\n    UserGroupInformation tmpUGI = UserGroupInformation.createUserForTesting(\n        tmpusername, new String[] {tmpusername});\n    String results = tmpUGI.doAs(new PrivilegedExceptionAction<String>() {\n      @Override\n      public String run() throws Exception {\n        return runLsr(new FsShell(conf), root, 1);\n      }\n    });\n    assertTrue(results.contains(\"zzz\"));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   * Test -stat [format] <path>... prints statistics about the file/directory\n   * at <path> in the specified format.\n   */\n  @Test (timeout = 30000)\n  public void testStat() throws Exception {\n    final int blockSize = 1024;\n    final Configuration conf = new HdfsConfiguration();\n    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, blockSize);\n\n    try (MiniDFSCluster cluster =\n             new MiniDFSCluster.Builder(conf).numDataNodes(3).build()) {\n      cluster.waitActive();\n      final DistributedFileSystem dfs = cluster.getFileSystem();\n\n      final SimpleDateFormat fmt = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n      fmt.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n      final Path testDir1 = new Path(\"testStat\", \"dir1\");\n      dfs.mkdirs(testDir1);\n      final Path testFile2 = new Path(testDir1, \"file2\");\n      DFSTestUtil.createFile(dfs, testFile2, 2 * blockSize, (short) 3, 0);\n      final FileStatus status1 = dfs.getFileStatus(testDir1);\n      final String mtime1 = fmt.format(new Date(status1.getModificationTime()));\n      final FileStatus status2 = dfs.getFileStatus(testFile2);\n      final String mtime2 = fmt.format(new Date(status2.getModificationTime()));\n\n      final ByteArrayOutputStream out = new ByteArrayOutputStream();\n      System.setOut(new PrintStream(out));\n\n      doFsStat(conf, null);\n\n      out.reset();\n      doFsStat(conf, null, testDir1);\n      assertEquals(\"Unexpected -stat output: \" + out,\n          out.toString(), String.format(\"%s%n\", mtime1));\n\n      out.reset();\n      doFsStat(conf, null, testDir1, testFile2);\n      assertEquals(\"Unexpected -stat output: \" + out,\n          out.toString(), String.format(\"%s%n%s%n\", mtime1, mtime2));\n\n      doFsStat(conf, \"%F %u:%g %b %y %n\");\n\n      out.reset();\n      doFsStat(conf, \"%F %u:%g %b %y %n\", testDir1);\n      assertTrue(out.toString(), out.toString().contains(mtime1));\n      assertTrue(out.toString(), out.toString().contains(\"directory\"));\n      assertTrue(out.toString(), out.toString().contains(status1.getGroup()));\n\n      out.reset();\n      doFsStat(conf, \"%F %u:%g %b %y %n\", testDir1, testFile2);\n      assertTrue(out.toString(), out.toString().contains(mtime1));\n      assertTrue(out.toString(), out.toString().contains(\"regular file\"));\n      assertTrue(out.toString(), out.toString().contains(mtime2));\n    }\n  }","id":37757,"modified_method":"/**\n   * Test -stat [format] <path>... prints statistics about the file/directory\n   * at <path> in the specified format.\n   */\n  @Test (timeout = 30000)\n  public void testStat() throws Exception {\n    final SimpleDateFormat fmt = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n    fmt.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n    final Path testDir1 = new Path(\"testStat\", \"dir1\");\n    dfs.mkdirs(testDir1);\n    final Path testFile2 = new Path(testDir1, \"file2\");\n    DFSTestUtil.createFile(dfs, testFile2, 2 * BLOCK_SIZE, (short) 3, 0);\n    final FileStatus status1 = dfs.getFileStatus(testDir1);\n    final String mtime1 = fmt.format(new Date(status1.getModificationTime()));\n    final FileStatus status2 = dfs.getFileStatus(testFile2);\n    final String mtime2 = fmt.format(new Date(status2.getModificationTime()));\n\n    final ByteArrayOutputStream out = new ByteArrayOutputStream();\n    System.setOut(new PrintStream(out));\n\n    doFsStat(dfs.getConf(), null);\n\n    out.reset();\n    doFsStat(dfs.getConf(), null, testDir1);\n    assertEquals(\"Unexpected -stat output: \" + out,\n        out.toString(), String.format(\"%s%n\", mtime1));\n\n    out.reset();\n    doFsStat(dfs.getConf(), null, testDir1, testFile2);\n    assertEquals(\"Unexpected -stat output: \" + out,\n        out.toString(), String.format(\"%s%n%s%n\", mtime1, mtime2));\n\n    doFsStat(dfs.getConf(), \"%F %u:%g %b %y %n\");\n\n    out.reset();\n    doFsStat(dfs.getConf(), \"%F %u:%g %b %y %n\", testDir1);\n    assertTrue(out.toString(), out.toString().contains(mtime1));\n    assertTrue(out.toString(), out.toString().contains(\"directory\"));\n    assertTrue(out.toString(), out.toString().contains(status1.getGroup()));\n\n    out.reset();\n    doFsStat(dfs.getConf(), \"%F %u:%g %b %y %n\", testDir1, testFile2);\n    assertTrue(out.toString(), out.toString().contains(mtime1));\n    assertTrue(out.toString(), out.toString().contains(\"regular file\"));\n    assertTrue(out.toString(), out.toString().contains(mtime2));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testCount() throws Exception {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    DistributedFileSystem dfs = cluster.getFileSystem();\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      String root = createTree(dfs, \"count\");\n\n      // Verify the counts\n      runCount(root, 2, 4, shell);\n      runCount(root + \"2\", 2, 1, shell);\n      runCount(root + \"2/f1\", 0, 1, shell);\n      runCount(root + \"2/sub\", 1, 0, shell);\n\n      final FileSystem localfs = FileSystem.getLocal(conf);\n      Path localpath = new Path(TEST_ROOT_DIR, \"testcount\");\n      localpath = localpath.makeQualified(localfs.getUri(),\n          localfs.getWorkingDirectory());\n      localfs.mkdirs(localpath);\n\n      final String localstr = localpath.toString();\n      System.out.println(\"localstr=\" + localstr);\n      runCount(localstr, 1, 0, shell);\n      assertEquals(0, runCmd(shell, \"-count\", root, localstr));\n    } finally {\n      try {\n        dfs.close();\n      } catch (Exception e) {\n      }\n      cluster.shutdown();\n    }\n  }","id":37758,"modified_method":"@Test (timeout = 30000)\n  public void testCount() throws Exception {\n    FsShell shell = new FsShell(dfs.getConf());\n\n    String root = createTree(dfs, \"count\");\n\n    // Verify the counts\n    runCount(root, 2, 4, shell);\n    runCount(root + \"2\", 2, 1, shell);\n    runCount(root + \"2/f1\", 0, 1, shell);\n    runCount(root + \"2/sub\", 1, 0, shell);\n\n    final FileSystem localfs = FileSystem.getLocal(dfs.getConf());\n    Path localpath = new Path(TEST_ROOT_DIR, \"testcount\");\n    localpath = localpath.makeQualified(localfs.getUri(),\n        localfs.getWorkingDirectory());\n    localfs.mkdirs(localpath);\n\n    final String localstr = localpath.toString();\n    System.out.println(\"localstr=\" + localstr);\n    runCount(localstr, 1, 0, shell);\n    assertEquals(0, runCmd(shell, \"-count\", root, localstr));\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"/**\n   * Tests various options of DFSShell.\n   */\n  @Test (timeout = 120000)\n  public void testDFSShell() throws Exception {\n    final Configuration conf = new HdfsConfiguration();\n    /* This tests some properties of ChecksumFileSystem as well.\n     * Make sure that we create ChecksumDFS */\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    assertTrue(\"Not a HDFS: \"+fs.getUri(),\n            fs instanceof DistributedFileSystem);\n    DistributedFileSystem fileSys = (DistributedFileSystem)fs;\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      // First create a new directory with mkdirs\n      Path myPath = new Path(\"/test/mkdirs\");\n      assertTrue(fileSys.mkdirs(myPath));\n      assertTrue(fileSys.exists(myPath));\n      assertTrue(fileSys.mkdirs(myPath));\n\n      // Second, create a file in that directory.\n      Path myFile = new Path(\"/test/mkdirs/myFile\");\n      writeFile(fileSys, myFile);\n      assertTrue(fileSys.exists(myFile));\n      Path myFile2 = new Path(\"/test/mkdirs/myFile2\");\n      writeFile(fileSys, myFile2);\n      assertTrue(fileSys.exists(myFile2));\n\n      // Verify that rm with a pattern\n      {\n        String[] args = new String[2];\n        args[0] = \"-rm\";\n        args[1] = \"/test/mkdirs/myFile*\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertTrue(val == 0);\n        assertFalse(fileSys.exists(myFile));\n        assertFalse(fileSys.exists(myFile2));\n\n        //re-create the files for other tests\n        writeFile(fileSys, myFile);\n        assertTrue(fileSys.exists(myFile));\n        writeFile(fileSys, myFile2);\n        assertTrue(fileSys.exists(myFile2));\n      }\n\n      // Verify that we can read the file\n      {\n        String[] args = new String[3];\n        args[0] = \"-cat\";\n        args[1] = \"/test/mkdirs/myFile\";\n        args[2] = \"/test/mkdirs/myFile2\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run: \" +\n                             StringUtils.stringifyException(e));\n        }\n        assertTrue(val == 0);\n      }\n      fileSys.delete(myFile2, true);\n\n      // Verify that we get an error while trying to read an nonexistent file\n      {\n        String[] args = new String[2];\n        args[0] = \"-cat\";\n        args[1] = \"/test/mkdirs/myFile1\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertTrue(val != 0);\n      }\n\n      // Verify that we get an error while trying to delete an nonexistent file\n      {\n        String[] args = new String[2];\n        args[0] = \"-rm\";\n        args[1] = \"/test/mkdirs/myFile1\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertTrue(val != 0);\n      }\n\n      // Verify that we succeed in removing the file we created\n      {\n        String[] args = new String[2];\n        args[0] = \"-rm\";\n        args[1] = \"/test/mkdirs/myFile\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertTrue(val == 0);\n      }\n\n      // Verify touch/test\n      {\n        String[] args;\n        int val;\n\n        args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-e\";\n        args[2] = \"/test/mkdirs/noFileHere\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n\n        args[1] = \"-z\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n\n        args = new String[2];\n        args[0] = \"-touchz\";\n        args[1] = \"/test/mkdirs/isFileHere\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        args = new String[2];\n        args[0] = \"-touchz\";\n        args[1] = \"/test/mkdirs/thisDirNotExists/isFileHere\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n\n\n        args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-e\";\n        args[2] = \"/test/mkdirs/isFileHere\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        args[1] = \"-d\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n\n        args[1] = \"-z\";\n        val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n      }\n\n      // Verify that cp from a directory to a subdirectory fails\n      {\n        String[] args = new String[2];\n        args[0] = \"-mkdir\";\n        args[1] = \"/test/dir1\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        // this should fail\n        String[] args1 = new String[3];\n        args1[0] = \"-cp\";\n        args1[1] = \"/test/dir1\";\n        args1[2] = \"/test/dir1/dir2\";\n        val = 0;\n        try {\n          val = shell.run(args1);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n\n        // this should succeed\n        args1[0] = \"-cp\";\n        args1[1] = \"/test/dir1\";\n        args1[2] = \"/test/dir1foo\";\n        val = -1;\n        try {\n          val = shell.run(args1);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        // this should fail\n        args1[0] = \"-cp\";\n        args1[1] = \"/\";\n        args1[2] = \"/test\";\n        val = 0;\n        try {\n          val = shell.run(args1);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n              e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n      }\n\n      // Verify -test -f negative case (missing file)\n      {\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-f\";\n        args[2] = \"/test/mkdirs/noFileHere\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n      }\n\n      // Verify -test -f negative case (directory rather than file)\n      {\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-f\";\n        args[2] = \"/test/mkdirs\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n      }\n\n      // Verify -test -f positive case\n      {\n        writeFile(fileSys, myFile);\n        assertTrue(fileSys.exists(myFile));\n\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-f\";\n        args[2] = myFile.toString();\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n      }\n\n      // Verify -test -s negative case (missing file)\n      {\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-s\";\n        args[2] = \"/test/mkdirs/noFileHere\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n      }\n\n      // Verify -test -s negative case (zero length file)\n      {\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-s\";\n        args[2] = \"/test/mkdirs/isFileHere\";\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(1, val);\n      }\n\n      // Verify -test -s positive case (nonzero length file)\n      {\n        String[] args = new String[3];\n        args[0] = \"-test\";\n        args[1] = \"-s\";\n        args[2] = myFile.toString();\n        int val = -1;\n        try {\n          val = shell.run(args);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n      }\n\n      // Verify -test -w/-r\n      {\n        Path permDir = new Path(\"/test/permDir\");\n        Path permFile = new Path(\"/test/permDir/permFile\");\n        mkdir(fs, permDir);\n        writeFile(fs, permFile);\n\n        // Verify -test -w positive case (dir exists and can write)\n        final String[] wargs = new String[3];\n        wargs[0] = \"-test\";\n        wargs[1] = \"-w\";\n        wargs[2] = permDir.toString();\n        int val = -1;\n        try {\n          val = shell.run(wargs);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n              e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        // Verify -test -r positive case (file exists and can read)\n        final String[] rargs = new String[3];\n        rargs[0] = \"-test\";\n        rargs[1] = \"-r\";\n        rargs[2] = permFile.toString();\n        try {\n          val = shell.run(rargs);\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n              e.getLocalizedMessage());\n        }\n        assertEquals(0, val);\n\n        // Verify -test -r negative case (file exists but cannot read)\n        runCmd(shell, \"-chmod\", \"600\", permFile.toString());\n\n        UserGroupInformation smokeUser =\n            UserGroupInformation.createUserForTesting(\"smokeUser\",\n                new String[] {\"hadoop\"});\n        smokeUser.doAs(new PrivilegedExceptionAction<String>() {\n            @Override\n            public String run() throws Exception {\n              FsShell shell = new FsShell(conf);\n              int exitCode = shell.run(rargs);\n              assertEquals(1, exitCode);\n              return null;\n            }\n          });\n\n        // Verify -test -w negative case (dir exists but cannot write)\n        runCmd(shell, \"-chown\", \"-R\", \"not_allowed\", permDir.toString());\n        runCmd(shell, \"-chmod\", \"-R\", \"700\", permDir.toString());\n\n        smokeUser.doAs(new PrivilegedExceptionAction<String>() {\n          @Override\n          public String run() throws Exception {\n            FsShell shell = new FsShell(conf);\n            int exitCode = shell.run(wargs);\n            assertEquals(1, exitCode);\n            return null;\n          }\n        });\n\n        // cleanup\n        fs.delete(permDir, true);\n      }\n    } finally {\n      try {\n        fileSys.close();\n      } catch (Exception e) {\n      }\n      cluster.shutdown();\n    }\n  }","id":37759,"modified_method":"/**\n   * Tests various options of DFSShell.\n   */\n  @Test (timeout = 120000)\n  public void testDFSShell() throws Exception {\n    /* This tests some properties of ChecksumFileSystem as well.\n     * Make sure that we create ChecksumDFS */\n    FsShell shell = new FsShell(dfs.getConf());\n\n    // First create a new directory with mkdirs\n    Path myPath = new Path(\"/testDFSShell/mkdirs\");\n    assertTrue(dfs.mkdirs(myPath));\n    assertTrue(dfs.exists(myPath));\n    assertTrue(dfs.mkdirs(myPath));\n\n    // Second, create a file in that directory.\n    Path myFile = new Path(\"/testDFSShell/mkdirs/myFile\");\n    writeFile(dfs, myFile);\n    assertTrue(dfs.exists(myFile));\n    Path myFile2 = new Path(\"/testDFSShell/mkdirs/myFile2\");\n    writeFile(dfs, myFile2);\n    assertTrue(dfs.exists(myFile2));\n\n    // Verify that rm with a pattern\n    {\n      String[] args = new String[2];\n      args[0] = \"-rm\";\n      args[1] = \"/testDFSShell/mkdirs/myFile*\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertTrue(val == 0);\n      assertFalse(dfs.exists(myFile));\n      assertFalse(dfs.exists(myFile2));\n\n      //re-create the files for other tests\n      writeFile(dfs, myFile);\n      assertTrue(dfs.exists(myFile));\n      writeFile(dfs, myFile2);\n      assertTrue(dfs.exists(myFile2));\n    }\n\n    // Verify that we can read the file\n    {\n      String[] args = new String[3];\n      args[0] = \"-cat\";\n      args[1] = \"/testDFSShell/mkdirs/myFile\";\n      args[2] = \"/testDFSShell/mkdirs/myFile2\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run: \" +\n                           StringUtils.stringifyException(e));\n      }\n      assertTrue(val == 0);\n    }\n    dfs.delete(myFile2, true);\n\n    // Verify that we get an error while trying to read an nonexistent file\n    {\n      String[] args = new String[2];\n      args[0] = \"-cat\";\n      args[1] = \"/testDFSShell/mkdirs/myFile1\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertTrue(val != 0);\n    }\n\n    // Verify that we get an error while trying to delete an nonexistent file\n    {\n      String[] args = new String[2];\n      args[0] = \"-rm\";\n      args[1] = \"/testDFSShell/mkdirs/myFile1\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertTrue(val != 0);\n    }\n\n    // Verify that we succeed in removing the file we created\n    {\n      String[] args = new String[2];\n      args[0] = \"-rm\";\n      args[1] = \"/testDFSShell/mkdirs/myFile\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertTrue(val == 0);\n    }\n\n    // Verify touch/test\n    {\n      String[] args;\n      int val;\n\n      args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-e\";\n      args[2] = \"/testDFSShell/mkdirs/noFileHere\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n\n      args[1] = \"-z\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n\n      args = new String[2];\n      args[0] = \"-touchz\";\n      args[1] = \"/testDFSShell/mkdirs/isFileHere\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      args = new String[2];\n      args[0] = \"-touchz\";\n      args[1] = \"/testDFSShell/mkdirs/thisDirNotExists/isFileHere\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n\n\n      args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-e\";\n      args[2] = \"/testDFSShell/mkdirs/isFileHere\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      args[1] = \"-d\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n\n      args[1] = \"-z\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n    }\n\n    // Verify that cp from a directory to a subdirectory fails\n    {\n      String[] args = new String[2];\n      args[0] = \"-mkdir\";\n      args[1] = \"/testDFSShell/dir1\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      // this should fail\n      String[] args1 = new String[3];\n      args1[0] = \"-cp\";\n      args1[1] = \"/testDFSShell/dir1\";\n      args1[2] = \"/testDFSShell/dir1/dir2\";\n      val = 0;\n      try {\n        val = shell.run(args1);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n\n      // this should succeed\n      args1[0] = \"-cp\";\n      args1[1] = \"/testDFSShell/dir1\";\n      args1[2] = \"/testDFSShell/dir1foo\";\n      val = -1;\n      try {\n        val = shell.run(args1);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      // this should fail\n      args1[0] = \"-cp\";\n      args1[1] = \"/\";\n      args1[2] = \"/test\";\n      val = 0;\n      try {\n        val = shell.run(args1);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n    }\n\n    // Verify -test -f negative case (missing file)\n    {\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-f\";\n      args[2] = \"/testDFSShell/mkdirs/noFileHere\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n    }\n\n    // Verify -test -f negative case (directory rather than file)\n    {\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-f\";\n      args[2] = \"/testDFSShell/mkdirs\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n    }\n\n    // Verify -test -f positive case\n    {\n      writeFile(dfs, myFile);\n      assertTrue(dfs.exists(myFile));\n\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-f\";\n      args[2] = myFile.toString();\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n    }\n\n    // Verify -test -s negative case (missing file)\n    {\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-s\";\n      args[2] = \"/testDFSShell/mkdirs/noFileHere\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n    }\n\n    // Verify -test -s negative case (zero length file)\n    {\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-s\";\n      args[2] = \"/testDFSShell/mkdirs/isFileHere\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(1, val);\n    }\n\n    // Verify -test -s positive case (nonzero length file)\n    {\n      String[] args = new String[3];\n      args[0] = \"-test\";\n      args[1] = \"-s\";\n      args[2] = myFile.toString();\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n    }\n\n    // Verify -test -w/-r\n    {\n      Path permDir = new Path(\"/testDFSShell/permDir\");\n      Path permFile = new Path(\"/testDFSShell/permDir/permFile\");\n      mkdir(dfs, permDir);\n      writeFile(dfs, permFile);\n\n      // Verify -test -w positive case (dir exists and can write)\n      final String[] wargs = new String[3];\n      wargs[0] = \"-test\";\n      wargs[1] = \"-w\";\n      wargs[2] = permDir.toString();\n      int val = -1;\n      try {\n        val = shell.run(wargs);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      // Verify -test -r positive case (file exists and can read)\n      final String[] rargs = new String[3];\n      rargs[0] = \"-test\";\n      rargs[1] = \"-r\";\n      rargs[2] = permFile.toString();\n      try {\n        val = shell.run(rargs);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(0, val);\n\n      // Verify -test -r negative case (file exists but cannot read)\n      runCmd(shell, \"-chmod\", \"600\", permFile.toString());\n\n      UserGroupInformation smokeUser =\n          UserGroupInformation.createUserForTesting(\"smokeUser\",\n              new String[] {\"hadoop\"});\n      smokeUser.doAs(new PrivilegedExceptionAction<String>() {\n          @Override\n          public String run() throws Exception {\n            FsShell shell = new FsShell(dfs.getConf());\n            int exitCode = shell.run(rargs);\n            assertEquals(1, exitCode);\n            return null;\n          }\n        });\n\n      // Verify -test -w negative case (dir exists but cannot write)\n      runCmd(shell, \"-chown\", \"-R\", \"not_allowed\", permDir.toString());\n      runCmd(shell, \"-chmod\", \"-R\", \"700\", permDir.toString());\n\n      smokeUser.doAs(new PrivilegedExceptionAction<String>() {\n        @Override\n        public String run() throws Exception {\n          FsShell shell = new FsShell(dfs.getConf());\n          int exitCode = shell.run(wargs);\n          assertEquals(1, exitCode);\n          return null;\n        }\n      });\n\n      // cleanup\n      dfs.delete(permDir, true);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testCopyToLocal() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    assertTrue(\"Not a HDFS: \"+fs.getUri(),\n               fs instanceof DistributedFileSystem);\n    DistributedFileSystem dfs = (DistributedFileSystem)fs;\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      String root = createTree(dfs, \"copyToLocal\");\n\n      // Verify copying the tree\n      {\n        try {\n          assertEquals(0,\n              runCmd(shell, \"-copyToLocal\", root + \"*\", TEST_ROOT_DIR));\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                             e.getLocalizedMessage());\n        }\n\n        File localroot = new File(TEST_ROOT_DIR, \"copyToLocal\");\n        File localroot2 = new File(TEST_ROOT_DIR, \"copyToLocal2\");\n\n        File f1 = new File(localroot, \"f1\");\n        assertTrue(\"Copying failed.\", f1.isFile());\n\n        File f2 = new File(localroot, \"f2\");\n        assertTrue(\"Copying failed.\", f2.isFile());\n\n        File sub = new File(localroot, \"sub\");\n        assertTrue(\"Copying failed.\", sub.isDirectory());\n\n        File f3 = new File(sub, \"f3\");\n        assertTrue(\"Copying failed.\", f3.isFile());\n\n        File f4 = new File(sub, \"f4\");\n        assertTrue(\"Copying failed.\", f4.isFile());\n\n        File f5 = new File(localroot2, \"f1\");\n        assertTrue(\"Copying failed.\", f5.isFile());\n\n        f1.delete();\n        f2.delete();\n        f3.delete();\n        f4.delete();\n        f5.delete();\n        sub.delete();\n      }\n      // Verify copying non existing sources do not create zero byte\n      // destination files\n      {\n        String[] args = {\"-copyToLocal\", \"nosuchfile\", TEST_ROOT_DIR};\n        try {\n          assertEquals(1, shell.run(args));\n        } catch (Exception e) {\n          System.err.println(\"Exception raised from DFSShell.run \" +\n                            e.getLocalizedMessage());\n        }\n        File f6 = new File(TEST_ROOT_DIR, \"nosuchfile\");\n        assertTrue(!f6.exists());\n      }\n    } finally {\n      try {\n        dfs.close();\n      } catch (Exception e) {\n      }\n      cluster.shutdown();\n    }\n  }","id":37760,"modified_method":"@Test (timeout = 30000)\n  public void testCopyToLocal() throws IOException {\n    FsShell shell = new FsShell(dfs.getConf());\n\n    String root = createTree(dfs, \"copyToLocal\");\n\n    // Verify copying the tree\n    {\n      try {\n        assertEquals(0,\n            runCmd(shell, \"-copyToLocal\", root + \"*\", TEST_ROOT_DIR));\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                           e.getLocalizedMessage());\n      }\n\n      File localroot = new File(TEST_ROOT_DIR, \"copyToLocal\");\n      File localroot2 = new File(TEST_ROOT_DIR, \"copyToLocal2\");\n\n      File f1 = new File(localroot, \"f1\");\n      assertTrue(\"Copying failed.\", f1.isFile());\n\n      File f2 = new File(localroot, \"f2\");\n      assertTrue(\"Copying failed.\", f2.isFile());\n\n      File sub = new File(localroot, \"sub\");\n      assertTrue(\"Copying failed.\", sub.isDirectory());\n\n      File f3 = new File(sub, \"f3\");\n      assertTrue(\"Copying failed.\", f3.isFile());\n\n      File f4 = new File(sub, \"f4\");\n      assertTrue(\"Copying failed.\", f4.isFile());\n\n      File f5 = new File(localroot2, \"f1\");\n      assertTrue(\"Copying failed.\", f5.isFile());\n\n      f1.delete();\n      f2.delete();\n      f3.delete();\n      f4.delete();\n      f5.delete();\n      sub.delete();\n    }\n    // Verify copying non existing sources do not create zero byte\n    // destination files\n    {\n      String[] args = {\"-copyToLocal\", \"nosuchfile\", TEST_ROOT_DIR};\n      try {\n        assertEquals(1, shell.run(args));\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                          e.getLocalizedMessage());\n      }\n      File f6 = new File(TEST_ROOT_DIR, \"nosuchfile\");\n      assertTrue(!f6.exists());\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testCopyFromLocalWithPermissionDenied() throws Exception {\n    Configuration conf = new Configuration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    PrintStream bak = null;\n\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileWithNoReadPermissions\");\n    final String localfilepath = new Path(localFile.getAbsolutePath()).toUri().toString();\n    final String testdir = \"/tmp/TestDFSShell-CopyFromLocalWithPermissionDenied-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      localFile.createNewFile();\n      localFile.setReadable(false);\n      writeFile(fs, new Path(testdir, \"testFileForPut\"));\n      shell = new FsShell();\n\n      // capture system error messages, snarfed from testErrOutPut()\n      bak = System.err;\n      ByteArrayOutputStream out = new ByteArrayOutputStream();\n      PrintStream tmp = new PrintStream(out);\n      System.setErr(tmp);\n\n      // Tests for put\n      String[] argv = new String[] { \"-put\", localfilepath, testdir };\n      int res = ToolRunner.run(shell, argv);\n      assertEquals(\"put is working\", ERROR, res);\n      String returned = out.toString();\n      assertTrue(\" outputs Permission denied error message\",\n          (returned.lastIndexOf(\"Permission denied\") != -1));\n\n      // Tests for copyFromLocal\n      argv = new String[] { \"-copyFromLocal\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"copyFromLocal -f is working\", ERROR, res);\n      returned = out.toString();\n      assertTrue(\" outputs Permission denied error message\",\n          (returned.lastIndexOf(\"Permission denied\") != -1));\n\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n\n      if (null != shell)\n        shell.close();\n\n      if (localFile.exists())\n        localFile.delete();\n\n      if (null != fs) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37761,"modified_method":"@Test (timeout = 30000)\n  public void testCopyFromLocalWithPermissionDenied() throws Exception {\n    FsShell shell = null;\n    PrintStream bak = null;\n\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileWithNoReadPermissions\");\n    final String localfilepath = new Path(localFile.getAbsolutePath()).toUri().toString();\n    final String testdir = \"/tmp/TestDFSShell-CopyFromLocalWithPermissionDenied-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      localFile.createNewFile();\n      localFile.setReadable(false);\n      writeFile(dfs, new Path(testdir, \"testFileForPut\"));\n      shell = new FsShell();\n\n      // capture system error messages, snarfed from testErrOutPut()\n      bak = System.err;\n      ByteArrayOutputStream out = new ByteArrayOutputStream();\n      PrintStream tmp = new PrintStream(out);\n      System.setErr(tmp);\n\n      // Tests for put\n      String[] argv = new String[] { \"-put\", localfilepath, testdir };\n      int res = ToolRunner.run(shell, argv);\n      assertEquals(\"put is working\", ERROR, res);\n      String returned = out.toString();\n      assertTrue(\" outputs Permission denied error message\",\n          (returned.lastIndexOf(\"Permission denied\") != -1));\n\n      // Tests for copyFromLocal\n      argv = new String[] { \"-copyFromLocal\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"copyFromLocal -f is working\", ERROR, res);\n      returned = out.toString();\n      assertTrue(\" outputs Permission denied error message\",\n          (returned.lastIndexOf(\"Permission denied\") != -1));\n\n    } finally {\n      if (bak != null) {\n        System.setErr(bak);\n      }\n\n      if (null != shell)\n        shell.close();\n\n      if (localFile.exists())\n        localFile.delete();\n\n      dfs.delete(hdfsTestDir, true);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testCopyCommandsWithForceOption() throws Exception {\n    Configuration conf = new Configuration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileForPut\");\n    final String localfilepath = new Path(localFile.getAbsolutePath()).toUri().toString();\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithForceOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      localFile.createNewFile();\n      writeFile(fs, new Path(testdir, \"testFileForPut\"));\n      shell = new FsShell();\n\n      // Tests for put\n      String[] argv = new String[] { \"-put\", \"-f\", localfilepath, testdir };\n      int res = ToolRunner.run(shell, argv);\n      assertEquals(\"put -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-put\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"put command itself is able to overwrite the file\", ERROR,\n          res);\n\n      // Tests for copyFromLocal\n      argv = new String[] { \"-copyFromLocal\", \"-f\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"copyFromLocal -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-copyFromLocal\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\n          \"copyFromLocal command itself is able to overwrite the file\", ERROR,\n          res);\n\n      // Tests for cp\n      argv = new String[] { \"-cp\", \"-f\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-cp\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"cp command itself is able to overwrite the file\", ERROR,\n          res);\n    } finally {\n      if (null != shell)\n        shell.close();\n\n      if (localFile.exists())\n        localFile.delete();\n\n      if (null != fs) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37762,"modified_method":"@Test (timeout = 30000)\n  public void testCopyCommandsWithForceOption() throws Exception {\n    FsShell shell = null;\n    final File localFile = new File(TEST_ROOT_DIR, \"testFileForPut\");\n    final String localfilepath = new Path(localFile.getAbsolutePath()).toUri().toString();\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithForceOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      localFile.createNewFile();\n      writeFile(dfs, new Path(testdir, \"testFileForPut\"));\n      shell = new FsShell();\n\n      // Tests for put\n      String[] argv = new String[] { \"-put\", \"-f\", localfilepath, testdir };\n      int res = ToolRunner.run(shell, argv);\n      assertEquals(\"put -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-put\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"put command itself is able to overwrite the file\", ERROR,\n          res);\n\n      // Tests for copyFromLocal\n      argv = new String[] { \"-copyFromLocal\", \"-f\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"copyFromLocal -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-copyFromLocal\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\n          \"copyFromLocal command itself is able to overwrite the file\", ERROR,\n          res);\n\n      // Tests for cp\n      argv = new String[] { \"-cp\", \"-f\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -f is not working\", SUCCESS, res);\n\n      argv = new String[] { \"-cp\", localfilepath, testdir };\n      res = ToolRunner.run(shell, argv);\n      assertEquals(\"cp command itself is able to overwrite the file\", ERROR,\n          res);\n    } finally {\n      if (null != shell)\n        shell.close();\n\n      if (localFile.exists())\n        localFile.delete();\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testDu() throws IOException {\n    int replication = 2;\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n        .numDataNodes(replication).build();\n    DistributedFileSystem fs = cluster.getFileSystem();\n    PrintStream psBackup = System.out;\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    PrintStream psOut = new PrintStream(out);\n    System.setOut(psOut);\n    FsShell shell = new FsShell();\n    shell.setConf(conf);\n\n    try {\n      cluster.waitActive();\n      Path myPath = new Path(\"/test/dir\");\n      assertTrue(fs.mkdirs(myPath));\n      assertTrue(fs.exists(myPath));\n      Path myFile = new Path(\"/test/dir/file\");\n      writeFile(fs, myFile);\n      assertTrue(fs.exists(myFile));\n      Path myFile2 = new Path(\"/test/dir/file2\");\n      writeFile(fs, myFile2);\n      assertTrue(fs.exists(myFile2));\n      Long myFileLength = fs.getFileStatus(myFile).getLen();\n      Long myFileDiskUsed = myFileLength * replication;\n      Long myFile2Length = fs.getFileStatus(myFile2).getLen();\n      Long myFile2DiskUsed = myFile2Length * replication;\n\n      String[] args = new String[2];\n      args[0] = \"-du\";\n      args[1] = \"/test/dir\";\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                            e.getLocalizedMessage());\n      }\n      assertTrue(val == 0);\n      String returnString = out.toString();\n      out.reset();\n      // Check if size matches as expected\n      assertThat(returnString, containsString(myFileLength.toString()));\n      assertThat(returnString, containsString(myFileDiskUsed.toString()));\n      assertThat(returnString, containsString(myFile2Length.toString()));\n      assertThat(returnString, containsString(myFile2DiskUsed.toString()));\n\n      // Check that -du -s reports the state of the snapshot\n      String snapshotName = \"ss1\";\n      Path snapshotPath = new Path(myPath, \".snapshot/\" + snapshotName);\n      fs.allowSnapshot(myPath);\n      assertThat(fs.createSnapshot(myPath, snapshotName), is(snapshotPath));\n      assertThat(fs.delete(myFile, false), is(true));\n      assertThat(fs.exists(myFile), is(false));\n\n      args = new String[3];\n      args[0] = \"-du\";\n      args[1] = \"-s\";\n      args[2] = snapshotPath.toString();\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertThat(val, is(0));\n      returnString = out.toString();\n      out.reset();\n      Long combinedLength = myFileLength + myFile2Length;\n      Long combinedDiskUsed = myFileDiskUsed + myFile2DiskUsed;\n      assertThat(returnString, containsString(combinedLength.toString()));\n      assertThat(returnString, containsString(combinedDiskUsed.toString()));\n\n      // Check if output is rendered properly with multiple input paths\n      Path myFile3 = new Path(\"/test/dir/file3\");\n      writeByte(fs, myFile3);\n      assertTrue(fs.exists(myFile3));\n      args = new String[3];\n      args[0] = \"-du\";\n      args[1] = \"/test/dir/file3\";\n      args[2] = \"/test/dir/file2\";\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(\"Return code should be 0.\", 0, val);\n      returnString = out.toString();\n      out.reset();\n      assertTrue(returnString.contains(\"1   2   /test/dir/file3\"));\n      assertTrue(returnString.contains(\"23  46  /test/dir/file2\"));\n    } finally {\n      System.setOut(psBackup);\n      cluster.shutdown();\n    }\n  }","id":37763,"modified_method":"@Test (timeout = 30000)\n  public void testDu() throws IOException {\n    int replication = 2;\n    PrintStream psBackup = System.out;\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\n    PrintStream psOut = new PrintStream(out);\n    System.setOut(psOut);\n    FsShell shell = new FsShell(dfs.getConf());\n\n    try {\n      final Path myPath = new Path(\"/testDu\", \"dir\");\n      assertTrue(dfs.mkdirs(myPath));\n      assertTrue(dfs.exists(myPath));\n      final Path myFile = new Path(myPath, \"file\");\n      writeFile(dfs, myFile);\n      assertTrue(dfs.exists(myFile));\n      final Path myFile2 = new Path(myPath, \"file2\");\n      writeFile(dfs, myFile2);\n      assertTrue(dfs.exists(myFile2));\n      Long myFileLength = dfs.getFileStatus(myFile).getLen();\n      Long myFileDiskUsed = myFileLength * replication;\n      Long myFile2Length = dfs.getFileStatus(myFile2).getLen();\n      Long myFile2DiskUsed = myFile2Length * replication;\n\n      String[] args = new String[2];\n      args[0] = \"-du\";\n      args[1] = myPath.toString();\n      int val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n                            e.getLocalizedMessage());\n      }\n      assertTrue(val == 0);\n      String returnString = out.toString();\n      out.reset();\n      // Check if size matches as expected\n      assertThat(returnString, containsString(myFileLength.toString()));\n      assertThat(returnString, containsString(myFileDiskUsed.toString()));\n      assertThat(returnString, containsString(myFile2Length.toString()));\n      assertThat(returnString, containsString(myFile2DiskUsed.toString()));\n\n      // Check that -du -s reports the state of the snapshot\n      String snapshotName = \"ss1\";\n      Path snapshotPath = new Path(myPath, \".snapshot/\" + snapshotName);\n      dfs.allowSnapshot(myPath);\n      assertThat(dfs.createSnapshot(myPath, snapshotName), is(snapshotPath));\n      assertThat(dfs.delete(myFile, false), is(true));\n      assertThat(dfs.exists(myFile), is(false));\n\n      args = new String[3];\n      args[0] = \"-du\";\n      args[1] = \"-s\";\n      args[2] = snapshotPath.toString();\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertThat(val, is(0));\n      returnString = out.toString();\n      out.reset();\n      Long combinedLength = myFileLength + myFile2Length;\n      Long combinedDiskUsed = myFileDiskUsed + myFile2DiskUsed;\n      assertThat(returnString, containsString(combinedLength.toString()));\n      assertThat(returnString, containsString(combinedDiskUsed.toString()));\n\n      // Check if output is rendered properly with multiple input paths\n      final Path myFile3 = new Path(myPath, \"file3\");\n      writeByte(dfs, myFile3);\n      assertTrue(dfs.exists(myFile3));\n      args = new String[3];\n      args[0] = \"-du\";\n      args[1] = myFile3.toString();\n      args[2] = myFile2.toString();\n      val = -1;\n      try {\n        val = shell.run(args);\n      } catch (Exception e) {\n        System.err.println(\"Exception raised from DFSShell.run \" +\n            e.getLocalizedMessage());\n      }\n      assertEquals(\"Return code should be 0.\", 0, val);\n      returnString = out.toString();\n      out.reset();\n      assertTrue(returnString.contains(\"1   2   \" + myFile3.toString()));\n      assertTrue(returnString.contains(\"25  50  \" + myFile2.toString()));\n    } finally {\n      System.setOut(psBackup);\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 30000)\n  public void testRmReserved() throws IOException {\n    Configuration conf = new HdfsConfiguration();\n    MiniDFSCluster cluster =\n        new MiniDFSCluster.Builder(conf).numDataNodes(2).build();\n    FileSystem fs = cluster.getFileSystem();\n    try {\n      fs.delete(new Path(\"/.reserved\"), true);\n      fail(\"Can't delete /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid path name /.reserved\"));\n    }\n    cluster.shutdown();\n  }","id":37764,"modified_method":"@Test (timeout = 30000)\n  public void testRmReserved() throws IOException {\n    try {\n      dfs.delete(new Path(\"/.reserved\"), true);\n      fail(\"Can't delete /.reserved\");\n    } catch (Exception e) {\n      // Expected, InvalidPathException thrown from remote\n      assertTrue(e.getMessage().contains(\"Invalid path name /.reserved\"));\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Test (timeout = 120000)\n  public void testCopyCommandsWithPreserveOption() throws Exception {\n    Configuration conf = new Configuration();\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY, true);\n    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY, true);\n    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1)\n        .format(true).build();\n    FsShell shell = null;\n    FileSystem fs = null;\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithPreserveOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      fs = cluster.getFileSystem();\n      fs.mkdirs(hdfsTestDir);\n      Path src = new Path(hdfsTestDir, \"srcfile\");\n      fs.create(src).close();\n\n      fs.setAcl(src, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(ACCESS, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n\n      FileStatus status = fs.getFileStatus(src);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      fs.setXAttr(src, USER_A1, USER_A1_VALUE);\n      fs.setXAttr(src, TRUSTED_A1, TRUSTED_A1_VALUE);\n\n      shell = new FsShell(conf);\n\n      // -p\n      Path target1 = new Path(hdfsTestDir, \"targetfile1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", src.toUri().toString(),\n          target1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -p is not working\", SUCCESS, ret);\n      FileStatus targetStatus = fs.getFileStatus(target1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      Map<String, byte[]> xattrs = fs.getXAttrs(target1);\n      assertTrue(xattrs.isEmpty());\n      List<AclEntry> acls = fs.getAclStatus(target1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptop\n      Path target2 = new Path(hdfsTestDir, \"targetfile2\");\n      argv = new String[] { \"-cp\", \"-ptop\", src.toUri().toString(),\n          target2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptop is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(target2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(target2);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(target2).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopx\n      Path target3 = new Path(hdfsTestDir, \"targetfile3\");\n      argv = new String[] { \"-cp\", \"-ptopx\", src.toUri().toString(),\n          target3.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopx is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(target3);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(target3);\n      assertEquals(xattrs.size(), 2);\n      assertArrayEquals(USER_A1_VALUE, xattrs.get(USER_A1));\n      assertArrayEquals(TRUSTED_A1_VALUE, xattrs.get(TRUSTED_A1));\n      acls = fs.getAclStatus(target3).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa\n      Path target4 = new Path(hdfsTestDir, \"targetfile4\");\n      argv = new String[] { \"-cp\", \"-ptopa\", src.toUri().toString(),\n          target4.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(target4);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(target4);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(target4).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(fs.getAclStatus(src), fs.getAclStatus(target4));\n\n      // -ptoa (verify -pa option will preserve permissions also)\n      Path target5 = new Path(hdfsTestDir, \"targetfile5\");\n      argv = new String[] { \"-cp\", \"-ptoa\", src.toUri().toString(),\n          target5.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptoa is not working\", SUCCESS, ret);\n      targetStatus = fs.getFileStatus(target5);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = fs.getXAttrs(target5);\n      assertTrue(xattrs.isEmpty());\n      acls = fs.getAclStatus(target5).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(fs.getAclStatus(src), fs.getAclStatus(target5));\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n\n      if (null != fs) {\n        fs.delete(hdfsTestDir, true);\n        fs.close();\n      }\n      cluster.shutdown();\n    }\n  }","id":37765,"modified_method":"@Test (timeout = 120000)\n  public void testCopyCommandsWithPreserveOption() throws Exception {\n    FsShell shell = null;\n    final String testdir = \"/tmp/TestDFSShell-testCopyCommandsWithPreserveOption-\"\n        + counter.getAndIncrement();\n    final Path hdfsTestDir = new Path(testdir);\n    try {\n      dfs.mkdirs(hdfsTestDir);\n      Path src = new Path(hdfsTestDir, \"srcfile\");\n      dfs.create(src).close();\n\n      dfs.setAcl(src, Lists.newArrayList(\n          aclEntry(ACCESS, USER, ALL),\n          aclEntry(ACCESS, USER, \"foo\", ALL),\n          aclEntry(ACCESS, GROUP, READ_EXECUTE),\n          aclEntry(ACCESS, GROUP, \"bar\", READ_EXECUTE),\n          aclEntry(ACCESS, OTHER, EXECUTE)));\n\n      FileStatus status = dfs.getFileStatus(src);\n      final long mtime = status.getModificationTime();\n      final long atime = status.getAccessTime();\n      final String owner = status.getOwner();\n      final String group = status.getGroup();\n      final FsPermission perm = status.getPermission();\n\n      dfs.setXAttr(src, USER_A1, USER_A1_VALUE);\n      dfs.setXAttr(src, TRUSTED_A1, TRUSTED_A1_VALUE);\n\n      shell = new FsShell(dfs.getConf());\n\n      // -p\n      Path target1 = new Path(hdfsTestDir, \"targetfile1\");\n      String[] argv = new String[] { \"-cp\", \"-p\", src.toUri().toString(),\n          target1.toUri().toString() };\n      int ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -p is not working\", SUCCESS, ret);\n      FileStatus targetStatus = dfs.getFileStatus(target1);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      FsPermission targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      Map<String, byte[]> xattrs = dfs.getXAttrs(target1);\n      assertTrue(xattrs.isEmpty());\n      List<AclEntry> acls = dfs.getAclStatus(target1).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptop\n      Path target2 = new Path(hdfsTestDir, \"targetfile2\");\n      argv = new String[] { \"-cp\", \"-ptop\", src.toUri().toString(),\n          target2.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptop is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(target2);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(target2);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(target2).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopx\n      Path target3 = new Path(hdfsTestDir, \"targetfile3\");\n      argv = new String[] { \"-cp\", \"-ptopx\", src.toUri().toString(),\n          target3.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopx is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(target3);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(target3);\n      assertEquals(xattrs.size(), 2);\n      assertArrayEquals(USER_A1_VALUE, xattrs.get(USER_A1));\n      assertArrayEquals(TRUSTED_A1_VALUE, xattrs.get(TRUSTED_A1));\n      acls = dfs.getAclStatus(target3).getEntries();\n      assertTrue(acls.isEmpty());\n      assertFalse(targetPerm.getAclBit());\n\n      // -ptopa\n      Path target4 = new Path(hdfsTestDir, \"targetfile4\");\n      argv = new String[] { \"-cp\", \"-ptopa\", src.toUri().toString(),\n          target4.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptopa is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(target4);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(target4);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(target4).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(dfs.getAclStatus(src), dfs.getAclStatus(target4));\n\n      // -ptoa (verify -pa option will preserve permissions also)\n      Path target5 = new Path(hdfsTestDir, \"targetfile5\");\n      argv = new String[] { \"-cp\", \"-ptoa\", src.toUri().toString(),\n          target5.toUri().toString() };\n      ret = ToolRunner.run(shell, argv);\n      assertEquals(\"cp -ptoa is not working\", SUCCESS, ret);\n      targetStatus = dfs.getFileStatus(target5);\n      assertEquals(mtime, targetStatus.getModificationTime());\n      assertEquals(atime, targetStatus.getAccessTime());\n      assertEquals(owner, targetStatus.getOwner());\n      assertEquals(group, targetStatus.getGroup());\n      targetPerm = targetStatus.getPermission();\n      assertTrue(perm.equals(targetPerm));\n      xattrs = dfs.getXAttrs(target5);\n      assertTrue(xattrs.isEmpty());\n      acls = dfs.getAclStatus(target5).getEntries();\n      assertFalse(acls.isEmpty());\n      assertTrue(targetPerm.getAclBit());\n      assertEquals(dfs.getAclStatus(src), dfs.getAclStatus(target5));\n    } finally {\n      if (null != shell) {\n        shell.close();\n      }\n    }\n  }","commit_id":"202325485d66dda7826218faa1fbd21fcd8b882e","url":"https://github.com/apache/hadoop"},{"original_method":"@Override\n\tpublic SetBucketAccessControlPolicyResponseType setBucketAccessControlPolicy(final SetBucketAccessControlPolicyType request) throws S3Exception {\n        Bucket bucket = getBucketAndCheckAuthorization(request);\n        if(request.getAccessControlPolicy() == null || request.getAccessControlPolicy().getAccessControlList() == null) {\n            //Can't set to null\n            throw new MalformedACLErrorException(request.getBucket() + \"/\" + request.getKey() + \"?acl\");\n        } else {\n            AccessControlPolicy fullPolicy;\n            //Expand the acl first\n            if(isCannedAclPolicy(request.getAccessControlPolicy())) {\n                fullPolicy = new AccessControlPolicy();\n                fullPolicy.setOwner(new CanonicalUser(bucket.getOwnerCanonicalId(), bucket.getOwnerDisplayName()));\n                try {\n                    fullPolicy.setAccessControlList(AclUtils.expandCannedAcl(request.getAccessControlPolicy().getAccessControlList(), bucket.getOwnerCanonicalId(), null));\n                } catch(Exception e) {\n                    throw new MalformedACLErrorException(request.getBucket() + \"?acl\");\n                }\n            } else {\n                fullPolicy = request.getAccessControlPolicy();\n                //Must have explicit owner\n                if(fullPolicy.getAccessControlList() == null || fullPolicy.getOwner() == null) {\n                    //Something happened in acl expansion.\n                    LOG.error(\"Cannot put ACL that does not exist in request\");\n                    throw new MalformedACLErrorException(request.getBucket() + \"?acl\");\n                }\n            }\n\n            try {\n                BucketMetadataManagers.getInstance().setAcp(bucket, fullPolicy);\n                SetBucketAccessControlPolicyResponseType reply = request.getReply();\n                reply.setBucket(request.getBucket());\n                return reply;\n            } catch(Exception e) {\n                LOG.error(\"Transaction error updating bucket ACL for bucket \" + request.getBucket(),e);\n                throw new InternalErrorException(request.getBucket() + \"?acl\");\n            }\n        }\n\t}","id":37766,"modified_method":"@Override\n\tpublic SetBucketAccessControlPolicyResponseType setBucketAccessControlPolicy(final SetBucketAccessControlPolicyType request) throws S3Exception {\n        Bucket bucket = getBucketAndCheckAuthorization(request);\n\t\tif (request.getAccessControlPolicy() == null || request.getAccessControlPolicy().getAccessControlList() == null) {\n\t\t\t// Can't set to null\n\t\t\tLOG.error(\"Cannot put ACL that does not exist in request\");\n\t\t\tthrow new MalformedACLErrorException(request.getBucket() + \"?acl\");\n\t\t} else {\n\t\t\t// Expand the acl first\n\t\t\tAccessControlPolicy fullPolicy = new AccessControlPolicy();\n\t\t\ttry {\n\t\t\t\tfullPolicy.setAccessControlList(AclUtils.expandCannedAcl(request.getAccessControlPolicy().getAccessControlList(), bucket.getOwnerCanonicalId(),\n\t\t\t\t\t\tnull));\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.error(\"Cannot expand the ACL in the request\");\n\t\t\t\tthrow new MalformedACLErrorException(request.getBucket() + \"?acl\");\n\t\t\t}\n\n\t\t\t// Check for the grants\n\t\t\tif (fullPolicy.getAccessControlList() == null || fullPolicy.getAccessControlList().getGrants() == null\n\t\t\t\t\t|| fullPolicy.getAccessControlList().getGrants().size() == 0) {\n\t\t\t\tLOG.error(\"Cannot put ACL that does not exist in request\");\n\t\t\t\tthrow new MalformedACLErrorException(request.getBucket() + \"?acl\");\n\t\t\t}\n\n\t\t\t// Check for the owner\n\t\t\tif (request.getAccessControlPolicy().getOwner() == null) {\n\t\t\t\tfullPolicy.setOwner(new CanonicalUser(bucket.getOwnerCanonicalId(), bucket.getOwnerDisplayName()));\n\t\t\t} else {\n\t\t\t\tfullPolicy.setOwner(request.getAccessControlPolicy().getOwner());\n\t\t\t}\n\n\t\t\t// Marshal into a string\n\t\t\ttry {\n\t\t\t\tString aclString = S3AccessControlledEntity.marshallAcpToString(fullPolicy);\n\t\t\t\tif (Strings.isNullOrEmpty(aclString)) {\n\t\t\t\t\tthrow new MalformedACLErrorException(request.getBucket() + \"?acl\");\n\t\t\t\t}\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.error(\"Invalid ACL policy\");\n\t\t\t\tthrow new MalformedACLErrorException(request.getBucket() + \"?acl\");\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tBucketMetadataManagers.getInstance().setAcp(bucket, fullPolicy);\n\t\t\t\tSetBucketAccessControlPolicyResponseType reply = request.getReply();\n\t\t\t\treply.setBucket(request.getBucket());\n\t\t\t\treturn reply;\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.error(\"Transaction error updating bucket ACL for bucket \" + request.getBucket(), e);\n\t\t\t\tthrow new InternalErrorException(request.getBucket() + \"?acl\");\n\t\t\t}\n\t\t}\n\t}","commit_id":"1d2bc96b1d25197b4911ece4d1dc6b488de5a003","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"/**\n     * Set from the messaging type. The owner must be properly set in\n     * the message msgAcl.\n     *\n     * @param msgAcl\n     */\n    public void setAcl(final AccessControlPolicy msgAcl) {\n        AccessControlPolicy policy = msgAcl;\n\n        //Add the owner info if not already set\n        if (policy.getOwner() == null && this.getOwnerCanonicalId() != null) {\n            policy.setOwner(new CanonicalUser(this.getOwnerCanonicalId(), this.getOwnerDisplayName()));\n        } else {\n            //Already present or can't be set\n        }\n\n        Map<String, Integer> resultMap = AccessControlPolicyToMap.INSTANCE.apply(policy);\n\n        //Serialize into json\n        setAcl(JSONObject.fromObject(resultMap).toString());\n        setDecodedAcl(resultMap);\n    }","id":37767,"modified_method":"/**\n     * Set from the messaging type. The owner must be properly set in\n     * the message msgAcl.\n     *\n     * @param msgAcl\n     */\n    public void setAcl(final AccessControlPolicy msgAcl) {\n        AccessControlPolicy policy = msgAcl;\n\n\t\t// Check for the owner and add it if not already set\n\t\tif (policy.getOwner() != null) {\n\t\t\tif (!StringUtils.equals(policy.getOwner().getID(), this.getOwnerCanonicalId())\n\t\t\t\t\t|| !StringUtils.equals(policy.getOwner().getDisplayName(), this.getOwnerDisplayName())) {\n\t\t\t\tthrow new RuntimeException(\"Owner cannot be changed\");\n\t\t\t} else {\n\t\t\t\t// Nothing to do here\n\t\t\t}\n\t\t} else {\n\t\t\t policy.setOwner(new CanonicalUser(this.getOwnerCanonicalId(), this.getOwnerDisplayName()));\n\t\t}\n\n        Map<String, Integer> resultMap = AccessControlPolicyToMap.INSTANCE.apply(policy);\n\n        //Serialize into json\n        setAcl(JSONObject.fromObject(resultMap).toString());\n        setDecodedAcl(resultMap);\n    }","commit_id":"1d2bc96b1d25197b4911ece4d1dc6b488de5a003","url":"https://github.com/eucalyptus/eucalyptus"},{"original_method":"@Override\n\t\tpublic Lock lock(String className, String key, String owner) {\n\t\t\tif (_lock == null) {\n\t\t\t\tLock lock = new LockImpl();\n\n\t\t\t\tlock.setKey(key);\n\n\t\t\t\tif (_override) {\n\t\t\t\t\tlock.setOwner(_value);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlock.setOwner(owner);\n\t\t\t\t}\n\n\t\t\t\t_lock = lock;\n\t\t\t}\n\n\t\t\treturn _lock;\n\t\t}","id":37768,"modified_method":"@Override\n\t\tpublic Lock lock(String className, String key, String owner) {\n\t\t\tif (_lock == null) {\n\t\t\t\tLock lock = new LockImpl();\n\n\t\t\t\tlock.setKey(key);\n\t\t\t\tlock.setOwner(owner);\n\n\t\t\t\t_lock = lock;\n\t\t\t}\n\n\t\t\treturn _lock;\n\t\t}","commit_id":"8d94470617d817e1b18e824954da6e2b468a887a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@Override\n\t\tpublic boolean isClusterNodeAlive(Address address) {\n\t\t\tif (_break && address.equals(_otherAddress)) {\n\t\t\t\tthrow new RuntimeException();\n\t\t\t}\n\n\t\t\treturn _addresses.contains(address);\n\t\t}","id":37769,"modified_method":"@Override\n\t\tpublic boolean isClusterNodeAlive(Address address) {\n\t\t\treturn _addresses.contains(address);\n\t\t}","commit_id":"8d94470617d817e1b18e824954da6e2b468a887a","url":"https://github.com/liferay/liferay-portal"},{"original_method":"@CheckForNull\n  public Notification sendChanges(DefaultIssue issue, IssueChangeContext context, IssueQueryResult queryResult, @Nullable String comment) {\n    Notification notification = createNotification(issue, context, queryResult.rule(issue), queryResult.project(issue), queryResult.component(issue), comment);\n    notificationsManager.scheduleForSending(notification);\n    return notification;\n  }","id":37770,"modified_method":"@CheckForNull\n  public Notification sendChanges(DefaultIssue issue, IssueChangeContext context, IssueQueryResult queryResult, @Nullable String comment) {\n    Notification notification = createChangeNotification(issue, context, queryResult.rule(issue), queryResult.project(issue), queryResult.component(issue), comment);\n    if (notification != null) {\n      notificationsManager.scheduleForSending(notification);\n    }\n    return notification;\n  }","commit_id":"9252f14cf53c146aaf52862f298d67989874b41f","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private Notification createNotification(DefaultIssue issue, IssueChangeContext context, Rule rule, Component project, @Nullable Component component, @Nullable String comment){\n    Notification notification = newNotification(project, \"issue-changes\");\n    notification.setFieldValue(\"key\", issue.key());\n    notification.setFieldValue(\"changeAuthor\", context.login());\n    notification.setFieldValue(\"reporter\", issue.reporter());\n    notification.setFieldValue(\"assignee\", issue.assignee());\n    notification.setFieldValue(\"message\", issue.message());\n    notification.setFieldValue(\"ruleName\", ruleName(rule));\n    notification.setFieldValue(\"componentKey\", issue.componentKey());\n    if (component != null) {\n      notification.setFieldValue(\"componentName\", component.longName());\n    }\n    if (comment != null) {\n      notification.setFieldValue(\"comment\", comment);\n    }\n\n    FieldDiffs diffs = issue.diffs();\n    if (diffs != null) {\n      for (Map.Entry<String, FieldDiffs.Diff> entry : diffs.diffs().entrySet()) {\n        String type = entry.getKey();\n        FieldDiffs.Diff diff = entry.getValue();\n        notification.setFieldValue(\"old.\" + type, diff.oldValue() != null ? diff.oldValue().toString() : null);\n        notification.setFieldValue(\"new.\" + type, diff.newValue() != null ? diff.newValue().toString() : null);\n      }\n    }\n    return notification;\n  }","id":37771,"modified_method":"@CheckForNull\n  private Notification createChangeNotification(DefaultIssue issue, IssueChangeContext context, Rule rule, Component project, @Nullable Component component, @Nullable String comment) {\n    if (comment == null && (issue.diffs() == null || issue.diffs().diffs().isEmpty())) {\n      return null;\n    }\n    Notification notification = newNotification(project, \"issue-changes\");\n    notification.setFieldValue(\"key\", issue.key());\n    notification.setFieldValue(\"changeAuthor\", context.login());\n    notification.setFieldValue(\"reporter\", issue.reporter());\n    notification.setFieldValue(\"assignee\", issue.assignee());\n    notification.setFieldValue(\"message\", issue.message());\n    notification.setFieldValue(\"ruleName\", ruleName(rule));\n    notification.setFieldValue(\"componentKey\", issue.componentKey());\n    if (component != null) {\n      notification.setFieldValue(\"componentName\", component.longName());\n    }\n    if (comment != null) {\n      notification.setFieldValue(\"comment\", comment);\n    }\n\n    FieldDiffs diffs = issue.diffs();\n    if (diffs != null) {\n      for (Map.Entry<String, FieldDiffs.Diff> entry : diffs.diffs().entrySet()) {\n        String type = entry.getKey();\n        FieldDiffs.Diff diff = entry.getValue();\n        notification.setFieldValue(\"old.\" + type, diff.oldValue() != null ? diff.oldValue().toString() : null);\n        notification.setFieldValue(\"new.\" + type, diff.newValue() != null ? diff.newValue().toString() : null);\n      }\n    }\n    return notification;\n  }","commit_id":"9252f14cf53c146aaf52862f298d67989874b41f","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"@CheckForNull\n  public Notification sendChanges(DefaultIssue issue, IssueChangeContext context, Rule rule, Component project, @Nullable Component component) {\n    if (issue.diffs() != null) {\n      Notification notification = createNotification(issue, context, rule, project, component, null);\n      notificationsManager.scheduleForSending(notification);\n      return notification;\n    }\n    return null;\n  }","id":37772,"modified_method":"@CheckForNull\n  public Notification sendChanges(DefaultIssue issue, IssueChangeContext context, Rule rule, Component project, @Nullable Component component) {\n    Notification notification = createChangeNotification(issue, context, rule, project, component, null);\n    if (notification != null) {\n      notificationsManager.scheduleForSending(notification);\n    }\n    return notification;\n  }","commit_id":"9252f14cf53c146aaf52862f298d67989874b41f","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"private void sendNotifications(Project project) {\n    int newIssues = 0;\n    IssueChangeContext context = IssueChangeContext.createScan(project.getAnalysisDate());\n    for (DefaultIssue issue : issueCache.all()) {\n      if (issue.isNew() && issue.resolution() == null) {\n        newIssues++;\n      }\n      if (issue.isChanged() && issue.diffs() != null) {\n        Rule rule = ruleFinder.findByKey(issue.ruleKey());\n        // TODO warning - rules with status REMOVED are currently ignored, but should not\n        if (rule != null) {\n          notifications.sendChanges(issue, context, rule, project, null);\n        }\n      }\n    }\n    if (newIssues > 0) {\n      notifications.sendNewIssues(project, newIssues);\n    }\n  }","id":37773,"modified_method":"private void sendNotifications(Project project) {\n    int newIssues = 0;\n    IssueChangeContext context = IssueChangeContext.createScan(project.getAnalysisDate());\n    for (DefaultIssue issue : issueCache.all()) {\n      if (issue.isNew() && issue.resolution() == null) {\n        newIssues++;\n      }\n      if (issue.isChanged()) {\n        Rule rule = ruleFinder.findByKey(issue.ruleKey());\n        // TODO warning - rules with status REMOVED are currently ignored, but should not\n        if (rule != null) {\n          notifications.sendChanges(issue, context, rule, project, null);\n        }\n      }\n    }\n    if (newIssues > 0) {\n      notifications.sendNewIssues(project, newIssues);\n    }\n  }","commit_id":"9252f14cf53c146aaf52862f298d67989874b41f","url":"https://github.com/SonarSource/sonarqube"},{"original_method":"/**\n     * Sets the currently used <tt>AccountRegistrationWizard<\/tt>.\n     *\n     * @param wizard the <tt>AccountRegistrationWizard<\/tt> to set as\n     *            current one\n     */\n    public void setCurrentWizard(AccountRegistrationWizard wizard)\n    {\n        this.currentWizard = wizard;\n\n        Dimension wizardSize = this.currentWizard.getSize();\n\n        summaryPage.setPreferredSize(wizardSize);\n\n        Iterator<WizardPage> i = wizard.getPages();\n\n        while(i.hasNext())\n        {\n            WizardPage page = i.next();\n\n            this.registerWizardPage(page.getIdentifier(), page);\n        }\n\n        this.setCurrentPage(wizard.getFirstPageIdentifier());\n\n        try {\n            this.setWizzardIcon(\n                ImageIO.read(new ByteArrayInputStream(wizard.getPageImage())));\n        }\n        catch (IOException e1) {\n            e1.printStackTrace();\n        }\n    }","id":37774,"modified_method":"/**\n     * Sets the currently used <tt>AccountRegistrationWizard<\/tt>.\n     *\n     * @param wizard the <tt>AccountRegistrationWizard<\/tt> to set as\n     *            current one\n     */\n    public void setCurrentWizard(AccountRegistrationWizard wizard)\n    {\n        this.currentWizard = wizard;\n\n        summaryPage.setPreferredSize(this.currentWizard.getSize());\n\n        Iterator<WizardPage> i = wizard.getPages();\n\n        while(i.hasNext())\n        {\n            WizardPage page = i.next();\n\n            this.registerWizardPage(page.getIdentifier(), page);\n        }\n\n        this.setCurrentPage(wizard.getFirstPageIdentifier());\n\n        try {\n            this.setWizzardIcon(\n                ImageIO.read(new ByteArrayInputStream(wizard.getPageImage())));\n        }\n        catch (IOException e1) {\n            e1.printStackTrace();\n        }\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Opens the corresponding wizard to modify an existing account given by the\n     * <tt>protocolProvider<\/tt> parameter.\n     *\n     * @param protocolProvider The <tt>ProtocolProviderService<\/tt> for the\n     *            account to modify.\n     */\n    public void modifyAccount(ProtocolProviderService protocolProvider)\n    {\n        AccountRegistrationWizard wizard\n            = registeredWizards.get(protocolProvider.getProtocolDisplayName());\n\n        this.setCurrentWizard(wizard);\n\n        wizard.setModification(true);\n\n        Iterator<WizardPage> i = wizard.getPages();\n\n        boolean firstPage = true;\n\n        while (i.hasNext())\n        {\n            WizardPage page = i.next();\n            Object identifier = page.getIdentifier();\n\n            this.registerWizardPage(identifier, page);\n\n            if (firstPage)\n            {\n                this.setCurrentPage(identifier);\n                firstPage = false;\n            }\n        }\n\n        wizard.loadAccount(protocolProvider);\n\n        try\n        {\n            this.setWizzardIcon(ImageIO.read(new ByteArrayInputStream(wizard\n                .getPageImage())));\n        }\n        catch (IOException e1)\n        {\n            e1.printStackTrace();\n        }\n    }","id":37775,"modified_method":"/**\n     * Opens the corresponding wizard to modify an existing account given by the\n     * <tt>protocolProvider<\/tt> parameter.\n     *\n     * @param protocolProvider The <tt>ProtocolProviderService<\/tt> for the\n     *            account to modify.\n     */\n    public void modifyAccount(ProtocolProviderService protocolProvider)\n    {\n        AccountRegistrationWizard wizard\n            = registeredWizards.get(protocolProvider.getProtocolDisplayName());\n\n        this.setCurrentWizard(wizard);\n\n        wizard.setModification(true);\n\n        wizard.loadAccount(protocolProvider);\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Saves the (protocol provider, wizard) pair in through the\n     * <tt>ConfigurationService<\/tt>.\n     *\n     * @param protocolProvider the protocol provider to save\n     * @param wizard the wizard to save\n     */\n    public void saveAccountWizard(ProtocolProviderService protocolProvider,\n        AccountRegistrationWizard wizard)\n    {\n        String prefix = \"net.java.sip.communicator.impl.gui.accounts\";\n\n        List<String> accounts =\n            configService.getPropertyNamesByPrefix(prefix, true);\n\n        boolean savedAccount = false;\n\n        for (String accountRootPropName : accounts)\n        {\n            String accountUID = configService.getString(accountRootPropName);\n\n            if (accountUID.equals(protocolProvider.getAccountID()\n                .getAccountUniqueID()))\n            {\n\n                configService.setProperty(accountRootPropName + \".wizard\",\n                    wizard.getClass().getName().replace('.', '_'));\n\n                savedAccount = true;\n            }\n        }\n\n        if (!savedAccount)\n        {\n            String accNodeName =\n                \"acc\" + Long.toString(System.currentTimeMillis());\n\n            String accountPackage =\n                \"net.java.sip.communicator.impl.gui.accounts.\" + accNodeName;\n\n            configService.setProperty(accountPackage, protocolProvider\n                .getAccountID().getAccountUniqueID());\n\n            configService.setProperty(accountPackage + \".wizard\", wizard);\n        }\n    }","id":37776,"modified_method":"/**\n     * Saves the (protocol provider, wizard) pair in through the\n     * <tt>ConfigurationService<\/tt>.\n     *\n     * @param protocolProvider the protocol provider to save\n     * @param wizard the wizard to save\n     */\n    public void saveAccountWizard(ProtocolProviderService protocolProvider,\n        AccountRegistrationWizard wizard)\n    {\n        String prefix = \"net.java.sip.communicator.impl.gui.accounts\";\n\n        List<String> accounts =\n            configService.getPropertyNamesByPrefix(prefix, true);\n\n        boolean savedAccount = false;\n\n        for (String accountRootPropName : accounts)\n        {\n            String accountUID = configService.getString(accountRootPropName);\n\n            if (accountUID.equals(\n                    protocolProvider.getAccountID().getAccountUniqueID()))\n            {\n                configService.setProperty(accountRootPropName + \".wizard\",\n                    wizard.getClass().getName().replace('.', '_'));\n\n                savedAccount = true;\n            }\n        }\n\n        if (!savedAccount)\n        {\n            String accountPackage\n                = prefix + \".acc\" + Long.toString(System.currentTimeMillis());\n\n            configService.setProperty(accountPackage, protocolProvider\n                .getAccountID().getAccountUniqueID());\n\n            configService.setProperty(accountPackage + \".wizard\", wizard);\n        }\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"public AccountRegWizardContainerImpl(MainFrame mainFrame)\n    {\n        super(mainFrame);\n\n        this.setTitle(GuiActivator.getResources()\n            .getI18NString(\"service.gui.ACCOUNT_REGISTRATION_WIZARD\"));\n\n        this.summaryPage = new AccountRegSummaryPage(this);\n\n        this.registerWizardPage(summaryPage.getIdentifier(), summaryPage);\n\n        ServiceReference[] accountWizardRefs = null;\n        try\n        {\n            accountWizardRefs = GuiActivator.bundleContext\n                .getServiceReferences(\n                    AccountRegistrationWizard.class.getName(),\n                    null);\n        }\n        catch (InvalidSyntaxException ex)\n        {\n            // this shouldn't happen since we're providing no parameter string\n            // but let's log just in case.\n            logger.error(\n                \"Error while retrieving service refs\", ex);\n            return;\n        }\n\n        // in case we found any, add them in this container.\n        if (accountWizardRefs != null)\n        {\n            logger.debug(\"Found \"\n                         + accountWizardRefs.length\n                         + \" already installed providers.\");\n            for (int i = 0; i < accountWizardRefs.length; i++)\n            {\n                ServiceReference serRef = accountWizardRefs[i];\n\n                String protocolName = (String) serRef\n                    .getProperty(ProtocolProviderFactory.PROTOCOL);\n\n                AccountRegistrationWizard wizard\n                    = (AccountRegistrationWizard) GuiActivator.bundleContext\n                        .getService(serRef);\n\n                this.addAccountRegistrationWizard(protocolName, wizard);\n            }\n        }\n\n        GuiActivator.bundleContext.addServiceListener(this);\n    }","id":37777,"modified_method":"public AccountRegWizardContainerImpl(MainFrame mainFrame)\n    {\n        super(mainFrame);\n\n        this.setTitle(GuiActivator.getResources()\n            .getI18NString(\"service.gui.ACCOUNT_REGISTRATION_WIZARD\"));\n\n        this.summaryPage = new AccountRegSummaryPage(this);\n\n        this.registerWizardPage(summaryPage.getIdentifier(), summaryPage);\n\n        ServiceReference[] accountWizardRefs = null;\n        try\n        {\n            accountWizardRefs = GuiActivator.bundleContext\n                .getServiceReferences(\n                    AccountRegistrationWizard.class.getName(),\n                    null);\n        }\n        catch (InvalidSyntaxException ex)\n        {\n            // this shouldn't happen since we're providing no parameter string\n            // but let's log just in case.\n            logger.error(\n                \"Error while retrieving service refs\", ex);\n            return;\n        }\n\n        // in case we found any, add them in this container.\n        if (accountWizardRefs != null)\n        {\n            logger.debug(\"Found \"\n                         + accountWizardRefs.length\n                         + \" already installed providers.\");\n            for (ServiceReference serRef : accountWizardRefs)\n            {\n                String protocolName = (String)\n                    serRef.getProperty(ProtocolProviderFactory.PROTOCOL);\n                AccountRegistrationWizard wizard = (AccountRegistrationWizard)\n                    GuiActivator.bundleContext.getService(serRef);\n\n                this.addAccountRegistrationWizard(protocolName, wizard);\n            }\n        }\n\n        GuiActivator.bundleContext.addServiceListener(this);\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Handles registration of a new account wizard.\n     */\n    public void serviceChanged(ServiceEvent event)\n    {\n        if(!GuiActivator.isStarted)\n            return;\n\n        ServiceReference serRef = event.getServiceReference();\n\n        String protocolName\n            = (String) serRef.getProperty(ProtocolProviderFactory.PROTOCOL);\n\n        Object sService = GuiActivator.bundleContext.getService(\n            event.getServiceReference());\n\n        // we don't care if the source service is not a plugin component\n        if (! (sService instanceof AccountRegistrationWizard))\n        {\n            return;\n        }\n\n        AccountRegistrationWizard wizard\n            = (AccountRegistrationWizard) sService;\n\n        switch (event.getType()) {\n        case ServiceEvent.REGISTERED:\n            logger\n                .info(\"Handling registration of a new Account Wizard.\");\n\n            this.addAccountRegistrationWizard(protocolName, wizard);\n            break;\n        case ServiceEvent.UNREGISTERING:\n            this.removeAccountRegistrationWizard(protocolName, wizard);\n            break;\n        }\n    }","id":37778,"modified_method":"/**\n     * Handles registration of a new account wizard.\n     */\n    public void serviceChanged(ServiceEvent event)\n    {\n        if(!GuiActivator.isStarted)\n            return;\n\n        ServiceReference serRef = event.getServiceReference();\n        Object sService = GuiActivator.bundleContext.getService(serRef);\n\n        // we don't care if the source service is not a plugin component\n        if (! (sService instanceof AccountRegistrationWizard))\n            return;\n\n        String protocolName\n            = (String) serRef.getProperty(ProtocolProviderFactory.PROTOCOL);\n        AccountRegistrationWizard wizard\n            = (AccountRegistrationWizard) sService;\n\n        switch (event.getType()) {\n        case ServiceEvent.REGISTERED:\n            logger\n                .info(\"Handling registration of a new Account Wizard.\");\n\n            this.addAccountRegistrationWizard(protocolName, wizard);\n            break;\n        case ServiceEvent.UNREGISTERING:\n            this.removeAccountRegistrationWizard(protocolName, wizard);\n            break;\n        }\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Method used to listen for property change events from the model and\n     * update the dialog's graphical components as necessary.\n     * \n     * @param evt PropertyChangeEvent passed from the model to signal that one\n     *            of its properties has changed value.\n     */\n    public void propertyChange(PropertyChangeEvent evt)\n    {\n\n        if (evt.getPropertyName().equals(WizardModel.CURRENT_PAGE_PROPERTY))\n        {\n            wizardController.resetButtonsToPanelRules();\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.NEXT_FINISH_BUTTON_TEXT_PROPERTY))\n        {\n            nextButton.setText(evt.getNewValue().toString());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.BACK_BUTTON_TEXT_PROPERTY))\n        {\n            backButton.setText(evt.getNewValue().toString());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.CANCEL_BUTTON_TEXT_PROPERTY))\n        {\n            cancelButton.setText(evt.getNewValue().toString());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.NEXT_FINISH_BUTTON_ENABLED_PROPERTY))\n        {\n            nextButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.BACK_BUTTON_ENABLED_PROPERTY))\n        {\n            backButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.CANCEL_BUTTON_ENABLED_PROPERTY))\n        {\n            cancelButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.NEXT_FINISH_BUTTON_ICON_PROPERTY))\n        {\n            nextButton.setIcon((Icon) evt.getNewValue());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.BACK_BUTTON_ICON_PROPERTY))\n        {\n            backButton.setIcon((Icon) evt.getNewValue());\n        }\n        else if (evt.getPropertyName().equals(\n            WizardModel.CANCEL_BUTTON_ICON_PROPERTY))\n        {\n            cancelButton.setIcon((Icon) evt.getNewValue());\n        }\n\n    }","id":37779,"modified_method":"/**\n     * Method used to listen for property change events from the model and\n     * update the dialog's graphical components as necessary.\n     * \n     * @param evt PropertyChangeEvent passed from the model to signal that one\n     *            of its properties has changed value.\n     */\n    public void propertyChange(PropertyChangeEvent evt)\n    {\n        String name = evt.getPropertyName();\n\n        if (WizardModel.CURRENT_PAGE_PROPERTY.equals(name))\n        {\n            wizardController.resetButtonsToPanelRules();\n        }\n        else if (WizardModel.NEXT_FINISH_BUTTON_TEXT_PROPERTY.equals(name))\n        {\n            nextButton.setText(evt.getNewValue().toString());\n        }\n        else if (WizardModel.BACK_BUTTON_TEXT_PROPERTY.equals(name))\n        {\n            backButton.setText(evt.getNewValue().toString());\n        }\n        else if (WizardModel.CANCEL_BUTTON_TEXT_PROPERTY.equals(name))\n        {\n            cancelButton.setText(evt.getNewValue().toString());\n        }\n        else if (WizardModel.NEXT_FINISH_BUTTON_ENABLED_PROPERTY.equals(name))\n        {\n            nextButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (WizardModel.BACK_BUTTON_ENABLED_PROPERTY.equals(name))\n        {\n            backButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (WizardModel.CANCEL_BUTTON_ENABLED_PROPERTY.equals(name))\n        {\n            cancelButton.setEnabled((Boolean) evt.getNewValue());\n        }\n        else if (WizardModel.NEXT_FINISH_BUTTON_ICON_PROPERTY.equals(name))\n        {\n            nextButton.setIcon((Icon) evt.getNewValue());\n        }\n        else if (WizardModel.BACK_BUTTON_ICON_PROPERTY.equals(name))\n        {\n            backButton.setIcon((Icon) evt.getNewValue());\n        }\n        else if (WizardModel.CANCEL_BUTTON_ICON_PROPERTY.equals(name))\n        {\n            cancelButton.setIcon((Icon) evt.getNewValue());\n        }\n\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * This method accepts a java.awt.Frame object as the javax.swing.JDialog's\n     * parent.\n     * \n     * @param owner The java.awt.Frame object that is the owner of the\n     *            javax.swing.JDialog.\n     */\n    public Wizard(Frame owner)\n    {\n        super(owner, false);\n\n        wizardModel = new WizardModel();\n\n        initComponents();\n    }","id":37780,"modified_method":"/**\n     * This method accepts a java.awt.Frame object as the javax.swing.JDialog's\n     * parent.\n     * \n     * @param owner The java.awt.Frame object that is the owner of the\n     *            javax.swing.JDialog.\n     */\n    public Wizard(Frame owner)\n    {\n        super(owner, false);\n\n        initComponents();\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * This method accepts a java.awt.Dialog object as the javax.swing.JDialog's\n     * parent.\n     * \n     * @param owner The java.awt.Dialog object that is the owner of this dialog.\n     */\n    public Wizard(Dialog owner)\n    {\n        super(owner, false);\n\n        wizardModel = new WizardModel();\n\n        initComponents();\n    }","id":37781,"modified_method":"/**\n     * This method accepts a java.awt.Dialog object as the javax.swing.JDialog's\n     * parent.\n     * \n     * @param owner The java.awt.Dialog object that is the owner of this dialog.\n     */\n    public Wizard(Dialog owner)\n    {\n        super(owner, false);\n\n        initComponents();\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     *  Resets the buttons to support the original panel rules, including\n     *  whether the next or back buttons are enabled or disabled, or if\n     *  the panel is finishable. If the panel in question has another panel\n     *  behind it, enables the back button. Otherwise, disables it. If the\n     *  panel in question has one or more panels in front of it, enables the\n     *  next button. Otherwise, disables it.\n     */\n    void resetButtonsToPanelRules() {\n\n        WizardModel model = wizard.getModel();\n        WizardPage page = model.getCurrentWizardPage();\n\n        model.setCancelButtonText(Wizard.CANCEL_TEXT);\n\n        model.setBackButtonText(Wizard.BACK_TEXT);\n\n        if (page.getBackPageIdentifier() != null) {\n            model.setBackButtonEnabled(Boolean.TRUE);\n        }\n        else {\n            model.setBackButtonEnabled(Boolean.FALSE);\n        }\n\n        if (page.getNextPageIdentifier() != null) {\n            model.setNextFinishButtonEnabled(Boolean.TRUE);\n\n        }\n        else {\n            model.setNextFinishButtonEnabled(Boolean.FALSE);\n        }\n\n        if (page.getNextPageIdentifier()\n                .equals(WizardPage.FINISH_PAGE_IDENTIFIER)) {\n\n            model.setNextFinishButtonText(Wizard.FINISH_TEXT);\n        } else {\n            model.setNextFinishButtonText(Wizard.NEXT_TEXT);\n        }\n\n    }","id":37782,"modified_method":"/**\n     *  Resets the buttons to support the original panel rules, including\n     *  whether the next or back buttons are enabled or disabled, or if\n     *  the panel is finishable. If the panel in question has another panel\n     *  behind it, enables the back button. Otherwise, disables it. If the\n     *  panel in question has one or more panels in front of it, enables the\n     *  next button. Otherwise, disables it.\n     */\n    void resetButtonsToPanelRules()\n    {\n        WizardModel model = wizard.getModel();\n        WizardPage page = model.getCurrentWizardPage();\n\n        model.setCancelButtonText(Wizard.CANCEL_TEXT);\n\n        Object backPageIdentifier = page.getBackPageIdentifier();\n        model.setBackButtonEnabled(\n            (backPageIdentifier != null)\n                && !WizardPage.DEFAULT_PAGE_IDENTIFIER.equals(backPageIdentifier));\n\n        model.setBackButtonText(Wizard.BACK_TEXT);\n\n        model.setNextFinishButtonEnabled(page.getNextPageIdentifier() != null);\n\n        if (page.getNextPageIdentifier().equals(\n                WizardPage.FINISH_PAGE_IDENTIFIER)) {\n            model.setNextFinishButtonText(Wizard.FINISH_TEXT);\n        } else {\n            model.setNextFinishButtonText(Wizard.NEXT_TEXT);\n        }\n    }","commit_id":"74e985d894848de833fd4ac7d030e73acd63ee59","url":"https://github.com/jitsi/jitsi"},{"original_method":"public PsiMember fromString(final String s, final ConvertContext context) {\n    if (s == null) return null;\n    final PsiClass psiClass = getTargetClass(context);\n    if (psiClass == null) return null;\n    final String propertyName = isPropertyNameUsed() ? s : PropertyUtil.getPropertyName(s);\n    for (PropertyMemberType type : getMemberTypes(context)) {\n      switch (type) {\n        case FIELD:\n          final PsiField field = psiClass.findFieldByName(s, isLookDeep());\n          if (field != null) return field;\n          break;\n        case GETTER:\n          final PsiMethod getter = PropertyUtil.findPropertyGetter(psiClass, propertyName, false, isLookDeep());\n          if (getter != null) return getter;\n          break;\n        case SETTER:\n          final PsiMethod setter = PropertyUtil.findPropertySetter(psiClass, propertyName, false, isLookDeep());\n          if (setter != null) return setter;\n          break;\n      }\n    }\n    return null;\n  }","id":37783,"modified_method":"public PsiMember fromString(final String s, final ConvertContext context) {\n    if (s == null) return null;\n    final PsiClass psiClass = getTargetClass(context);\n    if (psiClass == null) return null;\n    for (PropertyMemberType type : getMemberTypes(context)) {\n      switch (type) {\n        case FIELD:\n          final PsiField field = psiClass.findFieldByName(s, isLookDeep());\n          if (field != null) return field;\n          break;\n        case GETTER:\n          final PsiMethod getter = PropertyUtil.findPropertyGetter(psiClass, getPropertyName(s, context), false, isLookDeep());\n          if (getter != null) return getter;\n          break;\n        case SETTER:\n          final PsiMethod setter = PropertyUtil.findPropertySetter(psiClass, getPropertyName(s, context), false, isLookDeep());\n          if (setter != null) return setter;\n          break;\n      }\n    }\n    return null;\n  }","commit_id":"728ae46a2716bcf4a5002e4fea7ff1a688ce05de","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void bindReference(final GenericDomValue<PsiMember> genericValue, final ConvertContext context, final PsiElement newTarget) {\n    if (newTarget instanceof PsiMember) {\n      final String elementName = ((PsiMember)newTarget).getName();\n      genericValue.setStringValue(isPropertyNameUsed() ? PropertyUtil.getPropertyName(elementName) : elementName);\n    }\n  }","id":37784,"modified_method":"public void bindReference(final GenericDomValue<PsiMember> genericValue, final ConvertContext context, final PsiElement newTarget) {\n    if (newTarget instanceof PsiMember) {\n      final String elementName = ((PsiMember)newTarget).getName();\n      genericValue.setStringValue(getPropertyName(elementName, context));\n    }\n  }","commit_id":"728ae46a2716bcf4a5002e4fea7ff1a688ce05de","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public String toString(final PsiMember t, final ConvertContext context) {\n    return t == null? null : isPropertyNameUsed()? PropertyUtil.getPropertyName(t) : t.getName();\n  }","id":37785,"modified_method":"public String toString(final PsiMember t, final ConvertContext context) {\n    return t == null? null : getPropertyName(t.getName(), context);\n  }","commit_id":"728ae46a2716bcf4a5002e4fea7ff1a688ce05de","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public void handleElementRename(final GenericDomValue<PsiMember> genericValue, final ConvertContext context, final String newElementName) {\n    super.handleElementRename(genericValue, context, isPropertyNameUsed()? PropertyUtil.getPropertyName(newElementName) : newElementName);\n  }","id":37786,"modified_method":"public void handleElementRename(final GenericDomValue<PsiMember> genericValue, final ConvertContext context, final String newElementName) {\n    super.handleElementRename(genericValue, context, getPropertyName(newElementName, context));\n  }","commit_id":"728ae46a2716bcf4a5002e4fea7ff1a688ce05de","url":"https://github.com/JetBrains/intellij-community"},{"original_method":"public static byte[] loadIcon(String imagePath, Class clazz)\n    {\n        InputStream is = getResourceAsStream(imagePath, clazz);\n\n        byte[] icon = null;\n        try\n        {\n            icon = new byte[is.available()];\n            is.read(icon);\n        }\n        catch (IOException exc)\n        {\n            logger.error(\"Failed to load icon: \" + imagePath, exc);\n        }\n        finally {\n            try\n            {\n                is.close();\n            }\n            catch (IOException ex)\n            {\n                /*\n                 * We're closing an InputStream so there shouldn't be data loss\n                 * because of it (in contrast to an OutputStream) and a warning\n                 * in the log should be enough.\n                 */\n                logger.warn(\"Failed to close the InputStream of icon: \"\n                    + imagePath, ex);\n            }\n        }\n        return icon;\n    }","id":37787,"modified_method":"public static byte[] loadIcon(String imagePath, Class<?> clazz)\n    {\n        InputStream is = getResourceAsStream(imagePath, clazz);\n\n        byte[] icon = null;\n        try\n        {\n            icon = new byte[is.available()];\n            is.read(icon);\n        }\n        catch (IOException exc)\n        {\n            logger.error(\"Failed to load icon: \" + imagePath, exc);\n        }\n        finally {\n            try\n            {\n                is.close();\n            }\n            catch (IOException ex)\n            {\n                /*\n                 * We're closing an InputStream so there shouldn't be data loss\n                 * because of it (in contrast to an OutputStream) and a warning\n                 * in the log should be enough.\n                 */\n                logger.warn(\"Failed to close the InputStream of icon: \"\n                    + imagePath, ex);\n            }\n        }\n        return icon;\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"private static InputStream getResourceAsStream(String name, Class clazz)\n    {\n        if (name.indexOf(\"://\") != -1)\n        {\n            try\n            {\n                return new URL(name).openStream();\n            }\n            catch (IOException ex)\n            {\n                /*\n                 * Well, we didn't really know whether the specified name\n                 * represented an URL so we just tried. We'll resort to\n                 * Class#getResourceAsStream then.\n                 */\n            }\n        }\n        return clazz.getClassLoader().getResourceAsStream(name);\n    }","id":37788,"modified_method":"private static InputStream getResourceAsStream(String name, Class<?> clazz)\n    {\n        if (name.indexOf(\"://\") != -1)\n        {\n            try\n            {\n                return new URL(name).openStream();\n            }\n            catch (IOException ex)\n            {\n                /*\n                 * Well, we didn't really know whether the specified name\n                 * represented an URL so we just tried. We'll resort to\n                 * Class#getResourceAsStream then.\n                 */\n            }\n        }\n        return clazz.getClassLoader().getResourceAsStream(name);\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Indicates whether some other object is \"equal to\" this one. To\n     * PresenceStatus instances are considered equal if and only if both their\n     * connecfitivity coefficient and their name are equal.\n     * <p>\n     * @param   obj   the reference object with which to compare.\n     * @return  <tt>true<\/tt> if this presence status instance is equal to\n     *          the obj argument; <tt>false<\/tt> otherwise.\n     */\n    public boolean equals(Object obj)\n    {\n        if (obj == null\n            || !(obj instanceof PresenceStatus) )\n        return false;\n\n        PresenceStatus status = (PresenceStatus)obj;\n\n        if (status.getStatus() != getStatus()\n            || !status.getStatusName().equals(statusName))\n            return false;\n\n        return true;\n    }","id":37789,"modified_method":"/**\n     * Indicates whether some other object is \"equal to\" this one. To\n     * PresenceStatus instances are considered equal if and only if both their\n     * connectivity coefficient and their name are equal.\n     * <p>\n     * \n     * @param obj the reference object with which to compare.\n     * @return <tt>true<\/tt> if this presence status instance is equal to the\n     *         <code>obj<\/code> argument; <tt>false<\/tt> otherwise.\n     */\n    public boolean equals(Object obj)\n    {\n        if (obj == null || !(obj instanceof PresenceStatus))\n            return false;\n\n        PresenceStatus status = (PresenceStatus) obj;\n\n        return status.getStatus() == getStatus()\n            && status.getStatusName().equals(getStatusName());\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"public void paintComponent(Graphics g)\n        {\n            super.paintComponent(g);\n\n            // If the custom color window background is not enabled we have\n            // nothing to do here.\n            if (!isColorBgEnabled)\n                return;\n\n            g = g.create();\n            try\n            {\n                internalPaintComponent(g);\n            }\n            finally\n            {\n                g.dispose();\n            }\n        }","id":37790,"modified_method":"public void paintComponent(Graphics g)\n        {\n            super.paintComponent(g);\n\n            // If the custom color window background is not enabled we have\n            // nothing to do here.\n            if (isColorBgEnabled)\n            {\n                g = g.create();\n                try\n                {\n                    internalPaintComponent(g);\n                }\n                finally\n                {\n                    g.dispose();\n                }\n            }\n        }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"public SipStatusEnum(String iconPath)\n    {\n        this.iconPath = iconPath;\n\n        this.offlineStatus = new SipPresenceStatus(\n            0,\n            OFFLINE, \n            loadIcon(iconPath + \"/sip16x16-offline.png\"));\n\n        this.busyStatus = new SipPresenceStatus(\n            30,\n            BUSY,\n            loadIcon(iconPath + \"/sip16x16-busy.png\"));\n\n        this.onThePhoneStatus = new SipPresenceStatus(\n            37,\n            ON_THE_PHONE,\n            loadIcon(iconPath + \"/sip16x16-phone.png\"));\n\n        this.awayStatus = new SipPresenceStatus(\n            40,\n            AWAY,\n            loadIcon(iconPath + \"/sip16x16-away.png\"));\n\n        this.onlineStatus = new SipPresenceStatus(\n            65,\n            ONLINE,\n            loadIcon(iconPath + \"/sip16x16-online.png\"));\n\n        this.unknownStatus = new SipPresenceStatus(\n            1,\n            UNKNOWN,\n            loadIcon(iconPath + \"/sip16x16-offline.png\"));\n\n        // Initialize the list of supported status states.\n        supportedStatusSet.add(onlineStatus);\n        supportedStatusSet.add(awayStatus);\n        supportedStatusSet.add(onThePhoneStatus);\n        supportedStatusSet.add(busyStatus);\n        supportedStatusSet.add(offlineStatus);\n    }","id":37791,"modified_method":"public SipStatusEnum(String iconPath)\n    {\n        this.offlineStatus = new SipPresenceStatus(\n            0,\n            OFFLINE, \n            loadIcon(iconPath + \"/sip16x16-offline.png\"));\n\n        this.busyStatus = new SipPresenceStatus(\n            30,\n            BUSY,\n            loadIcon(iconPath + \"/sip16x16-busy.png\"));\n\n        this.onThePhoneStatus = new SipPresenceStatus(\n            37,\n            ON_THE_PHONE,\n            loadIcon(iconPath + \"/sip16x16-phone.png\"));\n\n        this.awayStatus = new SipPresenceStatus(\n            40,\n            AWAY,\n            loadIcon(iconPath + \"/sip16x16-away.png\"));\n\n        this.onlineStatus = new SipPresenceStatus(\n            65,\n            ONLINE,\n            loadIcon(iconPath + \"/sip16x16-online.png\"));\n\n        this.unknownStatus = new SipPresenceStatus(\n            1,\n            UNKNOWN,\n            loadIcon(iconPath + \"/sip16x16-offline.png\"));\n\n        // Initialize the list of supported status states.\n        supportedStatusSet.add(onlineStatus);\n        supportedStatusSet.add(awayStatus);\n        supportedStatusSet.add(onThePhoneStatus);\n        supportedStatusSet.add(busyStatus);\n        supportedStatusSet.add(offlineStatus);\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Notifies all plugin containers of a <tt>PluginComponent<\/tt>\n     * registration.\n     */\n    public void serviceChanged(ServiceEvent event)\n    {\n        Object sService = GuiActivator.bundleContext.getService(\n            event.getServiceReference());\n\n        // we don't care if the source service is not a plugin component\n        if (! (sService instanceof PluginComponent))\n        {\n            return;\n        }\n\n        PluginComponent pluginComponent = (PluginComponent) sService;\n\n        if (event.getType() == ServiceEvent.REGISTERED)\n        {\n            logger\n                .info(\"Handling registration of a new Plugin Component.\");\n\n            if(pluginComponent.getComponent() == null\n                || !(pluginComponent.getComponent() instanceof Component))\n            {\n                logger.error(\"Plugin Component type is not supported.\" +\n                            \"Should provide a plugin in AWT, SWT or Swing.\");\n                logger.debug(\"Logging exception to show the calling plugin\",\n                            new Exception(\"\"));\n                return;\n            }\n\n            this.firePluginEvent(   pluginComponent,\n                                    PluginComponentEvent.PLUGIN_COMPONENT_ADDED);\n        }\n        else if (event.getType() == ServiceEvent.UNREGISTERING)\n        {\n            this.firePluginEvent(   pluginComponent,\n                                    PluginComponentEvent\n                                        .PLUGIN_COMPONENT_REMOVED);\n        }\n    }","id":37792,"modified_method":"/**\n     * Notifies all plugin containers of a <tt>PluginComponent<\/tt>\n     * registration.\n     */\n    public void serviceChanged(ServiceEvent event)\n    {\n        Object sService = GuiActivator.bundleContext.getService(\n            event.getServiceReference());\n\n        // we don't care if the source service is not a plugin component\n        if (! (sService instanceof PluginComponent))\n        {\n            return;\n        }\n\n        PluginComponent pluginComponent = (PluginComponent) sService;\n\n        switch (event.getType())\n        {\n        case ServiceEvent.REGISTERED:\n            logger.info(\"Handling registration of a new Plugin Component.\");\n\n            Object component = pluginComponent.getComponent();\n            if (component == null || !(component instanceof Component))\n            {\n                logger.error(\"Plugin Component type is not supported.\"\n                    + \"Should provide a plugin in AWT, SWT or Swing.\");\n                logger.debug(\"Logging exception to show the calling plugin\",\n                    new Exception(\"\"));\n                return;\n            }\n\n            this.firePluginEvent(pluginComponent,\n                PluginComponentEvent.PLUGIN_COMPONENT_ADDED);\n            break;\n\n        case ServiceEvent.UNREGISTERING:\n            this.firePluginEvent(pluginComponent,\n                PluginComponentEvent.PLUGIN_COMPONENT_REMOVED);\n            break;\n        }\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Implements the <code>getExportedWindow<\/code> in the UIService\n     * interface. Returns the window corresponding to the given\n     * <tt>WindowID<\/tt>.\n     *\n     * @param windowID the id of the window we'd like to retrieve.\n     * @param params the params to be passed to the returned window.\n     * @return a reference to the <tt>ExportedWindow<\/tt> instance corresponding\n     * to <tt>windowID<\/tt>.\n     * @see UIService#getExportedWindow(WindowID)\n     */\n    public ExportedWindow getExportedWindow(WindowID windowID, Object[] params)\n    {\n        if (exportedWindows.containsKey(windowID))\n        {\n            ExportedWindow win = (ExportedWindow) exportedWindows.get(windowID);\n            win.setParams(params);\n\n            return win;\n        }\n        return null;\n    }","id":37793,"modified_method":"/**\n     * Implements the <code>getExportedWindow<\/code> in the UIService interface.\n     * Returns the window corresponding to the given <tt>WindowID<\/tt>.\n     * \n     * @param windowID the id of the window we'd like to retrieve.\n     * @param params the params to be passed to the returned window.\n     * @return a reference to the <tt>ExportedWindow<\/tt> instance corresponding\n     *         to <tt>windowID<\/tt>.\n     * @see UIService#getExportedWindow(WindowID)\n     */\n    public ExportedWindow getExportedWindow(WindowID windowID, Object[] params)\n    {\n        ExportedWindow win = exportedWindows.get(windowID);\n\n        if (win != null)\n            win.setParams(params);\n\n        return win;\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Implements the <code>UIService.setExitOnMainWindowClose<\/code>. Sets a\n     * boolean property, which indicates whether the application should be\n     * exited when the main application window is closed.\n     *\n     * @param exitOnClose specifies if closing the main application window\n     * should also be exiting the application.\n     */\n    public void setExitOnMainWindowClose(boolean exitOnClose)\n    {\n        this.exitOnClose = exitOnClose;\n\n        if (mainFrame == null)\n            return;\n\n        if (exitOnClose)\n            mainFrame.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE);\n        else\n            mainFrame.setDefaultCloseOperation(JFrame.HIDE_ON_CLOSE);\n    }","id":37794,"modified_method":"/**\n     * Implements the <code>UIService.setExitOnMainWindowClose<\/code>. Sets a\n     * boolean property, which indicates whether the application should be\n     * exited when the main application window is closed.\n     *\n     * @param exitOnClose specifies if closing the main application window\n     * should also be exiting the application.\n     */\n    public void setExitOnMainWindowClose(boolean exitOnClose)\n    {\n        this.exitOnClose = exitOnClose;\n\n        if (mainFrame != null)\n            mainFrame\n                .setDefaultCloseOperation(exitOnClose ? JFrame.DISPOSE_ON_CLOSE\n                    : JFrame.HIDE_ON_CLOSE);\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Creates the corresponding PluginComponentEvent and notifies all\n     * <tt>ContainerPluginListener<\/tt>s that a plugin component is added or\n     * removed from the container.\n     * \n     * @param pluginComponent the plugin component that is added to the\n     *            container.\n     * @param containerID the containerID that corresponds to the container\n     *            where the component is added.\n     * @param eventID one of the PLUGIN_COMPONENT_XXX static fields indicating\n     *            the nature of the event.\n     */\n    private void firePluginEvent(PluginComponent pluginComponent, int eventID)\n    {\n        PluginComponentEvent evt =\n            new PluginComponentEvent(pluginComponent, eventID);\n\n        logger.debug(\"Will dispatch the following plugin component event: \"\n            + evt);\n\n        synchronized (pluginComponentListeners)\n        {\n            Iterator<PluginComponentListener> listeners =\n                this.pluginComponentListeners.iterator();\n\n            while (listeners.hasNext())\n            {\n                PluginComponentListener l = listeners.next();\n\n                switch (evt.getEventID())\n                {\n                case PluginComponentEvent.PLUGIN_COMPONENT_ADDED:\n                    l.pluginComponentAdded(evt);\n                    break;\n                case PluginComponentEvent.PLUGIN_COMPONENT_REMOVED:\n                    l.pluginComponentRemoved(evt);\n                    break;\n                default:\n                    logger.error(\"Unknown event type \" + evt.getEventID());\n                }\n            }\n        }\n    }","id":37795,"modified_method":"/**\n     * Creates the corresponding PluginComponentEvent and notifies all\n     * <tt>ContainerPluginListener<\/tt>s that a plugin component is added or\n     * removed from the container.\n     * \n     * @param pluginComponent the plugin component that is added to the\n     *            container.\n     * @param containerID the containerID that corresponds to the container\n     *            where the component is added.\n     * @param eventID one of the PLUGIN_COMPONENT_XXX static fields indicating\n     *            the nature of the event.\n     */\n    private void firePluginEvent(PluginComponent pluginComponent, int eventID)\n    {\n        PluginComponentEvent evt =\n            new PluginComponentEvent(pluginComponent, eventID);\n\n        logger.debug(\"Will dispatch the following plugin component event: \"\n            + evt);\n\n        synchronized (pluginComponentListeners)\n        {\n            for (PluginComponentListener l : pluginComponentListeners)\n            {\n                switch (evt.getEventID())\n                {\n                case PluginComponentEvent.PLUGIN_COMPONENT_ADDED:\n                    l.pluginComponentAdded(evt);\n                    break;\n                case PluginComponentEvent.PLUGIN_COMPONENT_REMOVED:\n                    l.pluginComponentRemoved(evt);\n                    break;\n                default:\n                    logger.error(\"Unknown event type \" + evt.getEventID());\n                    break;\n                }\n            }\n        }\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"/**\n     * Initialize main window font.\n     */\n    private void initCustomFonts()\n    {\n        JComponent layeredPane = mainFrame.getLayeredPane();\n\n        String fontName\n            = GuiActivator.getResources().getSettingsString(\n                \"service.gui.FONT_NAME\");\n\n        String titleFontSize\n            = GuiActivator.getResources().getSettingsString(\n                \"service.gui.FONT_SIZE\");\n\n        Font font = new Font(   fontName,\n                                Font.BOLD,\n                                new Integer(titleFontSize).intValue());\n\n        for (int i = 0; i < layeredPane.getComponentCount(); i++)\n        {\n            layeredPane.getComponent(i).setFont(font);\n        }\n    }","id":37796,"modified_method":"/**\n     * Initialize main window font.\n     */\n    private void initCustomFonts()\n    {\n        JComponent layeredPane = mainFrame.getLayeredPane();\n\n        ResourceManagementService resources = GuiActivator.getResources();\n        String fontName = resources.getSettingsString(\"service.gui.FONT_NAME\");\n        String titleFontSize =\n            resources.getSettingsString(\"service.gui.FONT_SIZE\");\n\n        Font font = new Font(   fontName,\n                                Font.BOLD,\n                                new Integer(titleFontSize).intValue());\n\n        for (int i = 0; i < layeredPane.getComponentCount(); i++)\n        {\n            layeredPane.getComponent(i).setFont(font);\n        }\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"public void propertyChange(PropertyChangeEvent evt)\n    {\n        if (evt.getPropertyName().equals(\n            \"impl.gui.IS_TRANSPARENT_WINDOW_ENABLED\"))\n        {\n            String isTransparentString = (String) evt.getNewValue();\n\n            boolean isTransparentWindowEnabled\n                = new Boolean(isTransparentString).booleanValue();\n\n            try\n            {\n                WindowUtils.setWindowTransparent(   mainFrame,\n                    isTransparentWindowEnabled);\n            }\n            catch (UnsupportedOperationException ex)\n            {\n                logger.error(ex.getMessage(), ex);\n\n                if (isTransparentWindowEnabled)\n                {\n                    new ErrorDialog(mainFrame,\n                        GuiActivator.getResources()\n                            .getI18NString(\"service.gui.ERROR\"),\n                        GuiActivator.getResources()\n                        .getI18NString(\"service.gui.TRANSPARENCY_NOT_ENABLED\"))\n                    .showDialog();\n                }\n\n                ConfigurationManager.setTransparentWindowEnabled(false);\n            }\n        }\n        else if (evt.getPropertyName().equals(\n            \"impl.gui.WINDOW_TRANSPARENCY\"))\n        {\n            mainFrame.repaint();\n        }\n    }","id":37797,"modified_method":"public void propertyChange(PropertyChangeEvent evt)\n    {\n        String propertyName = evt.getPropertyName();\n\n        if (propertyName.equals(\n            \"impl.gui.IS_TRANSPARENT_WINDOW_ENABLED\"))\n        {\n            String isTransparentString = (String) evt.getNewValue();\n\n            boolean isTransparentWindowEnabled\n                = new Boolean(isTransparentString).booleanValue();\n\n            try\n            {\n                WindowUtils.setWindowTransparent(   mainFrame,\n                    isTransparentWindowEnabled);\n            }\n            catch (UnsupportedOperationException ex)\n            {\n                logger.error(ex.getMessage(), ex);\n\n                if (isTransparentWindowEnabled)\n                {\n                    ResourceManagementService resources =\n                        GuiActivator.getResources();\n\n                    new ErrorDialog(mainFrame, resources\n                        .getI18NString(\"service.gui.ERROR\"), resources\n                        .getI18NString(\"service.gui.TRANSPARENCY_NOT_ENABLED\"))\n                        .showDialog();\n                }\n\n                ConfigurationManager.setTransparentWindowEnabled(false);\n            }\n        }\n        else if (propertyName.equals(\n            \"impl.gui.WINDOW_TRANSPARENCY\"))\n        {\n            mainFrame.repaint();\n        }\n    }","commit_id":"7711b71c9b087ec6a8677357644e6a7ad2afd07c","url":"https://github.com/jitsi/jitsi"},{"original_method":"public Folder updateFolder(\n\t\t\tlong folderId, String title, String description,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId objectId = toFolderId(session, folderId);\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder cmisFolder =\n\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\tsession.getObject(objectId);\n\n\t\t\tString oldTitle = cmisFolder.getName();\n\n\t\t\tMap<String, Object> properties = new HashMap<String, Object>();\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tObjectId newObjectId = cmisFolder.updateProperties(\n\t\t\t\tproperties, true);\n\n\t\t\tif (!objectId.toString().equals(newObjectId.toString())) {\n\t\t\t\tcmisFolder =\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tsession.getObject(newObjectId);\n\n\t\t\t\tupdateMappedId(folderId, newObjectId.toString());\n\t\t\t}\n\n\t\t\treturn toFolder(cmisFolder);\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37798,"modified_method":"public Folder updateFolder(\n\t\t\tlong folderId, String title, String description,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = toFolderId(session, folderId);\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder cmisFolder =\n\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\tsession.getObject(objectId);\n\n\t\t\tString oldTitle = cmisFolder.getName();\n\n\t\t\tMap<String, Object> properties = new HashMap<String, Object>();\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tString newObjectId = cmisFolder.updateProperties(\n\t\t\t\tproperties, true).getId();\n\n\t\t\tif (!objectId.equals(newObjectId)) {\n\t\t\t\tcmisFolder =\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tsession.getObject(newObjectId);\n\n\t\t\t\tupdateMappedId(folderId, newObjectId);\n\t\t\t}\n\n\t\t\treturn toFolder(cmisFolder);\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected FileEntry getFileEntry(Session session, long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\tObjectId objectId = toFileEntryId(fileEntryId);\n\n\t\tDocument document = (Document)session.getObject(objectId);\n\n\t\treturn toFileEntry(document.getObjectOfLatestVersion(false));\n\t}","id":37799,"modified_method":"protected FileEntry getFileEntry(Session session, long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\tString objectId = toFileEntryId(fileEntryId);\n\n\t\tDocument document = (Document)session.getObject(objectId);\n\n\t\treturn toFileEntry(document.getObjectOfLatestVersion(false));\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public FileEntry moveFileEntry(\n\t\t\tlong fileEntryId, long newFolderId, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\t\t\tObjectId newFolderObjectId = toFolderId(session, newFolderId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tvalidateTitle(session, newFolderId, document.getName());\n\n\t\t\tString oldFolderObjectId = document.getParents().get(0).getId();\n\n\t\t\tif (oldFolderObjectId.equals(newFolderObjectId.toString())) {\n\t\t\t\treturn toFileEntry(document);\n\t\t\t}\n\n\t\t\tdocument = (Document)document.move(\n\t\t\t\tnew ObjectIdImpl(oldFolderObjectId), newFolderObjectId);\n\n\t\t\tObjectId newObjectId = new ObjectIdImpl(\n\t\t\t\tdocument.getVersionSeriesId());\n\n\t\t\tif (!versionSeriesId.toString().equals(newObjectId.toString())) {\n\t\t\t\tdocument = (Document)session.getObject(newObjectId);\n\n\t\t\t\tupdateMappedId(fileEntryId, document.getVersionSeriesId());\n\t\t\t}\n\n\t\t\tFileEntry fileEntry = toFileEntry(document);\n\n\t\t\tdocument = null;\n\n\t\t\treturn fileEntry;\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37800,"modified_method":"public FileEntry moveFileEntry(\n\t\t\tlong fileEntryId, long newFolderId, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\t\t\tString newFolderObjectId = toFolderId(session, newFolderId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tvalidateTitle(session, newFolderId, document.getName());\n\n\t\t\tString oldFolderObjectId = document.getParents().get(0).getId();\n\n\t\t\tif (oldFolderObjectId.equals(newFolderObjectId)) {\n\t\t\t\treturn toFileEntry(document);\n\t\t\t}\n\n\t\t\tdocument = (Document)document.move(\n\t\t\t\tnew ObjectIdImpl(oldFolderObjectId), \n\t\t\t\tnew ObjectIdImpl(newFolderObjectId));\n\n\t\t\tString newObjectId = document.getVersionSeriesId();\n\n\t\t\tif (!versionSeriesId.equals(newObjectId)) {\n\t\t\t\tdocument = (Document)session.getObject(newObjectId);\n\n\t\t\t\tupdateMappedId(fileEntryId, document.getVersionSeriesId());\n\t\t\t}\n\n\t\t\tFileEntry fileEntry = toFileEntry(document);\n\n\t\t\tdocument = null;\n\n\t\t\treturn fileEntry;\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void revertFileEntry(\n\t\t\tlong fileEntryId, String version, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tDocument document = null;\n\n\t\tboolean checkedOut = false;\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tDocument oldVersion = null;\n\n\t\t\tList<Document> documentVersions = document.getAllVersions();\n\n\t\t\tfor (Document currentVersion : documentVersions) {\n\t\t\t\tString currentVersionLabel = currentVersion.getVersionLabel();\n\n\t\t\t\tif (Validator.isNull(currentVersionLabel)) {\n\t\t\t\t\tcurrentVersionLabel = DLFileEntryConstants.DEFAULT_VERSION;\n\t\t\t\t}\n\n\t\t\t\tif (currentVersionLabel.equals(version)) {\n\t\t\t\t\toldVersion = currentVersion;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tString changeLog = \"Reverted to \" + version;\n\t\t\tString title = oldVersion.getName();\n\t\t\tContentStream contentStream = oldVersion.getContentStream();\n\n\t\t\tAllowableActions allowableActions = document.getAllowableActions();\n\n\t\t\tSet<Action> allowableActionsSet =\n\t\t\t\tallowableActions.getAllowableActions();\n\n\t\t\tif (allowableActionsSet.contains(Action.CAN_CHECK_OUT)) {\n\t\t\t\tdocument.checkOut();\n\n\t\t\t\tcheckedOut = true;\n\t\t\t}\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tString oldTitle = document.getName();\n\n\t\t\tMap<String, Object> properties = null;\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties = new HashMap<String, Object>();\n\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tcheckUpdatable(allowableActionsSet, properties, contentStream);\n\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.checkIn(true, properties, contentStream, changeLog);\n\n\t\t\t\tcheckedOut = false;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (properties != null) {\n\t\t\t\t\tdocument = (Document)document.updateProperties(properties);\n\t\t\t\t}\n\n\t\t\t\tdocument.setContentStream(contentStream, true);\n\t\t\t}\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t\tfinally {\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.cancelCheckOut();\n\t\t\t}\n\t\t}\n\t}","id":37801,"modified_method":"public void revertFileEntry(\n\t\t\tlong fileEntryId, String version, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tDocument document = null;\n\n\t\tboolean checkedOut = false;\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tDocument oldVersion = null;\n\n\t\t\tList<Document> documentVersions = document.getAllVersions();\n\n\t\t\tfor (Document currentVersion : documentVersions) {\n\t\t\t\tString currentVersionLabel = currentVersion.getVersionLabel();\n\n\t\t\t\tif (Validator.isNull(currentVersionLabel)) {\n\t\t\t\t\tcurrentVersionLabel = DLFileEntryConstants.DEFAULT_VERSION;\n\t\t\t\t}\n\n\t\t\t\tif (currentVersionLabel.equals(version)) {\n\t\t\t\t\toldVersion = currentVersion;\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tString changeLog = \"Reverted to \" + version;\n\t\t\tString title = oldVersion.getName();\n\t\t\tContentStream contentStream = oldVersion.getContentStream();\n\n\t\t\tAllowableActions allowableActions = document.getAllowableActions();\n\n\t\t\tSet<Action> allowableActionsSet =\n\t\t\t\tallowableActions.getAllowableActions();\n\n\t\t\tif (allowableActionsSet.contains(Action.CAN_CHECK_OUT)) {\n\t\t\t\tdocument.checkOut();\n\n\t\t\t\tcheckedOut = true;\n\t\t\t}\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tString oldTitle = document.getName();\n\n\t\t\tMap<String, Object> properties = null;\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties = new HashMap<String, Object>();\n\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tcheckUpdatable(allowableActionsSet, properties, contentStream);\n\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.checkIn(true, properties, contentStream, changeLog);\n\n\t\t\t\tcheckedOut = false;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (properties != null) {\n\t\t\t\t\tdocument = (Document)document.updateProperties(properties);\n\t\t\t\t}\n\n\t\t\t\tdocument.setContentStream(contentStream, true);\n\t\t\t}\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t\tfinally {\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.cancelCheckOut();\n\t\t\t}\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected Folder getFolder(Session session, long folderId)\n\t\tthrows PortalException, SystemException {\n\n\t\tObjectId objectId = toFolderId(session, folderId);\n\n\t\tCmisObject cmisObject = session.getObject(objectId);\n\n\t\treturn (Folder)toFolderOrFileEntry(cmisObject);\n\t}","id":37802,"modified_method":"protected Folder getFolder(Session session, long folderId)\n\t\tthrows PortalException, SystemException {\n\n\t\tString objectId = toFolderId(session, folderId);\n\n\t\tCmisObject cmisObject = session.getObject(objectId);\n\n\t\treturn (Folder)toFolderOrFileEntry(cmisObject);\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public Folder moveFolder(\n\t\t\tlong folderId, long parentFolderId, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId objectId = toFolderId(session, folderId);\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder cmisFolder =\n\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\tsession.getObject(objectId);\n\n\t\t\tvalidateTitle(session, parentFolderId, cmisFolder.getName());\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder parentCmisFolder =\n\t\t\t\tcmisFolder.getFolderParent();\n\n\t\t\tif (parentCmisFolder == null) {\n\t\t\t\tthrow new RepositoryException(\n\t\t\t\t\t\"Cannot move CMIS root folder \" + folderId);\n\t\t\t}\n\n\t\t\tObjectId sourceFolderId = new ObjectIdImpl(\n\t\t\t\tparentCmisFolder.getId());\n\n\t\t\tObjectId targetFolderId = toFolderId(session, parentFolderId);\n\n\t\t\tif (!sourceFolderId.getId().equals(targetFolderId.getId()) &&\n\t\t\t\t!targetFolderId.getId().equals(objectId.getId())) {\n\n\t\t\t\tcmisFolder =\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tcmisFolder.move(sourceFolderId, targetFolderId);\n\t\t\t}\n\n\t\t\treturn toFolder(cmisFolder);\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37803,"modified_method":"public Folder moveFolder(\n\t\t\tlong folderId, long parentFolderId, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = toFolderId(session, folderId);\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder cmisFolder =\n\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\tsession.getObject(objectId);\n\n\t\t\tvalidateTitle(session, parentFolderId, cmisFolder.getName());\n\n\t\t\torg.apache.chemistry.opencmis.client.api.Folder parentCmisFolder =\n\t\t\t\tcmisFolder.getFolderParent();\n\n\t\t\tif (parentCmisFolder == null) {\n\t\t\t\tthrow new RepositoryException(\n\t\t\t\t\t\"Cannot move CMIS root folder \" + folderId);\n\t\t\t}\n\n\t\t\tString sourceFolderId = parentCmisFolder.getId();\n\n\t\t\tString targetFolderId = toFolderId(session, parentFolderId);\n\n\t\t\tif (!sourceFolderId.equals(targetFolderId) &&\n\t\t\t\t!targetFolderId.equals(objectId)) {\n\n\t\t\t\tcmisFolder =\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tcmisFolder.move(\n\t\t\t\t\t\t\tnew ObjectIdImpl(sourceFolderId), \n\t\t\t\t\t\t\tnew ObjectIdImpl(targetFolderId));\n\t\t\t}\n\n\t\t\treturn toFolder(cmisFolder);\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected ObjectId toFolderId(Session session, long folderId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry =\n\t\t\tRepositoryEntryUtil.fetchByPrimaryKey(folderId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tDLFolder dlFolder = DLFolderUtil.fetchByPrimaryKey(folderId);\n\n\t\t\tif (dlFolder == null) {\n\t\t\t\tthrow new NoSuchFolderException(\n\t\t\t\t\t\"No CMIS folder with {folderId=\" + folderId + \"}\");\n\t\t\t}\n\t\t\telse if (!dlFolder.isMountPoint()) {\n\t\t\t\tthrow new RepositoryException(\n\t\t\t\t\t\"CMIS repository should not be used for folder ID \" +\n\t\t\t\t\t\tfolderId);\n\t\t\t}\n\n\t\t\tString rootFolderId = session.getRepositoryInfo().getRootFolderId();\n\n\t\t\trepositoryEntry = RepositoryEntryUtil.fetchByR_M(\n\t\t\t\tgetRepositoryId(), rootFolderId);\n\n\t\t\tif (repositoryEntry == null) {\n\t\t\t\tlong repositoryEntryId = counterLocalService.increment();\n\n\t\t\t\trepositoryEntry = RepositoryEntryUtil.create(repositoryEntryId);\n\n\t\t\t\trepositoryEntry.setGroupId(getGroupId());\n\t\t\t\trepositoryEntry.setRepositoryId(getRepositoryId());\n\t\t\t\trepositoryEntry.setMappedId(rootFolderId);\n\n\t\t\t\tRepositoryEntryUtil.update(repositoryEntry, false);\n\t\t\t}\n\t\t}\n\n\t\treturn new ObjectIdImpl(repositoryEntry.getMappedId());\n\t}","id":37804,"modified_method":"protected String toFolderId(Session session, long folderId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry =\n\t\t\tRepositoryEntryUtil.fetchByPrimaryKey(folderId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tDLFolder dlFolder = DLFolderUtil.fetchByPrimaryKey(folderId);\n\n\t\t\tif (dlFolder == null) {\n\t\t\t\tthrow new NoSuchFolderException(\n\t\t\t\t\t\"No CMIS folder with {folderId=\" + folderId + \"}\");\n\t\t\t}\n\t\t\telse if (!dlFolder.isMountPoint()) {\n\t\t\t\tthrow new RepositoryException(\n\t\t\t\t\t\"CMIS repository should not be used for folder ID \" +\n\t\t\t\t\t\tfolderId);\n\t\t\t}\n\n\t\t\tString rootFolderId = session.getRepositoryInfo().getRootFolderId();\n\n\t\t\trepositoryEntry = RepositoryEntryUtil.fetchByR_M(\n\t\t\t\tgetRepositoryId(), rootFolderId);\n\n\t\t\tif (repositoryEntry == null) {\n\t\t\t\tlong repositoryEntryId = counterLocalService.increment();\n\n\t\t\t\trepositoryEntry = RepositoryEntryUtil.create(repositoryEntryId);\n\n\t\t\t\trepositoryEntry.setGroupId(getGroupId());\n\t\t\t\trepositoryEntry.setRepositoryId(getRepositoryId());\n\t\t\t\trepositoryEntry.setMappedId(rootFolderId);\n\n\t\t\t\tRepositoryEntryUtil.update(repositoryEntry, false);\n\t\t\t}\n\t\t}\n\n\t\treturn repositoryEntry.getMappedId();\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void lockFileEntry(long fileEntryId) {\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tdocument.checkOut();\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\t\t}\n\t}","id":37805,"modified_method":"public void lockFileEntry(long fileEntryId) {\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tdocument.checkOut();\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected ObjectId toFileEntryId(long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.fetchByPrimaryKey(\n\t\t\tfileEntryId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tthrow new NoSuchFileEntryException(\n\t\t\t\t\"No CMIS file entry with {fileEntryId=\" + fileEntryId + \"}\");\n\t\t}\n\n\t\treturn new ObjectIdImpl(repositoryEntry.getMappedId());\n\t}","id":37806,"modified_method":"protected String toFileEntryId(long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.fetchByPrimaryKey(\n\t\t\tfileEntryId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tthrow new NoSuchFileEntryException(\n\t\t\t\t\"No CMIS file entry with {fileEntryId=\" + fileEntryId + \"}\");\n\t\t}\n\n\t\treturn repositoryEntry.getMappedId();\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public FileEntry getFileEntryByUuid(String uuid)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.findByUUID_G(\n\t\t\t\tuuid, getGroupId());\n\n\t\t\tObjectId objectId = new ObjectIdImpl(repositoryEntry.getMappedId());\n\n\t\t\treturn toFileEntry((Document)session.getObject(objectId));\n\t\t}\n\t\tcatch (NoSuchRepositoryEntryException nsree) {\n\t\t\tthrow new NoSuchFileEntryException(nsree);\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37807,"modified_method":"public FileEntry getFileEntryByUuid(String uuid)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.findByUUID_G(\n\t\t\t\tuuid, getGroupId());\n\n\t\t\tString objectId = repositoryEntry.getMappedId();\n\n\t\t\treturn toFileEntry((Document)session.getObject(objectId));\n\t\t}\n\t\tcatch (NoSuchRepositoryEntryException nsree) {\n\t\t\tthrow new NoSuchFileEntryException(nsree);\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public FileEntry updateFileEntry(\n\t\t\tlong fileEntryId, String sourceFileName, String title,\n\t\t\tString description, String changeLog, boolean majorVersion,\n\t\t\tInputStream is, long size, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tDocument document = null;\n\n\t\tboolean checkedOut = false;\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tString oldTitle = document.getName();\n\n\t\t\tAllowableActions allowableActions = document.getAllowableActions();\n\n\t\t\tSet<Action> allowableActionsSet =\n\t\t\t\tallowableActions.getAllowableActions();\n\n\t\t\tif (allowableActionsSet.contains(Action.CAN_CHECK_OUT)) {\n\t\t\t\tdocument.checkOut();\n\n\t\t\t\tcheckedOut = true;\n\t\t\t}\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tMap<String, Object> properties = null;\n\n\t\t\tContentStream contentStream = null;\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties = new HashMap<String, Object>();\n\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tif (is != null) {\n\t\t\t\tString contentType = (String)serviceContext.getAttribute(\n\t\t\t\t\t\"contentType\");\n\n\t\t\t\tcontentStream = new ContentStreamImpl(\n\t\t\t\t\tsourceFileName, BigInteger.valueOf(size), contentType, is);\n\t\t\t}\n\n\t\t\tcheckUpdatable(allowableActionsSet, properties, contentStream);\n\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.checkIn(\n\t\t\t\t\tmajorVersion, properties, contentStream, changeLog);\n\n\t\t\t\tcheckedOut = false;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (properties != null) {\n\t\t\t\t\tdocument = (Document)document.updateProperties(properties);\n\t\t\t\t}\n\n\t\t\t\tif (contentStream != null) {\n\t\t\t\t\tdocument.setContentStream(contentStream, true);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tFileEntry fileEntry = toFileEntry(document);\n\n\t\t\treturn fileEntry;\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t\tfinally {\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.cancelCheckOut();\n\t\t\t}\n\t\t}\n\t}","id":37808,"modified_method":"public FileEntry updateFileEntry(\n\t\t\tlong fileEntryId, String sourceFileName, String title,\n\t\t\tString description, String changeLog, boolean majorVersion,\n\t\t\tInputStream is, long size, ServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\tDocument document = null;\n\n\t\tboolean checkedOut = false;\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tString oldTitle = document.getName();\n\n\t\t\tAllowableActions allowableActions = document.getAllowableActions();\n\n\t\t\tSet<Action> allowableActionsSet =\n\t\t\t\tallowableActions.getAllowableActions();\n\n\t\t\tif (allowableActionsSet.contains(Action.CAN_CHECK_OUT)) {\n\t\t\t\tdocument.checkOut();\n\n\t\t\t\tcheckedOut = true;\n\t\t\t}\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tMap<String, Object> properties = null;\n\n\t\t\tContentStream contentStream = null;\n\n\t\t\tif (Validator.isNotNull(title) && !title.equals(oldTitle)) {\n\t\t\t\tproperties = new HashMap<String, Object>();\n\n\t\t\t\tproperties.put(PropertyIds.NAME, title);\n\t\t\t}\n\n\t\t\tif (is != null) {\n\t\t\t\tString contentType = (String)serviceContext.getAttribute(\n\t\t\t\t\t\"contentType\");\n\n\t\t\t\tcontentStream = new ContentStreamImpl(\n\t\t\t\t\tsourceFileName, BigInteger.valueOf(size), contentType, is);\n\t\t\t}\n\n\t\t\tcheckUpdatable(allowableActionsSet, properties, contentStream);\n\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.checkIn(\n\t\t\t\t\tmajorVersion, properties, contentStream, changeLog);\n\n\t\t\t\tcheckedOut = false;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (properties != null) {\n\t\t\t\t\tdocument = (Document)document.updateProperties(properties);\n\t\t\t\t}\n\n\t\t\t\tif (contentStream != null) {\n\t\t\t\t\tdocument.setContentStream(contentStream, true);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tFileEntry fileEntry = toFileEntry(document);\n\n\t\t\treturn fileEntry;\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t\tfinally {\n\t\t\tif (checkedOut) {\n\t\t\t\tdocument.cancelCheckOut();\n\t\t\t}\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void deleteFileEntry(long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId objectId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(objectId);\n\n\t\t\tdeleteMappedFileEntry(document);\n\n\t\t\tdocument.deleteAllVersions();\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37809,"modified_method":"public void deleteFileEntry(long fileEntryId)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(objectId);\n\n\t\t\tdeleteMappedFileEntry(document);\n\n\t\t\tdocument.deleteAllVersions();\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected FileVersion getFileVersion(Session session, long fileVersionId)\n\t\tthrows PortalException, SystemException {\n\n\t\tObjectId objectId = toFileVersionId(fileVersionId);\n\n\t\treturn toFileVersion((Document)session.getObject(objectId));\n\t}","id":37810,"modified_method":"protected FileVersion getFileVersion(Session session, long fileVersionId)\n\t\tthrows PortalException, SystemException {\n\n\t\tString objectId = toFileVersionId(fileVersionId);\n\n\t\treturn toFileVersion((Document)session.getObject(objectId));\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void copyFileEntry(\n\t\t\tlong groupId, long fileEntryId, long destFolderId,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\t\t\tObjectId destFolderObjectId = toFolderId(session, destFolderId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tvalidateTitle(session, destFolderId, document.getName());\n\n\t\t\tdocument.copy(destFolderObjectId);\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37811,"modified_method":"public void copyFileEntry(\n\t\t\tlong groupId, long fileEntryId, long destFolderId,\n\t\t\tServiceContext serviceContext)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\t\t\tString destFolderObjectId = toFolderId(session, destFolderId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tvalidateTitle(session, destFolderId, document.getName());\n\n\t\t\tdocument.copy(new ObjectIdImpl(destFolderObjectId));\n\t\t}\n\t\tcatch (PortalException pe) {\n\t\t\tthrow pe;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public FileEntry getFileEntry(long folderId, String title)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = getObjectId(session, folderId, true, title);\n\n\t\t\tif (objectId != null) {\n\t\t\t\tCmisObject cmisObject = session.getObject(\n\t\t\t\t\tnew ObjectIdImpl(objectId));\n\n\t\t\t\tDocument document = (Document)cmisObject;\n\n\t\t\t\treturn toFileEntry(document);\n\t\t\t}\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\n\t\tthrow new NoSuchFileEntryException(\n\t\t\t\"No CMIS file entry with {folderId=\" + folderId + \", title=\" +\n\t\t\t\ttitle + \"}\");\n\t}","id":37812,"modified_method":"public FileEntry getFileEntry(long folderId, String title)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = getObjectId(session, folderId, true, title);\n\n\t\t\tif (objectId != null) {\n\t\t\t\tCmisObject cmisObject = session.getObject(objectId);\n\n\t\t\t\tDocument document = (Document)cmisObject;\n\n\t\t\t\treturn toFileEntry(document);\n\t\t\t}\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\n\t\tthrow new NoSuchFileEntryException(\n\t\t\t\"No CMIS file entry with {folderId=\" + folderId + \", title=\" +\n\t\t\t\ttitle + \"}\");\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public void unlockFileEntry(long fileEntryId) {\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tObjectId versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tdocument.checkIn(false, null, null, StringPool.BLANK);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\t\t}\n\t}","id":37813,"modified_method":"public void unlockFileEntry(long fileEntryId) {\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString versionSeriesId = toFileEntryId(fileEntryId);\n\n\t\t\tDocument document = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\n\t\t\tdocument = document.getObjectOfLatestVersion(false);\n\n\t\t\tdocument.checkIn(false, null, null, StringPool.BLANK);\n\n\t\t\tdocument = (Document)session.getObject(versionSeriesId);\n\n\t\t\tdocument.refresh();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t_log.error(e, e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected String getObjectId(\n\t\t\tSession session, long folderId, boolean fileEntry, String name)\n\t\tthrows SystemException {\n\n\t\ttry {\n\t\t\tObjectId objectId = toFolderId(session, folderId);\n\n\t\t\tStringBundler sb = new StringBundler(7);\n\n\t\t\tsb.append(\"SELECT cmis:objectId FROM \");\n\n\t\t\tif (fileEntry) {\n\t\t\t\tsb.append(\"cmis:document \");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsb.append(\"cmis:folder \");\n\t\t\t}\n\n\t\t\tsb.append(\"WHERE cmis:name = '\");\n\t\t\tsb.append(name);\n\t\t\tsb.append(\"' AND IN_FOLDER('\");\n\t\t\tsb.append(objectId.getId());\n\t\t\tsb.append(\"')\");\n\n\t\t\tString query = sb.toString();\n\n\t\t\tif (_log.isDebugEnabled()) {\n\t\t\t\t_log.debug(\"Calling query \" + query);\n\t\t\t}\n\n\t\t\tItemIterable<QueryResult> queryResults = session.query(\n\t\t\t\tquery, false);\n\n\t\t\tIterator<QueryResult> itr = queryResults.iterator();\n\n\t\t\tif (itr.hasNext()) {\n\t\t\t\tQueryResult queryResult = itr.next();\n\n\t\t\t\tPropertyData<String> propertyData = queryResult.getPropertyById(\n\t\t\t\t\tPropertyIds.OBJECT_ID);\n\n\t\t\t\tList<String> values = propertyData.getValues();\n\n\t\t\t\treturn values.get(0);\n\t\t\t}\n\n\t\t\treturn null;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","id":37814,"modified_method":"protected String getObjectId(\n\t\t\tSession session, long folderId, boolean fileEntry, String name)\n\t\tthrows SystemException {\n\n\t\ttry {\n\t\t\tString objectId = toFolderId(session, folderId);\n\n\t\t\tStringBundler sb = new StringBundler(7);\n\n\t\t\tsb.append(\"SELECT cmis:objectId FROM \");\n\n\t\t\tif (fileEntry) {\n\t\t\t\tsb.append(\"cmis:document \");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsb.append(\"cmis:folder \");\n\t\t\t}\n\n\t\t\tsb.append(\"WHERE cmis:name = '\");\n\t\t\tsb.append(name);\n\t\t\tsb.append(\"' AND IN_FOLDER('\");\n\t\t\tsb.append(objectId);\n\t\t\tsb.append(\"')\");\n\n\t\t\tString query = sb.toString();\n\n\t\t\tif (_log.isDebugEnabled()) {\n\t\t\t\t_log.debug(\"Calling query \" + query);\n\t\t\t}\n\n\t\t\tItemIterable<QueryResult> queryResults = session.query(\n\t\t\t\tquery, false);\n\n\t\t\tIterator<QueryResult> itr = queryResults.iterator();\n\n\t\t\tif (itr.hasNext()) {\n\t\t\t\tQueryResult queryResult = itr.next();\n\n\t\t\t\tPropertyData<String> propertyData = queryResult.getPropertyById(\n\t\t\t\t\tPropertyIds.OBJECT_ID);\n\n\t\t\t\tList<String> values = propertyData.getValues();\n\n\t\t\t\treturn values.get(0);\n\t\t\t}\n\n\t\t\treturn null;\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"public Folder getFolder(long parentFolderId, String title)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = getObjectId(\n\t\t\t\tsession, parentFolderId, false, title);\n\n\t\t\tif (objectId != null) {\n\t\t\t\tCmisObject cmisObject = session.getObject(\n\t\t\t\t\tnew ObjectIdImpl(objectId));\n\n\t\t\t\treturn toFolder(\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tcmisObject);\n\t\t\t}\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\n\t\tthrow new NoSuchFolderException(\n\t\t\t\"No CMIS file entry with {parentFolderId=\" + parentFolderId +\n\t\t\t\t\", title=\" + title + \"}\");\n\t}","id":37815,"modified_method":"public Folder getFolder(long parentFolderId, String title)\n\t\tthrows PortalException, SystemException {\n\n\t\ttry {\n\t\t\tSession session = getSession();\n\n\t\t\tString objectId = getObjectId(\n\t\t\t\tsession, parentFolderId, false, title);\n\n\t\t\tif (objectId != null) {\n\t\t\t\tCmisObject cmisObject = session.getObject(objectId);\n\n\t\t\t\treturn toFolder(\n\t\t\t\t\t(org.apache.chemistry.opencmis.client.api.Folder)\n\t\t\t\t\t\tcmisObject);\n\t\t\t}\n\t\t}\n\t\tcatch (SystemException se) {\n\t\t\tthrow se;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tprocessException(e);\n\n\t\t\tthrow new RepositoryException(e);\n\t\t}\n\n\t\tthrow new NoSuchFolderException(\n\t\t\t\"No CMIS file entry with {parentFolderId=\" + parentFolderId +\n\t\t\t\t\", title=\" + title + \"}\");\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"protected ObjectId toFileVersionId(long fileVersionId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.fetchByPrimaryKey(\n\t\t\tfileVersionId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tthrow new NoSuchFileEntryException(\n\t\t\t\t\"No CMIS file version with {fileVersionId=\" + fileVersionId +\n\t\t\t\t\t\"}\");\n\t\t}\n\n\t\treturn new ObjectIdImpl(repositoryEntry.getMappedId());\n\t}","id":37816,"modified_method":"protected String toFileVersionId(long fileVersionId)\n\t\tthrows PortalException, SystemException {\n\n\t\tRepositoryEntry repositoryEntry = RepositoryEntryUtil.fetchByPrimaryKey(\n\t\t\tfileVersionId);\n\n\t\tif (repositoryEntry == null) {\n\t\t\tthrow new NoSuchFileEntryException(\n\t\t\t\t\"No CMIS file version with {fileVersionId=\" + fileVersionId +\n\t\t\t\t\t\"}\");\n\t\t}\n\n\t\treturn repositoryEntry.getMappedId();\n\t}","commit_id":"1148a9dbdca95861d4f18f67602dc9363fe1cc26","url":"https://github.com/liferay/liferay-portal"},{"original_method":"/** Returns the number of mismatches in the pileup element within the given reference context.\r\n     *\r\n     * @param p       the pileup element\r\n     * @param ref     the reference context\r\n     * @param ignoreTargetSite     if true, ignore mismatches at the target locus (i.e. the center of the window)\r\n     * @return the number of mismatches\r\n     */\r\n    public static int mismatchesInRefWindow(PileupElement p, ReferenceContext ref, boolean ignoreTargetSite) {\r\n\r\n        int mismatches = 0;\r\n\r\n        GenomeLoc window = ref.getWindow();\r\n        char[] refBases = ref.getBases();\r\n        byte[] readBases = p.getRead().getReadBases();\r\n        Cigar c = p.getRead().getCigar();\r\n\r\n        int readIndex = 0;\r\n        int currentPos = p.getRead().getAlignmentStart();\r\n        int refIndex = Math.max(0, currentPos - (int)window.getStart());\r\n\r\n        for (int i = 0 ; i < c.numCigarElements() ; i++) {\r\n            CigarElement ce = c.getCigarElement(i);\r\n            switch ( ce.getOperator() ) {\r\n                case M:\r\n                    for (int j = 0; j < ce.getLength(); j++, readIndex++, currentPos++) {\r\n                        // are we past the ref window?\r\n                        if ( currentPos > window.getStop() )\r\n                            break;\r\n\r\n                        // are we before the ref window?\r\n                        if ( currentPos < window.getStart() )\r\n                            continue;\r\n\r\n                        char refChr = refBases[refIndex++];\r\n\r\n                        // do we need to skip the target site?\r\n                        if ( ignoreTargetSite && ref.getLocus().getStart() == currentPos )\r\n                            continue;\r\n\r\n                        char readChr = (char)readBases[readIndex];\r\n                        if ( Character.toUpperCase(readChr) != Character.toUpperCase(refChr) )\r\n                            mismatches++;\r\n                    }\r\n                    break;\r\n                case I:\r\n                    readIndex += ce.getLength();\r\n                    break;\r\n                case D:\r\n                    currentPos += ce.getLength();\r\n                    if ( currentPos > window.getStart() )\r\n                        refIndex += Math.min(ce.getLength(), currentPos - window.getStart());\r\n                    break;\r\n                case S:\r\n                    readIndex += ce.getLength();\r\n                    break;\r\n                default: throw new StingException(\"Only M,I,D,S cigar elements are currently supported; there was \" + ce.getOperator());\r\n            }\r\n\r\n        }\r\n\r\n        return mismatches;\r\n    }","id":37817,"modified_method":"/** Returns the number of mismatches in the pileup element within the given reference context.\r\n     *\r\n     * @param p       the pileup element\r\n     * @param ref     the reference context\r\n     * @param ignoreTargetSite     if true, ignore mismatches at the target locus (i.e. the center of the window)\r\n     * @return the number of mismatches\r\n     */\r\n    public static int mismatchesInRefWindow(PileupElement p, ReferenceContext ref, boolean ignoreTargetSite) {\r\n\r\n        int mismatches = 0;\r\n\r\n        int windowStart = (int)ref.getWindow().getStart();\r\n        int windowStop = (int)ref.getWindow().getStop();\r\n        char[] refBases = ref.getBases();\r\n        byte[] readBases = p.getRead().getReadBases();\r\n        Cigar c = p.getRead().getCigar();\r\n\r\n        int readIndex = 0;\r\n        int currentPos = p.getRead().getAlignmentStart();\r\n        int refIndex = Math.max(0, currentPos - windowStart);\r\n\r\n        for (int i = 0 ; i < c.numCigarElements() ; i++) {\r\n            CigarElement ce = c.getCigarElement(i);\r\n            int cigarElementLength = ce.getLength();\r\n            switch ( ce.getOperator() ) {\r\n                case M:\r\n                    for (int j = 0; j < cigarElementLength; j++, readIndex++, currentPos++) {\r\n                        // are we past the ref window?\r\n                        if ( currentPos > windowStop )\r\n                            break;\r\n\r\n                        // are we before the ref window?\r\n                        if ( currentPos < windowStart )\r\n                            continue;\r\n\r\n                        char refChr = refBases[refIndex++];\r\n\r\n                        // do we need to skip the target site?\r\n                        if ( ignoreTargetSite && ref.getLocus().getStart() == currentPos )\r\n                            continue;\r\n\r\n                        char readChr = (char)readBases[readIndex];\r\n                        if ( Character.toUpperCase(readChr) != Character.toUpperCase(refChr) )\r\n                            mismatches++;\r\n                    }\r\n                    break;\r\n                case I:\r\n                    readIndex += cigarElementLength;\r\n                    break;\r\n                case D:\r\n                    currentPos += cigarElementLength;\r\n                    if ( currentPos > windowStart )\r\n                        refIndex += Math.min(cigarElementLength, currentPos - windowStart);\r\n                    break;\r\n                case S:\r\n                    readIndex += cigarElementLength;\r\n                    break;\r\n                default: throw new StingException(\"Only M,I,D,S cigar elements are currently supported; there was \" + ce.getOperator());\r\n            }\r\n\r\n        }\r\n\r\n        return mismatches;\r\n    }","commit_id":"bb92e31118cd0342077ce1ef29d20fcca11cca58","url":"https://github.com/broadgsa/gatk"},{"original_method":"public DoCInfo map(RefMetaDataTracker tracker, ReferenceContext ref, AlignmentContext context) {\n\n        // fill in and print all of the per-locus coverage data, then return it to reduce\n\n        ReadBackedPileup pileup = context.getPileup().getBaseAndMappingFilteredPileup(minBaseQ, -1);\n\n        DoCInfo info = new DoCInfo();\n        info.totalCoverage = pileup.size();\n\n        int nBadMAPQReads = 0, nDeletionReads = 0;\n        for ( PileupElement p : pileup ) {\n\n            if ( excludeMAPQBelowThis > 0 && p.getRead().getMappingQuality() < excludeMAPQBelowThis )\n                nBadMAPQReads++;\n            else if ( p.isDeletion() )\n                nDeletionReads++;\n\n            if ( printBaseCounts ) {\n                int baseIndex = BaseUtils.simpleBaseToBaseIndex(p.getBase());\n                if ( baseIndex != -1 )\n                    info.baseCounts[baseIndex]++;\n            }\n\n            SAMReadGroupRecord readGroup = p.getRead().getReadGroup();\n            if ( readGroup == null )\n                continue;\n\n            if ( byReadGroup ) {\n                String readGroupName = readGroup.getReadGroupId();\n                int oldDepth = info.depthByReadGroup.get(readGroupName);\n                info.depthByReadGroup.put(readGroupName, oldDepth + 1);\n            }\n\n            if ( bySample ) {\n                String sample = readGroup.getSample();\n                if ( sample != null ) {\n                    int oldDepth = info.depthBySample.get(sample);\n                    info.depthBySample.put(sample, oldDepth + 1);\n                }\n            }\n        }\n\n        info.numDeletions = nDeletionReads;\n        if ( excludeMAPQBelowThis > 0 )\n            info.numBadMQReads = nBadMAPQReads;\n\n        // if we need to print the histogram, fill in the data\n        if ( printHistogram )\n            incCov(info.totalCoverage);\n\n        if ( !suppressLocusPrinting )\n            printDoCInfo(context.getLocation(), info, false);\n\n        return info;\n    }","id":37818,"modified_method":"public DoCInfo map(RefMetaDataTracker tracker, ReferenceContext ref, AlignmentContext context) {\n\n        // fill in and print all of the per-locus coverage data, then return it to reduce\n\n        ReadBackedPileup pileup = context.getPileup().getBaseFilteredPileup(minBaseQ);\n\n        DoCInfo info = new DoCInfo();\n        info.totalCoverage = pileup.size();\n\n        int nBadMAPQReads = 0, nDeletionReads = 0;\n        for ( PileupElement p : pileup ) {\n\n            if ( excludeMAPQBelowThis > 0 && p.getRead().getMappingQuality() < excludeMAPQBelowThis )\n                nBadMAPQReads++;\n            else if ( p.isDeletion() )\n                nDeletionReads++;\n\n            if ( printBaseCounts ) {\n                int baseIndex = BaseUtils.simpleBaseToBaseIndex(p.getBase());\n                if ( baseIndex != -1 )\n                    info.baseCounts[baseIndex]++;\n            }\n\n            SAMReadGroupRecord readGroup = p.getRead().getReadGroup();\n            if ( readGroup == null )\n                continue;\n\n            if ( byReadGroup ) {\n                String readGroupName = readGroup.getReadGroupId();\n                int oldDepth = info.depthByReadGroup.get(readGroupName);\n                info.depthByReadGroup.put(readGroupName, oldDepth + 1);\n            }\n\n            if ( bySample ) {\n                String sample = readGroup.getSample();\n                if ( sample != null ) {\n                    int oldDepth = info.depthBySample.get(sample);\n                    info.depthBySample.put(sample, oldDepth + 1);\n                }\n            }\n        }\n\n        info.numDeletions = nDeletionReads;\n        if ( excludeMAPQBelowThis > 0 )\n            info.numBadMQReads = nBadMAPQReads;\n\n        // if we need to print the histogram, fill in the data\n        if ( printHistogram )\n            incCov(info.totalCoverage);\n\n        if ( !suppressLocusPrinting )\n            printDoCInfo(context.getLocation(), info, false);\n\n        return info;\n    }","commit_id":"bb92e31118cd0342077ce1ef29d20fcca11cca58","url":"https://github.com/broadgsa/gatk"},{"original_method":"private static ReadBackedPileup filterPileup(ReadBackedPileup pileup, ReferenceContext refContext, int maxMismatches, boolean useBadMates) {\n        ArrayList<PileupElement> filteredPileup = new ArrayList<PileupElement>();\n        for ( PileupElement p : pileup ) {\n            if ( (useBadMates || !p.getRead().getReadPairedFlag() || p.getRead().getMateUnmappedFlag() || p.getRead().getMateReferenceIndex() == p.getRead().getReferenceIndex()) &&\n                 AlignmentUtils.mismatchesInRefWindow(p, refContext, true) <= maxMismatches )\n                filteredPileup.add(p);\n        }\n        return new ReadBackedPileup(pileup.getLocation(), filteredPileup);\n\n    }","id":37819,"modified_method":"private static ReadBackedPileup filterPileup(ReadBackedPileup pileup, ReferenceContext refContext, int maxMismatches) {\n        ArrayList<PileupElement> filteredPileup = new ArrayList<PileupElement>();\n        for ( PileupElement p : pileup ) {\n            if ( AlignmentUtils.mismatchesInRefWindow(p, refContext, true) <= maxMismatches )\n                filteredPileup.add(p);\n        }\n        return new ReadBackedPileup(pileup.getLocation(), filteredPileup);\n\n    }","commit_id":"bb92e31118cd0342077ce1ef29d20fcca11cca58","url":"https://github.com/broadgsa/gatk"},{"original_method":"/**\n     * Compute at a given locus.\n     *\n     * @param tracker the meta data tracker\n     * @param refContext the reference base\n     * @param rawContext contextual information around the locus\n     */\n    public Pair<VariationCall, List<Genotype>> map(RefMetaDataTracker tracker, ReferenceContext refContext, AlignmentContext rawContext) {\n        char ref = Character.toUpperCase(refContext.getBase());\n        if ( !BaseUtils.isRegularBase(ref) )\n            return null;\n\n        // filter the context based on min base and mapping qualities\n        ReadBackedPileup pileup = rawContext.getPileup().getBaseAndMappingFilteredPileup(UAC.MIN_BASE_QUALTY_SCORE, UAC.MIN_MAPPING_QUALTY_SCORE);\n\n        // filter the context based on mismatches and reads with bad mates\n        pileup = filterPileup(pileup, refContext, UAC.MAX_MISMATCHES, UAC.USE_BADLY_MATED_READS);\n\n        // an optimization to speed things up when there is no coverage or when overly covered\n        if ( pileup.size() == 0 ||\n             (UAC.MAX_READS_IN_PILEUP > 0 && pileup.size() > UAC.MAX_READS_IN_PILEUP) )\n            return null;\n\n        // are there too many deletions in the pileup?\n        if ( isValidDeletionFraction(UAC.MAX_DELETION_FRACTION) &&\n             (double)pileup.getNumberOfDeletions() / (double)pileup.size() > UAC.MAX_DELETION_FRACTION )\n            return null;\n\n        // stratify the AlignmentContext and cut by sample\n        // Note that for testing purposes, we may want to throw multi-samples at pooled mode\n        Map<String, StratifiedAlignmentContext> stratifiedContexts = StratifiedAlignmentContext.splitContextBySample(pileup, UAC.ASSUME_SINGLE_SAMPLE, (UAC.genotypeModel == GenotypeCalculationModel.Model.POOLED ? PooledCalculationModel.POOL_SAMPLE_NAME : null));\n        if ( stratifiedContexts == null )\n            return null;\n\n        DiploidGenotypePriors priors = new DiploidGenotypePriors(ref, UAC.heterozygosity, DiploidGenotypePriors.PROB_OF_TRISTATE_GENOTYPE);\n        Pair<VariationCall, List<Genotype>> call = gcm.calculateGenotype(tracker, ref, rawContext.getLocation(), stratifiedContexts, priors);\n\n        // annotate the call, if possible\n        if ( call != null && call.first != null && call.first instanceof ArbitraryFieldsBacked ) {\n            Map<String, String> annotations;\n            if ( UAC.ALL_ANNOTATIONS )\n                annotations = VariantAnnotator.getAllAnnotations(refContext, stratifiedContexts, call.first);\n            else\n                annotations = VariantAnnotator.getAnnotations(refContext, stratifiedContexts, call.first);\n            ((ArbitraryFieldsBacked)call.first).setFields(annotations);\n        }\n\n        return call;\n    }","id":37820,"modified_method":"/**\n     * Compute at a given locus.\n     *\n     * @param tracker the meta data tracker\n     * @param refContext the reference base\n     * @param rawContext contextual information around the locus\n     */\n    public Pair<VariationCall, List<Genotype>> map(RefMetaDataTracker tracker, ReferenceContext refContext, AlignmentContext rawContext) {\n        char ref = Character.toUpperCase(refContext.getBase());\n        if ( !BaseUtils.isRegularBase(ref) )\n            return null;\n\n        // filter the context based on min base and mapping qualities\n        ReadBackedPileup pileup = rawContext.getPileup().getBaseFilteredPileup(UAC.MIN_BASE_QUALTY_SCORE);\n\n        // filter the context based on mismatches\n        pileup = filterPileup(pileup, refContext, UAC.MAX_MISMATCHES);\n\n        // an optimization to speed things up when there is no coverage or when overly covered\n        if ( pileup.size() == 0 ||\n             (UAC.MAX_READS_IN_PILEUP > 0 && pileup.size() > UAC.MAX_READS_IN_PILEUP) )\n            return null;\n\n        // are there too many deletions in the pileup?\n        if ( isValidDeletionFraction(UAC.MAX_DELETION_FRACTION) &&\n             (double)pileup.getNumberOfDeletions() / (double)pileup.size() > UAC.MAX_DELETION_FRACTION )\n            return null;\n\n        // stratify the AlignmentContext and cut by sample\n        // Note that for testing purposes, we may want to throw multi-samples at pooled mode\n        Map<String, StratifiedAlignmentContext> stratifiedContexts = StratifiedAlignmentContext.splitContextBySample(pileup, UAC.ASSUME_SINGLE_SAMPLE, (UAC.genotypeModel == GenotypeCalculationModel.Model.POOLED ? PooledCalculationModel.POOL_SAMPLE_NAME : null));\n        if ( stratifiedContexts == null )\n            return null;\n\n        DiploidGenotypePriors priors = new DiploidGenotypePriors(ref, UAC.heterozygosity, DiploidGenotypePriors.PROB_OF_TRISTATE_GENOTYPE);\n        Pair<VariationCall, List<Genotype>> call = gcm.calculateGenotype(tracker, ref, rawContext.getLocation(), stratifiedContexts, priors);\n\n        // annotate the call, if possible\n        if ( call != null && call.first != null && call.first instanceof ArbitraryFieldsBacked ) {\n            Map<String, String> annotations;\n            if ( UAC.ALL_ANNOTATIONS )\n                annotations = VariantAnnotator.getAllAnnotations(refContext, stratifiedContexts, call.first);\n            else\n                annotations = VariantAnnotator.getAnnotations(refContext, stratifiedContexts, call.first);\n            ((ArbitraryFieldsBacked)call.first).setFields(annotations);\n        }\n\n        return call;\n    }","commit_id":"bb92e31118cd0342077ce1ef29d20fcca11cca58","url":"https://github.com/broadgsa/gatk"},{"original_method":"private Set<VCFHeaderLine> getHeaderInfo() {\n        Set<VCFHeaderLine> headerInfo = new HashSet<VCFHeaderLine>();\n\n        // this is only applicable to VCF\n        if ( UAC.VAR_FORMAT != GenotypeWriterFactory.GENOTYPE_FORMAT.VCF )\n            return headerInfo;\n\n        // first, the basic info\n        headerInfo.add(new VCFHeaderLine(\"source\", \"UnifiedGenotyper\"));\n        headerInfo.add(new VCFHeaderLine(\"reference\", getToolkit().getArguments().referenceFile.getName()));\n\n        // annotation (INFO) fields from VariantAnnotator\n        if ( UAC.ALL_ANNOTATIONS )\n            headerInfo.addAll(VariantAnnotator.getAllVCFAnnotationDescriptions());\n        else\n            headerInfo.addAll(VariantAnnotator.getVCFAnnotationDescriptions());\n\n        // annotation (INFO) fields from UnifiedGenotyper\n        headerInfo.add(new VCFHeaderLine(\"INFO_NOTE\", \"\\\"All annotations in the INFO field are generated only from the FILTERED context used for calling variants\\\"\"));\n        headerInfo.add(new VCFInfoHeaderLine(\"AF\", 1, VCFInfoHeaderLine.INFO_TYPE.Float, \"Allele Frequency\"));\n        headerInfo.add(new VCFInfoHeaderLine(\"NS\", 1, VCFInfoHeaderLine.INFO_TYPE.Integer, \"Number of Samples With Data\"));\n        if ( !UAC.NO_SLOD )\n            headerInfo.add(new VCFInfoHeaderLine(\"SB\", 1, VCFInfoHeaderLine.INFO_TYPE.Float, \"Strand Bias\"));\n\n        // FORMAT fields if not in POOLED mode\n        if ( UAC.genotypeModel != GenotypeCalculationModel.Model.POOLED )\n            headerInfo.addAll(VCFGenotypeRecord.getSupportedHeaderStrings());\n\n        // all of the arguments from the argument collection\n        Map<String,String> commandLineArgs = CommandLineUtils.getApproximateCommandLineArguments(Collections.<Object>singleton(UAC));\n        for ( Map.Entry<String, String> commandLineArg : commandLineArgs.entrySet() )\n            headerInfo.add(new VCFHeaderLine(String.format(\"UG_%s\", commandLineArg.getKey()), commandLineArg.getValue()));            \n\n        return headerInfo;\n    }","id":37821,"modified_method":"private Set<VCFHeaderLine> getHeaderInfo() {\n        Set<VCFHeaderLine> headerInfo = new HashSet<VCFHeaderLine>();\n\n        // this is only applicable to VCF\n        if ( UAC.VAR_FORMAT != GenotypeWriterFactory.GENOTYPE_FORMAT.VCF )\n            return headerInfo;\n\n        // first, the basic info\n        headerInfo.add(new VCFHeaderLine(\"source\", \"UnifiedGenotyper\"));\n        headerInfo.add(new VCFHeaderLine(\"reference\", getToolkit().getArguments().referenceFile.getName()));\n\n        // annotation (INFO) fields from VariantAnnotator\n        if ( UAC.ALL_ANNOTATIONS )\n            headerInfo.addAll(VariantAnnotator.getAllVCFAnnotationDescriptions());\n        else\n            headerInfo.addAll(VariantAnnotator.getVCFAnnotationDescriptions());\n\n        // annotation (INFO) fields from UnifiedGenotyper\n        headerInfo.add(new VCFHeaderLine(\"INFO_NOTE\", \"\\\"All annotations in the INFO field are generated only from the FILTERED context used for calling variants\\\"\"));\n        headerInfo.add(new VCFInfoHeaderLine(\"AF\", 1, VCFInfoHeaderLine.INFO_TYPE.Float, \"Allele Frequency\"));\n        headerInfo.add(new VCFInfoHeaderLine(\"NS\", 1, VCFInfoHeaderLine.INFO_TYPE.Integer, \"Number of Samples With Data\"));\n        if ( !UAC.NO_SLOD )\n            headerInfo.add(new VCFInfoHeaderLine(\"SB\", 1, VCFInfoHeaderLine.INFO_TYPE.Float, \"Strand Bias\"));\n\n        // FORMAT fields if not in POOLED mode\n        if ( UAC.genotypeModel != GenotypeCalculationModel.Model.POOLED )\n            headerInfo.addAll(VCFGenotypeRecord.getSupportedHeaderStrings());\n\n        // all of the arguments from the argument collection\n        Set<Object> x = new HashSet<Object>();\n        x.add(UAC);\n        x.addAll(getToolkit().getFilters());\n        Map<String,String> commandLineArgs = CommandLineUtils.getApproximateCommandLineArguments(x);\n        for ( Map.Entry<String, String> commandLineArg : commandLineArgs.entrySet() )\n            headerInfo.add(new VCFHeaderLine(String.format(\"UG_%s\", commandLineArg.getKey()), commandLineArg.getValue()));            \n\n        return headerInfo;\n    }","commit_id":"bb92e31118cd0342077ce1ef29d20fcca11cca58","url":"https://github.com/broadgsa/gatk"},{"original_method":"public void actionPerformed(ActionEvent e) {\n\t\tObject obj = e.getSource();\n\n\t\tstatusLabel.setVisible(false);\n\t\tstatusLabel.setText(\"\");\n\t\tif (obj.equals(playB)) {\n\t\t\t// System.out.println(\"playB\");\n\t\t\tlastButtonClicked = PLAY;\n\t\t\tplayback.start();\n\t\t\tsamplingGraph.start();\n\t\t\tcaptB.setEnabled(false);\n\t\t\tstopB.setEnabled(true);\n\t\t\tplayB.setEnabled(false);\n\t\t} else if (obj.equals(captB)) {\n\t\t\t// System.out.println(\"captB\");\n\t\t\tlastButtonClicked = RECORD;\n\t\t\tif (containingApplet != null) {\n\t\t\t\tJSObject openingWindow = (JSObject)((JSObject)JSObject.getWindow(containingApplet).getMember(\"opener\"));\n\t\t\t\topeningWindow.call(\"disableSubmitForGrade\", null);\n\t\t\t\topeningWindow.call(\"disableSave\", null);\n\t\t\t\t// openingWindow.call(\"hide\", new Object[]{\"question\" + params.getQuestionId()});\n\t\t\t}\n\t\t\tfile = null;\n\t\t\tcapture.start();\n\t\t\tfileName = res.getString(\"default_file_name\");\n\t\t\tsamplingGraph.start();\n\t\t\taudioMeter.start();\n\t\t\tcaptB.setEnabled(false);\n\t\t\tplayB.setEnabled(false);\n\t\t\tsaveButton.setEnabled(false);\n\t\t\tsamplingPanelContainer.remove(samplingGraph);\n\t\t\tsamplingPanelContainer.add(audioMeter);\n\t\t\tstopB.setEnabled(true);\n\t\t\tstartTimer();\n\t\t}\n\t\telse if (obj.equals(stopB)) {\n\t\t\t// System.out.println(\"stopB\");\n\t\t\tif (RECORD.equals(lastButtonClicked)) {\n\t\t\t\t// System.out.println(\"captB is enabled\");\n\t\t\t\tstatusLabel.setText(res.getString(\"processing\"));\n\t\t\t\tstatusLabel.setVisible(true);\n\t\t\t\tplayB.setEnabled(false);\n\t\t\t\tcaptB.setEnabled(false);\n\t\t\t\tsaveButton.setEnabled(false);\n\t\t\t\tstopB.setEnabled(false);\n\t\t\t\taudioMeter.stop();\n\t\t\t\tsamplingPanelContainer.remove(audioMeter);\n\t\t\t\tsamplingPanelContainer.add(samplingGraph);\n\t\t\t\tcaptureAudio();\n\t\t\t}\n\t\t\telse if (PLAY.equals(lastButtonClicked)) {\n\t\t\t\t// System.out.println(\"playB is enabled\");\n\t\t\t\tplayback.stop();\n\t\t\t\tsamplingGraph.stop();\n\t\t\t\tif (params.getAttemptsAllowed() > 0) {\n\t\t\t\t\tif (attempts == 0)\n\t\t\t\t\t\tcaptB.setEnabled(false);\n\t\t\t\t\telse\n\t\t\t\t\t\tcaptB.setEnabled(true);\n\t\t\t\t\tstopB.setEnabled(false);\n\t\t\t\t\tplayB.setEnabled(true);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (obj.equals(saveButton)) {\n\t\t\tsaveButton.setEnabled(false);\n\t\t\tcaptB.setEnabled(false);\n\t\t\tplayB.setEnabled(false);\n\t\t\tstatusLabel.setText(res.getString(\"processing\"));\n\t\t\tstatusLabel.setVisible(true);\n\t\t\tsaveMedia();\n\t\t}\n\t}","id":37822,"modified_method":"public void actionPerformed(ActionEvent e) {\n\t\tObject obj = e.getSource();\n\n\t\tstatusLabel.setVisible(false);\n\t\tstatusLabel.setText(\"\");\n\t\tif (obj.equals(playB)) {\n\t\t\t// System.out.println(\"playB\");\n\t\t\tlastButtonClicked = PLAY;\n\t\t\tplayback.start();\n\t\t\tsamplingGraph.start();\n\t\t\tcaptB.setEnabled(false);\n\t\t\tstopB.setEnabled(true);\n\t\t\tplayB.setEnabled(false);\n\t\t} else if (obj.equals(captB)) {\n\t\t\t// System.out.println(\"captB\");\n\t\t\tlastButtonClicked = RECORD;\n\t\t\tif (containingApplet != null) {\n\t\t\t\tJSObject window = (JSObject) JSObject.getWindow(containingApplet);\n\t\t\t\twindow.call(\"callOpener\", new String[]{\"disableSubmitForGrade\"});\n\t\t\t\twindow.call(\"callOpener\", new String[]{\"disableSave\"});\n\t\t\t\t// openingWindow.call(\"hide\", new Object[]{\"question\" + params.getQuestionId()});\n\t\t\t}\n\t\t\tfile = null;\n\t\t\tcapture.start();\n\t\t\tfileName = res.getString(\"default_file_name\");\n\t\t\tsamplingGraph.start();\n\t\t\taudioMeter.start();\n\t\t\tcaptB.setEnabled(false);\n\t\t\tplayB.setEnabled(false);\n\t\t\tsaveButton.setEnabled(false);\n\t\t\tsamplingPanelContainer.remove(samplingGraph);\n\t\t\tsamplingPanelContainer.add(audioMeter);\n\t\t\tstopB.setEnabled(true);\n\t\t\tstartTimer();\n\t\t}\n\t\telse if (obj.equals(stopB)) {\n\t\t\t// System.out.println(\"stopB\");\n\t\t\tif (RECORD.equals(lastButtonClicked)) {\n\t\t\t\t// System.out.println(\"captB is enabled\");\n\t\t\t\tstatusLabel.setText(res.getString(\"processing\"));\n\t\t\t\tstatusLabel.setVisible(true);\n\t\t\t\tplayB.setEnabled(false);\n\t\t\t\tcaptB.setEnabled(false);\n\t\t\t\tsaveButton.setEnabled(false);\n\t\t\t\tstopB.setEnabled(false);\n\t\t\t\taudioMeter.stop();\n\t\t\t\tsamplingPanelContainer.remove(audioMeter);\n\t\t\t\tsamplingPanelContainer.add(samplingGraph);\n\t\t\t\tcaptureAudio();\n\t\t\t}\n\t\t\telse if (PLAY.equals(lastButtonClicked)) {\n\t\t\t\t// System.out.println(\"playB is enabled\");\n\t\t\t\tplayback.stop();\n\t\t\t\tsamplingGraph.stop();\n\t\t\t\tif (params.getAttemptsAllowed() > 0) {\n\t\t\t\t\tif (attempts == 0)\n\t\t\t\t\t\tcaptB.setEnabled(false);\n\t\t\t\t\telse\n\t\t\t\t\t\tcaptB.setEnabled(true);\n\t\t\t\t\tstopB.setEnabled(false);\n\t\t\t\t\tplayB.setEnabled(true);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (obj.equals(saveButton)) {\n\t\t\tsaveButton.setEnabled(false);\n\t\t\tcaptB.setEnabled(false);\n\t\t\tplayB.setEnabled(false);\n\t\t\tstatusLabel.setText(res.getString(\"processing\"));\n\t\t\tstatusLabel.setVisible(true);\n\t\t\tsaveMedia();\n\t\t}\n\t}","commit_id":"7e5b601dad59abd2edb5603930ad3f2f20e6780a","url":"https://github.com/sakaiproject/sakai"},{"original_method":"private void captureAudio() {\n\t\t// timer was started by clicking Record to enforce time limit\n\t\tif (timer != null) {\n\t\t\ttimer.stop();\n\t\t}\n\n\t\tlines.removeAllElements();\n\t\tcapture.stop();\n\t\tsamplingGraph.stop();\n\t\tint retry = 1;\n\t\twhile (audioInputStream == null) {\n\t    \ttry {\n\t    \t\t// politely waiting for capture Thread to finish with audioInputStream.\n\t    \t\tThread.sleep(1000);\n\t    \t} catch (InterruptedException e) {\n\t    \t\t// TODO Auto-generated catch block\n\t    \t\te.printStackTrace();\n\t    \t}\n\t\t}\n\t\t// reset to the beginnning of the captured data\n\t\ttry {\n\t\t\taudioInputStream.reset();\n\t\t} catch (Exception ex) {\n\t\t\treportStatus(res.getString(\"Unable_to_reset\") + ex);\n\t\t\treturn;\n\t\t}\n\t\tstatusLabel.setVisible(false);\n\t\tstatusLabel.setText(\"\");\n\t\tplayB.setEnabled(true);\n\t\tsaveButton.setEnabled(true);\n\t\tattempts = params.getAttemptsRemaining();\n\t\tif (attempts > 0) {\n\t\t\tif (attempts < 9999) {\n\t\t\t\tparams.setAttemptsRemaining(--attempts);\n\t\t\t\trtextField.setText(\"\" + attempts);\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (attempts == 0)\n\t\t\tcaptB.setEnabled(false);\n\t\telse\n\t\t\tcaptB.setEnabled(true);\n\t\t\n\t\t// earlier we add 1sec leeway for the applet to load after the timer\n\t\t// start. to avoid\n\t\t// alarm user, the duration value shown would not be over max seconds\n\t\t// allowed.\n\t\t// However, for record keeping, the actual duration is saved.\n\t\tif (duration > params.getMaxSeconds())\n\t\t\ttextField.setText(NoDecimalPlaces.format(params.getMaxSeconds()));\n\t\telse\n\t\t\ttextField.setText(NoDecimalPlaces.format(duration));\n\t\t\n\t\tsamplingGraph.repaint();\n\t\t\n\t\tif (containingApplet != null) {\n\t\t\tJSObject openingWindow = (JSObject)((JSObject)JSObject.getWindow(containingApplet).getMember(\"opener\"));\n\t\t\topeningWindow.call(\"enableSubmitForGrade\", null);\n\t\t\topeningWindow.call(\"enableSave\", null);\n\t\t}\n\t}","id":37823,"modified_method":"private void captureAudio() {\n\t\t// timer was started by clicking Record to enforce time limit\n\t\tif (timer != null) {\n\t\t\ttimer.stop();\n\t\t}\n\n\t\tlines.removeAllElements();\n\t\tcapture.stop();\n\t\tsamplingGraph.stop();\n\t\tint retry = 1;\n\t\twhile (audioInputStream == null) {\n\t    \ttry {\n\t    \t\t// politely waiting for capture Thread to finish with audioInputStream.\n\t    \t\tThread.sleep(1000);\n\t    \t} catch (InterruptedException e) {\n\t    \t\t// TODO Auto-generated catch block\n\t    \t\te.printStackTrace();\n\t    \t}\n\t\t}\n\t\t// reset to the beginnning of the captured data\n\t\ttry {\n\t\t\taudioInputStream.reset();\n\t\t} catch (Exception ex) {\n\t\t\treportStatus(res.getString(\"Unable_to_reset\") + ex);\n\t\t\treturn;\n\t\t}\n\t\tstatusLabel.setVisible(false);\n\t\tstatusLabel.setText(\"\");\n\t\tplayB.setEnabled(true);\n\t\tsaveButton.setEnabled(true);\n\t\tattempts = params.getAttemptsRemaining();\n\t\tif (attempts > 0) {\n\t\t\tif (attempts < 9999) {\n\t\t\t\tparams.setAttemptsRemaining(--attempts);\n\t\t\t\trtextField.setText(\"\" + attempts);\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (attempts == 0)\n\t\t\tcaptB.setEnabled(false);\n\t\telse\n\t\t\tcaptB.setEnabled(true);\n\t\t\n\t\t// earlier we add 1sec leeway for the applet to load after the timer\n\t\t// start. to avoid\n\t\t// alarm user, the duration value shown would not be over max seconds\n\t\t// allowed.\n\t\t// However, for record keeping, the actual duration is saved.\n\t\tif (duration > params.getMaxSeconds())\n\t\t\ttextField.setText(NoDecimalPlaces.format(params.getMaxSeconds()));\n\t\telse\n\t\t\ttextField.setText(NoDecimalPlaces.format(duration));\n\t\t\n\t\tsamplingGraph.repaint();\n\t\t\n\t\tif (containingApplet != null) {\n\t\t\tJSObject window = (JSObject) JSObject.getWindow(containingApplet);\n\t\t\twindow.call(\"callOpener\", new String[]{\"enableSubmitForGrade\"});\n\t\t\twindow.call(\"callOpener\", new String[]{\"enableSave\"});\n\t\t}\n\t}","commit_id":"7e5b601dad59abd2edb5603930ad3f2f20e6780a","url":"https://github.com/sakaiproject/sakai"},{"original_method":"/**\n\t * Post audio data directly.\n\t * \n\t * @param audioType\n\t *            the audio type string\n\t * @param urlString\n\t *            the url (in applets must use getCodeBase().toString() +\n\t *            same-host relative url)\n\t * @param inputStream\n\t *            the input stream\n\t * @param attemptsLeft\n\t *            attempts left\n\t */\n\tpublic void saveAndPost(InputStream inputStream,\n\t\t\tfinal AudioFileFormat.Type audioType, final String urlString,\n\t\t\tint attemptsLeft, final boolean post) {\n\t\tThread saveAndPostThread = new Thread() {\n\t\t\tpublic void run() {\n\t\t\t    while (audioInputStream == null) {\n\t\t\t    \ttry {\n\t\t\t    \t\t// politely waiting for capture Thread to finish with audioInputStream.\n\t\t\t    \t\tThread.sleep(1000);\n\t\t\t    \t} catch (InterruptedException e) {\n\t\t\t    \t\t// TODO Auto-generated catch block\n\t\t\t    \t\te.printStackTrace();\n\t\t\t    \t}\n\t\t\t\t}\n\t\t\t\t// reset to the beginnning of the captured data\n\t\t\t\ttry {\n\t\t\t\t\taudioInputStream.reset();\n\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\treportStatus(res.getString(\"Unable_to_reset\") + ex);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (post)\n\t\t\t\t\tpostAudio(audioType, urlString);\n\t\t\t\t\n\t\t\t\tif (containingApplet != null) {\n\t\t\t\t\tJSObject window = (JSObject)JSObject.getWindow(containingApplet);\n\t\t\t\t\tJSObject opener = (JSObject)window.getMember(\"opener\");\n\t\t\t\t\topener.call(\"clickReloadLink\", new Object[]{window});\n\t\t\t\t\twindow.call(\"close\", null);\t\n\t\t\t\t}\n\t\t\t} // end of run\n\t\t}; // end of saveAndPostThread\n\t\tsaveAndPostThread.start();\n\t}","id":37824,"modified_method":"/**\n\t * Post audio data directly.\n\t * \n\t * @param audioType\n\t *            the audio type string\n\t * @param urlString\n\t *            the url (in applets must use getCodeBase().toString() +\n\t *            same-host relative url)\n\t * @param inputStream\n\t *            the input stream\n\t * @param attemptsLeft\n\t *            attempts left\n\t */\n\tpublic void saveAndPost(InputStream inputStream,\n\t\t\tfinal AudioFileFormat.Type audioType, final String urlString,\n\t\t\tint attemptsLeft, final boolean post) {\n\t\tThread saveAndPostThread = new Thread() {\n\t\t\tpublic void run() {\n\t\t\t    while (audioInputStream == null) {\n\t\t\t    \ttry {\n\t\t\t    \t\t// politely waiting for capture Thread to finish with audioInputStream.\n\t\t\t    \t\tThread.sleep(1000);\n\t\t\t    \t} catch (InterruptedException e) {\n\t\t\t    \t\t// TODO Auto-generated catch block\n\t\t\t    \t\te.printStackTrace();\n\t\t\t    \t}\n\t\t\t\t}\n\t\t\t\t// reset to the beginnning of the captured data\n\t\t\t\ttry {\n\t\t\t\t\taudioInputStream.reset();\n\t\t\t\t} catch (Exception ex) {\n\t\t\t\t\treportStatus(res.getString(\"Unable_to_reset\") + ex);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (post)\n\t\t\t\t\tpostAudio(audioType, urlString);\n\t\t\t\t\n\t\t\t\tif (containingApplet != null) {\n\t\t\t\t\tJSObject window = (JSObject)JSObject.getWindow(containingApplet);\n\t\t\t\t\twindow.call(\"callOpener\", new Object[]{\"clickReloadLink\", window});\n\t\t\t\t\twindow.call(\"close\", null);\t\n\t\t\t\t}\n\t\t\t} // end of run\n\t\t}; // end of saveAndPostThread\n\t\tsaveAndPostThread.start();\n\t}","commit_id":"7e5b601dad59abd2edb5603930ad3f2f20e6780a","url":"https://github.com/sakaiproject/sakai"},{"original_method":"private static void invalid(Class<?> source, String reason) {\n        throw new InvalidModelRuleDeclarationException(\"Type \" + source.getName() + \" is not a valid model rule source: \" + reason);\n    }","id":37825,"modified_method":"private static RuntimeException invalid(Class<?> source, String reason) {\n        return new InvalidModelRuleDeclarationException(\"Type \" + source.getName() + \" is not a valid model rule source: \" + reason);\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"public <T> void inspect(Class<T> source, ModelRegistry modelRegistry) {\n        validate(source);\n        Method[] methods = source.getDeclaredMethods();\n        for (Method method : methods) {\n            Model modelAnnotation = method.getAnnotation(Model.class);\n            if (modelAnnotation != null) {\n                if (method.getParameterTypes().length > 0) {\n                    throw new IllegalArgumentException(\"@Model rules cannot take arguments\");\n                }\n\n                // TODO other validations on method: synthetic, bridge methods, varargs, abstract, native\n\n                // TODO validate model name\n                String modelName = determineModelName(modelAnnotation, method);\n\n                if (method.getTypeParameters().length > 0) {\n                    invalid(\"model creation rule\", method, \"cannot have type variables (i.e. cannot be a generic method)\");\n                }\n\n                // TODO validate the return type (generics?)\n\n                TypeToken<?> returnType = TypeToken.of(method.getGenericReturnType());\n\n                doRegisterCreation(source, method, returnType, modelName, modelRegistry);\n            }\n        }\n    }","id":37826,"modified_method":"public <T> void inspect(Class<T> source, ModelRegistry modelRegistry) {\n        validate(source);\n        Method[] methods = source.getDeclaredMethods();\n        for (Method method : methods) {\n            Annotation annotation = getTypeAnnotation(method);\n            if (annotation != null) {\n                if (annotation instanceof Model) {\n                    creationMethod(modelRegistry, method, (Model) annotation);\n                } else if (annotation instanceof Mutate) {\n                    mutationMethod(modelRegistry, method);\n                } else {\n                    throw new IllegalStateException(\"Unhandled rule type annotation: \" + annotation);\n                }\n            }\n        }\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private static void invalid(String description, Method method, String reason) {\n        StringBuilder sb = new StringBuilder();\n        new MethodModelRuleSourceDescriptor(method).describeTo(sb);\n        sb.append(\" is not a valid \").append(description).append(\": \").append(reason);\n        throw new InvalidModelRuleDeclarationException(sb.toString());\n    }","id":37827,"modified_method":"private static RuntimeException invalid(String description, Method method, String reason) {\n        StringBuilder sb = new StringBuilder();\n        new MethodModelRuleSourceDescriptor(method).describeTo(sb);\n        sb.append(\" is not a valid \").append(description).append(\": \").append(reason);\n        return new InvalidModelRuleDeclarationException(sb.toString());\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private <T, R> void doRegisterCreation(final Class<T> source, final Method method, final TypeToken<R> returnType, final String modelName, ModelRegistry modelRegistry) {\n        @SuppressWarnings(\"unchecked\") final Class<T> clazz = (Class<T>) source.getClass();\n        @SuppressWarnings(\"unchecked\") Class<R> returnTypeClass = (Class<R>) returnType.getRawType();\n        final JavaMethod<T, R> methodWrapper = JavaReflectionUtil.method(clazz, returnTypeClass, method);\n\n        modelRegistry.create(modelName, Collections.<String>emptyList(), new ModelCreator<R>() {\n\n            public ModelReference<R> getReference() {\n                return new ModelReference<R>(new ModelPath(modelName), new ModelType<R>(returnType));\n            }\n\n            public R create(Inputs inputs) {\n                T instance = Modifier.isStatic(method.getModifiers()) ? null : toInstance(source);\n                // ignore inputs, we know they're empty\n                return methodWrapper.invoke(instance);\n            }\n\n            public ModelRuleSourceDescriptor getSourceDescriptor() {\n                return new MethodModelRuleSourceDescriptor(method);\n            }\n        });\n    }","id":37828,"modified_method":"private <T, R> void doRegisterCreation(final Method method, final TypeToken<R> returnType, final String modelName, ModelRegistry modelRegistry) {\n        @SuppressWarnings(\"unchecked\") final Class<T> clazz = (Class<T>) method.getDeclaringClass();\n        @SuppressWarnings(\"unchecked\") Class<R> returnTypeClass = (Class<R>) returnType.getRawType();\n        final JavaMethod<T, R> methodWrapper = JavaReflectionUtil.method(clazz, returnTypeClass, method);\n\n        modelRegistry.create(modelName, Collections.<String>emptyList(), new ModelCreator<R>() {\n\n            public ModelReference<R> getReference() {\n                return new ModelReference<R>(new ModelPath(modelName), new ModelType<R>(returnType));\n            }\n\n            public R create(Inputs inputs) {\n                T instance = Modifier.isStatic(method.getModifiers()) ? null : toInstance(clazz);\n                // ignore inputs, we know they're empty\n                return methodWrapper.invoke(instance);\n            }\n\n            public ModelRuleSourceDescriptor getSourceDescriptor() {\n                return new MethodModelRuleSourceDescriptor(method);\n            }\n        });\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"/**\n     * Validates that the given class is effectively static and has no instance state.\n     *\n     * @param source the class the validate\n     */\n    public void validate(Class<?> source) throws InvalidModelRuleDeclarationException {\n\n        // TODO - exceptions thrown here should point to some extensive documentation on the concept of class rule sources\n\n        int modifiers = source.getModifiers();\n\n        if (Modifier.isInterface(modifiers)) {\n            invalid(source, \"must be a class, not an interface\");\n        }\n        if (Modifier.isAbstract(modifiers)) {\n            invalid(source, \"class cannot be abstract\");\n        }\n\n        if (source.getEnclosingClass() != null) {\n            if (Modifier.isStatic(modifiers)) {\n                if (Modifier.isPrivate(modifiers)) {\n                    invalid(source, \"class cannot be private\");\n                }\n            } else {\n                invalid(source, \"enclosed classes must be static and non private\");\n            }\n        }\n\n        Class<?> superclass = source.getSuperclass();\n        if (!superclass.equals(Object.class)) {\n            invalid(source, \"cannot have superclass\");\n        }\n\n        Constructor<?>[] constructors = source.getDeclaredConstructors();\n        if (constructors.length > 1) {\n            invalid(source, \"cannot have more than one constructor\");\n        }\n\n        Constructor constructor = constructors[0];\n        if (constructor.getParameterTypes().length > 0) {\n            invalid(source, \"constructor cannot take any arguments\");\n        }\n\n        Field[] fields = source.getDeclaredFields();\n        for (Field field : fields) {\n            int fieldModifiers = field.getModifiers();\n            if (!field.isSynthetic() && !(Modifier.isStatic(fieldModifiers) && Modifier.isFinal(fieldModifiers))) {\n                invalid(source, \"field \" + field.getName() + \" is not static final\");\n            }\n        }\n\n    }","id":37829,"modified_method":"/**\n     * Validates that the given class is effectively static and has no instance state.\n     *\n     * @param source the class the validate\n     */\n    public void validate(Class<?> source) throws InvalidModelRuleDeclarationException {\n\n        // TODO - exceptions thrown here should point to some extensive documentation on the concept of class rule sources\n\n        int modifiers = source.getModifiers();\n\n        if (Modifier.isInterface(modifiers)) {\n            throw invalid(source, \"must be a class, not an interface\");\n        }\n        if (Modifier.isAbstract(modifiers)) {\n            throw invalid(source, \"class cannot be abstract\");\n        }\n\n        if (source.getEnclosingClass() != null) {\n            if (Modifier.isStatic(modifiers)) {\n                if (Modifier.isPrivate(modifiers)) {\n                    throw invalid(source, \"class cannot be private\");\n                }\n            } else {\n                throw invalid(source, \"enclosed classes must be static and non private\");\n            }\n        }\n\n        Class<?> superclass = source.getSuperclass();\n        if (!superclass.equals(Object.class)) {\n            throw invalid(source, \"cannot have superclass\");\n        }\n\n        Constructor<?>[] constructors = source.getDeclaredConstructors();\n        if (constructors.length > 1) {\n            throw invalid(source, \"cannot have more than one constructor\");\n        }\n\n        Constructor constructor = constructors[0];\n        if (constructor.getParameterTypes().length > 0) {\n            throw invalid(source, \"constructor cannot take any arguments\");\n        }\n\n        Field[] fields = source.getDeclaredFields();\n        for (Field field : fields) {\n            int fieldModifiers = field.getModifiers();\n            if (!field.isSynthetic() && !(Modifier.isStatic(fieldModifiers) && Modifier.isFinal(fieldModifiers))) {\n                throw invalid(source, \"field \" + field.getName() + \" is not static final\");\n            }\n        }\n\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"public Class<T> getType() {\n            return type;\n        }","id":37830,"modified_method":"public ModelType<T> getType() {\n            return type;\n        }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private static <T> BindableParameter binding(Class<T> type, Annotation[] annotations) {\n        Path pathAnnotation = (Path) findFirst(annotations, new Spec<Annotation>() {\n            public boolean isSatisfiedBy(Annotation element) {\n                return element.annotationType().equals(Path.class);\n            }\n        });\n        String path = pathAnnotation == null ? null : pathAnnotation.value();\n        return new BindableParameter<T>(path == null ? null : ModelPath.path(path), type);\n    }","id":37831,"modified_method":"private static <T> BindableParameter binding(Type type, Annotation[] annotations) {\n        Path pathAnnotation = (Path) findFirst(annotations, new Spec<Annotation>() {\n            public boolean isSatisfiedBy(Annotation element) {\n                return element.annotationType().equals(Path.class);\n            }\n        });\n        String path = pathAnnotation == null ? null : pathAnnotation.value();\n        @SuppressWarnings(\"unchecked\") TypeToken<T> cast = (TypeToken<T>) TypeToken.of(type);\n        return new BindableParameter<T>(path == null ? null : ModelPath.path(path), new ModelType<T>(cast));\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private static void registerMutator(ModelRegistry modelRegistry, ModelRule modelRule, final Method bindingMethod, final List<BindableParameter<?>> bindings) {\n        BindableParameter<?> first = bindings.get(0);\n        List<BindableParameter<?>> tail = bindings.subList(1, bindings.size());\n        ModelMutator<?> modelMutator = toMutator(modelRule, bindingMethod, first, tail);\n\n        String path = first.getPath().toString();\n        List<String> bindingPaths = CollectionUtils.collect(tail, new Transformer<String, BindableParameter<?>>() {\n            public String transform(BindableParameter<?> bindableParameter) {\n                return bindableParameter.getPath().toString();\n            }\n        });\n\n        if (modelRule instanceof ModelFinalizer) {\n            modelRegistry.finalize(path, bindingPaths, modelMutator);\n        } else {\n            modelRegistry.mutate(path, bindingPaths, modelMutator);\n        }\n    }","id":37832,"modified_method":"private static void registerMutator(ModelRegistry modelRegistry, final Method bindingMethod, final List<BindableParameter<?>> bindings, boolean isFinalizer, Factory<?> instance) {\n        BindableParameter<?> first = bindings.get(0);\n        List<BindableParameter<?>> tail = bindings.subList(1, bindings.size());\n        ModelMutator<?> modelMutator = toMutator(bindingMethod, first, tail, instance);\n\n        String path = first.getPath().toString();\n        List<String> bindingPaths = CollectionUtils.collect(tail, new Transformer<String, BindableParameter<?>>() {\n            public String transform(BindableParameter<?> bindableParameter) {\n                return bindableParameter.getPath().toString();\n            }\n        });\n\n        if (isFinalizer) {\n            modelRegistry.finalize(path, bindingPaths, modelMutator);\n        } else {\n            modelRegistry.mutate(path, bindingPaths, modelMutator);\n        }\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private static <T> ModelMutator<T> toMutator(final ModelRule modelRule, final Method bindingMethod, final BindableParameter<T> first, final List<BindableParameter<?>> tail) {\n        return new ModelMutator<T>() {\n\n            private final MethodModelRuleSourceDescriptor methodModelRuleSourceDescriptor = new MethodModelRuleSourceDescriptor(bindingMethod);\n\n            public ModelRuleSourceDescriptor getSourceDescriptor() {\n                return methodModelRuleSourceDescriptor;\n            }\n\n            public ModelReference<T> getReference() {\n                return new ModelReference<T>(first.path, new ModelType<T>(first.type));\n            }\n\n            public void mutate(T object, Inputs inputs) {\n                Object[] args = new Object[1 + tail.size()];\n                args[0] = object;\n                for (int i = 0; i < inputs.size(); ++i) {\n                    args[i + 1] = inputs.get(i, tail.get(i).getType()).getInstance();\n                }\n\n                bindingMethod.setAccessible(true);\n\n                try {\n                    bindingMethod.invoke(modelRule, args);\n                } catch (Exception e) {\n                    Throwable t = e;\n                    if (t instanceof InvocationTargetException) {\n                        t = e.getCause();\n                    }\n\n                    throw UncheckedException.throwAsUncheckedException(t);\n                }\n            }\n        };\n    }","id":37833,"modified_method":"private static <T> ModelMutator<T> toMutator(final Method bindingMethod, final BindableParameter<T> first, final List<BindableParameter<?>> tail, final Factory<?> instance) {\n        return new ModelMutator<T>() {\n\n            private final MethodModelRuleSourceDescriptor methodModelRuleSourceDescriptor = new MethodModelRuleSourceDescriptor(bindingMethod);\n\n            public ModelRuleSourceDescriptor getSourceDescriptor() {\n                return methodModelRuleSourceDescriptor;\n            }\n\n            public ModelReference<T> getReference() {\n                return new ModelReference<T>(first.path, first.type);\n            }\n\n            public void mutate(T object, Inputs inputs) {\n                Object[] args = new Object[1 + tail.size()];\n                args[0] = object;\n                for (int i = 0; i < inputs.size(); ++i) {\n                    args[i + 1] = inputs.get(i, tail.get(i).getType()).getInstance();\n                }\n\n                bindingMethod.setAccessible(true);\n\n                try {\n                    bindingMethod.invoke(instance.create(), args);\n                } catch (Exception e) {\n                    Throwable t = e;\n                    if (t instanceof InvocationTargetException) {\n                        t = e.getCause();\n                    }\n\n                    throw UncheckedException.throwAsUncheckedException(t);\n                }\n            }\n        };\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"public BindableParameter(@Nullable ModelPath path, Class<T> type) {\n            this.path = path;\n            this.type = type;\n        }","id":37834,"modified_method":"public BindableParameter(@Nullable ModelPath path, ModelType<T> type) {\n            this.path = path;\n            this.type = type;\n        }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"public static void rule(final ModelRegistry modelRegistry, final ModelRule modelRule) {\n        final Method bindingMethod = findBindingMethod(modelRule);\n        final List<BindableParameter<?>> initialBindings = bindings(bindingMethod);\n\n        boolean unsatisfied = CollectionUtils.any(initialBindings, new Spec<BindableParameter<?>>() {\n            public boolean isSatisfiedBy(BindableParameter<?> element) {\n                return element.getPath() == null;\n            }\n        });\n\n        if (unsatisfied) {\n            modelRegistry.registerListener(new ModelCreationListener() {\n\n                private List<BindableParameter<?>> bindings = initialBindings;\n\n                public boolean onCreate(ModelReference<?> reference) {\n                    ImmutableList.Builder<BindableParameter<?>> bindingsBuilder = ImmutableList.builder();\n\n                    boolean unsatisfied = false;\n\n                    for (BindableParameter<?> binding : bindings) {\n                        if (binding.getPath() == null) {\n                            if (binding.getType().isAssignableFrom(reference.getType().getRawClass())) {\n                                bindingsBuilder.add(copyBindingWithPath(reference.getPath(), binding));\n                                continue;\n                            } else {\n                                unsatisfied = true;\n                            }\n                        }\n\n                        bindingsBuilder.add(binding);\n                    }\n\n                    bindings = bindingsBuilder.build();\n\n                    if (unsatisfied) {\n                        return false;\n                    } else {\n                        registerMutator(modelRegistry, modelRule, bindingMethod, bindings);\n                        return true;\n                    }\n                }\n            });\n        } else {\n            registerMutator(modelRegistry, modelRule, bindingMethod, initialBindings);\n        }\n    }","id":37835,"modified_method":"public static void rule(final ModelRegistry modelRegistry, final ModelRule modelRule) {\n        final Method bindingMethod = findBindingMethod(modelRule);\n        bind(modelRegistry, bindingMethod, new Action<List<BindableParameter<?>>>() {\n            public void execute(List<BindableParameter<?>> bindableParameters) {\n                registerMutator(modelRegistry, bindingMethod, bindableParameters, modelRule instanceof ModelFinalizer, Factories.constant(modelRule));\n            }\n        });\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"private static List<BindableParameter<?>> bindings(Method method) {\n        return bindings(method.getParameterTypes(), method.getParameterAnnotations());\n    }","id":37836,"modified_method":"private static List<BindableParameter<?>> bindings(Method method) {\n        return bindings(method.getGenericParameterTypes(), method.getParameterAnnotations());\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"static List<BindableParameter<?>> bindings(Class[] types, Annotation[][] annotations) {\n        ImmutableList.Builder<BindableParameter<?>> inputBindingBuilder = ImmutableList.builder();\n\n        for (int i = 0; i < types.length; i++) {\n            Class<?> paramType = types[i];\n            Annotation[] paramAnnotations = annotations[i];\n\n            inputBindingBuilder.add(binding(paramType, paramAnnotations));\n        }\n\n        return inputBindingBuilder.build();\n    }","id":37837,"modified_method":"static List<BindableParameter<?>> bindings(Type[] types, Annotation[][] annotations) {\n        ImmutableList.Builder<BindableParameter<?>> inputBindingBuilder = ImmutableList.builder();\n\n        for (int i = 0; i < types.length; i++) {\n            Type paramType = types[i];\n            Annotation[] paramAnnotations = annotations[i];\n\n            inputBindingBuilder.add(binding(paramType, paramAnnotations));\n        }\n\n        return inputBindingBuilder.build();\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"public Repositories create(Inputs inputs) {\n        FlavorContainer flavors = inputs.get(0, FlavorContainer.class).getInstance();\n        PlatformContainer platforms = inputs.get(1, PlatformContainer.class).getInstance();\n        BuildTypeContainer buildTypes = inputs.get(2, BuildTypeContainer.class).getInstance();\n        Action<PrebuiltLibrary> initializer = new PrebuiltLibraryInitializer(instantiator, platforms, buildTypes, flavors);\n        return new DefaultRepositories(instantiator, fileResolver, initializer);\n    }","id":37838,"modified_method":"public Repositories create(Inputs inputs) {\n        FlavorContainer flavors = inputs.get(0, ModelType.of(FlavorContainer.class)).getInstance();\n        PlatformContainer platforms = inputs.get(1, ModelType.of(PlatformContainer.class)).getInstance();\n        BuildTypeContainer buildTypes = inputs.get(2, ModelType.of(BuildTypeContainer.class)).getInstance();\n        Action<PrebuiltLibrary> initializer = new PrebuiltLibraryInitializer(instantiator, platforms, buildTypes, flavors);\n        return new DefaultRepositories(instantiator, fileResolver, initializer);\n    }","commit_id":"441e0078e0ee1d5f8e6e95cd9205ae6b69862ef6","url":"https://github.com/gradle/gradle"},{"original_method":"@Inject\n    public RecoverySource(Settings settings, TransportService transportService, IndicesService indicesService,\n                          RecoverySettings recoverySettings) {\n        super(settings);\n        this.transportService = transportService;\n        this.indicesService = indicesService;\n\n        this.recoverySettings = recoverySettings;\n\n        transportService.registerHandler(Actions.START_RECOVERY, new StartRecoveryTransportRequestHandler());\n        this.internalActionTimeout = componentSettings.getAsTime(\"internal_action_timeout\", TimeValue.timeValueMinutes(15));\n        this.internalActionLongTimeout = new TimeValue(internalActionTimeout.millis() * 2);\n    }","id":37839,"modified_method":"@Inject\n    public RecoverySource(Settings settings, TransportService transportService, IndicesService indicesService,\n                          RecoverySettings recoverySettings, ClusterService clusterService) {\n        super(settings);\n        this.transportService = transportService;\n        this.indicesService = indicesService;\n        this.clusterService = clusterService;\n\n        this.recoverySettings = recoverySettings;\n\n        transportService.registerHandler(Actions.START_RECOVERY, new StartRecoveryTransportRequestHandler());\n        this.internalActionTimeout = componentSettings.getAsTime(\"internal_action_timeout\", TimeValue.timeValueMinutes(15));\n        this.internalActionLongTimeout = new TimeValue(internalActionTimeout.millis() * 2);\n    }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private RecoveryResponse recover(final StartRecoveryRequest request) {\n        final InternalIndexShard shard = (InternalIndexShard) indicesService.indexServiceSafe(request.shardId().index().name()).shardSafe(request.shardId().id());\n        logger.trace(\"[{}][{}] starting recovery to {}, mark_as_relocated {}\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), request.markAsRelocated());\n        final RecoveryResponse response = new RecoveryResponse();\n        shard.recover(new Engine.RecoveryHandler() {\n            @Override\n            public void phase1(final SnapshotIndexCommit snapshot) throws ElasticSearchException {\n                long totalSize = 0;\n                long existingTotalSize = 0;\n                try {\n                    StopWatch stopWatch = new StopWatch().start();\n\n                    for (String name : snapshot.getFiles()) {\n                        StoreFileMetaData md = shard.store().metaData(name);\n                        boolean useExisting = false;\n                        if (request.existingFiles().containsKey(name)) {\n                            // we don't compute checksum for segments, so always recover them\n                            if (!name.startsWith(\"segments\") && md.isSame(request.existingFiles().get(name))) {\n                                response.phase1ExistingFileNames.add(name);\n                                response.phase1ExistingFileSizes.add(md.length());\n                                existingTotalSize += md.length();\n                                useExisting = true;\n                                if (logger.isTraceEnabled()) {\n                                    logger.trace(\"[{}][{}] recovery [phase1] to {}: not recovering [{}], exists in local store and has checksum [{}], size [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name, md.checksum(), md.length());\n                                }\n                            }\n                        }\n                        if (!useExisting) {\n                            if (request.existingFiles().containsKey(name)) {\n                                logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering [{}], exists in local store, but is different: remote [{}], local [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name, request.existingFiles().get(name), md);\n                            } else {\n                                logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering [{}], does not exists in remote\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name);\n                            }\n                            response.phase1FileNames.add(name);\n                            response.phase1FileSizes.add(md.length());\n                        }\n                        totalSize += md.length();\n                    }\n                    response.phase1TotalSize = totalSize;\n                    response.phase1ExistingTotalSize = existingTotalSize;\n\n                    logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering_files [{}] with total_size [{}], reusing_files [{}] with total_size [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), response.phase1FileNames.size(), new ByteSizeValue(totalSize), response.phase1ExistingFileNames.size(), new ByteSizeValue(existingTotalSize));\n\n                    RecoveryFilesInfoRequest recoveryInfoFilesRequest = new RecoveryFilesInfoRequest(request.recoveryId(), request.shardId(), response.phase1FileNames, response.phase1FileSizes,\n                            response.phase1ExistingFileNames, response.phase1ExistingFileSizes, response.phase1TotalSize, response.phase1ExistingTotalSize);\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FILES_INFO, recoveryInfoFilesRequest, TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n\n                    final CountDownLatch latch = new CountDownLatch(response.phase1FileNames.size());\n                    final AtomicReference<Exception> lastException = new AtomicReference<Exception>();\n                    for (final String name : response.phase1FileNames) {\n                        recoverySettings.concurrentStreamPool().execute(new Runnable() {\n                            @Override\n                            public void run() {\n                                IndexInput indexInput = null;\n                                try {\n                                    final int BUFFER_SIZE = (int) recoverySettings.fileChunkSize().bytes();\n                                    byte[] buf = new byte[BUFFER_SIZE];\n                                    StoreFileMetaData md = shard.store().metaData(name);\n                                    // TODO: maybe use IOContext.READONCE?\n                                    indexInput = shard.store().openInputRaw(name, IOContext.READ);\n                                    boolean shouldCompressRequest = recoverySettings.compress();\n                                    if (CompressorFactory.isCompressed(indexInput)) {\n                                        shouldCompressRequest = false;\n                                    }\n\n                                    long len = indexInput.length();\n                                    long readCount = 0;\n                                    while (readCount < len) {\n                                        if (shard.state() == IndexShardState.CLOSED) { // check if the shard got closed on us\n                                            throw new IndexShardClosedException(shard.shardId());\n                                        }\n                                        int toRead = readCount + BUFFER_SIZE > len ? (int) (len - readCount) : BUFFER_SIZE;\n                                        long position = indexInput.getFilePointer();\n\n                                        if (recoverySettings.rateLimiter() != null) {\n                                            recoverySettings.rateLimiter().pause(toRead);\n                                        }\n\n                                        indexInput.readBytes(buf, 0, toRead, false);\n                                        BytesArray content = new BytesArray(buf, 0, toRead);\n                                        transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FILE_CHUNK, new RecoveryFileChunkRequest(request.recoveryId(), request.shardId(), name, position, len, md.checksum(), content),\n                                                TransportRequestOptions.options().withCompress(shouldCompressRequest).withLowType().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                                        readCount += toRead;\n                                    }\n                                } catch (Exception e) {\n                                    lastException.set(e);\n                                } finally {\n                                    if (indexInput != null) {\n                                        try {\n                                            indexInput.close();\n                                        } catch (IOException e) {\n                                            // ignore\n                                        }\n                                    }\n                                    latch.countDown();\n                                }\n                            }\n                        });\n                    }\n\n                    latch.await();\n\n                    if (lastException.get() != null) {\n                        throw lastException.get();\n                    }\n\n                    // now, set the clean files request\n                    Set<String> snapshotFiles = Sets.newHashSet(snapshot.getFiles());\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.CLEAN_FILES, new RecoveryCleanFilesRequest(request.recoveryId(), shard.shardId(), snapshotFiles), TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n\n                    stopWatch.stop();\n                    logger.trace(\"[{}][{}] recovery [phase1] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                    response.phase1Time = stopWatch.totalTime().millis();\n                } catch (Throwable e) {\n                    throw new RecoverFilesRecoveryException(request.shardId(), response.phase1FileNames.size(), new ByteSizeValue(totalSize), e);\n                }\n            }\n\n            @Override\n            public void phase2(Translog.Snapshot snapshot) throws ElasticSearchException {\n                if (shard.state() == IndexShardState.CLOSED) {\n                    throw new IndexShardClosedException(request.shardId());\n                }\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: start\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                StopWatch stopWatch = new StopWatch().start();\n                transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.PREPARE_TRANSLOG, new RecoveryPrepareForTranslogOperationsRequest(request.recoveryId(), request.shardId()), TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                stopWatch.stop();\n                response.startTime = stopWatch.totalTime().millis();\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: start took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: sending transaction log operations\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                stopWatch = new StopWatch().start();\n                int totalOperations = sendSnapshot(snapshot);\n                stopWatch.stop();\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                response.phase2Time = stopWatch.totalTime().millis();\n                response.phase2Operations = totalOperations;\n            }\n\n            @Override\n            public void phase3(Translog.Snapshot snapshot) throws ElasticSearchException {\n                if (shard.state() == IndexShardState.CLOSED) {\n                    throw new IndexShardClosedException(request.shardId());\n                }\n                logger.trace(\"[{}][{}] recovery [phase3] to {}: sending transaction log operations\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                StopWatch stopWatch = new StopWatch().start();\n                int totalOperations = sendSnapshot(snapshot);\n                transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FINALIZE, new RecoveryFinalizeRecoveryRequest(request.recoveryId(), request.shardId()), TransportRequestOptions.options().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                if (request.markAsRelocated()) {\n                    // TODO what happens if the recovery process fails afterwards, we need to mark this back to started\n                    try {\n                        shard.relocated(\"to \" + request.targetNode());\n                    } catch (IllegalIndexShardStateException e) {\n                        // we can ignore this exception since, on the other node, when it moved to phase3\n                        // it will also send shard started, which might cause the index shard we work against\n                        // to move be closed by the time we get to the the relocated method\n                    }\n                }\n                stopWatch.stop();\n                logger.trace(\"[{}][{}] recovery [phase3] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                response.phase3Time = stopWatch.totalTime().millis();\n                response.phase3Operations = totalOperations;\n            }\n\n            private int sendSnapshot(Translog.Snapshot snapshot) throws ElasticSearchException {\n                int ops = 0;\n                long size = 0;\n                int totalOperations = 0;\n                List<Translog.Operation> operations = Lists.newArrayList();\n                while (snapshot.hasNext()) {\n                    if (shard.state() == IndexShardState.CLOSED) {\n                        throw new IndexShardClosedException(request.shardId());\n                    }\n                    Translog.Operation operation = snapshot.next();\n                    operations.add(operation);\n                    ops += 1;\n                    size += operation.estimateSize();\n                    totalOperations++;\n                    if (ops >= recoverySettings.translogOps() || size >= recoverySettings.translogSize().bytes()) {\n\n                        if (recoverySettings.rateLimiter() != null) {\n                            recoverySettings.rateLimiter().pause(size);\n                        }\n\n                        RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest(request.recoveryId(), request.shardId(), operations);\n                        transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.TRANSLOG_OPS, translogOperationsRequest, TransportRequestOptions.options().withCompress(recoverySettings.compress()).withLowType().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                        ops = 0;\n                        size = 0;\n                        operations.clear();\n                    }\n                }\n                // send the leftover\n                if (!operations.isEmpty()) {\n                    RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest(request.recoveryId(), request.shardId(), operations);\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.TRANSLOG_OPS, translogOperationsRequest, TransportRequestOptions.options().withCompress(recoverySettings.compress()).withLowType().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                }\n                return totalOperations;\n            }\n        });\n        return response;\n    }","id":37840,"modified_method":"private RecoveryResponse recover(final StartRecoveryRequest request) {\n        final InternalIndexShard shard = (InternalIndexShard) indicesService.indexServiceSafe(request.shardId().index().name()).shardSafe(request.shardId().id());\n\n        // verify that our (the source) shard state is marking the shard to be in recovery mode as well, otherwise\n        // the index operations will not be routed to it properly\n        RoutingNode node = clusterService.state().readOnlyRoutingNodes().node(request.targetNode().id());\n        if (node == null) {\n            throw new DelayRecoveryException(\"source node does not have the node [\" + request.targetNode() + \"] in its state yet..\");\n        }\n        ShardRouting targetShardRouting = null;\n        for (ShardRouting shardRouting : node) {\n            if (shardRouting.shardId().equals(request.shardId())) {\n                targetShardRouting = shardRouting;\n                break;\n            }\n        }\n        if (targetShardRouting == null) {\n            throw new DelayRecoveryException(\"source node does not have the shard listed in its state as allocated on the node\");\n        }\n        if (!targetShardRouting.initializing()) {\n            throw new DelayRecoveryException(\"source node has the state of the target shard to be [\" + targetShardRouting.state() + \"], expecting to be [initializing]\");\n        }\n\n        logger.trace(\"[{}][{}] starting recovery to {}, mark_as_relocated {}\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), request.markAsRelocated());\n        final RecoveryResponse response = new RecoveryResponse();\n        shard.recover(new Engine.RecoveryHandler() {\n            @Override\n            public void phase1(final SnapshotIndexCommit snapshot) throws ElasticSearchException {\n                long totalSize = 0;\n                long existingTotalSize = 0;\n                try {\n                    StopWatch stopWatch = new StopWatch().start();\n\n                    for (String name : snapshot.getFiles()) {\n                        StoreFileMetaData md = shard.store().metaData(name);\n                        boolean useExisting = false;\n                        if (request.existingFiles().containsKey(name)) {\n                            // we don't compute checksum for segments, so always recover them\n                            if (!name.startsWith(\"segments\") && md.isSame(request.existingFiles().get(name))) {\n                                response.phase1ExistingFileNames.add(name);\n                                response.phase1ExistingFileSizes.add(md.length());\n                                existingTotalSize += md.length();\n                                useExisting = true;\n                                if (logger.isTraceEnabled()) {\n                                    logger.trace(\"[{}][{}] recovery [phase1] to {}: not recovering [{}], exists in local store and has checksum [{}], size [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name, md.checksum(), md.length());\n                                }\n                            }\n                        }\n                        if (!useExisting) {\n                            if (request.existingFiles().containsKey(name)) {\n                                logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering [{}], exists in local store, but is different: remote [{}], local [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name, request.existingFiles().get(name), md);\n                            } else {\n                                logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering [{}], does not exists in remote\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), name);\n                            }\n                            response.phase1FileNames.add(name);\n                            response.phase1FileSizes.add(md.length());\n                        }\n                        totalSize += md.length();\n                    }\n                    response.phase1TotalSize = totalSize;\n                    response.phase1ExistingTotalSize = existingTotalSize;\n\n                    logger.trace(\"[{}][{}] recovery [phase1] to {}: recovering_files [{}] with total_size [{}], reusing_files [{}] with total_size [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), response.phase1FileNames.size(), new ByteSizeValue(totalSize), response.phase1ExistingFileNames.size(), new ByteSizeValue(existingTotalSize));\n\n                    RecoveryFilesInfoRequest recoveryInfoFilesRequest = new RecoveryFilesInfoRequest(request.recoveryId(), request.shardId(), response.phase1FileNames, response.phase1FileSizes,\n                            response.phase1ExistingFileNames, response.phase1ExistingFileSizes, response.phase1TotalSize, response.phase1ExistingTotalSize);\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FILES_INFO, recoveryInfoFilesRequest, TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n\n                    final CountDownLatch latch = new CountDownLatch(response.phase1FileNames.size());\n                    final AtomicReference<Exception> lastException = new AtomicReference<Exception>();\n                    for (final String name : response.phase1FileNames) {\n                        recoverySettings.concurrentStreamPool().execute(new Runnable() {\n                            @Override\n                            public void run() {\n                                IndexInput indexInput = null;\n                                try {\n                                    final int BUFFER_SIZE = (int) recoverySettings.fileChunkSize().bytes();\n                                    byte[] buf = new byte[BUFFER_SIZE];\n                                    StoreFileMetaData md = shard.store().metaData(name);\n                                    // TODO: maybe use IOContext.READONCE?\n                                    indexInput = shard.store().openInputRaw(name, IOContext.READ);\n                                    boolean shouldCompressRequest = recoverySettings.compress();\n                                    if (CompressorFactory.isCompressed(indexInput)) {\n                                        shouldCompressRequest = false;\n                                    }\n\n                                    long len = indexInput.length();\n                                    long readCount = 0;\n                                    while (readCount < len) {\n                                        if (shard.state() == IndexShardState.CLOSED) { // check if the shard got closed on us\n                                            throw new IndexShardClosedException(shard.shardId());\n                                        }\n                                        int toRead = readCount + BUFFER_SIZE > len ? (int) (len - readCount) : BUFFER_SIZE;\n                                        long position = indexInput.getFilePointer();\n\n                                        if (recoverySettings.rateLimiter() != null) {\n                                            recoverySettings.rateLimiter().pause(toRead);\n                                        }\n\n                                        indexInput.readBytes(buf, 0, toRead, false);\n                                        BytesArray content = new BytesArray(buf, 0, toRead);\n                                        transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FILE_CHUNK, new RecoveryFileChunkRequest(request.recoveryId(), request.shardId(), name, position, len, md.checksum(), content),\n                                                TransportRequestOptions.options().withCompress(shouldCompressRequest).withLowType().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                                        readCount += toRead;\n                                    }\n                                } catch (Exception e) {\n                                    lastException.set(e);\n                                } finally {\n                                    if (indexInput != null) {\n                                        try {\n                                            indexInput.close();\n                                        } catch (IOException e) {\n                                            // ignore\n                                        }\n                                    }\n                                    latch.countDown();\n                                }\n                            }\n                        });\n                    }\n\n                    latch.await();\n\n                    if (lastException.get() != null) {\n                        throw lastException.get();\n                    }\n\n                    // now, set the clean files request\n                    Set<String> snapshotFiles = Sets.newHashSet(snapshot.getFiles());\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.CLEAN_FILES, new RecoveryCleanFilesRequest(request.recoveryId(), shard.shardId(), snapshotFiles), TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n\n                    stopWatch.stop();\n                    logger.trace(\"[{}][{}] recovery [phase1] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                    response.phase1Time = stopWatch.totalTime().millis();\n                } catch (Throwable e) {\n                    throw new RecoverFilesRecoveryException(request.shardId(), response.phase1FileNames.size(), new ByteSizeValue(totalSize), e);\n                }\n            }\n\n            @Override\n            public void phase2(Translog.Snapshot snapshot) throws ElasticSearchException {\n                if (shard.state() == IndexShardState.CLOSED) {\n                    throw new IndexShardClosedException(request.shardId());\n                }\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: start\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                StopWatch stopWatch = new StopWatch().start();\n                transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.PREPARE_TRANSLOG, new RecoveryPrepareForTranslogOperationsRequest(request.recoveryId(), request.shardId()), TransportRequestOptions.options().withTimeout(internalActionTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                stopWatch.stop();\n                response.startTime = stopWatch.totalTime().millis();\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: start took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: sending transaction log operations\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                stopWatch = new StopWatch().start();\n                int totalOperations = sendSnapshot(snapshot);\n                stopWatch.stop();\n                logger.trace(\"[{}][{}] recovery [phase2] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                response.phase2Time = stopWatch.totalTime().millis();\n                response.phase2Operations = totalOperations;\n            }\n\n            @Override\n            public void phase3(Translog.Snapshot snapshot) throws ElasticSearchException {\n                if (shard.state() == IndexShardState.CLOSED) {\n                    throw new IndexShardClosedException(request.shardId());\n                }\n                logger.trace(\"[{}][{}] recovery [phase3] to {}: sending transaction log operations\", request.shardId().index().name(), request.shardId().id(), request.targetNode());\n                StopWatch stopWatch = new StopWatch().start();\n                int totalOperations = sendSnapshot(snapshot);\n                transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.FINALIZE, new RecoveryFinalizeRecoveryRequest(request.recoveryId(), request.shardId()), TransportRequestOptions.options().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                if (request.markAsRelocated()) {\n                    // TODO what happens if the recovery process fails afterwards, we need to mark this back to started\n                    try {\n                        shard.relocated(\"to \" + request.targetNode());\n                    } catch (IllegalIndexShardStateException e) {\n                        // we can ignore this exception since, on the other node, when it moved to phase3\n                        // it will also send shard started, which might cause the index shard we work against\n                        // to move be closed by the time we get to the the relocated method\n                    }\n                }\n                stopWatch.stop();\n                logger.trace(\"[{}][{}] recovery [phase3] to {}: took [{}]\", request.shardId().index().name(), request.shardId().id(), request.targetNode(), stopWatch.totalTime());\n                response.phase3Time = stopWatch.totalTime().millis();\n                response.phase3Operations = totalOperations;\n            }\n\n            private int sendSnapshot(Translog.Snapshot snapshot) throws ElasticSearchException {\n                int ops = 0;\n                long size = 0;\n                int totalOperations = 0;\n                List<Translog.Operation> operations = Lists.newArrayList();\n                while (snapshot.hasNext()) {\n                    if (shard.state() == IndexShardState.CLOSED) {\n                        throw new IndexShardClosedException(request.shardId());\n                    }\n                    Translog.Operation operation = snapshot.next();\n                    operations.add(operation);\n                    ops += 1;\n                    size += operation.estimateSize();\n                    totalOperations++;\n                    if (ops >= recoverySettings.translogOps() || size >= recoverySettings.translogSize().bytes()) {\n\n                        if (recoverySettings.rateLimiter() != null) {\n                            recoverySettings.rateLimiter().pause(size);\n                        }\n\n                        RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest(request.recoveryId(), request.shardId(), operations);\n                        transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.TRANSLOG_OPS, translogOperationsRequest, TransportRequestOptions.options().withCompress(recoverySettings.compress()).withLowType().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                        ops = 0;\n                        size = 0;\n                        operations.clear();\n                    }\n                }\n                // send the leftover\n                if (!operations.isEmpty()) {\n                    RecoveryTranslogOperationsRequest translogOperationsRequest = new RecoveryTranslogOperationsRequest(request.recoveryId(), request.shardId(), operations);\n                    transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.TRANSLOG_OPS, translogOperationsRequest, TransportRequestOptions.options().withCompress(recoverySettings.compress()).withLowType().withTimeout(internalActionLongTimeout), EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                }\n                return totalOperations;\n            }\n        });\n        return response;\n    }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private void doRecovery(final StartRecoveryRequest request, final RecoveryStatus recoveryStatus, final RecoveryListener listener) {\n        if (request.sourceNode() == null) {\n            listener.onIgnoreRecovery(false, \"No node to recover from, retry on next cluster state update\");\n            return;\n        }\n        final InternalIndexShard shard = recoveryStatus.indexShard;\n        if (shard == null) {\n            listener.onIgnoreRecovery(false, \"shard missing locally, stop recovery\");\n            return;\n        }\n        if (shard.state() == IndexShardState.CLOSED) {\n            listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n            return;\n        }\n        if (recoveryStatus.canceled) {\n            // don't remove it, the cancellation code will remove it...\n            listener.onIgnoreRecovery(false, \"canceled recovery\");\n            return;\n        }\n\n        recoveryStatus.recoveryThread = Thread.currentThread();\n\n        try {\n            logger.trace(\"[{}][{}] starting recovery from {}\", request.shardId().index().name(), request.shardId().id(), request.sourceNode());\n\n            StopWatch stopWatch = new StopWatch().start();\n            RecoveryResponse recoveryResponse = transportService.submitRequest(request.sourceNode(), RecoverySource.Actions.START_RECOVERY, request, new FutureTransportResponseHandler<RecoveryResponse>() {\n                @Override\n                public RecoveryResponse newInstance() {\n                    return new RecoveryResponse();\n                }\n            }).txGet();\n            if (shard.state() == IndexShardState.CLOSED) {\n                removeAndCleanOnGoingRecovery(recoveryStatus);\n                listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n                return;\n            }\n            stopWatch.stop();\n            if (logger.isDebugEnabled()) {\n                StringBuilder sb = new StringBuilder();\n                sb.append('[').append(request.shardId().index().name()).append(']').append('[').append(request.shardId().id()).append(\"] \");\n                sb.append(\"recovery completed from \").append(request.sourceNode()).append(\", took[\").append(stopWatch.totalTime()).append(\"]\\n\");\n                sb.append(\"   phase1: recovered_files [\").append(recoveryResponse.phase1FileNames.size()).append(\"]\").append(\" with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1TotalSize)).append(\"]\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase1Time)).append(\"], throttling_wait [\").append(timeValueMillis(recoveryResponse.phase1ThrottlingWaitTime)).append(']')\n                        .append(\"\\n\");\n                sb.append(\"         : reusing_files   [\").append(recoveryResponse.phase1ExistingFileNames.size()).append(\"] with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1ExistingTotalSize)).append(\"]\\n\");\n                sb.append(\"   phase2: start took [\").append(timeValueMillis(recoveryResponse.startTime)).append(\"]\\n\");\n                sb.append(\"         : recovered [\").append(recoveryResponse.phase2Operations).append(\"]\").append(\" transaction log operations\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase2Time)).append(\"]\")\n                        .append(\"\\n\");\n                sb.append(\"   phase3: recovered [\").append(recoveryResponse.phase3Operations).append(\"]\").append(\" transaction log operations\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase3Time)).append(\"]\");\n                logger.debug(sb.toString());\n            }\n            removeAndCleanOnGoingRecovery(recoveryStatus);\n            listener.onRecoveryDone();\n        } catch (Exception e) {\n//            logger.trace(\"[{}][{}] Got exception on recovery\", e, request.shardId().index().name(), request.shardId().id());\n            if (recoveryStatus.canceled) {\n                // don't remove it, the cancellation code will remove it...\n                listener.onIgnoreRecovery(false, \"canceled recovery\");\n                return;\n            }\n            if (shard.state() == IndexShardState.CLOSED) {\n                removeAndCleanOnGoingRecovery(recoveryStatus);\n                listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n                return;\n            }\n            Throwable cause = ExceptionsHelper.unwrapCause(e);\n            if (cause instanceof RecoveryEngineException) {\n                // unwrap an exception that was thrown as part of the recovery\n                cause = cause.getCause();\n            }\n            // do it twice, in case we have double transport exception\n            cause = ExceptionsHelper.unwrapCause(cause);\n            if (cause instanceof RecoveryEngineException) {\n                // unwrap an exception that was thrown as part of the recovery\n                cause = cause.getCause();\n            }\n\n            // here, we would add checks against exception that need to be retried (and not removeAndClean in this case)\n\n            if (cause instanceof IndexShardNotStartedException || cause instanceof IndexMissingException || cause instanceof IndexShardMissingException) {\n                // if the target is not ready yet, retry\n                listener.onRetryRecovery(TimeValue.timeValueMillis(500), recoveryStatus);\n                return;\n            }\n\n            // here, we check against ignore recovery options\n\n            // in general, no need to clean the shard on ignored recovery, since we want to try and reuse it later\n            // it will get deleted in the IndicesStore if all are allocated and no shard exists on this node...\n\n            removeAndCleanOnGoingRecovery(recoveryStatus);\n\n            if (cause instanceof ConnectTransportException) {\n                listener.onIgnoreRecovery(true, \"source node disconnected (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            if (cause instanceof IndexShardClosedException) {\n                listener.onIgnoreRecovery(true, \"source shard is closed (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            if (cause instanceof AlreadyClosedException) {\n                listener.onIgnoreRecovery(true, \"source shard is closed (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            logger.trace(\"[{}][{}] recovery from [{}] failed\", e, request.shardId().index().name(), request.shardId().id(), request.sourceNode());\n            listener.onRecoveryFailure(new RecoveryFailedException(request, e), true);\n        }\n    }","id":37841,"modified_method":"private void doRecovery(final StartRecoveryRequest request, final RecoveryStatus recoveryStatus, final RecoveryListener listener) {\n        if (request.sourceNode() == null) {\n            listener.onIgnoreRecovery(false, \"No node to recover from, retry on next cluster state update\");\n            return;\n        }\n        final InternalIndexShard shard = recoveryStatus.indexShard;\n        if (shard == null) {\n            listener.onIgnoreRecovery(false, \"shard missing locally, stop recovery\");\n            return;\n        }\n        if (shard.state() == IndexShardState.CLOSED) {\n            listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n            return;\n        }\n        if (recoveryStatus.canceled) {\n            // don't remove it, the cancellation code will remove it...\n            listener.onIgnoreRecovery(false, \"canceled recovery\");\n            return;\n        }\n\n        recoveryStatus.recoveryThread = Thread.currentThread();\n\n        try {\n            logger.trace(\"[{}][{}] starting recovery from {}\", request.shardId().index().name(), request.shardId().id(), request.sourceNode());\n\n            StopWatch stopWatch = new StopWatch().start();\n            RecoveryResponse recoveryResponse = transportService.submitRequest(request.sourceNode(), RecoverySource.Actions.START_RECOVERY, request, new FutureTransportResponseHandler<RecoveryResponse>() {\n                @Override\n                public RecoveryResponse newInstance() {\n                    return new RecoveryResponse();\n                }\n            }).txGet();\n            if (shard.state() == IndexShardState.CLOSED) {\n                removeAndCleanOnGoingRecovery(recoveryStatus);\n                listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n                return;\n            }\n            stopWatch.stop();\n            if (logger.isDebugEnabled()) {\n                StringBuilder sb = new StringBuilder();\n                sb.append('[').append(request.shardId().index().name()).append(']').append('[').append(request.shardId().id()).append(\"] \");\n                sb.append(\"recovery completed from \").append(request.sourceNode()).append(\", took[\").append(stopWatch.totalTime()).append(\"]\\n\");\n                sb.append(\"   phase1: recovered_files [\").append(recoveryResponse.phase1FileNames.size()).append(\"]\").append(\" with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1TotalSize)).append(\"]\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase1Time)).append(\"], throttling_wait [\").append(timeValueMillis(recoveryResponse.phase1ThrottlingWaitTime)).append(']')\n                        .append(\"\\n\");\n                sb.append(\"         : reusing_files   [\").append(recoveryResponse.phase1ExistingFileNames.size()).append(\"] with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1ExistingTotalSize)).append(\"]\\n\");\n                sb.append(\"   phase2: start took [\").append(timeValueMillis(recoveryResponse.startTime)).append(\"]\\n\");\n                sb.append(\"         : recovered [\").append(recoveryResponse.phase2Operations).append(\"]\").append(\" transaction log operations\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase2Time)).append(\"]\")\n                        .append(\"\\n\");\n                sb.append(\"   phase3: recovered [\").append(recoveryResponse.phase3Operations).append(\"]\").append(\" transaction log operations\")\n                        .append(\", took [\").append(timeValueMillis(recoveryResponse.phase3Time)).append(\"]\");\n                logger.debug(sb.toString());\n            }\n            removeAndCleanOnGoingRecovery(recoveryStatus);\n            listener.onRecoveryDone();\n        } catch (Exception e) {\n//            logger.trace(\"[{}][{}] Got exception on recovery\", e, request.shardId().index().name(), request.shardId().id());\n            if (recoveryStatus.canceled) {\n                // don't remove it, the cancellation code will remove it...\n                listener.onIgnoreRecovery(false, \"canceled recovery\");\n                return;\n            }\n            if (shard.state() == IndexShardState.CLOSED) {\n                removeAndCleanOnGoingRecovery(recoveryStatus);\n                listener.onIgnoreRecovery(false, \"local shard closed, stop recovery\");\n                return;\n            }\n            Throwable cause = ExceptionsHelper.unwrapCause(e);\n            if (cause instanceof RecoveryEngineException) {\n                // unwrap an exception that was thrown as part of the recovery\n                cause = cause.getCause();\n            }\n            // do it twice, in case we have double transport exception\n            cause = ExceptionsHelper.unwrapCause(cause);\n            if (cause instanceof RecoveryEngineException) {\n                // unwrap an exception that was thrown as part of the recovery\n                cause = cause.getCause();\n            }\n\n            // here, we would add checks against exception that need to be retried (and not removeAndClean in this case)\n\n            if (cause instanceof IndexShardNotStartedException || cause instanceof IndexMissingException || cause instanceof IndexShardMissingException) {\n                // if the target is not ready yet, retry\n                listener.onRetryRecovery(TimeValue.timeValueMillis(500), recoveryStatus);\n                return;\n            }\n\n            if (cause instanceof DelayRecoveryException) {\n                listener.onRetryRecovery(TimeValue.timeValueMillis(500), recoveryStatus);\n                return;\n            }\n\n            // here, we check against ignore recovery options\n\n            // in general, no need to clean the shard on ignored recovery, since we want to try and reuse it later\n            // it will get deleted in the IndicesStore if all are allocated and no shard exists on this node...\n\n            removeAndCleanOnGoingRecovery(recoveryStatus);\n\n            if (cause instanceof ConnectTransportException) {\n                listener.onIgnoreRecovery(true, \"source node disconnected (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            if (cause instanceof IndexShardClosedException) {\n                listener.onIgnoreRecovery(true, \"source shard is closed (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            if (cause instanceof AlreadyClosedException) {\n                listener.onIgnoreRecovery(true, \"source shard is closed (\" + request.sourceNode() + \")\");\n                return;\n            }\n\n            logger.trace(\"[{}][{}] recovery from [{}] failed\", e, request.shardId().index().name(), request.shardId().id(), request.sourceNode());\n            listener.onRecoveryFailure(new RecoveryFailedException(request, e), true);\n        }\n    }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"void performOnReplica(final PrimaryResponse<Response, ReplicaRequest> response, final AtomicInteger counter, final ShardRouting shard, String nodeId) {\n            // if we don't have that node, it means that it might have failed and will be created again, in\n            // this case, we don't have to do the operation, and just let it failover\n            if (!nodes.nodeExists(nodeId)) {\n                if (counter.decrementAndGet() == 0) {\n                    listener.onResponse(response.response());\n                }\n                return;\n            }\n\n            final ReplicaOperationRequest shardRequest = new ReplicaOperationRequest(shardIt.shardId().id(), response.replicaRequest());\n            if (!nodeId.equals(nodes.localNodeId())) {\n                DiscoveryNode node = nodes.get(nodeId);\n                transportService.sendRequest(node, transportReplicaAction, shardRequest, transportOptions, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {\n                    @Override\n                    public void handleResponse(TransportResponse.Empty vResponse) {\n                        finishIfPossible();\n                    }\n\n                    @Override\n                    public void handleException(TransportException exp) {\n                        if (!ignoreReplicaException(exp.unwrapCause())) {\n                            logger.warn(\"Failed to perform \" + transportAction + \" on replica \" + shardIt.shardId(), exp);\n                            shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(exp) + \"]\");\n                        }\n                        finishIfPossible();\n                    }\n\n                    private void finishIfPossible() {\n                        if (counter.decrementAndGet() == 0) {\n                            listener.onResponse(response.response());\n                        }\n                    }\n                });\n            } else {\n                if (request.operationThreaded()) {\n                    request.beforeLocalFork();\n                    threadPool.executor(executor).execute(new Runnable() {\n                        @Override\n                        public void run() {\n                            try {\n                                shardOperationOnReplica(shardRequest);\n                            } catch (Exception e) {\n                                if (!ignoreReplicaException(e)) {\n                                    logger.warn(\"Failed to perform \" + transportAction + \" on replica \" + shardIt.shardId(), e);\n                                    shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(e) + \"]\");\n                                }\n                            }\n                            if (counter.decrementAndGet() == 0) {\n                                listener.onResponse(response.response());\n                            }\n                        }\n                    });\n                } else {\n                    try {\n                        shardOperationOnReplica(shardRequest);\n                    } catch (Exception e) {\n                        if (!ignoreReplicaException(e)) {\n                            logger.warn(\"Failed to perform \" + transportAction + \" on replica\" + shardIt.shardId(), e);\n                            shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(e) + \"]\");\n                        }\n                    }\n                    if (counter.decrementAndGet() == 0) {\n                        listener.onResponse(response.response());\n                    }\n                }\n            }\n        }","id":37842,"modified_method":"void performOnReplica(final PrimaryResponse<Response, ReplicaRequest> response, final AtomicInteger counter, final ShardRouting shard, String nodeId) {\n            // if we don't have that node, it means that it might have failed and will be created again, in\n            // this case, we don't have to do the operation, and just let it failover\n            if (!clusterState.nodes().nodeExists(nodeId)) {\n                if (counter.decrementAndGet() == 0) {\n                    listener.onResponse(response.response());\n                }\n                return;\n            }\n\n            final ReplicaOperationRequest shardRequest = new ReplicaOperationRequest(shardIt.shardId().id(), response.replicaRequest());\n            if (!nodeId.equals(clusterState.nodes().localNodeId())) {\n                DiscoveryNode node = clusterState.nodes().get(nodeId);\n                transportService.sendRequest(node, transportReplicaAction, shardRequest, transportOptions, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {\n                    @Override\n                    public void handleResponse(TransportResponse.Empty vResponse) {\n                        finishIfPossible();\n                    }\n\n                    @Override\n                    public void handleException(TransportException exp) {\n                        if (!ignoreReplicaException(exp.unwrapCause())) {\n                            logger.warn(\"Failed to perform \" + transportAction + \" on replica \" + shardIt.shardId(), exp);\n                            shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(exp) + \"]\");\n                        }\n                        finishIfPossible();\n                    }\n\n                    private void finishIfPossible() {\n                        if (counter.decrementAndGet() == 0) {\n                            listener.onResponse(response.response());\n                        }\n                    }\n                });\n            } else {\n                if (request.operationThreaded()) {\n                    request.beforeLocalFork();\n                    threadPool.executor(executor).execute(new Runnable() {\n                        @Override\n                        public void run() {\n                            try {\n                                shardOperationOnReplica(shardRequest);\n                            } catch (Exception e) {\n                                if (!ignoreReplicaException(e)) {\n                                    logger.warn(\"Failed to perform \" + transportAction + \" on replica \" + shardIt.shardId(), e);\n                                    shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(e) + \"]\");\n                                }\n                            }\n                            if (counter.decrementAndGet() == 0) {\n                                listener.onResponse(response.response());\n                            }\n                        }\n                    });\n                } else {\n                    try {\n                        shardOperationOnReplica(shardRequest);\n                    } catch (Exception e) {\n                        if (!ignoreReplicaException(e)) {\n                            logger.warn(\"Failed to perform \" + transportAction + \" on replica\" + shardIt.shardId(), e);\n                            shardStateAction.shardFailed(shard, \"Failed to perform [\" + transportAction + \"] on replica, message [\" + detailedMessage(e) + \"]\");\n                        }\n                    }\n                    if (counter.decrementAndGet() == 0) {\n                        listener.onResponse(response.response());\n                    }\n                }\n            }\n        }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"void retry(boolean fromClusterEvent, @Nullable final Throwable failure) {\n            if (!fromClusterEvent) {\n                // make it threaded operation so we fork on the discovery listener thread\n                request.beforeLocalFork();\n                request.operationThreaded(true);\n                clusterService.add(request.timeout(), new TimeoutClusterStateListener() {\n                    @Override\n                    public void postAdded() {\n                        if (start(true)) {\n                            // if we managed to start and perform the operation on the primary, we can remove this listener\n                            clusterService.remove(this);\n                        }\n                    }\n\n                    @Override\n                    public void onClose() {\n                        clusterService.remove(this);\n                        listener.onFailure(new NodeClosedException(nodes.localNode()));\n                    }\n\n                    @Override\n                    public void clusterChanged(ClusterChangedEvent event) {\n                        if (start(true)) {\n                            // if we managed to start and perform the operation on the primary, we can remove this listener\n                            clusterService.remove(this);\n                        }\n                    }\n\n                    @Override\n                    public void onTimeout(TimeValue timeValue) {\n                        // just to be on the safe side, see if we can start it now?\n                        if (start(true)) {\n                            clusterService.remove(this);\n                            return;\n                        }\n                        clusterService.remove(this);\n                        Throwable listenerFailure = failure;\n                        if (listenerFailure == null) {\n                            if (shardIt == null) {\n                                listenerFailure = new UnavailableShardsException(null, \"no available shards: Timeout waiting for [\" + timeValue + \"], request: \" + request.toString());\n                            } else {\n                                listenerFailure = new UnavailableShardsException(shardIt.shardId(), \"[\" + shardIt.size() + \"] shardIt, [\" + shardIt.sizeActive() + \"] active : Timeout waiting for [\" + timeValue + \"], request: \" + request.toString());\n                            }\n                        }\n                        listener.onFailure(listenerFailure);\n                    }\n                });\n            }\n        }","id":37843,"modified_method":"void retry(boolean fromClusterEvent, @Nullable final Throwable failure) {\n            if (!fromClusterEvent) {\n                // make it threaded operation so we fork on the discovery listener thread\n                request.beforeLocalFork();\n                request.operationThreaded(true);\n                clusterService.add(request.timeout(), new TimeoutClusterStateListener() {\n                    @Override\n                    public void postAdded() {\n                        if (start(true)) {\n                            // if we managed to start and perform the operation on the primary, we can remove this listener\n                            clusterService.remove(this);\n                        }\n                    }\n\n                    @Override\n                    public void onClose() {\n                        clusterService.remove(this);\n                        listener.onFailure(new NodeClosedException(clusterState.nodes().localNode()));\n                    }\n\n                    @Override\n                    public void clusterChanged(ClusterChangedEvent event) {\n                        if (start(true)) {\n                            // if we managed to start and perform the operation on the primary, we can remove this listener\n                            clusterService.remove(this);\n                        }\n                    }\n\n                    @Override\n                    public void onTimeout(TimeValue timeValue) {\n                        // just to be on the safe side, see if we can start it now?\n                        if (start(true)) {\n                            clusterService.remove(this);\n                            return;\n                        }\n                        clusterService.remove(this);\n                        Throwable listenerFailure = failure;\n                        if (listenerFailure == null) {\n                            if (shardIt == null) {\n                                listenerFailure = new UnavailableShardsException(null, \"no available shards: Timeout waiting for [\" + timeValue + \"], request: \" + request.toString());\n                            } else {\n                                listenerFailure = new UnavailableShardsException(shardIt.shardId(), \"[\" + shardIt.size() + \"] shardIt, [\" + shardIt.sizeActive() + \"] active : Timeout waiting for [\" + timeValue + \"], request: \" + request.toString());\n                            }\n                        }\n                        listener.onFailure(listenerFailure);\n                    }\n                });\n            }\n        }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n         * Returns <tt>true<\/tt> if the action starting to be performed on the primary (or is done).\n         */\n        public boolean start(final boolean fromClusterEvent) throws ElasticSearchException {\n            final ClusterState clusterState = clusterService.state();\n            nodes = clusterState.nodes();\n            try {\n                ClusterBlockException blockException = checkGlobalBlock(clusterState, request);\n                if (blockException != null) {\n                    if (blockException.retryable()) {\n                        retry(fromClusterEvent, blockException);\n                        return false;\n                    } else {\n                        throw blockException;\n                    }\n                }\n                // check if we need to execute, and if not, return\n                if (!resolveRequest(clusterState, request, listener)) {\n                    return true;\n                }\n                blockException = checkRequestBlock(clusterState, request);\n                if (blockException != null) {\n                    if (blockException.retryable()) {\n                        retry(fromClusterEvent, blockException);\n                        return false;\n                    } else {\n                        throw blockException;\n                    }\n                }\n                shardIt = shards(clusterState, request);\n            } catch (Exception e) {\n                listener.onFailure(e);\n                return true;\n            }\n\n            // no shardIt, might be in the case between index gateway recovery and shardIt initialization\n            if (shardIt.size() == 0) {\n                retry(fromClusterEvent, null);\n                return false;\n            }\n\n            boolean foundPrimary = false;\n            ShardRouting shardX;\n            while ((shardX = shardIt.nextOrNull()) != null) {\n                final ShardRouting shard = shardX;\n                // we only deal with primary shardIt here...\n                if (!shard.primary()) {\n                    continue;\n                }\n                if (!shard.active() || !nodes.nodeExists(shard.currentNodeId())) {\n                    retry(fromClusterEvent, null);\n                    return false;\n                }\n\n                // check here for consistency\n                if (checkWriteConsistency) {\n                    WriteConsistencyLevel consistencyLevel = defaultWriteConsistencyLevel;\n                    if (request.consistencyLevel() != WriteConsistencyLevel.DEFAULT) {\n                        consistencyLevel = request.consistencyLevel();\n                    }\n                    int requiredNumber = 1;\n                    if (consistencyLevel == WriteConsistencyLevel.QUORUM && shardIt.size() > 2) {\n                        // only for more than 2 in the number of shardIt it makes sense, otherwise its 1 shard with 1 replica, quorum is 1 (which is what it is initialized to)\n                        requiredNumber = (shardIt.size() / 2) + 1;\n                    } else if (consistencyLevel == WriteConsistencyLevel.ALL) {\n                        requiredNumber = shardIt.size();\n                    }\n\n                    if (shardIt.sizeActive() < requiredNumber) {\n                        retry(fromClusterEvent, null);\n                        return false;\n                    }\n                }\n\n                if (!primaryOperationStarted.compareAndSet(false, true)) {\n                    return true;\n                }\n\n                foundPrimary = true;\n                if (shard.currentNodeId().equals(nodes.localNodeId())) {\n                    if (request.operationThreaded()) {\n                        request.beforeLocalFork();\n                        threadPool.executor(executor).execute(new Runnable() {\n                            @Override\n                            public void run() {\n                                performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n                            }\n                        });\n                    } else {\n                        performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n                    }\n                } else {\n                    DiscoveryNode node = nodes.get(shard.currentNodeId());\n                    transportService.sendRequest(node, transportAction, request, transportOptions, new BaseTransportResponseHandler<Response>() {\n\n                        @Override\n                        public Response newInstance() {\n                            return newResponseInstance();\n                        }\n\n                        @Override\n                        public String executor() {\n                            return ThreadPool.Names.SAME;\n                        }\n\n                        @Override\n                        public void handleResponse(Response response) {\n                            listener.onResponse(response);\n                        }\n\n                        @Override\n                        public void handleException(TransportException exp) {\n                            // if we got disconnected from the node, or the node / shard is not in the right state (being closed)\n                            if (exp.unwrapCause() instanceof ConnectTransportException || exp.unwrapCause() instanceof NodeClosedException ||\n                                    retryPrimaryException(exp)) {\n                                primaryOperationStarted.set(false);\n                                // we already marked it as started when we executed it (removed the listener) so pass false\n                                // to re-add to the cluster listener\n                                retry(false, null);\n                            } else {\n                                listener.onFailure(exp);\n                            }\n                        }\n                    });\n                }\n                break;\n            }\n            // we should never get here, but here we go\n            if (!foundPrimary) {\n                retry(fromClusterEvent, null);\n                return false;\n            }\n            return true;\n        }","id":37844,"modified_method":"/**\n         * Returns <tt>true<\/tt> if the action starting to be performed on the primary (or is done).\n         */\n        public boolean start(final boolean fromClusterEvent) throws ElasticSearchException {\n            this.clusterState = clusterService.state();\n            try {\n                ClusterBlockException blockException = checkGlobalBlock(clusterState, request);\n                if (blockException != null) {\n                    if (blockException.retryable()) {\n                        retry(fromClusterEvent, blockException);\n                        return false;\n                    } else {\n                        throw blockException;\n                    }\n                }\n                // check if we need to execute, and if not, return\n                if (!resolveRequest(clusterState, request, listener)) {\n                    return true;\n                }\n                blockException = checkRequestBlock(clusterState, request);\n                if (blockException != null) {\n                    if (blockException.retryable()) {\n                        retry(fromClusterEvent, blockException);\n                        return false;\n                    } else {\n                        throw blockException;\n                    }\n                }\n                shardIt = shards(clusterState, request);\n            } catch (Exception e) {\n                listener.onFailure(e);\n                return true;\n            }\n\n            // no shardIt, might be in the case between index gateway recovery and shardIt initialization\n            if (shardIt.size() == 0) {\n                retry(fromClusterEvent, null);\n                return false;\n            }\n\n            boolean foundPrimary = false;\n            ShardRouting shardX;\n            while ((shardX = shardIt.nextOrNull()) != null) {\n                final ShardRouting shard = shardX;\n                // we only deal with primary shardIt here...\n                if (!shard.primary()) {\n                    continue;\n                }\n                if (!shard.active() || !clusterState.nodes().nodeExists(shard.currentNodeId())) {\n                    retry(fromClusterEvent, null);\n                    return false;\n                }\n\n                // check here for consistency\n                if (checkWriteConsistency) {\n                    WriteConsistencyLevel consistencyLevel = defaultWriteConsistencyLevel;\n                    if (request.consistencyLevel() != WriteConsistencyLevel.DEFAULT) {\n                        consistencyLevel = request.consistencyLevel();\n                    }\n                    int requiredNumber = 1;\n                    if (consistencyLevel == WriteConsistencyLevel.QUORUM && shardIt.size() > 2) {\n                        // only for more than 2 in the number of shardIt it makes sense, otherwise its 1 shard with 1 replica, quorum is 1 (which is what it is initialized to)\n                        requiredNumber = (shardIt.size() / 2) + 1;\n                    } else if (consistencyLevel == WriteConsistencyLevel.ALL) {\n                        requiredNumber = shardIt.size();\n                    }\n\n                    if (shardIt.sizeActive() < requiredNumber) {\n                        retry(fromClusterEvent, null);\n                        return false;\n                    }\n                }\n\n                if (!primaryOperationStarted.compareAndSet(false, true)) {\n                    return true;\n                }\n\n                foundPrimary = true;\n                if (shard.currentNodeId().equals(clusterState.nodes().localNodeId())) {\n                    if (request.operationThreaded()) {\n                        request.beforeLocalFork();\n                        threadPool.executor(executor).execute(new Runnable() {\n                            @Override\n                            public void run() {\n                                performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n                            }\n                        });\n                    } else {\n                        performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n                    }\n                } else {\n                    DiscoveryNode node = clusterState.nodes().get(shard.currentNodeId());\n                    transportService.sendRequest(node, transportAction, request, transportOptions, new BaseTransportResponseHandler<Response>() {\n\n                        @Override\n                        public Response newInstance() {\n                            return newResponseInstance();\n                        }\n\n                        @Override\n                        public String executor() {\n                            return ThreadPool.Names.SAME;\n                        }\n\n                        @Override\n                        public void handleResponse(Response response) {\n                            listener.onResponse(response);\n                        }\n\n                        @Override\n                        public void handleException(TransportException exp) {\n                            // if we got disconnected from the node, or the node / shard is not in the right state (being closed)\n                            if (exp.unwrapCause() instanceof ConnectTransportException || exp.unwrapCause() instanceof NodeClosedException ||\n                                    retryPrimaryException(exp)) {\n                                primaryOperationStarted.set(false);\n                                // we already marked it as started when we executed it (removed the listener) so pass false\n                                // to re-add to the cluster listener\n                                retry(false, null);\n                            } else {\n                                listener.onFailure(exp);\n                            }\n                        }\n                    });\n                }\n                break;\n            }\n            // we should never get here, but here we go\n            if (!foundPrimary) {\n                retry(fromClusterEvent, null);\n                return false;\n            }\n            return true;\n        }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"void performReplicas(final PrimaryResponse<Response, ReplicaRequest> response) {\n            if (ignoreReplicas() || shardIt.size() == 1 /* no replicas */) {\n                postPrimaryOperation(request, response);\n                listener.onResponse(response.response());\n                return;\n            }\n\n            // initialize the counter\n            int replicaCounter = shardIt.assignedReplicasIncludingRelocating();\n\n            if (replicaCounter == 0) {\n                postPrimaryOperation(request, response);\n                listener.onResponse(response.response());\n                return;\n            }\n\n            if (replicationType == ReplicationType.ASYNC) {\n                postPrimaryOperation(request, response);\n                // async replication, notify the listener\n                listener.onResponse(response.response());\n                // now, trick the counter so it won't decrease to 0 and notify the listeners\n                replicaCounter = Integer.MIN_VALUE;\n            }\n\n            // we add one to the replica count to do the postPrimaryOperation\n            replicaCounter++;\n\n            AtomicInteger counter = new AtomicInteger(replicaCounter);\n            shardIt.reset(); // reset the iterator\n            ShardRouting shard;\n            while ((shard = shardIt.nextOrNull()) != null) {\n                // if its unassigned, nothing to do here...\n                if (shard.unassigned()) {\n                    continue;\n                }\n\n                // if the shard is primary and relocating, add one to the counter since we perform it on the replica as well\n                // (and we already did it on the primary)\n                boolean doOnlyOnRelocating = false;\n                if (shard.primary()) {\n                    if (shard.relocating()) {\n                        doOnlyOnRelocating = true;\n                    } else {\n                        continue;\n                    }\n                }\n                // we index on a replica that is initializing as well since we might not have got the event\n                // yet that it was started. We will get an exception IllegalShardState exception if its not started\n                // and that's fine, we will ignore it\n                if (!doOnlyOnRelocating) {\n                    performOnReplica(response, counter, shard, shard.currentNodeId());\n                }\n                if (shard.relocating()) {\n                    performOnReplica(response, counter, shard, shard.relocatingNodeId());\n                }\n            }\n\n            // now do the postPrimary operation, and check if the listener needs to be invoked\n            postPrimaryOperation(request, response);\n            // we also invoke here in case replicas finish before postPrimaryAction does\n            if (counter.decrementAndGet() == 0) {\n                listener.onResponse(response.response());\n            }\n        }","id":37845,"modified_method":"void performReplicas(final PrimaryResponse<Response, ReplicaRequest> response) {\n            if (ignoreReplicas() || shardIt.size() == 1 /* no replicas */) {\n                postPrimaryOperation(request, response);\n                listener.onResponse(response.response());\n                return;\n            }\n\n            // we double check on the state, if it got changed we need to make sure we take the latest one cause\n            // maybe a replica shard started its recovery process and we need to apply it there...\n            ClusterState newState = clusterService.state();\n            if (clusterState != newState) {\n                clusterState = newState;\n                shardIt = shards(newState, request);\n            }\n\n            // initialize the counter\n            int replicaCounter = shardIt.assignedReplicasIncludingRelocating();\n\n            if (replicaCounter == 0) {\n                postPrimaryOperation(request, response);\n                listener.onResponse(response.response());\n                return;\n            }\n\n            if (replicationType == ReplicationType.ASYNC) {\n                postPrimaryOperation(request, response);\n                // async replication, notify the listener\n                listener.onResponse(response.response());\n                // now, trick the counter so it won't decrease to 0 and notify the listeners\n                replicaCounter = Integer.MIN_VALUE;\n            }\n\n            // we add one to the replica count to do the postPrimaryOperation\n            replicaCounter++;\n\n            AtomicInteger counter = new AtomicInteger(replicaCounter);\n            shardIt.reset(); // reset the iterator\n            ShardRouting shard;\n            while ((shard = shardIt.nextOrNull()) != null) {\n                // if its unassigned, nothing to do here...\n                if (shard.unassigned()) {\n                    continue;\n                }\n\n                // if the shard is primary and relocating, add one to the counter since we perform it on the replica as well\n                // (and we already did it on the primary)\n                boolean doOnlyOnRelocating = false;\n                if (shard.primary()) {\n                    if (shard.relocating()) {\n                        doOnlyOnRelocating = true;\n                    } else {\n                        continue;\n                    }\n                }\n                // we index on a replica that is initializing as well since we might not have got the event\n                // yet that it was started. We will get an exception IllegalShardState exception if its not started\n                // and that's fine, we will ignore it\n                if (!doOnlyOnRelocating) {\n                    performOnReplica(response, counter, shard, shard.currentNodeId());\n                }\n                if (shard.relocating()) {\n                    performOnReplica(response, counter, shard, shard.relocatingNodeId());\n                }\n            }\n\n            // now do the postPrimary operation, and check if the listener needs to be invoked\n            postPrimaryOperation(request, response);\n            // we also invoke here in case replicas finish before postPrimaryAction does\n            if (counter.decrementAndGet() == 0) {\n                listener.onResponse(response.response());\n            }\n        }","commit_id":"bfdf8fe5905553e0b60046c2973d3829947a979c","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected MappingUpdatedResponse masterOperation(MappingUpdatedRequest request) throws ElasticSearchException {\n        metaDataService.updateMapping(request.index(), request.type(), request.mappingSource());\n        return new MappingUpdatedResponse();\n    }","id":37846,"modified_method":"@Override protected MappingUpdatedResponse masterOperation(MappingUpdatedRequest request, ClusterState state) throws ElasticSearchException {\n        metaDataService.updateMapping(request.index(), request.type(), request.mappingSource());\n        return new MappingUpdatedResponse();\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * Shuts down nodes based on the nodes ids specified. If none are passed, <b>all<\/b>\n     * nodes will be shutdown.\n     */\n    public NodesShutdownRequest(String... nodesIds) {\n        super(nodesIds);\n    }","id":37847,"modified_method":"public NodesShutdownRequest(String... nodesIds) {\n        this.nodesIds = nodesIds;\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        super.readFrom(in);\n        delay = readTimeValue(in);\n    }","id":37848,"modified_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        super.readFrom(in);\n        delay = readTimeValue(in);\n        int size = in.readVInt();\n        if (size > 0) {\n            nodesIds = new String[size];\n            for (int i = 0; i < nodesIds.length; i++) {\n                nodesIds[i] = in.readUTF();\n            }\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected NodesShutdownRequest() {\n    }","id":37849,"modified_method":"NodesShutdownRequest() {\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        delay.writeTo(out);\n    }","id":37850,"modified_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        delay.writeTo(out);\n        if (nodesIds == null) {\n            out.writeVInt(0);\n        } else {\n            out.writeVInt(nodesIds.length);\n            for (String nodeId : nodesIds) {\n                out.writeUTF(nodeId);\n            }\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        super.readFrom(in);\n        nodes = new NodeShutdownResponse[in.readVInt()];\n        for (int i = 0; i < nodes.length; i++) {\n            nodes[i] = NodeShutdownResponse.readNodeShutdownResponse(in);\n        }\n    }","id":37851,"modified_method":"@Override public void readFrom(StreamInput in) throws IOException {\n        clusterName = ClusterName.readClusterName(in);\n        nodes = new DiscoveryNode[in.readVInt()];\n        for (int i = 0; i < nodes.length; i++) {\n            nodes[i] = DiscoveryNode.readNode(in);\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        out.writeVInt(nodes.length);\n        for (NodeShutdownResponse node : nodes) {\n            node.writeTo(out);\n        }\n    }","id":37852,"modified_method":"@Override public void writeTo(StreamOutput out) throws IOException {\n        clusterName.writeTo(out);\n        out.writeVInt(nodes.length);\n        for (DiscoveryNode node : nodes) {\n            node.writeTo(out);\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"public NodesShutdownResponse(ClusterName clusterName, NodeShutdownResponse[] nodes) {\n        super(clusterName, nodes);\n    }","id":37853,"modified_method":"public NodesShutdownResponse(ClusterName clusterName, DiscoveryNode[] nodes) {\n        this.clusterName = clusterName;\n        this.nodes = nodes;\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void handleRequest(final RestRequest request, final RestChannel channel) {\n        String[] nodesIds = RestActions.splitNodes(request.param(\"nodeId\"));\n        NodesShutdownRequest nodesShutdownRequest = new NodesShutdownRequest(nodesIds);\n        nodesShutdownRequest.listenerThreaded(false);\n        nodesShutdownRequest.delay(request.paramAsTime(\"delay\", nodesShutdownRequest.delay()));\n        client.admin().cluster().nodesShutdown(nodesShutdownRequest, new ActionListener<NodesShutdownResponse>() {\n            @Override public void onResponse(NodesShutdownResponse result) {\n                try {\n                    XContentBuilder builder = restContentBuilder(request);\n                    builder.startObject();\n                    builder.field(\"cluster_name\", result.clusterName().value());\n\n                    builder.startObject(\"nodes\");\n                    for (NodesShutdownResponse.NodeShutdownResponse nodeInfo : result) {\n                        builder.startObject(nodeInfo.node().id());\n                        builder.field(\"name\", nodeInfo.node().name());\n                        builder.endObject();\n                    }\n                    builder.endObject();\n\n                    builder.endObject();\n                    channel.sendResponse(new XContentRestResponse(request, RestResponse.Status.OK, builder));\n                } catch (Exception e) {\n                    onFailure(e);\n                }\n            }\n\n            @Override public void onFailure(Throwable e) {\n                try {\n                    channel.sendResponse(new XContentThrowableRestResponse(request, e));\n                } catch (IOException e1) {\n                    logger.error(\"Failed to send failure response\", e1);\n                }\n            }\n        });\n    }","id":37854,"modified_method":"@Override public void handleRequest(final RestRequest request, final RestChannel channel) {\n        String[] nodesIds = RestActions.splitNodes(request.param(\"nodeId\"));\n        NodesShutdownRequest nodesShutdownRequest = new NodesShutdownRequest(nodesIds);\n        nodesShutdownRequest.listenerThreaded(false);\n        nodesShutdownRequest.delay(request.paramAsTime(\"delay\", nodesShutdownRequest.delay()));\n        client.admin().cluster().nodesShutdown(nodesShutdownRequest, new ActionListener<NodesShutdownResponse>() {\n            @Override public void onResponse(NodesShutdownResponse response) {\n                try {\n                    XContentBuilder builder = restContentBuilder(request);\n                    builder.startObject();\n                    builder.field(\"cluster_name\", response.clusterName().value());\n\n                    builder.startObject(\"nodes\");\n                    for (DiscoveryNode node : response.nodes()) {\n                        builder.startObject(node.id());\n                        builder.field(\"name\", node.name());\n                        builder.endObject();\n                    }\n                    builder.endObject();\n\n                    builder.endObject();\n                    channel.sendResponse(new XContentRestResponse(request, RestResponse.Status.OK, builder));\n                } catch (Exception e) {\n                    onFailure(e);\n                }\n            }\n\n            @Override public void onFailure(Throwable e) {\n                try {\n                    channel.sendResponse(new XContentThrowableRestResponse(request, e));\n                } catch (IOException e1) {\n                    logger.error(\"Failed to send failure response\", e1);\n                }\n            }\n        });\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected ClusterHealthResponse masterOperation(ClusterHealthRequest request) throws ElasticSearchException {\n        int waitFor = 3;\n        if (request.waitForStatus() == null) {\n            waitFor--;\n        }\n        if (request.waitForRelocatingShards() == -1) {\n            waitFor--;\n        }\n        if (request.waitForActiveShards() == -1) {\n            waitFor--;\n        }\n        if (waitFor == 0) {\n            // no need to wait for anything\n            return clusterHealth(request);\n        }\n        long endTime = System.currentTimeMillis() + request.timeout().millis();\n        while (true) {\n            int waitForCounter = 0;\n            ClusterHealthResponse response = clusterHealth(request);\n            if (request.waitForStatus() != null && response.status().value() <= request.waitForStatus().value()) {\n                waitForCounter++;\n            }\n            if (request.waitForRelocatingShards() != -1 && response.relocatingShards() <= request.waitForRelocatingShards()) {\n                waitForCounter++;\n            }\n            if (request.waitForActiveShards() != -1 && response.activeShards() >= request.waitForActiveShards()) {\n                waitForCounter++;\n            }\n            if (waitForCounter == waitFor) {\n                return response;\n            }\n            if (timerService.estimatedTimeInMillis() > endTime) {\n                response.timedOut = true;\n                return response;\n            }\n            try {\n                Thread.sleep(200);\n            } catch (InterruptedException e) {\n                response.timedOut = true;\n                // we got interrupted, bail\n                return response;\n            }\n        }\n    }","id":37855,"modified_method":"@Override protected ClusterHealthResponse masterOperation(ClusterHealthRequest request, ClusterState state) throws ElasticSearchException {\n        int waitFor = 3;\n        if (request.waitForStatus() == null) {\n            waitFor--;\n        }\n        if (request.waitForRelocatingShards() == -1) {\n            waitFor--;\n        }\n        if (request.waitForActiveShards() == -1) {\n            waitFor--;\n        }\n        if (waitFor == 0) {\n            // no need to wait for anything\n            return clusterHealth(request);\n        }\n        long endTime = System.currentTimeMillis() + request.timeout().millis();\n        while (true) {\n            int waitForCounter = 0;\n            ClusterHealthResponse response = clusterHealth(request);\n            if (request.waitForStatus() != null && response.status().value() <= request.waitForStatus().value()) {\n                waitForCounter++;\n            }\n            if (request.waitForRelocatingShards() != -1 && response.relocatingShards() <= request.waitForRelocatingShards()) {\n                waitForCounter++;\n            }\n            if (request.waitForActiveShards() != -1 && response.activeShards() >= request.waitForActiveShards()) {\n                waitForCounter++;\n            }\n            if (waitForCounter == waitFor) {\n                return response;\n            }\n            if (timerService.estimatedTimeInMillis() > endTime) {\n                response.timedOut = true;\n                return response;\n            }\n            try {\n                Thread.sleep(200);\n            } catch (InterruptedException e) {\n                response.timedOut = true;\n                // we got interrupted, bail\n                return response;\n            }\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected ClusterStateResponse masterOperation(ClusterStateRequest request) throws ElasticSearchException {\n        ClusterState currentState = clusterService.state();\n        ClusterState.Builder builder = newClusterStateBuilder();\n        if (!request.filterNodes()) {\n            builder.nodes(currentState.nodes());\n        }\n        if (!request.filterRoutingTable()) {\n            builder.routingTable(currentState.routingTable());\n        }\n        if (!request.filterBlocks()) {\n            builder.blocks(currentState.blocks());\n        }\n        if (!request.filterMetaData()) {\n            if (request.filteredIndices().length > 0) {\n                MetaData.Builder mdBuilder = newMetaDataBuilder();\n                String[] indices = currentState.metaData().concreteIndices(request.filteredIndices());\n                for (String filteredIndex : indices) {\n                    IndexMetaData indexMetaData = currentState.metaData().index(filteredIndex);\n                    if (indexMetaData == null) {\n                        throw new IndexMissingException(new Index(filteredIndex));\n                    }\n                    mdBuilder.put(indexMetaData);\n                }\n                builder.metaData(mdBuilder);\n            } else {\n                builder.metaData(currentState.metaData());\n            }\n        }\n        return new ClusterStateResponse(clusterName, builder.build());\n    }","id":37856,"modified_method":"@Override protected ClusterStateResponse masterOperation(ClusterStateRequest request, ClusterState state) throws ElasticSearchException {\n        ClusterState currentState = clusterService.state();\n        ClusterState.Builder builder = newClusterStateBuilder();\n        if (!request.filterNodes()) {\n            builder.nodes(currentState.nodes());\n        }\n        if (!request.filterRoutingTable()) {\n            builder.routingTable(currentState.routingTable());\n        }\n        if (!request.filterBlocks()) {\n            builder.blocks(currentState.blocks());\n        }\n        if (!request.filterMetaData()) {\n            if (request.filteredIndices().length > 0) {\n                MetaData.Builder mdBuilder = newMetaDataBuilder();\n                String[] indices = currentState.metaData().concreteIndices(request.filteredIndices());\n                for (String filteredIndex : indices) {\n                    IndexMetaData indexMetaData = currentState.metaData().index(filteredIndex);\n                    if (indexMetaData == null) {\n                        throw new IndexMissingException(new Index(filteredIndex));\n                    }\n                    mdBuilder.put(indexMetaData);\n                }\n                builder.metaData(mdBuilder);\n            } else {\n                builder.metaData(currentState.metaData());\n            }\n        }\n        return new ClusterStateResponse(clusterName, builder.build());\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected CreateIndexResponse masterOperation(CreateIndexRequest request) throws ElasticSearchException {\n        String cause = request.cause();\n        if (cause.length() == 0) {\n            cause = \"api\";\n        }\n        MetaDataService.CreateIndexResult createIndexResult = metaDataService.createIndex(cause, request.index(), request.settings(), request.mappings(), request.timeout());\n        return new CreateIndexResponse(createIndexResult.acknowledged());\n    }","id":37857,"modified_method":"@Override protected CreateIndexResponse masterOperation(CreateIndexRequest request, ClusterState state) throws ElasticSearchException {\n        String cause = request.cause();\n        if (cause.length() == 0) {\n            cause = \"api\";\n        }\n        MetaDataService.CreateIndexResult createIndexResult = metaDataService.createIndex(cause, request.index(), request.settings(), request.mappings(), request.timeout());\n        return new CreateIndexResponse(createIndexResult.acknowledged());\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected DeleteIndexResponse masterOperation(DeleteIndexRequest request) throws ElasticSearchException {\n        MetaDataService.DeleteIndexResult deleteIndexResult = metaDataService.deleteIndex(request.index(), request.timeout());\n        return new DeleteIndexResponse(deleteIndexResult.acknowledged());\n    }","id":37858,"modified_method":"@Override protected DeleteIndexResponse masterOperation(DeleteIndexRequest request, ClusterState state) throws ElasticSearchException {\n        MetaDataService.DeleteIndexResult deleteIndexResult = metaDataService.deleteIndex(request.index(), request.timeout());\n        return new DeleteIndexResponse(deleteIndexResult.acknowledged());\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected IndicesAliasesResponse masterOperation(IndicesAliasesRequest request) throws ElasticSearchException {\n        MetaDataService.IndicesAliasesResult indicesAliasesResult = metaDataService.indicesAliases(request.aliasActions());\n        return new IndicesAliasesResponse();\n    }","id":37859,"modified_method":"@Override protected IndicesAliasesResponse masterOperation(IndicesAliasesRequest request, ClusterState state) throws ElasticSearchException {\n        MetaDataService.IndicesAliasesResult indicesAliasesResult = metaDataService.indicesAliases(request.aliasActions());\n        return new IndicesAliasesResponse();\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void messageReceived(final Request request, final TransportChannel channel) throws Exception {\n            if (clusterService.state().nodes().localNodeMaster()) {\n                checkBlock(request, clusterService.state());\n                Response response = masterOperation(request);\n                channel.sendResponse(response);\n            } else {\n                transportService.sendRequest(clusterService.state().nodes().masterNode(), transportAction(), request, new BaseTransportResponseHandler<Response>() {\n                    @Override public Response newInstance() {\n                        return newResponse();\n                    }\n\n                    @Override public void handleResponse(Response response) {\n                        try {\n                            channel.sendResponse(response);\n                        } catch (Exception e) {\n                            logger.error(\"Failed to send response\", e);\n                        }\n                    }\n\n                    @Override public void handleException(RemoteTransportException exp) {\n                        try {\n                            channel.sendResponse(exp);\n                        } catch (Exception e) {\n                            logger.error(\"Failed to send response\", e);\n                        }\n                    }\n                });\n            }\n        }","id":37860,"modified_method":"@Override public void messageReceived(final Request request, final TransportChannel channel) throws Exception {\n            final ClusterState clusterState = clusterService.state();\n            if (clusterState.nodes().localNodeMaster()) {\n                checkBlock(request, clusterState);\n                Response response = masterOperation(request, clusterState);\n                channel.sendResponse(response);\n            } else {\n                transportService.sendRequest(clusterService.state().nodes().masterNode(), transportAction(), request, new BaseTransportResponseHandler<Response>() {\n                    @Override public Response newInstance() {\n                        return newResponse();\n                    }\n\n                    @Override public void handleResponse(Response response) {\n                        try {\n                            channel.sendResponse(response);\n                        } catch (Exception e) {\n                            logger.error(\"Failed to send response\", e);\n                        }\n                    }\n\n                    @Override public void handleException(RemoteTransportException exp) {\n                        try {\n                            channel.sendResponse(exp);\n                        } catch (Exception e) {\n                            logger.error(\"Failed to send response\", e);\n                        }\n                    }\n                });\n            }\n        }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doExecute(final Request request, final ActionListener<Response> listener) {\n        DiscoveryNodes nodes = clusterService.state().nodes();\n        if (nodes.localNodeMaster()) {\n            threadPool.execute(new Runnable() {\n                @Override public void run() {\n                    try {\n                        checkBlock(request, clusterService.state());\n                        Response response = masterOperation(request);\n                        listener.onResponse(response);\n                    } catch (Exception e) {\n                        listener.onFailure(e);\n                    }\n                }\n            });\n        } else {\n            if (nodes.masterNode() == null) {\n                throw new ElasticSearchIllegalStateException(\"No master node discovered or set\");\n            }\n            transportService.sendRequest(nodes.masterNode(), transportAction(), request, new BaseTransportResponseHandler<Response>() {\n                @Override public Response newInstance() {\n                    return newResponse();\n                }\n\n                @Override public void handleResponse(Response response) {\n                    listener.onResponse(response);\n                }\n\n                @Override public void handleException(RemoteTransportException exp) {\n                    listener.onFailure(exp);\n                }\n            });\n        }\n    }","id":37861,"modified_method":"@Override protected void doExecute(final Request request, final ActionListener<Response> listener) {\n        final ClusterState clusterState = clusterService.state();\n        DiscoveryNodes nodes = clusterState.nodes();\n        if (nodes.localNodeMaster()) {\n            threadPool.execute(new Runnable() {\n                @Override public void run() {\n                    try {\n                        checkBlock(request, clusterState);\n                        Response response = masterOperation(request, clusterState);\n                        listener.onResponse(response);\n                    } catch (Exception e) {\n                        listener.onFailure(e);\n                    }\n                }\n            });\n        } else {\n            if (nodes.masterNode() == null) {\n                throw new ElasticSearchIllegalStateException(\"No master node discovered or set\");\n            }\n            processBeforeDelegationToMaster(request, clusterState);\n            transportService.sendRequest(nodes.masterNode(), transportAction(), request, new BaseTransportResponseHandler<Response>() {\n                @Override public Response newInstance() {\n                    return newResponse();\n                }\n\n                @Override public void handleResponse(Response response) {\n                    listener.onResponse(response);\n                }\n\n                @Override public void handleException(RemoteTransportException exp) {\n                    listener.onFailure(exp);\n                }\n            });\n        }\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"protected abstract Response masterOperation(Request request) throws ElasticSearchException;","id":37862,"modified_method":"protected abstract Response masterOperation(Request request, ClusterState state) throws ElasticSearchException;","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"private AsyncAction(Request request, ActionListener<Response> listener) {\n            this.request = request;\n            this.listener = listener;\n            clusterState = clusterService.state();\n            String[] nodesIds = request.nodesIds();\n            if (nodesIds == null || nodesIds.length == 0 || (nodesIds.length == 1 && nodesIds[0].equals(\"_all\"))) {\n                int index = 0;\n                nodesIds = new String[clusterState.nodes().size()];\n                for (DiscoveryNode node : clusterState.nodes()) {\n                    nodesIds[index++] = node.id();\n                }\n            }\n            for (int i = 0; i < nodesIds.length; i++) {\n                if (nodesIds[i].equals(\"_local\")) {\n                    nodesIds[i] = clusterState.nodes().localNodeId();\n                } else if (nodesIds[i].equals(\"_master\")) {\n                    nodesIds[i] = clusterState.nodes().masterNodeId();\n                }\n            }\n            this.nodesIds = filterNodeIds(clusterState.nodes(), nodesIds);\n            this.responses = new AtomicReferenceArray<Object>(this.nodesIds.length);\n        }","id":37863,"modified_method":"private AsyncAction(Request request, ActionListener<Response> listener) {\n            this.request = request;\n            this.listener = listener;\n            clusterState = clusterService.state();\n            String[] nodesIds = Actions.buildNodesIds(clusterState.nodes(), request.nodesIds());\n            this.nodesIds = filterNodeIds(clusterState.nodes(), nodesIds);\n            this.responses = new AtomicReferenceArray<Object>(this.nodesIds.length);\n        }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected NodesShutdownResponse.NodeShutdownResponse nodeOperation(final NodeShutdownRequest request) throws ElasticSearchException {\n        if (disabled) {\n            throw new ElasticSearchIllegalStateException(\"Shutdown is disabled\");\n        }\n        logger.info(\"Shutting down in [{}]\", request.delay);\n        Thread t = new Thread(new Runnable() {\n            @Override public void run() {\n                try {\n                    Thread.sleep(request.delay.millis());\n                } catch (InterruptedException e) {\n                    // ignore\n                }\n                boolean shutdownWithWrapper = false;\n                if (System.getProperty(\"elasticsearch-service\") != null) {\n                    try {\n                        Class wrapperManager = settings.getClassLoader().loadClass(\"org.tanukisoftware.wrapper.WrapperManager\");\n                        logger.info(\"Initiating requested shutdown (using service)\");\n                        wrapperManager.getMethod(\"stopAndReturn\", int.class).invoke(null, 0);\n                        shutdownWithWrapper = true;\n                    } catch (Throwable e) {\n                        e.printStackTrace();\n                    }\n                }\n                if (!shutdownWithWrapper) {\n                    logger.info(\"Initiating requested shutdown\");\n                    try {\n                        node.close();\n                    } catch (Exception e) {\n                        logger.warn(\"Failed to shutdown\", e);\n                    } finally {\n                        // make sure we initiate the shutdown hooks, so the Bootstrap#main thread will exit\n                        System.exit(0);\n                    }\n                }\n            }\n        });\n        t.start();\n        return new NodesShutdownResponse.NodeShutdownResponse(clusterService.state().nodes().localNode());\n    }","id":37864,"modified_method":"@Override protected NodesShutdownResponse masterOperation(final NodesShutdownRequest request, final ClusterState state) throws ElasticSearchException {\n        if (disabled) {\n            throw new ElasticSearchIllegalStateException(\"Shutdown is disabled\");\n        }\n        Set<DiscoveryNode> nodes = Sets.newHashSet();\n        if (Actions.isAllNodes(request.nodesIds)) {\n            logger.info(\"[cluster_shutdown]: requested, shutting down in [{}]\", request.delay);\n            nodes.addAll(state.nodes().nodes().values());\n            Thread t = new Thread(new Runnable() {\n                @Override public void run() {\n                    try {\n                        Thread.sleep(request.delay.millis());\n                    } catch (InterruptedException e) {\n                        // ignore\n                    }\n                    // first, stop the cluster service\n                    logger.trace(\"[cluster_shutdown]: stopping the cluster service so no re-routing will occur\");\n                    clusterService.stop();\n\n                    final CountDownLatch latch = new CountDownLatch(state.nodes().size());\n                    for (final DiscoveryNode node : state.nodes()) {\n                        if (node.id().equals(state.nodes().masterNodeId())) {\n                            // don't shutdown the master yet...\n                            latch.countDown();\n                        } else {\n                            logger.trace(\"[cluster_shutdown]: sending shutdown request to [{}]\", node);\n                            transportService.sendRequest(node, NodeShutdownRequestHandler.ACTION, VoidStreamable.INSTANCE, new VoidTransportResponseHandler() {\n                                @Override public void handleResponse(VoidStreamable response) {\n                                    logger.trace(\"[cluster_shutdown]: received shutdown response from [{}]\", node);\n                                    latch.countDown();\n                                }\n\n                                @Override public void handleException(RemoteTransportException exp) {\n                                    logger.warn(\"[cluster_shutdown]: received failed shutdown response from [{}]\", exp, node);\n                                    latch.countDown();\n                                }\n                            });\n                        }\n                    }\n                    try {\n                        latch.await();\n                    } catch (InterruptedException e) {\n                        // ignore\n                    }\n                    logger.info(\"[cluster_shutdown]: done shutting done all nodes except master, proceeding to master\");\n\n                    // now, kill the master\n                    logger.trace(\"[cluster_shutdown]: shutting down the master [{}]\", state.nodes().masterNode());\n                    transportService.sendRequest(state.nodes().masterNode(), NodeShutdownRequestHandler.ACTION, VoidStreamable.INSTANCE, new VoidTransportResponseHandler() {\n                        @Override public void handleResponse(VoidStreamable response) {\n                            logger.trace(\"[cluster_shutdown]: received shutdown response from master\");\n                        }\n\n                        @Override public void handleException(RemoteTransportException exp) {\n                            logger.warn(\"[cluster_shutdown]: received failed shutdown response master\", exp);\n                        }\n                    });\n                }\n            });\n            t.start();\n        } else {\n            final String[] nodesIds = Actions.buildNodesIds(state.nodes(), request.nodesIds);\n            logger.info(\"[partial_cluster_shutdown]: requested, shutting down [{}] in [{}]\", nodesIds, request.delay);\n\n            for (String nodeId : nodesIds) {\n                final DiscoveryNode node = state.nodes().get(nodeId);\n                if (node != null) {\n                    nodes.add(node);\n                }\n            }\n\n            Thread t = new Thread(new Runnable() {\n                @Override public void run() {\n                    try {\n                        Thread.sleep(request.delay.millis());\n                    } catch (InterruptedException e) {\n                        // ignore\n                    }\n\n                    final CountDownLatch latch = new CountDownLatch(nodesIds.length);\n                    for (String nodeId : nodesIds) {\n                        final DiscoveryNode node = state.nodes().get(nodeId);\n                        if (node == null) {\n                            logger.warn(\"[partial_cluster_shutdown]: no node to shutdown for node_id [{}]\", nodeId);\n                            latch.countDown();\n                            continue;\n                        }\n\n                        logger.trace(\"[partial_cluster_shutdown]: sending shutdown request to [{}]\", node);\n                        transportService.sendRequest(node, NodeShutdownRequestHandler.ACTION, VoidStreamable.INSTANCE, new VoidTransportResponseHandler() {\n                            @Override public void handleResponse(VoidStreamable response) {\n                                logger.trace(\"[partial_cluster_shutdown]: received shutdown response from [{}]\", node);\n                                latch.countDown();\n                            }\n\n                            @Override public void handleException(RemoteTransportException exp) {\n                                logger.warn(\"[partial_cluster_shutdown]: received failed shutdown response from [{}]\", exp, node);\n                                latch.countDown();\n                            }\n                        });\n                    }\n\n                    try {\n                        latch.await();\n                    } catch (InterruptedException e) {\n                        // ignore\n                    }\n\n                    logger.info(\"[partial_cluster_shutdown]: done shutting down [{}]\", nodesIds);\n                }\n            });\n            t.start();\n        }\n        return new NodesShutdownResponse(clusterName, nodes.toArray(new DiscoveryNode[nodes.size()]));\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Inject public TransportNodesShutdownAction(Settings settings, ClusterName clusterName, ThreadPool threadPool,\n                                                ClusterService clusterService, TransportService transportService,\n                                                Node node) {\n        super(settings, clusterName, threadPool, clusterService, transportService);\n        this.node = node;\n        disabled = componentSettings.getAsBoolean(\"disabled\", false);\n    }","id":37865,"modified_method":"@Inject public TransportNodesShutdownAction(Settings settings, TransportService transportService, ClusterService clusterService, ThreadPool threadPool,\n                                                Node node, ClusterName clusterName) {\n        super(settings, transportService, clusterService, threadPool);\n        this.node = node;\n        this.clusterName = clusterName;\n        this.disabled = componentSettings.getAsBoolean(\"disabled\", false);\n        this.delay = componentSettings.getAsTime(\"delay\", TimeValue.timeValueMillis(200));\n\n        this.transportService.registerHandler(NodeShutdownRequestHandler.ACTION, new NodeShutdownRequestHandler());\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected NodesShutdownResponse.NodeShutdownResponse newNodeResponse() {\n        return new NodesShutdownResponse.NodeShutdownResponse();\n    }","id":37866,"modified_method":"@Override protected NodesShutdownResponse newResponse() {\n        return new NodesShutdownResponse();\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected PutMappingResponse masterOperation(PutMappingRequest request) throws ElasticSearchException {\n        ClusterState clusterState = clusterService.state();\n\n        // update to concrete indices\n        request.indices(clusterState.metaData().concreteIndices(request.indices()));\n        final String[] indices = request.indices();\n\n        MetaDataService.PutMappingResult result = metaDataService.putMapping(indices, request.type(), request.source(), request.ignoreConflicts(), request.timeout());\n        return new PutMappingResponse(result.acknowledged());\n    }","id":37867,"modified_method":"@Override protected PutMappingResponse masterOperation(PutMappingRequest request, ClusterState state) throws ElasticSearchException {\n        ClusterState clusterState = clusterService.state();\n\n        // update to concrete indices\n        request.indices(clusterState.metaData().concreteIndices(request.indices()));\n        final String[] indices = request.indices();\n\n        MetaDataService.PutMappingResult result = metaDataService.putMapping(indices, request.type(), request.source(), request.ignoreConflicts(), request.timeout());\n        return new PutMappingResponse(result.acknowledged());\n    }","commit_id":"294f09a1d7a603f26ebd554be6c4e74a6f5ed76b","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Inject public GatewayService(Settings settings, Gateway gateway, ClusterService clusterService, DiscoveryService discoveryService, ThreadPool threadPool) {\n        super(settings);\n        this.gateway = gateway;\n        this.clusterService = clusterService;\n        this.discoveryService = discoveryService;\n        this.threadPool = threadPool;\n        this.initialStateTimeout = componentSettings.getAsTime(\"initial_state_timeout\", TimeValue.timeValueSeconds(30));\n        // allow to control a delay of when indices will get created\n        this.recoverAfterTime = componentSettings.getAsTime(\"recover_after_time\", null);\n        this.recoverAfterNodes = componentSettings.getAsInt(\"recover_after_nodes\", -1);\n    }","id":37868,"modified_method":"@Inject public GatewayService(Settings settings, Gateway gateway, ClusterService clusterService, DiscoveryService discoveryService, ThreadPool threadPool) {\n        super(settings);\n        this.gateway = gateway;\n        this.clusterService = clusterService;\n        this.discoveryService = discoveryService;\n        this.threadPool = threadPool;\n        this.initialStateTimeout = componentSettings.getAsTime(\"initial_state_timeout\", TimeValue.timeValueSeconds(30));\n        // allow to control a delay of when indices will get created\n        this.recoverAfterTime = componentSettings.getAsTime(\"recover_after_time\", null);\n        this.recoverAfterNodes = componentSettings.getAsInt(\"recover_after_nodes\", -1);\n        this.recoverAfterDataNodes = componentSettings.getAsInt(\"recover_after_data_nodes\", -1);\n        this.recoverAfterMasterNodes = componentSettings.getAsInt(\"recover_after_master_nodes\", -1);\n    }","commit_id":"25246902cc389d90ac4ab589077ea3b4736e5e9f","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override public void clusterChanged(final ClusterChangedEvent event) {\n        if (!lifecycle.started()) {\n            return;\n        }\n        if (event.localNodeMaster()) {\n            if (!event.state().metaData().recoveredFromGateway()) {\n                ClusterState clusterState = event.state();\n                if (recoverAfterNodes != -1 && clusterState.nodes().dataNodes().size() < recoverAfterNodes) {\n                    logger.debug(\"not recovering from gateway, data_nodes_size [\" + clusterState.nodes().dataNodes().size() + \"] < recover_after_nodes [\" + recoverAfterNodes + \"]\");\n                } else {\n                    if (performedStateRecovery.compareAndSet(false, true)) {\n                        threadPool.cached().execute(new Runnable() {\n                            @Override public void run() {\n                                performStateRecovery(null);\n                            }\n                        });\n                    }\n                }\n            }\n        }\n    }","id":37869,"modified_method":"@Override public void clusterChanged(final ClusterChangedEvent event) {\n        if (!lifecycle.started()) {\n            return;\n        }\n        if (event.localNodeMaster()) {\n            if (!event.state().metaData().recoveredFromGateway()) {\n                ClusterState clusterState = event.state();\n                DiscoveryNodes nodes = clusterState.nodes();\n                if (recoverAfterNodes != -1 && (nodes.masterAndDataNodes().size()) < recoverAfterNodes) {\n                    logger.debug(\"not recovering from gateway, nodes_size (data+master) [\" + nodes.masterAndDataNodes().size() + \"] < recover_after_nodes [\" + recoverAfterNodes + \"]\");\n                } else if (recoverAfterDataNodes != -1 && nodes.dataNodes().size() < recoverAfterDataNodes) {\n                    logger.debug(\"not recovering from gateway, nodes_size (data) [\" + nodes.dataNodes().size() + \"] < recover_after_data_nodes [\" + recoverAfterDataNodes + \"]\");\n                } else if (recoverAfterMasterNodes != -1 && nodes.masterNodes().size() < recoverAfterMasterNodes) {\n                    logger.debug(\"not recovering from gateway, nodes_size (master) [\" + nodes.masterNodes().size() + \"] < recover_after_master_nodes [\" + recoverAfterMasterNodes + \"]\");\n                } else {\n                    if (performedStateRecovery.compareAndSet(false, true)) {\n                        threadPool.cached().execute(new Runnable() {\n                            @Override public void run() {\n                                performStateRecovery(null);\n                            }\n                        });\n                    }\n                }\n            }\n        }\n    }","commit_id":"25246902cc389d90ac4ab589077ea3b4736e5e9f","url":"https://github.com/elastic/elasticsearch"},{"original_method":"@Override protected void doStart() throws ElasticSearchException {\n        gateway.start();\n        // if we received initial state, see if we can recover within the start phase, so we hold the\n        // node from starting until we recovered properly\n        if (discoveryService.initialStateReceived()) {\n            ClusterState clusterState = clusterService.state();\n            if (clusterState.nodes().localNodeMaster() && !clusterState.metaData().recoveredFromGateway()) {\n                if (recoverAfterNodes != -1 && clusterState.nodes().dataNodes().size() < recoverAfterNodes) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, data_nodes_size [\" + clusterState.nodes().dataNodes().size() + \"] < recover_after_nodes [\" + recoverAfterNodes + \"]\");\n                } else if (recoverAfterTime != null) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, recover_after_time [{}]\", recoverAfterTime);\n                } else {\n                    if (performedStateRecovery.compareAndSet(false, true)) {\n                        performStateRecovery(initialStateTimeout);\n                    }\n                }\n            }\n        } else {\n            logger.debug(\"can't wait on start for (possibly) reading state from gateway, will do it asynchronously\");\n        }\n        clusterService.add(this);\n    }","id":37870,"modified_method":"@Override protected void doStart() throws ElasticSearchException {\n        gateway.start();\n        // if we received initial state, see if we can recover within the start phase, so we hold the\n        // node from starting until we recovered properly\n        if (discoveryService.initialStateReceived()) {\n            ClusterState clusterState = clusterService.state();\n            DiscoveryNodes nodes = clusterState.nodes();\n            if (clusterState.nodes().localNodeMaster() && !clusterState.metaData().recoveredFromGateway()) {\n                if (recoverAfterNodes != -1 && (nodes.masterAndDataNodes().size()) < recoverAfterNodes) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, nodes_size (data+master) [\" + nodes.masterAndDataNodes().size() + \"] < recover_after_nodes [\" + recoverAfterNodes + \"]\");\n                } else if (recoverAfterDataNodes != -1 && nodes.dataNodes().size() < recoverAfterDataNodes) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, nodes_size (data) [\" + nodes.dataNodes().size() + \"] < recover_after_data_nodes [\" + recoverAfterDataNodes + \"]\");\n                } else if (recoverAfterMasterNodes != -1 && nodes.masterNodes().size() < recoverAfterMasterNodes) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, nodes_size (master) [\" + nodes.masterNodes().size() + \"] < recover_after_master_nodes [\" + recoverAfterMasterNodes + \"]\");\n                } else if (recoverAfterTime != null) {\n                    updateClusterStateBlockedOnNotRecovered();\n                    logger.debug(\"not recovering from gateway, recover_after_time [{}]\", recoverAfterTime);\n                } else {\n                    if (performedStateRecovery.compareAndSet(false, true)) {\n                        performStateRecovery(initialStateTimeout);\n                    }\n                }\n            }\n        } else {\n            logger.debug(\"can't wait on start for (possibly) reading state from gateway, will do it asynchronously\");\n        }\n        clusterService.add(this);\n    }","commit_id":"25246902cc389d90ac4ab589077ea3b4736e5e9f","url":"https://github.com/elastic/elasticsearch"},{"original_method":"/**\n     * An {@link IdMapper} that doesn't touch the input ids, but just asserts that node ids arrive in ascending order.\n     */\n    public static IdMapper actual()\n    {\n        return new IdMapper()\n        {\n            @Override\n            public void put( Object inputId, long actualId )\n            {   // No need to remember anything\n            }\n\n            @Override\n            public boolean needsPreparation()\n            {\n                return false;\n            }\n\n            @Override\n            public void prepare()\n            {   // No need to prepare anything\n            }\n\n            @Override\n            public long get( Object inputId )\n            {\n                return ((Long)inputId).longValue();\n            }\n\n            @Override\n            public void visitMemoryStats( MemoryStatsVisitor visitor )\n            {   // No memory usage\n            }\n        };\n    }","id":37871,"modified_method":"/**\n     * An {@link IdMapper} that doesn't touch the input ids, but just asserts that node ids arrive in ascending order.\n     */\n    public static IdMapper actual()\n    {\n        return new IdMapper()\n        {\n            @Override\n            public void put( Object inputId, long actualId )\n            {   // No need to remember anything\n            }\n\n            @Override\n            public boolean needsPreparation()\n            {\n                return false;\n            }\n\n            @Override\n            public void prepare( Iterable<Object> nodeData )\n            {   // No need to prepare anything\n            }\n\n            @Override\n            public long get( Object inputId )\n            {\n                return ((Long)inputId).longValue();\n            }\n\n            @Override\n            public void visitMemoryStats( MemoryStatsVisitor visitor )\n            {   // No memory usage\n            }\n        };\n    }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    protected void done()\n    {\n        // We're done adding ids to the IdMapper, sort so that the following stages can query it.\n        idMapper.prepare();\n        super.done();\n    }","id":37872,"modified_method":"@Override\n    protected void done()\n    {\n        // We're done adding ids to the IdMapper, prepare for other stages querying it.\n        // We pass in allIds because they may be needed to sort out colliding values in case of String->long\n        // encoding.\n        idMapper.prepare( allIds );\n        super.done();\n    }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"public NodeEncoderStep( StageControl control, String name, int workAheadSize, int numberOfExecutors,\n            IdMapper idMapper, IdGenerator idGenerator, BatchingTokenRepository<?> propertyKeyHolder,\n            BatchingTokenRepository<?> labelHolder,\n            NodeStore nodeStore, PropertyStore propertyStore )\n    {\n        super( control, name, workAheadSize, numberOfExecutors );\n        this.idMapper = idMapper;\n        this.idGenerator = idGenerator;\n        this.nodeStore = nodeStore;\n        this.propertyKeyHolder = propertyKeyHolder;\n        this.labelHolder = labelHolder;\n        this.propertyCreator = new PropertyCreator( propertyStore, null );\n    }","id":37873,"modified_method":"public NodeEncoderStep( StageControl control, String name, int workAheadSize, int numberOfExecutors,\n            IdMapper idMapper, IdGenerator idGenerator, BatchingTokenRepository<?> propertyKeyHolder,\n            BatchingTokenRepository<?> labelHolder,\n            NodeStore nodeStore, PropertyStore propertyStore,\n            Iterable<Object> allIds )\n    {\n        super( control, name, workAheadSize, numberOfExecutors );\n        this.idMapper = idMapper;\n        this.idGenerator = idGenerator;\n        this.nodeStore = nodeStore;\n        this.propertyKeyHolder = propertyKeyHolder;\n        this.labelHolder = labelHolder;\n        this.allIds = allIds;\n        this.propertyCreator = new PropertyCreator( propertyStore, null );\n    }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"public NodeStage( ResourceIterator<InputNode> input, IdMapper idMapper, IdGenerator idGenerator,\n                          BatchingNeoStore neoStore )\n        {\n            super( logging, \"Nodes\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), input ) );\n\n            NodeStore nodeStore = neoStore.getNodeStore();\n            PropertyStore propertyStore = neoStore.getPropertyStore();\n            add( new NodeEncoderStep( control(), \"ENCODER\", config.workAheadSize(), 1, idMapper, idGenerator,\n                    neoStore.getPropertyKeyRepository(), neoStore.getLabelRepository(),\n                    nodeStore, propertyStore ) );\n            add( new EntityStoreUpdaterStep<>( control(), \"WRITER\", nodeStore, propertyStore, writeMonitor ) );\n        }","id":37874,"modified_method":"public NodeStage( ResourceIterable<InputNode> nodes, IdMapper idMapper, IdGenerator idGenerator,\n                          BatchingNeoStore neoStore )\n        {\n            super( logging, \"Nodes\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), nodes.iterator() ) );\n\n            NodeStore nodeStore = neoStore.getNodeStore();\n            PropertyStore propertyStore = neoStore.getPropertyStore();\n            Iterable<Object> allIds = new IterableWrapper<Object, InputNode>( nodes )\n            {\n                @Override\n                protected Object underlyingObjectToObject( InputNode object )\n                {\n                    return object.id();\n                }\n            };\n            add( new NodeEncoderStep( control(), \"ENCODER\", config.workAheadSize(), 1, idMapper, idGenerator,\n                    neoStore.getPropertyKeyRepository(), neoStore.getLabelRepository(),\n                    nodeStore, propertyStore, allIds ) );\n            add( new EntityStoreUpdaterStep<>( control(), \"WRITER\", nodeStore, propertyStore, writeMonitor ) );\n        }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"public CalculateDenseNodesStage( ResourceIterator<InputRelationship> input,\n                NodeRelationshipLink nodeRelationshipLink, IdMapper idMapper )\n        {\n            super( logging, \"Calculate dense nodes\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), input ) );\n\n            add( new CalculateDenseNodesStep( control(), config.workAheadSize(), nodeRelationshipLink,\n                    idMapper, logger ) );\n        }","id":37875,"modified_method":"public CalculateDenseNodesStage( ResourceIterable<InputRelationship> relationships,\n                NodeRelationshipLink nodeRelationshipLink, IdMapper idMapper )\n        {\n            super( logging, \"Calculate dense nodes\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), relationships.iterator() ) );\n\n            add( new CalculateDenseNodesStep( control(), config.workAheadSize(), nodeRelationshipLink,\n                    idMapper, logger ) );\n        }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Override\n    public void doImport( Input input ) throws IOException\n    {\n        logger.info( \"Import starting\" );\n\n        long startTime = currentTimeMillis();\n        try ( BatchingNeoStore neoStore = new BatchingNeoStore( fileSystem, storeDir, config,\n                writeMonitor, logging, monitors, writerFactory ) )\n        {\n            // Some temporary caches and indexes in the import\n            final IdMapping idMapping = input.idMapping();\n            final IdMapper idMapper = idMapping.idMapper();\n            final IdGenerator idGenerator = idMapping.idGenerator();\n            final NodeRelationshipLink nodeRelationshipLink =\n                    new NodeRelationshipLinkImpl( LongArrayFactory.AUTO, config.denseNodeThreshold() );\n\n            // Stage 1 -- nodes, properties, labels\n            final NodeStage nodeStage = new NodeStage( input.nodes().iterator(), idMapper, idGenerator, neoStore );\n\n            // Stage 2 -- calculate dense node threshold\n            final CalculateDenseNodesStage calculateDenseNodesStage =\n                    new CalculateDenseNodesStage( input.relationships().iterator(), nodeRelationshipLink, idMapper );\n\n            // Execute stages 1 and 2 in parallel or sequentially?\n            if ( idMapper.needsPreparation() )\n            {   // The id mapper of choice needs preparation in order to get ids from it,\n                // So we need to execute the node stage first as it fills the id mapper and prepares it in the end,\n                // before executing any stage that needs ids from the id mapper, for example calc dense node stage.\n                executeStages( nodeStage );\n                executeStages( calculateDenseNodesStage );\n            }\n            else\n            {   // The id mapper of choice doesn't need any preparation, so we can go ahead and execute\n                // the node and calc dende node stages in parallel.\n                executeStages( nodeStage, calculateDenseNodesStage );\n            }\n\n            // Stage 3 -- relationships, properties\n            final RelationshipStage relationshipStage =\n                    new RelationshipStage( input.relationships().iterator(), idMapper, neoStore, nodeRelationshipLink );\n\n            // execute stage 3\n            executeStages( relationshipStage );\n\n            // Switch to reverse updating mode\n            writerFactory.awaitEverythingWritten();\n            neoStore.switchToUpdateMode();\n\n            // Stage 4 -- set node nextRel fields\n            final NodeFirstRelationshipStage nodeFirstRelationshipStage =\n                    new NodeFirstRelationshipStage( neoStore, nodeRelationshipLink );\n\n            // execute stage 4\n            executeStages( nodeFirstRelationshipStage );\n\n            nodeRelationshipLink.clearRelationships();\n\n            // Stage 5 -- link relationship chains together\n            final RelationshipLinkbackStage relationshipLinkbackStage =\n                    new RelationshipLinkbackStage( neoStore, nodeRelationshipLink );\n\n            // execute stage 5\n            executeStages( relationshipLinkbackStage );\n\n            executionMonitor.done( currentTimeMillis() - startTime );\n        }\n        catch ( Throwable t )\n        {\n            logger.error( \"Error during import\", t );\n            throw Exceptions.launderedException( IOException.class, t );\n        }\n        finally\n        {\n            writerFactory.shutdown();\n        }\n\n        // TODO add import starts to this log message\n        logger.info( \"Import completed\" );\n    }","id":37876,"modified_method":"@Override\n    public void doImport( Input input ) throws IOException\n    {\n        logger.info( \"Import starting\" );\n\n        long startTime = currentTimeMillis();\n        try ( BatchingNeoStore neoStore = new BatchingNeoStore( fileSystem, storeDir, config,\n                writeMonitor, logging, monitors, writerFactory ) )\n        {\n            // Some temporary caches and indexes in the import\n            final IdMapping idMapping = input.idMapping();\n            final IdMapper idMapper = idMapping.idMapper();\n            final IdGenerator idGenerator = idMapping.idGenerator();\n            final NodeRelationshipLink nodeRelationshipLink =\n                    new NodeRelationshipLinkImpl( LongArrayFactory.AUTO, config.denseNodeThreshold() );\n            final ResourceIterable<InputNode> nodes = input.nodes();\n            final ResourceIterable<InputRelationship> relationships = input.relationships();\n\n            // Stage 1 -- nodes, properties, labels\n            final NodeStage nodeStage = new NodeStage( nodes, idMapper, idGenerator, neoStore );\n\n            // Stage 2 -- calculate dense node threshold\n            final CalculateDenseNodesStage calculateDenseNodesStage =\n                    new CalculateDenseNodesStage( relationships, nodeRelationshipLink, idMapper );\n\n            // Execute stages 1 and 2 in parallel or sequentially?\n            if ( idMapper.needsPreparation() )\n            {   // The id mapper of choice needs preparation in order to get ids from it,\n                // So we need to execute the node stage first as it fills the id mapper and prepares it in the end,\n                // before executing any stage that needs ids from the id mapper, for example calc dense node stage.\n                executeStages( nodeStage );\n                executeStages( calculateDenseNodesStage );\n            }\n            else\n            {   // The id mapper of choice doesn't need any preparation, so we can go ahead and execute\n                // the node and calc dende node stages in parallel.\n                executeStages( nodeStage, calculateDenseNodesStage );\n            }\n\n            // Stage 3 -- relationships, properties\n            final RelationshipStage relationshipStage =\n                    new RelationshipStage( relationships, idMapper, neoStore, nodeRelationshipLink );\n\n            // execute stage 3\n            executeStages( relationshipStage );\n\n            // Switch to reverse updating mode\n            writerFactory.awaitEverythingWritten();\n            neoStore.switchToUpdateMode();\n\n            // Stage 4 -- set node nextRel fields\n            final NodeFirstRelationshipStage nodeFirstRelationshipStage =\n                    new NodeFirstRelationshipStage( neoStore, nodeRelationshipLink );\n\n            // execute stage 4\n            executeStages( nodeFirstRelationshipStage );\n\n            nodeRelationshipLink.clearRelationships();\n\n            // Stage 5 -- link relationship chains together\n            final RelationshipLinkbackStage relationshipLinkbackStage =\n                    new RelationshipLinkbackStage( neoStore, nodeRelationshipLink );\n\n            // execute stage 5\n            executeStages( relationshipLinkbackStage );\n\n            executionMonitor.done( currentTimeMillis() - startTime );\n        }\n        catch ( Throwable t )\n        {\n            logger.error( \"Error during import\", t );\n            throw Exceptions.launderedException( IOException.class, t );\n        }\n        finally\n        {\n            writerFactory.shutdown();\n        }\n\n        // TODO add import starts to this log message\n        logger.info( \"Import completed\" );\n    }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"public RelationshipStage( ResourceIterator<InputRelationship> input, IdMapper idMapper,\n                BatchingNeoStore neoStore, NodeRelationshipLink nodeRelationshipLink )\n        {\n            super( logging, \"Relationships\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), input ) );\n\n            RelationshipStore relationshipStore = neoStore.getRelationshipStore();\n            PropertyStore propertyStore = neoStore.getPropertyStore();\n            add( new RelationshipEncoderStep( control(), \"ENCODER\", config.workAheadSize(), 1, idMapper,\n                    neoStore.getPropertyKeyRepository(), neoStore.getRelationshipTypeRepository(),\n                    relationshipStore, propertyStore, nodeRelationshipLink ) );\n            add( new EntityStoreUpdaterStep<>( control(), \"WRITER\", relationshipStore, propertyStore, writeMonitor ) );\n        }","id":37877,"modified_method":"public RelationshipStage( ResourceIterable<InputRelationship> relationships, IdMapper idMapper,\n                BatchingNeoStore neoStore, NodeRelationshipLink nodeRelationshipLink )\n        {\n            super( logging, \"Relationships\", config );\n            add( new IteratorBatcherStep<>( control(), \"INPUT\", config.batchSize(), relationships.iterator() ) );\n\n            RelationshipStore relationshipStore = neoStore.getRelationshipStore();\n            PropertyStore propertyStore = neoStore.getPropertyStore();\n            add( new RelationshipEncoderStep( control(), \"ENCODER\", config.workAheadSize(), 1, idMapper,\n                    neoStore.getPropertyKeyRepository(), neoStore.getRelationshipTypeRepository(),\n                    relationshipStore, propertyStore, nodeRelationshipLink ) );\n            add( new EntityStoreUpdaterStep<>( control(), \"WRITER\", relationshipStore, propertyStore, writeMonitor ) );\n        }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"@Test\n    public void shouldHandleGreatAmountsOfStuff() throws Exception\n    {\n        // GIVEN\n        IdMapper idMapper = new StringIdMapper( LongArrayFactory.AUTO );\n\n        // WHEN\n        int hundredThousands = 3;\n        long index = 0;\n        log( \"Putting...\" );\n        for ( long m = 0; m < hundredThousands; m++ )\n        {\n            for ( long i = 0; i < 100_000; i++, index++ )\n            {\n                String string = randomUUID();\n                idMapper.put( string, index );\n            }\n            log( \"put \" + m + \" million\" );\n        }\n        log( \"Sorting...\" );\n        idMapper.prepare();\n        MemoryStatsVisitor memoryStats = new GatheringMemoryStatsVisitor();\n        idMapper.visitMemoryStats( memoryStats );\n\n        // THEN\n        resetRandomness();\n        log( \"Reading...\" );\n        for ( long m = 0; m < hundredThousands; m++ )\n        {\n            for ( long i = 0; i < 100_000; i++, index++ )\n            {\n                // the UUIDs here will be generated in the same sequence as above because we reset the random\n                String string = randomUUID();\n                if ( idMapper.get( string ) == -1 )\n                {\n                    fail( \"Couldn't find \" + string + \" even though I added it just previously\" );\n                }\n            }\n            log( \"read \" + m + \" million\" );\n        }\n    }","id":37878,"modified_method":"@Test\n    public void shouldHandleGreatAmountsOfStuff() throws Exception\n    {\n        // GIVEN\n        IdMapper idMapper = new StringIdMapper( LongArrayFactory.AUTO );\n        Iterable<Object> ids = new Iterable<Object>()\n        {\n            @Override\n            public Iterator<Object> iterator()\n            {\n                resetRandomness();\n                return new PrefetchingIterator<Object>()\n                {\n                    private int i;\n\n                    @Override\n                    protected Object fetchNextOrNull()\n                    {\n                        return i++ < 300_000 ? randomUUID() : null;\n                    }\n                };\n            }\n        };\n\n        // WHEN\n        long index = 0;\n        for ( Object id : ids )\n        {\n            idMapper.put( id, index++ );\n        }\n        idMapper.prepare( ids );\n        MemoryStatsVisitor memoryStats = new GatheringMemoryStatsVisitor();\n        idMapper.visitMemoryStats( memoryStats );\n\n        // THEN\n        for ( Object id : ids )\n        {\n            // the UUIDs here will be generated in the same sequence as above because we reset the random\n            if ( idMapper.get( id ) == -1 )\n            {\n                fail( \"Couldn't find \" + id + \" even though I added it just previously\" );\n            }\n        }\n    }","commit_id":"85000682d0e18440ed3181420181ef6ee5361ddf","url":"https://github.com/neo4j/neo4j"},{"original_method":"protected void performRuntime(final OperationContext context, final ModelNode operation, final ModelNode model, final ServiceVerificationHandler verificationHandler, final List<ServiceController<?>> newControllers) throws OperationFailedException {\n        final String name = PathAddress.pathAddress(operation.get(ModelDescriptionConstants.ADDRESS)).getLastElement().getValue();\n\n        final Service<KeyGeneratorFactory> keyGeneratorFactory = getKeyGeneratorFactory(context, model);\n        final ServiceBuilder<KeyGeneratorFactory> factoryServiceBuilder = context.getServiceTarget().addService(getServiceName(name), keyGeneratorFactory)\n                .addDependency(KeyGeneratorFactoryRegistry.SERVICE_NAME, KeyGeneratorFactoryRegistry.class, KeyGeneratorFactoryRegistry.getRegistryInjector(name, keyGeneratorFactory))\n                .addListener(verificationHandler);\n        addDependencies(operation, keyGeneratorFactory, factoryServiceBuilder);\n\n        ModelNode jndiNode = AbstractKeyGeneratorResourceDescription.JNDI_NAME.resolveModelAttribute(context, model);\n\n        if (jndiNode.isDefined()) {\n            // Bind the KeyGeneratorFactory into JNDI\n            String jndiName = jndiNode.asString();\n\n            final ManagedReferenceFactory valueManagedReferenceFactory = new org.jboss.as.naming.ContextListAndJndiViewManagedReferenceFactory() {\n\n                @Override\n                public String getJndiViewInstanceValue() {\n                    return String.valueOf(getReference().getInstance());\n                }\n\n                @Override\n                public String getInstanceClassName() {\n                    final Object value = getReference().getInstance();\n                    return value != null ? value.getClass().getName() : org.jboss.as.naming.ContextListManagedReferenceFactory.DEFAULT_INSTANCE_CLASS_NAME;\n                }\n\n                @Override\n                public org.jboss.as.naming.ManagedReference getReference() {\n                    return new org.jboss.as.naming.ValueManagedReference(new org.jboss.msc.value.ImmediateValue<Object>(keyGeneratorFactory.getValue()));\n                }\n            };\n\n            final ContextNames.BindInfo bindInfo = ContextNames.bindInfoFor(jndiName);\n            final BinderService keyGenFactoryBinderService = new BinderService(bindInfo.getBindName());\n            final ServiceBuilder<ManagedReferenceFactory> keyGenFactoryBinderBuilder = context.getServiceTarget()\n                    .addService(bindInfo.getBinderServiceName(), keyGenFactoryBinderService)\n                    .addInjection(keyGenFactoryBinderService.getManagedObjectInjector(), valueManagedReferenceFactory)\n                    .addDependency(bindInfo.getParentContextServiceName(), ServiceBasedNamingStore.class, keyGenFactoryBinderService.getNamingStoreInjector());\n\n            newControllers.add(keyGenFactoryBinderBuilder.install());\n        }\n\n        newControllers.add(factoryServiceBuilder.install());\n    }","id":37879,"modified_method":"protected void performRuntime(final OperationContext context, final ModelNode operation, final ModelNode model, final ServiceVerificationHandler verificationHandler, final List<ServiceController<?>> newControllers) throws OperationFailedException {\n        final String name = PathAddress.pathAddress(operation.get(ModelDescriptionConstants.ADDRESS)).getLastElement().getValue();\n\n        final Service<KeyGeneratorFactory> keyGeneratorFactory = getKeyGeneratorFactory(context, model);\n        final ServiceBuilder<KeyGeneratorFactory> factoryServiceBuilder = context.getServiceTarget().addService(getServiceName(name), keyGeneratorFactory)\n                .addDependency(KeyGeneratorFactoryRegistry.SERVICE_NAME, KeyGeneratorFactoryRegistry.class, KeyGeneratorFactoryRegistry.getRegistryInjector(name, keyGeneratorFactory))\n                .addListener(verificationHandler);\n        addDependencies(operation, keyGeneratorFactory, factoryServiceBuilder);\n\n        ModelNode jndiNode = AbstractKeyGeneratorResourceDefinition.JNDI_NAME.resolveModelAttribute(context, model);\n\n        if (jndiNode.isDefined()) {\n            // Bind the KeyGeneratorFactory into JNDI\n            String jndiName = jndiNode.asString();\n\n            final ManagedReferenceFactory valueManagedReferenceFactory = new org.jboss.as.naming.ContextListAndJndiViewManagedReferenceFactory() {\n\n                @Override\n                public String getJndiViewInstanceValue() {\n                    return String.valueOf(getReference().getInstance());\n                }\n\n                @Override\n                public String getInstanceClassName() {\n                    final Object value = getReference().getInstance();\n                    return value != null ? value.getClass().getName() : org.jboss.as.naming.ContextListManagedReferenceFactory.DEFAULT_INSTANCE_CLASS_NAME;\n                }\n\n                @Override\n                public org.jboss.as.naming.ManagedReference getReference() {\n                    return new org.jboss.as.naming.ValueManagedReference(new org.jboss.msc.value.ImmediateValue<Object>(keyGeneratorFactory.getValue()));\n                }\n            };\n\n            final ContextNames.BindInfo bindInfo = ContextNames.bindInfoFor(jndiName);\n            final BinderService keyGenFactoryBinderService = new BinderService(bindInfo.getBindName());\n            final ServiceBuilder<ManagedReferenceFactory> keyGenFactoryBinderBuilder = context.getServiceTarget()\n                    .addService(bindInfo.getBinderServiceName(), keyGenFactoryBinderService)\n                    .addInjection(keyGenFactoryBinderService.getManagedObjectInjector(), valueManagedReferenceFactory)\n                    .addDependency(bindInfo.getParentContextServiceName(), ServiceBasedNamingStore.class, keyGenFactoryBinderService.getNamingStoreInjector());\n\n            newControllers.add(keyGenFactoryBinderBuilder.install());\n        }\n\n        newControllers.add(factoryServiceBuilder.install());\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void initialize(final ExtensionContext context) {\n        final SubsystemRegistration subsystem = context.registerSubsystem(SUBSYSTEM_NAME, MANAGEMENT_API_MAJOR_VERSION,\n                MANAGEMENT_API_MINOR_VERSION, MANAGEMENT_API_MICRO_VERSION);\n\n        final ManagementResourceRegistration subsystemRegistration = subsystem.registerSubsystemModel(CMPSubsystemRootResourceDescription.INSTANCE);\n        subsystemRegistration.registerOperationHandler(GenericSubsystemDescribeHandler.DEFINITION, GenericSubsystemDescribeHandler.INSTANCE);\n\n        subsystem.registerXMLElementWriter(CmpSubsystem11Parser.INSTANCE);\n\n        subsystemRegistration.registerSubModel(UUIDKeyGeneratorResourceDescription.INSTANCE);\n\n        subsystemRegistration.registerSubModel(HiLoKeyGeneratorResourceDescription.INSTANCE);\n    }","id":37880,"modified_method":"public void initialize(final ExtensionContext context) {\n        final SubsystemRegistration subsystem = context.registerSubsystem(SUBSYSTEM_NAME, MANAGEMENT_API_MAJOR_VERSION,\n                MANAGEMENT_API_MINOR_VERSION, MANAGEMENT_API_MICRO_VERSION);\n\n        final ManagementResourceRegistration subsystemRegistration = subsystem.registerSubsystemModel(CMPSubsystemRootResourceDefinition.INSTANCE);\n        subsystemRegistration.registerOperationHandler(GenericSubsystemDescribeHandler.DEFINITION, GenericSubsystemDescribeHandler.INSTANCE);\n\n        subsystem.registerXMLElementWriter(CmpSubsystem11Parser.INSTANCE);\n\n        subsystemRegistration.registerSubModel(UUIDKeyGeneratorResourceDefinition.INSTANCE);\n\n        subsystemRegistration.registerSubModel(HiLoKeyGeneratorResourceDefinition.INSTANCE);\n        registerTransformers(subsystem);\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"public static ResourceDescriptionResolver getResourceDescriptionResolver(final String keyPrefix) {\n        return new StandardResourceDescriptionResolver(keyPrefix, RESOURCE_NAME, CmpExtension.class.getClassLoader(), true, true);\n    }","id":37881,"modified_method":"public static ResourceDescriptionResolver getResolver(final String keyPrefix) {\n        return new StandardResourceDescriptionResolver(keyPrefix, RESOURCE_NAME, CmpExtension.class.getClassLoader(), true, true);\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected void standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        super.standardSubsystemTest(configId, false);\n    }","id":37882,"modified_method":"@Override\n    protected KernelServices standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        return super.standardSubsystemTest(configId, false);\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        return getSubsystemXml(\"subsystem-cmp-key-generators_1_0.xml\");\n    }","id":37883,"modified_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        return readResource(\"subsystem-cmp-key-generators_1_0.xml\");\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        return getSubsystemXml(\"subsystem-cmp-key-generators_1_1.xml\");\n    }","id":37884,"modified_method":"@Override\n    protected String getSubsystemXml() throws IOException {\n        return readResource(\"subsystem-cmp-key-generators_1_1.xml\");\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected void standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        super.standardSubsystemTest(configId, true);\n    }","id":37885,"modified_method":"@Override\n    protected KernelServices standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        return super.standardSubsystemTest(configId, true);\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected ModelNode parseUuid(final XMLExtendedStreamReader reader, final ModelNode parentAddress) throws XMLStreamException {\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = new ModelNode();\n        op.get(OP).set(ADD);\n        final ModelNode address = parentAddress.clone();\n        address.add(UUID_KEY_GENERATOR, name);\n        address.protect();\n        op.get(OP_ADDR).set(address);\n\n        requireNoContent(reader);\n        return op;\n    }","id":37886,"modified_method":"protected ModelNode parseUuid(final XMLExtendedStreamReader reader, final PathAddress parentAddress) throws XMLStreamException {\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = Util.createAddOperation(parentAddress.append(UUID_KEY_GENERATOR, name));\n        requireNoContent(reader);\n        return op;\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void writeHilo(final XMLExtendedStreamWriter writer, final String name, final ModelNode model) throws XMLStreamException {\n        writer.writeStartElement(Element.HILO.getLocalName());\n        writer.writeAttribute(Attribute.NAME.getLocalName(), name);\n        HiLoKeyGeneratorResourceDescription.JNDI_NAME.marshallAsAttribute(model, writer);\n\n        for(SimpleAttributeDefinition attribute : HiLoKeyGeneratorResourceDescription.ATTRIBUTES) {\n            if (!attribute.equals(HiLoKeyGeneratorResourceDescription.JNDI_NAME))\n                attribute.marshallAsElement(model, writer);\n        }\n        writer.writeEndElement();\n    }","id":37887,"modified_method":"private void writeHilo(final XMLExtendedStreamWriter writer, final String name, final ModelNode model) throws XMLStreamException {\n        writer.writeStartElement(Element.HILO.getLocalName());\n        writer.writeAttribute(Attribute.NAME.getLocalName(), name);\n        HiLoKeyGeneratorResourceDefinition.JNDI_NAME.marshallAsAttribute(model, writer);\n\n        for(SimpleAttributeDefinition attribute : HiLoKeyGeneratorResourceDefinition.ATTRIBUTES) {\n            if (!attribute.equals(HiLoKeyGeneratorResourceDefinition.JNDI_NAME))\n                attribute.marshallAsElement(model, writer);\n        }\n        writer.writeEndElement();\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void parseKeyGenerators(final XMLExtendedStreamReader reader, final List<ModelNode> operations, final ModelNode parentAddress) throws XMLStreamException {\n        requireNoAttributes(reader);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            switch (Element.forName(reader.getLocalName())) {\n                case UUID: {\n                    operations.add(parseUuid(reader, parentAddress));\n                    break;\n                }\n                case HILO: {\n                    operations.add(parseHilo(reader, parentAddress));\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }","id":37888,"modified_method":"private void parseKeyGenerators(final XMLExtendedStreamReader reader, final List<ModelNode> operations, final PathAddress parentAddress) throws XMLStreamException {\n        requireNoAttributes(reader);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            switch (Element.forName(reader.getLocalName())) {\n                case UUID: {\n                    operations.add(parseUuid(reader, parentAddress));\n                    break;\n                }\n                case HILO: {\n                    operations.add(parseHilo(reader, parentAddress));\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected ModelNode parseHilo(final XMLExtendedStreamReader reader, final ModelNode parentAddress) throws XMLStreamException {\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = new ModelNode();\n        op.get(OP).set(ADD);\n        final ModelNode address = parentAddress.clone();\n        address.add(HILO_KEY_GENERATOR, name);\n        address.protect();\n        op.get(OP_ADDR).set(address);\n        final EnumSet<Element> required = EnumSet.of(Element.DATA_SOURCE, Element.TABLE_NAME, Element.ID_COLUMN, Element.SEQUENCE_COLUMN, Element.SEQUENCE_NAME);\n\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final String value = reader.getElementText();\n            final String tag = reader.getLocalName();\n            final Element element = Element.forName(tag);\n            required.remove(element);\n\n            SimpleAttributeDefinition attribute = HiLoKeyGeneratorResourceDescription.ATTRIBUTE_MAP.get(tag);\n            if(attribute == null) {\n                throw unexpectedElement(reader);\n            }\n            attribute.parseAndSetParameter(value, op, reader);\n        }\n        if(!required.isEmpty()) {\n            throw missingRequiredElement(reader, required);\n        }\n        return op;\n    }","id":37889,"modified_method":"protected ModelNode parseHilo(final XMLExtendedStreamReader reader, final PathAddress parentAddress) throws XMLStreamException {\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = Util.createAddOperation(parentAddress.append(HILO_KEY_GENERATOR, name));\n        final EnumSet<Element> required = EnumSet.of(Element.DATA_SOURCE, Element.TABLE_NAME, Element.ID_COLUMN, Element.SEQUENCE_COLUMN, Element.SEQUENCE_NAME);\n\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final String value = reader.getElementText();\n            final String tag = reader.getLocalName();\n            final Element element = Element.forName(tag);\n            required.remove(element);\n\n            SimpleAttributeDefinition attribute = HiLoKeyGeneratorResourceDefinition.ATTRIBUTE_MAP.get(tag);\n            if(attribute == null) {\n                throw unexpectedElement(reader);\n            }\n            attribute.parseAndSetParameter(value, op, reader);\n        }\n        if(!required.isEmpty()) {\n            throw missingRequiredElement(reader, required);\n        }\n        return op;\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> operations) throws XMLStreamException {\n        final ModelNode address = new ModelNode();\n        address.add(SUBSYSTEM, CmpExtension.SUBSYSTEM_NAME);\n        address.protect();\n\n        requireNoAttributes(reader);\n        final ModelNode cmpSubsystem = new ModelNode();\n        cmpSubsystem.get(OP).set(ADD);\n        cmpSubsystem.get(OP_ADDR).set(address);\n        operations.add(cmpSubsystem);\n\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final Element element = Element.forName(reader.getLocalName());\n            switch (element) {\n                case KEY_GENERATORS: {\n                    this.parseKeyGenerators(reader, operations, address);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }","id":37890,"modified_method":"public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> operations) throws XMLStreamException {\n        final PathAddress address = PathAddress.EMPTY_ADDRESS.append(SUBSYSTEM, CmpExtension.SUBSYSTEM_NAME);\n\n        requireNoAttributes(reader);\n        final ModelNode cmpSubsystem = Util.createAddOperation(address);\n        operations.add(cmpSubsystem);\n\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final Element element = Element.forName(reader.getLocalName());\n            switch (element) {\n                case KEY_GENERATORS: {\n                    this.parseKeyGenerators(reader, operations, address);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"private void writeUuid(final XMLExtendedStreamWriter writer, final String name, final ModelNode model) throws XMLStreamException {\n        writer.writeStartElement(Element.UUID.getLocalName());\n        writer.writeAttribute(Attribute.NAME.getLocalName(), name);\n        UUIDKeyGeneratorResourceDescription.JNDI_NAME.marshallAsAttribute(model, writer);\n        writer.writeEndElement();\n    }","id":37891,"modified_method":"private void writeUuid(final XMLExtendedStreamWriter writer, final String name, final ModelNode model) throws XMLStreamException {\n        writer.writeStartElement(Element.UUID.getLocalName());\n        writer.writeAttribute(Attribute.NAME.getLocalName(), name);\n        UUIDKeyGeneratorResourceDefinition.JNDI_NAME.marshallAsAttribute(model, writer);\n        writer.writeEndElement();\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected ModelNode parseUuid(final XMLExtendedStreamReader reader, final ModelNode parentAddress) throws XMLStreamException {\n        String name = null;\n        String jndiname = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                case JNDI_NAME: {\n                    jndiname = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = new ModelNode();\n        op.get(OP).set(ADD);\n        final ModelNode address = parentAddress.clone();\n        address.add(UUID_KEY_GENERATOR, name);\n        address.protect();\n        op.get(OP_ADDR).set(address);\n\n        if (jndiname != null) {\n            UUIDKeyGeneratorResourceDescription.JNDI_NAME.parseAndSetParameter(jndiname, op, reader);\n        }\n        requireNoContent(reader);\n        return op;\n    }","id":37892,"modified_method":"@Override\n    protected ModelNode parseUuid(final XMLExtendedStreamReader reader, final PathAddress parentAddress) throws XMLStreamException {\n        final ModelNode op = Util.createAddOperation();\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                case JNDI_NAME: {\n                    UUIDKeyGeneratorResourceDefinition.JNDI_NAME.parseAndSetParameter(value, op, reader);\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        op.get(OP_ADDR).set(parentAddress.append(UUID_KEY_GENERATOR, name).toModelNode());\n\n        requireNoContent(reader);\n        return op;\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected ModelNode parseHilo(final XMLExtendedStreamReader reader, final ModelNode parentAddress) throws XMLStreamException {\n        String name = null;\n        String jndiname = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                case JNDI_NAME: {\n                    jndiname = value;\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        final ModelNode op = new ModelNode();\n        op.get(OP).set(ADD);\n        final ModelNode address = parentAddress.clone();\n        address.add(HILO_KEY_GENERATOR, name);\n        address.protect();\n        op.get(OP_ADDR).set(address);\n\n        if (jndiname != null) {\n            HiLoKeyGeneratorResourceDescription.JNDI_NAME.parseAndSetParameter(jndiname, op, reader);\n        }\n\n        final EnumSet<Element> required = EnumSet.of(Element.DATA_SOURCE, Element.TABLE_NAME, Element.ID_COLUMN, Element.SEQUENCE_COLUMN, Element.SEQUENCE_NAME);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final String value = reader.getElementText();\n            final String tag = reader.getLocalName();\n            final Element element = Element.forName(tag);\n            required.remove(element);\n\n            SimpleAttributeDefinition attribute = HiLoKeyGeneratorResourceDescription.ATTRIBUTE_MAP.get(tag);\n            if(attribute == null) {\n                throw unexpectedElement(reader);\n            }\n            attribute.parseAndSetParameter(value, op, reader);\n        }\n        if(!required.isEmpty()) {\n            throw missingRequiredElement(reader, required);\n        }\n        return op;\n    }","id":37893,"modified_method":"@Override\n    protected ModelNode parseHilo(final XMLExtendedStreamReader reader, final PathAddress parentAddress) throws XMLStreamException {\n        final ModelNode op = Util.createAddOperation();\n        String name = null;\n        int count = reader.getAttributeCount();\n        for (int i = 0; i < count; i++) {\n            requireNoNamespaceAttribute(reader, i);\n            final String value = reader.getAttributeValue(i);\n            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));\n            switch (attribute) {\n                case NAME: {\n                    name = value;\n                    break;\n                }\n                case JNDI_NAME: {\n                    HiLoKeyGeneratorResourceDefinition.JNDI_NAME.parseAndSetParameter(value, op, reader);\n                    break;\n                }\n                default:\n                    throw unexpectedAttribute(reader, i);\n            }\n        }\n        if (name == null) {\n            throw missingRequired(reader, Collections.singleton(Attribute.NAME));\n        }\n\n        op.get(OP_ADDR).set(parentAddress.append(HILO_KEY_GENERATOR, name).toModelNode());\n\n        final EnumSet<Element> required = EnumSet.of(Element.DATA_SOURCE, Element.TABLE_NAME, Element.ID_COLUMN, Element.SEQUENCE_COLUMN, Element.SEQUENCE_NAME);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            final String value = reader.getElementText();\n            final String tag = reader.getLocalName();\n            final Element element = Element.forName(tag);\n            required.remove(element);\n\n            SimpleAttributeDefinition attribute = HiLoKeyGeneratorResourceDefinition.ATTRIBUTE_MAP.get(tag);\n            if(attribute == null) {\n                throw unexpectedElement(reader);\n            }\n            attribute.parseAndSetParameter(value, op, reader);\n        }\n        if(!required.isEmpty()) {\n            throw missingRequiredElement(reader, required);\n        }\n        return op;\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected void populateModel(final ModelNode operation, final ModelNode model) throws OperationFailedException {\n        model.setEmptyObject();\n    }","id":37894,"modified_method":"protected void populateModel(final ModelNode operation, final ModelNode model) throws OperationFailedException {\n\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected void populateModel(final ModelNode operation, final ModelNode model) throws OperationFailedException {\n        for(AttributeDefinition attribute : HiLoKeyGeneratorResourceDescription.ATTRIBUTES) {\n            attribute.validateAndSet(operation, model);\n        }\n    }","id":37895,"modified_method":"protected void populateModel(final ModelNode operation, final ModelNode model) throws OperationFailedException {\n        for(AttributeDefinition attribute : HiLoKeyGeneratorResourceDefinition.ATTRIBUTES) {\n            attribute.validateAndSet(operation, model);\n        }\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected Service<KeyGeneratorFactory> getKeyGeneratorFactory(final OperationContext context, final ModelNode model)\n            throws OperationFailedException {\n        final HiLoKeyGeneratorFactory factory = new HiLoKeyGeneratorFactory();\n\n        ModelNode node;\n        if ((node = HiLoKeyGeneratorResourceDescription.BLOCK_SIZE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setBlockSize(node.asLong());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.CREATE_TABLE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setCreateTable(node.asBoolean());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.CREATE_TABLE_DDL.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setCreateTableDdl(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.DROP_TABLE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setDropTable(node.asBoolean());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.ID_COLUMN.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setIdColumnName(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.SELECT_HI_DDL.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSelectHiSql(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.SEQUENCE_COLUMN.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSequenceColumn(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.SEQUENCE_NAME.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSequenceName(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDescription.TABLE_NAME.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setTableName(node.asString());\n        }\n        return factory;\n    }","id":37896,"modified_method":"protected Service<KeyGeneratorFactory> getKeyGeneratorFactory(final OperationContext context, final ModelNode model)\n            throws OperationFailedException {\n        final HiLoKeyGeneratorFactory factory = new HiLoKeyGeneratorFactory();\n\n        ModelNode node;\n        if ((node = HiLoKeyGeneratorResourceDefinition.BLOCK_SIZE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setBlockSize(node.asLong());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.CREATE_TABLE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setCreateTable(node.asBoolean());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.CREATE_TABLE_DDL.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setCreateTableDdl(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.DROP_TABLE.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setDropTable(node.asBoolean());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.ID_COLUMN.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setIdColumnName(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.SELECT_HI_DDL.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSelectHiSql(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.SEQUENCE_COLUMN.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSequenceColumn(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.SEQUENCE_NAME.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setSequenceName(node.asString());\n        }\n        if ((node = HiLoKeyGeneratorResourceDefinition.TABLE_NAME.resolveModelAttribute(context, model)).isDefined()) {\n            factory.setTableName(node.asString());\n        }\n        return factory;\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"protected void populateModel(ModelNode operation, ModelNode model) throws OperationFailedException {\n        for(AttributeDefinition attribute : UUIDKeyGeneratorResourceDescription.ATTRIBUTES) {\n            attribute.validateAndSet(operation, model);\n        }\n    }","id":37897,"modified_method":"protected void populateModel(ModelNode operation, ModelNode model) throws OperationFailedException {\n        for(AttributeDefinition attribute : UUIDKeyGeneratorResourceDefinition.ATTRIBUTES) {\n            attribute.validateAndSet(operation, model);\n        }\n    }","commit_id":"ad0291d2945429065f2efd6490e202c98606c68d","url":"https://github.com/wildfly/wildfly"},{"original_method":"/**\n     * Tests the ability to create a model from an xml configuration, marshal the model back to xml,\n     * re-read that marshalled model into a new model that matches the first one, execute a \"describe\"\n     * operation for the model, create yet another model from executing the results of that describe\n     * operation, and compare that model to first model.\n     *\n     * @param configId  id to pass to {@link #getSubsystemXml(String)} to get the configuration; if {@code null}\n     *                  {@link #getSubsystemXml()} will be called\n     *\n     * @param compareXml if {@code true} a comparison of xml output to original input is performed. This can be\n     *                   set to {@code false} if the original input is from an earlier xsd and the current\n     *                   schema has a different output\n     *\n     * @throws Exception\n     */\n    protected void standardSubsystemTest(final String configId, boolean compareXml) throws Exception {\n        final AdditionalInitialization additionalInit = createAdditionalInitialization();\n\n        // Parse the subsystem xml and install into the first controller\n        final String subsystemXml = configId == null ? getSubsystemXml() : getSubsystemXml(configId);\n        final KernelServices servicesA = super.createKernelServicesBuilder(additionalInit).setSubsystemXml(subsystemXml).build();\n        Assert.assertTrue(\"Subsystem boot failed!\",servicesA.isSuccessfulBoot());\n        //Get the model and the persisted xml from the first controller\n        final ModelNode modelA = servicesA.readWholeModel();\n        validateModel(modelA);\n\n        // Test marshaling\n        final String marshalled = servicesA.getPersistedSubsystemXml();\n        servicesA.shutdown();\n\n\n        // validate the the normalized xmls\n        String normalizedSubsystem = normalizeXML(subsystemXml);\n\n        if (compareXml) {\n            compareXml(configId, normalizedSubsystem, normalizeXML(marshalled));\n        }\n\n        //Install the persisted xml from the first controller into a second controller\n        final KernelServices servicesB = super.createKernelServicesBuilder(additionalInit).setSubsystemXml(marshalled).build();\n        final ModelNode modelB = servicesB.readWholeModel();\n\n        //Make sure the models from the two controllers are identical\n        compare(modelA, modelB);\n\n        // Test the describe operation\n        final ModelNode operation = createDescribeOperation();\n        final ModelNode result = servicesB.executeOperation(operation);\n        Assert.assertTrue(\"the subsystem describe operation has to generate a list of operations to recreate the subsystem\",\n                !result.hasDefined(ModelDescriptionConstants.FAILURE_DESCRIPTION));\n        final List<ModelNode> operations = result.get(ModelDescriptionConstants.RESULT).asList();\n        servicesB.shutdown();\n\n        final KernelServices servicesC = super.createKernelServicesBuilder(additionalInit).setBootOperations(operations).build();\n        final ModelNode modelC = servicesC.readWholeModel();\n\n        compare(modelA, modelC);\n\n        assertRemoveSubsystemResources(servicesC, getIgnoredChildResourcesForRemovalTest());\n    }","id":37898,"modified_method":"/**\n     * Tests the ability to create a model from an xml configuration, marshal the model back to xml,\n     * re-read that marshalled model into a new model that matches the first one, execute a \"describe\"\n     * operation for the model, create yet another model from executing the results of that describe\n     * operation, and compare that model to first model.\n     *\n     * @param configId  id to pass to {@link #getSubsystemXml(String)} to get the configuration; if {@code null}\n     *                  {@link #getSubsystemXml()} will be called\n     *\n     * @param compareXml if {@code true} a comparison of xml output to original input is performed. This can be\n     *                   set to {@code false} if the original input is from an earlier xsd and the current\n     *                   schema has a different output\n     *\n     * @throws Exception\n     */\n    protected KernelServices standardSubsystemTest(final String configId, boolean compareXml) throws Exception {\n        final AdditionalInitialization additionalInit = createAdditionalInitialization();\n\n        // Parse the subsystem xml and install into the first controller\n        final String subsystemXml = configId == null ? getSubsystemXml() : getSubsystemXml(configId);\n        final KernelServices servicesA = super.createKernelServicesBuilder(additionalInit).setSubsystemXml(subsystemXml).build();\n        Assert.assertTrue(\"Subsystem boot failed!\",servicesA.isSuccessfulBoot());\n        //Get the model and the persisted xml from the first controller\n        final ModelNode modelA = servicesA.readWholeModel();\n        validateModel(modelA);\n\n        // Test marshaling\n        final String marshalled = servicesA.getPersistedSubsystemXml();\n        servicesA.shutdown();\n\n\n        // validate the the normalized xmls\n        String normalizedSubsystem = normalizeXML(subsystemXml);\n\n        if (compareXml) {\n            compareXml(configId, normalizedSubsystem, normalizeXML(marshalled));\n        }\n\n        //Install the persisted xml from the first controller into a second controller\n        final KernelServices servicesB = super.createKernelServicesBuilder(additionalInit).setSubsystemXml(marshalled).build();\n        final ModelNode modelB = servicesB.readWholeModel();\n\n        //Make sure the models from the two controllers are identical\n        compare(modelA, modelB);\n\n        // Test the describe operation\n        final ModelNode operation = createDescribeOperation();\n        final ModelNode result = servicesB.executeOperation(operation);\n        Assert.assertTrue(\"the subsystem describe operation has to generate a list of operations to recreate the subsystem\",\n                !result.hasDefined(ModelDescriptionConstants.FAILURE_DESCRIPTION));\n        final List<ModelNode> operations = result.get(ModelDescriptionConstants.RESULT).asList();\n        servicesB.shutdown();\n\n        final KernelServices servicesC = super.createKernelServicesBuilder(additionalInit).setBootOperations(operations).build();\n        final ModelNode modelC = servicesC.readWholeModel();\n\n        compare(modelA, modelC);\n\n        assertRemoveSubsystemResources(servicesC, getIgnoredChildResourcesForRemovalTest());\n        return servicesA;\n    }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n    protected void standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        super.standardSubsystemTest(configId, false);\n    }","id":37899,"modified_method":"@Override\n    protected KernelServices standardSubsystemTest(String configId, boolean compareXml) throws Exception {\n        return super.standardSubsystemTest(configId, false);\n    }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"private ModelNode internalTransform(ModelNode model, String name) {\n            model = model.clone();\n            if (model.hasDefined(name) && model.get(name).getType() != ModelType.EXPRESSION) {\n                long rounded = Math.round(model.get(name).asDouble());\n                if (rounded > Integer.MAX_VALUE) {\n                    throw ModClusterMessages.MESSAGES.capacityIsGreaterThanIntegerMaxValue(rounded);\n                }\n                model.get(name).set((int)rounded);\n            }\n            return fixProperties(model);\n        }","id":37900,"modified_method":"private ModelNode internalTransform(ModelNode model) {\n            model = model.clone();\n            transformCapacity(model.get(CAPACITY.getName()));\n            transformProperties(model.get(LoadMetricDefinition.PROPERTY.getName()));\n            return model;\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"OperationTransformer getWriteAttributeTransformer() {\n            return new OperationTransformer() {\n                @Override\n                public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation)\n                        throws OperationFailedException {\n                    return internalTransformOperation(operation, VALUE);\n                }\n            };\n        }","id":37901,"modified_method":"OperationTransformer getWriteAttributeTransformer() {\n            return new OperationTransformer() {\n                @Override\n                public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation)\n                        throws OperationFailedException {\n                    ModelNode transformed = operation.get(VALUE);\n                    String name = operation.get(NAME).asString();\n                    if (name.equals(PROPERTY.getName())) {\n                        transformProperties(transformed);\n                    } else if (name.equals(CAPACITY.getName())) {\n                        transformCapacity(transformed);\n                    }\n                    return new TransformedOperation(transformed, OperationResultTransformer.ORIGINAL_RESULT);\n                }\n            };\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n        public void transformResource(ChainedResourceTransformationContext context, PathAddress address, Resource resource)\n                throws OperationFailedException {\n            resource.writeModel(internalTransform(resource.getModel(), CAPACITY.getName()));\n        }","id":37902,"modified_method":"@Override\n        public void transformResource(ChainedResourceTransformationContext context, PathAddress address, Resource resource)\n                throws OperationFailedException {\n            resource.writeModel(internalTransform(resource.getModel()));\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"private TransformedOperation internalTransformOperation(ModelNode operation, String name) {\n            return new TransformedOperation(internalTransform(operation, name), OperationResultTransformer.ORIGINAL_RESULT);\n        }","id":37903,"modified_method":"private TransformedOperation internalTransformOperation(ModelNode operation) {\n            return new TransformedOperation(internalTransform(operation), OperationResultTransformer.ORIGINAL_RESULT);\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Override\n        public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation)\n                throws OperationFailedException {\n            return internalTransformOperation(operation, CAPACITY.getName());\n        }","id":37904,"modified_method":"@Override\n        public TransformedOperation transformOperation(TransformationContext context, PathAddress address, ModelNode operation) throws OperationFailedException {\n            return internalTransformOperation(operation);\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"private ModelNode fixProperties(ModelNode model) {\n            ModelNode fixed = model.clone();\n            ModelNode modelProps = model.get(LoadMetricDefinition.PROPERTY.getName());\n            if (modelProps.isDefined()) {\n                for (Property p : modelProps.asPropertyList()) {//legacy was broken, only one property can be passed trough\n                    fixed.get(LoadMetricDefinition.PROPERTY.getName()).set(p.getName(), p.getValue().asString());\n                }\n            }\n            return fixed;\n        }","id":37905,"modified_method":"private void transformProperties(ModelNode model) {\n            if (model.isDefined()) {\n                for (Property p : model.asPropertyList()) {//legacy was broken, only one property can be passed trough\n                    model.set(p.getName(), p.getValue().asString());\n                }\n            }\n        }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    public void testExpressionsAreRejectedByVersion_1_2() throws Exception {\n        String subsystemXml = readResource(\"subsystem.xml\");\n        ModelVersion modelVersion = ModelVersion.create(1, 2, 0);\n        KernelServicesBuilder builder = createKernelServicesBuilder(createAdditionalInitialization());\n\n        builder.createLegacyKernelServicesBuilder(null, modelVersion)\n        .addMavenResourceURL(\"org.jboss.as:jboss-as-modcluster:7.1.2.Final\");\n\n        KernelServices mainServices = builder.build();\n        KernelServices legacyServices = mainServices.getLegacyServices(modelVersion);\n        Assert.assertNotNull(legacyServices);\n        Assert.assertTrue(mainServices.isSuccessfulBoot());\n        Assert.assertTrue(legacyServices.isSuccessfulBoot());\n\n        PathAddress rootAddr = PathAddress.pathAddress(PathElement.pathElement(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME));\n        PathAddress confAddr = rootAddr.append(PathElement.pathElement(CommonAttributes.MOD_CLUSTER_CONFIG, CommonAttributes.CONFIGURATION));\n        PathAddress simpAddr = confAddr.append(PathElement.pathElement(CommonAttributes.SIMPLE_LOAD_PROVIDER_FACTOR, CommonAttributes.CONFIGURATION));\n        PathAddress dynaAddr = confAddr.append(PathElement.pathElement(CommonAttributes.DYNAMIC_LOAD_PROVIDER, CommonAttributes.CONFIGURATION));\n        PathAddress metrAddr = dynaAddr.append(PathElement.pathElement(CommonAttributes.LOAD_METRIC, \"*\"));\n        PathAddress custAddr = dynaAddr.append(PathElement.pathElement(CommonAttributes.CUSTOM_LOAD_METRIC, \"*\"));\n        PathAddress sslAddr = confAddr.append(PathElement.pathElement(CommonAttributes.SSL, CommonAttributes.CONFIGURATION));\n        ModelTestUtils.checkFailedTransformedBootOperations(mainServices, modelVersion, parse(subsystemXml),\n                new FailedOperationTransformationConfig()\n                    .addFailedAttribute(metrAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.CAPACITY, CommonAttributes.WEIGHT\n                                    ))\n                     .addFailedAttribute(custAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.CAPACITY, CommonAttributes.WEIGHT,\n                                    CommonAttributes.CLASS))\n                    .addFailedAttribute(dynaAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.DECAY, CommonAttributes.HISTORY))\n                     .addFailedAttribute(simpAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.FACTOR))\n                     .addFailedAttribute(sslAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(\n                                    CommonAttributes.CIPHER_SUITE, CommonAttributes.KEY_ALIAS,\n                                    CommonAttributes.PROTOCOL))\n                    .addFailedAttribute(confAddr,\n                            new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.ADVERTISE,\n                                    CommonAttributes.ADVERTISE_SOCKET, CommonAttributes.ADVERTISE_SOCKET,\n                                    CommonAttributes.AUTO_ENABLE_CONTEXTS, CommonAttributes.FLUSH_PACKETS,\n                                    CommonAttributes.PING,\n                                    CommonAttributes.STICKY_SESSION, CommonAttributes.STICKY_SESSION_FORCE, CommonAttributes.STICKY_SESSION_REMOVE\n                                    ))\n                    );\n    }","id":37906,"modified_method":"@Test\n    public void testExpressionsAreRejectedByVersion_1_2() throws Exception {\n        String subsystemXml = readResource(\"subsystem.xml\");\n        ModelVersion modelVersion = ModelVersion.create(1, 2, 0);\n        KernelServicesBuilder builder = createKernelServicesBuilder(createAdditionalInitialization());\n\n        builder.createLegacyKernelServicesBuilder(null, modelVersion)\n                .addMavenResourceURL(\"org.jboss.as:jboss-as-modcluster:7.1.2.Final\");\n\n        KernelServices mainServices = builder.build();\n        KernelServices legacyServices = mainServices.getLegacyServices(modelVersion);\n        Assert.assertNotNull(legacyServices);\n        Assert.assertTrue(mainServices.isSuccessfulBoot());\n        Assert.assertTrue(legacyServices.isSuccessfulBoot());\n\n        PathAddress rootAddr = PathAddress.pathAddress(PathElement.pathElement(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME));\n        PathAddress confAddr = rootAddr.append(PathElement.pathElement(MOD_CLUSTER_CONFIG, CONFIGURATION));\n        PathAddress simpAddr = confAddr.append(PathElement.pathElement(CommonAttributes.SIMPLE_LOAD_PROVIDER_FACTOR, CONFIGURATION));\n        PathAddress dynaAddr = confAddr.append(PathElement.pathElement(CommonAttributes.DYNAMIC_LOAD_PROVIDER, CONFIGURATION));\n        PathAddress metrAddr = dynaAddr.append(PathElement.pathElement(CommonAttributes.LOAD_METRIC, \"*\"));\n        PathAddress custAddr = dynaAddr.append(PathElement.pathElement(CommonAttributes.CUSTOM_LOAD_METRIC, \"*\"));\n        PathAddress sslAddr = confAddr.append(PathElement.pathElement(CommonAttributes.SSL, CONFIGURATION));\n        ModelTestUtils.checkFailedTransformedBootOperations(mainServices, modelVersion, parse(subsystemXml),\n                new FailedOperationTransformationConfig()\n                        .addFailedAttribute(metrAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.CAPACITY, CommonAttributes.WEIGHT\n                                ))\n                        .addFailedAttribute(custAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.CAPACITY, CommonAttributes.WEIGHT,\n                                        CommonAttributes.CLASS))\n                        .addFailedAttribute(dynaAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.DECAY, CommonAttributes.HISTORY))\n                        .addFailedAttribute(simpAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.FACTOR))\n                        .addFailedAttribute(sslAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(\n                                        CommonAttributes.CIPHER_SUITE, CommonAttributes.KEY_ALIAS,\n                                        CommonAttributes.PROTOCOL))\n                        .addFailedAttribute(confAddr,\n                                new FailedOperationTransformationConfig.RejectExpressionsConfig(CommonAttributes.ADVERTISE,\n                                        CommonAttributes.ADVERTISE_SOCKET, CommonAttributes.ADVERTISE_SOCKET,\n                                        CommonAttributes.AUTO_ENABLE_CONTEXTS, CommonAttributes.FLUSH_PACKETS,\n                                        CommonAttributes.PING,\n                                        CommonAttributes.STICKY_SESSION, CommonAttributes.STICKY_SESSION_FORCE, CommonAttributes.STICKY_SESSION_REMOVE\n                                ))\n        );\n    }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@Test\n    public void testTransformers_1_2_0() throws Exception {\n        String subsystemXml = readResource(\"subsystem-no-expressions.xml\");\n        ModelVersion modelVersion = ModelVersion.create(1, 2, 0);\n        KernelServicesBuilder builder = createKernelServicesBuilder(createAdditionalInitialization())\n                .setSubsystemXml(subsystemXml);\n\n        builder.createLegacyKernelServicesBuilder(null, modelVersion)\n        .addMavenResourceURL(\"org.jboss.as:jboss-as-modcluster:7.1.2.Final\");\n\n        KernelServices mainServices = builder.build();\n        KernelServices legacyServices = mainServices.getLegacyServices(modelVersion);\n        Assert.assertNotNull(legacyServices);\n        Assert.assertTrue(mainServices.isSuccessfulBoot());\n        Assert.assertTrue(legacyServices.isSuccessfulBoot());\n\n        ModelNode legacySubsystem = checkSubsystemModelTransformation(mainServices, modelVersion, new ModelFixer() {\n            @Override\n            public ModelNode fixModel(ModelNode modelNode) {\n                ModelNode loadMetrics = modelNode.get(CommonAttributes.MOD_CLUSTER_CONFIG, CommonAttributes.CONFIGURATION, CommonAttributes.DYNAMIC_LOAD_PROVIDER, CommonAttributes.CONFIGURATION, CommonAttributes.LOAD_METRIC);\n                for (String key : loadMetrics.keys()) {\n                    ModelNode capacity = loadMetrics.get(key, CommonAttributes.CAPACITY);\n                    if (capacity.getType() == ModelType.DOUBLE && capacity.asString().equals(\"1.0\")) {\n                        //There is a bug in 7.1.2 where this attribute is of type int, but its default is a double with value = 1.0\n                        capacity.set(1);\n                    }\n                }\n                return modelNode;\n            }\n        });\n\n        ModelNode mainSessionCapacity = mainServices.readWholeModel().get(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME, CommonAttributes.MOD_CLUSTER_CONFIG, CommonAttributes.CONFIGURATION,\n                CommonAttributes.DYNAMIC_LOAD_PROVIDER, CommonAttributes.CONFIGURATION, CommonAttributes.LOAD_METRIC, \"sessions\", CommonAttributes.CAPACITY);\n        ModelNode legacySessionCapacity = legacySubsystem.get(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME, CommonAttributes.MOD_CLUSTER_CONFIG, CommonAttributes.CONFIGURATION,\n                CommonAttributes.DYNAMIC_LOAD_PROVIDER, CommonAttributes.CONFIGURATION, CommonAttributes.LOAD_METRIC, \"sessions\", CommonAttributes.CAPACITY);\n        Assert.assertEquals(ModelType.DOUBLE, mainSessionCapacity.getType());\n        Assert.assertEquals(ModelType.INT, legacySessionCapacity.getType());\n        Assert.assertFalse(mainSessionCapacity.asString().equals(legacySessionCapacity.asString()));\n        Assert.assertEquals(mainSessionCapacity.asInt(), legacySessionCapacity.asInt());\n    }","id":37907,"modified_method":"@Test\n    public void testTransformers_1_2_0() throws Exception {\n        String subsystemXml = readResource(\"subsystem-no-expressions.xml\");\n        ModelVersion modelVersion = ModelVersion.create(1, 2, 0);\n        KernelServicesBuilder builder = createKernelServicesBuilder(createAdditionalInitialization())\n                .setSubsystemXml(subsystemXml);\n\n        builder.createLegacyKernelServicesBuilder(null, modelVersion)\n                .addMavenResourceURL(\"org.jboss.as:jboss-as-modcluster:7.1.2.Final\");\n\n        KernelServices mainServices = builder.build();\n        KernelServices legacyServices = mainServices.getLegacyServices(modelVersion);\n        Assert.assertNotNull(legacyServices);\n        Assert.assertTrue(mainServices.isSuccessfulBoot());\n        Assert.assertTrue(legacyServices.isSuccessfulBoot());\n\n        ModelNode legacySubsystem = checkSubsystemModelTransformation(mainServices, modelVersion, new ModelFixer() {\n            @Override\n            public ModelNode fixModel(ModelNode modelNode) {\n                ModelNode loadMetrics = modelNode.get(MOD_CLUSTER_CONFIG, CONFIGURATION, CommonAttributes.DYNAMIC_LOAD_PROVIDER, CONFIGURATION, CommonAttributes.LOAD_METRIC);\n                for (String key : loadMetrics.keys()) {\n                    ModelNode capacity = loadMetrics.get(key, CommonAttributes.CAPACITY);\n                    if (capacity.getType() == ModelType.DOUBLE && capacity.asString().equals(\"1.0\")) {\n                        //There is a bug in 7.1.2 where this attribute is of type int, but its default is a double with value = 1.0\n                        capacity.set(1);\n                    }\n                }\n                return modelNode;\n            }\n        });\n\n        ModelNode mainSessionCapacity = mainServices.readWholeModel().get(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME, MOD_CLUSTER_CONFIG, CONFIGURATION,\n                CommonAttributes.DYNAMIC_LOAD_PROVIDER, CONFIGURATION, CommonAttributes.LOAD_METRIC, \"sessions\", CommonAttributes.CAPACITY);\n        ModelNode legacySessionCapacity = legacySubsystem.get(SUBSYSTEM, ModClusterExtension.SUBSYSTEM_NAME, MOD_CLUSTER_CONFIG, CONFIGURATION,\n                CommonAttributes.DYNAMIC_LOAD_PROVIDER, CONFIGURATION, CommonAttributes.LOAD_METRIC, \"sessions\", CommonAttributes.CAPACITY);\n        Assert.assertEquals(ModelType.DOUBLE, mainSessionCapacity.getType());\n        Assert.assertEquals(ModelType.INT, legacySessionCapacity.getType());\n        Assert.assertFalse(mainSessionCapacity.asString().equals(legacySessionCapacity.asString()));\n        Assert.assertEquals(mainSessionCapacity.asInt(), legacySessionCapacity.asInt());\n    }","commit_id":"4d68ccec7d69a6684ea886bac7d6e4d28bc25638","url":"https://github.com/wildfly/wildfly"},{"original_method":"@NotNull\n    public static LookupElement createLookupElement(@NotNull BindingContext bindingContext, @NotNull DeclarationDescriptor descriptor) {\n        if (descriptor instanceof CallableMemberDescriptor) {\n            CallableMemberDescriptor callableMemberDescriptor = (CallableMemberDescriptor) descriptor;\n            while (callableMemberDescriptor.getKind() == CallableMemberDescriptor.Kind.FAKE_OVERRIDE) {\n                // TODO: need to know all of them\n                callableMemberDescriptor = callableMemberDescriptor.getOverriddenDescriptors().iterator().next();\n            }\n            descriptor = callableMemberDescriptor;\n        }\n        return createLookupElement(bindingContext, descriptor, BindingContextUtils.descriptorToDeclaration(bindingContext, descriptor));\n    }","id":37908,"modified_method":"@NotNull\n    public static LookupElement createLookupElement(\n            @NotNull ResolveSession resolveSession,\n            @NotNull BindingContext bindingContext,\n            @NotNull DeclarationDescriptor descriptor) {\n        if (descriptor instanceof CallableMemberDescriptor) {\n            CallableMemberDescriptor callableMemberDescriptor = (CallableMemberDescriptor) descriptor;\n            while (callableMemberDescriptor.getKind() == CallableMemberDescriptor.Kind.FAKE_OVERRIDE) {\n                // TODO: need to know all of them\n                callableMemberDescriptor = callableMemberDescriptor.getOverriddenDescriptors().iterator().next();\n            }\n            descriptor = callableMemberDescriptor;\n        }\n        return createLookupElement(resolveSession, descriptor, BindingContextUtils.descriptorToDeclaration(bindingContext, descriptor));\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public static LookupElement[] collectLookupElements(BindingContext bindingContext, Iterable<DeclarationDescriptor> descriptors) {\n        List<LookupElement> result = Lists.newArrayList();\n\n        for (final DeclarationDescriptor descriptor : descriptors) {\n            result.add(createLookupElement(bindingContext, descriptor));\n        }\n\n        return result.toArray(new LookupElement[result.size()]);\n    }","id":37909,"modified_method":"public static LookupElement[] collectLookupElements(\n            @NotNull ResolveSession resolveSession,\n            @NotNull BindingContext bindingContext,\n            @NotNull Iterable<DeclarationDescriptor> descriptors) {\n        List<LookupElement> result = Lists.newArrayList();\n\n        for (final DeclarationDescriptor descriptor : descriptors) {\n            result.add(createLookupElement(resolveSession, bindingContext, descriptor));\n        }\n\n        return result.toArray(new LookupElement[result.size()]);\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    public static LookupElement createLookupElement(@NotNull BindingContext bindingContext,\n            @NotNull DeclarationDescriptor descriptor, @Nullable PsiElement declaration) {\n\n        LookupElementBuilder element = LookupElementBuilder.create(\n                new JetLookupObject(descriptor, bindingContext, declaration), descriptor.getName().getName());\n\n        String presentableText = descriptor.getName().getName();\n        String typeText = \"\";\n        String tailText = \"\";\n        boolean tailTextGrayed = true;\n\n        if (descriptor instanceof FunctionDescriptor) {\n            FunctionDescriptor functionDescriptor = (FunctionDescriptor) descriptor;\n            JetType returnType = functionDescriptor.getReturnType();\n            typeText = DescriptorRenderer.TEXT.renderType(returnType);\n            presentableText += DescriptorRenderer.TEXT.renderFunctionParameters(functionDescriptor);\n\n            boolean extensionFunction = functionDescriptor.getReceiverParameter().exists();\n            DeclarationDescriptor containingDeclaration = descriptor.getContainingDeclaration();\n            if (containingDeclaration != null && extensionFunction) {\n                tailText += \" for \" + DescriptorRenderer.TEXT.renderType(functionDescriptor.getReceiverParameter().getType());\n                tailText += \" in \" + DescriptorUtils.getFQName(containingDeclaration);\n            }\n\n            // TODO: A special case when it's impossible to resolve type parameters from arguments. Need '<' caret '>'\n            // TODO: Support omitting brackets for one argument functions\n            if (functionDescriptor.getValueParameters().isEmpty()) {\n                element = element.setInsertHandler(EMPTY_FUNCTION_HANDLER);\n            }\n            else {\n                if (functionDescriptor.getValueParameters().size() == 1\n                        && JetStandardClasses.isFunctionType(functionDescriptor.getValueParameters().get(0).getType())) {\n                    element = element.setInsertHandler(PARAMS_BRACES_FUNCTION_HANDLER);\n                } else {\n                    element = element.setInsertHandler(PARAMS_PARENTHESIS_FUNCTION_HANDLER);\n                }\n            }\n        }\n        else if (descriptor instanceof VariableDescriptor) {\n            JetType outType = ((VariableDescriptor) descriptor).getType();\n            typeText = DescriptorRenderer.TEXT.renderType(outType);\n        }\n        else if (descriptor instanceof ClassDescriptor) {\n            DeclarationDescriptor declaredIn = descriptor.getContainingDeclaration();\n            assert declaredIn != null;\n            tailText = \" (\" + DescriptorUtils.getFQName(declaredIn) + \")\";\n            tailTextGrayed = true;\n            element = element.setInsertHandler(JetClassInsertHandler.INSTANCE);\n        }\n        else {\n            typeText = DescriptorRenderer.TEXT.render(descriptor);\n        }\n\n        element = element.setTailText(tailText, tailTextGrayed).setTypeText(typeText).setPresentableText(presentableText);\n        element = element.setIcon(JetDescriptorIconProvider.getIcon(descriptor, Iconable.ICON_FLAG_VISIBILITY));\n\n        return element;\n    }","id":37910,"modified_method":"@NotNull\n    public static LookupElement createLookupElement(@NotNull ResolveSession resolveSession,\n            @NotNull DeclarationDescriptor descriptor, @Nullable PsiElement declaration) {\n\n        LookupElementBuilder element = LookupElementBuilder.create(\n                new JetLookupObject(descriptor, resolveSession, declaration), descriptor.getName().getName());\n\n        String presentableText = descriptor.getName().getName();\n        String typeText = \"\";\n        String tailText = \"\";\n        boolean tailTextGrayed = true;\n\n        if (descriptor instanceof FunctionDescriptor) {\n            FunctionDescriptor functionDescriptor = (FunctionDescriptor) descriptor;\n            JetType returnType = functionDescriptor.getReturnType();\n            typeText = DescriptorRenderer.TEXT.renderType(returnType);\n            presentableText += DescriptorRenderer.TEXT.renderFunctionParameters(functionDescriptor);\n\n            boolean extensionFunction = functionDescriptor.getReceiverParameter().exists();\n            DeclarationDescriptor containingDeclaration = descriptor.getContainingDeclaration();\n            if (containingDeclaration != null && extensionFunction) {\n                tailText += \" for \" + DescriptorRenderer.TEXT.renderType(functionDescriptor.getReceiverParameter().getType());\n                tailText += \" in \" + DescriptorUtils.getFQName(containingDeclaration);\n            }\n\n            // TODO: A special case when it's impossible to resolve type parameters from arguments. Need '<' caret '>'\n            // TODO: Support omitting brackets for one argument functions\n            if (functionDescriptor.getValueParameters().isEmpty()) {\n                element = element.withInsertHandler(EMPTY_FUNCTION_HANDLER);\n            }\n            else {\n                if (functionDescriptor.getValueParameters().size() == 1\n                        && JetStandardClasses.isFunctionType(functionDescriptor.getValueParameters().get(0).getType())) {\n                    element = element.withInsertHandler(PARAMS_BRACES_FUNCTION_HANDLER);\n                } else {\n                    element = element.withInsertHandler(PARAMS_PARENTHESIS_FUNCTION_HANDLER);\n                }\n            }\n        }\n        else if (descriptor instanceof VariableDescriptor) {\n            JetType outType = ((VariableDescriptor) descriptor).getType();\n            typeText = DescriptorRenderer.TEXT.renderType(outType);\n        }\n        else if (descriptor instanceof ClassDescriptor) {\n            DeclarationDescriptor declaredIn = descriptor.getContainingDeclaration();\n            assert declaredIn != null;\n            tailText = \" (\" + DescriptorUtils.getFQName(declaredIn) + \")\";\n            tailTextGrayed = true;\n            element = element.withInsertHandler(JetClassInsertHandler.INSTANCE);\n        }\n        else {\n            typeText = DescriptorRenderer.TEXT.render(descriptor);\n        }\n\n        element = element.withTailText(tailText, tailTextGrayed).withTypeText(typeText).withPresentableText(presentableText);\n        element = element.withIcon(JetDescriptorIconProvider.getIcon(descriptor, Iconable.ICON_FLAG_VISIBILITY));\n\n        return element;\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    static void addClasses(\n            @NotNull final CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final BindingContext jetContext,\n            @NotNull final ResolveSession resolveSession,\n            @NotNull final Consumer<LookupElement> consumer\n    ) {\n        CompletionResultSet tempResult = result.withPrefixMatcher(CompletionUtil.findReferenceOrAlphanumericPrefix(parameters));\n\n        final Collection<DeclarationDescriptor> jetOnlyClasses = JetShortNamesCache.getJetOnlyTypes();\n        for (DeclarationDescriptor jetOnlyClass : jetOnlyClasses) {\n            consumer.consume(DescriptorLookupConverter.createLookupElement(jetContext, jetOnlyClass));\n        }\n\n        if (!JsModuleDetector.isJsModule((JetFile)parameters.getOriginalFile())) {\n            JavaClassNameCompletionContributor.addAllClasses(\n                    parameters,\n                    false,\n                    JavaCompletionSorting.addJavaSorting(parameters, tempResult).getPrefixMatcher(),\n                    new Consumer<LookupElement>() {\n                        @Override\n                        public void consume(LookupElement lookupElement) {\n                            if (lookupElement instanceof JavaPsiClassReferenceElement) {\n                                JavaPsiClassReferenceElement javaPsiReferenceElement = (JavaPsiClassReferenceElement) lookupElement;\n\n                                PsiClass psiClass = javaPsiReferenceElement.getObject();\n                                if (addAsJetLookupElement(parameters, psiClass, resolveSession, jetContext, consumer)) {\n                                    return;\n                                }\n\n                                // Redefine standard java insert handler which is going to insert fqn\n                                javaPsiReferenceElement.setInsertHandler(JetJavaClassInsertHandler.JAVA_CLASS_INSERT_HANDLER);\n                                consumer.consume(lookupElement);\n                            }\n                        }\n                    });\n        }\n        else {\n            Project project = parameters.getOriginalFile().getProject();\n            JetShortNamesCache namesCache = JetCacheManager.getInstance(project).getNamesCache();\n            Collection<ClassDescriptor> descriptors = namesCache.getJetClassesDescriptors(\n                    new Condition<String>() {\n                        @Override\n                        public boolean value(String shortName) {\n                            return result.getPrefixMatcher().prefixMatches(shortName);\n                        }\n                    }, resolveSession);\n\n            for (ClassDescriptor descriptor : descriptors) {\n                consumer.consume(DescriptorLookupConverter.createLookupElement(jetContext, descriptor));\n            }\n        }\n    }","id":37911,"modified_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    static void addClasses(\n            @NotNull final CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final BindingContext jetContext,\n            @NotNull final ResolveSession resolveSession,\n            @NotNull final Consumer<LookupElement> consumer\n    ) {\n        CompletionResultSet tempResult = result.withPrefixMatcher(CompletionUtil.findReferenceOrAlphanumericPrefix(parameters));\n\n        final Collection<DeclarationDescriptor> jetOnlyClasses = JetShortNamesCache.getJetOnlyTypes();\n        for (DeclarationDescriptor jetOnlyClass : jetOnlyClasses) {\n            consumer.consume(DescriptorLookupConverter.createLookupElement(resolveSession, jetContext, jetOnlyClass));\n        }\n\n        if (!JsModuleDetector.isJsModule((JetFile)parameters.getOriginalFile())) {\n            JavaClassNameCompletionContributor.addAllClasses(\n                    parameters,\n                    false,\n                    JavaCompletionSorting.addJavaSorting(parameters, tempResult).getPrefixMatcher(),\n                    new Consumer<LookupElement>() {\n                        @Override\n                        public void consume(LookupElement lookupElement) {\n                            if (lookupElement instanceof JavaPsiClassReferenceElement) {\n                                JavaPsiClassReferenceElement javaPsiReferenceElement = (JavaPsiClassReferenceElement) lookupElement;\n\n                                PsiClass psiClass = javaPsiReferenceElement.getObject();\n                                if (addAsJetLookupElement(parameters, psiClass, resolveSession, jetContext, consumer)) {\n                                    return;\n                                }\n\n                                // Redefine standard java insert handler which is going to insert fqn\n                                javaPsiReferenceElement.setInsertHandler(JetJavaClassInsertHandler.JAVA_CLASS_INSERT_HANDLER);\n                                consumer.consume(lookupElement);\n                            }\n                        }\n                    });\n        }\n        else {\n            Project project = parameters.getOriginalFile().getProject();\n            JetShortNamesCache namesCache = JetCacheManager.getInstance(project).getNamesCache();\n            Collection<ClassDescriptor> descriptors = namesCache.getJetClassesDescriptors(\n                    new Condition<String>() {\n                        @Override\n                        public boolean value(String shortName) {\n                            return result.getPrefixMatcher().prefixMatches(shortName);\n                        }\n                    }, resolveSession);\n\n            for (ClassDescriptor descriptor : descriptors) {\n                consumer.consume(DescriptorLookupConverter.createLookupElement(resolveSession, jetContext, descriptor));\n            }\n        }\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static boolean addAsJetLookupElement(\n            CompletionParameters parameters,\n            PsiClass aClass,\n            ResolveSession resolveSession,\n            BindingContext context,\n            Consumer<LookupElement> consumer\n    ) {\n        if (aClass instanceof JetLightClass) {\n            Project project = parameters.getPosition().getProject();\n\n            Collection<JetClassOrObject> classOrObjects =\n                    JetFullClassNameIndex.getInstance().get(aClass.getQualifiedName(), project, GlobalSearchScope.allScope(project));\n\n            for (JetClassOrObject classOrObject : classOrObjects) {\n                if (classOrObject.getContainingFile().getOriginalFile().equals(aClass.getContainingFile())) {\n                    Collection<ClassDescriptor> classDescriptors = ResolveSessionUtils.getClassDescriptorsByFqName(\n                            resolveSession,((JetLightClass) aClass).getFqName());\n                    for (ClassDescriptor descriptor : classDescriptors) {\n                        consumer.consume(DescriptorLookupConverter.createLookupElement(context, descriptor));\n                    }\n\n                    return true;\n                }\n            }\n        }\n\n        return false;\n    }","id":37912,"modified_method":"private static boolean addAsJetLookupElement(\n            CompletionParameters parameters,\n            PsiClass aClass,\n            ResolveSession resolveSession,\n            BindingContext context,\n            Consumer<LookupElement> consumer\n    ) {\n        if (aClass instanceof JetLightClass) {\n            Project project = parameters.getPosition().getProject();\n\n            Collection<JetClassOrObject> classOrObjects =\n                    JetFullClassNameIndex.getInstance().get(aClass.getQualifiedName(), project, GlobalSearchScope.allScope(project));\n\n            for (JetClassOrObject classOrObject : classOrObjects) {\n                if (classOrObject.getContainingFile().getOriginalFile().equals(aClass.getContainingFile())) {\n                    Collection<ClassDescriptor> classDescriptors = ResolveSessionUtils.getClassDescriptorsByFqName(\n                            resolveSession,((JetLightClass) aClass).getFqName());\n                    for (ClassDescriptor descriptor : classDescriptors) {\n                        consumer.consume(DescriptorLookupConverter.createLookupElement(resolveSession, context, descriptor));\n                    }\n\n                    return true;\n                }\n            }\n        }\n\n        return false;\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addJetExtensions(\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session\n    ) {\n        final PrefixMatcher prefixMatcher = result.getPrefixMatcher();\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        Condition<String> matchPrefixCondition = new Condition<String>() {\n            @Override\n            public boolean value(@NotNull String callableName) {\n                return prefixMatcher.prefixMatches(callableName);\n            }\n        };\n\n        Collection<DeclarationDescriptor> jetCallableExtensions = namesCache.getJetCallableExtensions(\n                matchPrefixCondition, expression, session.resolveSession, GlobalSearchScope.allScope(position.getProject()));\n\n        for (DeclarationDescriptor jetCallableExtension : jetCallableExtensions) {\n            result.addElement(DescriptorLookupConverter.createLookupElement(session.expressionBindingContext, jetCallableExtension));\n        }\n    }","id":37913,"modified_method":"private static void addJetExtensions(\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session\n    ) {\n        final PrefixMatcher prefixMatcher = result.getPrefixMatcher();\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        Condition<String> matchPrefixCondition = new Condition<String>() {\n            @Override\n            public boolean value(@NotNull String callableName) {\n                return prefixMatcher.prefixMatches(callableName);\n            }\n        };\n\n        Collection<DeclarationDescriptor> jetCallableExtensions = namesCache.getJetCallableExtensions(\n                matchPrefixCondition, expression, session.resolveSession, GlobalSearchScope.allScope(position.getProject()));\n\n        for (DeclarationDescriptor jetCallableExtension : jetCallableExtensions) {\n            result.addElement(DescriptorLookupConverter.createLookupElement(\n                    session.resolveSession, session.expressionBindingContext, jetCallableExtension));\n        }\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addJetTopLevelFunctions(@NotNull JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session) {\n        String actualPrefix = result.getPrefixMatcher().getPrefix();\n\n        Project project = position.getProject();\n\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        GlobalSearchScope scope = GlobalSearchScope.allScope(project);\n        Collection<String> functionNames = namesCache.getAllTopLevelFunctionNames();\n\n        ResolveSession resolveSession = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile((JetFile) position.getContainingFile());\n        BindingContext resolutionContext = ResolveSessionUtils.getExpressionBindingContext(resolveSession, expression);\n\n        for (String name : functionNames) {\n            if (name.contains(actualPrefix)) {\n                for (FunctionDescriptor function : namesCache.getTopLevelFunctionDescriptorsByName(name, expression, resolveSession, scope)) {\n                    addCompletionToResult(result, DescriptorLookupConverter.createLookupElement(resolutionContext, function), session);\n                }\n            }\n        }\n    }","id":37914,"modified_method":"private static void addJetTopLevelFunctions(@NotNull JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session) {\n        String actualPrefix = result.getPrefixMatcher().getPrefix();\n\n        Project project = position.getProject();\n\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        GlobalSearchScope scope = GlobalSearchScope.allScope(project);\n        Collection<String> functionNames = namesCache.getAllTopLevelFunctionNames();\n\n        for (String name : functionNames) {\n            if (name.contains(actualPrefix)) {\n                for (FunctionDescriptor function : namesCache.getTopLevelFunctionDescriptorsByName(name, expression, session.resolveSession, scope)) {\n                    addCompletionToResult(result, DescriptorLookupConverter.createLookupElement(\n                            session.resolveSession, session.expressionBindingContext, function), session);\n                }\n            }\n        }\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    private static LookupElement[] getReferenceVariants(\n            @NotNull JetSimpleNameReference reference,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session\n    ) {\n        Collection<DeclarationDescriptor> descriptors = TipsManager.getReferenceVariants(reference.getExpression(), session.expressionBindingContext);\n\n        Collection<DeclarationDescriptor> checkedDescriptors = Collections2.filter(descriptors, new Predicate<DeclarationDescriptor>() {\n            @Override\n            public boolean apply(@Nullable DeclarationDescriptor descriptor) {\n                if (descriptor == null) {\n                    return false;\n                }\n\n                return result.getPrefixMatcher().prefixMatches(descriptor.getName().getName()) && isVisibleDescriptor(descriptor, session);\n            }\n        });\n\n        return DescriptorLookupConverter.collectLookupElements(session.expressionBindingContext, checkedDescriptors);\n    }","id":37915,"modified_method":"@NotNull\n    private static LookupElement[] getReferenceVariants(\n            @NotNull JetSimpleNameReference reference,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session\n    ) {\n        Collection<DeclarationDescriptor> descriptors = TipsManager.getReferenceVariants(reference.getExpression(), session.expressionBindingContext);\n\n        Collection<DeclarationDescriptor> checkedDescriptors = Collections2.filter(descriptors, new Predicate<DeclarationDescriptor>() {\n            @Override\n            public boolean apply(@Nullable DeclarationDescriptor descriptor) {\n                if (descriptor == null) {\n                    return false;\n                }\n\n                return result.getPrefixMatcher().prefixMatches(descriptor.getName().getName()) && isVisibleDescriptor(descriptor, session);\n            }\n        });\n\n        return DescriptorLookupConverter.collectLookupElements(session.resolveSession, session.expressionBindingContext, checkedDescriptors);\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public boolean equals(Object obj) {\n        if (obj == null || obj.getClass() != getClass()) {\n            return false;\n        }\n\n        JetLookupObject other = (JetLookupObject)obj;\n\n        // Same descriptor - same lookup element\n        if (descriptor != null && other.descriptor != null) {\n            if (context == other.context) {\n                if (descriptor.equals(other.descriptor)) {\n                    return true;\n                }\n            }\n            else {\n                String descriptorText = DescriptorRenderer.TEXT.render(descriptor);\n                @SuppressWarnings(\"ConstantConditions\")\n                String otherDescriptorText = DescriptorRenderer.TEXT.render(other.descriptor);\n                if (descriptorText.equals(otherDescriptorText)) {\n                    return true;\n                }\n            }\n        }\n\n        if (psiElement != null && psiElement.equals(other.psiElement)) {\n            // Warning here - why descriptors are not same???\n            return true;\n        }\n\n        return (descriptor == null && other.descriptor == null &&\n                psiElement == null && other.psiElement == null);\n    }","id":37916,"modified_method":"@Override\n    public boolean equals(Object obj) {\n        if (obj == null || obj.getClass() != getClass()) {\n            return false;\n        }\n\n        JetLookupObject other = (JetLookupObject)obj;\n\n        // Same descriptor - same lookup element\n        if (descriptor != null && other.descriptor != null) {\n            if (resolveSession == other.resolveSession) {\n                if (descriptor.equals(other.descriptor)) {\n                    return true;\n                }\n            }\n            else {\n                LOG.warn(\"Descriptors from different resolve sessions\");\n\n                String descriptorText = DescriptorRenderer.TEXT.render(descriptor);\n                @SuppressWarnings(\"ConstantConditions\")\n                String otherDescriptorText = DescriptorRenderer.TEXT.render(other.descriptor);\n                if (descriptorText.equals(otherDescriptorText)) {\n                    return true;\n                }\n            }\n        }\n\n        if (psiElement != null && psiElement.equals(other.psiElement)) {\n            // Warning here - why descriptors are not same???\n            return true;\n        }\n\n        return (descriptor == null && other.descriptor == null &&\n                psiElement == null && other.psiElement == null);\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public JetLookupObject(@Nullable DeclarationDescriptor descriptor, @NotNull BindingContext context, @Nullable PsiElement psiElement) {\n        this.descriptor = descriptor;\n        this.context = context;\n        this.psiElement = psiElement;\n    }","id":37917,"modified_method":"public JetLookupObject(@Nullable DeclarationDescriptor descriptor, @NotNull ResolveSession resolveSession, @Nullable PsiElement psiElement) {\n        this.descriptor = descriptor;\n        this.resolveSession = resolveSession;\n        this.psiElement = psiElement;\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public JetPackagesContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                                                 @NotNull CompletionResultSet result) {\n\n                       final PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetNamespaceHeader namespaceHeader = PsiTreeUtil.getParentOfType(position, JetNamespaceHeader.class);\n                       if (namespaceHeader == null) {\n                           return;\n                       }\n\n                       final PsiReference ref = parameters.getPosition().getContainingFile().findReferenceAt(parameters.getOffset());\n\n                       if (ref instanceof JetSimpleNameReference) {\n                           JetSimpleNameReference simpleNameReference = (JetSimpleNameReference)ref;\n\n                           String name = simpleNameReference.getExpression().getText();\n                           if (name == null) {\n                               return;\n                           }\n\n                           int prefixLength = parameters.getOffset() - simpleNameReference.getExpression().getTextOffset();\n                           result = result.withPrefixMatcher(new PlainPrefixMatcher(name.substring(0, prefixLength)));\n\n                           BindingContext bindingContext = WholeProjectAnalyzerFacade.getLazyResolveContext(\n                                   (JetFile) namespaceHeader.getContainingFile(), simpleNameReference.getExpression());\n\n                           for (LookupElement variant : DescriptorLookupConverter.collectLookupElements(\n                                   bindingContext, TipsManager.getPackageReferenceVariants(simpleNameReference.getExpression(), bindingContext))) {\n                               if (!variant.getLookupString().contains(DUMMY_IDENTIFIER)) {\n                                   result.addElement(variant);\n                               }\n                           }\n\n                           result.stopHere();\n                       }\n                   }\n               });\n    }","id":37918,"modified_method":"public JetPackagesContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                                                 @NotNull CompletionResultSet result) {\n\n                       final PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetNamespaceHeader namespaceHeader = PsiTreeUtil.getParentOfType(position, JetNamespaceHeader.class);\n                       if (namespaceHeader == null) {\n                           return;\n                       }\n\n                       final PsiReference ref = parameters.getPosition().getContainingFile().findReferenceAt(parameters.getOffset());\n\n                       if (ref instanceof JetSimpleNameReference) {\n                           JetSimpleNameReference simpleNameReference = (JetSimpleNameReference)ref;\n\n                           String name = simpleNameReference.getExpression().getText();\n                           if (name == null) {\n                               return;\n                           }\n\n                           int prefixLength = parameters.getOffset() - simpleNameReference.getExpression().getTextOffset();\n                           result = result.withPrefixMatcher(new PlainPrefixMatcher(name.substring(0, prefixLength)));\n\n                           ResolveSession resolveSession = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile(\n                                   (JetFile) simpleNameReference.getExpression().getContainingFile());\n                           BindingContext bindingContext = ResolveSessionUtils.getExpressionBindingContext(\n                                   resolveSession, simpleNameReference.getExpression());\n\n                           for (LookupElement variant : DescriptorLookupConverter.collectLookupElements(\n                                   resolveSession, bindingContext, TipsManager.getPackageReferenceVariants(simpleNameReference.getExpression(), bindingContext))) {\n                               if (!variant.getLookupString().contains(DUMMY_IDENTIFIER)) {\n                                   result.addElement(variant);\n                               }\n                           }\n\n                           result.stopHere();\n                       }\n                   }\n               });\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    @Override\n    public Object[] getVariants() {\n        BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(\n                (JetFile) myExpression.getContainingFile())\n                    .getBindingContext();\n\n        return DescriptorLookupConverter.collectLookupElements(\n                bindingContext, TipsManager.getReferenceVariants(myExpression, bindingContext));\n    }","id":37919,"modified_method":"@NotNull\n    @Override\n    public Object[] getVariants() {\n        ResolveSession resolveSession = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile((JetFile) getExpression().getContainingFile());\n        BindingContext bindingContext = ResolveSessionUtils.getExpressionBindingContext(resolveSession, getExpression());\n\n        return DescriptorLookupConverter.collectLookupElements(\n                resolveSession, bindingContext, TipsManager.getReferenceVariants(myExpression, bindingContext));\n    }","commit_id":"b1860641306ab153b4e42b795f559b401ee6eafa","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n    public LineMarkerInfo getLineMarkerInfo(@NotNull PsiElement element) {\n        JetFile file = (JetFile)element.getContainingFile();\n        if (file == null) return null;\n\n        if (!(element instanceof JetNamedFunction || element instanceof JetProperty)) return null;\n\n        BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(file).getBindingContext();\n\n        DeclarationDescriptor descriptor = bindingContext.get(BindingContext.DECLARATION_TO_DESCRIPTOR, element);\n        if (!(descriptor instanceof CallableMemberDescriptor)) {\n            return null;\n        }\n\n        Set<? extends CallableMemberDescriptor> overriddenMembers = ((CallableMemberDescriptor)descriptor).getOverriddenDescriptors();\n        if (overriddenMembers.size() == 0) {\n            return null;\n        }\n\n        boolean allOverriddenAbstract = true;\n        for (CallableMemberDescriptor function : overriddenMembers) {\n            allOverriddenAbstract &= function.getModality() == Modality.ABSTRACT;\n        }\n\n        // NOTE: Don't store descriptors in line markers because line markers are not deleted while editing other files and this can prevent\n        // clearing the whole BindingTrace.\n        return new LineMarkerInfo<PsiElement>(\n                element,\n                element.getTextOffset(),\n                allOverriddenAbstract ? IMPLEMENTING_MARK : OVERRIDING_MARK,\n                Pass.UPDATE_ALL,\n                new Function<PsiElement, String>() {\n                    @Override\n                    public String fun(PsiElement element) {\n                        return calculateTooltipString(element);\n                    }\n                },\n                new GutterIconNavigationHandler<PsiElement>() {\n                    @Override\n                    public void navigate(MouseEvent event, PsiElement elt) {\n                        iconNavigatorHandler(event, elt);\n                    }\n                }\n        );\n    }","id":37920,"modified_method":"@Override\n    public LineMarkerInfo getLineMarkerInfo(@NotNull PsiElement element) {\n        JetFile file = (JetFile)element.getContainingFile();\n        if (file == null) return null;\n\n        if (!(element instanceof JetNamedFunction || element instanceof JetProperty)) return null;\n\n        ResolveSession sessionForFile = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile(file);\n        BindingContext bindingContext;\n\n        if ((element instanceof JetNamedFunction && ((JetNamedFunction) element).isLocal()) ||\n                element instanceof JetProperty && ((JetProperty) element).isLocal()) {\n            bindingContext = ResolveSessionUtils.resolveToExpression(sessionForFile, (JetElement) element);\n        }\n        else {\n            try {\n                sessionForFile.resolveToDescriptor((JetDeclaration) element);\n                bindingContext = sessionForFile.getBindingContext();\n            } catch (IllegalStateException e) {\n                return null;\n            }\n        }\n\n        DeclarationDescriptor descriptor = bindingContext.get(BindingContext.DECLARATION_TO_DESCRIPTOR, element);\n\n        if (!(descriptor instanceof CallableMemberDescriptor)) {\n            return null;\n        }\n\n        Set<? extends CallableMemberDescriptor> overriddenMembers = ((CallableMemberDescriptor)descriptor).getOverriddenDescriptors();\n        if (overriddenMembers.size() == 0) {\n            return null;\n        }\n\n        boolean allOverriddenAbstract = true;\n        for (CallableMemberDescriptor function : overriddenMembers) {\n            allOverriddenAbstract &= function.getModality() == Modality.ABSTRACT;\n        }\n\n        // NOTE: Don't store descriptors in line markers because line markers are not deleted while editing other files and this can prevent\n        // clearing the whole BindingTrace.\n        return new LineMarkerInfo<PsiElement>(\n                element,\n                element.getTextOffset(),\n                allOverriddenAbstract ? IMPLEMENTING_MARK : OVERRIDING_MARK,\n                Pass.UPDATE_ALL,\n                new Function<PsiElement, String>() {\n                    @Override\n                    public String fun(PsiElement element) {\n                        return calculateTooltipString(element);\n                    }\n                },\n                new GutterIconNavigationHandler<PsiElement>() {\n                    @Override\n                    public void navigate(MouseEvent event, PsiElement elt) {\n                        iconNavigatorHandler(event, elt);\n                    }\n                }\n        );\n    }","commit_id":"94ad93d81024a1da6197c18fc0f2b7fab1762fa9","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void iconNavigatorHandler(MouseEvent event, PsiElement elt) {\n        JetFile file = (JetFile)elt.getContainingFile();\n        assert file != null;\n\n        BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(file).getBindingContext();\n        DeclarationDescriptor descriptor = bindingContext.get(BindingContext.DECLARATION_TO_DESCRIPTOR, elt);\n        if (!(descriptor instanceof CallableMemberDescriptor)) {\n            return;\n        }\n\n        Set<? extends CallableMemberDescriptor> overriddenMembers = ((CallableMemberDescriptor)descriptor).getOverriddenDescriptors();\n        if (overriddenMembers.size() == 0) {\n            return;\n        }\n\n        if (overriddenMembers.isEmpty()) return;\n        List<PsiElement> list = Lists.newArrayList();\n        for (CallableMemberDescriptor overriddenMember : overriddenMembers) {\n            PsiElement declarationPsiElement = BindingContextUtils.descriptorToDeclaration(bindingContext, overriddenMember);\n            list.add(declarationPsiElement);\n        }\n        if (list.isEmpty()) {\n            String myEmptyText = \"empty text\";\n            JComponent renderer = HintUtil.createErrorLabel(myEmptyText);\n            JBPopup popup = JBPopupFactory.getInstance().createComponentPopupBuilder(renderer, renderer).createPopup();\n            if (event != null) {\n                popup.show(new RelativePoint(event));\n            }\n            return;\n        }\n        if (list.size() == 1) {\n            PsiNavigateUtil.navigate(list.iterator().next());\n        }\n        else {\n            JBPopup popup = NavigationUtil.getPsiElementPopup(PsiUtilCore.toPsiElementArray(list),\n                                                              new JetFunctionPsiElementCellRenderer(bindingContext),\n                                                              DescriptorRenderer.TEXT.render(descriptor));\n            if (event != null) {\n                popup.show(new RelativePoint(event));\n            }\n        }\n    }","id":37921,"modified_method":"private static void iconNavigatorHandler(MouseEvent event, PsiElement elt) {\n        JetFile file = (JetFile)elt.getContainingFile();\n        assert file != null;\n\n        BindingContext bindingContext = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile(file).getBindingContext();\n        DeclarationDescriptor descriptor = bindingContext.get(BindingContext.DECLARATION_TO_DESCRIPTOR, elt);\n        if (!(descriptor instanceof CallableMemberDescriptor)) {\n            return;\n        }\n\n        Set<? extends CallableMemberDescriptor> overriddenMembers = ((CallableMemberDescriptor)descriptor).getOverriddenDescriptors();\n        if (overriddenMembers.size() == 0) {\n            return;\n        }\n\n        if (overriddenMembers.isEmpty()) return;\n        List<PsiElement> list = Lists.newArrayList();\n        for (CallableMemberDescriptor overriddenMember : overriddenMembers) {\n            PsiElement declarationPsiElement = BindingContextUtils.descriptorToDeclaration(bindingContext, overriddenMember);\n            list.add(declarationPsiElement);\n        }\n        if (list.isEmpty()) {\n            String myEmptyText = \"empty text\";\n            JComponent renderer = HintUtil.createErrorLabel(myEmptyText);\n            JBPopup popup = JBPopupFactory.getInstance().createComponentPopupBuilder(renderer, renderer).createPopup();\n            if (event != null) {\n                popup.show(new RelativePoint(event));\n            }\n            return;\n        }\n        if (list.size() == 1) {\n            PsiNavigateUtil.navigate(list.iterator().next());\n        }\n        else {\n            JBPopup popup = NavigationUtil.getPsiElementPopup(PsiUtilCore.toPsiElementArray(list),\n                                                              new JetFunctionPsiElementCellRenderer(bindingContext),\n                                                              DescriptorRenderer.TEXT.render(descriptor));\n            if (event != null) {\n                popup.show(new RelativePoint(event));\n            }\n        }\n    }","commit_id":"94ad93d81024a1da6197c18fc0f2b7fab1762fa9","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static boolean addAsJetLookupElement(PsiClass aClass, BindingContext bindingContext, Consumer<LookupElement> consumer) {\n        if (aClass instanceof JetLightClass) {\n            ClassDescriptor descriptor = bindingContext.get(\n                    BindingContext.FQNAME_TO_CLASS_DESCRIPTOR, ((JetLightClass)aClass).getFqName());\n\n            if (descriptor != null) {\n                LookupElement element = DescriptorLookupConverter.createLookupElement(bindingContext, descriptor);\n                consumer.consume(element);\n                return true;\n            }\n        }\n\n        return false;\n    }","id":37922,"modified_method":"private static boolean addAsJetLookupElement(CompletionParameters parameters, PsiClass aClass, Consumer<LookupElement> consumer) {\n        if (aClass instanceof JetLightClass) {\n            Project project = parameters.getPosition().getProject();\n            PsiFile completionFile = parameters.getPosition().getContainingFile();\n\n            Collection<JetClassOrObject> classOrObjects =\n                    JetFullClassNameIndex.getInstance().get(aClass.getQualifiedName(), project, GlobalSearchScope.allScope(project));\n\n            for (JetClassOrObject classOrObject : classOrObjects) {\n                if (classOrObject.getContainingFile().getOriginalFile().equals(aClass.getContainingFile())) {\n                    PsiFile fileOfClass = completionFile.getOriginalFile().equals(aClass.getContainingFile()) ? completionFile : aClass.getContainingFile();\n\n                    ResolveSession resolveSessionForFile = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile((JetFile) fileOfClass);\n                    ClassDescriptor descriptor = resolveSessionForFile.getClassDescriptor(classOrObject);\n\n                    LookupElement element = DescriptorLookupConverter.createLookupElement(resolveSessionForFile.getBindingContext(), descriptor);\n                    consumer.consume(element);\n                    return true;\n                }\n            }\n        }\n\n        return false;\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    static void addClasses(\n            @NotNull final CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final Consumer<LookupElement> consumer\n    ) {\n        CompletionResultSet tempResult = result.withPrefixMatcher(CompletionUtil.findReferenceOrAlphanumericPrefix(parameters));\n\n        // TODO: Make icon for standard types\n        final Collection<DeclarationDescriptor> jetOnlyClasses = JetShortNamesCache.getJetOnlyTypes();\n        final BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(\n                (JetFile)parameters.getPosition().getContainingFile()).getBindingContext();\n\n        for (DeclarationDescriptor jetOnlyClass : jetOnlyClasses) {\n            consumer.consume(DescriptorLookupConverter.createLookupElement(bindingContext, jetOnlyClass));\n        }\n\n        if (!JsModuleDetector.isJsModule((JetFile)parameters.getOriginalFile())) {\n            JavaClassNameCompletionContributor.addAllClasses(\n                    parameters,\n                    false,\n                    JavaCompletionSorting.addJavaSorting(parameters, tempResult).getPrefixMatcher(),\n                    new Consumer<LookupElement>() {\n                        @Override\n                        public void consume(LookupElement lookupElement) {\n                            if (lookupElement instanceof JavaPsiClassReferenceElement) {\n                                JavaPsiClassReferenceElement javaPsiReferenceElement = (JavaPsiClassReferenceElement) lookupElement;\n\n                                PsiClass object = javaPsiReferenceElement.getObject();\n                                if (addAsJetLookupElement(object, bindingContext, consumer)) {\n                                    return;\n                                }\n\n                                // Redefine standard java insert handler which is going to insert fqn\n                                javaPsiReferenceElement.setInsertHandler(JetJavaClassInsertHandler.JAVA_CLASS_INSERT_HANDLER);\n                                consumer.consume(lookupElement);\n                            }\n                        }\n                    });\n        }\n        else {\n            Project project = parameters.getOriginalFile().getProject();\n            JetShortNamesCache namesCache = JetCacheManager.getInstance(project).getNamesCache();\n            Collection<ClassDescriptor> descriptors = namesCache.getJetClassesDescriptors(\n                    new Condition<String>() {\n                        @Override\n                        public boolean value(String shortName) {\n                            return result.getPrefixMatcher().prefixMatches(shortName);\n                        }\n                    },\n                    (JetFile) parameters.getOriginalFile());\n\n            for (ClassDescriptor descriptor : descriptors) {\n                consumer.consume(DescriptorLookupConverter.createLookupElement(bindingContext, descriptor));\n            }\n        }\n    }","id":37923,"modified_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    static void addClasses(\n            @NotNull final CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final BindingContext jetContext,\n            @NotNull final Consumer<LookupElement> consumer\n    ) {\n        CompletionResultSet tempResult = result.withPrefixMatcher(CompletionUtil.findReferenceOrAlphanumericPrefix(parameters));\n\n        final Collection<DeclarationDescriptor> jetOnlyClasses = JetShortNamesCache.getJetOnlyTypes();\n        for (DeclarationDescriptor jetOnlyClass : jetOnlyClasses) {\n            consumer.consume(DescriptorLookupConverter.createLookupElement(jetContext, jetOnlyClass));\n        }\n\n        if (!JsModuleDetector.isJsModule((JetFile)parameters.getOriginalFile())) {\n            JavaClassNameCompletionContributor.addAllClasses(\n                    parameters,\n                    false,\n                    JavaCompletionSorting.addJavaSorting(parameters, tempResult).getPrefixMatcher(),\n                    new Consumer<LookupElement>() {\n                        @Override\n                        public void consume(LookupElement lookupElement) {\n                            if (lookupElement instanceof JavaPsiClassReferenceElement) {\n                                JavaPsiClassReferenceElement javaPsiReferenceElement = (JavaPsiClassReferenceElement) lookupElement;\n\n                                PsiClass psiClass = javaPsiReferenceElement.getObject();\n                                if (addAsJetLookupElement(parameters, psiClass, consumer)) {\n                                    return;\n                                }\n\n                                // Redefine standard java insert handler which is going to insert fqn\n                                javaPsiReferenceElement.setInsertHandler(JetJavaClassInsertHandler.JAVA_CLASS_INSERT_HANDLER);\n                                consumer.consume(lookupElement);\n                            }\n                        }\n                    });\n        }\n        else {\n            Project project = parameters.getOriginalFile().getProject();\n            JetShortNamesCache namesCache = JetCacheManager.getInstance(project).getNamesCache();\n            Collection<ClassDescriptor> descriptors = namesCache.getJetClassesDescriptors(\n                    new Condition<String>() {\n                        @Override\n                        public boolean value(String shortName) {\n                            return result.getPrefixMatcher().prefixMatches(shortName);\n                        }\n                    },\n                    (JetFile) parameters.getOriginalFile());\n\n            for (ClassDescriptor descriptor : descriptors) {\n                consumer.consume(DescriptorLookupConverter.createLookupElement(jetContext, descriptor));\n            }\n        }\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addJetExtensions(JetSimpleNameExpression expression, CompletionResultSet result, PsiElement position) {\n        final PrefixMatcher prefixMatcher = result.getPrefixMatcher();\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        Condition<String> matchPrefixCondition = new Condition<String>() {\n            @Override\n            public boolean value(String callableName) {\n                return prefixMatcher.prefixMatches(callableName);\n            }\n        };\n\n        Collection<DeclarationDescriptor> jetCallableExtensions = namesCache.getJetCallableExtensions(\n                matchPrefixCondition, expression, GlobalSearchScope.allScope(position.getProject()));\n\n        BindingContext context = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile((JetFile)position.getContainingFile())\n                .getBindingContext();\n\n        for (DeclarationDescriptor jetCallableExtension : jetCallableExtensions) {\n            result.addElement(DescriptorLookupConverter.createLookupElement(context, jetCallableExtension));\n        }\n    }","id":37924,"modified_method":"private static void addJetExtensions(@NotNull JetSimpleNameExpression expression, @NotNull CompletionResultSet result, @NotNull PsiElement position) {\n        final PrefixMatcher prefixMatcher = result.getPrefixMatcher();\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        Condition<String> matchPrefixCondition = new Condition<String>() {\n            @Override\n            public boolean value(@NotNull String callableName) {\n                return prefixMatcher.prefixMatches(callableName);\n            }\n        };\n\n        Collection<DeclarationDescriptor> jetCallableExtensions = namesCache.getJetCallableExtensions(\n                matchPrefixCondition, expression, GlobalSearchScope.allScope(position.getProject()));\n\n        BindingContext context = WholeProjectAnalyzerFacade.getLazyResolveContext(\n                (JetFile) position.getContainingFile(), expression);\n\n        for (DeclarationDescriptor jetCallableExtension : jetCallableExtensions) {\n            result.addElement(DescriptorLookupConverter.createLookupElement(context, jetCallableExtension));\n        }\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public JetCompletionContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                           @NotNull CompletionResultSet result) {\n                       result.restartCompletionWhenNothingMatches();\n                       result = JetCompletionSorting.addJetSorting(parameters, result);\n\n                       CompletionSession session = new CompletionSession();\n                       session.customInvocationCount = parameters.getInvocationCount();\n\n                       PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetSimpleNameReference jetReference = getJetReference(parameters);\n                       if (jetReference != null) {\n\n                           BindingContext jetContext =\n                                   WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile((JetFile)position.getContainingFile())\n                                           .getBindingContext();\n\n                           JetScope scope = jetContext.get(BindingContext.RESOLUTION_SCOPE, jetReference.getExpression());\n                           session.inDescriptor = scope != null ? scope.getContainingDeclaration() : null;\n\n                           completeForReference(parameters, result, position, jetReference, session);\n\n                           if (!session.isSomethingAdded && session.customInvocationCount == 0) {\n                               // Rerun completion if nothing was found\n                               session.customInvocationCount = 1;\n                               completeForReference(parameters, result, position, jetReference, session);\n                           }\n                       }\n\n                       // Prevent from adding reference variants from standard reference contributor\n                       result.stopHere();\n                   }\n               });\n    }","id":37925,"modified_method":"public JetCompletionContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                           @NotNull CompletionResultSet result) {\n                       result.restartCompletionWhenNothingMatches();\n                       result = JetCompletionSorting.addJetSorting(parameters, result);\n\n                       CompletionSession session = new CompletionSession();\n                       session.customInvocationCount = parameters.getInvocationCount();\n\n                       PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetSimpleNameReference jetReference = getJetReference(parameters);\n                       if (jetReference != null) {\n                           BindingContext jetContext = WholeProjectAnalyzerFacade.getLazyResolveContext(\n                                   (JetFile) position.getContainingFile(), jetReference.getExpression());\n\n                           JetScope scope = jetContext.get(BindingContext.RESOLUTION_SCOPE, jetReference.getExpression());\n                           session.inDescriptor = scope != null ? scope.getContainingDeclaration() : null;\n\n                           completeForReference(parameters, result, position, jetReference, session, jetContext);\n\n                           if (!session.isSomethingAdded && session.customInvocationCount == 0) {\n                               // Rerun completion if nothing was found\n                               session.customInvocationCount = 1;\n                               completeForReference(parameters, result, position, jetReference, session, jetContext);\n                           }\n                       }\n\n                       // Prevent from adding reference variants from standard reference contributor\n                       result.stopHere();\n                   }\n               });\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static boolean isVisibleDescriptor(DeclarationDescriptor descriptor, CompletionSession session) {\n        if (session.customInvocationCount >= 2) {\n            // Show everything if user insist on showing completion list\n            return true;\n        }\n\n        if (descriptor instanceof DeclarationDescriptorWithVisibility) {\n            return Visibilities.isVisible((DeclarationDescriptorWithVisibility)descriptor, session.inDescriptor);\n        }\n\n        return true;\n    }","id":37926,"modified_method":"private static boolean isVisibleDescriptor(DeclarationDescriptor descriptor, @NotNull CompletionSession session) {\n        if (session.customInvocationCount >= 2) {\n            // Show everything if user insist on showing completion list\n            return true;\n        }\n\n        if (descriptor instanceof DeclarationDescriptorWithVisibility) {\n            if (session.inDescriptor != null) {\n                return Visibilities.isVisible((DeclarationDescriptorWithVisibility)descriptor, session.inDescriptor);\n            }\n        }\n\n        return true;\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    private static void addClasses(\n            @NotNull CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session\n    ) {\n        JetClassCompletionContributor.addClasses(parameters, result, new Consumer<LookupElement>() {\n            @Override\n            public void consume(@NotNull LookupElement element) {\n                addCompletionToResult(result, element, session);\n            }\n        });\n    }","id":37927,"modified_method":"/**\n     * Jet classes will be added as java completions for unification\n     */\n    private static void addClasses(\n            @NotNull CompletionParameters parameters,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session,\n            BindingContext jetContext) {\n        JetClassCompletionContributor.addClasses(parameters, result, jetContext, new Consumer<LookupElement>() {\n            @Override\n            public void consume(@NotNull LookupElement element) {\n                addCompletionToResult(result, element, session);\n            }\n        });\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    private static LookupElement[] getReferenceVariants(\n            @NotNull JetSimpleNameReference reference,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session\n    ) {\n        BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(\n                (JetFile)reference.getExpression().getContainingFile())\n                .getBindingContext();\n\n        Collection<DeclarationDescriptor> descriptors = TipsManager.getReferenceVariants(reference.getExpression(), bindingContext);\n\n        Collection<DeclarationDescriptor> checkedDescriptors = Collections2.filter(descriptors, new Predicate<DeclarationDescriptor>() {\n            @Override\n            public boolean apply(@Nullable DeclarationDescriptor descriptor) {\n                if (descriptor == null) {\n                    return false;\n                }\n\n                return result.getPrefixMatcher().prefixMatches(descriptor.getName().getName()) && isVisibleDescriptor(descriptor, session);\n            }\n        });\n\n        return DescriptorLookupConverter.collectLookupElements(bindingContext, checkedDescriptors);\n    }","id":37928,"modified_method":"@NotNull\n    private static LookupElement[] getReferenceVariants(\n            @NotNull JetSimpleNameReference reference,\n            @NotNull final CompletionResultSet result,\n            @NotNull final CompletionSession session,\n            BindingContext jetContext\n    ) {\n        Collection<DeclarationDescriptor> descriptors = TipsManager.getReferenceVariants(reference.getExpression(), jetContext);\n\n        Collection<DeclarationDescriptor> checkedDescriptors = Collections2.filter(descriptors, new Predicate<DeclarationDescriptor>() {\n            @Override\n            public boolean apply(@Nullable DeclarationDescriptor descriptor) {\n                if (descriptor == null) {\n                    return false;\n                }\n\n                return result.getPrefixMatcher().prefixMatches(descriptor.getName().getName()) && isVisibleDescriptor(descriptor, session);\n            }\n        });\n\n        return DescriptorLookupConverter.collectLookupElements(jetContext, checkedDescriptors);\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void addJetTopLevelFunctions(JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session) {\n\n        String actualPrefix = result.getPrefixMatcher().getPrefix();\n\n        Project project = position.getProject();\n\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        GlobalSearchScope scope = GlobalSearchScope.allScope(project);\n        Collection<String> functionNames = namesCache.getAllTopLevelFunctionNames();\n\n        BindingContext resolutionContext =\n                WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile((JetFile)position.getContainingFile()).getBindingContext();\n\n        for (String name : functionNames) {\n            if (name.contains(actualPrefix)) {\n                for (FunctionDescriptor function : namesCache.getTopLevelFunctionDescriptorsByName(name, expression, scope)) {\n                    addCompletionToResult(result, DescriptorLookupConverter.createLookupElement(resolutionContext, function), session);\n                }\n            }\n        }\n    }","id":37929,"modified_method":"private static void addJetTopLevelFunctions(@NotNull JetSimpleNameExpression expression,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull CompletionSession session) {\n        String actualPrefix = result.getPrefixMatcher().getPrefix();\n\n        Project project = position.getProject();\n\n        JetShortNamesCache namesCache = JetCacheManager.getInstance(position.getProject()).getNamesCache();\n        GlobalSearchScope scope = GlobalSearchScope.allScope(project);\n        Collection<String> functionNames = namesCache.getAllTopLevelFunctionNames();\n\n        BindingContext resolutionContext = WholeProjectAnalyzerFacade.getLazyResolveContext(\n                (JetFile) position.getContainingFile(), expression);\n\n        for (String name : functionNames) {\n            if (name.contains(actualPrefix)) {\n                for (FunctionDescriptor function : namesCache.getTopLevelFunctionDescriptorsByName(name, expression, scope)) {\n                    addCompletionToResult(result, DescriptorLookupConverter.createLookupElement(resolutionContext, function), session);\n                }\n            }\n        }\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private static void completeForReference(\n            @NotNull CompletionParameters parameters,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull JetSimpleNameReference jetReference,\n            @NotNull CompletionSession session\n    ) {\n        if (isOnlyKeywordCompletion(position)) {\n            return;\n        }\n\n        if (shouldRunTypeCompletionOnly(position, jetReference)) {\n            if (session.customInvocationCount > 0) {\n                addClasses(parameters, result, session);\n            }\n            else {\n                for (LookupElement variant : getReferenceVariants(jetReference, result, session)) {\n                    if (isTypeDeclaration(variant)) {\n                        addCheckedCompletionToResult(result, variant, session);\n                    }\n                }\n            }\n\n            return;\n        }\n\n        for (LookupElement variant : getReferenceVariants(jetReference, result, session)) {\n            addCheckedCompletionToResult(result, variant, session);\n        }\n\n        String prefix = result.getPrefixMatcher().getPrefix();\n\n        // Try to avoid computing not-imported descriptors for empty prefix\n        if (prefix.isEmpty()) {\n            if (session.customInvocationCount < 2) {\n                return;\n            }\n\n            if (PsiTreeUtil.getParentOfType(jetReference.getElement(), JetDotQualifiedExpression.class) == null) {\n                return;\n            }\n        }\n\n        if (shouldRunTopLevelCompletion(parameters, session)) {\n            addClasses(parameters, result, session);\n            addJetTopLevelFunctions(jetReference.getExpression(), result, position, session);\n        }\n\n        if (shouldRunExtensionsCompletion(parameters, prefix, session)) {\n            addJetExtensions(jetReference.getExpression(), result, position);\n        }\n    }","id":37930,"modified_method":"private static void completeForReference(\n            @NotNull CompletionParameters parameters,\n            @NotNull CompletionResultSet result,\n            @NotNull PsiElement position,\n            @NotNull JetSimpleNameReference jetReference,\n            @NotNull CompletionSession session,\n            BindingContext jetContext) {\n        if (isOnlyKeywordCompletion(position)) {\n            return;\n        }\n\n        if (shouldRunTypeCompletionOnly(position, jetReference)) {\n            if (session.customInvocationCount > 0) {\n                addClasses(parameters, result, session, jetContext);\n            }\n            else {\n                for (LookupElement variant : getReferenceVariants(jetReference, result, session, jetContext)) {\n                    if (isTypeDeclaration(variant)) {\n                        addCheckedCompletionToResult(result, variant, session);\n                    }\n                }\n            }\n\n            return;\n        }\n\n        for (LookupElement variant : getReferenceVariants(jetReference, result, session, jetContext)) {\n            addCheckedCompletionToResult(result, variant, session);\n        }\n\n        String prefix = result.getPrefixMatcher().getPrefix();\n\n        // Try to avoid computing not-imported descriptors for empty prefix\n        if (prefix.isEmpty()) {\n            if (session.customInvocationCount < 2) {\n                return;\n            }\n\n            if (PsiTreeUtil.getParentOfType(jetReference.getElement(), JetDotQualifiedExpression.class) == null) {\n                return;\n            }\n        }\n\n        if (shouldRunTopLevelCompletion(parameters, session)) {\n            addClasses(parameters, result, session, jetContext);\n            addJetTopLevelFunctions(jetReference.getExpression(), result, position, session);\n        }\n\n        if (shouldRunExtensionsCompletion(parameters, prefix, session)) {\n            addJetExtensions(jetReference.getExpression(), result, position);\n        }\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@Override\n        protected void addCompletions(@NotNull CompletionParameters parameters,\n                                      ProcessingContext context,\n                                      final @NotNull CompletionResultSet result\n        ) {\n            if (parameters.getInvocationCount() > 0 || parameters.getCompletionType() == CompletionType.CLASS_NAME) {\n                JetClassCompletionContributor.addClasses(parameters, result, new Consumer<LookupElement>() {\n                    @Override\n                    public void consume(@NotNull LookupElement element) {\n                        result.addElement(element);\n                    }\n                });\n            }\n\n            result.stopHere();\n        }","id":37931,"modified_method":"@Override\n        protected void addCompletions(@NotNull CompletionParameters parameters,\n                                      ProcessingContext context,\n                                      final @NotNull CompletionResultSet result\n        ) {\n            BindingContext jetContext = WholeProjectAnalyzerFacade\n                    .getLazyResolveContext((JetFile) parameters.getPosition().getContainingFile(), null);\n\n            if (parameters.getInvocationCount() > 0 || parameters.getCompletionType() == CompletionType.CLASS_NAME) {\n                JetClassCompletionContributor.addClasses(parameters, result, jetContext, new Consumer<LookupElement>() {\n                    @Override\n                    public void consume(@NotNull LookupElement element) {\n                        result.addElement(element);\n                    }\n                });\n            }\n\n            result.stopHere();\n        }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public JetPackagesContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                                                 @NotNull CompletionResultSet result) {\n\n                       final PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetNamespaceHeader namespaceHeader = PsiTreeUtil.getParentOfType(position, JetNamespaceHeader.class);\n                       if (namespaceHeader == null) {\n                           return;\n                       }\n\n                       final PsiReference ref = parameters.getPosition().getContainingFile().findReferenceAt(parameters.getOffset());\n\n                       if (ref instanceof JetSimpleNameReference) {\n                           JetSimpleNameReference simpleNameReference = (JetSimpleNameReference)ref;\n\n                           String name = simpleNameReference.getExpression().getText();\n                           if (name == null) {\n                               return;\n                           }\n\n                           int prefixLength = parameters.getOffset() - simpleNameReference.getExpression().getTextOffset();\n                           result = result.withPrefixMatcher(new PlainPrefixMatcher(name.substring(0, prefixLength)));\n\n                           BindingContext bindingContext = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(\n                                   (JetFile)namespaceHeader.getContainingFile())\n                                   .getBindingContext();\n\n                           for (LookupElement variant : DescriptorLookupConverter.collectLookupElements(\n                                   bindingContext, TipsManager.getReferenceVariants(namespaceHeader, bindingContext))) {\n                               if (!variant.getLookupString().contains(DUMMY_IDENTIFIER)) {\n                                   result.addElement(variant);\n                               }\n                           }\n\n                           result.stopHere();\n                       }\n                   }\n               });\n    }","id":37932,"modified_method":"public JetPackagesContributor() {\n        extend(CompletionType.BASIC, PlatformPatterns.psiElement(),\n               new CompletionProvider<CompletionParameters>() {\n                   @Override\n                   protected void addCompletions(@NotNull CompletionParameters parameters, ProcessingContext context,\n                                                 @NotNull CompletionResultSet result) {\n\n                       final PsiElement position = parameters.getPosition();\n                       if (!(position.getContainingFile() instanceof JetFile)) {\n                           return;\n                       }\n\n                       JetNamespaceHeader namespaceHeader = PsiTreeUtil.getParentOfType(position, JetNamespaceHeader.class);\n                       if (namespaceHeader == null) {\n                           return;\n                       }\n\n                       final PsiReference ref = parameters.getPosition().getContainingFile().findReferenceAt(parameters.getOffset());\n\n                       if (ref instanceof JetSimpleNameReference) {\n                           JetSimpleNameReference simpleNameReference = (JetSimpleNameReference)ref;\n\n                           String name = simpleNameReference.getExpression().getText();\n                           if (name == null) {\n                               return;\n                           }\n\n                           int prefixLength = parameters.getOffset() - simpleNameReference.getExpression().getTextOffset();\n                           result = result.withPrefixMatcher(new PlainPrefixMatcher(name.substring(0, prefixLength)));\n\n                           BindingContext bindingContext = WholeProjectAnalyzerFacade.getLazyResolveContext(\n                                   (JetFile) namespaceHeader.getContainingFile(), simpleNameReference.getExpression());\n\n                           for (LookupElement variant : DescriptorLookupConverter.collectLookupElements(\n                                   bindingContext, TipsManager.getPackageReferenceVariants(simpleNameReference.getExpression(), bindingContext))) {\n                               if (!variant.getLookupString().contains(DUMMY_IDENTIFIER)) {\n                                   result.addElement(variant);\n                               }\n                           }\n\n                           result.stopHere();\n                       }\n                   }\n               });\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public Collection<DeclarationDescriptor> getJetCallableExtensions(\n            @NotNull Condition<String> acceptedNameCondition,\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull GlobalSearchScope searchScope\n    ) {\n        Collection<DeclarationDescriptor> resultDescriptors = new ArrayList<DeclarationDescriptor>();\n\n        JetFile jetFile = (JetFile) expression.getContainingFile();\n\n        BindingContext context = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(jetFile).getBindingContext();\n        JetExpression receiverExpression = expression.getReceiverExpression();\n\n        if (receiverExpression != null) {\n            JetType expressionType = context.get(BindingContext.EXPRESSION_TYPE, receiverExpression);\n            JetScope scope = context.get(BindingContext.RESOLUTION_SCOPE, receiverExpression);\n\n            if (expressionType != null && scope != null) {\n                Collection<String> extensionFunctionsNames = getAllJetExtensionFunctionsNames(searchScope);\n\n                Set<FqName> functionFQNs = new java.util.HashSet<FqName>();\n\n                // Collect all possible extension function qualified names\n                for (String name : extensionFunctionsNames) {\n                    if (acceptedNameCondition.value(name)) {\n                        Collection<PsiElement> extensionFunctions = getJetExtensionFunctionsByName(name, searchScope);\n\n                        for (PsiElement extensionFunction : extensionFunctions) {\n                            if (extensionFunction instanceof JetNamedFunction) {\n                                functionFQNs.add(JetPsiUtil.getFQName((JetNamedFunction) extensionFunction));\n                            }\n                            else if (extensionFunction instanceof PsiMethod) {\n                                FqName functionFQN = JetFromJavaDescriptorHelper.getJetTopLevelDeclarationFQN((PsiMethod) extensionFunction);\n                                if (functionFQN != null) {\n                                    functionFQNs.add(functionFQN);\n                                }\n                            }\n                        }\n                    }\n                }\n\n                // Iterate through the function with attempt to resolve found functions\n                for (FqName functionFQN : functionFQNs) {\n                    for (CallableDescriptor functionDescriptor : ExpressionTypingUtils.canFindSuitableCall(\n                            functionFQN, project, receiverExpression, expressionType, scope)) {\n\n                        resultDescriptors.add(functionDescriptor);\n                    }\n                }\n            }\n        }\n\n        return resultDescriptors;\n    }","id":37933,"modified_method":"public Collection<DeclarationDescriptor> getJetCallableExtensions(\n            @NotNull Condition<String> acceptedNameCondition,\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull GlobalSearchScope searchScope\n    ) {\n        Collection<DeclarationDescriptor> resultDescriptors = new ArrayList<DeclarationDescriptor>();\n\n        JetFile jetFile = (JetFile) expression.getContainingFile();\n\n        BindingContext context = WholeProjectAnalyzerFacade.getLazyResolveContext(jetFile, expression);\n        JetExpression receiverExpression = expression.getReceiverExpression();\n\n        if (receiverExpression != null) {\n            JetType expressionType = context.get(BindingContext.EXPRESSION_TYPE, receiverExpression);\n            JetScope scope = context.get(BindingContext.RESOLUTION_SCOPE, receiverExpression);\n\n            if (expressionType != null && scope != null) {\n                Collection<String> extensionFunctionsNames = getAllJetExtensionFunctionsNames(searchScope);\n\n                Set<FqName> functionFQNs = new java.util.HashSet<FqName>();\n\n                // Collect all possible extension function qualified names\n                for (String name : extensionFunctionsNames) {\n                    if (acceptedNameCondition.value(name)) {\n                        Collection<PsiElement> extensionFunctions = getJetExtensionFunctionsByName(name, searchScope);\n\n                        for (PsiElement extensionFunction : extensionFunctions) {\n                            if (extensionFunction instanceof JetNamedFunction) {\n                                functionFQNs.add(JetPsiUtil.getFQName((JetNamedFunction) extensionFunction));\n                            }\n                            else if (extensionFunction instanceof PsiMethod) {\n                                FqName functionFQN = JetFromJavaDescriptorHelper.getJetTopLevelDeclarationFQN((PsiMethod) extensionFunction);\n                                if (functionFQN != null) {\n                                    functionFQNs.add(functionFQN);\n                                }\n                            }\n                        }\n                    }\n                }\n\n                // Iterate through the function with attempt to resolve found functions\n                for (FqName functionFQN : functionFQNs) {\n                    for (CallableDescriptor functionDescriptor : ExpressionTypingUtils.canFindSuitableCall(\n                            functionFQN, project, receiverExpression, expressionType, scope)) {\n\n                        resultDescriptors.add(functionDescriptor);\n                    }\n                }\n            }\n        }\n\n        return resultDescriptors;\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public Collection<ClassDescriptor> getJetClassesDescriptors(\n            @NotNull Condition<String> acceptedShortNameCondition,\n            @NotNull JetFile jetFile\n    ) {\n        BindingContext context = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(jetFile).getBindingContext();\n        Collection<ClassDescriptor> classDescriptors = new ArrayList<ClassDescriptor>();\n\n        for (String fqName : JetFullClassNameIndex.getInstance().getAllKeys(project)) {\n            FqName classFQName = new FqName(fqName);\n            if (acceptedShortNameCondition.value(classFQName.shortName().getName())) {\n                ClassDescriptor descriptor = context.get(BindingContext.FQNAME_TO_CLASS_DESCRIPTOR, classFQName);\n                if (descriptor != null) {\n                    classDescriptors.add(descriptor);\n                }\n            }\n        }\n\n        return classDescriptors;\n    }","id":37934,"modified_method":"public Collection<ClassDescriptor> getJetClassesDescriptors(\n            @NotNull Condition<String> acceptedShortNameCondition,\n            @NotNull JetFile jetFile\n    ) {\n        BindingContext context = WholeProjectAnalyzerFacade.getLazyResolveContext(jetFile, null);\n        Collection<ClassDescriptor> classDescriptors = new ArrayList<ClassDescriptor>();\n\n        for (String fqName : JetFullClassNameIndex.getInstance().getAllKeys(project)) {\n            FqName classFQName = new FqName(fqName);\n            if (acceptedShortNameCondition.value(classFQName.shortName().getName())) {\n                ClassDescriptor descriptor = context.get(BindingContext.FQNAME_TO_CLASS_DESCRIPTOR, classFQName);\n                if (descriptor != null) {\n                    classDescriptors.add(descriptor);\n                }\n            }\n        }\n\n        return classDescriptors;\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    public Collection<FunctionDescriptor> getTopLevelFunctionDescriptorsByName(\n            @NotNull String name,\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull GlobalSearchScope scope\n    ) {\n        HashSet<FunctionDescriptor> result = new HashSet<FunctionDescriptor>();\n\n        JetFile jetFile = (JetFile) expression.getContainingFile();\n        BindingContext context = WholeProjectAnalyzerFacade.analyzeProjectWithCacheOnAFile(jetFile).getBindingContext();\n        JetScope jetScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n\n        if (jetScope == null) {\n            return result;\n        }\n\n        Collection<PsiMethod> topLevelFunctionPrototypes = JetFromJavaDescriptorHelper.getTopLevelFunctionPrototypesByName(name, project, scope);\n        for (PsiMethod method : topLevelFunctionPrototypes) {\n            FqName functionFQN = JetFromJavaDescriptorHelper.getJetTopLevelDeclarationFQN(method);\n            if (functionFQN != null) {\n                JetImportDirective importDirective = JetPsiFactory.createImportDirective(project, new ImportPath(functionFQN, false));\n                Collection<? extends DeclarationDescriptor> declarationDescriptors = new QualifiedExpressionResolver().analyseImportReference(importDirective, jetScope, new BindingTraceContext());\n                for (DeclarationDescriptor declarationDescriptor : declarationDescriptors) {\n                    if (declarationDescriptor instanceof FunctionDescriptor) {\n                        result.add((FunctionDescriptor) declarationDescriptor);\n                    }\n                }\n            }\n        }\n\n        Collection<JetNamedFunction> jetNamedFunctions = JetShortFunctionNameIndex.getInstance().get(name, project, scope);\n        for (JetNamedFunction jetNamedFunction : jetNamedFunctions) {\n            SimpleFunctionDescriptor functionDescriptor = context.get(BindingContext.FUNCTION, jetNamedFunction);\n            if (functionDescriptor != null) {\n                result.add(functionDescriptor);\n            }\n        }\n\n        return result;\n    }","id":37935,"modified_method":"@NotNull\n    public Collection<FunctionDescriptor> getTopLevelFunctionDescriptorsByName(\n            @NotNull String name,\n            @NotNull JetSimpleNameExpression expression,\n            @NotNull GlobalSearchScope scope\n    ) {\n        JetFile jetFile = (JetFile) expression.getContainingFile();\n        final ResolveSession resolveSessionForFile = WholeProjectAnalyzerFacade.getLazyResolveSessionForFile(jetFile);\n        LazyBindingContextUtils.getExpressionBindingContext(resolveSessionForFile, expression);\n        BindingContext context = WholeProjectAnalyzerFacade.getLazyResolveContext(jetFile, expression);\n        JetScope jetScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n\n        if (jetScope == null) {\n            return Collections.emptyList();\n        }\n\n        Set<FunctionDescriptor> result = Sets.newHashSet();\n\n        Collection<PsiMethod> topLevelFunctionPrototypes = JetFromJavaDescriptorHelper.getTopLevelFunctionPrototypesByName(name, project, scope);\n        for (PsiMethod method : topLevelFunctionPrototypes) {\n            FqName functionFQN = JetFromJavaDescriptorHelper.getJetTopLevelDeclarationFQN(method);\n            if (functionFQN != null) {\n                JetImportDirective importDirective = JetPsiFactory.createImportDirective(project, new ImportPath(functionFQN, false));\n                Collection<? extends DeclarationDescriptor> declarationDescriptors = new QualifiedExpressionResolver().analyseImportReference(\n                        importDirective, jetScope, new BindingTraceContext());\n                for (DeclarationDescriptor declarationDescriptor : declarationDescriptors) {\n                    if (declarationDescriptor instanceof FunctionDescriptor) {\n                        result.add((FunctionDescriptor) declarationDescriptor);\n                    }\n                }\n            }\n        }\n\n        Collection<JetNamedFunction> jetNamedFunctions = JetShortFunctionNameIndex.getInstance().get(name, project, scope);\n        for (JetNamedFunction jetNamedFunction : jetNamedFunctions) {\n            FunctionDescriptor functionDescriptor = (FunctionDescriptor) resolveSessionForFile.resolveToDescriptor(jetNamedFunction);\n            result.add(functionDescriptor);\n        }\n\n        return result;\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    public static Collection<DeclarationDescriptor> getReferenceVariants(JetSimpleNameExpression expression, BindingContext context) {\n        JetExpression receiverExpression = expression.getReceiverExpression();\n        if (receiverExpression != null) {\n            // Process as call expression\n            final JetScope resolutionScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n            final JetType expressionType = context.get(BindingContext.EXPRESSION_TYPE, receiverExpression);\n\n            if (expressionType != null && resolutionScope != null) {\n                if (!(expressionType instanceof NamespaceType)) {\n                    ExpressionReceiver receiverDescriptor = new ExpressionReceiver(receiverExpression, expressionType);\n                    Set<DeclarationDescriptor> descriptors = new HashSet<DeclarationDescriptor>();\n\n                    DataFlowInfo info = context.get(BindingContext.NON_DEFAULT_EXPRESSION_DATA_FLOW, expression);\n                    if (info == null) {\n                        info = DataFlowInfo.EMPTY;\n                    }\n\n                    AutoCastServiceImpl autoCastService = new AutoCastServiceImpl(info, context);\n                    List<ReceiverDescriptor> variantsForExplicitReceiver = autoCastService.getVariantsForReceiver(receiverDescriptor);\n\n                    for (ReceiverDescriptor descriptor : variantsForExplicitReceiver) {\n                        descriptors.addAll(includeExternalCallableExtensions(\n                                excludePrivateDescriptors(descriptor.getType().getMemberScope().getAllDescriptors()),\n                                resolutionScope, descriptor));\n                    }\n\n                    return descriptors;\n                }\n\n                return includeExternalCallableExtensions(\n                        excludePrivateDescriptors(expressionType.getMemberScope().getAllDescriptors()),\n                        resolutionScope, new ExpressionReceiver(receiverExpression, expressionType));\n            }\n            return Collections.emptyList();\n        }\n        else {\n            return getVariantsNoReceiver(expression, context);\n        }\n    }","id":37936,"modified_method":"@NotNull\n    public static Collection<DeclarationDescriptor> getReferenceVariants(\n            @NotNull final JetSimpleNameExpression expression,\n            @NotNull final BindingContext context\n    ) {\n        JetExpression receiverExpression = expression.getReceiverExpression();\n        if (receiverExpression != null) {\n            // Process as call expression\n            JetScope resolutionScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n            JetType expressionType = context.get(BindingContext.EXPRESSION_TYPE, receiverExpression);\n\n            if (expressionType != null && resolutionScope != null) {\n                if (!(expressionType instanceof NamespaceType)) {\n                    ExpressionReceiver receiverDescriptor = new ExpressionReceiver(receiverExpression, expressionType);\n                    Set<DeclarationDescriptor> descriptors = new HashSet<DeclarationDescriptor>();\n\n                    DataFlowInfo info = context.get(BindingContext.NON_DEFAULT_EXPRESSION_DATA_FLOW, expression);\n                    if (info == null) {\n                        info = DataFlowInfo.EMPTY;\n                    }\n\n                    AutoCastServiceImpl autoCastService = new AutoCastServiceImpl(info, context);\n                    List<ReceiverDescriptor> variantsForExplicitReceiver = autoCastService.getVariantsForReceiver(receiverDescriptor);\n\n                    for (ReceiverDescriptor descriptor : variantsForExplicitReceiver) {\n                        descriptors.addAll(includeExternalCallableExtensions(\n                                excludePrivateDescriptors(descriptor.getType().getMemberScope().getAllDescriptors()),\n                                resolutionScope, descriptor));\n                    }\n\n                    return descriptors;\n                }\n\n                return includeExternalCallableExtensions(\n                        excludePrivateDescriptors(expressionType.getMemberScope().getAllDescriptors()),\n                        resolutionScope, new ExpressionReceiver(receiverExpression, expressionType));\n            }\n            return Collections.emptyList();\n        }\n        else {\n            return getVariantsNoReceiver(expression, context);\n        }\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    public static Collection<DeclarationDescriptor> getReferenceVariants(JetNamespaceHeader expression, BindingContext context) {\n        JetScope resolutionScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n        if (resolutionScope != null) {\n            return excludeNonPackageDescriptors(resolutionScope.getAllDescriptors());\n        }\n\n        return Collections.emptyList();\n    }","id":37937,"modified_method":"@NotNull\n    public static Collection<DeclarationDescriptor> getPackageReferenceVariants(JetSimpleNameExpression expression, BindingContext context) {\n        JetScope resolutionScope = context.get(BindingContext.RESOLUTION_SCOPE, expression);\n        if (resolutionScope != null) {\n            return excludeNonPackageDescriptors(resolutionScope.getAllDescriptors());\n        }\n\n        return Collections.emptyList();\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n     * Forbid creating\n     */\n    private WholeProjectAnalyzerFacade() {\n    }","id":37938,"modified_method":"private WholeProjectAnalyzerFacade() {\n    }","commit_id":"365bb3ad8a47634e0085c0e8efb5ecde65d0e0f3","url":"https://github.com/JetBrains/kotlin"},{"original_method":"/**\n\t\t * @see java.lang.Object#hashCode()\n\t\t */\n\t\t@Override\n\t\tpublic int hashCode()\n\t\t{\n\t\t\treturn contribution.hashCode();\n\t\t}","id":37939,"modified_method":"/**\n\t\t * @see java.lang.Object#hashCode()\n\t\t */\n\t\t@Override\n\t\tpublic int hashCode()\n\t\t{\n\t\t\tObject object = contribution.getObject(null);\n\t\t\treturn (object != null) ? object.hashCode() : 0;\n\t\t}","commit_id":"db6e43300ce256953c7db551eb483c614eb89c0e","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t\t * @see java.lang.Object#equals(java.lang.Object)\n\t\t */\n\t\t@Override\n\t\tpublic boolean equals(Object obj)\n\t\t{\n\t\t\tif (obj instanceof StringContributor)\n\t\t\t{\n\t\t\t\treturn ((StringContributor)obj).equals(this);\n\t\t\t}\n\t\t\treturn false;\n\t\t}","id":37940,"modified_method":"/**\n\t\t * @see java.lang.Object#equals(java.lang.Object)\n\t\t */\n\t\t@Override\n\t\tpublic boolean equals(Object obj)\n\t\t{\n\t\t\tif (obj instanceof StringContributor)\n\t\t\t{\n\t\t\t\tObject thisContrib = contribution.getObject(null);\n\t\t\t\tObject thatContrib = ((StringContributor)obj).contribution.getObject(null);\n\t\t\t\treturn Objects.equal(thisContrib, thatContrib);\n\t\t\t}\n\t\t\treturn false;\n\t\t}","commit_id":"db6e43300ce256953c7db551eb483c614eb89c0e","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t\t * Construct.\n\t\t * \n\t\t * @param contribution\n\t\t *            The contribution as a plain string\n\t\t */\n\t\tpublic StringContributor(String contribution)\n\t\t{\n\t\t\tif (contribution == null)\n\t\t\t{\n\t\t\t\tthrow new IllegalArgumentException(\"argument contribition must be not null\");\n\t\t\t}\n\n\t\t\tthis.contribution = new Model(contribution);\n\t\t}","id":37941,"modified_method":"/**\n\t\t * Construct.\n\t\t * \n\t\t * @param contribution\n\t\t *            The contribution as a plain string\n\t\t */\n\t\tpublic StringContributor(String contribution)\n\t\t{\n\t\t\tif (contribution == null)\n\t\t\t{\n\t\t\t\tthrow new IllegalArgumentException(\"argument contribition must be not null\");\n\t\t\t}\n\n\t\t\tthis.contribution = new Model<String>(contribution);\n\t\t}","commit_id":"db6e43300ce256953c7db551eb483c614eb89c0e","url":"https://github.com/apache/wicket"},{"original_method":"@Override\n\tpublic boolean checkTrigger(GameEvent event, Game game) {\n\t\t//Something hit the stack from the hand, see if its a spell with this ability.\n\t\tif ( event.getType() == EventType.ZONE_CHANGE &&\n\t\t\t ((ZoneChangeEvent)event).getFromZone() == Zone.HAND &&\n\t\t\t ((ZoneChangeEvent)event).getToZone() == Zone.STACK )\n\t\t{\n\t\t\tCard card = (Card)game.getObject(event.getTargetId());\n\n\t\t\tif ( card.getAbilities().contains(this) ) {\n\t\t\t\tthis.installReboundEffect = true;\n\t\t\t}\n\t\t}\n\n\t\t//Only 'install' the effect on a successfully cast spell otherwise the user\n\t\t//may cancel before paying its costs and potentially having two copies rebound\n\t\tif ( event.getType() == EventType.SPELL_CAST && this.installReboundEffect ) {\n\t\t\tSpell spell = game.getStack().getSpell(event.getTargetId());\n\t\t\tif (spell != null && spell.getSourceId().equals(this.getSourceId())) {\n\t\t\t\tspell.getSpellAbility().addEffect(new ReboundEffect(spell.getId()));\n\t\t\t\tthis.installReboundEffect = false;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}","id":37942,"modified_method":"@Override\n\tpublic boolean checkTrigger(GameEvent event, Game game) {\n\t\t//Something hit the stack from the hand, see if its a spell with this ability.\n\t\tif ( event.getType() == EventType.ZONE_CHANGE &&\n\t\t\t ((ZoneChangeEvent)event).getFromZone() == Zone.HAND &&\n\t\t\t ((ZoneChangeEvent)event).getToZone() == Zone.STACK )\n\t\t{\n\t\t\tCard card = (Card)game.getObject(event.getTargetId());\n\n\t\t\tif ( card.getAbilities().contains(this) ) {\n\t\t\t\tthis.installReboundEffect = true;\n\t\t\t}\n\t\t}\n\n\t\t//Only 'install' the effect on a successfully cast spell otherwise the user\n\t\t//may cancel before paying its costs and potentially having two copies rebound\n\t\tif ( event.getType() == EventType.SPELL_CAST && this.installReboundEffect ) {\n\t\t\tSpell spell = game.getStack().getSpell(event.getTargetId());\n\t\t\tif (spell != null && spell.getSourceId().equals(this.getSourceId())) {\n\t\t\t\tspell.getSpellAbility().addEffect(new ReboundEffect());\n\t\t\t\tthis.installReboundEffect = false;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}","commit_id":"e0fb91f380a2daee4ec9e4a748908867d949d272","url":"https://github.com/magefree/mage"},{"original_method":"@Override\n\tpublic boolean apply(Game game, Ability source) {\n\t\tif (!originalId.equals(source.getId())) {\n\t\t\tlog.warn(\"rebound was ignored. was it copied spell?\");\n\t\t\treturn false;\n\t\t}\n\n\t\tCard sourceCard = (Card)game.getObject(source.getSourceId());\n\t\tReboundEffectCastFromExileDelayedTrigger trigger = new ReboundEffectCastFromExileDelayedTrigger(sourceCard.getId(), sourceCard.getId());\n\t\ttrigger.setControllerId(source.getControllerId());\n\t\tgame.addDelayedTriggeredAbility(trigger);\n\n\t\tgame.getContinuousEffects().addEffect(new ReboundCastFromHandReplacementEffect(sourceCard.getId()), source);\n\t\treturn true;\n\t}","id":37943,"modified_method":"@Override\n\tpublic boolean apply(Game game, Ability source) {\n\t\tSpell sourceSpell = (Spell)game.getObject(source.getId());\n\t\tif ( sourceSpell.isCopiedSpell() ) {\n\t\t\treturn false;\n\t\t}\n\t\telse {\n\t\t\tCard sourceCard = (Card)game.getObject(source.getSourceId());\n\t\t\tReboundEffectCastFromExileDelayedTrigger trigger = new ReboundEffectCastFromExileDelayedTrigger(sourceCard.getId(), sourceCard.getId());\n\t\t\ttrigger.setControllerId(source.getControllerId());\n\t\t\tgame.addDelayedTriggeredAbility(trigger);\n\n\t\t\tgame.getContinuousEffects().addEffect(new ReboundCastFromHandReplacementEffect(sourceCard.getId()), source);\n\t\t\treturn true;\n\t\t}\n\t}","commit_id":"e0fb91f380a2daee4ec9e4a748908867d949d272","url":"https://github.com/magefree/mage"},{"original_method":"public ReboundEffect ( ReboundEffect effect ) {\n\t\tsuper(effect);\n\t\tthis.originalId = effect.originalId;\n\t}","id":37944,"modified_method":"public ReboundEffect ( ReboundEffect effect ) {\n\t\tsuper(effect);\n\t}","commit_id":"e0fb91f380a2daee4ec9e4a748908867d949d272","url":"https://github.com/magefree/mage"},{"original_method":"@Override\n\tpublic boolean replaceEvent(GameEvent event, Ability source, Game game) {\n\t\tCard sourceCard = (Card)game.getObject(source.getSourceId());\n\t\tPlayer player = game.getPlayer(sourceCard.getOwnerId());\n\n\t\tsourceCard.moveToExile(source.getSourceId(), player.getName() + \" Rebound Exile\", source.getId(), game);\n\t\tthis.used = true;\n\n\t\treturn true;\n\t}","id":37945,"modified_method":"@Override\n\tpublic boolean replaceEvent(GameEvent event, Ability source, Game game) {\n\t\tSpell sourceSpell = (Spell)game.getObject(source.getId());\n\t\tif ( sourceSpell.isCopiedSpell() ) {\n\t\t\treturn false;\n\t\t}\n\t\telse {\n\t\t\tCard sourceCard = (Card)game.getObject(source.getSourceId());\n\t\t\tPlayer player = game.getPlayer(sourceCard.getOwnerId());\n\n\t\t\tsourceCard.moveToExile(source.getSourceId(), player.getName() + \" Rebound Exile\", source.getId(), game);\n\t\t\tthis.used = true;\n\n\t\t\treturn true;\n\t\t}\n\t}","commit_id":"e0fb91f380a2daee4ec9e4a748908867d949d272","url":"https://github.com/magefree/mage"},{"original_method":"public ReboundEffect(UUID originalId) {\n\t\tsuper(Outcome.Benefit);\n\t\tthis.originalId = originalId;\n\t}","id":37946,"modified_method":"public ReboundEffect() {\n\t\tsuper(Outcome.Benefit);\n\t}","commit_id":"e0fb91f380a2daee4ec9e4a748908867d949d272","url":"https://github.com/magefree/mage"},{"original_method":"/**\n\t\t * @see java.lang.Object#equals(java.lang.Object)\n\t\t */\n\t\tpublic boolean equals(Object obj)\n\t\t{\n\t\t\tif (obj instanceof StringContributor)\n\t\t\t{\n\t\t\t\treturn ((StringContributor)obj).equals(this);\n\t\t\t}\n\t\t\treturn false;\n\t\t}","id":37947,"modified_method":"/**\n\t\t * @see java.lang.Object#equals(java.lang.Object)\n\t\t */\n\t\tpublic boolean equals(Object obj)\n\t\t{\n\t\t\tif (obj instanceof StringContributor)\n\t\t\t{\n\t\t\t\tObject thisContrib = contribution.getObject(null);\n\t\t\t\tObject thatContrib = ((StringContributor)obj).contribution.getObject(null);\n\t\t\t\treturn Objects.equal(thisContrib, thatContrib);\n\t\t\t}\n\t\t\treturn false;\n\t\t}","commit_id":"7ebbc090d6351eec388bd531a5760a9d023cff20","url":"https://github.com/apache/wicket"},{"original_method":"/**\n\t\t * @see java.lang.Object#hashCode()\n\t\t */\n\t\tpublic int hashCode()\n\t\t{\n\t\t\treturn contribution.hashCode();\n\t\t}","id":37948,"modified_method":"/**\n\t\t * @see java.lang.Object#hashCode()\n\t\t */\n\t\tpublic int hashCode()\n\t\t{\n\t\t\tObject object = contribution.getObject(null);\n\t\t\treturn (object != null) ? object.hashCode() : 0;\n\t\t}","commit_id":"7ebbc090d6351eec388bd531a5760a9d023cff20","url":"https://github.com/apache/wicket"},{"original_method":"/**\n     * Check various properties set in the policy of the binding\n     */\n    protected boolean checkProperties(\n        AbstractSymmetricAsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults,\n        Message message\n    ) {\n        // Check the IncludeTimestamp\n        if (!validateTimestamp(binding.isIncludeTimestamp(), false, results, signedResults, message)) {\n            String error = \"Received Timestamp does not match the requirements\";\n            ai.setNotAsserted(error);\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, SPConstants.INCLUDE_TIMESTAMP);\n        \n        // Check the EntireHeaderAndBodySignatures property\n        if (binding.isOnlySignEntireHeadersAndBody()\n            && !validateEntireHeaderAndBodySignatures(signedResults)) {\n            String error = \"OnlySignEntireHeadersAndBody does not match the requirements\";\n            ai.setNotAsserted(error);\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, SPConstants.ONLY_SIGN_ENTIRE_HEADERS_AND_BODY);\n        \n        // Check whether the signatures were encrypted or not\n        if (binding.isEncryptSignature() && !isSignatureEncrypted(results)) {\n            ai.setNotAsserted(\"The signature is not protected\");\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, SPConstants.ENCRYPT_SIGNATURE);\n        PolicyUtils.assertPolicy(aim, SPConstants.PROTECT_TOKENS);\n        \n        /*\n        // Check ProtectTokens\n        if (binding.isTokenProtection() && !isTokenProtected(results, signedResults)) {\n            ai.setNotAsserted(\"The token protection property is not valid\");\n            return false;\n        }\n        */\n        \n        return true;\n    }","id":37949,"modified_method":"/**\n     * Check various properties set in the policy of the binding\n     */\n    protected boolean checkProperties(\n        AbstractSymmetricAsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults,\n        Message message\n    ) {\n        // Check the IncludeTimestamp\n        if (!validateTimestamp(binding.isIncludeTimestamp(), false, results, signedResults, message)) {\n            String error = \"Received Timestamp does not match the requirements\";\n            ai.setNotAsserted(error);\n            return false;\n        }\n        String namespace = binding.getName().getNamespaceURI();\n        PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.INCLUDE_TIMESTAMP));\n        \n        // Check the EntireHeaderAndBodySignatures property\n        if (binding.isOnlySignEntireHeadersAndBody()\n            && !validateEntireHeaderAndBodySignatures(signedResults)) {\n            String error = \"OnlySignEntireHeadersAndBody does not match the requirements\";\n            ai.setNotAsserted(error);\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.ONLY_SIGN_ENTIRE_HEADERS_AND_BODY));\n        \n        // Check whether the signatures were encrypted or not\n        if (binding.isEncryptSignature() && !isSignatureEncrypted(results)) {\n            ai.setNotAsserted(\"The signature is not protected\");\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.ENCRYPT_SIGNATURE));\n        PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.PROTECT_TOKENS));\n        \n        /*\n        // Check ProtectTokens\n        if (binding.isTokenProtection() && !isTokenProtected(results, signedResults)) {\n            ai.setNotAsserted(\"The token protection property is not valid\");\n            return false;\n        }\n        */\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Check the Protection Order of the binding\n     */\n    protected boolean checkProtectionOrder(\n        AbstractSymmetricAsymmetricBinding binding, \n        AssertionInfoMap aim,\n        AssertionInfo ai,\n        List<WSSecurityEngineResult> results\n    ) {\n        ProtectionOrder protectionOrder = binding.getProtectionOrder();\n        if (protectionOrder == ProtectionOrder.EncryptBeforeSigning) {\n            if (!binding.isProtectTokens() && isSignedBeforeEncrypted(results)) {\n                ai.setNotAsserted(\"Not encrypted before signed\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.ENCRYPT_BEFORE_SIGNING);\n        } else if (protectionOrder == ProtectionOrder.SignBeforeEncrypting) { \n            if (isEncryptedBeforeSigned(results)) {\n                ai.setNotAsserted(\"Not signed before encrypted\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.SIGN_BEFORE_ENCRYPTING);\n        }\n        return true;\n    }","id":37950,"modified_method":"/**\n     * Check the Protection Order of the binding\n     */\n    protected boolean checkProtectionOrder(\n        AbstractSymmetricAsymmetricBinding binding, \n        AssertionInfoMap aim,\n        AssertionInfo ai,\n        List<WSSecurityEngineResult> results\n    ) {\n        ProtectionOrder protectionOrder = binding.getProtectionOrder();\n        String namespace = binding.getName().getNamespaceURI();\n        \n        if (protectionOrder == ProtectionOrder.EncryptBeforeSigning) {\n            if (!binding.isProtectTokens() && isSignedBeforeEncrypted(results)) {\n                ai.setNotAsserted(\"Not encrypted before signed\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.ENCRYPT_BEFORE_SIGNING));\n        } else if (protectionOrder == ProtectionOrder.SignBeforeEncrypting) { \n            if (isEncryptedBeforeSigned(results)) {\n                ai.setNotAsserted(\"Not signed before encrypted\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, new QName(namespace, SPConstants.SIGN_BEFORE_ENCRYPTING));\n        }\n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Process X509 Tokens.\n     */\n    protected boolean processX509Tokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<WSSecurityEngineResult>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<WSSecurityEngineResult>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.BST) {\n                BinarySecurity binarySecurity = \n                    (BinarySecurity)wser.get(WSSecurityEngineResult.TAG_BINARY_SECURITY_TOKEN);\n                if (binarySecurity instanceof X509Security\n                    || binarySecurity instanceof PKIPathSecurity) {\n                    if (derived) {\n                        WSSecurityEngineResult resultToStore = processX509DerivedTokenResult(wser);\n                        if (resultToStore != null) {\n                            dktResults.add(resultToStore);\n                        }\n                    }\n                    tokenResults.add(wser);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","id":37951,"modified_method":"/**\n     * Process X509 Tokens.\n     */\n    protected boolean processX509Tokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.BST) {\n                BinarySecurity binarySecurity = \n                    (BinarySecurity)wser.get(WSSecurityEngineResult.TAG_BINARY_SECURITY_TOKEN);\n                if (binarySecurity instanceof X509Security\n                    || binarySecurity instanceof PKIPathSecurity) {\n                    if (derived) {\n                        WSSecurityEngineResult resultToStore = processX509DerivedTokenResult(wser);\n                        if (resultToStore != null) {\n                            dktResults.add(resultToStore);\n                        }\n                    }\n                    tokenResults.add(wser);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Validate SignedElements or EncryptedElements policies\n     */\n    private boolean validateSignedEncryptedElements(\n        RequiredElements elements,\n        boolean content,\n        List<WSSecurityEngineResult> protResults,\n        List<WSSecurityEngineResult> tokenResults\n    ) {\n        if (elements == null) {\n            return true;\n        }\n        \n        List<org.apache.wss4j.policy.model.XPath> xpaths = elements.getXPaths();\n        \n        //Map<String, String> namespaces = elements.getDeclaredNamespaces();\n        //List<String> xpaths = elements.getXPathExpressions();\n        \n        if (xpaths != null) {\n            SOAPMessage soapMessage = message.getContent(SOAPMessage.class);\n            Element soapEnvelope = soapMessage.getSOAPPart().getDocumentElement();\n            \n            for (org.apache.wss4j.policy.model.XPath xPath : xpaths) {\n                if (!checkXPathResult(soapEnvelope, xPath.getXPath(), xPath.getPrefixNamespaceMap(), \n                                      protResults, tokenResults)) {\n                    return false;\n                }\n            }\n        }\n        \n        return true;\n    }","id":37952,"modified_method":"/**\n     * Validate SignedElements or EncryptedElements policies\n     */\n    private boolean validateSignedEncryptedElements(\n        RequiredElements elements,\n        boolean content,\n        List<WSSecurityEngineResult> protResults,\n        List<WSSecurityEngineResult> tokenResults\n    ) {\n        if (elements == null) {\n            return true;\n        }\n        \n        List<org.apache.wss4j.policy.model.XPath> xpaths = elements.getXPaths();\n        \n        //Map<String, String> namespaces = elements.getDeclaredNamespaces();\n        //List<String> xpaths = elements.getXPathExpressions();\n        \n        if (xpaths != null && !xpaths.isEmpty()) {\n            SOAPMessage soapMessage = message.getContent(SOAPMessage.class);\n            Element soapEnvelope = soapMessage.getSOAPPart().getDocumentElement();\n            \n            // XPathFactory and XPath are not thread-safe so we must recreate them\n            // each request.\n            final XPathFactory factory = XPathFactory.newInstance();\n            final XPath xpath = factory.newXPath();\n            \n            List<String> expressions = new ArrayList<>();\n            MapNamespaceContext namespaceContext = new MapNamespaceContext();\n            \n            for (org.apache.wss4j.policy.model.XPath xPath : xpaths) {\n                expressions.add(xPath.getXPath());\n                Map<String, String> namespaceMap = xPath.getPrefixNamespaceMap();\n                if (namespaceMap != null) {\n                    namespaceContext.addNamespaces(namespaceMap);\n                }\n            }\n            xpath.setNamespaceContext(namespaceContext);\n            \n            for (org.apache.wss4j.policy.model.XPath xPath : xpaths) {\n                if (!checkXPathResult(soapEnvelope, xpath, xPath.getXPath(), protResults, tokenResults)) {\n                    return false;\n                }\n            }\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Process KeyValue Tokens.\n     */\n    protected boolean processKeyValueTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<WSSecurityEngineResult>();\n        for (WSSecurityEngineResult wser : signedResults) {\n            PublicKey publicKey = \n                (PublicKey)wser.get(WSSecurityEngineResult.TAG_PUBLIC_KEY);\n            if (publicKey != null) {\n                tokenResults.add(wser);\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","id":37953,"modified_method":"/**\n     * Process KeyValue Tokens.\n     */\n    protected boolean processKeyValueTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<>();\n        for (WSSecurityEngineResult wser : signedResults) {\n            PublicKey publicKey = \n                (PublicKey)wser.get(WSSecurityEngineResult.TAG_PUBLIC_KEY);\n            if (publicKey != null) {\n                tokenResults.add(wser);\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"protected void assertSecurePartsIfTokenNotRequired(\n        AbstractSecurityAssertion securedPart, String localName, AssertionInfoMap aim\n    ) {\n        Collection<AssertionInfo> sp11Ais = aim.get(new QName(SP11Constants.SP_NS, localName));\n        if (sp11Ais != null && !sp11Ais.isEmpty()) {\n            for (AssertionInfo ai : sp11Ais) {\n                if (ai.getAssertion().equals(securedPart)) {\n                    ai.setAsserted(true);\n                }\n            }    \n        }\n\n        Collection<AssertionInfo> sp12Ais = aim.get(new QName(SP12Constants.SP_NS, localName));\n        if (sp12Ais != null && !sp12Ais.isEmpty()) {\n            for (AssertionInfo ai : sp12Ais) {\n                if (ai.getAssertion().equals(securedPart)) {\n                    ai.setAsserted(true);\n                }\n            }    \n        }\n    }","id":37954,"modified_method":"protected void assertSecurePartsIfTokenNotRequired(\n        AbstractSecurityAssertion securedPart, QName name, AssertionInfoMap aim\n    ) {\n        Collection<AssertionInfo> ais = aim.get(name);\n        if (ais != null && !ais.isEmpty()) {\n            for (AssertionInfo ai : ais) {\n                if (ai.getAssertion().equals(securedPart)) {\n                    ai.setAsserted(true);\n                }\n            }    \n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Process Kerberos Tokens.\n     */\n    protected boolean processKerberosTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<WSSecurityEngineResult>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<WSSecurityEngineResult>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.BST) {\n                BinarySecurity binarySecurity = \n                    (BinarySecurity)wser.get(WSSecurityEngineResult.TAG_BINARY_SECURITY_TOKEN);\n                if (binarySecurity instanceof KerberosSecurity) {\n                    if (derived) {\n                        byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                        WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                        if (dktResult != null) {\n                            dktResults.add(dktResult);\n                        }\n                    }\n                    tokenResults.add(wser);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","id":37955,"modified_method":"/**\n     * Process Kerberos Tokens.\n     */\n    protected boolean processKerberosTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.BST) {\n                BinarySecurity binarySecurity = \n                    (BinarySecurity)wser.get(WSSecurityEngineResult.TAG_BINARY_SECURITY_TOKEN);\n                if (binarySecurity instanceof KerberosSecurity) {\n                    if (derived) {\n                        byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                        WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                        if (dktResult != null) {\n                            dktResults.add(dktResult);\n                        }\n                    }\n                    tokenResults.add(wser);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Process UsernameTokens.\n     */\n    protected boolean processUsernameTokens() {\n        if (!validateUsernameToken) {\n            return true;\n        }\n        \n        List<WSSecurityEngineResult> tokenResults = new ArrayList<WSSecurityEngineResult>();\n        tokenResults.addAll(utResults);\n        List<WSSecurityEngineResult> dktResults = new ArrayList<WSSecurityEngineResult>();\n        for (WSSecurityEngineResult wser : utResults) {\n            if (derived) {\n                byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                if (dktResult != null) {\n                    dktResults.add(dktResult);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if ((endorsed && !checkEndorsed(tokenResults)) || !validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","id":37956,"modified_method":"/**\n     * Process UsernameTokens.\n     */\n    protected boolean processUsernameTokens() {\n        if (!validateUsernameToken) {\n            return true;\n        }\n        \n        List<WSSecurityEngineResult> tokenResults = new ArrayList<>();\n        tokenResults.addAll(utResults);\n        List<WSSecurityEngineResult> dktResults = new ArrayList<>();\n        for (WSSecurityEngineResult wser : utResults) {\n            if (derived) {\n                byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                if (dktResult != null) {\n                    dktResults.add(dktResult);\n                }\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if ((endorsed && !checkEndorsed(tokenResults)) || !validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Process Security Context Tokens.\n     */\n    protected boolean processSCTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<WSSecurityEngineResult>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<WSSecurityEngineResult>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.SCT) {\n                if (derived) {\n                    byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                    WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                    if (dktResult != null) {\n                        dktResults.add(dktResult);\n                    }\n                }\n                tokenResults.add(wser);\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","id":37957,"modified_method":"/**\n     * Process Security Context Tokens.\n     */\n    protected boolean processSCTokens() {\n        List<WSSecurityEngineResult> tokenResults = new ArrayList<>();\n        List<WSSecurityEngineResult> dktResults = new ArrayList<>();\n        for (WSSecurityEngineResult wser : results) {\n            Integer actInt = (Integer)wser.get(WSSecurityEngineResult.TAG_ACTION);\n            if (actInt.intValue() == WSConstants.SCT) {\n                if (derived) {\n                    byte[] secret = (byte[])wser.get(WSSecurityEngineResult.TAG_SECRET);\n                    WSSecurityEngineResult dktResult = getMatchingDerivedKey(secret);\n                    if (dktResult != null) {\n                        dktResults.add(dktResult);\n                    }\n                }\n                tokenResults.add(wser);\n            }\n        }\n        \n        if (tokenResults.isEmpty()) {\n            return false;\n        }\n        \n        if (signed && !areTokensSigned(tokenResults)) {\n            return false;\n        }\n        if (encrypted && !areTokensEncrypted(tokenResults)) {\n            return false;\n        }\n        tokenResults.addAll(dktResults);\n        if (endorsed && !checkEndorsed(tokenResults)) {\n            return false;\n        }\n        \n        if (!validateSignedEncryptedPolicies(tokenResults)) {\n            return false;\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Check a particular XPath result\n     */\n    private boolean checkXPathResult(\n        Element soapEnvelope,\n        String xPath,\n        Map<String, String> namespaces,\n        List<WSSecurityEngineResult> protResults,\n        List<WSSecurityEngineResult> tokenResults\n    ) {\n        // XPathFactory and XPath are not thread-safe so we must recreate them\n        // each request.\n        final XPathFactory factory = XPathFactory.newInstance();\n        final XPath xpath = factory.newXPath();\n        \n        if (namespaces != null) {\n            xpath.setNamespaceContext(new MapNamespaceContext(namespaces));\n        }\n        \n        // For each XPath\n        for (String xpathString : Arrays.asList(xPath)) {\n            // Get the matching nodes\n            NodeList list;\n            try {\n                list = (NodeList)xpath.evaluate(\n                        xpathString, \n                        soapEnvelope,\n                        XPathConstants.NODESET);\n            } catch (XPathExpressionException e) {\n                LOG.log(Level.FINE, e.getMessage(), e);\n                return false;\n            }\n            \n            // If we found nodes then we need to do the check.\n            if (list.getLength() != 0) {\n                // For each matching element, check for a ref that\n                // covers it.\n                for (int x = 0; x < list.getLength(); x++) {\n                    final Element el = (Element)list.item(x);\n                    \n                    if (!checkProtectionResult(el, false, protResults, tokenResults)) {\n                        return false;\n                    }\n                }\n            }\n        }\n        return true;\n    }","id":37958,"modified_method":"/**\n     * Check a particular XPath result\n     */\n    private boolean checkXPathResult(\n        Element soapEnvelope,\n        XPath xpath,\n        String xPathString,\n        List<WSSecurityEngineResult> protResults,\n        List<WSSecurityEngineResult> tokenResults\n    ) {\n        // Get the matching nodes\n        NodeList list;\n        try {\n            list = (NodeList)xpath.evaluate(xPathString, \n                                            soapEnvelope,\n                                            XPathConstants.NODESET);\n        } catch (XPathExpressionException e) {\n            LOG.log(Level.FINE, e.getMessage(), e);\n            return false;\n        }\n\n        // If we found nodes then we need to do the check.\n        if (list.getLength() != 0) {\n            // For each matching element, check for a ref that\n            // covers it.\n            for (int x = 0; x < list.getLength(); x++) {\n                final Element el = (Element)list.item(x);\n\n                if (!checkProtectionResult(el, false, protResults, tokenResults)) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"protected void assertSecurePartsIfTokenNotRequired(\n        SupportingTokens supportingToken, AssertionInfoMap aim\n    ) {\n        if (supportingToken.getSignedParts() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getSignedParts(),\n                                                SPConstants.SIGNED_PARTS, aim);\n        }\n        if (supportingToken.getSignedElements() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getSignedElements(),\n                                                SPConstants.SIGNED_ELEMENTS, aim);\n        }\n        if (supportingToken.getEncryptedParts() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getEncryptedParts(),\n                                                SPConstants.ENCRYPTED_PARTS, aim);\n        }\n        if (supportingToken.getEncryptedElements() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getEncryptedElements(),\n                                                SPConstants.ENCRYPTED_ELEMENTS, aim);\n        }\n    }","id":37959,"modified_method":"protected void assertSecurePartsIfTokenNotRequired(\n        SupportingTokens supportingToken, AssertionInfoMap aim\n    ) {\n        String namespace = supportingToken.getName().getNamespaceURI();\n        if (supportingToken.getSignedParts() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getSignedParts(),\n                                                new QName(namespace, SPConstants.SIGNED_PARTS), aim);\n        }\n        if (supportingToken.getSignedElements() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getSignedElements(),\n                                                new QName(namespace, SPConstants.SIGNED_ELEMENTS), aim);\n        }\n        if (supportingToken.getEncryptedParts() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getEncryptedParts(),\n                                                new QName(namespace, SPConstants.ENCRYPTED_PARTS), aim);\n        }\n        if (supportingToken.getEncryptedElements() != null) {\n            assertSecurePartsIfTokenNotRequired(supportingToken.getEncryptedElements(),\n                                                new QName(namespace, SPConstants.ENCRYPTED_ELEMENTS), aim);\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private boolean checkRecipientTokens(\n        AbstractTokenWrapper wrapper, \n        AsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim, \n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults) {\n\n        PolicyUtils.assertPolicy(aim, wrapper.getName());\n        if (!checkDerivedKeys(wrapper, hasDerivedKeys, signedResults, encryptedResults)) {\n            ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_DERIVED_KEYS);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_IMPLIED_DERIVED_KEYS);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXPLICIT_DERIVED_KEYS);\n\n        return true;\n    }","id":37960,"modified_method":"private boolean checkRecipientTokens(\n        AbstractTokenWrapper wrapper, \n        AsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim, \n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults) {\n\n        PolicyUtils.assertPolicy(aim, wrapper.getName());\n        if (!checkDerivedKeys(wrapper, hasDerivedKeys, signedResults, encryptedResults)) {\n            ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n            return false;\n        }\n        assertToken(wrapper, aim);\n\n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private boolean checkInitiatorTokens(\n        AbstractTokenWrapper wrapper, \n        AsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim, \n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults) {\n\n        AbstractToken token = wrapper.getToken();\n        if (token instanceof X509Token) {\n            boolean foundCert = false;\n            for (WSSecurityEngineResult result : signedResults) {\n                X509Certificate cert = (X509Certificate)result\n                    .get(WSSecurityEngineResult.TAG_X509_CERTIFICATE);\n                if (cert != null) {\n                    foundCert = true;\n                    break;\n                }\n            }\n            if (!foundCert && !signedResults.isEmpty()) {\n                String error = \"An X.509 certificate was not used for the \" + wrapper.getName();\n                notAssertPolicy(aim, wrapper.getName(), error);\n                ai.setNotAsserted(error);\n                return false;\n            }\n        }\n        PolicyUtils.assertPolicy(aim, wrapper.getName());\n        if (!checkDerivedKeys(wrapper, hasDerivedKeys, signedResults, encryptedResults)) {\n            ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n            return false;\n        }\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_DERIVED_KEYS);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_IMPLIED_DERIVED_KEYS);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXPLICIT_DERIVED_KEYS);\n\n        return true;\n    }","id":37961,"modified_method":"private boolean checkInitiatorTokens(\n        AbstractTokenWrapper wrapper, \n        AsymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim, \n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults) {\n\n        AbstractToken token = wrapper.getToken();\n        if (token instanceof X509Token) {\n            boolean foundCert = false;\n            for (WSSecurityEngineResult result : signedResults) {\n                X509Certificate cert = (X509Certificate)result\n                    .get(WSSecurityEngineResult.TAG_X509_CERTIFICATE);\n                if (cert != null) {\n                    foundCert = true;\n                    break;\n                }\n            }\n            if (!foundCert && !signedResults.isEmpty()) {\n                String error = \"An X.509 certificate was not used for the \" + wrapper.getName();\n                notAssertPolicy(aim, wrapper.getName(), error);\n                ai.setNotAsserted(error);\n                return false;\n            }\n        }\n        PolicyUtils.assertPolicy(aim, wrapper.getName());\n        if (!checkDerivedKeys(wrapper, hasDerivedKeys, signedResults, encryptedResults)) {\n            ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n            return false;\n        }\n        assertToken(wrapper, aim);\n\n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        Collection<AssertionInfo> ais,\n        SamlAssertionWrapper assertionWrapper\n    ) {\n        if (ais == null || ais.isEmpty()) {\n            return true;\n        }\n        \n        for (AssertionInfo ai : ais) {\n            IssuedToken issuedToken = (IssuedToken)ai.getAssertion();\n            ai.setAsserted(true);\n\n            if (!isTokenRequired(issuedToken, message)) {\n                continue;\n            }\n            \n            if (assertionWrapper == null) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            Element template = issuedToken.getRequestSecurityTokenTemplate();\n            if (template != null && !checkIssuedTokenTemplate(template, assertionWrapper)) {\n                ai.setNotAsserted(\"Error in validating the IssuedToken policy\");\n                continue;\n            }\n            \n            Element claims = issuedToken.getClaims();\n            if (claims != null) {\n                String dialect = claims.getAttributeNS(null, \"Dialect\");\n                if (claimsValidator.getDialect().equals(dialect)\n                    && !claimsValidator.validatePolicy(claims, assertionWrapper)) {\n                    ai.setNotAsserted(\"Error in validating the Claims policy\");\n                    continue;\n                }\n            }\n\n            TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n            Certificate[] tlsCerts = null;\n            if (tlsInfo != null) {\n                tlsCerts = tlsInfo.getPeerCertificates();\n            }\n            if (!checkHolderOfKey(assertionWrapper, signedResults, tlsCerts)) {\n                ai.setNotAsserted(\"Assertion fails holder-of-key requirements\");\n                continue;\n            }\n        }\n        \n        AssertionInfoMap aim = message.get(AssertionInfoMap.class);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_INTERNAL_REFERENCE);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXTERNAL_REFERENCE);\n        \n        return true;\n    }","id":37962,"modified_method":"public boolean validatePolicy(\n        Collection<AssertionInfo> ais,\n        SamlAssertionWrapper assertionWrapper\n    ) {\n        if (ais == null || ais.isEmpty()) {\n            return true;\n        }\n        \n        for (AssertionInfo ai : ais) {\n            IssuedToken issuedToken = (IssuedToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(issuedToken, message.get(AssertionInfoMap.class));\n\n            if (!isTokenRequired(issuedToken, message)) {\n                continue;\n            }\n            \n            if (assertionWrapper == null) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            Element template = issuedToken.getRequestSecurityTokenTemplate();\n            if (template != null && !checkIssuedTokenTemplate(template, assertionWrapper)) {\n                ai.setNotAsserted(\"Error in validating the IssuedToken policy\");\n                continue;\n            }\n            \n            Element claims = issuedToken.getClaims();\n            if (claims != null) {\n                String dialect = claims.getAttributeNS(null, \"Dialect\");\n                if (claimsValidator.getDialect().equals(dialect)\n                    && !claimsValidator.validatePolicy(claims, assertionWrapper)) {\n                    ai.setNotAsserted(\"Error in validating the Claims policy\");\n                    continue;\n                }\n            }\n\n            TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n            Certificate[] tlsCerts = null;\n            if (tlsInfo != null) {\n                tlsCerts = tlsInfo.getPeerCertificates();\n            }\n            if (!checkHolderOfKey(assertionWrapper, signedResults, tlsCerts)) {\n                ai.setNotAsserted(\"Assertion fails holder-of-key requirements\");\n                continue;\n            }\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        Collection<AssertionInfo> ais,\n        BinarySecurity binarySecurityToken\n    ) {\n        if (ais == null || ais.isEmpty()) {\n            return true;\n        }\n        \n        for (AssertionInfo ai : ais) {\n            IssuedToken issuedToken = (IssuedToken)ai.getAssertion();\n            ai.setAsserted(true);\n\n            if (!isTokenRequired(issuedToken, message)) {\n                continue;\n            }\n            if (binarySecurityToken == null) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                return false;\n            }\n\n            Element template = issuedToken.getRequestSecurityTokenTemplate();\n            if (template != null && !checkIssuedTokenTemplate(template, binarySecurityToken)) {\n                ai.setNotAsserted(\"Error in validating the IssuedToken policy\");\n                return false;\n            }\n        }\n        \n        AssertionInfoMap aim = message.get(AssertionInfoMap.class);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_INTERNAL_REFERENCE);\n        PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXTERNAL_REFERENCE);\n        \n        return true;\n    }","id":37963,"modified_method":"public boolean validatePolicy(\n        Collection<AssertionInfo> ais,\n        BinarySecurity binarySecurityToken\n    ) {\n        if (ais == null || ais.isEmpty()) {\n            return true;\n        }\n        \n        for (AssertionInfo ai : ais) {\n            IssuedToken issuedToken = (IssuedToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(issuedToken, message.get(AssertionInfoMap.class));\n\n            if (!isTokenRequired(issuedToken, message)) {\n                continue;\n            }\n            if (binarySecurityToken == null) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                return false;\n            }\n\n            Element template = issuedToken.getRequestSecurityTokenTemplate();\n            if (template != null && !checkIssuedTokenTemplate(template, binarySecurityToken)) {\n                ai.setNotAsserted(\"Error in validating the IssuedToken policy\");\n                return false;\n            }\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        AssertionInfoMap aim, \n        Collection<AssertionInfo> ais, \n        KerberosSecurity kerberosToken\n    ) {\n        for (AssertionInfo ai : ais) {\n            KerberosToken kerberosTokenPolicy = (KerberosToken)ai.getAssertion();\n            ai.setAsserted(true);\n            \n            if (!isTokenRequired(kerberosTokenPolicy, message)) {\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(kerberosTokenPolicy.getVersion().getNamespace(), \n                              \"WssKerberosV5ApReqToken11\")\n                );\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(kerberosTokenPolicy.getVersion().getNamespace(), \n                              \"WssGssKerberosV5ApReqToken11\")\n                );\n                continue;\n            }\n            \n            if (!checkToken(aim, kerberosTokenPolicy, kerberosToken)) {\n                ai.setNotAsserted(\"An incorrect Kerberos Token Type is detected\");\n                continue;\n            }\n        }\n    }","id":37964,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim, \n        Collection<AssertionInfo> ais, \n        KerberosSecurity kerberosToken\n    ) {\n        for (AssertionInfo ai : ais) {\n            KerberosToken kerberosTokenPolicy = (KerberosToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(kerberosTokenPolicy, aim);\n            \n            if (!isTokenRequired(kerberosTokenPolicy, message)) {\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(kerberosTokenPolicy.getVersion().getNamespace(), \n                              \"WssKerberosV5ApReqToken11\")\n                );\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(kerberosTokenPolicy.getVersion().getNamespace(), \n                              \"WssGssKerberosV5ApReqToken11\")\n                );\n                continue;\n            }\n            \n            if (!checkToken(aim, kerberosTokenPolicy, kerberosToken)) {\n                ai.setNotAsserted(\"An incorrect Kerberos Token Type is detected\");\n                continue;\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        KerberosSecurity kerberosToken\n    ) {\n        Collection<AssertionInfo> krbAis = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.KERBEROS_TOKEN);\n        if (!krbAis.isEmpty()) {\n            parsePolicies(aim, krbAis, kerberosToken);\n            \n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_KEY_IDENTIFIER_REFERENCE);\n        }\n        \n        return true;\n    }","id":37965,"modified_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        KerberosSecurity kerberosToken\n    ) {\n        Collection<AssertionInfo> krbAis = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.KERBEROS_TOKEN);\n        if (!krbAis.isEmpty()) {\n            parsePolicies(aim, krbAis, kerberosToken);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,  \n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        for (AssertionInfo ai : ais) {\n            Layout layout = (Layout)ai.getAssertion();\n            ai.setAsserted(true);\n            \n            if (!validatePolicy(layout, results, signedResults)) {\n                String error = \"Layout does not match the requirements\";\n                ai.setNotAsserted(error);\n            }\n        }\n        \n        PolicyUtils.assertPolicy(aim, SPConstants.LAYOUT_LAX);\n        PolicyUtils.assertPolicy(aim, SPConstants.LAYOUT_LAX_TIMESTAMP_FIRST);\n        PolicyUtils.assertPolicy(aim, SPConstants.LAYOUT_LAX_TIMESTAMP_LAST);\n        PolicyUtils.assertPolicy(aim, SPConstants.LAYOUT_STRICT);\n    }","id":37966,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,  \n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        for (AssertionInfo ai : ais) {\n            Layout layout = (Layout)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(layout, aim);\n            \n            if (!validatePolicy(layout, results, signedResults)) {\n                String error = \"Layout does not match the requirements\";\n                ai.setNotAsserted(error);\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        AssertionInfoMap aim, \n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        final List<Integer> actions = new ArrayList<Integer>(2);\n        actions.add(WSConstants.ST_SIGNED);\n        actions.add(WSConstants.ST_UNSIGNED);\n        List<WSSecurityEngineResult> samlResults = \n            WSSecurityUtil.fetchAllActionResults(results, actions);\n        \n        for (AssertionInfo ai : ais) {\n            SamlToken samlToken = (SamlToken)ai.getAssertion();\n            ai.setAsserted(true);\n\n            if (!isTokenRequired(samlToken, message)) {\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(samlToken.getVersion().getNamespace(), samlToken.getSamlTokenType().name())\n                );\n                continue;\n            }\n\n            if (samlResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n            \n            // All of the received SAML Assertions must conform to the policy\n            for (WSSecurityEngineResult result : samlResults) {\n                SamlAssertionWrapper assertionWrapper = \n                    (SamlAssertionWrapper)result.get(WSSecurityEngineResult.TAG_SAML_ASSERTION);\n                \n                if (!checkVersion(aim, samlToken, assertionWrapper)) {\n                    ai.setNotAsserted(\"Wrong SAML Version\");\n                    continue;\n                }\n                TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n                Certificate[] tlsCerts = null;\n                if (tlsInfo != null) {\n                    tlsCerts = tlsInfo.getPeerCertificates();\n                }\n                if (!checkHolderOfKey(assertionWrapper, signedResults, tlsCerts)) {\n                    ai.setNotAsserted(\"Assertion fails holder-of-key requirements\");\n                    continue;\n                }\n                if (!DOMSAMLUtil.checkSenderVouches(assertionWrapper, tlsCerts, body, signed)) {\n                    ai.setNotAsserted(\"Assertion fails sender-vouches requirements\");\n                    continue;\n                }\n                /*\n                    if (!checkIssuerName(samlToken, assertionWrapper)) {\n                        ai.setNotAsserted(\"Wrong IssuerName\");\n                    }\n                 */\n            }\n        }\n    }","id":37967,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim, \n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        final List<Integer> actions = new ArrayList<Integer>(2);\n        actions.add(WSConstants.ST_SIGNED);\n        actions.add(WSConstants.ST_UNSIGNED);\n        List<WSSecurityEngineResult> samlResults = \n            WSSecurityUtil.fetchAllActionResults(results, actions);\n        \n        for (AssertionInfo ai : ais) {\n            SamlToken samlToken = (SamlToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(samlToken, aim);\n\n            if (!isTokenRequired(samlToken, message)) {\n                PolicyUtils.assertPolicy(\n                    aim, \n                    new QName(samlToken.getVersion().getNamespace(), samlToken.getSamlTokenType().name())\n                );\n                continue;\n            }\n\n            if (samlResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n            \n            // All of the received SAML Assertions must conform to the policy\n            for (WSSecurityEngineResult result : samlResults) {\n                SamlAssertionWrapper assertionWrapper = \n                    (SamlAssertionWrapper)result.get(WSSecurityEngineResult.TAG_SAML_ASSERTION);\n                \n                if (!checkVersion(aim, samlToken, assertionWrapper)) {\n                    ai.setNotAsserted(\"Wrong SAML Version\");\n                    continue;\n                }\n                TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n                Certificate[] tlsCerts = null;\n                if (tlsInfo != null) {\n                    tlsCerts = tlsInfo.getPeerCertificates();\n                }\n                if (!checkHolderOfKey(assertionWrapper, signedResults, tlsCerts)) {\n                    ai.setNotAsserted(\"Assertion fails holder-of-key requirements\");\n                    continue;\n                }\n                if (!DOMSAMLUtil.checkSenderVouches(assertionWrapper, tlsCerts, body, signed)) {\n                    ai.setNotAsserted(\"Assertion fails sender-vouches requirements\");\n                    continue;\n                }\n                /*\n                    if (!checkIssuerName(samlToken, assertionWrapper)) {\n                        ai.setNotAsserted(\"Wrong IssuerName\");\n                    }\n                 */\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        body = soapBody;\n        signed = signedResults;\n        \n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.SAML_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(aim, ais, message, results, signedResults);\n            \n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_KEY_IDENTIFIER_REFERENCE);\n        }\n        \n        return true;\n    }","id":37968,"modified_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        body = soapBody;\n        signed = signedResults;\n        \n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.SAML_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(aim, ais, message, results, signedResults);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> sctResults = \n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.SCT);\n\n        for (AssertionInfo ai : ais) {\n            SecurityContextToken sctPolicy = (SecurityContextToken)ai.getAssertion();\n            ai.setAsserted(true);\n            \n            PolicyUtils.assertPolicy(aim, SP12Constants.REQUIRE_EXTERNAL_URI_REFERENCE);\n            PolicyUtils.assertPolicy(aim, SP12Constants.SC13_SECURITY_CONTEXT_TOKEN);\n            PolicyUtils.assertPolicy(aim, SP11Constants.SC10_SECURITY_CONTEXT_TOKEN);\n\n            if (!isTokenRequired(sctPolicy, message)) {\n                continue;\n            }\n\n            if (sctResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n        }\n    }","id":37969,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> sctResults = \n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.SCT);\n\n        for (AssertionInfo ai : ais) {\n            SecurityContextToken sctPolicy = (SecurityContextToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(sctPolicy, aim);\n            \n            if (!isTokenRequired(sctPolicy, message)) {\n                continue;\n            }\n\n            if (sctResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"/**\n     * Check various tokens of the binding\n     */\n    private boolean checkTokens(\n        SymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim,\n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults\n    ) {\n        if (binding.getEncryptionToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getEncryptionToken().getName());\n            if (!checkDerivedKeys(\n                binding.getEncryptionToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_IMPLIED_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXPLICIT_DERIVED_KEYS);\n        }\n        \n        if (binding.getSignatureToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getSignatureToken().getName());\n            if (!checkDerivedKeys(\n                binding.getSignatureToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_IMPLIED_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXPLICIT_DERIVED_KEYS);\n        }\n        \n        if (binding.getProtectionToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getProtectionToken().getName());\n            if (!checkDerivedKeys(\n                binding.getProtectionToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_IMPLIED_DERIVED_KEYS);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EXPLICIT_DERIVED_KEYS);\n        }\n        \n        return true;\n    }","id":37970,"modified_method":"/**\n     * Check various tokens of the binding\n     */\n    private boolean checkTokens(\n        SymmetricBinding binding, \n        AssertionInfo ai,\n        AssertionInfoMap aim,\n        boolean hasDerivedKeys,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> encryptedResults\n    ) {\n        if (binding.getEncryptionToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getEncryptionToken().getName());\n            if (!checkDerivedKeys(\n                binding.getEncryptionToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            assertToken(binding.getEncryptionToken(), aim);\n        }\n        \n        if (binding.getSignatureToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getSignatureToken().getName());\n            if (!checkDerivedKeys(\n                binding.getSignatureToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            assertToken(binding.getSignatureToken(), aim);\n        }\n        \n        if (binding.getProtectionToken() != null) {\n            PolicyUtils.assertPolicy(aim, binding.getProtectionToken().getName());\n            if (!checkDerivedKeys(\n                binding.getProtectionToken(), hasDerivedKeys, signedResults, encryptedResults\n            )) {\n                ai.setNotAsserted(\"Message fails the DerivedKeys requirement\");\n                return false;\n            }\n            assertToken(binding.getProtectionToken(), aim);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        for (AssertionInfo ai : ais) {\n            TransportBinding binding = (TransportBinding)ai.getAssertion();\n            ai.setAsserted(true);\n            \n            // Check that TLS is in use if we are not the requestor\n            boolean initiator = MessageUtils.isRequestor(message);\n            TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n            if (!initiator && tlsInfo == null) {\n                ai.setNotAsserted(\"TLS is not enabled\");\n                continue;\n            }\n            \n            // HttpsToken is validated by the HttpsTokenInterceptorProvider\n            if (binding.getTransportToken() != null) {\n                PolicyUtils.assertPolicy(aim, binding.getTransportToken().getName());\n            }\n            \n            // Check the IncludeTimestamp\n            if (!validateTimestamp(binding.isIncludeTimestamp(), true, results, signedResults, message)) {\n                String error = \"Received Timestamp does not match the requirements\";\n                ai.setNotAsserted(error);\n                continue;\n            }\n            PolicyUtils.assertPolicy(aim, SPConstants.INCLUDE_TIMESTAMP);\n        }\n\n    }","id":37971,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        for (AssertionInfo ai : ais) {\n            TransportBinding binding = (TransportBinding)ai.getAssertion();\n            ai.setAsserted(true);\n            \n            // Check that TLS is in use if we are not the requestor\n            boolean initiator = MessageUtils.isRequestor(message);\n            TLSSessionInfo tlsInfo = message.get(TLSSessionInfo.class);\n            if (!initiator && tlsInfo == null) {\n                ai.setNotAsserted(\"TLS is not enabled\");\n                continue;\n            }\n            \n            // HttpsToken is validated by the HttpsTokenInterceptorProvider\n            if (binding.getTransportToken() != null) {\n                PolicyUtils.assertPolicy(aim, binding.getTransportToken().getName());\n            }\n            \n            // Check the IncludeTimestamp\n            if (!validateTimestamp(binding.isIncludeTimestamp(), true, results, signedResults, message)) {\n                String error = \"Received Timestamp does not match the requirements\";\n                ai.setNotAsserted(error);\n                continue;\n            }\n            PolicyUtils.assertPolicy(aim,\n                                     new QName(binding.getName().getNamespaceURI(), SPConstants.INCLUDE_TIMESTAMP));\n        }\n\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results\n    ) {\n        final List<Integer> actions = new ArrayList<Integer>(2);\n        actions.add(WSConstants.UT);\n        actions.add(WSConstants.UT_NOPASSWORD);\n        List<WSSecurityEngineResult> utResults = \n            WSSecurityUtil.fetchAllActionResults(results, actions);\n        \n        for (AssertionInfo ai : ais) {\n            org.apache.wss4j.policy.model.UsernameToken usernameTokenPolicy = \n                (org.apache.wss4j.policy.model.UsernameToken)ai.getAssertion();\n            ai.setAsserted(true);\n            if (!isTokenRequired(usernameTokenPolicy, message)) {\n                continue;\n            }\n\n            if (utResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            if (!checkTokens(usernameTokenPolicy, ai, utResults)) {\n                continue;\n            }\n        }\n    }","id":37972,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> results\n    ) {\n        final List<Integer> actions = new ArrayList<Integer>(2);\n        actions.add(WSConstants.UT);\n        actions.add(WSConstants.UT_NOPASSWORD);\n        List<WSSecurityEngineResult> utResults = \n            WSSecurityUtil.fetchAllActionResults(results, actions);\n        \n        for (AssertionInfo ai : ais) {\n            org.apache.wss4j.policy.model.UsernameToken usernameTokenPolicy = \n                (org.apache.wss4j.policy.model.UsernameToken)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(usernameTokenPolicy, aim);\n            \n            if (!isTokenRequired(usernameTokenPolicy, message)) {\n                continue;\n            }\n\n            if (utResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            if (!checkTokens(usernameTokenPolicy, ai, utResults)) {\n                continue;\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.USERNAME_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(ais, message, results);\n            \n            PolicyUtils.assertPolicy(aim, SP13Constants.CREATED);\n            PolicyUtils.assertPolicy(aim, SP13Constants.NONCE);\n            PolicyUtils.assertPolicy(aim, SPConstants.NO_PASSWORD);\n            PolicyUtils.assertPolicy(aim, SPConstants.HASH_PASSWORD);\n            PolicyUtils.assertPolicy(aim, SPConstants.USERNAME_TOKEN10);\n            PolicyUtils.assertPolicy(aim, SPConstants.USERNAME_TOKEN11);\n        }\n        \n        return true;\n    }","id":37973,"modified_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.USERNAME_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(aim, ais, message, results);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        Collection<AssertionInfo> ais, \n        Message message,  \n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> scResults =\n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.SC);\n        \n        for (AssertionInfo ai : ais) {\n            Wss11 wss11 = (Wss11)ai.getAssertion();\n            ai.setAsserted(true);\n\n            if (!MessageUtils.isRequestor(message)) {\n                continue;\n            }\n            \n            if ((wss11.isRequireSignatureConfirmation() && scResults.isEmpty())\n                || (!wss11.isRequireSignatureConfirmation() && !scResults.isEmpty())) {\n                ai.setNotAsserted(\n                    \"Signature Confirmation policy validation failed\"\n                );\n                continue;\n            }\n        }\n    }","id":37974,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,  \n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> scResults =\n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.SC);\n        \n        for (AssertionInfo ai : ais) {\n            Wss11 wss11 = (Wss11)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(wss11, aim);\n\n            if (!MessageUtils.isRequestor(message)) {\n                continue;\n            }\n            \n            if ((wss11.isRequireSignatureConfirmation() && scResults.isEmpty())\n                || (!wss11.isRequireSignatureConfirmation() && !scResults.isEmpty())) {\n                ai.setNotAsserted(\n                    \"Signature Confirmation policy validation failed\"\n                );\n                continue;\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.WSS11);\n        if (!ais.isEmpty()) {\n            parsePolicies(ais, message, results);\n            \n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_THUMBPRINT);\n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_ENCRYPTED_KEY);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_SIGNATURE_CONFIRMATION);\n            \n            // WSS 1.0\n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_KEY_IDENTIFIER);\n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_ISSUER_SERIAL);\n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_EXTERNAL_URI);\n            PolicyUtils.assertPolicy(aim, SPConstants.MUST_SUPPORT_REF_EMBEDDED_TOKEN);\n        }\n        \n        return true;\n    }","id":37975,"modified_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.WSS11);\n        if (!ais.isEmpty()) {\n            parsePolicies(aim, ais, message, results);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.X509_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(ais, message, signedResults, results);\n            \n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_PKI_PATH_V1_TOKEN10);\n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_PKI_PATH_V1_TOKEN11);\n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_V1_TOKEN10);\n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_V1_TOKEN11);\n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_V3_TOKEN10);\n            PolicyUtils.assertPolicy(aim, SPConstants.WSS_X509_V3_TOKEN11);\n            \n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_ISSUER_SERIAL_REFERENCE);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_THUMBPRINT_REFERENCE);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_KEY_IDENTIFIER_REFERENCE);\n            PolicyUtils.assertPolicy(aim, SPConstants.REQUIRE_EMBEDDED_TOKEN_REFERENCE);\n        }\n        \n        return true;\n    }","id":37976,"modified_method":"public boolean validatePolicy(\n        AssertionInfoMap aim,\n        Message message,\n        Element soapBody,\n        List<WSSecurityEngineResult> results,\n        List<WSSecurityEngineResult> signedResults\n    ) {\n        Collection<AssertionInfo> ais = \n            PolicyUtils.getAllAssertionsByLocalname(aim, SPConstants.X509_TOKEN);\n        if (!ais.isEmpty()) {\n            parsePolicies(aim, ais, message, signedResults, results);\n        }\n        \n        return true;\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"private void parsePolicies(\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> bstResults = \n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.BST);\n        \n        for (AssertionInfo ai : ais) {\n            X509Token x509TokenPolicy = (X509Token)ai.getAssertion();\n            ai.setAsserted(true);\n\n            if (!isTokenRequired(x509TokenPolicy, message)) {\n                continue;\n            }\n\n            if (bstResults.isEmpty() && signedResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            if (!checkTokenType(x509TokenPolicy.getTokenType(), bstResults, signedResults)) {\n                ai.setNotAsserted(\"An incorrect X.509 Token Type is detected\");\n                continue;\n            }\n        }\n    }","id":37977,"modified_method":"private void parsePolicies(\n        AssertionInfoMap aim,\n        Collection<AssertionInfo> ais, \n        Message message,\n        List<WSSecurityEngineResult> signedResults,\n        List<WSSecurityEngineResult> results\n    ) {\n        List<WSSecurityEngineResult> bstResults = \n            WSSecurityUtil.fetchAllActionResults(results, WSConstants.BST);\n        \n        for (AssertionInfo ai : ais) {\n            X509Token x509TokenPolicy = (X509Token)ai.getAssertion();\n            ai.setAsserted(true);\n            assertToken(x509TokenPolicy, aim);\n            \n            if (!isTokenRequired(x509TokenPolicy, message)) {\n                continue;\n            }\n\n            if (bstResults.isEmpty() && signedResults.isEmpty()) {\n                ai.setNotAsserted(\n                    \"The received token does not match the token inclusion requirement\"\n                );\n                continue;\n            }\n\n            if (!checkTokenType(x509TokenPolicy.getTokenType(), bstResults, signedResults)) {\n                ai.setNotAsserted(\"An incorrect X.509 Token Type is detected\");\n                continue;\n            }\n        }\n    }","commit_id":"d4f9674baa811936429271cbf64c4a558282c764","url":"https://github.com/apache/cxf"},{"original_method":"protected SchedulerFactory createSchedulerFactory() throws SchedulerException {\n        SchedulerFactory answer;\n\n        Properties prop = loadProperties();\n        if (prop != null) {\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        } else {\n            // read default props to be able to use a single scheduler per camel context\n            // if we need more than one scheduler per context use setScheduler(Scheduler) \n            // or setFactory(SchedulerFactory) methods\n\n            // must use classloader from StdSchedulerFactory to work even in OSGi\n            InputStream is = StdSchedulerFactory.class.getClassLoader().getResourceAsStream(\"org/quartz/quartz.properties\");\n            if (is == null) {\n                throw new SchedulerException(\"Quartz properties file not found in classpath: org/quartz/quartz.properties\");\n            }\n            prop = new Properties();\n            try {\n                prop.load(is);\n            } catch (IOException e) {\n                throw new SchedulerException(\"Error loading Quartz properties file from classpath: org/quartz/quartz.properties\", e);\n            }\n\n            // camel context name will be a suffix to use one scheduler per context\n            String identity = getCamelContext().getName();\n\n            String instName = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            if (instName == null) {\n                instName = \"scheduler-\" + identity;\n            } else {\n                instName = instName + \"-\" + identity;\n            }\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        }\n\n        if (LOG.isDebugEnabled()) {\n            String name = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            LOG.debug(\"Creating SchedulerFactory: {} with properties: {}\", name, prop);\n        }\n        return answer;\n    }","id":37978,"modified_method":"protected SchedulerFactory createSchedulerFactory() throws SchedulerException {\n        SchedulerFactory answer;\n\n        Properties prop = loadProperties();\n        if (prop != null) {\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n\n            // camel context name will be a suffix to use one scheduler per context\n            String instName = createInstanceName(prop);\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        } else {\n            // read default props to be able to use a single scheduler per camel context\n            // if we need more than one scheduler per context use setScheduler(Scheduler) \n            // or setFactory(SchedulerFactory) methods\n\n            // must use classloader from StdSchedulerFactory to work even in OSGi\n            InputStream is = StdSchedulerFactory.class.getClassLoader().getResourceAsStream(\"org/quartz/quartz.properties\");\n            if (is == null) {\n                throw new SchedulerException(\"Quartz properties file not found in classpath: org/quartz/quartz.properties\");\n            }\n            prop = new Properties();\n            try {\n                prop.load(is);\n            } catch (IOException e) {\n                throw new SchedulerException(\"Error loading Quartz properties file from classpath: org/quartz/quartz.properties\", e);\n            }\n\n            // camel context name will be a suffix to use one scheduler per context\n            String instName = createInstanceName(prop);\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        }\n\n        if (LOG.isDebugEnabled()) {\n            String name = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            LOG.debug(\"Creating SchedulerFactory: {} with properties: {}\", name, prop);\n        }\n        return answer;\n    }","commit_id":"b26df9f012568fe1d6997e06d05c78570db21a3e","url":"https://github.com/apache/camel"},{"original_method":"private SchedulerFactory createSchedulerFactory() throws SchedulerException {\n        SchedulerFactory answer;\n\n        Properties prop = loadProperties();\n        if (prop != null) {\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n            prop.put(\"org.terracotta.quartz.skipUpdateCheck\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        } else {\n            // read default props to be able to use a single scheduler per camel context\n            // if we need more than one scheduler per context use setScheduler(Scheduler)\n            // or setFactory(SchedulerFactory) methods\n\n            // must use classloader from StdSchedulerFactory to work even in OSGi\n            InputStream is = StdSchedulerFactory.class.getClassLoader().getResourceAsStream(\"org/quartz/quartz.properties\");\n            if (is == null) {\n                throw new SchedulerException(\"Quartz properties file not found in classpath: org/quartz/quartz.properties\");\n            }\n            prop = new Properties();\n            try {\n                prop.load(is);\n            } catch (IOException e) {\n                throw new SchedulerException(\"Error loading Quartz properties file from classpath: org/quartz/quartz.properties\", e);\n            }\n\n            // camel context name will be a suffix to use one scheduler per context\n            String identity = getCamelContext().getManagementName();\n\n            String instName = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            if (instName == null) {\n                instName = \"scheduler-\" + identity;\n            } else {\n                instName = instName + \"-\" + identity;\n            }\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n            prop.put(\"org.terracotta.quartz.skipUpdateCheck=true\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        }\n\n        if (LOG.isDebugEnabled()) {\n            String name = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            LOG.debug(\"Creating SchedulerFactory: {} with properties: {}\", name, prop);\n        }\n        return answer;\n    }","id":37979,"modified_method":"private SchedulerFactory createSchedulerFactory() throws SchedulerException {\n        SchedulerFactory answer;\n\n        Properties prop = loadProperties();\n        if (prop != null) {\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n            prop.put(\"org.terracotta.quartz.skipUpdateCheck\", \"true\");\n\n            // camel context name will be a suffix to use one scheduler per context\n            String instName = createInstanceName(prop);\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        } else {\n            // read default props to be able to use a single scheduler per camel context\n            // if we need more than one scheduler per context use setScheduler(Scheduler)\n            // or setFactory(SchedulerFactory) methods\n\n            // must use classloader from StdSchedulerFactory to work even in OSGi\n            InputStream is = StdSchedulerFactory.class.getClassLoader().getResourceAsStream(\"org/quartz/quartz.properties\");\n            if (is == null) {\n                throw new SchedulerException(\"Quartz properties file not found in classpath: org/quartz/quartz.properties\");\n            }\n            prop = new Properties();\n            try {\n                prop.load(is);\n            } catch (IOException e) {\n                throw new SchedulerException(\"Error loading Quartz properties file from classpath: org/quartz/quartz.properties\", e);\n            }\n\n            // camel context name will be a suffix to use one scheduler per context\n            String instName = createInstanceName(prop);\n            prop.setProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME, instName);\n\n            // force disabling update checker (will do online check over the internet)\n            prop.put(\"org.quartz.scheduler.skipUpdateCheck\", \"true\");\n            prop.put(\"org.terracotta.quartz.skipUpdateCheck=true\", \"true\");\n\n            // enable jmx unless configured to not do so\n            if (enableJmx && !prop.containsKey(\"org.quartz.scheduler.jmx.export\")) {\n                prop.put(\"org.quartz.scheduler.jmx.export\", \"true\");\n                LOG.info(\"Setting org.quartz.scheduler.jmx.export=true to ensure QuartzScheduler(s) will be enlisted in JMX.\");\n            }\n\n            answer = new StdSchedulerFactory(prop);\n        }\n\n        if (LOG.isDebugEnabled()) {\n            String name = prop.getProperty(StdSchedulerFactory.PROP_SCHED_INSTANCE_NAME);\n            LOG.debug(\"Creating SchedulerFactory: {} with properties: {}\", name, prop);\n        }\n        return answer;\n    }","commit_id":"b26df9f012568fe1d6997e06d05c78570db21a3e","url":"https://github.com/apache/camel"},{"original_method":"private static void addLocalPackages( File outputDirectory, Analyzer analyzer )\n    {\n        Collection packages = new TreeSet();\n\n        if ( outputDirectory != null && outputDirectory.isDirectory() )\n        {\n            // scan classes directory for potential packages\n            DirectoryScanner scanner = new DirectoryScanner();\n            scanner.setBasedir( outputDirectory );\n            scanner.setIncludes( new String[]\n                { \"**/*.class\" } );\n\n            scanner.addDefaultExcludes();\n            scanner.scan();\n\n            String[] paths = scanner.getIncludedFiles();\n            for ( int i = 0; i < paths.length; i++ )\n            {\n                packages.add( getPackageName( paths[i] ) );\n            }\n        }\n\n        StringBuffer exportedPkgs = new StringBuffer();\n        StringBuffer privatePkgs = new StringBuffer();\n\n        boolean noprivatePackages = \"!*\".equals( analyzer.getProperty( Analyzer.PRIVATE_PACKAGE ) );\n\n        for ( Iterator i = packages.iterator(); i.hasNext(); )\n        {\n            String pkg = ( String ) i.next();\n\n            // mark all source packages as private by default (can be overridden by export list)\n            if ( privatePkgs.length() > 0 )\n            {\n                privatePkgs.append( ';' );\n            }\n            privatePkgs.append( pkg );\n\n            // we can't export the default package (\".\") and we shouldn't export internal packages \n            if ( noprivatePackages || !( \".\".equals( pkg ) || pkg.contains( \".internal\" ) || pkg.contains( \".impl\" ) ) )\n            {\n                if ( exportedPkgs.length() > 0 )\n                {\n                    exportedPkgs.append( ';' );\n                }\n                exportedPkgs.append( pkg );\n            }\n        }\n\n        if ( analyzer.getProperty( Analyzer.EXPORT_PACKAGE ) == null )\n        {\n            if ( analyzer.getProperty( Analyzer.EXPORT_CONTENTS ) == null )\n            {\n                // no -exportcontents overriding the exports, so use our computed list\n                analyzer.setProperty( Analyzer.EXPORT_PACKAGE, exportedPkgs + \";-split-package:=merge-first\" );\n            }\n            else\n            {\n                // leave Export-Package empty (but non-null) as we have -exportcontents\n                analyzer.setProperty( Analyzer.EXPORT_PACKAGE, \"\" );\n            }\n        }\n        else\n        {\n            String exported = analyzer.getProperty( Analyzer.EXPORT_PACKAGE );\n            if ( exported.indexOf( LOCAL_PACKAGES ) >= 0 )\n            {\n                String newExported = StringUtils.replace( exported, LOCAL_PACKAGES, exportedPkgs.toString() );\n                analyzer.setProperty( Analyzer.EXPORT_PACKAGE, newExported );\n\n            }\n        }\n\n        String internal = analyzer.getProperty( Analyzer.PRIVATE_PACKAGE );\n        if ( internal == null )\n        {\n            if ( privatePkgs.length() > 0 )\n            {\n                analyzer.setProperty( Analyzer.PRIVATE_PACKAGE, privatePkgs + \";-split-package:=merge-first\" );\n            }\n            else\n            {\n                // if there are really no private packages then use \"!*\" as this will keep the Bnd Tool happy\n                analyzer.setProperty( Analyzer.PRIVATE_PACKAGE, \"!*\" );\n            }\n        }\n        else if ( internal.indexOf( LOCAL_PACKAGES ) >= 0 )\n        {\n            String newInternal = StringUtils.replace( internal, LOCAL_PACKAGES, privatePkgs.toString() );\n            analyzer.setProperty( Analyzer.PRIVATE_PACKAGE, newInternal );\n        }\n    }","id":37980,"modified_method":"private static void addLocalPackages( File outputDirectory, Analyzer analyzer ) throws IOException\n    {\n        Packages packages = new Packages();\n\n        if ( outputDirectory != null && outputDirectory.isDirectory() )\n        {\n            // scan classes directory for potential packages\n            DirectoryScanner scanner = new DirectoryScanner();\n            scanner.setBasedir( outputDirectory );\n            scanner.setIncludes( new String[]\n                { \"**/*.class\" } );\n\n            scanner.addDefaultExcludes();\n            scanner.scan();\n\n            String[] paths = scanner.getIncludedFiles();\n            for ( int i = 0; i < paths.length; i++ )\n            {\n                packages.put( analyzer.getPackageRef( getPackageName( paths[i] ) ) );\n            }\n        }\n\n        Packages exportedPkgs = new Packages();\n        Packages privatePkgs = new Packages();\n\n        boolean noprivatePackages = \"!*\".equals( analyzer.getProperty( Analyzer.PRIVATE_PACKAGE ) );\n\n        for ( PackageRef pkg : packages.keySet() )\n        {\n            // mark all source packages as private by default (can be overridden by export list)\n            privatePkgs.put( pkg );\n\n            // we can't export the default package (\".\") and we shouldn't export internal packages \n            String fqn = pkg.getFQN();\n            if ( noprivatePackages || !( \".\".equals( fqn ) || fqn.contains( \".internal\" ) || fqn.contains( \".impl\" ) ) )\n            {\n                exportedPkgs.put( pkg );\n            }\n        }\n\n        Properties properties = analyzer.getProperties();\n        String exported = properties.getProperty( Analyzer.EXPORT_PACKAGE );\n        if ( exported == null )\n        {\n            if ( !properties.containsKey( Analyzer.EXPORT_CONTENTS ) )\n            {\n                // no -exportcontents overriding the exports, so use our computed list\n                for ( Attrs attrs : exportedPkgs.values() )\n                {\n                    attrs.put( Constants.SPLIT_PACKAGE_DIRECTIVE, \"merge-first\" );\n                }\n                properties.setProperty( Analyzer.EXPORT_PACKAGE, Processor.printClauses( exportedPkgs ) );\n            }\n            else\n            {\n                // leave Export-Package empty (but non-null) as we have -exportcontents\n                properties.setProperty( Analyzer.EXPORT_PACKAGE, \"\" );\n            }\n        }\n        else if ( exported.indexOf( LOCAL_PACKAGES ) >= 0 )\n        {\n            String newExported = StringUtils.replace( exported, LOCAL_PACKAGES, Processor.printClauses( exportedPkgs ) );\n            properties.setProperty( Analyzer.EXPORT_PACKAGE, newExported );\n        }\n\n        String internal = properties.getProperty( Analyzer.PRIVATE_PACKAGE );\n        if ( internal == null )\n        {\n            if ( !privatePkgs.isEmpty() )\n            {\n                for ( Attrs attrs : privatePkgs.values() )\n                {\n                    attrs.put( Constants.SPLIT_PACKAGE_DIRECTIVE, \"merge-first\" );\n                }\n                properties.setProperty( Analyzer.PRIVATE_PACKAGE, Processor.printClauses( privatePkgs ) );\n            }\n            else\n            {\n                // if there are really no private packages then use \"!*\" as this will keep the Bnd Tool happy\n                properties.setProperty( Analyzer.PRIVATE_PACKAGE, \"!*\" );\n            }\n        }\n        else if ( internal.indexOf( LOCAL_PACKAGES ) >= 0 )\n        {\n            String newInternal = StringUtils.replace( internal, LOCAL_PACKAGES, Processor.printClauses( privatePkgs ) );\n            properties.setProperty( Analyzer.PRIVATE_PACKAGE, newInternal );\n        }\n    }","commit_id":"1648f401ba39cb7067f61619e1e1d9bc653f9405","url":"https://github.com/apache/felix"},{"original_method":"@Override\n    public <T> T executeTransaction(TransactionalTask<T> task) throws TransactionException {\n        throw new UnsupportedOperationException(\"Transactions not implemented yet!\");\n    }","id":37981,"modified_method":"@Override\n    public <T> T executeTransaction(TransactionalTask<T> task) throws TransactionException {\n        return executeTransaction(TransactionOptions.getDefault(), task);\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Override\n    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {\n        throw new UnsupportedOperationException(\"Transactions not implemented yet!\");\n    }","id":37982,"modified_method":"@Override\n    public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {\n        final TransactionContext context = newTransactionContext(options);\n        context.beginTransaction();\n        try {\n            final T value = task.execute(context);\n            context.commitTransaction();\n            return value;\n        } catch (Throwable e) {\n            context.rollbackTransaction();\n            if (e instanceof TransactionException) {\n                throw (TransactionException) e;\n            }\n            if (e.getCause() instanceof TransactionException) {\n                throw (TransactionException) e.getCause();\n            }\n            if (e instanceof RuntimeException) {\n                throw (RuntimeException) e;\n            }\n            throw new TransactionException(e);\n        }\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public TransactionContextProxy(HazelcastClient client, TransactionOptions options) {\n        this.client = client;\n        this.connection = connect();\n        if (connection == null){\n            throw new HazelcastException(\"Could not obtain Connection!!!\");\n        }\n        this.transaction = new TransactionProxy(client, options, connection);\n    }","id":37983,"modified_method":"public TransactionContextProxy(HazelcastClient client, TransactionOptions options) {\n        this.client = client;\n        this.connection = connect();\n        if (connection == null) {\n            throw new ClientException(\"Could not obtain Connection!!!\");\n        }\n        this.transaction = new TransactionProxy(client, options, connection);\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {\n        final TransactionContextImpl context = new TransactionContextImpl(this, nodeEngine, options, false);\n        context.beginTransaction();\n        try {\n            final T value = task.execute(context);\n            context.commitTransaction();\n            return value;\n        } catch (Throwable e) {\n            context.rollbackTransaction();\n            if (e instanceof TransactionException) {\n                throw (TransactionException) e;\n            }\n            if (e.getCause() instanceof TransactionException) {\n                throw (TransactionException) e.getCause();\n            }\n            if (e instanceof RuntimeException) {\n                throw (RuntimeException) e;\n            }\n            if (e instanceof Error) {\n                throw (Error) e;\n            }\n            throw new TransactionException(e);\n        }\n    }","id":37984,"modified_method":"public <T> T executeTransaction(TransactionOptions options, TransactionalTask<T> task) throws TransactionException {\n        final TransactionContextImpl context = new TransactionContextImpl(this, nodeEngine, options, false);\n        context.beginTransaction();\n        try {\n            final T value = task.execute(context);\n            context.commitTransaction();\n            return value;\n        } catch (Throwable e) {\n            context.rollbackTransaction();\n            if (e instanceof TransactionException) {\n                throw (TransactionException) e;\n            }\n            if (e.getCause() instanceof TransactionException) {\n                throw (TransactionException) e.getCause();\n            }\n            if (e instanceof RuntimeException) {\n                throw (RuntimeException) e;\n            }\n            throw new TransactionException(e);\n        }\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public long getTimeoutMillis() {\n        return 0;\n    }","id":37985,"modified_method":"public long getTimeoutMillis() {\n        return options.getTimeoutMillis();\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"private <T> T sendAndReceive(Object request) {\n        try {\n            return clusterService.sendAndReceiveFixedConnection(connection, request);\n        } catch (IOException e) {\n            ExceptionUtil.rethrow(e);\n        }\n        return null;\n    }","id":37986,"modified_method":"private <T> T sendAndReceive(Object request) {\n        try {\n            return clusterService.sendAndReceiveFixedConnection(connection, request);\n        } catch (IOException e) {\n            throw ExceptionUtil.rethrow(e);\n        }\n    }","commit_id":"ed3a66ae2475babd00dfb4437d3da44d501cc49f","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public boolean offerInternal(Data data, long timeout){\n        throwExceptionIfNull(data);\n        TxnReserveOfferOperation operation = new TxnReserveOfferOperation(name, timeout, offerIdQueue.size());\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<Long> f = invocation.invoke();\n            Long itemId = f.get();\n            if (itemId != null){\n                if(offerIdQueue.contains(itemId) || pollIdQueue.contains(itemId)){\n                    throw new TransactionException(\"Duplicate itemId: \" + itemId);\n                }\n                offerIdQueue.offer(new QueueItem(null, itemId, data));\n                tx.addTransactionLog(new QueueTransactionLog(itemId, name, partitionId, new TxnOfferOperation(name, itemId, data)));\n                return true;\n            }\n        } catch (Throwable t) {\n            ExceptionUtil.rethrow(t);\n        }\n        return false;\n    }","id":37987,"modified_method":"public boolean offerInternal(Data data, long timeout) {\n        throwExceptionIfNull(data);\n        TxnReserveOfferOperation operation = new TxnReserveOfferOperation(name, timeout, offerIdQueue.size());\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<Long> f = invocation.invoke();\n            Long itemId = f.get();\n            if (itemId != null) {\n                // TODO: @mm - offerIdQueue is queue of QueueItems not longs!\n                // !!! offerIdQueue.contains(item.getItemId() fails always !!!\n                if (offerIdQueue.contains(itemId) || pollIdQueue.contains(itemId)) {\n                    throw new TransactionException(\"Duplicate itemId: \" + itemId);\n                }\n                offerIdQueue.offer(new QueueItem(null, itemId, data));\n                tx.addTransactionLog(new QueueTransactionLog(itemId, name, partitionId, new TxnOfferOperation(name, itemId, data)));\n                return true;\n            }\n        } catch (Throwable t) {\n            throw ExceptionUtil.rethrow(t);\n        }\n        return false;\n    }","commit_id":"87b1e47ee96328755b9ab6b3504a002da1190e58","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public Data pollInternal(long timeout){\n        QueueItem reservedOffer = offerIdQueue.peek();\n        TxnReservePollOperation operation = new TxnReservePollOperation(name, timeout, reservedOffer == null ? -1 : reservedOffer.getItemId());\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<QueueItem> f = invocation.invoke();\n            QueueItem item = f.get();\n            if (item != null){\n                if (reservedOffer != null && item.getItemId() == reservedOffer.getItemId()){\n                    offerIdQueue.poll();\n                    tx.removeTransactionLog(reservedOffer.getItemId());\n                    return reservedOffer.getData();\n                }\n                if(pollIdQueue.contains(item.getItemId()) || offerIdQueue.contains(item.getItemId())){\n                    throw new TransactionException(\"Duplicate itemId: \" + item.getItemId());\n                }\n                pollIdQueue.offer(item.getItemId());\n                tx.addTransactionLog(new QueueTransactionLog(item.getItemId(), name, partitionId, new TxnPollOperation(name, item.getItemId())));\n                return item.getData();\n            }\n        } catch (Throwable t) {\n            ExceptionUtil.rethrow(t);\n        }\n        return null;\n    }","id":37988,"modified_method":"public Data pollInternal(long timeout) {\n        QueueItem reservedOffer = offerIdQueue.peek();\n        TxnReservePollOperation operation = new TxnReservePollOperation(name, timeout, reservedOffer == null ? -1 : reservedOffer.getItemId());\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<QueueItem> f = invocation.invoke();\n            QueueItem item = f.get();\n            if (item != null) {\n                if (reservedOffer != null && item.getItemId() == reservedOffer.getItemId()) {\n                    offerIdQueue.poll();\n                    tx.removeTransactionLog(reservedOffer.getItemId());\n                    return reservedOffer.getData();\n                }\n                if (pollIdQueue.contains(item.getItemId()) || offerIdQueue.contains(item)) {\n                    throw new TransactionException(\"Duplicate itemId: \" + item.getItemId());\n                }\n                pollIdQueue.offer(item.getItemId());\n                tx.addTransactionLog(new QueueTransactionLog(item.getItemId(), name, partitionId, new TxnPollOperation(name, item.getItemId())));\n                return item.getData();\n            }\n        } catch (Throwable t) {\n            throw ExceptionUtil.rethrow(t);\n        }\n        return null;\n    }","commit_id":"87b1e47ee96328755b9ab6b3504a002da1190e58","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"public int size() {\n        SizeOperation operation = new SizeOperation(name);\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<Integer> f = invocation.invoke();\n            Integer size = f.get();\n            return size + offerIdQueue.size();\n        } catch (Throwable t) {\n            ExceptionUtil.rethrow(t);\n        }\n        return 0;\n    }","id":37989,"modified_method":"public int size() {\n        SizeOperation operation = new SizeOperation(name);\n        try {\n            Invocation invocation = getNodeEngine().getOperationService().createInvocationBuilder(QueueService.SERVICE_NAME, operation, partitionId).build();\n            Future<Integer> f = invocation.invoke();\n            Integer size = f.get();\n            return size + offerIdQueue.size();\n        } catch (Throwable t) {\n            throw ExceptionUtil.rethrow(t);\n        }\n    }","commit_id":"87b1e47ee96328755b9ab6b3504a002da1190e58","url":"https://github.com/hazelcast/hazelcast"},{"original_method":"@Nullable\n    private StackTraceElement parseStackTraceLine(@NotNull String line) {\n        Matcher matcher = STACK_TRACE_ELEMENT_PATTERN.matcher(line);\n        if (matcher.matches()) {\n            String declaringClass = matcher.group(1);\n            String methodName = matcher.group(2);\n            String fileName = matcher.group(3);\n            int lineNumber = Integer.parseInt(matcher.group(4));\n            return new StackTraceElement(declaringClass, methodName, fileName, lineNumber);\n        }\n        return null;\n    }","id":37990,"modified_method":"@Nullable\n    private static StackTraceElement parseStackTraceLine(@NotNull String line) {\n        Matcher matcher = STACK_TRACE_ELEMENT_PATTERN.matcher(line);\n        if (matcher.matches()) {\n            String declaringClass = matcher.group(1);\n            String methodName = matcher.group(2);\n            String fileName = matcher.group(3);\n            String lineNumber = matcher.group(4);\n            //noinspection ConstantConditions\n            return new StackTraceElement(declaringClass, methodName, fileName, Integer.parseInt(lineNumber));\n        }\n        return null;\n    }","commit_id":"43c26d0947f2406712802682cc8daca61770440b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public JetExceptionFilter(@NotNull GlobalSearchScope searchScope) {\n        exceptionFilter = new ExceptionFilter(searchScope);\n        this.searchScope = searchScope;\n    }","id":37991,"modified_method":"public JetExceptionFilter(@NotNull GlobalSearchScope searchScope) {\n        this.exceptionFilter = new ExceptionFilter(searchScope);\n        this.searchScope = searchScope;\n    }","commit_id":"43c26d0947f2406712802682cc8daca61770440b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    private Result patchResult(@NotNull Result result, @NotNull String line) {\n        HyperlinkInfo newHyperlinkInfo = createHyperlinkInfo(line);\n        return newHyperlinkInfo == null ? result :\n               new Result(result.highlightStartOffset, result.highlightEndOffset, newHyperlinkInfo, result.highlightAttributes);\n    }","id":37992,"modified_method":"@NotNull\n    private Result patchResult(@NotNull Result result, @NotNull String line) {\n        final HyperlinkInfo newHyperlinkInfo = createHyperlinkInfo(line);\n        if (newHyperlinkInfo == null) return result;\n\n        return new Result(KotlinPackage.map(result.getResultItems(), new Function1<ResultItem, ResultItem>() {\n            @Override\n            public ResultItem invoke(ResultItem item) {\n                return new ResultItem(item.getHighlightStartOffset(), item.getHighlightEndOffset(), newHyperlinkInfo,\n                                      item.getHighlightAttributes());\n            }\n        }));\n    }","commit_id":"43c26d0947f2406712802682cc8daca61770440b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void configure() {\n        try {\n            String path = getTestDataPath() + getTestRoot() + getTestName(true);\n\n            rootDir = PsiTestUtil.createTestProjectStructure(myProject, myModule, path, myFilesToDelete, false);\n            prepareProject(rootDir);\n            PsiDocumentManager.getInstance(myProject).commitAllDocuments();\n        }\n        catch (Exception e) {\n            UtilsPackage.rethrow(e);\n        }\n    }","id":37993,"modified_method":"private void configure() {\n        try {\n            String path = getTestDataPath() + getTestRoot() + getTestName(true);\n\n            rootDir = PsiTestUtil.createTestProjectStructure(myProject, myModule, path, myFilesToDelete, false);\n            prepareProject(rootDir);\n            PsiDocumentManager.getInstance(myProject).commitAllDocuments();\n        }\n        catch (Exception e) {\n            throw UtilsPackage.rethrow(e);\n        }\n    }","commit_id":"43c26d0947f2406712802682cc8daca61770440b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void doTest(@NotNull String fileName, @NotNull String className, int lineNumber) {\n        if (rootDir == null) {\n            configure();\n        }\n        assert rootDir != null;\n\n        Filter filter = jetExceptionFilterFactory.create(GlobalSearchScope.allScope(myProject));\n\n        String line = createStackTraceElementLine(fileName, className, lineNumber);\n        Filter.Result result = filter.applyFilter(line, 0);\n\n        assertNotNull(result);\n        assertInstanceOf(result.hyperlinkInfo, OpenFileHyperlinkInfo.class);\n        OpenFileHyperlinkInfo info = (OpenFileHyperlinkInfo) result.hyperlinkInfo;\n        OpenFileDescriptor descriptor = info.getDescriptor();\n        assertNotNull(descriptor);\n\n        VirtualFile expectedFile = VfsUtil.findRelativeFile(fileName, rootDir);\n        assertNotNull(expectedFile);\n        assertEquals(expectedFile, descriptor.getFile());\n\n        Document document = FileDocumentManager.getInstance().getDocument(expectedFile);\n        assertNotNull(document);\n        int expectedOffset = document.getLineStartOffset(lineNumber - 1);\n        assertEquals(expectedOffset, descriptor.getOffset());\n    }","id":37994,"modified_method":"private void doTest(@NotNull String fileName, @NotNull String className, int lineNumber) {\n        if (rootDir == null) {\n            configure();\n        }\n        assert rootDir != null;\n\n        Filter filter = new JetExceptionFilterFactory().create(GlobalSearchScope.allScope(myProject));\n\n        String line = createStackTraceElementLine(fileName, className, lineNumber);\n        Filter.Result result = filter.applyFilter(line, 0);\n\n        assertNotNull(result);\n        HyperlinkInfo info = result.getFirstHyperlinkInfo();\n        assertNotNull(info);\n        assertInstanceOf(info, OpenFileHyperlinkInfo.class);\n        OpenFileDescriptor descriptor = ((OpenFileHyperlinkInfo) info).getDescriptor();\n        assertNotNull(descriptor);\n\n        VirtualFile expectedFile = VfsUtilCore.findRelativeFile(fileName, rootDir);\n        assertNotNull(expectedFile);\n        assertEquals(expectedFile, descriptor.getFile());\n\n        Document document = FileDocumentManager.getInstance().getDocument(expectedFile);\n        assertNotNull(document);\n        int expectedOffset = document.getLineStartOffset(lineNumber - 1);\n        assertEquals(expectedOffset, descriptor.getOffset());\n    }","commit_id":"43c26d0947f2406712802682cc8daca61770440b","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private void blackBox() {\n        ClassFileFactory factory = generateClassesInFile();\n        GeneratedClassLoader loader = createClassLoader(factory);\n\n        // If there are many files, the first of them should contain the 'box(): String' function\n        JetFile firstFile = myFiles.getPsiFiles().get(0);\n        String fqName = getPackageClassFqName(JetPsiUtil.getFQName(firstFile)).asString();\n\n        try {\n            Class<?> namespaceClass = loader.loadClass(fqName);\n            Method method = namespaceClass.getMethod(\"box\");\n\n            String r = (String) method.invoke(null);\n            assertEquals(\"OK\", r);\n        } catch (Throwable e) {\n            System.out.println(generateToText());\n            ExceptionUtils.rethrow(e);\n        }\n    }","id":37995,"modified_method":"private void blackBox() {\n        // If there are many files, the first of them should contain the 'box(): String' function\n        JetFile firstFile = myFiles.getPsiFiles().get(0);\n        String fqName = getPackageClassFqName(JetPsiUtil.getFQName(firstFile)).asString();\n\n        try {\n            Method method = generateClass(fqName).getMethod(\"box\");\n            String r = (String) method.invoke(null);\n            assertEquals(\"OK\", r);\n        } catch (Throwable e) {\n            System.out.println(generateToText());\n            throw ExceptionUtils.rethrow(e);\n        }\n    }","commit_id":"5539a294398bd70472a3887c926355edf1913cf4","url":"https://github.com/JetBrains/kotlin"},{"original_method":"private ClassLoader loadFileGetClassLoader(@NotNull String text) {\n        loadText(text);\n        ClassFileFactory state = generateClassesInFile();\n        return createClassLoader(state);\n    }","id":37996,"modified_method":"private ClassLoader loadFileGetClassLoader(@NotNull String text) {\n        loadText(text);\n        return generateAndCreateClassLoader();\n    }","commit_id":"5539a294398bd70472a3887c926355edf1913cf4","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public void testDelegationToVal() throws Exception {\n        loadFile(\"classes/delegationToVal.kt\");\n        ClassFileFactory state = generateClassesInFile();\n        GeneratedClassLoader loader = createClassLoader(state);\n        Class aClass = loader.loadClass(PackageClassUtils.getPackageClassName(FqName.ROOT));\n        assertEquals(\"OK\", aClass.getMethod(\"box\").invoke(null));\n\n        Class test = loader.loadClass(\"Test\");\n        try {\n            test.getDeclaredField(\"$delegate_0\");\n            fail(\"$delegate_0 field generated for class Test but should not\");\n        }\n        catch (NoSuchFieldException e) {}\n\n        Class test2 = loader.loadClass(\"Test2\");\n        try {\n            test2.getDeclaredField(\"$delegate_0\");\n            fail(\"$delegate_0 field generated for class Test2 but should not\");\n        }\n        catch (NoSuchFieldException e) {}\n\n        Class test3 = loader.loadClass(\"Test3\");\n        Class iActing = loader.loadClass(\"IActing\");\n        Object obj = test3.newInstance();\n        assertTrue(iActing.isInstance(obj));\n        Method iActingMethod = iActing.getMethod(\"act\");\n        assertEquals(\"OK\", iActingMethod.invoke(obj));\n        assertEquals(\"OKOK\", iActingMethod.invoke(test3.getMethod(\"getActing\").invoke(obj)));\n    }","id":37997,"modified_method":"public void testDelegationToVal() throws Exception {\n        loadFile(\"classes/delegationToVal.kt\");\n        GeneratedClassLoader loader = generateAndCreateClassLoader();\n        Class aClass = loader.loadClass(PackageClassUtils.getPackageClassName(FqName.ROOT));\n        assertEquals(\"OK\", aClass.getMethod(\"box\").invoke(null));\n\n        Class test = loader.loadClass(\"Test\");\n        try {\n            test.getDeclaredField(\"$delegate_0\");\n            fail(\"$delegate_0 field generated for class Test but should not\");\n        }\n        catch (NoSuchFieldException e) {}\n\n        Class test2 = loader.loadClass(\"Test2\");\n        try {\n            test2.getDeclaredField(\"$delegate_0\");\n            fail(\"$delegate_0 field generated for class Test2 but should not\");\n        }\n        catch (NoSuchFieldException e) {}\n\n        Class test3 = loader.loadClass(\"Test3\");\n        Class iActing = loader.loadClass(\"IActing\");\n        Object obj = test3.newInstance();\n        assertTrue(iActing.isInstance(obj));\n        Method iActingMethod = iActing.getMethod(\"act\");\n        assertEquals(\"OK\", iActingMethod.invoke(obj));\n        assertEquals(\"OKOK\", iActingMethod.invoke(test3.getMethod(\"getActing\").invoke(obj)));\n    }","commit_id":"5539a294398bd70472a3887c926355edf1913cf4","url":"https://github.com/JetBrains/kotlin"},{"original_method":"public void testClassObjectIsInnerClass() throws Exception {\n        loadFile(\"classes/classObjectIsInnerClass.kt\");\n        GeneratedClassLoader loader = createClassLoader(generateClassesInFile());\n        Class<?> a = loader.loadClass(\"A\");\n        Class<?> aClassObject = loader.loadClass(\"A\" + JvmAbi.CLASS_OBJECT_SUFFIX);\n        assertSameElements(a.getDeclaredClasses(), aClassObject);\n        assertEquals(a, aClassObject.getDeclaringClass());\n    }","id":37998,"modified_method":"public void testClassObjectIsInnerClass() throws Exception {\n        loadFile(\"classes/classObjectIsInnerClass.kt\");\n        GeneratedClassLoader loader = generateAndCreateClassLoader();\n        Class<?> a = loader.loadClass(\"A\");\n        Class<?> aClassObject = loader.loadClass(\"A\" + JvmAbi.CLASS_OBJECT_SUFFIX);\n        assertSameElements(a.getDeclaredClasses(), aClassObject);\n        assertEquals(a, aClassObject.getDeclaringClass());\n    }","commit_id":"5539a294398bd70472a3887c926355edf1913cf4","url":"https://github.com/JetBrains/kotlin"},{"original_method":"@NotNull\n    protected Class<?> generateClass(@NotNull String name) {\n        try {\n            return createClassLoader(generateClassesInFile()).loadClass(name);\n        } catch (ClassNotFoundException e) {\n            fail(\"No class file was generated for: \" + name);\n            return null;\n        }\n    }","id":37999,"modified_method":"@NotNull\n    protected Class<?> generateClass(@NotNull String name) {\n        try {\n            return generateAndCreateClassLoader().loadClass(name);\n        } catch (ClassNotFoundException e) {\n            fail(\"No class file was generated for: \" + name);\n            return null;\n        }\n    }","commit_id":"5539a294398bd70472a3887c926355edf1913cf4","url":"https://github.com/JetBrains/kotlin"}]